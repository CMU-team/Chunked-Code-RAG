[{"name": "abc", "path": "library/abc", "type": "Runtime", "text": "\nSource code: Lib/abc.py\n\nThis module provides the infrastructure for defining abstract base classes\n(ABCs) in Python, as outlined in PEP 3119; see the PEP for why this was added\nto Python. (See also PEP 3141 and the `numbers` module regarding a type\nhierarchy for numbers based on ABCs.)\n\nThe `collections` module has some concrete classes that derive from ABCs;\nthese can, of course, be further derived. In addition, the `collections.abc`\nsubmodule has some ABCs that can be used to test whether a class or instance\nprovides a particular interface, for example, if it is hashable or if it is a\nmapping.\n\nThis module provides the metaclass `ABCMeta` for defining ABCs and a helper\nclass `ABC` to alternatively define ABCs through inheritance:\n\nA helper class that has `ABCMeta` as its metaclass. With this class, an\nabstract base class can be created by simply deriving from `ABC` avoiding\nsometimes confusing metaclass usage, for example:\n\nNote that the type of `ABC` is still `ABCMeta`, therefore inheriting from\n`ABC` requires the usual precautions regarding metaclass usage, as multiple\ninheritance may lead to metaclass conflicts. One may also define an abstract\nbase class by passing the metaclass keyword and using `ABCMeta` directly, for\nexample:\n\nNew in version 3.4.\n\nMetaclass for defining Abstract Base Classes (ABCs).\n\nUse this metaclass to create an ABC. An ABC can be subclassed directly, and\nthen acts as a mix-in class. You can also register unrelated concrete classes\n(even built-in classes) and unrelated ABCs as \u201cvirtual subclasses\u201d \u2013 these and\ntheir descendants will be considered subclasses of the registering ABC by the\nbuilt-in `issubclass()` function, but the registering ABC won\u2019t show up in\ntheir MRO (Method Resolution Order) nor will method implementations defined by\nthe registering ABC be callable (not even via `super()`). 1\n\nClasses created with a metaclass of `ABCMeta` have the following method:\n\nRegister subclass as a \u201cvirtual subclass\u201d of this ABC. For example:\n\nChanged in version 3.3: Returns the registered subclass, to allow usage as a\nclass decorator.\n\nChanged in version 3.4: To detect calls to `register()`, you can use the\n`get_cache_token()` function.\n\nYou can also override this method in an abstract base class:\n\n(Must be defined as a class method.)\n\nCheck whether subclass is considered a subclass of this ABC. This means that\nyou can customize the behavior of `issubclass` further without the need to\ncall `register()` on every class you want to consider a subclass of the ABC.\n(This class method is called from the `__subclasscheck__()` method of the\nABC.)\n\nThis method should return `True`, `False` or `NotImplemented`. If it returns\n`True`, the subclass is considered a subclass of this ABC. If it returns\n`False`, the subclass is not considered a subclass of this ABC, even if it\nwould normally be one. If it returns `NotImplemented`, the subclass check is\ncontinued with the usual mechanism.\n\nFor a demonstration of these concepts, look at this example ABC definition:\n\nThe ABC `MyIterable` defines the standard iterable method, `__iter__()`, as an\nabstract method. The implementation given here can still be called from\nsubclasses. The `get_iterator()` method is also part of the `MyIterable`\nabstract base class, but it does not have to be overridden in non-abstract\nderived classes.\n\nThe `__subclasshook__()` class method defined here says that any class that\nhas an `__iter__()` method in its `__dict__` (or in that of one of its base\nclasses, accessed via the `__mro__` list) is considered a `MyIterable` too.\n\nFinally, the last line makes `Foo` a virtual subclass of `MyIterable`, even\nthough it does not define an `__iter__()` method (it uses the old-style\niterable protocol, defined in terms of `__len__()` and `__getitem__()`). Note\nthat this will not make `get_iterator` available as a method of `Foo`, so it\nis provided separately.\n\nThe `abc` module also provides the following decorator:\n\nA decorator indicating abstract methods.\n\nUsing this decorator requires that the class\u2019s metaclass is `ABCMeta` or is\nderived from it. A class that has a metaclass derived from `ABCMeta` cannot be\ninstantiated unless all of its abstract methods and properties are overridden.\nThe abstract methods can be called using any of the normal \u2018super\u2019 call\nmechanisms. `abstractmethod()` may be used to declare abstract methods for\nproperties and descriptors.\n\nDynamically adding abstract methods to a class, or attempting to modify the\nabstraction status of a method or class once it is created, are not supported.\nThe `abstractmethod()` only affects subclasses derived using regular\ninheritance; \u201cvirtual subclasses\u201d registered with the ABC\u2019s `register()`\nmethod are not affected.\n\nWhen `abstractmethod()` is applied in combination with other method\ndescriptors, it should be applied as the innermost decorator, as shown in the\nfollowing usage examples:\n\nIn order to correctly interoperate with the abstract base class machinery, the\ndescriptor must identify itself as abstract using `__isabstractmethod__`. In\ngeneral, this attribute should be `True` if any of the methods used to compose\nthe descriptor are abstract. For example, Python\u2019s built-in `property` does\nthe equivalent of:\n\nNote\n\nUnlike Java abstract methods, these abstract methods may have an\nimplementation. This implementation can be called via the `super()` mechanism\nfrom the class that overrides it. This could be useful as an end-point for a\nsuper-call in a framework that uses cooperative multiple-inheritance.\n\nThe `abc` module also supports the following legacy decorators:\n\nNew in version 3.2.\n\nDeprecated since version 3.3: It is now possible to use `classmethod` with\n`abstractmethod()`, making this decorator redundant.\n\nA subclass of the built-in `classmethod()`, indicating an abstract\nclassmethod. Otherwise it is similar to `abstractmethod()`.\n\nThis special case is deprecated, as the `classmethod()` decorator is now\ncorrectly identified as abstract when applied to an abstract method:\n\nNew in version 3.2.\n\nDeprecated since version 3.3: It is now possible to use `staticmethod` with\n`abstractmethod()`, making this decorator redundant.\n\nA subclass of the built-in `staticmethod()`, indicating an abstract\nstaticmethod. Otherwise it is similar to `abstractmethod()`.\n\nThis special case is deprecated, as the `staticmethod()` decorator is now\ncorrectly identified as abstract when applied to an abstract method:\n\nDeprecated since version 3.3: It is now possible to use `property`,\n`property.getter()`, `property.setter()` and `property.deleter()` with\n`abstractmethod()`, making this decorator redundant.\n\nA subclass of the built-in `property()`, indicating an abstract property.\n\nThis special case is deprecated, as the `property()` decorator is now\ncorrectly identified as abstract when applied to an abstract method:\n\nThe above example defines a read-only property; you can also define a read-\nwrite abstract property by appropriately marking one or more of the underlying\nmethods as abstract:\n\nIf only some components are abstract, only those components need to be updated\nto create a concrete property in a subclass:\n\nThe `abc` module also provides the following functions:\n\nReturns the current abstract base class cache token.\n\nThe token is an opaque object (that supports equality testing) identifying the\ncurrent version of the abstract base class cache for virtual subclasses. The\ntoken changes with every call to `ABCMeta.register()` on any ABC.\n\nNew in version 3.4.\n\nC++ programmers should note that Python\u2019s virtual base class concept is not\nthe same as C++\u2019s.\n\n"}, {"name": "abc.ABC", "path": "library/abc#abc.ABC", "type": "Runtime", "text": "\nA helper class that has `ABCMeta` as its metaclass. With this class, an\nabstract base class can be created by simply deriving from `ABC` avoiding\nsometimes confusing metaclass usage, for example:\n\nNote that the type of `ABC` is still `ABCMeta`, therefore inheriting from\n`ABC` requires the usual precautions regarding metaclass usage, as multiple\ninheritance may lead to metaclass conflicts. One may also define an abstract\nbase class by passing the metaclass keyword and using `ABCMeta` directly, for\nexample:\n\nNew in version 3.4.\n\n"}, {"name": "abc.ABCMeta", "path": "library/abc#abc.ABCMeta", "type": "Runtime", "text": "\nMetaclass for defining Abstract Base Classes (ABCs).\n\nUse this metaclass to create an ABC. An ABC can be subclassed directly, and\nthen acts as a mix-in class. You can also register unrelated concrete classes\n(even built-in classes) and unrelated ABCs as \u201cvirtual subclasses\u201d \u2013 these and\ntheir descendants will be considered subclasses of the registering ABC by the\nbuilt-in `issubclass()` function, but the registering ABC won\u2019t show up in\ntheir MRO (Method Resolution Order) nor will method implementations defined by\nthe registering ABC be callable (not even via `super()`). 1\n\nClasses created with a metaclass of `ABCMeta` have the following method:\n\nRegister subclass as a \u201cvirtual subclass\u201d of this ABC. For example:\n\nChanged in version 3.3: Returns the registered subclass, to allow usage as a\nclass decorator.\n\nChanged in version 3.4: To detect calls to `register()`, you can use the\n`get_cache_token()` function.\n\nYou can also override this method in an abstract base class:\n\n(Must be defined as a class method.)\n\nCheck whether subclass is considered a subclass of this ABC. This means that\nyou can customize the behavior of `issubclass` further without the need to\ncall `register()` on every class you want to consider a subclass of the ABC.\n(This class method is called from the `__subclasscheck__()` method of the\nABC.)\n\nThis method should return `True`, `False` or `NotImplemented`. If it returns\n`True`, the subclass is considered a subclass of this ABC. If it returns\n`False`, the subclass is not considered a subclass of this ABC, even if it\nwould normally be one. If it returns `NotImplemented`, the subclass check is\ncontinued with the usual mechanism.\n\nFor a demonstration of these concepts, look at this example ABC definition:\n\nThe ABC `MyIterable` defines the standard iterable method, `__iter__()`, as an\nabstract method. The implementation given here can still be called from\nsubclasses. The `get_iterator()` method is also part of the `MyIterable`\nabstract base class, but it does not have to be overridden in non-abstract\nderived classes.\n\nThe `__subclasshook__()` class method defined here says that any class that\nhas an `__iter__()` method in its `__dict__` (or in that of one of its base\nclasses, accessed via the `__mro__` list) is considered a `MyIterable` too.\n\nFinally, the last line makes `Foo` a virtual subclass of `MyIterable`, even\nthough it does not define an `__iter__()` method (it uses the old-style\niterable protocol, defined in terms of `__len__()` and `__getitem__()`). Note\nthat this will not make `get_iterator` available as a method of `Foo`, so it\nis provided separately.\n\n"}, {"name": "abc.ABCMeta.register()", "path": "library/abc#abc.ABCMeta.register", "type": "Runtime", "text": "\nRegister subclass as a \u201cvirtual subclass\u201d of this ABC. For example:\n\nChanged in version 3.3: Returns the registered subclass, to allow usage as a\nclass decorator.\n\nChanged in version 3.4: To detect calls to `register()`, you can use the\n`get_cache_token()` function.\n\n"}, {"name": "abc.ABCMeta.__subclasshook__()", "path": "library/abc#abc.ABCMeta.__subclasshook__", "type": "Runtime", "text": "\n(Must be defined as a class method.)\n\nCheck whether subclass is considered a subclass of this ABC. This means that\nyou can customize the behavior of `issubclass` further without the need to\ncall `register()` on every class you want to consider a subclass of the ABC.\n(This class method is called from the `__subclasscheck__()` method of the\nABC.)\n\nThis method should return `True`, `False` or `NotImplemented`. If it returns\n`True`, the subclass is considered a subclass of this ABC. If it returns\n`False`, the subclass is not considered a subclass of this ABC, even if it\nwould normally be one. If it returns `NotImplemented`, the subclass check is\ncontinued with the usual mechanism.\n\n"}, {"name": "abc.abstractclassmethod()", "path": "library/abc#abc.abstractclassmethod", "type": "Runtime", "text": "\nNew in version 3.2.\n\nDeprecated since version 3.3: It is now possible to use `classmethod` with\n`abstractmethod()`, making this decorator redundant.\n\nA subclass of the built-in `classmethod()`, indicating an abstract\nclassmethod. Otherwise it is similar to `abstractmethod()`.\n\nThis special case is deprecated, as the `classmethod()` decorator is now\ncorrectly identified as abstract when applied to an abstract method:\n\n"}, {"name": "abc.abstractmethod()", "path": "library/abc#abc.abstractmethod", "type": "Runtime", "text": "\nA decorator indicating abstract methods.\n\nUsing this decorator requires that the class\u2019s metaclass is `ABCMeta` or is\nderived from it. A class that has a metaclass derived from `ABCMeta` cannot be\ninstantiated unless all of its abstract methods and properties are overridden.\nThe abstract methods can be called using any of the normal \u2018super\u2019 call\nmechanisms. `abstractmethod()` may be used to declare abstract methods for\nproperties and descriptors.\n\nDynamically adding abstract methods to a class, or attempting to modify the\nabstraction status of a method or class once it is created, are not supported.\nThe `abstractmethod()` only affects subclasses derived using regular\ninheritance; \u201cvirtual subclasses\u201d registered with the ABC\u2019s `register()`\nmethod are not affected.\n\nWhen `abstractmethod()` is applied in combination with other method\ndescriptors, it should be applied as the innermost decorator, as shown in the\nfollowing usage examples:\n\nIn order to correctly interoperate with the abstract base class machinery, the\ndescriptor must identify itself as abstract using `__isabstractmethod__`. In\ngeneral, this attribute should be `True` if any of the methods used to compose\nthe descriptor are abstract. For example, Python\u2019s built-in `property` does\nthe equivalent of:\n\nNote\n\nUnlike Java abstract methods, these abstract methods may have an\nimplementation. This implementation can be called via the `super()` mechanism\nfrom the class that overrides it. This could be useful as an end-point for a\nsuper-call in a framework that uses cooperative multiple-inheritance.\n\n"}, {"name": "abc.abstractproperty()", "path": "library/abc#abc.abstractproperty", "type": "Runtime", "text": "\nDeprecated since version 3.3: It is now possible to use `property`,\n`property.getter()`, `property.setter()` and `property.deleter()` with\n`abstractmethod()`, making this decorator redundant.\n\nA subclass of the built-in `property()`, indicating an abstract property.\n\nThis special case is deprecated, as the `property()` decorator is now\ncorrectly identified as abstract when applied to an abstract method:\n\nThe above example defines a read-only property; you can also define a read-\nwrite abstract property by appropriately marking one or more of the underlying\nmethods as abstract:\n\nIf only some components are abstract, only those components need to be updated\nto create a concrete property in a subclass:\n\n"}, {"name": "abc.abstractstaticmethod()", "path": "library/abc#abc.abstractstaticmethod", "type": "Runtime", "text": "\nNew in version 3.2.\n\nDeprecated since version 3.3: It is now possible to use `staticmethod` with\n`abstractmethod()`, making this decorator redundant.\n\nA subclass of the built-in `staticmethod()`, indicating an abstract\nstaticmethod. Otherwise it is similar to `abstractmethod()`.\n\nThis special case is deprecated, as the `staticmethod()` decorator is now\ncorrectly identified as abstract when applied to an abstract method:\n\n"}, {"name": "abc.get_cache_token()", "path": "library/abc#abc.get_cache_token", "type": "Runtime", "text": "\nReturns the current abstract base class cache token.\n\nThe token is an opaque object (that supports equality testing) identifying the\ncurrent version of the abstract base class cache for virtual subclasses. The\ntoken changes with every call to `ABCMeta.register()` on any ABC.\n\nNew in version 3.4.\n\n"}, {"name": "abs()", "path": "library/functions#abs", "type": "Built-in Functions", "text": "\nReturn the absolute value of a number. The argument may be an integer, a\nfloating point number, or an object implementing `__abs__()`. If the argument\nis a complex number, its magnitude is returned.\n\n"}, {"name": "aifc", "path": "library/aifc", "type": "Multimedia", "text": "\nSource code: Lib/aifc.py\n\nThis module provides support for reading and writing AIFF and AIFF-C files.\nAIFF is Audio Interchange File Format, a format for storing digital audio\nsamples in a file. AIFF-C is a newer version of the format that includes the\nability to compress the audio data.\n\nAudio files have a number of parameters that describe the audio data. The\nsampling rate or frame rate is the number of times per second the sound is\nsampled. The number of channels indicate if the audio is mono, stereo, or\nquadro. Each frame consists of one sample per channel. The sample size is the\nsize in bytes of each sample. Thus a frame consists of `nchannels *\nsamplesize` bytes, and a second\u2019s worth of audio consists of `nchannels *\nsamplesize * framerate` bytes.\n\nFor example, CD quality audio has a sample size of two bytes (16 bits), uses\ntwo channels (stereo) and has a frame rate of 44,100 frames/second. This gives\na frame size of 4 bytes (2*2), and a second\u2019s worth occupies 2*2*44100 bytes\n(176,400 bytes).\n\nModule `aifc` defines the following function:\n\nOpen an AIFF or AIFF-C file and return an object instance with methods that\nare described below. The argument file is either a string naming a file or a\nfile object. mode must be `'r'` or `'rb'` when the file must be opened for\nreading, or `'w'` or `'wb'` when the file must be opened for writing. If\nomitted, `file.mode` is used if it exists, otherwise `'rb'` is used. When used\nfor writing, the file object should be seekable, unless you know ahead of time\nhow many samples you are going to write in total and use `writeframesraw()`\nand `setnframes()`. The `open()` function may be used in a `with` statement.\nWhen the `with` block completes, the `close()` method is called.\n\nChanged in version 3.4: Support for the `with` statement was added.\n\nObjects returned by `open()` when a file is opened for reading have the\nfollowing methods:\n\nReturn the number of audio channels (1 for mono, 2 for stereo).\n\nReturn the size in bytes of individual samples.\n\nReturn the sampling rate (number of audio frames per second).\n\nReturn the number of audio frames in the file.\n\nReturn a bytes array of length 4 describing the type of compression used in\nthe audio file. For AIFF files, the returned value is `b'NONE'`.\n\nReturn a bytes array convertible to a human-readable description of the type\nof compression used in the audio file. For AIFF files, the returned value is\n`b'not compressed'`.\n\nReturns a `namedtuple()` `(nchannels, sampwidth, framerate, nframes, comptype,\ncompname)`, equivalent to output of the `get*()` methods.\n\nReturn a list of markers in the audio file. A marker consists of a tuple of\nthree elements. The first is the mark ID (an integer), the second is the mark\nposition in frames from the beginning of the data (an integer), the third is\nthe name of the mark (a string).\n\nReturn the tuple as described in `getmarkers()` for the mark with the given\nid.\n\nRead and return the next nframes frames from the audio file. The returned data\nis a string containing for each frame the uncompressed samples of all\nchannels.\n\nRewind the read pointer. The next `readframes()` will start from the\nbeginning.\n\nSeek to the specified frame number.\n\nReturn the current frame number.\n\nClose the AIFF file. After calling this method, the object can no longer be\nused.\n\nObjects returned by `open()` when a file is opened for writing have all the\nabove methods, except for `readframes()` and `setpos()`. In addition the\nfollowing methods exist. The `get*()` methods can only be called after the\ncorresponding `set*()` methods have been called. Before the first\n`writeframes()` or `writeframesraw()`, all parameters except for the number of\nframes must be filled in.\n\nCreate an AIFF file. The default is that an AIFF-C file is created, unless the\nname of the file ends in `'.aiff'` in which case the default is an AIFF file.\n\nCreate an AIFF-C file. The default is that an AIFF-C file is created, unless\nthe name of the file ends in `'.aiff'` in which case the default is an AIFF\nfile.\n\nSpecify the number of channels in the audio file.\n\nSpecify the size in bytes of audio samples.\n\nSpecify the sampling frequency in frames per second.\n\nSpecify the number of frames that are to be written to the audio file. If this\nparameter is not set, or not set correctly, the file needs to support seeking.\n\nSpecify the compression type. If not specified, the audio data will not be\ncompressed. In AIFF files, compression is not possible. The name parameter\nshould be a human-readable description of the compression type as a bytes\narray, the type parameter should be a bytes array of length 4. Currently the\nfollowing compression types are supported: `b'NONE'`, `b'ULAW'`, `b'ALAW'`,\n`b'G722'`.\n\nSet all the above parameters at once. The argument is a tuple consisting of\nthe various parameters. This means that it is possible to use the result of a\n`getparams()` call as argument to `setparams()`.\n\nAdd a mark with the given id (larger than 0), and the given name at the given\nposition. This method can be called at any time before `close()`.\n\nReturn the current write position in the output file. Useful in combination\nwith `setmark()`.\n\nWrite data to the output file. This method can only be called after the audio\nfile parameters have been set.\n\nChanged in version 3.4: Any bytes-like object is now accepted.\n\nLike `writeframes()`, except that the header of the audio file is not updated.\n\nChanged in version 3.4: Any bytes-like object is now accepted.\n\nClose the AIFF file. The header of the file is updated to reflect the actual\nsize of the audio data. After calling this method, the object can no longer be\nused.\n\n"}, {"name": "aifc.aifc.aifc()", "path": "library/aifc#aifc.aifc.aifc", "type": "Multimedia", "text": "\nCreate an AIFF-C file. The default is that an AIFF-C file is created, unless\nthe name of the file ends in `'.aiff'` in which case the default is an AIFF\nfile.\n\n"}, {"name": "aifc.aifc.aiff()", "path": "library/aifc#aifc.aifc.aiff", "type": "Multimedia", "text": "\nCreate an AIFF file. The default is that an AIFF-C file is created, unless the\nname of the file ends in `'.aiff'` in which case the default is an AIFF file.\n\n"}, {"name": "aifc.aifc.close()", "path": "library/aifc#aifc.aifc.close", "type": "Multimedia", "text": "\nClose the AIFF file. After calling this method, the object can no longer be\nused.\n\n"}, {"name": "aifc.aifc.getcompname()", "path": "library/aifc#aifc.aifc.getcompname", "type": "Multimedia", "text": "\nReturn a bytes array convertible to a human-readable description of the type\nof compression used in the audio file. For AIFF files, the returned value is\n`b'not compressed'`.\n\n"}, {"name": "aifc.aifc.getcomptype()", "path": "library/aifc#aifc.aifc.getcomptype", "type": "Multimedia", "text": "\nReturn a bytes array of length 4 describing the type of compression used in\nthe audio file. For AIFF files, the returned value is `b'NONE'`.\n\n"}, {"name": "aifc.aifc.getframerate()", "path": "library/aifc#aifc.aifc.getframerate", "type": "Multimedia", "text": "\nReturn the sampling rate (number of audio frames per second).\n\n"}, {"name": "aifc.aifc.getmark()", "path": "library/aifc#aifc.aifc.getmark", "type": "Multimedia", "text": "\nReturn the tuple as described in `getmarkers()` for the mark with the given\nid.\n\n"}, {"name": "aifc.aifc.getmarkers()", "path": "library/aifc#aifc.aifc.getmarkers", "type": "Multimedia", "text": "\nReturn a list of markers in the audio file. A marker consists of a tuple of\nthree elements. The first is the mark ID (an integer), the second is the mark\nposition in frames from the beginning of the data (an integer), the third is\nthe name of the mark (a string).\n\n"}, {"name": "aifc.aifc.getnchannels()", "path": "library/aifc#aifc.aifc.getnchannels", "type": "Multimedia", "text": "\nReturn the number of audio channels (1 for mono, 2 for stereo).\n\n"}, {"name": "aifc.aifc.getnframes()", "path": "library/aifc#aifc.aifc.getnframes", "type": "Multimedia", "text": "\nReturn the number of audio frames in the file.\n\n"}, {"name": "aifc.aifc.getparams()", "path": "library/aifc#aifc.aifc.getparams", "type": "Multimedia", "text": "\nReturns a `namedtuple()` `(nchannels, sampwidth, framerate, nframes, comptype,\ncompname)`, equivalent to output of the `get*()` methods.\n\n"}, {"name": "aifc.aifc.getsampwidth()", "path": "library/aifc#aifc.aifc.getsampwidth", "type": "Multimedia", "text": "\nReturn the size in bytes of individual samples.\n\n"}, {"name": "aifc.aifc.readframes()", "path": "library/aifc#aifc.aifc.readframes", "type": "Multimedia", "text": "\nRead and return the next nframes frames from the audio file. The returned data\nis a string containing for each frame the uncompressed samples of all\nchannels.\n\n"}, {"name": "aifc.aifc.rewind()", "path": "library/aifc#aifc.aifc.rewind", "type": "Multimedia", "text": "\nRewind the read pointer. The next `readframes()` will start from the\nbeginning.\n\n"}, {"name": "aifc.aifc.setcomptype()", "path": "library/aifc#aifc.aifc.setcomptype", "type": "Multimedia", "text": "\nSpecify the compression type. If not specified, the audio data will not be\ncompressed. In AIFF files, compression is not possible. The name parameter\nshould be a human-readable description of the compression type as a bytes\narray, the type parameter should be a bytes array of length 4. Currently the\nfollowing compression types are supported: `b'NONE'`, `b'ULAW'`, `b'ALAW'`,\n`b'G722'`.\n\n"}, {"name": "aifc.aifc.setframerate()", "path": "library/aifc#aifc.aifc.setframerate", "type": "Multimedia", "text": "\nSpecify the sampling frequency in frames per second.\n\n"}, {"name": "aifc.aifc.setmark()", "path": "library/aifc#aifc.aifc.setmark", "type": "Multimedia", "text": "\nAdd a mark with the given id (larger than 0), and the given name at the given\nposition. This method can be called at any time before `close()`.\n\n"}, {"name": "aifc.aifc.setnchannels()", "path": "library/aifc#aifc.aifc.setnchannels", "type": "Multimedia", "text": "\nSpecify the number of channels in the audio file.\n\n"}, {"name": "aifc.aifc.setnframes()", "path": "library/aifc#aifc.aifc.setnframes", "type": "Multimedia", "text": "\nSpecify the number of frames that are to be written to the audio file. If this\nparameter is not set, or not set correctly, the file needs to support seeking.\n\n"}, {"name": "aifc.aifc.setparams()", "path": "library/aifc#aifc.aifc.setparams", "type": "Multimedia", "text": "\nSet all the above parameters at once. The argument is a tuple consisting of\nthe various parameters. This means that it is possible to use the result of a\n`getparams()` call as argument to `setparams()`.\n\n"}, {"name": "aifc.aifc.setpos()", "path": "library/aifc#aifc.aifc.setpos", "type": "Multimedia", "text": "\nSeek to the specified frame number.\n\n"}, {"name": "aifc.aifc.setsampwidth()", "path": "library/aifc#aifc.aifc.setsampwidth", "type": "Multimedia", "text": "\nSpecify the size in bytes of audio samples.\n\n"}, {"name": "aifc.aifc.tell()", "path": "library/aifc#aifc.aifc.tell", "type": "Multimedia", "text": "\nReturn the current frame number.\n\n"}, {"name": "aifc.aifc.writeframes()", "path": "library/aifc#aifc.aifc.writeframes", "type": "Multimedia", "text": "\nWrite data to the output file. This method can only be called after the audio\nfile parameters have been set.\n\nChanged in version 3.4: Any bytes-like object is now accepted.\n\n"}, {"name": "aifc.aifc.writeframesraw()", "path": "library/aifc#aifc.aifc.writeframesraw", "type": "Multimedia", "text": "\nLike `writeframes()`, except that the header of the audio file is not updated.\n\nChanged in version 3.4: Any bytes-like object is now accepted.\n\n"}, {"name": "aifc.open()", "path": "library/aifc#aifc.open", "type": "Multimedia", "text": "\nOpen an AIFF or AIFF-C file and return an object instance with methods that\nare described below. The argument file is either a string naming a file or a\nfile object. mode must be `'r'` or `'rb'` when the file must be opened for\nreading, or `'w'` or `'wb'` when the file must be opened for writing. If\nomitted, `file.mode` is used if it exists, otherwise `'rb'` is used. When used\nfor writing, the file object should be seekable, unless you know ahead of time\nhow many samples you are going to write in total and use `writeframesraw()`\nand `setnframes()`. The `open()` function may be used in a `with` statement.\nWhen the `with` block completes, the `close()` method is called.\n\nChanged in version 3.4: Support for the `with` statement was added.\n\n"}, {"name": "all()", "path": "library/functions#all", "type": "Built-in Functions", "text": "\nReturn `True` if all elements of the iterable are true (or if the iterable is\nempty). Equivalent to:\n\n"}, {"name": "any()", "path": "library/functions#any", "type": "Built-in Functions", "text": "\nReturn `True` if any element of the iterable is true. If the iterable is\nempty, return `False`. Equivalent to:\n\n"}, {"name": "argparse", "path": "library/argparse", "type": "Operating System", "text": "\nNew in version 3.2.\n\nSource code: Lib/argparse.py\n\nTutorial\n\nThis page contains the API reference information. For a more gentle\nintroduction to Python command-line parsing, have a look at the argparse\ntutorial.\n\nThe `argparse` module makes it easy to write user-friendly command-line\ninterfaces. The program defines what arguments it requires, and `argparse`\nwill figure out how to parse those out of `sys.argv`. The `argparse` module\nalso automatically generates help and usage messages and issues errors when\nusers give the program invalid arguments.\n\nThe following code is a Python program that takes a list of integers and\nproduces either the sum or the max:\n\nAssuming the Python code above is saved into a file called `prog.py`, it can\nbe run at the command line and provides useful help messages:\n\nWhen run with the appropriate arguments, it prints either the sum or the max\nof the command-line integers:\n\nIf invalid arguments are passed in, it will issue an error:\n\nThe following sections walk you through this example.\n\nThe first step in using the `argparse` is creating an `ArgumentParser` object:\n\nThe `ArgumentParser` object will hold all the information necessary to parse\nthe command line into Python data types.\n\nFilling an `ArgumentParser` with information about program arguments is done\nby making calls to the `add_argument()` method. Generally, these calls tell\nthe `ArgumentParser` how to take the strings on the command line and turn them\ninto objects. This information is stored and used when `parse_args()` is\ncalled. For example:\n\nLater, calling `parse_args()` will return an object with two attributes,\n`integers` and `accumulate`. The `integers` attribute will be a list of one or\nmore ints, and the `accumulate` attribute will be either the `sum()` function,\nif `--sum` was specified at the command line, or the `max()` function if it\nwas not.\n\n`ArgumentParser` parses arguments through the `parse_args()` method. This will\ninspect the command line, convert each argument to the appropriate type and\nthen invoke the appropriate action. In most cases, this means a simple\n`Namespace` object will be built up from attributes parsed out of the command\nline:\n\nIn a script, `parse_args()` will typically be called with no arguments, and\nthe `ArgumentParser` will automatically determine the command-line arguments\nfrom `sys.argv`.\n\nCreate a new `ArgumentParser` object. All parameters should be passed as\nkeyword arguments. Each parameter has its own more detailed description below,\nbut in short they are:\n\nChanged in version 3.5: allow_abbrev parameter was added.\n\nChanged in version 3.8: In previous versions, allow_abbrev also disabled\ngrouping of short flags such as `-vv` to mean `-v -v`.\n\nChanged in version 3.9: exit_on_error parameter was added.\n\nThe following sections describe how each of these are used.\n\nBy default, `ArgumentParser` objects use `sys.argv[0]` to determine how to\ndisplay the name of the program in help messages. This default is almost\nalways desirable because it will make the help messages match how the program\nwas invoked on the command line. For example, consider a file named\n`myprogram.py` with the following code:\n\nThe help for this program will display `myprogram.py` as the program name\n(regardless of where the program was invoked from):\n\nTo change this default behavior, another value can be supplied using the\n`prog=` argument to `ArgumentParser`:\n\nNote that the program name, whether determined from `sys.argv[0]` or from the\n`prog=` argument, is available to help messages using the `%(prog)s` format\nspecifier.\n\nBy default, `ArgumentParser` calculates the usage message from the arguments\nit contains:\n\nThe default message can be overridden with the `usage=` keyword argument:\n\nThe `%(prog)s` format specifier is available to fill in the program name in\nyour usage messages.\n\nMost calls to the `ArgumentParser` constructor will use the `description=`\nkeyword argument. This argument gives a brief description of what the program\ndoes and how it works. In help messages, the description is displayed between\nthe command-line usage string and the help messages for the various arguments:\n\nBy default, the description will be line-wrapped so that it fits within the\ngiven space. To change this behavior, see the formatter_class argument.\n\nSome programs like to display additional description of the program after the\ndescription of the arguments. Such text can be specified using the `epilog=`\nargument to `ArgumentParser`:\n\nAs with the description argument, the `epilog=` text is by default line-\nwrapped, but this behavior can be adjusted with the formatter_class argument\nto `ArgumentParser`.\n\nSometimes, several parsers share a common set of arguments. Rather than\nrepeating the definitions of these arguments, a single parser with all the\nshared arguments and passed to `parents=` argument to `ArgumentParser` can be\nused. The `parents=` argument takes a list of `ArgumentParser` objects,\ncollects all the positional and optional actions from them, and adds these\nactions to the `ArgumentParser` object being constructed:\n\nNote that most parent parsers will specify `add_help=False`. Otherwise, the\n`ArgumentParser` will see two `-h/--help` options (one in the parent and one\nin the child) and raise an error.\n\nNote\n\nYou must fully initialize the parsers before passing them via `parents=`. If\nyou change the parent parsers after the child parser, those changes will not\nbe reflected in the child.\n\n`ArgumentParser` objects allow the help formatting to be customized by\nspecifying an alternate formatting class. Currently, there are four such\nclasses:\n\n`RawDescriptionHelpFormatter` and `RawTextHelpFormatter` give more control\nover how textual descriptions are displayed. By default, `ArgumentParser`\nobjects line-wrap the description and epilog texts in command-line help\nmessages:\n\nPassing `RawDescriptionHelpFormatter` as `formatter_class=` indicates that\ndescription and epilog are already correctly formatted and should not be line-\nwrapped:\n\n`RawTextHelpFormatter` maintains whitespace for all sorts of help text,\nincluding argument descriptions. However, multiple new lines are replaced with\none. If you wish to preserve multiple blank lines, add spaces between the\nnewlines.\n\n`ArgumentDefaultsHelpFormatter` automatically adds information about default\nvalues to each of the argument help messages:\n\n`MetavarTypeHelpFormatter` uses the name of the type argument for each\nargument as the display name for its values (rather than using the dest as the\nregular formatter does):\n\nMost command-line options will use `-` as the prefix, e.g. `-f/--foo`. Parsers\nthat need to support different or additional prefix characters, e.g. for\noptions like `+f` or `/foo`, may specify them using the `prefix_chars=`\nargument to the ArgumentParser constructor:\n\nThe `prefix_chars=` argument defaults to `'-'`. Supplying a set of characters\nthat does not include `-` will cause `-f/--foo` options to be disallowed.\n\nSometimes, for example when dealing with a particularly long argument lists,\nit may make sense to keep the list of arguments in a file rather than typing\nit out at the command line. If the `fromfile_prefix_chars=` argument is given\nto the `ArgumentParser` constructor, then arguments that start with any of the\nspecified characters will be treated as files, and will be replaced by the\narguments they contain. For example:\n\nArguments read from a file must by default be one per line (but see also\n`convert_arg_line_to_args()`) and are treated as if they were in the same\nplace as the original file referencing argument on the command line. So in the\nexample above, the expression `['-f', 'foo', '@args.txt']` is considered\nequivalent to the expression `['-f', 'foo', '-f', 'bar']`.\n\nThe `fromfile_prefix_chars=` argument defaults to `None`, meaning that\narguments will never be treated as file references.\n\nGenerally, argument defaults are specified either by passing a default to\n`add_argument()` or by calling the `set_defaults()` methods with a specific\nset of name-value pairs. Sometimes however, it may be useful to specify a\nsingle parser-wide default for arguments. This can be accomplished by passing\nthe `argument_default=` keyword argument to `ArgumentParser`. For example, to\nglobally suppress attribute creation on `parse_args()` calls, we supply\n`argument_default=SUPPRESS`:\n\nNormally, when you pass an argument list to the `parse_args()` method of an\n`ArgumentParser`, it recognizes abbreviations of long options.\n\nThis feature can be disabled by setting `allow_abbrev` to `False`:\n\nNew in version 3.5.\n\n`ArgumentParser` objects do not allow two actions with the same option string.\nBy default, `ArgumentParser` objects raise an exception if an attempt is made\nto create an argument with an option string that is already in use:\n\nSometimes (e.g. when using parents) it may be useful to simply override any\nolder arguments with the same option string. To get this behavior, the value\n`'resolve'` can be supplied to the `conflict_handler=` argument of\n`ArgumentParser`:\n\nNote that `ArgumentParser` objects only remove an action if all of its option\nstrings are overridden. So, in the example above, the old `-f/--foo` action is\nretained as the `-f` action, because only the `--foo` option string was\noverridden.\n\nBy default, ArgumentParser objects add an option which simply displays the\nparser\u2019s help message. For example, consider a file named `myprogram.py`\ncontaining the following code:\n\nIf `-h` or `--help` is supplied at the command line, the ArgumentParser help\nwill be printed:\n\nOccasionally, it may be useful to disable the addition of this help option.\nThis can be achieved by passing `False` as the `add_help=` argument to\n`ArgumentParser`:\n\nThe help option is typically `-h/--help`. The exception to this is if the\n`prefix_chars=` is specified and does not include `-`, in which case `-h` and\n`--help` are not valid options. In this case, the first character in\n`prefix_chars` is used to prefix the help options:\n\nNormally, when you pass an invalid argument list to the `parse_args()` method\nof an `ArgumentParser`, it will exit with error info.\n\nIf the user would like to catch errors manually, the feature can be enabled by\nsetting `exit_on_error` to `False`:\n\nNew in version 3.9.\n\nDefine how a single command-line argument should be parsed. Each parameter has\nits own more detailed description below, but in short they are:\n\nThe following sections describe how each of these are used.\n\nThe `add_argument()` method must know whether an optional argument, like `-f`\nor `--foo`, or a positional argument, like a list of filenames, is expected.\nThe first arguments passed to `add_argument()` must therefore be either a\nseries of flags, or a simple argument name. For example, an optional argument\ncould be created like:\n\nwhile a positional argument could be created like:\n\nWhen `parse_args()` is called, optional arguments will be identified by the\n`-` prefix, and the remaining arguments will be assumed to be positional:\n\n`ArgumentParser` objects associate command-line arguments with actions. These\nactions can do just about anything with the command-line arguments associated\nwith them, though most actions simply add an attribute to the object returned\nby `parse_args()`. The `action` keyword argument specifies how the command-\nline arguments should be handled. The supplied actions are:\n\n`'store'` \\- This just stores the argument\u2019s value. This is the default\naction. For example:\n\n`'store_const'` \\- This stores the value specified by the const keyword\nargument. The `'store_const'` action is most commonly used with optional\narguments that specify some sort of flag. For example:\n\n`'store_true'` and `'store_false'` \\- These are special cases of\n`'store_const'` used for storing the values `True` and `False` respectively.\nIn addition, they create default values of `False` and `True` respectively.\nFor example:\n\n`'append'` \\- This stores a list, and appends each argument value to the list.\nThis is useful to allow an option to be specified multiple times. Example\nusage:\n\n`'append_const'` \\- This stores a list, and appends the value specified by the\nconst keyword argument to the list. (Note that the const keyword argument\ndefaults to `None`.) The `'append_const'` action is typically useful when\nmultiple arguments need to store constants to the same list. For example:\n\n`'count'` \\- This counts the number of times a keyword argument occurs. For\nexample, this is useful for increasing verbosity levels:\n\nNote, the default will be `None` unless explicitly set to 0.\n\n`'version'` \\- This expects a `version=` keyword argument in the\n`add_argument()` call, and prints version information and exits when invoked:\n\n`'extend'` \\- This stores a list, and extends each argument value to the list.\nExample usage:\n\nNew in version 3.8.\n\nYou may also specify an arbitrary action by passing an Action subclass or\nother object that implements the same interface. The `BooleanOptionalAction`\nis available in `argparse` and adds support for boolean actions such as\n`--foo` and `--no-foo`:\n\nThe recommended way to create a custom action is to extend `Action`,\noverriding the `__call__` method and optionally the `__init__` and\n`format_usage` methods.\n\nAn example of a custom action:\n\nFor more details, see `Action`.\n\nArgumentParser objects usually associate a single command-line argument with a\nsingle action to be taken. The `nargs` keyword argument associates a different\nnumber of command-line arguments with a single action. The supported values\nare:\n\n`N` (an integer). `N` arguments from the command line will be gathered\ntogether into a list. For example:\n\nNote that `nargs=1` produces a list of one item. This is different from the\ndefault, in which the item is produced by itself.\n\n`'?'`. One argument will be consumed from the command line if possible, and\nproduced as a single item. If no command-line argument is present, the value\nfrom default will be produced. Note that for optional arguments, there is an\nadditional case - the option string is present but not followed by a command-\nline argument. In this case the value from const will be produced. Some\nexamples to illustrate this:\n\nOne of the more common uses of `nargs='?'` is to allow optional input and\noutput files:\n\n`'*'`. All command-line arguments present are gathered into a list. Note that\nit generally doesn\u2019t make much sense to have more than one positional argument\nwith `nargs='*'`, but multiple optional arguments with `nargs='*'` is\npossible. For example:\n\n`'+'`. Just like `'*'`, all command-line args present are gathered into a\nlist. Additionally, an error message will be generated if there wasn\u2019t at\nleast one command-line argument present. For example:\n\nIf the `nargs` keyword argument is not provided, the number of arguments\nconsumed is determined by the action. Generally this means a single command-\nline argument will be consumed and a single item (not a list) will be\nproduced.\n\nThe `const` argument of `add_argument()` is used to hold constant values that\nare not read from the command line but are required for the various\n`ArgumentParser` actions. The two most common uses of it are:\n\nWith the `'store_const'` and `'append_const'` actions, the `const` keyword\nargument must be given. For other actions, it defaults to `None`.\n\nAll optional arguments and some positional arguments may be omitted at the\ncommand line. The `default` keyword argument of `add_argument()`, whose value\ndefaults to `None`, specifies what value should be used if the command-line\nargument is not present. For optional arguments, the `default` value is used\nwhen the option string was not present at the command line:\n\nIf the target namespace already has an attribute set, the action default will\nnot over write it:\n\nIf the `default` value is a string, the parser parses the value as if it were\na command-line argument. In particular, the parser applies any type conversion\nargument, if provided, before setting the attribute on the `Namespace` return\nvalue. Otherwise, the parser uses the value as is:\n\nFor positional arguments with nargs equal to `?` or `*`, the `default` value\nis used when no command-line argument was present:\n\nProviding `default=argparse.SUPPRESS` causes no attribute to be added if the\ncommand-line argument was not present:\n\nBy default, the parser reads command-line arguments in as simple strings.\nHowever, quite often the command-line string should instead be interpreted as\nanother type, such as a `float` or `int`. The `type` keyword for\n`add_argument()` allows any necessary type-checking and type conversions to be\nperformed.\n\nIf the type keyword is used with the default keyword, the type converter is\nonly applied if the default is a string.\n\nThe argument to `type` can be any callable that accepts a single string. If\nthe function raises `ArgumentTypeError`, `TypeError`, or `ValueError`, the\nexception is caught and a nicely formatted error message is displayed. No\nother exception types are handled.\n\nCommon built-in types and functions can be used as type converters:\n\nUser defined functions can be used as well:\n\nThe `bool()` function is not recommended as a type converter. All it does is\nconvert empty strings to `False` and non-empty strings to `True`. This is\nusually not what is desired.\n\nIn general, the `type` keyword is a convenience that should only be used for\nsimple conversions that can only raise one of the three supported exceptions.\nAnything with more interesting error-handling or resource management should be\ndone downstream after the arguments are parsed.\n\nFor example, JSON or YAML conversions have complex error cases that require\nbetter reporting than can be given by the `type` keyword. An `JSONDecodeError`\nwould not be well formatted and a `FileNotFound` exception would not be\nhandled at all.\n\nEven `FileType` has its limitations for use with the `type` keyword. If one\nargument uses FileType and then a subsequent argument fails, an error is\nreported but the file is not automatically closed. In this case, it would be\nbetter to wait until after the parser has run and then use the\n`with`-statement to manage the files.\n\nFor type checkers that simply check against a fixed set of values, consider\nusing the choices keyword instead.\n\nSome command-line arguments should be selected from a restricted set of\nvalues. These can be handled by passing a container object as the choices\nkeyword argument to `add_argument()`. When the command line is parsed,\nargument values will be checked, and an error message will be displayed if the\nargument was not one of the acceptable values:\n\nNote that inclusion in the choices container is checked after any type\nconversions have been performed, so the type of the objects in the choices\ncontainer should match the type specified:\n\nAny container can be passed as the choices value, so `list` objects, `set`\nobjects, and custom containers are all supported.\n\nUse of `enum.Enum` is not recommended because it is difficult to control its\nappearance in usage, help, and error messages.\n\nFormatted choices overrides the default metavar which is normally derived from\ndest. This is usually what you want because the user never sees the dest\nparameter. If this display isn\u2019t desirable (perhaps because there are many\nchoices), just specify an explicit metavar.\n\nIn general, the `argparse` module assumes that flags like `-f` and `--bar`\nindicate optional arguments, which can always be omitted at the command line.\nTo make an option required, `True` can be specified for the `required=`\nkeyword argument to `add_argument()`:\n\nAs the example shows, if an option is marked as `required`, `parse_args()`\nwill report an error if that option is not present at the command line.\n\nNote\n\nRequired options are generally considered bad form because users expect\noptions to be optional, and thus they should be avoided when possible.\n\nThe `help` value is a string containing a brief description of the argument.\nWhen a user requests help (usually by using `-h` or `--help` at the command\nline), these `help` descriptions will be displayed with each argument:\n\nThe `help` strings can include various format specifiers to avoid repetition\nof things like the program name or the argument default. The available\nspecifiers include the program name, `%(prog)s` and most keyword arguments to\n`add_argument()`, e.g. `%(default)s`, `%(type)s`, etc.:\n\nAs the help string supports %-formatting, if you want a literal `%` to appear\nin the help string, you must escape it as `%%`.\n\n`argparse` supports silencing the help entry for certain options, by setting\nthe `help` value to `argparse.SUPPRESS`:\n\nWhen `ArgumentParser` generates help messages, it needs some way to refer to\neach expected argument. By default, ArgumentParser objects use the dest value\nas the \u201cname\u201d of each object. By default, for positional argument actions, the\ndest value is used directly, and for optional argument actions, the dest value\nis uppercased. So, a single positional argument with `dest='bar'` will be\nreferred to as `bar`. A single optional argument `--foo` that should be\nfollowed by a single command-line argument will be referred to as `FOO`. An\nexample:\n\nAn alternative name can be specified with `metavar`:\n\nNote that `metavar` only changes the displayed name - the name of the\nattribute on the `parse_args()` object is still determined by the dest value.\n\nDifferent values of `nargs` may cause the metavar to be used multiple times.\nProviding a tuple to `metavar` specifies a different display for each of the\narguments:\n\nMost `ArgumentParser` actions add some value as an attribute of the object\nreturned by `parse_args()`. The name of this attribute is determined by the\n`dest` keyword argument of `add_argument()`. For positional argument actions,\n`dest` is normally supplied as the first argument to `add_argument()`:\n\nFor optional argument actions, the value of `dest` is normally inferred from\nthe option strings. `ArgumentParser` generates the value of `dest` by taking\nthe first long option string and stripping away the initial `--` string. If no\nlong option strings were supplied, `dest` will be derived from the first short\noption string by stripping the initial `-` character. Any internal `-`\ncharacters will be converted to `_` characters to make sure the string is a\nvalid attribute name. The examples below illustrate this behavior:\n\n`dest` allows a custom attribute name to be provided:\n\nAction classes implement the Action API, a callable which returns a callable\nwhich processes arguments from the command-line. Any object which follows this\nAPI may be passed as the `action` parameter to `add_argument()`.\n\nAction objects are used by an ArgumentParser to represent the information\nneeded to parse a single argument from one or more strings from the command\nline. The Action class must accept the two positional arguments plus any\nkeyword arguments passed to `ArgumentParser.add_argument()` except for the\n`action` itself.\n\nInstances of Action (or return value of any callable to the `action`\nparameter) should have attributes \u201cdest\u201d, \u201coption_strings\u201d, \u201cdefault\u201d, \u201ctype\u201d,\n\u201crequired\u201d, \u201chelp\u201d, etc. defined. The easiest way to ensure these attributes\nare defined is to call `Action.__init__`.\n\nAction instances should be callable, so subclasses must override the\n`__call__` method, which should accept four parameters:\n\nThe `__call__` method may perform arbitrary actions, but will typically set\nattributes on the `namespace` based on `dest` and `values`.\n\nAction subclasses can define a `format_usage` method that takes no argument\nand return a string which will be used when printing the usage of the program.\nIf such method is not provided, a sensible default will be used.\n\nConvert argument strings to objects and assign them as attributes of the\nnamespace. Return the populated namespace.\n\nPrevious calls to `add_argument()` determine exactly what objects are created\nand how they are assigned. See the documentation for `add_argument()` for\ndetails.\n\nThe `parse_args()` method supports several ways of specifying the value of an\noption (if it takes one). In the simplest case, the option and its value are\npassed as two separate arguments:\n\nFor long options (options with names longer than a single character), the\noption and value can also be passed as a single command-line argument, using\n`=` to separate them:\n\nFor short options (options only one character long), the option and its value\ncan be concatenated:\n\nSeveral short options can be joined together, using only a single `-` prefix,\nas long as only the last option (or none of them) requires a value:\n\nWhile parsing the command line, `parse_args()` checks for a variety of errors,\nincluding ambiguous options, invalid types, invalid options, wrong number of\npositional arguments, etc. When it encounters such an error, it exits and\nprints the error along with a usage message:\n\nThe `parse_args()` method attempts to give errors whenever the user has\nclearly made a mistake, but some situations are inherently ambiguous. For\nexample, the command-line argument `-1` could either be an attempt to specify\nan option or an attempt to provide a positional argument. The `parse_args()`\nmethod is cautious here: positional arguments may only begin with `-` if they\nlook like negative numbers and there are no options in the parser that look\nlike negative numbers:\n\nIf you have positional arguments that must begin with `-` and don\u2019t look like\nnegative numbers, you can insert the pseudo-argument `'--'` which tells\n`parse_args()` that everything after that is a positional argument:\n\nThe `parse_args()` method by default allows long options to be abbreviated to\na prefix, if the abbreviation is unambiguous (the prefix matches a unique\noption):\n\nAn error is produced for arguments that could produce more than one options.\nThis feature can be disabled by setting allow_abbrev to `False`.\n\nSometimes it may be useful to have an ArgumentParser parse arguments other\nthan those of `sys.argv`. This can be accomplished by passing a list of\nstrings to `parse_args()`. This is useful for testing at the interactive\nprompt:\n\nSimple class used by default by `parse_args()` to create an object holding\nattributes and return it.\n\nThis class is deliberately simple, just an `object` subclass with a readable\nstring representation. If you prefer to have dict-like view of the attributes,\nyou can use the standard Python idiom, `vars()`:\n\nIt may also be useful to have an `ArgumentParser` assign attributes to an\nalready existing object, rather than a new `Namespace` object. This can be\nachieved by specifying the `namespace=` keyword argument:\n\nMany programs split up their functionality into a number of sub-commands, for\nexample, the `svn` program can invoke sub-commands like `svn checkout`, `svn\nupdate`, and `svn commit`. Splitting up functionality this way can be a\nparticularly good idea when a program performs several different functions\nwhich require different kinds of command-line arguments. `ArgumentParser`\nsupports the creation of such sub-commands with the `add_subparsers()` method.\nThe `add_subparsers()` method is normally called with no arguments and returns\na special action object. This object has a single method, `add_parser()`,\nwhich takes a command name and any `ArgumentParser` constructor arguments, and\nreturns an `ArgumentParser` object that can be modified as usual.\n\nDescription of parameters:\n\nSome example usage:\n\nNote that the object returned by `parse_args()` will only contain attributes\nfor the main parser and the subparser that was selected by the command line\n(and not any other subparsers). So in the example above, when the `a` command\nis specified, only the `foo` and `bar` attributes are present, and when the\n`b` command is specified, only the `foo` and `baz` attributes are present.\n\nSimilarly, when a help message is requested from a subparser, only the help\nfor that particular parser will be printed. The help message will not include\nparent parser or sibling parser messages. (A help message for each subparser\ncommand, however, can be given by supplying the `help=` argument to\n`add_parser()` as above.)\n\nThe `add_subparsers()` method also supports `title` and `description` keyword\narguments. When either is present, the subparser\u2019s commands will appear in\ntheir own group in the help output. For example:\n\nFurthermore, `add_parser` supports an additional `aliases` argument, which\nallows multiple strings to refer to the same subparser. This example, like\n`svn`, aliases `co` as a shorthand for `checkout`:\n\nOne particularly effective way of handling sub-commands is to combine the use\nof the `add_subparsers()` method with calls to `set_defaults()` so that each\nsubparser knows which Python function it should execute. For example:\n\nThis way, you can let `parse_args()` do the job of calling the appropriate\nfunction after argument parsing is complete. Associating functions with\nactions like this is typically the easiest way to handle the different actions\nfor each of your subparsers. However, if it is necessary to check the name of\nthe subparser that was invoked, the `dest` keyword argument to the\n`add_subparsers()` call will work:\n\nChanged in version 3.7: New required keyword argument.\n\nThe `FileType` factory creates objects that can be passed to the type argument\nof `ArgumentParser.add_argument()`. Arguments that have `FileType` objects as\ntheir type will open command-line arguments as files with the requested modes,\nbuffer sizes, encodings and error handling (see the `open()` function for more\ndetails):\n\nFileType objects understand the pseudo-argument `'-'` and automatically\nconvert this into `sys.stdin` for readable `FileType` objects and `sys.stdout`\nfor writable `FileType` objects:\n\nNew in version 3.4: The encodings and errors keyword arguments.\n\nBy default, `ArgumentParser` groups command-line arguments into \u201cpositional\narguments\u201d and \u201coptional arguments\u201d when displaying help messages. When there\nis a better conceptual grouping of arguments than this default one,\nappropriate groups can be created using the `add_argument_group()` method:\n\nThe `add_argument_group()` method returns an argument group object which has\nan `add_argument()` method just like a regular `ArgumentParser`. When an\nargument is added to the group, the parser treats it just like a normal\nargument, but displays the argument in a separate group for help messages. The\n`add_argument_group()` method accepts title and description arguments which\ncan be used to customize this display:\n\nNote that any arguments not in your user-defined groups will end up back in\nthe usual \u201cpositional arguments\u201d and \u201coptional arguments\u201d sections.\n\nCreate a mutually exclusive group. `argparse` will make sure that only one of\nthe arguments in the mutually exclusive group was present on the command line:\n\nThe `add_mutually_exclusive_group()` method also accepts a required argument,\nto indicate that at least one of the mutually exclusive arguments is required:\n\nNote that currently mutually exclusive argument groups do not support the\ntitle and description arguments of `add_argument_group()`.\n\nMost of the time, the attributes of the object returned by `parse_args()` will\nbe fully determined by inspecting the command-line arguments and the argument\nactions. `set_defaults()` allows some additional attributes that are\ndetermined without any inspection of the command line to be added:\n\nNote that parser-level defaults always override argument-level defaults:\n\nParser-level defaults can be particularly useful when working with multiple\nparsers. See the `add_subparsers()` method for an example of this type.\n\nGet the default value for a namespace attribute, as set by either\n`add_argument()` or by `set_defaults()`:\n\nIn most typical applications, `parse_args()` will take care of formatting and\nprinting any usage or error messages. However, several formatting methods are\navailable:\n\nPrint a brief description of how the `ArgumentParser` should be invoked on the\ncommand line. If file is `None`, `sys.stdout` is assumed.\n\nPrint a help message, including the program usage and information about the\narguments registered with the `ArgumentParser`. If file is `None`,\n`sys.stdout` is assumed.\n\nThere are also variants of these methods that simply return a string instead\nof printing it:\n\nReturn a string containing a brief description of how the `ArgumentParser`\nshould be invoked on the command line.\n\nReturn a string containing a help message, including the program usage and\ninformation about the arguments registered with the `ArgumentParser`.\n\nSometimes a script may only parse a few of the command-line arguments, passing\nthe remaining arguments on to another script or program. In these cases, the\n`parse_known_args()` method can be useful. It works much like `parse_args()`\nexcept that it does not produce an error when extra arguments are present.\nInstead, it returns a two item tuple containing the populated namespace and\nthe list of remaining argument strings.\n\nWarning\n\nPrefix matching rules apply to `parse_known_args()`. The parser may consume an\noption even if it\u2019s just a prefix of one of its known options, instead of\nleaving it in the remaining arguments list.\n\nArguments that are read from a file (see the fromfile_prefix_chars keyword\nargument to the `ArgumentParser` constructor) are read one argument per line.\n`convert_arg_line_to_args()` can be overridden for fancier reading.\n\nThis method takes a single argument arg_line which is a string read from the\nargument file. It returns a list of arguments parsed from this string. The\nmethod is called once per line read from the argument file, in order.\n\nA useful override of this method is one that treats each space-separated word\nas an argument. The following example demonstrates how to do this:\n\nThis method terminates the program, exiting with the specified status and, if\ngiven, it prints a message before that. The user can override this method to\nhandle these steps differently:\n\nThis method prints a usage message including the message to the standard error\nand terminates the program with a status code of 2.\n\nA number of Unix commands allow the user to intermix optional arguments with\npositional arguments. The `parse_intermixed_args()` and\n`parse_known_intermixed_args()` methods support this parsing style.\n\nThese parsers do not support all the argparse features, and will raise\nexceptions if unsupported features are used. In particular, subparsers,\n`argparse.REMAINDER`, and mutually exclusive groups that include both\noptionals and positionals are not supported.\n\nThe following example shows the difference between `parse_known_args()` and\n`parse_intermixed_args()`: the former returns `['2', '3']` as unparsed\narguments, while the latter collects all the positionals into `rest`.\n\n`parse_known_intermixed_args()` returns a two item tuple containing the\npopulated namespace and the list of remaining argument strings.\n`parse_intermixed_args()` raises an error if there are any remaining unparsed\nargument strings.\n\nNew in version 3.7.\n\nOriginally, the `argparse` module had attempted to maintain compatibility with\n`optparse`. However, `optparse` was difficult to extend transparently,\nparticularly with the changes required to support the new `nargs=` specifiers\nand better usage messages. When most everything in `optparse` had either been\ncopy-pasted over or monkey-patched, it no longer seemed practical to try to\nmaintain the backwards compatibility.\n\nThe `argparse` module improves on the standard library `optparse` module in a\nnumber of ways including:\n\nA partial upgrade path from `optparse` to `argparse`:\n\n"}, {"name": "argparse.Action", "path": "library/argparse#argparse.Action", "type": "Operating System", "text": "\n\n"}, {"name": "argparse.ArgumentDefaultsHelpFormatter", "path": "library/argparse#argparse.ArgumentDefaultsHelpFormatter", "type": "Operating System", "text": "\n\n"}, {"name": "argparse.ArgumentParser", "path": "library/argparse#argparse.ArgumentParser", "type": "Operating System", "text": "\nCreate a new `ArgumentParser` object. All parameters should be passed as\nkeyword arguments. Each parameter has its own more detailed description below,\nbut in short they are:\n\nChanged in version 3.5: allow_abbrev parameter was added.\n\nChanged in version 3.8: In previous versions, allow_abbrev also disabled\ngrouping of short flags such as `-vv` to mean `-v -v`.\n\nChanged in version 3.9: exit_on_error parameter was added.\n\n"}, {"name": "argparse.ArgumentParser.add_argument()", "path": "library/argparse#argparse.ArgumentParser.add_argument", "type": "Operating System", "text": "\nDefine how a single command-line argument should be parsed. Each parameter has\nits own more detailed description below, but in short they are:\n\n"}, {"name": "argparse.ArgumentParser.add_argument_group()", "path": "library/argparse#argparse.ArgumentParser.add_argument_group", "type": "Operating System", "text": "\nBy default, `ArgumentParser` groups command-line arguments into \u201cpositional\narguments\u201d and \u201coptional arguments\u201d when displaying help messages. When there\nis a better conceptual grouping of arguments than this default one,\nappropriate groups can be created using the `add_argument_group()` method:\n\nThe `add_argument_group()` method returns an argument group object which has\nan `add_argument()` method just like a regular `ArgumentParser`. When an\nargument is added to the group, the parser treats it just like a normal\nargument, but displays the argument in a separate group for help messages. The\n`add_argument_group()` method accepts title and description arguments which\ncan be used to customize this display:\n\nNote that any arguments not in your user-defined groups will end up back in\nthe usual \u201cpositional arguments\u201d and \u201coptional arguments\u201d sections.\n\n"}, {"name": "argparse.ArgumentParser.add_mutually_exclusive_group()", "path": "library/argparse#argparse.ArgumentParser.add_mutually_exclusive_group", "type": "Operating System", "text": "\nCreate a mutually exclusive group. `argparse` will make sure that only one of\nthe arguments in the mutually exclusive group was present on the command line:\n\nThe `add_mutually_exclusive_group()` method also accepts a required argument,\nto indicate that at least one of the mutually exclusive arguments is required:\n\nNote that currently mutually exclusive argument groups do not support the\ntitle and description arguments of `add_argument_group()`.\n\n"}, {"name": "argparse.ArgumentParser.add_subparsers()", "path": "library/argparse#argparse.ArgumentParser.add_subparsers", "type": "Operating System", "text": "\nMany programs split up their functionality into a number of sub-commands, for\nexample, the `svn` program can invoke sub-commands like `svn checkout`, `svn\nupdate`, and `svn commit`. Splitting up functionality this way can be a\nparticularly good idea when a program performs several different functions\nwhich require different kinds of command-line arguments. `ArgumentParser`\nsupports the creation of such sub-commands with the `add_subparsers()` method.\nThe `add_subparsers()` method is normally called with no arguments and returns\na special action object. This object has a single method, `add_parser()`,\nwhich takes a command name and any `ArgumentParser` constructor arguments, and\nreturns an `ArgumentParser` object that can be modified as usual.\n\nDescription of parameters:\n\nSome example usage:\n\nNote that the object returned by `parse_args()` will only contain attributes\nfor the main parser and the subparser that was selected by the command line\n(and not any other subparsers). So in the example above, when the `a` command\nis specified, only the `foo` and `bar` attributes are present, and when the\n`b` command is specified, only the `foo` and `baz` attributes are present.\n\nSimilarly, when a help message is requested from a subparser, only the help\nfor that particular parser will be printed. The help message will not include\nparent parser or sibling parser messages. (A help message for each subparser\ncommand, however, can be given by supplying the `help=` argument to\n`add_parser()` as above.)\n\nThe `add_subparsers()` method also supports `title` and `description` keyword\narguments. When either is present, the subparser\u2019s commands will appear in\ntheir own group in the help output. For example:\n\nFurthermore, `add_parser` supports an additional `aliases` argument, which\nallows multiple strings to refer to the same subparser. This example, like\n`svn`, aliases `co` as a shorthand for `checkout`:\n\nOne particularly effective way of handling sub-commands is to combine the use\nof the `add_subparsers()` method with calls to `set_defaults()` so that each\nsubparser knows which Python function it should execute. For example:\n\nThis way, you can let `parse_args()` do the job of calling the appropriate\nfunction after argument parsing is complete. Associating functions with\nactions like this is typically the easiest way to handle the different actions\nfor each of your subparsers. However, if it is necessary to check the name of\nthe subparser that was invoked, the `dest` keyword argument to the\n`add_subparsers()` call will work:\n\nChanged in version 3.7: New required keyword argument.\n\n"}, {"name": "argparse.ArgumentParser.convert_arg_line_to_args()", "path": "library/argparse#argparse.ArgumentParser.convert_arg_line_to_args", "type": "Operating System", "text": "\nArguments that are read from a file (see the fromfile_prefix_chars keyword\nargument to the `ArgumentParser` constructor) are read one argument per line.\n`convert_arg_line_to_args()` can be overridden for fancier reading.\n\nThis method takes a single argument arg_line which is a string read from the\nargument file. It returns a list of arguments parsed from this string. The\nmethod is called once per line read from the argument file, in order.\n\nA useful override of this method is one that treats each space-separated word\nas an argument. The following example demonstrates how to do this:\n\n"}, {"name": "argparse.ArgumentParser.error()", "path": "library/argparse#argparse.ArgumentParser.error", "type": "Operating System", "text": "\nThis method prints a usage message including the message to the standard error\nand terminates the program with a status code of 2.\n\n"}, {"name": "argparse.ArgumentParser.exit()", "path": "library/argparse#argparse.ArgumentParser.exit", "type": "Operating System", "text": "\nThis method terminates the program, exiting with the specified status and, if\ngiven, it prints a message before that. The user can override this method to\nhandle these steps differently:\n\n"}, {"name": "argparse.ArgumentParser.format_help()", "path": "library/argparse#argparse.ArgumentParser.format_help", "type": "Operating System", "text": "\nReturn a string containing a help message, including the program usage and\ninformation about the arguments registered with the `ArgumentParser`.\n\n"}, {"name": "argparse.ArgumentParser.format_usage()", "path": "library/argparse#argparse.ArgumentParser.format_usage", "type": "Operating System", "text": "\nReturn a string containing a brief description of how the `ArgumentParser`\nshould be invoked on the command line.\n\n"}, {"name": "argparse.ArgumentParser.get_default()", "path": "library/argparse#argparse.ArgumentParser.get_default", "type": "Operating System", "text": "\nGet the default value for a namespace attribute, as set by either\n`add_argument()` or by `set_defaults()`:\n\n"}, {"name": "argparse.ArgumentParser.parse_args()", "path": "library/argparse#argparse.ArgumentParser.parse_args", "type": "Operating System", "text": "\nConvert argument strings to objects and assign them as attributes of the\nnamespace. Return the populated namespace.\n\nPrevious calls to `add_argument()` determine exactly what objects are created\nand how they are assigned. See the documentation for `add_argument()` for\ndetails.\n\n"}, {"name": "argparse.ArgumentParser.parse_intermixed_args()", "path": "library/argparse#argparse.ArgumentParser.parse_intermixed_args", "type": "Operating System", "text": "\n\n"}, {"name": "argparse.ArgumentParser.parse_known_args()", "path": "library/argparse#argparse.ArgumentParser.parse_known_args", "type": "Operating System", "text": "\n\n"}, {"name": "argparse.ArgumentParser.parse_known_intermixed_args()", "path": "library/argparse#argparse.ArgumentParser.parse_known_intermixed_args", "type": "Operating System", "text": "\n\n"}, {"name": "argparse.ArgumentParser.print_help()", "path": "library/argparse#argparse.ArgumentParser.print_help", "type": "Operating System", "text": "\nPrint a help message, including the program usage and information about the\narguments registered with the `ArgumentParser`. If file is `None`,\n`sys.stdout` is assumed.\n\n"}, {"name": "argparse.ArgumentParser.print_usage()", "path": "library/argparse#argparse.ArgumentParser.print_usage", "type": "Operating System", "text": "\nPrint a brief description of how the `ArgumentParser` should be invoked on the\ncommand line. If file is `None`, `sys.stdout` is assumed.\n\n"}, {"name": "argparse.ArgumentParser.set_defaults()", "path": "library/argparse#argparse.ArgumentParser.set_defaults", "type": "Operating System", "text": "\nMost of the time, the attributes of the object returned by `parse_args()` will\nbe fully determined by inspecting the command-line arguments and the argument\nactions. `set_defaults()` allows some additional attributes that are\ndetermined without any inspection of the command line to be added:\n\nNote that parser-level defaults always override argument-level defaults:\n\nParser-level defaults can be particularly useful when working with multiple\nparsers. See the `add_subparsers()` method for an example of this type.\n\n"}, {"name": "argparse.FileType", "path": "library/argparse#argparse.FileType", "type": "Operating System", "text": "\nThe `FileType` factory creates objects that can be passed to the type argument\nof `ArgumentParser.add_argument()`. Arguments that have `FileType` objects as\ntheir type will open command-line arguments as files with the requested modes,\nbuffer sizes, encodings and error handling (see the `open()` function for more\ndetails):\n\nFileType objects understand the pseudo-argument `'-'` and automatically\nconvert this into `sys.stdin` for readable `FileType` objects and `sys.stdout`\nfor writable `FileType` objects:\n\nNew in version 3.4: The encodings and errors keyword arguments.\n\n"}, {"name": "argparse.MetavarTypeHelpFormatter", "path": "library/argparse#argparse.MetavarTypeHelpFormatter", "type": "Operating System", "text": "\n\n"}, {"name": "argparse.Namespace", "path": "library/argparse#argparse.Namespace", "type": "Operating System", "text": "\nSimple class used by default by `parse_args()` to create an object holding\nattributes and return it.\n\n"}, {"name": "argparse.RawDescriptionHelpFormatter", "path": "library/argparse#argparse.RawDescriptionHelpFormatter", "type": "Operating System", "text": "\n\n"}, {"name": "argparse.RawTextHelpFormatter", "path": "library/argparse#argparse.RawTextHelpFormatter", "type": "Operating System", "text": "\n\n"}, {"name": "ArithmeticError", "path": "library/exceptions#ArithmeticError", "type": "Built-in Exceptions", "text": "\nThe base class for those built-in exceptions that are raised for various\narithmetic errors: `OverflowError`, `ZeroDivisionError`, `FloatingPointError`.\n\n"}, {"name": "array", "path": "library/array", "type": "Data Types", "text": "\nThis module defines an object type which can compactly represent an array of\nbasic values: characters, integers, floating point numbers. Arrays are\nsequence types and behave very much like lists, except that the type of\nobjects stored in them is constrained. The type is specified at object\ncreation time by using a type code, which is a single character. The following\ntype codes are defined:\n\nType code\n\nC Type\n\nPython Type\n\nMinimum size in bytes\n\nNotes\n\n`'b'`\n\nsigned char\n\nint\n\n1\n\n`'B'`\n\nunsigned char\n\nint\n\n1\n\n`'u'`\n\nwchar_t\n\nUnicode character\n\n2\n\n(1)\n\n`'h'`\n\nsigned short\n\nint\n\n2\n\n`'H'`\n\nunsigned short\n\nint\n\n2\n\n`'i'`\n\nsigned int\n\nint\n\n2\n\n`'I'`\n\nunsigned int\n\nint\n\n2\n\n`'l'`\n\nsigned long\n\nint\n\n4\n\n`'L'`\n\nunsigned long\n\nint\n\n4\n\n`'q'`\n\nsigned long long\n\nint\n\n8\n\n`'Q'`\n\nunsigned long long\n\nint\n\n8\n\n`'f'`\n\nfloat\n\nfloat\n\n4\n\n`'d'`\n\ndouble\n\nfloat\n\n8\n\nNotes:\n\nIt can be 16 bits or 32 bits depending on the platform.\n\nChanged in version 3.9: `array('u')` now uses `wchar_t` as C type instead of\ndeprecated `Py_UNICODE`. This change doesn\u2019t affect to its behavior because\n`Py_UNICODE` is alias of `wchar_t` since Python 3.3.\n\nDeprecated since version 3.3, will be removed in version 4.0.\n\nThe actual representation of values is determined by the machine architecture\n(strictly speaking, by the C implementation). The actual size can be accessed\nthrough the `itemsize` attribute.\n\nThe module defines the following type:\n\nA new array whose items are restricted by typecode, and initialized from the\noptional initializer value, which must be a list, a bytes-like object, or\niterable over elements of the appropriate type.\n\nIf given a list or string, the initializer is passed to the new array\u2019s\n`fromlist()`, `frombytes()`, or `fromunicode()` method (see below) to add\ninitial items to the array. Otherwise, the iterable initializer is passed to\nthe `extend()` method.\n\nRaises an auditing event `array.__new__` with arguments `typecode`,\n`initializer`.\n\nA string with all available type codes.\n\nArray objects support the ordinary sequence operations of indexing, slicing,\nconcatenation, and multiplication. When using slice assignment, the assigned\nvalue must be an array object with the same type code; in all other cases,\n`TypeError` is raised. Array objects also implement the buffer interface, and\nmay be used wherever bytes-like objects are supported.\n\nThe following data items and methods are also supported:\n\nThe typecode character used to create the array.\n\nThe length in bytes of one array item in the internal representation.\n\nAppend a new item with value x to the end of the array.\n\nReturn a tuple `(address, length)` giving the current memory address and the\nlength in elements of the buffer used to hold array\u2019s contents. The size of\nthe memory buffer in bytes can be computed as `array.buffer_info()[1] *\narray.itemsize`. This is occasionally useful when working with low-level (and\ninherently unsafe) I/O interfaces that require memory addresses, such as\ncertain `ioctl()` operations. The returned numbers are valid as long as the\narray exists and no length-changing operations are applied to it.\n\nNote\n\nWhen using array objects from code written in C or C++ (the only way to\neffectively make use of this information), it makes more sense to use the\nbuffer interface supported by array objects. This method is maintained for\nbackward compatibility and should be avoided in new code. The buffer interface\nis documented in Buffer Protocol.\n\n\u201cByteswap\u201d all items of the array. This is only supported for values which are\n1, 2, 4, or 8 bytes in size; for other types of values, `RuntimeError` is\nraised. It is useful when reading data from a file written on a machine with a\ndifferent byte order.\n\nReturn the number of occurrences of x in the array.\n\nAppend items from iterable to the end of the array. If iterable is another\narray, it must have exactly the same type code; if not, `TypeError` will be\nraised. If iterable is not an array, it must be iterable and its elements must\nbe the right type to be appended to the array.\n\nAppends items from the string, interpreting the string as an array of machine\nvalues (as if it had been read from a file using the `fromfile()` method).\n\nNew in version 3.2: `fromstring()` is renamed to `frombytes()` for clarity.\n\nRead n items (as machine values) from the file object f and append them to the\nend of the array. If less than n items are available, `EOFError` is raised,\nbut the items that were available are still inserted into the array.\n\nAppend items from the list. This is equivalent to `for x in list: a.append(x)`\nexcept that if there is a type error, the array is unchanged.\n\nExtends this array with data from the given unicode string. The array must be\na type `'u'` array; otherwise a `ValueError` is raised. Use\n`array.frombytes(unicodestring.encode(enc))` to append Unicode data to an\narray of some other type.\n\nReturn the smallest i such that i is the index of the first occurrence of x in\nthe array.\n\nInsert a new item with value x in the array before position i. Negative values\nare treated as being relative to the end of the array.\n\nRemoves the item with the index i from the array and returns it. The optional\nargument defaults to `-1`, so that by default the last item is removed and\nreturned.\n\nRemove the first occurrence of x from the array.\n\nReverse the order of the items in the array.\n\nConvert the array to an array of machine values and return the bytes\nrepresentation (the same sequence of bytes that would be written to a file by\nthe `tofile()` method.)\n\nNew in version 3.2: `tostring()` is renamed to `tobytes()` for clarity.\n\nWrite all items (as machine values) to the file object f.\n\nConvert the array to an ordinary list with the same items.\n\nConvert the array to a unicode string. The array must be a type `'u'` array;\notherwise a `ValueError` is raised. Use `array.tobytes().decode(enc)` to\nobtain a unicode string from an array of some other type.\n\nWhen an array object is printed or converted to a string, it is represented as\n`array(typecode, initializer)`. The initializer is omitted if the array is\nempty, otherwise it is a string if the typecode is `'u'`, otherwise it is a\nlist of numbers. The string is guaranteed to be able to be converted back to\nan array with the same type and value using `eval()`, so long as the `array`\nclass has been imported using `from array import array`. Examples:\n\nSee also\n\nPacking and unpacking of heterogeneous binary data.\n\nPacking and unpacking of External Data Representation (XDR) data as used in\nsome remote procedure call systems.\n\nThe Numeric Python extension (NumPy) defines another array type; see\nhttp://www.numpy.org/ for further information about Numerical Python.\n\n"}, {"name": "array.array", "path": "library/array#array.array", "type": "Data Types", "text": "\nA new array whose items are restricted by typecode, and initialized from the\noptional initializer value, which must be a list, a bytes-like object, or\niterable over elements of the appropriate type.\n\nIf given a list or string, the initializer is passed to the new array\u2019s\n`fromlist()`, `frombytes()`, or `fromunicode()` method (see below) to add\ninitial items to the array. Otherwise, the iterable initializer is passed to\nthe `extend()` method.\n\nRaises an auditing event `array.__new__` with arguments `typecode`,\n`initializer`.\n\n"}, {"name": "array.array.append()", "path": "library/array#array.array.append", "type": "Data Types", "text": "\nAppend a new item with value x to the end of the array.\n\n"}, {"name": "array.array.buffer_info()", "path": "library/array#array.array.buffer_info", "type": "Data Types", "text": "\nReturn a tuple `(address, length)` giving the current memory address and the\nlength in elements of the buffer used to hold array\u2019s contents. The size of\nthe memory buffer in bytes can be computed as `array.buffer_info()[1] *\narray.itemsize`. This is occasionally useful when working with low-level (and\ninherently unsafe) I/O interfaces that require memory addresses, such as\ncertain `ioctl()` operations. The returned numbers are valid as long as the\narray exists and no length-changing operations are applied to it.\n\nNote\n\nWhen using array objects from code written in C or C++ (the only way to\neffectively make use of this information), it makes more sense to use the\nbuffer interface supported by array objects. This method is maintained for\nbackward compatibility and should be avoided in new code. The buffer interface\nis documented in Buffer Protocol.\n\n"}, {"name": "array.array.byteswap()", "path": "library/array#array.array.byteswap", "type": "Data Types", "text": "\n\u201cByteswap\u201d all items of the array. This is only supported for values which are\n1, 2, 4, or 8 bytes in size; for other types of values, `RuntimeError` is\nraised. It is useful when reading data from a file written on a machine with a\ndifferent byte order.\n\n"}, {"name": "array.array.count()", "path": "library/array#array.array.count", "type": "Data Types", "text": "\nReturn the number of occurrences of x in the array.\n\n"}, {"name": "array.array.extend()", "path": "library/array#array.array.extend", "type": "Data Types", "text": "\nAppend items from iterable to the end of the array. If iterable is another\narray, it must have exactly the same type code; if not, `TypeError` will be\nraised. If iterable is not an array, it must be iterable and its elements must\nbe the right type to be appended to the array.\n\n"}, {"name": "array.array.frombytes()", "path": "library/array#array.array.frombytes", "type": "Data Types", "text": "\nAppends items from the string, interpreting the string as an array of machine\nvalues (as if it had been read from a file using the `fromfile()` method).\n\nNew in version 3.2: `fromstring()` is renamed to `frombytes()` for clarity.\n\n"}, {"name": "array.array.fromfile()", "path": "library/array#array.array.fromfile", "type": "Data Types", "text": "\nRead n items (as machine values) from the file object f and append them to the\nend of the array. If less than n items are available, `EOFError` is raised,\nbut the items that were available are still inserted into the array.\n\n"}, {"name": "array.array.fromlist()", "path": "library/array#array.array.fromlist", "type": "Data Types", "text": "\nAppend items from the list. This is equivalent to `for x in list: a.append(x)`\nexcept that if there is a type error, the array is unchanged.\n\n"}, {"name": "array.array.fromunicode()", "path": "library/array#array.array.fromunicode", "type": "Data Types", "text": "\nExtends this array with data from the given unicode string. The array must be\na type `'u'` array; otherwise a `ValueError` is raised. Use\n`array.frombytes(unicodestring.encode(enc))` to append Unicode data to an\narray of some other type.\n\n"}, {"name": "array.array.index()", "path": "library/array#array.array.index", "type": "Data Types", "text": "\nReturn the smallest i such that i is the index of the first occurrence of x in\nthe array.\n\n"}, {"name": "array.array.insert()", "path": "library/array#array.array.insert", "type": "Data Types", "text": "\nInsert a new item with value x in the array before position i. Negative values\nare treated as being relative to the end of the array.\n\n"}, {"name": "array.array.itemsize", "path": "library/array#array.array.itemsize", "type": "Data Types", "text": "\nThe length in bytes of one array item in the internal representation.\n\n"}, {"name": "array.array.pop()", "path": "library/array#array.array.pop", "type": "Data Types", "text": "\nRemoves the item with the index i from the array and returns it. The optional\nargument defaults to `-1`, so that by default the last item is removed and\nreturned.\n\n"}, {"name": "array.array.remove()", "path": "library/array#array.array.remove", "type": "Data Types", "text": "\nRemove the first occurrence of x from the array.\n\n"}, {"name": "array.array.reverse()", "path": "library/array#array.array.reverse", "type": "Data Types", "text": "\nReverse the order of the items in the array.\n\n"}, {"name": "array.array.tobytes()", "path": "library/array#array.array.tobytes", "type": "Data Types", "text": "\nConvert the array to an array of machine values and return the bytes\nrepresentation (the same sequence of bytes that would be written to a file by\nthe `tofile()` method.)\n\nNew in version 3.2: `tostring()` is renamed to `tobytes()` for clarity.\n\n"}, {"name": "array.array.tofile()", "path": "library/array#array.array.tofile", "type": "Data Types", "text": "\nWrite all items (as machine values) to the file object f.\n\n"}, {"name": "array.array.tolist()", "path": "library/array#array.array.tolist", "type": "Data Types", "text": "\nConvert the array to an ordinary list with the same items.\n\n"}, {"name": "array.array.tounicode()", "path": "library/array#array.array.tounicode", "type": "Data Types", "text": "\nConvert the array to a unicode string. The array must be a type `'u'` array;\notherwise a `ValueError` is raised. Use `array.tobytes().decode(enc)` to\nobtain a unicode string from an array of some other type.\n\n"}, {"name": "array.array.typecode", "path": "library/array#array.array.typecode", "type": "Data Types", "text": "\nThe typecode character used to create the array.\n\n"}, {"name": "array.typecodes", "path": "library/array#array.typecodes", "type": "Data Types", "text": "\nA string with all available type codes.\n\n"}, {"name": "ascii()", "path": "library/functions#ascii", "type": "Built-in Functions", "text": "\nAs `repr()`, return a string containing a printable representation of an\nobject, but escape the non-ASCII characters in the string returned by `repr()`\nusing `\\x`, `\\u` or `\\U` escapes. This generates a string similar to that\nreturned by `repr()` in Python 2.\n\n"}, {"name": "AssertionError", "path": "library/exceptions#AssertionError", "type": "Built-in Exceptions", "text": "\nRaised when an `assert` statement fails.\n\n"}, {"name": "ast", "path": "library/ast", "type": "Language", "text": "\nSource code: Lib/ast.py\n\nThe `ast` module helps Python applications to process trees of the Python\nabstract syntax grammar. The abstract syntax itself might change with each\nPython release; this module helps to find out programmatically what the\ncurrent grammar looks like.\n\nAn abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as a\nflag to the `compile()` built-in function, or using the `parse()` helper\nprovided in this module. The result will be a tree of objects whose classes\nall inherit from `ast.AST`. An abstract syntax tree can be compiled into a\nPython code object using the built-in `compile()` function.\n\nThe abstract grammar is currently defined as follows:\n\nThis is the base of all AST node classes. The actual node classes are derived\nfrom the `Parser/Python.asdl` file, which is reproduced below. They are\ndefined in the `_ast` C module and re-exported in `ast`.\n\nThere is one class defined for each left-hand side symbol in the abstract\ngrammar (for example, `ast.stmt` or `ast.expr`). In addition, there is one\nclass defined for each constructor on the right-hand side; these classes\ninherit from the classes for the left-hand side trees. For example,\n`ast.BinOp` inherits from `ast.expr`. For production rules with alternatives\n(aka \u201csums\u201d), the left-hand side class is abstract: only instances of specific\nconstructor nodes are ever created.\n\nEach concrete class has an attribute `_fields` which gives the names of all\nchild nodes.\n\nEach instance of a concrete class has one attribute for each child node, of\nthe type as defined in the grammar. For example, `ast.BinOp` instances have an\nattribute `left` of type `ast.expr`.\n\nIf these attributes are marked as optional in the grammar (using a question\nmark), the value might be `None`. If the attributes can have zero-or-more\nvalues (marked with an asterisk), the values are represented as Python lists.\nAll possible attributes must be present and have valid values when compiling\nan AST with `compile()`.\n\nInstances of `ast.expr` and `ast.stmt` subclasses have `lineno`, `col_offset`,\n`lineno`, and `col_offset` attributes. The `lineno` and `end_lineno` are the\nfirst and last line numbers of source text span (1-indexed so the first line\nis line 1) and the `col_offset` and `end_col_offset` are the corresponding\nUTF-8 byte offsets of the first and last tokens that generated the node. The\nUTF-8 offset is recorded because the parser uses UTF-8 internally.\n\nNote that the end positions are not required by the compiler and are therefore\noptional. The end offset is after the last symbol, for example one can get the\nsource segment of a one-line expression node using\n`source_line[node.col_offset : node.end_col_offset]`.\n\nThe constructor of a class `ast.T` parses its arguments as follows:\n\nFor example, to create and populate an `ast.UnaryOp` node, you could use\n\nor the more compact\n\nChanged in version 3.8: Class `ast.Constant` is now used for all constants.\n\nChanged in version 3.9: Simple indices are represented by their value,\nextended slices are represented as tuples.\n\nDeprecated since version 3.8: Old classes `ast.Num`, `ast.Str`, `ast.Bytes`,\n`ast.NameConstant` and `ast.Ellipsis` are still available, but they will be\nremoved in future Python releases. In the meantime, instantiating them will\nreturn an instance of a different class.\n\nDeprecated since version 3.9: Old classes `ast.Index` and `ast.ExtSlice` are\nstill available, but they will be removed in future Python releases. In the\nmeantime, instantiating them will return an instance of a different class.\n\nNote\n\nThe descriptions of the specific node classes displayed here were initially\nadapted from the fantastic Green Tree Snakes project and all its contributors.\n\nA constant value. The `value` attribute of the `Constant` literal contains the\nPython object it represents. The values represented can be simple types such\nas a number, string or `None`, but also immutable container types (tuples and\nfrozensets) if all of their elements are constant.\n\nNode representing a single formatting field in an f-string. If the string\ncontains a single formatting field and nothing else the node can be isolated\notherwise it appears in `JoinedStr`.\n\n`conversion` is an integer:\n\nAn f-string, comprising a series of `FormattedValue` and `Constant` nodes.\n\nA list or tuple. `elts` holds a list of nodes representing the elements. `ctx`\nis `Store` if the container is an assignment target (i.e. `(x,y)=something`),\nand `Load` otherwise.\n\nA set. `elts` holds a list of nodes representing the set\u2019s elements.\n\nA dictionary. `keys` and `values` hold lists of nodes representing the keys\nand the values respectively, in matching order (what would be returned when\ncalling `dictionary.keys()` and `dictionary.values()`).\n\nWhen doing dictionary unpacking using dictionary literals the expression to be\nexpanded goes in the `values` list, with a `None` at the corresponding\nposition in `keys`.\n\nA variable name. `id` holds the name as a string, and `ctx` is one of the\nfollowing types.\n\nVariable references can be used to load the value of a variable, to assign a\nnew value to it, or to delete it. Variable references are given a context to\ndistinguish these cases.\n\nA `*var` variable reference. `value` holds the variable, typically a `Name`\nnode. This type must be used when building a `Call` node with `*args`.\n\nWhen an expression, such as a function call, appears as a statement by itself\nwith its return value not used or stored, it is wrapped in this container.\n`value` holds one of the other nodes in this section, a `Constant`, a `Name`,\na `Lambda`, a `Yield` or `YieldFrom` node.\n\nA unary operation. `op` is the operator, and `operand` any expression node.\n\nUnary operator tokens. `Not` is the `not` keyword, `Invert` is the `~`\noperator.\n\nA binary operation (like addition or division). `op` is the operator, and\n`left` and `right` are any expression nodes.\n\nBinary operator tokens.\n\nA boolean operation, \u2018or\u2019 or \u2018and\u2019. `op` is `Or` or `And`. `values` are the\nvalues involved. Consecutive operations with the same operator, such as `a or\nb or c`, are collapsed into one node with several values.\n\nThis doesn\u2019t include `not`, which is a `UnaryOp`.\n\nBoolean operator tokens.\n\nA comparison of two or more values. `left` is the first value in the\ncomparison, `ops` the list of operators, and `comparators` the list of values\nafter the first element in the comparison.\n\nComparison operator tokens.\n\nA function call. `func` is the function, which will often be a `Name` or\n`Attribute` object. Of the arguments:\n\nWhen creating a `Call` node, `args` and `keywords` are required, but they can\nbe empty lists. `starargs` and `kwargs` are optional.\n\nA keyword argument to a function call or class definition. `arg` is a raw\nstring of the parameter name, `value` is a node to pass in.\n\nAn expression such as `a if b else c`. Each field holds a single node, so in\nthe following example, all three are `Name` nodes.\n\nAttribute access, e.g. `d.keys`. `value` is a node, typically a `Name`. `attr`\nis a bare string giving the name of the attribute, and `ctx` is `Load`,\n`Store` or `Del` according to how the attribute is acted on.\n\nA named expression. This AST node is produced by the assignment expressions\noperator (also known as the walrus operator). As opposed to the `Assign` node\nin which the first argument can be multiple nodes, in this case both `target`\nand `value` must be single nodes.\n\nA subscript, such as `l[1]`. `value` is the subscripted object (usually\nsequence or mapping). `slice` is an index, slice or key. It can be a `Tuple`\nand contain a `Slice`. `ctx` is `Load`, `Store` or `Del` according to the\naction performed with the subscript.\n\nRegular slicing (on the form `lower:upper` or `lower:upper:step`). Can occur\nonly inside the slice field of `Subscript`, either directly or as an element\nof `Tuple`.\n\nList and set comprehensions, generator expressions, and dictionary\ncomprehensions. `elt` (or `key` and `value`) is a single node representing the\npart that will be evaluated for each item.\n\n`generators` is a list of `comprehension` nodes.\n\nOne `for` clause in a comprehension. `target` is the reference to use for each\nelement - typically a `Name` or `Tuple` node. `iter` is the object to iterate\nover. `ifs` is a list of test expressions: each `for` clause can have multiple\n`ifs`.\n\n`is_async` indicates a comprehension is asynchronous (using an `async for`\ninstead of `for`). The value is an integer (0 or 1).\n\nAn assignment. `targets` is a list of nodes, and `value` is a single node.\n\nMultiple nodes in `targets` represents assigning the same value to each.\nUnpacking is represented by putting a `Tuple` or `List` within `targets`.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\nAn assignment with a type annotation. `target` is a single node and can be a\n`Name`, a `Attribute` or a `Subscript`. `annotation` is the annotation, such\nas a `Constant` or `Name` node. `value` is a single optional node. `simple` is\na boolean integer set to True for a `Name` node in `target` that do not appear\nin between parenthesis and are hence pure names and not expressions.\n\nAugmented assignment, such as `a += 1`. In the following example, `target` is\na `Name` node for `x` (with the `Store` context), `op` is `Add`, and `value`\nis a `Constant` with value for 1.\n\nThe `target` attribute connot be of class `Tuple` or `List`, unlike the\ntargets of `Assign`.\n\nA `raise` statement. `exc` is the exception object to be raised, normally a\n`Call` or `Name`, or `None` for a standalone `raise`. `cause` is the optional\npart for `y` in `raise x from y`.\n\nAn assertion. `test` holds the condition, such as a `Compare` node. `msg`\nholds the failure message.\n\nRepresents a `del` statement. `targets` is a list of nodes, such as `Name`,\n`Attribute` or `Subscript` nodes.\n\nA `pass` statement.\n\nOther statements which are only applicable inside functions or loops are\ndescribed in other sections.\n\nAn import statement. `names` is a list of `alias` nodes.\n\nRepresents `from x import y`. `module` is a raw string of the \u2018from\u2019 name,\nwithout any leading dots, or `None` for statements such as `from . import\nfoo`. `level` is an integer holding the level of the relative import (0 means\nabsolute import).\n\nBoth parameters are raw strings of the names. `asname` can be `None` if the\nregular name is to be used.\n\nNote\n\nOptional clauses such as `else` are stored as an empty list if they\u2019re not\npresent.\n\nAn `if` statement. `test` holds a single node, such as a `Compare` node.\n`body` and `orelse` each hold a list of nodes.\n\n`elif` clauses don\u2019t have a special representation in the AST, but rather\nappear as extra `If` nodes within the `orelse` section of the previous one.\n\nA `for` loop. `target` holds the variable(s) the loop assigns to, as a single\n`Name`, `Tuple` or `List` node. `iter` holds the item to be looped over, again\nas a single node. `body` and `orelse` contain lists of nodes to execute. Those\nin `orelse` are executed if the loop finishes normally, rather than via a\n`break` statement.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\nA `while` loop. `test` holds the condition, such as a `Compare` node.\n\nThe `break` and `continue` statements.\n\n`try` blocks. All attributes are list of nodes to execute, except for\n`handlers`, which is a list of `ExceptHandler` nodes.\n\nA single `except` clause. `type` is the exception type it will match,\ntypically a `Name` node (or `None` for a catch-all `except:` clause). `name`\nis a raw string for the name to hold the exception, or `None` if the clause\ndoesn\u2019t have `as foo`. `body` is a list of nodes.\n\nA `with` block. `items` is a list of `withitem` nodes representing the context\nmanagers, and `body` is the indented block inside the context.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\nA single context manager in a `with` block. `context_expr` is the context\nmanager, often a `Call` node. `optional_vars` is a `Name`, `Tuple` or `List`\nfor the `as foo` part, or `None` if that isn\u2019t used.\n\nA function definition.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\n`lambda` is a minimal function definition that can be used inside an\nexpression. Unlike `FunctionDef`, `body` holds a single node.\n\nThe arguments for a function.\n\nA single argument in a list. `arg` is a raw string of the argument name,\n`annotation` is its annotation, such as a `Str` or `Name` node.\n\n`type_comment` is an optional string with the type annotation as a comment\n\nA `return` statement.\n\nA `yield` or `yield from` expression. Because these are expressions, they must\nbe wrapped in a `Expr` node if the value sent back is not used.\n\n`global` and `nonlocal` statements. `names` is a list of raw strings.\n\nA class definition.\n\nAn `async def` function definition. Has the same fields as `FunctionDef`.\n\nAn `await` expression. `value` is what it waits for. Only valid in the body of\nan `AsyncFunctionDef`.\n\n`async for` loops and `async with` context managers. They have the same fields\nas `For` and `With`, respectively. Only valid in the body of an\n`AsyncFunctionDef`.\n\nNote\n\nWhen a string is parsed by `ast.parse()`, operator nodes (subclasses of\n`ast.operator`, `ast.unaryop`, `ast.cmpop`, `ast.boolop` and\n`ast.expr_context`) on the returned tree will be singletons. Changes to one\nwill be reflected in all other occurrences of the same value (e.g. `ast.Add`).\n\nApart from the node classes, the `ast` module defines these utility functions\nand classes for traversing abstract syntax trees:\n\nParse the source into an AST node. Equivalent to `compile(source, filename,\nmode, ast.PyCF_ONLY_AST)`.\n\nIf `type_comments=True` is given, the parser is modified to check and return\ntype comments as specified by PEP 484 and PEP 526. This is equivalent to\nadding `ast.PyCF_TYPE_COMMENTS` to the flags passed to `compile()`. This will\nreport syntax errors for misplaced type comments. Without this flag, type\ncomments will be ignored, and the `type_comment` field on selected AST nodes\nwill always be `None`. In addition, the locations of `# type: ignore` comments\nwill be returned as the `type_ignores` attribute of `Module` (otherwise it is\nalways an empty list).\n\nIn addition, if `mode` is `'func_type'`, the input syntax is modified to\ncorrespond to PEP 484 \u201csignature type comments\u201d, e.g. `(str, int) ->\nList[str]`.\n\nAlso, setting `feature_version` to a tuple `(major, minor)` will attempt to\nparse using that Python version\u2019s grammar. Currently `major` must equal to\n`3`. For example, setting `feature_version=(3, 4)` will allow the use of\n`async` and `await` as variable names. The lowest supported version is `(3,\n4)`; the highest is `sys.version_info[0:2]`.\n\nWarning\n\nIt is possible to crash the Python interpreter with a sufficiently\nlarge/complex string due to stack depth limitations in Python\u2019s AST compiler.\n\nChanged in version 3.8: Added `type_comments`, `mode='func_type'` and\n`feature_version`.\n\nUnparse an `ast.AST` object and generate a string with code that would produce\nan equivalent `ast.AST` object if parsed back with `ast.parse()`.\n\nWarning\n\nThe produced code string will not necessarily be equal to the original code\nthat generated the `ast.AST` object (without any compiler optimizations, such\nas constant tuples/frozensets).\n\nWarning\n\nTrying to unparse a highly complex expression would result with\n`RecursionError`.\n\nNew in version 3.9.\n\nSafely evaluate an expression node or a string containing a Python literal or\ncontainer display. The string or node provided may only consist of the\nfollowing Python literal structures: strings, bytes, numbers, tuples, lists,\ndicts, sets, booleans, and `None`.\n\nThis can be used for safely evaluating strings containing Python values from\nuntrusted sources without the need to parse the values oneself. It is not\ncapable of evaluating arbitrarily complex expressions, for example involving\noperators or indexing.\n\nWarning\n\nIt is possible to crash the Python interpreter with a sufficiently\nlarge/complex string due to stack depth limitations in Python\u2019s AST compiler.\n\nChanged in version 3.2: Now allows bytes and set literals.\n\nChanged in version 3.9: Now supports creating empty sets with `'set()'`.\n\nReturn the docstring of the given node (which must be a `FunctionDef`,\n`AsyncFunctionDef`, `ClassDef`, or `Module` node), or `None` if it has no\ndocstring. If clean is true, clean up the docstring\u2019s indentation with\n`inspect.cleandoc()`.\n\nChanged in version 3.5: `AsyncFunctionDef` is now supported.\n\nGet source code segment of the source that generated node. If some location\ninformation (`lineno`, `end_lineno`, `col_offset`, or `end_col_offset`) is\nmissing, return `None`.\n\nIf padded is `True`, the first line of a multi-line statement will be padded\nwith spaces to match its original position.\n\nNew in version 3.8.\n\nWhen you compile a node tree with `compile()`, the compiler expects `lineno`\nand `col_offset` attributes for every node that supports them. This is rather\ntedious to fill in for generated nodes, so this helper adds these attributes\nrecursively where not already set, by setting them to the values of the parent\nnode. It works recursively starting at node.\n\nIncrement the line number and end line number of each node in the tree\nstarting at node by n. This is useful to \u201cmove code\u201d to a different location\nin a file.\n\nCopy source location (`lineno`, `col_offset`, `end_lineno`, and\n`end_col_offset`) from old_node to new_node if possible, and return new_node.\n\nYield a tuple of `(fieldname, value)` for each field in `node._fields` that is\npresent on node.\n\nYield all direct child nodes of node, that is, all fields that are nodes and\nall items of fields that are lists of nodes.\n\nRecursively yield all descendant nodes in the tree starting at node (including\nnode itself), in no specified order. This is useful if you only want to modify\nnodes in place and don\u2019t care about the context.\n\nA node visitor base class that walks the abstract syntax tree and calls a\nvisitor function for every node found. This function may return a value which\nis forwarded by the `visit()` method.\n\nThis class is meant to be subclassed, with the subclass adding visitor\nmethods.\n\nVisit a node. The default implementation calls the method called\n`self.visit_classname` where classname is the name of the node class, or\n`generic_visit()` if that method doesn\u2019t exist.\n\nThis visitor calls `visit()` on all children of the node.\n\nNote that child nodes of nodes that have a custom visitor method won\u2019t be\nvisited unless the visitor calls `generic_visit()` or visits them itself.\n\nDon\u2019t use the `NodeVisitor` if you want to apply changes to nodes during\ntraversal. For this a special visitor exists (`NodeTransformer`) that allows\nmodifications.\n\nDeprecated since version 3.8: Methods `visit_Num()`, `visit_Str()`,\n`visit_Bytes()`, `visit_NameConstant()` and `visit_Ellipsis()` are deprecated\nnow and will not be called in future Python versions. Add the\n`visit_Constant()` method to handle all constant nodes.\n\nA `NodeVisitor` subclass that walks the abstract syntax tree and allows\nmodification of nodes.\n\nThe `NodeTransformer` will walk the AST and use the return value of the\nvisitor methods to replace or remove the old node. If the return value of the\nvisitor method is `None`, the node will be removed from its location,\notherwise it is replaced with the return value. The return value may be the\noriginal node in which case no replacement takes place.\n\nHere is an example transformer that rewrites all occurrences of name lookups\n(`foo`) to `data['foo']`:\n\nKeep in mind that if the node you\u2019re operating on has child nodes you must\neither transform the child nodes yourself or call the `generic_visit()` method\nfor the node first.\n\nFor nodes that were part of a collection of statements (that applies to all\nstatement nodes), the visitor may also return a list of nodes rather than just\na single node.\n\nIf `NodeTransformer` introduces new nodes (that weren\u2019t part of original tree)\nwithout giving them location information (such as `lineno`),\n`fix_missing_locations()` should be called with the new sub-tree to\nrecalculate the location information:\n\nUsually you use the transformer like this:\n\nReturn a formatted dump of the tree in node. This is mainly useful for\ndebugging purposes. If annotate_fields is true (by default), the returned\nstring will show the names and the values for fields. If annotate_fields is\nfalse, the result string will be more compact by omitting unambiguous field\nnames. Attributes such as line numbers and column offsets are not dumped by\ndefault. If this is wanted, include_attributes can be set to true.\n\nIf indent is a non-negative integer or string, then the tree will be pretty-\nprinted with that indent level. An indent level of 0, negative, or `\"\"` will\nonly insert newlines. `None` (the default) selects the single line\nrepresentation. Using a positive integer indent indents that many spaces per\nlevel. If indent is a string (such as `\"\\t\"`), that string is used to indent\neach level.\n\nChanged in version 3.9: Added the indent option.\n\nThe following flags may be passed to `compile()` in order to change effects on\nthe compilation of a program:\n\nEnables support for top-level `await`, `async for`, `async with` and async\ncomprehensions.\n\nNew in version 3.8.\n\nGenerates and returns an abstract syntax tree instead of returning a compiled\ncode object.\n\nEnables support for PEP 484 and PEP 526 style type comments (`# type: <type>`,\n`# type: ignore <stuff>`).\n\nNew in version 3.8.\n\nNew in version 3.9.\n\nThe `ast` module can be executed as a script from the command line. It is as\nsimple as:\n\nThe following options are accepted:\n\nShow the help message and exit.\n\nSpecify what kind of code must be compiled, like the mode argument in\n`parse()`.\n\nDon\u2019t parse type comments.\n\nInclude attributes such as line numbers and column offsets.\n\nIndentation of nodes in AST (number of spaces).\n\nIf `infile` is specified its contents are parsed to AST and dumped to stdout.\nOtherwise, the content is read from stdin.\n\nSee also\n\nGreen Tree Snakes, an external documentation resource, has good details on\nworking with Python ASTs.\n\nASTTokens annotates Python ASTs with the positions of tokens and text in the\nsource code that generated them. This is helpful for tools that make source\ncode transformations.\n\nleoAst.py unifies the token-based and parse-tree-based views of python\nprograms by inserting two-way links between tokens and ast nodes.\n\nLibCST parses code as a Concrete Syntax Tree that looks like an ast tree and\nkeeps all formatting details. It\u2019s useful for building automated refactoring\n(codemod) applications and linters.\n\nParso is a Python parser that supports error recovery and round-trip parsing\nfor different Python versions (in multiple Python versions). Parso is also\nable to list multiple syntax errors in your python file.\n\n"}, {"name": "ast.Add", "path": "library/ast#ast.Add", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.alias", "path": "library/ast#ast.alias", "type": "Language", "text": "\nBoth parameters are raw strings of the names. `asname` can be `None` if the\nregular name is to be used.\n\n"}, {"name": "ast.And", "path": "library/ast#ast.And", "type": "Language", "text": "\nBoolean operator tokens.\n\n"}, {"name": "ast.AnnAssign", "path": "library/ast#ast.AnnAssign", "type": "Language", "text": "\nAn assignment with a type annotation. `target` is a single node and can be a\n`Name`, a `Attribute` or a `Subscript`. `annotation` is the annotation, such\nas a `Constant` or `Name` node. `value` is a single optional node. `simple` is\na boolean integer set to True for a `Name` node in `target` that do not appear\nin between parenthesis and are hence pure names and not expressions.\n\n"}, {"name": "ast.arg", "path": "library/ast#ast.arg", "type": "Language", "text": "\nA single argument in a list. `arg` is a raw string of the argument name,\n`annotation` is its annotation, such as a `Str` or `Name` node.\n\n`type_comment` is an optional string with the type annotation as a comment\n\n"}, {"name": "ast.arg.type_comment", "path": "library/ast#ast.arg.type_comment", "type": "Language", "text": "\n`type_comment` is an optional string with the type annotation as a comment\n\n"}, {"name": "ast.arguments", "path": "library/ast#ast.arguments", "type": "Language", "text": "\nThe arguments for a function.\n\n"}, {"name": "ast.Assert", "path": "library/ast#ast.Assert", "type": "Language", "text": "\nAn assertion. `test` holds the condition, such as a `Compare` node. `msg`\nholds the failure message.\n\n"}, {"name": "ast.Assign", "path": "library/ast#ast.Assign", "type": "Language", "text": "\nAn assignment. `targets` is a list of nodes, and `value` is a single node.\n\nMultiple nodes in `targets` represents assigning the same value to each.\nUnpacking is represented by putting a `Tuple` or `List` within `targets`.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.Assign.type_comment", "path": "library/ast#ast.Assign.type_comment", "type": "Language", "text": "\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.AST", "path": "library/ast#ast.AST", "type": "Language", "text": "\nThis is the base of all AST node classes. The actual node classes are derived\nfrom the `Parser/Python.asdl` file, which is reproduced below. They are\ndefined in the `_ast` C module and re-exported in `ast`.\n\nThere is one class defined for each left-hand side symbol in the abstract\ngrammar (for example, `ast.stmt` or `ast.expr`). In addition, there is one\nclass defined for each constructor on the right-hand side; these classes\ninherit from the classes for the left-hand side trees. For example,\n`ast.BinOp` inherits from `ast.expr`. For production rules with alternatives\n(aka \u201csums\u201d), the left-hand side class is abstract: only instances of specific\nconstructor nodes are ever created.\n\nEach concrete class has an attribute `_fields` which gives the names of all\nchild nodes.\n\nEach instance of a concrete class has one attribute for each child node, of\nthe type as defined in the grammar. For example, `ast.BinOp` instances have an\nattribute `left` of type `ast.expr`.\n\nIf these attributes are marked as optional in the grammar (using a question\nmark), the value might be `None`. If the attributes can have zero-or-more\nvalues (marked with an asterisk), the values are represented as Python lists.\nAll possible attributes must be present and have valid values when compiling\nan AST with `compile()`.\n\nInstances of `ast.expr` and `ast.stmt` subclasses have `lineno`, `col_offset`,\n`lineno`, and `col_offset` attributes. The `lineno` and `end_lineno` are the\nfirst and last line numbers of source text span (1-indexed so the first line\nis line 1) and the `col_offset` and `end_col_offset` are the corresponding\nUTF-8 byte offsets of the first and last tokens that generated the node. The\nUTF-8 offset is recorded because the parser uses UTF-8 internally.\n\nNote that the end positions are not required by the compiler and are therefore\noptional. The end offset is after the last symbol, for example one can get the\nsource segment of a one-line expression node using\n`source_line[node.col_offset : node.end_col_offset]`.\n\nThe constructor of a class `ast.T` parses its arguments as follows:\n\nFor example, to create and populate an `ast.UnaryOp` node, you could use\n\nor the more compact\n\n"}, {"name": "ast.AST.col_offset", "path": "library/ast#ast.AST.col_offset", "type": "Language", "text": "\nInstances of `ast.expr` and `ast.stmt` subclasses have `lineno`, `col_offset`,\n`lineno`, and `col_offset` attributes. The `lineno` and `end_lineno` are the\nfirst and last line numbers of source text span (1-indexed so the first line\nis line 1) and the `col_offset` and `end_col_offset` are the corresponding\nUTF-8 byte offsets of the first and last tokens that generated the node. The\nUTF-8 offset is recorded because the parser uses UTF-8 internally.\n\nNote that the end positions are not required by the compiler and are therefore\noptional. The end offset is after the last symbol, for example one can get the\nsource segment of a one-line expression node using\n`source_line[node.col_offset : node.end_col_offset]`.\n\n"}, {"name": "ast.AST.end_col_offset", "path": "library/ast#ast.AST.end_col_offset", "type": "Language", "text": "\nInstances of `ast.expr` and `ast.stmt` subclasses have `lineno`, `col_offset`,\n`lineno`, and `col_offset` attributes. The `lineno` and `end_lineno` are the\nfirst and last line numbers of source text span (1-indexed so the first line\nis line 1) and the `col_offset` and `end_col_offset` are the corresponding\nUTF-8 byte offsets of the first and last tokens that generated the node. The\nUTF-8 offset is recorded because the parser uses UTF-8 internally.\n\nNote that the end positions are not required by the compiler and are therefore\noptional. The end offset is after the last symbol, for example one can get the\nsource segment of a one-line expression node using\n`source_line[node.col_offset : node.end_col_offset]`.\n\n"}, {"name": "ast.AST.end_lineno", "path": "library/ast#ast.AST.end_lineno", "type": "Language", "text": "\nInstances of `ast.expr` and `ast.stmt` subclasses have `lineno`, `col_offset`,\n`lineno`, and `col_offset` attributes. The `lineno` and `end_lineno` are the\nfirst and last line numbers of source text span (1-indexed so the first line\nis line 1) and the `col_offset` and `end_col_offset` are the corresponding\nUTF-8 byte offsets of the first and last tokens that generated the node. The\nUTF-8 offset is recorded because the parser uses UTF-8 internally.\n\nNote that the end positions are not required by the compiler and are therefore\noptional. The end offset is after the last symbol, for example one can get the\nsource segment of a one-line expression node using\n`source_line[node.col_offset : node.end_col_offset]`.\n\n"}, {"name": "ast.AST.lineno", "path": "library/ast#ast.AST.lineno", "type": "Language", "text": "\nInstances of `ast.expr` and `ast.stmt` subclasses have `lineno`, `col_offset`,\n`lineno`, and `col_offset` attributes. The `lineno` and `end_lineno` are the\nfirst and last line numbers of source text span (1-indexed so the first line\nis line 1) and the `col_offset` and `end_col_offset` are the corresponding\nUTF-8 byte offsets of the first and last tokens that generated the node. The\nUTF-8 offset is recorded because the parser uses UTF-8 internally.\n\nNote that the end positions are not required by the compiler and are therefore\noptional. The end offset is after the last symbol, for example one can get the\nsource segment of a one-line expression node using\n`source_line[node.col_offset : node.end_col_offset]`.\n\n"}, {"name": "ast.AST._fields", "path": "library/ast#ast.AST._fields", "type": "Language", "text": "\nEach concrete class has an attribute `_fields` which gives the names of all\nchild nodes.\n\nEach instance of a concrete class has one attribute for each child node, of\nthe type as defined in the grammar. For example, `ast.BinOp` instances have an\nattribute `left` of type `ast.expr`.\n\nIf these attributes are marked as optional in the grammar (using a question\nmark), the value might be `None`. If the attributes can have zero-or-more\nvalues (marked with an asterisk), the values are represented as Python lists.\nAll possible attributes must be present and have valid values when compiling\nan AST with `compile()`.\n\n"}, {"name": "ast.AsyncFor", "path": "library/ast#ast.AsyncFor", "type": "Language", "text": "\n`async for` loops and `async with` context managers. They have the same fields\nas `For` and `With`, respectively. Only valid in the body of an\n`AsyncFunctionDef`.\n\n"}, {"name": "ast.AsyncFunctionDef", "path": "library/ast#ast.AsyncFunctionDef", "type": "Language", "text": "\nAn `async def` function definition. Has the same fields as `FunctionDef`.\n\n"}, {"name": "ast.AsyncWith", "path": "library/ast#ast.AsyncWith", "type": "Language", "text": "\n`async for` loops and `async with` context managers. They have the same fields\nas `For` and `With`, respectively. Only valid in the body of an\n`AsyncFunctionDef`.\n\n"}, {"name": "ast.Attribute", "path": "library/ast#ast.Attribute", "type": "Language", "text": "\nAttribute access, e.g. `d.keys`. `value` is a node, typically a `Name`. `attr`\nis a bare string giving the name of the attribute, and `ctx` is `Load`,\n`Store` or `Del` according to how the attribute is acted on.\n\n"}, {"name": "ast.AugAssign", "path": "library/ast#ast.AugAssign", "type": "Language", "text": "\nAugmented assignment, such as `a += 1`. In the following example, `target` is\na `Name` node for `x` (with the `Store` context), `op` is `Add`, and `value`\nis a `Constant` with value for 1.\n\nThe `target` attribute connot be of class `Tuple` or `List`, unlike the\ntargets of `Assign`.\n\n"}, {"name": "ast.Await", "path": "library/ast#ast.Await", "type": "Language", "text": "\nAn `await` expression. `value` is what it waits for. Only valid in the body of\nan `AsyncFunctionDef`.\n\n"}, {"name": "ast.BinOp", "path": "library/ast#ast.BinOp", "type": "Language", "text": "\nA binary operation (like addition or division). `op` is the operator, and\n`left` and `right` are any expression nodes.\n\n"}, {"name": "ast.BitAnd", "path": "library/ast#ast.BitAnd", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.BitOr", "path": "library/ast#ast.BitOr", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.BitXor", "path": "library/ast#ast.BitXor", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.BoolOp", "path": "library/ast#ast.BoolOp", "type": "Language", "text": "\nA boolean operation, \u2018or\u2019 or \u2018and\u2019. `op` is `Or` or `And`. `values` are the\nvalues involved. Consecutive operations with the same operator, such as `a or\nb or c`, are collapsed into one node with several values.\n\nThis doesn\u2019t include `not`, which is a `UnaryOp`.\n\n"}, {"name": "ast.Break", "path": "library/ast#ast.Break", "type": "Language", "text": "\nThe `break` and `continue` statements.\n\n"}, {"name": "ast.Call", "path": "library/ast#ast.Call", "type": "Language", "text": "\nA function call. `func` is the function, which will often be a `Name` or\n`Attribute` object. Of the arguments:\n\nWhen creating a `Call` node, `args` and `keywords` are required, but they can\nbe empty lists. `starargs` and `kwargs` are optional.\n\n"}, {"name": "ast.ClassDef", "path": "library/ast#ast.ClassDef", "type": "Language", "text": "\nA class definition.\n\n"}, {"name": "ast.Compare", "path": "library/ast#ast.Compare", "type": "Language", "text": "\nA comparison of two or more values. `left` is the first value in the\ncomparison, `ops` the list of operators, and `comparators` the list of values\nafter the first element in the comparison.\n\n"}, {"name": "ast.comprehension", "path": "library/ast#ast.comprehension", "type": "Language", "text": "\nOne `for` clause in a comprehension. `target` is the reference to use for each\nelement - typically a `Name` or `Tuple` node. `iter` is the object to iterate\nover. `ifs` is a list of test expressions: each `for` clause can have multiple\n`ifs`.\n\n`is_async` indicates a comprehension is asynchronous (using an `async for`\ninstead of `for`). The value is an integer (0 or 1).\n\n"}, {"name": "ast.Constant", "path": "library/ast#ast.Constant", "type": "Language", "text": "\nA constant value. The `value` attribute of the `Constant` literal contains the\nPython object it represents. The values represented can be simple types such\nas a number, string or `None`, but also immutable container types (tuples and\nfrozensets) if all of their elements are constant.\n\n"}, {"name": "ast.Continue", "path": "library/ast#ast.Continue", "type": "Language", "text": "\nThe `break` and `continue` statements.\n\n"}, {"name": "ast.copy_location()", "path": "library/ast#ast.copy_location", "type": "Language", "text": "\nCopy source location (`lineno`, `col_offset`, `end_lineno`, and\n`end_col_offset`) from old_node to new_node if possible, and return new_node.\n\n"}, {"name": "ast.Del", "path": "library/ast#ast.Del", "type": "Language", "text": "\nVariable references can be used to load the value of a variable, to assign a\nnew value to it, or to delete it. Variable references are given a context to\ndistinguish these cases.\n\n"}, {"name": "ast.Delete", "path": "library/ast#ast.Delete", "type": "Language", "text": "\nRepresents a `del` statement. `targets` is a list of nodes, such as `Name`,\n`Attribute` or `Subscript` nodes.\n\n"}, {"name": "ast.Dict", "path": "library/ast#ast.Dict", "type": "Language", "text": "\nA dictionary. `keys` and `values` hold lists of nodes representing the keys\nand the values respectively, in matching order (what would be returned when\ncalling `dictionary.keys()` and `dictionary.values()`).\n\nWhen doing dictionary unpacking using dictionary literals the expression to be\nexpanded goes in the `values` list, with a `None` at the corresponding\nposition in `keys`.\n\n"}, {"name": "ast.DictComp", "path": "library/ast#ast.DictComp", "type": "Language", "text": "\nList and set comprehensions, generator expressions, and dictionary\ncomprehensions. `elt` (or `key` and `value`) is a single node representing the\npart that will be evaluated for each item.\n\n`generators` is a list of `comprehension` nodes.\n\n"}, {"name": "ast.Div", "path": "library/ast#ast.Div", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.dump()", "path": "library/ast#ast.dump", "type": "Language", "text": "\nReturn a formatted dump of the tree in node. This is mainly useful for\ndebugging purposes. If annotate_fields is true (by default), the returned\nstring will show the names and the values for fields. If annotate_fields is\nfalse, the result string will be more compact by omitting unambiguous field\nnames. Attributes such as line numbers and column offsets are not dumped by\ndefault. If this is wanted, include_attributes can be set to true.\n\nIf indent is a non-negative integer or string, then the tree will be pretty-\nprinted with that indent level. An indent level of 0, negative, or `\"\"` will\nonly insert newlines. `None` (the default) selects the single line\nrepresentation. Using a positive integer indent indents that many spaces per\nlevel. If indent is a string (such as `\"\\t\"`), that string is used to indent\neach level.\n\nChanged in version 3.9: Added the indent option.\n\n"}, {"name": "ast.Eq", "path": "library/ast#ast.Eq", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.ExceptHandler", "path": "library/ast#ast.ExceptHandler", "type": "Language", "text": "\nA single `except` clause. `type` is the exception type it will match,\ntypically a `Name` node (or `None` for a catch-all `except:` clause). `name`\nis a raw string for the name to hold the exception, or `None` if the clause\ndoesn\u2019t have `as foo`. `body` is a list of nodes.\n\n"}, {"name": "ast.Expr", "path": "library/ast#ast.Expr", "type": "Language", "text": "\nWhen an expression, such as a function call, appears as a statement by itself\nwith its return value not used or stored, it is wrapped in this container.\n`value` holds one of the other nodes in this section, a `Constant`, a `Name`,\na `Lambda`, a `Yield` or `YieldFrom` node.\n\n"}, {"name": "ast.fix_missing_locations()", "path": "library/ast#ast.fix_missing_locations", "type": "Language", "text": "\nWhen you compile a node tree with `compile()`, the compiler expects `lineno`\nand `col_offset` attributes for every node that supports them. This is rather\ntedious to fill in for generated nodes, so this helper adds these attributes\nrecursively where not already set, by setting them to the values of the parent\nnode. It works recursively starting at node.\n\n"}, {"name": "ast.FloorDiv", "path": "library/ast#ast.FloorDiv", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.For", "path": "library/ast#ast.For", "type": "Language", "text": "\nA `for` loop. `target` holds the variable(s) the loop assigns to, as a single\n`Name`, `Tuple` or `List` node. `iter` holds the item to be looped over, again\nas a single node. `body` and `orelse` contain lists of nodes to execute. Those\nin `orelse` are executed if the loop finishes normally, rather than via a\n`break` statement.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.For.type_comment", "path": "library/ast#ast.For.type_comment", "type": "Language", "text": "\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.FormattedValue", "path": "library/ast#ast.FormattedValue", "type": "Language", "text": "\nNode representing a single formatting field in an f-string. If the string\ncontains a single formatting field and nothing else the node can be isolated\notherwise it appears in `JoinedStr`.\n\n`conversion` is an integer:\n\n"}, {"name": "ast.FunctionDef", "path": "library/ast#ast.FunctionDef", "type": "Language", "text": "\nA function definition.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.FunctionDef.type_comment", "path": "library/ast#ast.FunctionDef.type_comment", "type": "Language", "text": "\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.GeneratorExp", "path": "library/ast#ast.GeneratorExp", "type": "Language", "text": "\nList and set comprehensions, generator expressions, and dictionary\ncomprehensions. `elt` (or `key` and `value`) is a single node representing the\npart that will be evaluated for each item.\n\n`generators` is a list of `comprehension` nodes.\n\n"}, {"name": "ast.get_docstring()", "path": "library/ast#ast.get_docstring", "type": "Language", "text": "\nReturn the docstring of the given node (which must be a `FunctionDef`,\n`AsyncFunctionDef`, `ClassDef`, or `Module` node), or `None` if it has no\ndocstring. If clean is true, clean up the docstring\u2019s indentation with\n`inspect.cleandoc()`.\n\nChanged in version 3.5: `AsyncFunctionDef` is now supported.\n\n"}, {"name": "ast.get_source_segment()", "path": "library/ast#ast.get_source_segment", "type": "Language", "text": "\nGet source code segment of the source that generated node. If some location\ninformation (`lineno`, `end_lineno`, `col_offset`, or `end_col_offset`) is\nmissing, return `None`.\n\nIf padded is `True`, the first line of a multi-line statement will be padded\nwith spaces to match its original position.\n\nNew in version 3.8.\n\n"}, {"name": "ast.Global", "path": "library/ast#ast.Global", "type": "Language", "text": "\n`global` and `nonlocal` statements. `names` is a list of raw strings.\n\n"}, {"name": "ast.Gt", "path": "library/ast#ast.Gt", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.GtE", "path": "library/ast#ast.GtE", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.If", "path": "library/ast#ast.If", "type": "Language", "text": "\nAn `if` statement. `test` holds a single node, such as a `Compare` node.\n`body` and `orelse` each hold a list of nodes.\n\n`elif` clauses don\u2019t have a special representation in the AST, but rather\nappear as extra `If` nodes within the `orelse` section of the previous one.\n\n"}, {"name": "ast.IfExp", "path": "library/ast#ast.IfExp", "type": "Language", "text": "\nAn expression such as `a if b else c`. Each field holds a single node, so in\nthe following example, all three are `Name` nodes.\n\n"}, {"name": "ast.Import", "path": "library/ast#ast.Import", "type": "Language", "text": "\nAn import statement. `names` is a list of `alias` nodes.\n\n"}, {"name": "ast.ImportFrom", "path": "library/ast#ast.ImportFrom", "type": "Language", "text": "\nRepresents `from x import y`. `module` is a raw string of the \u2018from\u2019 name,\nwithout any leading dots, or `None` for statements such as `from . import\nfoo`. `level` is an integer holding the level of the relative import (0 means\nabsolute import).\n\n"}, {"name": "ast.In", "path": "library/ast#ast.In", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.increment_lineno()", "path": "library/ast#ast.increment_lineno", "type": "Language", "text": "\nIncrement the line number and end line number of each node in the tree\nstarting at node by n. This is useful to \u201cmove code\u201d to a different location\nin a file.\n\n"}, {"name": "ast.Invert", "path": "library/ast#ast.Invert", "type": "Language", "text": "\nUnary operator tokens. `Not` is the `not` keyword, `Invert` is the `~`\noperator.\n\n"}, {"name": "ast.Is", "path": "library/ast#ast.Is", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.IsNot", "path": "library/ast#ast.IsNot", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.iter_child_nodes()", "path": "library/ast#ast.iter_child_nodes", "type": "Language", "text": "\nYield all direct child nodes of node, that is, all fields that are nodes and\nall items of fields that are lists of nodes.\n\n"}, {"name": "ast.iter_fields()", "path": "library/ast#ast.iter_fields", "type": "Language", "text": "\nYield a tuple of `(fieldname, value)` for each field in `node._fields` that is\npresent on node.\n\n"}, {"name": "ast.JoinedStr", "path": "library/ast#ast.JoinedStr", "type": "Language", "text": "\nAn f-string, comprising a series of `FormattedValue` and `Constant` nodes.\n\n"}, {"name": "ast.keyword", "path": "library/ast#ast.keyword", "type": "Language", "text": "\nA keyword argument to a function call or class definition. `arg` is a raw\nstring of the parameter name, `value` is a node to pass in.\n\n"}, {"name": "ast.Lambda", "path": "library/ast#ast.Lambda", "type": "Language", "text": "\n`lambda` is a minimal function definition that can be used inside an\nexpression. Unlike `FunctionDef`, `body` holds a single node.\n\n"}, {"name": "ast.List", "path": "library/ast#ast.List", "type": "Language", "text": "\nA list or tuple. `elts` holds a list of nodes representing the elements. `ctx`\nis `Store` if the container is an assignment target (i.e. `(x,y)=something`),\nand `Load` otherwise.\n\n"}, {"name": "ast.ListComp", "path": "library/ast#ast.ListComp", "type": "Language", "text": "\nList and set comprehensions, generator expressions, and dictionary\ncomprehensions. `elt` (or `key` and `value`) is a single node representing the\npart that will be evaluated for each item.\n\n`generators` is a list of `comprehension` nodes.\n\n"}, {"name": "ast.literal_eval()", "path": "library/ast#ast.literal_eval", "type": "Language", "text": "\nSafely evaluate an expression node or a string containing a Python literal or\ncontainer display. The string or node provided may only consist of the\nfollowing Python literal structures: strings, bytes, numbers, tuples, lists,\ndicts, sets, booleans, and `None`.\n\nThis can be used for safely evaluating strings containing Python values from\nuntrusted sources without the need to parse the values oneself. It is not\ncapable of evaluating arbitrarily complex expressions, for example involving\noperators or indexing.\n\nWarning\n\nIt is possible to crash the Python interpreter with a sufficiently\nlarge/complex string due to stack depth limitations in Python\u2019s AST compiler.\n\nChanged in version 3.2: Now allows bytes and set literals.\n\nChanged in version 3.9: Now supports creating empty sets with `'set()'`.\n\n"}, {"name": "ast.Load", "path": "library/ast#ast.Load", "type": "Language", "text": "\nVariable references can be used to load the value of a variable, to assign a\nnew value to it, or to delete it. Variable references are given a context to\ndistinguish these cases.\n\n"}, {"name": "ast.LShift", "path": "library/ast#ast.LShift", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.Lt", "path": "library/ast#ast.Lt", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.LtE", "path": "library/ast#ast.LtE", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.MatMult", "path": "library/ast#ast.MatMult", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.Mod", "path": "library/ast#ast.Mod", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.Mult", "path": "library/ast#ast.Mult", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.Name", "path": "library/ast#ast.Name", "type": "Language", "text": "\nA variable name. `id` holds the name as a string, and `ctx` is one of the\nfollowing types.\n\n"}, {"name": "ast.NamedExpr", "path": "library/ast#ast.NamedExpr", "type": "Language", "text": "\nA named expression. This AST node is produced by the assignment expressions\noperator (also known as the walrus operator). As opposed to the `Assign` node\nin which the first argument can be multiple nodes, in this case both `target`\nand `value` must be single nodes.\n\n"}, {"name": "ast.NodeTransformer", "path": "library/ast#ast.NodeTransformer", "type": "Language", "text": "\nA `NodeVisitor` subclass that walks the abstract syntax tree and allows\nmodification of nodes.\n\nThe `NodeTransformer` will walk the AST and use the return value of the\nvisitor methods to replace or remove the old node. If the return value of the\nvisitor method is `None`, the node will be removed from its location,\notherwise it is replaced with the return value. The return value may be the\noriginal node in which case no replacement takes place.\n\nHere is an example transformer that rewrites all occurrences of name lookups\n(`foo`) to `data['foo']`:\n\nKeep in mind that if the node you\u2019re operating on has child nodes you must\neither transform the child nodes yourself or call the `generic_visit()` method\nfor the node first.\n\nFor nodes that were part of a collection of statements (that applies to all\nstatement nodes), the visitor may also return a list of nodes rather than just\na single node.\n\nIf `NodeTransformer` introduces new nodes (that weren\u2019t part of original tree)\nwithout giving them location information (such as `lineno`),\n`fix_missing_locations()` should be called with the new sub-tree to\nrecalculate the location information:\n\nUsually you use the transformer like this:\n\n"}, {"name": "ast.NodeVisitor", "path": "library/ast#ast.NodeVisitor", "type": "Language", "text": "\nA node visitor base class that walks the abstract syntax tree and calls a\nvisitor function for every node found. This function may return a value which\nis forwarded by the `visit()` method.\n\nThis class is meant to be subclassed, with the subclass adding visitor\nmethods.\n\nVisit a node. The default implementation calls the method called\n`self.visit_classname` where classname is the name of the node class, or\n`generic_visit()` if that method doesn\u2019t exist.\n\nThis visitor calls `visit()` on all children of the node.\n\nNote that child nodes of nodes that have a custom visitor method won\u2019t be\nvisited unless the visitor calls `generic_visit()` or visits them itself.\n\nDon\u2019t use the `NodeVisitor` if you want to apply changes to nodes during\ntraversal. For this a special visitor exists (`NodeTransformer`) that allows\nmodifications.\n\nDeprecated since version 3.8: Methods `visit_Num()`, `visit_Str()`,\n`visit_Bytes()`, `visit_NameConstant()` and `visit_Ellipsis()` are deprecated\nnow and will not be called in future Python versions. Add the\n`visit_Constant()` method to handle all constant nodes.\n\n"}, {"name": "ast.NodeVisitor.generic_visit()", "path": "library/ast#ast.NodeVisitor.generic_visit", "type": "Language", "text": "\nThis visitor calls `visit()` on all children of the node.\n\nNote that child nodes of nodes that have a custom visitor method won\u2019t be\nvisited unless the visitor calls `generic_visit()` or visits them itself.\n\n"}, {"name": "ast.NodeVisitor.visit()", "path": "library/ast#ast.NodeVisitor.visit", "type": "Language", "text": "\nVisit a node. The default implementation calls the method called\n`self.visit_classname` where classname is the name of the node class, or\n`generic_visit()` if that method doesn\u2019t exist.\n\n"}, {"name": "ast.Nonlocal", "path": "library/ast#ast.Nonlocal", "type": "Language", "text": "\n`global` and `nonlocal` statements. `names` is a list of raw strings.\n\n"}, {"name": "ast.Not", "path": "library/ast#ast.Not", "type": "Language", "text": "\nUnary operator tokens. `Not` is the `not` keyword, `Invert` is the `~`\noperator.\n\n"}, {"name": "ast.NotEq", "path": "library/ast#ast.NotEq", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.NotIn", "path": "library/ast#ast.NotIn", "type": "Language", "text": "\nComparison operator tokens.\n\n"}, {"name": "ast.Or", "path": "library/ast#ast.Or", "type": "Language", "text": "\nBoolean operator tokens.\n\n"}, {"name": "ast.parse()", "path": "library/ast#ast.parse", "type": "Language", "text": "\nParse the source into an AST node. Equivalent to `compile(source, filename,\nmode, ast.PyCF_ONLY_AST)`.\n\nIf `type_comments=True` is given, the parser is modified to check and return\ntype comments as specified by PEP 484 and PEP 526. This is equivalent to\nadding `ast.PyCF_TYPE_COMMENTS` to the flags passed to `compile()`. This will\nreport syntax errors for misplaced type comments. Without this flag, type\ncomments will be ignored, and the `type_comment` field on selected AST nodes\nwill always be `None`. In addition, the locations of `# type: ignore` comments\nwill be returned as the `type_ignores` attribute of `Module` (otherwise it is\nalways an empty list).\n\nIn addition, if `mode` is `'func_type'`, the input syntax is modified to\ncorrespond to PEP 484 \u201csignature type comments\u201d, e.g. `(str, int) ->\nList[str]`.\n\nAlso, setting `feature_version` to a tuple `(major, minor)` will attempt to\nparse using that Python version\u2019s grammar. Currently `major` must equal to\n`3`. For example, setting `feature_version=(3, 4)` will allow the use of\n`async` and `await` as variable names. The lowest supported version is `(3,\n4)`; the highest is `sys.version_info[0:2]`.\n\nWarning\n\nIt is possible to crash the Python interpreter with a sufficiently\nlarge/complex string due to stack depth limitations in Python\u2019s AST compiler.\n\nChanged in version 3.8: Added `type_comments`, `mode='func_type'` and\n`feature_version`.\n\n"}, {"name": "ast.Pass", "path": "library/ast#ast.Pass", "type": "Language", "text": "\nA `pass` statement.\n\n"}, {"name": "ast.Pow", "path": "library/ast#ast.Pow", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.PyCF_ALLOW_TOP_LEVEL_AWAIT", "path": "library/ast#ast.PyCF_ALLOW_TOP_LEVEL_AWAIT", "type": "Language", "text": "\nEnables support for top-level `await`, `async for`, `async with` and async\ncomprehensions.\n\nNew in version 3.8.\n\n"}, {"name": "ast.PyCF_ONLY_AST", "path": "library/ast#ast.PyCF_ONLY_AST", "type": "Language", "text": "\nGenerates and returns an abstract syntax tree instead of returning a compiled\ncode object.\n\n"}, {"name": "ast.PyCF_TYPE_COMMENTS", "path": "library/ast#ast.PyCF_TYPE_COMMENTS", "type": "Language", "text": "\nEnables support for PEP 484 and PEP 526 style type comments (`# type: <type>`,\n`# type: ignore <stuff>`).\n\nNew in version 3.8.\n\n"}, {"name": "ast.Raise", "path": "library/ast#ast.Raise", "type": "Language", "text": "\nA `raise` statement. `exc` is the exception object to be raised, normally a\n`Call` or `Name`, or `None` for a standalone `raise`. `cause` is the optional\npart for `y` in `raise x from y`.\n\n"}, {"name": "ast.Return", "path": "library/ast#ast.Return", "type": "Language", "text": "\nA `return` statement.\n\n"}, {"name": "ast.RShift", "path": "library/ast#ast.RShift", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.Set", "path": "library/ast#ast.Set", "type": "Language", "text": "\nA set. `elts` holds a list of nodes representing the set\u2019s elements.\n\n"}, {"name": "ast.SetComp", "path": "library/ast#ast.SetComp", "type": "Language", "text": "\nList and set comprehensions, generator expressions, and dictionary\ncomprehensions. `elt` (or `key` and `value`) is a single node representing the\npart that will be evaluated for each item.\n\n`generators` is a list of `comprehension` nodes.\n\n"}, {"name": "ast.Slice", "path": "library/ast#ast.Slice", "type": "Language", "text": "\nRegular slicing (on the form `lower:upper` or `lower:upper:step`). Can occur\nonly inside the slice field of `Subscript`, either directly or as an element\nof `Tuple`.\n\n"}, {"name": "ast.Starred", "path": "library/ast#ast.Starred", "type": "Language", "text": "\nA `*var` variable reference. `value` holds the variable, typically a `Name`\nnode. This type must be used when building a `Call` node with `*args`.\n\n"}, {"name": "ast.Store", "path": "library/ast#ast.Store", "type": "Language", "text": "\nVariable references can be used to load the value of a variable, to assign a\nnew value to it, or to delete it. Variable references are given a context to\ndistinguish these cases.\n\n"}, {"name": "ast.Sub", "path": "library/ast#ast.Sub", "type": "Language", "text": "\nBinary operator tokens.\n\n"}, {"name": "ast.Subscript", "path": "library/ast#ast.Subscript", "type": "Language", "text": "\nA subscript, such as `l[1]`. `value` is the subscripted object (usually\nsequence or mapping). `slice` is an index, slice or key. It can be a `Tuple`\nand contain a `Slice`. `ctx` is `Load`, `Store` or `Del` according to the\naction performed with the subscript.\n\n"}, {"name": "ast.Try", "path": "library/ast#ast.Try", "type": "Language", "text": "\n`try` blocks. All attributes are list of nodes to execute, except for\n`handlers`, which is a list of `ExceptHandler` nodes.\n\n"}, {"name": "ast.Tuple", "path": "library/ast#ast.Tuple", "type": "Language", "text": "\nA list or tuple. `elts` holds a list of nodes representing the elements. `ctx`\nis `Store` if the container is an assignment target (i.e. `(x,y)=something`),\nand `Load` otherwise.\n\n"}, {"name": "ast.UAdd", "path": "library/ast#ast.UAdd", "type": "Language", "text": "\nUnary operator tokens. `Not` is the `not` keyword, `Invert` is the `~`\noperator.\n\n"}, {"name": "ast.UnaryOp", "path": "library/ast#ast.UnaryOp", "type": "Language", "text": "\nA unary operation. `op` is the operator, and `operand` any expression node.\n\n"}, {"name": "ast.unparse()", "path": "library/ast#ast.unparse", "type": "Language", "text": "\nUnparse an `ast.AST` object and generate a string with code that would produce\nan equivalent `ast.AST` object if parsed back with `ast.parse()`.\n\nWarning\n\nThe produced code string will not necessarily be equal to the original code\nthat generated the `ast.AST` object (without any compiler optimizations, such\nas constant tuples/frozensets).\n\nWarning\n\nTrying to unparse a highly complex expression would result with\n`RecursionError`.\n\nNew in version 3.9.\n\n"}, {"name": "ast.USub", "path": "library/ast#ast.USub", "type": "Language", "text": "\nUnary operator tokens. `Not` is the `not` keyword, `Invert` is the `~`\noperator.\n\n"}, {"name": "ast.walk()", "path": "library/ast#ast.walk", "type": "Language", "text": "\nRecursively yield all descendant nodes in the tree starting at node (including\nnode itself), in no specified order. This is useful if you only want to modify\nnodes in place and don\u2019t care about the context.\n\n"}, {"name": "ast.While", "path": "library/ast#ast.While", "type": "Language", "text": "\nA `while` loop. `test` holds the condition, such as a `Compare` node.\n\n"}, {"name": "ast.With", "path": "library/ast#ast.With", "type": "Language", "text": "\nA `with` block. `items` is a list of `withitem` nodes representing the context\nmanagers, and `body` is the indented block inside the context.\n\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.With.type_comment", "path": "library/ast#ast.With.type_comment", "type": "Language", "text": "\n`type_comment` is an optional string with the type annotation as a comment.\n\n"}, {"name": "ast.withitem", "path": "library/ast#ast.withitem", "type": "Language", "text": "\nA single context manager in a `with` block. `context_expr` is the context\nmanager, often a `Call` node. `optional_vars` is a `Name`, `Tuple` or `List`\nfor the `as foo` part, or `None` if that isn\u2019t used.\n\n"}, {"name": "ast.Yield", "path": "library/ast#ast.Yield", "type": "Language", "text": "\nA `yield` or `yield from` expression. Because these are expressions, they must\nbe wrapped in a `Expr` node if the value sent back is not used.\n\n"}, {"name": "ast.YieldFrom", "path": "library/ast#ast.YieldFrom", "type": "Language", "text": "\nA `yield` or `yield from` expression. Because these are expressions, they must\nbe wrapped in a `Expr` node if the value sent back is not used.\n\n"}, {"name": "asynchat", "path": "library/asynchat", "type": "Networking & Interprocess Communication", "text": "\nSource code: Lib/asynchat.py\n\nDeprecated since version 3.6: Please use `asyncio` instead.\n\nNote\n\nThis module exists for backwards compatibility only. For new code we recommend\nusing `asyncio`.\n\nThis module builds on the `asyncore` infrastructure, simplifying asynchronous\nclients and servers and making it easier to handle protocols whose elements\nare terminated by arbitrary strings, or are of variable length. `asynchat`\ndefines the abstract class `async_chat` that you subclass, providing\nimplementations of the `collect_incoming_data()` and `found_terminator()`\nmethods. It uses the same asynchronous loop as `asyncore`, and the two types\nof channel, `asyncore.dispatcher` and `asynchat.async_chat`, can freely be\nmixed in the channel map. Typically an `asyncore.dispatcher` server channel\ngenerates new `asynchat.async_chat` channel objects as it receives incoming\nconnection requests.\n\nThis class is an abstract subclass of `asyncore.dispatcher`. To make practical\nuse of the code you must subclass `async_chat`, providing meaningful\n`collect_incoming_data()` and `found_terminator()` methods. The\n`asyncore.dispatcher` methods can be used, although not all make sense in a\nmessage/response context.\n\nLike `asyncore.dispatcher`, `async_chat` defines a set of events that are\ngenerated by an analysis of socket conditions after a `select()` call. Once\nthe polling loop has been started the `async_chat` object\u2019s methods are called\nby the event-processing framework with no action on the part of the\nprogrammer.\n\nTwo class attributes can be modified, to improve performance, or possibly even\nto conserve memory.\n\nThe asynchronous input buffer size (default `4096`).\n\nThe asynchronous output buffer size (default `4096`).\n\nUnlike `asyncore.dispatcher`, `async_chat` allows you to define a FIFO queue\nof producers. A producer need have only one method, `more()`, which should\nreturn data to be transmitted on the channel. The producer indicates\nexhaustion (i.e. that it contains no more data) by having its `more()` method\nreturn the empty bytes object. At this point the `async_chat` object removes\nthe producer from the queue and starts using the next producer, if any. When\nthe producer queue is empty the `handle_write()` method does nothing. You use\nthe channel object\u2019s `set_terminator()` method to describe how to recognize\nthe end of, or an important breakpoint in, an incoming transmission from the\nremote endpoint.\n\nTo build a functioning `async_chat` subclass your input methods\n`collect_incoming_data()` and `found_terminator()` must handle the data that\nthe channel receives asynchronously. The methods are described below.\n\nPushes a `None` on to the producer queue. When this producer is popped off the\nqueue it causes the channel to be closed.\n\nCalled with data holding an arbitrary amount of received data. The default\nmethod, which must be overridden, raises a `NotImplementedError` exception.\n\nIn emergencies this method will discard any data held in the input and/or\noutput buffers and the producer queue.\n\nCalled when the incoming data stream matches the termination condition set by\n`set_terminator()`. The default method, which must be overridden, raises a\n`NotImplementedError` exception. The buffered input data should be available\nvia an instance attribute.\n\nReturns the current terminator for the channel.\n\nPushes data on to the channel\u2019s queue to ensure its transmission. This is all\nyou need to do to have the channel write the data out to the network, although\nit is possible to use your own producers in more complex schemes to implement\nencryption and chunking, for example.\n\nTakes a producer object and adds it to the producer queue associated with the\nchannel. When all currently-pushed producers have been exhausted the channel\nwill consume this producer\u2019s data by calling its `more()` method and send the\ndata to the remote endpoint.\n\nSets the terminating condition to be recognized on the channel. `term` may be\nany of three types of value, corresponding to three different ways to handle\nincoming protocol data.\n\nterm\n\nDescription\n\nstring\n\nWill call `found_terminator()` when the string is found in the input stream\n\ninteger\n\nWill call `found_terminator()` when the indicated number of characters have\nbeen received\n\n`None`\n\nThe channel continues to collect data forever\n\nNote that any data following the terminator will be available for reading by\nthe channel after `found_terminator()` is called.\n\nThe following partial example shows how HTTP requests can be read with\n`async_chat`. A web server might create an `http_request_handler` object for\neach incoming client connection. Notice that initially the channel terminator\nis set to match the blank line at the end of the HTTP headers, and a flag\nindicates that the headers are being read.\n\nOnce the headers have been read, if the request is of type POST (indicating\nthat further data are present in the input stream) then the `Content-Length:`\nheader is used to set a numeric terminator to read the right amount of data\nfrom the channel.\n\nThe `handle_request()` method is called once all relevant input has been\nmarshalled, after setting the channel terminator to `None` to ensure that any\nextraneous data sent by the web client are ignored.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat", "path": "library/asynchat#asynchat.async_chat", "type": "Networking & Interprocess Communication", "text": "\nThis class is an abstract subclass of `asyncore.dispatcher`. To make practical\nuse of the code you must subclass `async_chat`, providing meaningful\n`collect_incoming_data()` and `found_terminator()` methods. The\n`asyncore.dispatcher` methods can be used, although not all make sense in a\nmessage/response context.\n\nLike `asyncore.dispatcher`, `async_chat` defines a set of events that are\ngenerated by an analysis of socket conditions after a `select()` call. Once\nthe polling loop has been started the `async_chat` object\u2019s methods are called\nby the event-processing framework with no action on the part of the\nprogrammer.\n\nTwo class attributes can be modified, to improve performance, or possibly even\nto conserve memory.\n\nThe asynchronous input buffer size (default `4096`).\n\nThe asynchronous output buffer size (default `4096`).\n\nUnlike `asyncore.dispatcher`, `async_chat` allows you to define a FIFO queue\nof producers. A producer need have only one method, `more()`, which should\nreturn data to be transmitted on the channel. The producer indicates\nexhaustion (i.e. that it contains no more data) by having its `more()` method\nreturn the empty bytes object. At this point the `async_chat` object removes\nthe producer from the queue and starts using the next producer, if any. When\nthe producer queue is empty the `handle_write()` method does nothing. You use\nthe channel object\u2019s `set_terminator()` method to describe how to recognize\nthe end of, or an important breakpoint in, an incoming transmission from the\nremote endpoint.\n\nTo build a functioning `async_chat` subclass your input methods\n`collect_incoming_data()` and `found_terminator()` must handle the data that\nthe channel receives asynchronously. The methods are described below.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.ac_in_buffer_size", "path": "library/asynchat#asynchat.async_chat.ac_in_buffer_size", "type": "Networking & Interprocess Communication", "text": "\nThe asynchronous input buffer size (default `4096`).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.ac_out_buffer_size", "path": "library/asynchat#asynchat.async_chat.ac_out_buffer_size", "type": "Networking & Interprocess Communication", "text": "\nThe asynchronous output buffer size (default `4096`).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.close_when_done()", "path": "library/asynchat#asynchat.async_chat.close_when_done", "type": "Networking & Interprocess Communication", "text": "\nPushes a `None` on to the producer queue. When this producer is popped off the\nqueue it causes the channel to be closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.collect_incoming_data()", "path": "library/asynchat#asynchat.async_chat.collect_incoming_data", "type": "Networking & Interprocess Communication", "text": "\nCalled with data holding an arbitrary amount of received data. The default\nmethod, which must be overridden, raises a `NotImplementedError` exception.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.discard_buffers()", "path": "library/asynchat#asynchat.async_chat.discard_buffers", "type": "Networking & Interprocess Communication", "text": "\nIn emergencies this method will discard any data held in the input and/or\noutput buffers and the producer queue.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.found_terminator()", "path": "library/asynchat#asynchat.async_chat.found_terminator", "type": "Networking & Interprocess Communication", "text": "\nCalled when the incoming data stream matches the termination condition set by\n`set_terminator()`. The default method, which must be overridden, raises a\n`NotImplementedError` exception. The buffered input data should be available\nvia an instance attribute.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.get_terminator()", "path": "library/asynchat#asynchat.async_chat.get_terminator", "type": "Networking & Interprocess Communication", "text": "\nReturns the current terminator for the channel.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.push()", "path": "library/asynchat#asynchat.async_chat.push", "type": "Networking & Interprocess Communication", "text": "\nPushes data on to the channel\u2019s queue to ensure its transmission. This is all\nyou need to do to have the channel write the data out to the network, although\nit is possible to use your own producers in more complex schemes to implement\nencryption and chunking, for example.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.push_with_producer()", "path": "library/asynchat#asynchat.async_chat.push_with_producer", "type": "Networking & Interprocess Communication", "text": "\nTakes a producer object and adds it to the producer queue associated with the\nchannel. When all currently-pushed producers have been exhausted the channel\nwill consume this producer\u2019s data by calling its `more()` method and send the\ndata to the remote endpoint.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asynchat.async_chat.set_terminator()", "path": "library/asynchat#asynchat.async_chat.set_terminator", "type": "Networking & Interprocess Communication", "text": "\nSets the terminating condition to be recognized on the channel. `term` may be\nany of three types of value, corresponding to three different ways to handle\nincoming protocol data.\n\nterm\n\nDescription\n\nstring\n\nWill call `found_terminator()` when the string is found in the input stream\n\ninteger\n\nWill call `found_terminator()` when the indicated number of characters have\nbeen received\n\n`None`\n\nThe channel continues to collect data forever\n\nNote that any data following the terminator will be available for reading by\nthe channel after `found_terminator()` is called.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio", "path": "library/asyncio", "type": "Asynchronous I/O", "text": "\nHello World!\n\nasyncio is a library to write concurrent code using the async/await syntax.\n\nasyncio is used as a foundation for multiple Python asynchronous frameworks\nthat provide high-performance network and web-servers, database connection\nlibraries, distributed task queues, etc.\n\nasyncio is often a perfect fit for IO-bound and high-level structured network\ncode.\n\nasyncio provides a set of high-level APIs to:\n\nAdditionally, there are low-level APIs for library and framework developers\nto:\n\nHigh-level APIs\n\nLow-level APIs\n\nGuides and Tutorials\n\nNote\n\nThe source code for asyncio can be found in Lib/asyncio/.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractChildWatcher", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher", "type": "Asynchronous I/O", "text": "\nRegister a new child handler.\n\nArrange for `callback(pid, returncode, *args)` to be called when a process\nwith PID equal to pid terminates. Specifying another callback for the same\nprocess replaces the previous handler.\n\nThe callback callable must be thread-safe.\n\nRemoves the handler for process with PID equal to pid.\n\nThe function returns `True` if the handler was successfully removed, `False`\nif there was nothing to remove.\n\nAttach the watcher to an event loop.\n\nIf the watcher was previously attached to an event loop, then it is first\ndetached before attaching to the new loop.\n\nNote: loop may be `None`.\n\nReturn `True` if the watcher is ready to use.\n\nSpawning a subprocess with inactive current child watcher raises\n`RuntimeError`.\n\nNew in version 3.8.\n\nClose the watcher.\n\nThis method has to be called to ensure that underlying resources are cleaned-\nup.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractChildWatcher.add_child_handler()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.add_child_handler", "type": "Asynchronous I/O", "text": "\nRegister a new child handler.\n\nArrange for `callback(pid, returncode, *args)` to be called when a process\nwith PID equal to pid terminates. Specifying another callback for the same\nprocess replaces the previous handler.\n\nThe callback callable must be thread-safe.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractChildWatcher.attach_loop()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.attach_loop", "type": "Asynchronous I/O", "text": "\nAttach the watcher to an event loop.\n\nIf the watcher was previously attached to an event loop, then it is first\ndetached before attaching to the new loop.\n\nNote: loop may be `None`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractChildWatcher.close()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.close", "type": "Asynchronous I/O", "text": "\nClose the watcher.\n\nThis method has to be called to ensure that underlying resources are cleaned-\nup.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractChildWatcher.is_active()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.is_active", "type": "Asynchronous I/O", "text": "\nReturn `True` if the watcher is ready to use.\n\nSpawning a subprocess with inactive current child watcher raises\n`RuntimeError`.\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractChildWatcher.remove_child_handler()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.remove_child_handler", "type": "Asynchronous I/O", "text": "\nRemoves the handler for process with PID equal to pid.\n\nThe function returns `True` if the handler was successfully removed, `False`\nif there was nothing to remove.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractEventLoop", "path": "library/asyncio-eventloop#asyncio.AbstractEventLoop", "type": "Asynchronous I/O", "text": "\nAbstract base class for asyncio-compliant event loops.\n\nThe Event Loop Methods section lists all methods that an alternative\nimplementation of `AbstractEventLoop` should have defined.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractEventLoopPolicy", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy", "type": "Asynchronous I/O", "text": "\nAn abstract base class for asyncio policies.\n\nGet the event loop for the current context.\n\nReturn an event loop object implementing the `AbstractEventLoop` interface.\n\nThis method should never return `None`.\n\nChanged in version 3.6.\n\nSet the event loop for the current context to loop.\n\nCreate and return a new event loop object.\n\nThis method should never return `None`.\n\nGet a child process watcher object.\n\nReturn a watcher object implementing the `AbstractChildWatcher` interface.\n\nThis function is Unix specific.\n\nSet the current child process watcher to watcher.\n\nThis function is Unix specific.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractEventLoopPolicy.get_child_watcher()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.get_child_watcher", "type": "Asynchronous I/O", "text": "\nGet a child process watcher object.\n\nReturn a watcher object implementing the `AbstractChildWatcher` interface.\n\nThis function is Unix specific.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractEventLoopPolicy.get_event_loop()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.get_event_loop", "type": "Asynchronous I/O", "text": "\nGet the event loop for the current context.\n\nReturn an event loop object implementing the `AbstractEventLoop` interface.\n\nThis method should never return `None`.\n\nChanged in version 3.6.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractEventLoopPolicy.new_event_loop()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.new_event_loop", "type": "Asynchronous I/O", "text": "\nCreate and return a new event loop object.\n\nThis method should never return `None`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractEventLoopPolicy.set_child_watcher()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.set_child_watcher", "type": "Asynchronous I/O", "text": "\nSet the current child process watcher to watcher.\n\nThis function is Unix specific.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.AbstractEventLoopPolicy.set_event_loop()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.set_event_loop", "type": "Asynchronous I/O", "text": "\nSet the event loop for the current context to loop.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.all_tasks()", "path": "library/asyncio-task#asyncio.all_tasks", "type": "Asynchronous I/O", "text": "\nReturn a set of not yet finished `Task` objects run by the loop.\n\nIf loop is `None`, `get_running_loop()` is used for getting current loop.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.DEVNULL", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.DEVNULL", "type": "Asynchronous I/O", "text": "\nSpecial value that can be used as the stdin, stdout or stderr argument to\nprocess creation functions. It indicates that the special file `os.devnull`\nwill be used for the corresponding subprocess stream.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.PIPE", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.PIPE", "type": "Asynchronous I/O", "text": "\nCan be passed to the stdin, stdout or stderr parameters.\n\nIf PIPE is passed to stdin argument, the `Process.stdin` attribute will point\nto a `StreamWriter` instance.\n\nIf PIPE is passed to stdout or stderr arguments, the `Process.stdout` and\n`Process.stderr` attributes will point to `StreamReader` instances.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process", "type": "Asynchronous I/O", "text": "\nAn object that wraps OS processes created by the `create_subprocess_exec()`\nand `create_subprocess_shell()` functions.\n\nThis class is designed to have a similar API to the `subprocess.Popen` class,\nbut there are some notable differences:\n\nThis class is not thread safe.\n\nSee also the Subprocess and Threads section.\n\nWait for the child process to terminate.\n\nSet and return the `returncode` attribute.\n\nNote\n\nThis method can deadlock when using `stdout=PIPE` or `stderr=PIPE` and the\nchild process generates so much output that it blocks waiting for the OS pipe\nbuffer to accept more data. Use the `communicate()` method when using pipes to\navoid this condition.\n\nInteract with process:\n\nThe optional input argument is the data (`bytes` object) that will be sent to\nthe child process.\n\nReturn a tuple `(stdout_data, stderr_data)`.\n\nIf either `BrokenPipeError` or `ConnectionResetError` exception is raised when\nwriting input into stdin, the exception is ignored. This condition occurs when\nthe process exits before all data are written into stdin.\n\nIf it is desired to send data to the process\u2019 stdin, the process needs to be\ncreated with `stdin=PIPE`. Similarly, to get anything other than `None` in the\nresult tuple, the process has to be created with `stdout=PIPE` and/or\n`stderr=PIPE` arguments.\n\nNote, that the data read is buffered in memory, so do not use this method if\nthe data size is large or unlimited.\n\nSends the signal signal to the child process.\n\nNote\n\nOn Windows, `SIGTERM` is an alias for `terminate()`. `CTRL_C_EVENT` and\n`CTRL_BREAK_EVENT` can be sent to processes started with a creationflags\nparameter which includes `CREATE_NEW_PROCESS_GROUP`.\n\nStop the child process.\n\nOn POSIX systems this method sends `signal.SIGTERM` to the child process.\n\nOn Windows the Win32 API function `TerminateProcess()` is called to stop the\nchild process.\n\nKill the child process.\n\nOn POSIX systems this method sends `SIGKILL` to the child process.\n\nOn Windows this method is an alias for `terminate()`.\n\nStandard input stream (`StreamWriter`) or `None` if the process was created\nwith `stdin=None`.\n\nStandard output stream (`StreamReader`) or `None` if the process was created\nwith `stdout=None`.\n\nStandard error stream (`StreamReader`) or `None` if the process was created\nwith `stderr=None`.\n\nWarning\n\nUse the `communicate()` method rather than `process.stdin.write()`, `await\nprocess.stdout.read()` or `await process.stderr.read`. This avoids deadlocks\ndue to streams pausing reading or writing and blocking the child process.\n\nProcess identification number (PID).\n\nNote that for processes created by the `create_subprocess_shell()` function,\nthis attribute is the PID of the spawned shell.\n\nReturn code of the process when it exits.\n\nA `None` value indicates that the process has not terminated yet.\n\nA negative value `-N` indicates that the child was terminated by signal `N`\n(POSIX only).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.communicate()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.communicate", "type": "Asynchronous I/O", "text": "\nInteract with process:\n\nThe optional input argument is the data (`bytes` object) that will be sent to\nthe child process.\n\nReturn a tuple `(stdout_data, stderr_data)`.\n\nIf either `BrokenPipeError` or `ConnectionResetError` exception is raised when\nwriting input into stdin, the exception is ignored. This condition occurs when\nthe process exits before all data are written into stdin.\n\nIf it is desired to send data to the process\u2019 stdin, the process needs to be\ncreated with `stdin=PIPE`. Similarly, to get anything other than `None` in the\nresult tuple, the process has to be created with `stdout=PIPE` and/or\n`stderr=PIPE` arguments.\n\nNote, that the data read is buffered in memory, so do not use this method if\nthe data size is large or unlimited.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.kill()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.kill", "type": "Asynchronous I/O", "text": "\nKill the child process.\n\nOn POSIX systems this method sends `SIGKILL` to the child process.\n\nOn Windows this method is an alias for `terminate()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.pid", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.pid", "type": "Asynchronous I/O", "text": "\nProcess identification number (PID).\n\nNote that for processes created by the `create_subprocess_shell()` function,\nthis attribute is the PID of the spawned shell.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.returncode", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.returncode", "type": "Asynchronous I/O", "text": "\nReturn code of the process when it exits.\n\nA `None` value indicates that the process has not terminated yet.\n\nA negative value `-N` indicates that the child was terminated by signal `N`\n(POSIX only).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.send_signal()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.send_signal", "type": "Asynchronous I/O", "text": "\nSends the signal signal to the child process.\n\nNote\n\nOn Windows, `SIGTERM` is an alias for `terminate()`. `CTRL_C_EVENT` and\n`CTRL_BREAK_EVENT` can be sent to processes started with a creationflags\nparameter which includes `CREATE_NEW_PROCESS_GROUP`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.stderr", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.stderr", "type": "Asynchronous I/O", "text": "\nStandard error stream (`StreamReader`) or `None` if the process was created\nwith `stderr=None`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.stdin", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.stdin", "type": "Asynchronous I/O", "text": "\nStandard input stream (`StreamWriter`) or `None` if the process was created\nwith `stdin=None`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.stdout", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.stdout", "type": "Asynchronous I/O", "text": "\nStandard output stream (`StreamReader`) or `None` if the process was created\nwith `stdout=None`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.terminate()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.terminate", "type": "Asynchronous I/O", "text": "\nStop the child process.\n\nOn POSIX systems this method sends `signal.SIGTERM` to the child process.\n\nOn Windows the Win32 API function `TerminateProcess()` is called to stop the\nchild process.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.Process.wait()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.wait", "type": "Asynchronous I/O", "text": "\nWait for the child process to terminate.\n\nSet and return the `returncode` attribute.\n\nNote\n\nThis method can deadlock when using `stdout=PIPE` or `stderr=PIPE` and the\nchild process generates so much output that it blocks waiting for the OS pipe\nbuffer to accept more data. Use the `communicate()` method when using pipes to\navoid this condition.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.asyncio.subprocess.STDOUT", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.STDOUT", "type": "Asynchronous I/O", "text": "\nSpecial value that can be used as the stderr argument and indicates that\nstandard error should be redirected into standard output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.as_completed()", "path": "library/asyncio-task#asyncio.as_completed", "type": "Asynchronous I/O", "text": "\nRun awaitable objects in the aws iterable concurrently. Return an iterator of\ncoroutines. Each coroutine returned can be awaited to get the earliest next\nresult from the iterable of the remaining awaitables.\n\nRaises `asyncio.TimeoutError` if the timeout occurs before all Futures are\ndone.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseProtocol", "path": "library/asyncio-protocol#asyncio.BaseProtocol", "type": "Asynchronous I/O", "text": "\nBase protocol with methods that all protocols share.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseProtocol.connection_lost()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.connection_lost", "type": "Asynchronous I/O", "text": "\nCalled when the connection is lost or closed.\n\nThe argument is either an exception object or `None`. The latter means a\nregular EOF is received, or the connection was aborted or closed by this side\nof the connection.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseProtocol.connection_made()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.connection_made", "type": "Asynchronous I/O", "text": "\nCalled when a connection is made.\n\nThe transport argument is the transport representing the connection. The\nprotocol is responsible for storing the reference to its transport.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseProtocol.pause_writing()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.pause_writing", "type": "Asynchronous I/O", "text": "\nCalled when the transport\u2019s buffer goes over the high watermark.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseProtocol.resume_writing()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.resume_writing", "type": "Asynchronous I/O", "text": "\nCalled when the transport\u2019s buffer drains below the low watermark.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseTransport", "path": "library/asyncio-protocol#asyncio.BaseTransport", "type": "Asynchronous I/O", "text": "\nBase class for all transports. Contains methods that all asyncio transports\nshare.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseTransport.close()", "path": "library/asyncio-protocol#asyncio.BaseTransport.close", "type": "Asynchronous I/O", "text": "\nClose the transport.\n\nIf the transport has a buffer for outgoing data, buffered data will be flushed\nasynchronously. No more data will be received. After all buffered data is\nflushed, the protocol\u2019s `protocol.connection_lost()` method will be called\nwith `None` as its argument.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseTransport.get_extra_info()", "path": "library/asyncio-protocol#asyncio.BaseTransport.get_extra_info", "type": "Asynchronous I/O", "text": "\nReturn information about the transport or underlying resources it uses.\n\nname is a string representing the piece of transport-specific information to\nget.\n\ndefault is the value to return if the information is not available, or if the\ntransport does not support querying it with the given third-party event loop\nimplementation or on the current platform.\n\nFor example, the following code attempts to get the underlying socket object\nof the transport:\n\nCategories of information that can be queried on some transports:\n\nsocket:\n\nSSL socket:\n\npipe:\n\nsubprocess:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseTransport.get_protocol()", "path": "library/asyncio-protocol#asyncio.BaseTransport.get_protocol", "type": "Asynchronous I/O", "text": "\nReturn the current protocol.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseTransport.is_closing()", "path": "library/asyncio-protocol#asyncio.BaseTransport.is_closing", "type": "Asynchronous I/O", "text": "\nReturn `True` if the transport is closing or is closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BaseTransport.set_protocol()", "path": "library/asyncio-protocol#asyncio.BaseTransport.set_protocol", "type": "Asynchronous I/O", "text": "\nSet a new protocol.\n\nSwitching protocol should only be done when both protocols are documented to\nsupport the switch.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BoundedSemaphore", "path": "library/asyncio-sync#asyncio.BoundedSemaphore", "type": "Asynchronous I/O", "text": "\nA bounded semaphore object. Not thread-safe.\n\nBounded Semaphore is a version of `Semaphore` that raises a `ValueError` in\n`release()` if it increases the internal counter above the initial value.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BufferedProtocol", "path": "library/asyncio-protocol#asyncio.BufferedProtocol", "type": "Asynchronous I/O", "text": "\nA base class for implementing streaming protocols with manual control of the\nreceive buffer.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BufferedProtocol.buffer_updated()", "path": "library/asyncio-protocol#asyncio.BufferedProtocol.buffer_updated", "type": "Asynchronous I/O", "text": "\nCalled when the buffer was updated with the received data.\n\nnbytes is the total number of bytes that were written to the buffer.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BufferedProtocol.eof_received()", "path": "library/asyncio-protocol#asyncio.BufferedProtocol.eof_received", "type": "Asynchronous I/O", "text": "\nSee the documentation of the `protocol.eof_received()` method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.BufferedProtocol.get_buffer()", "path": "library/asyncio-protocol#asyncio.BufferedProtocol.get_buffer", "type": "Asynchronous I/O", "text": "\nCalled to allocate a new receive buffer.\n\nsizehint is the recommended minimum size for the returned buffer. It is\nacceptable to return smaller or larger buffers than what sizehint suggests.\nWhen set to -1, the buffer size can be arbitrary. It is an error to return a\nbuffer with a zero size.\n\n`get_buffer()` must return an object implementing the buffer protocol.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.CancelledError", "path": "library/asyncio-exceptions#asyncio.CancelledError", "type": "Asynchronous I/O", "text": "\nThe operation has been cancelled.\n\nThis exception can be caught to perform custom operations when asyncio Tasks\nare cancelled. In almost all situations the exception must be re-raised.\n\nChanged in version 3.8: `CancelledError` is now a subclass of `BaseException`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition", "path": "library/asyncio-sync#asyncio.Condition", "type": "Asynchronous I/O", "text": "\nA Condition object. Not thread-safe.\n\nAn asyncio condition primitive can be used by a task to wait for some event to\nhappen and then get exclusive access to a shared resource.\n\nIn essence, a Condition object combines the functionality of an `Event` and a\n`Lock`. It is possible to have multiple Condition objects share one Lock,\nwhich allows coordinating exclusive access to a shared resource between\ndifferent tasks interested in particular states of that shared resource.\n\nThe optional lock argument must be a `Lock` object or `None`. In the latter\ncase a new Lock object is created automatically.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nThe preferred way to use a Condition is an `async with` statement:\n\nwhich is equivalent to:\n\nAcquire the underlying lock.\n\nThis method waits until the underlying lock is unlocked, sets it to locked and\nreturns `True`.\n\nWake up at most n tasks (1 by default) waiting on this condition. The method\nis no-op if no tasks are waiting.\n\nThe lock must be acquired before this method is called and released shortly\nafter. If called with an unlocked lock a `RuntimeError` error is raised.\n\nReturn `True` if the underlying lock is acquired.\n\nWake up all tasks waiting on this condition.\n\nThis method acts like `notify()`, but wakes up all waiting tasks.\n\nThe lock must be acquired before this method is called and released shortly\nafter. If called with an unlocked lock a `RuntimeError` error is raised.\n\nRelease the underlying lock.\n\nWhen invoked on an unlocked lock, a `RuntimeError` is raised.\n\nWait until notified.\n\nIf the calling task has not acquired the lock when this method is called, a\n`RuntimeError` is raised.\n\nThis method releases the underlying lock, and then blocks until it is awakened\nby a `notify()` or `notify_all()` call. Once awakened, the Condition re-\nacquires its lock and this method returns `True`.\n\nWait until a predicate becomes true.\n\nThe predicate must be a callable which result will be interpreted as a boolean\nvalue. The final value is the return value.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition.acquire()", "path": "library/asyncio-sync#asyncio.Condition.acquire", "type": "Asynchronous I/O", "text": "\nAcquire the underlying lock.\n\nThis method waits until the underlying lock is unlocked, sets it to locked and\nreturns `True`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition.locked()", "path": "library/asyncio-sync#asyncio.Condition.locked", "type": "Asynchronous I/O", "text": "\nReturn `True` if the underlying lock is acquired.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition.notify()", "path": "library/asyncio-sync#asyncio.Condition.notify", "type": "Asynchronous I/O", "text": "\nWake up at most n tasks (1 by default) waiting on this condition. The method\nis no-op if no tasks are waiting.\n\nThe lock must be acquired before this method is called and released shortly\nafter. If called with an unlocked lock a `RuntimeError` error is raised.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition.notify_all()", "path": "library/asyncio-sync#asyncio.Condition.notify_all", "type": "Asynchronous I/O", "text": "\nWake up all tasks waiting on this condition.\n\nThis method acts like `notify()`, but wakes up all waiting tasks.\n\nThe lock must be acquired before this method is called and released shortly\nafter. If called with an unlocked lock a `RuntimeError` error is raised.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition.release()", "path": "library/asyncio-sync#asyncio.Condition.release", "type": "Asynchronous I/O", "text": "\nRelease the underlying lock.\n\nWhen invoked on an unlocked lock, a `RuntimeError` is raised.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition.wait()", "path": "library/asyncio-sync#asyncio.Condition.wait", "type": "Asynchronous I/O", "text": "\nWait until notified.\n\nIf the calling task has not acquired the lock when this method is called, a\n`RuntimeError` is raised.\n\nThis method releases the underlying lock, and then blocks until it is awakened\nby a `notify()` or `notify_all()` call. Once awakened, the Condition re-\nacquires its lock and this method returns `True`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Condition.wait_for()", "path": "library/asyncio-sync#asyncio.Condition.wait_for", "type": "Asynchronous I/O", "text": "\nWait until a predicate becomes true.\n\nThe predicate must be a callable which result will be interpreted as a boolean\nvalue. The final value is the return value.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.coroutine()", "path": "library/asyncio-task#asyncio.coroutine", "type": "Asynchronous I/O", "text": "\nDecorator to mark generator-based coroutines.\n\nThis decorator enables legacy generator-based coroutines to be compatible with\nasync/await code:\n\nThis decorator should not be used for `async def` coroutines.\n\nDeprecated since version 3.8, will be removed in version 3.10: Use `async def`\ninstead.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.create_subprocess_exec()", "path": "library/asyncio-subprocess#asyncio.create_subprocess_exec", "type": "Asynchronous I/O", "text": "\nCreate a subprocess.\n\nThe limit argument sets the buffer limit for `StreamReader` wrappers for\n`Process.stdout` and `Process.stderr` (if `subprocess.PIPE` is passed to\nstdout and stderr arguments).\n\nReturn a `Process` instance.\n\nSee the documentation of `loop.subprocess_exec()` for other parameters.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.create_subprocess_shell()", "path": "library/asyncio-subprocess#asyncio.create_subprocess_shell", "type": "Asynchronous I/O", "text": "\nRun the cmd shell command.\n\nThe limit argument sets the buffer limit for `StreamReader` wrappers for\n`Process.stdout` and `Process.stderr` (if `subprocess.PIPE` is passed to\nstdout and stderr arguments).\n\nReturn a `Process` instance.\n\nSee the documentation of `loop.subprocess_shell()` for other parameters.\n\nImportant\n\nIt is the application\u2019s responsibility to ensure that all whitespace and\nspecial characters are quoted appropriately to avoid shell injection\nvulnerabilities. The `shlex.quote()` function can be used to properly escape\nwhitespace and special shell characters in strings that are going to be used\nto construct shell commands.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.create_task()", "path": "library/asyncio-task#asyncio.create_task", "type": "Asynchronous I/O", "text": "\nWrap the coro coroutine into a `Task` and schedule its execution. Return the\nTask object.\n\nIf name is not `None`, it is set as the name of the task using\n`Task.set_name()`.\n\nThe task is executed in the loop returned by `get_running_loop()`,\n`RuntimeError` is raised if there is no running loop in current thread.\n\nThis function has been added in Python 3.7. Prior to Python 3.7, the low-level\n`asyncio.ensure_future()` function can be used instead:\n\nNew in version 3.7.\n\nChanged in version 3.8: Added the `name` parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.current_task()", "path": "library/asyncio-task#asyncio.current_task", "type": "Asynchronous I/O", "text": "\nReturn the currently running `Task` instance, or `None` if no task is running.\n\nIf loop is `None` `get_running_loop()` is used to get the current loop.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.DatagramProtocol", "path": "library/asyncio-protocol#asyncio.DatagramProtocol", "type": "Asynchronous I/O", "text": "\nThe base class for implementing datagram (UDP) protocols.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.DatagramProtocol.datagram_received()", "path": "library/asyncio-protocol#asyncio.DatagramProtocol.datagram_received", "type": "Asynchronous I/O", "text": "\nCalled when a datagram is received. data is a bytes object containing the\nincoming data. addr is the address of the peer sending the data; the exact\nformat depends on the transport.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.DatagramProtocol.error_received()", "path": "library/asyncio-protocol#asyncio.DatagramProtocol.error_received", "type": "Asynchronous I/O", "text": "\nCalled when a previous send or receive operation raises an `OSError`. exc is\nthe `OSError` instance.\n\nThis method is called in rare conditions, when the transport (e.g. UDP)\ndetects that a datagram could not be delivered to its recipient. In many\nconditions though, undeliverable datagrams will be silently dropped.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.DatagramTransport", "path": "library/asyncio-protocol#asyncio.DatagramTransport", "type": "Asynchronous I/O", "text": "\nA transport for datagram (UDP) connections.\n\nInstances of the DatagramTransport class are returned from the\n`loop.create_datagram_endpoint()` event loop method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.DatagramTransport.abort()", "path": "library/asyncio-protocol#asyncio.DatagramTransport.abort", "type": "Asynchronous I/O", "text": "\nClose the transport immediately, without waiting for pending operations to\ncomplete. Buffered data will be lost. No more data will be received. The\nprotocol\u2019s `protocol.connection_lost()` method will eventually be called with\n`None` as its argument.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.DatagramTransport.sendto()", "path": "library/asyncio-protocol#asyncio.DatagramTransport.sendto", "type": "Asynchronous I/O", "text": "\nSend the data bytes to the remote peer given by addr (a transport-dependent\ntarget address). If addr is `None`, the data is sent to the target address\ngiven on transport creation.\n\nThis method does not block; it buffers the data and arranges for it to be sent\nout asynchronously.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.DefaultEventLoopPolicy", "path": "library/asyncio-policy#asyncio.DefaultEventLoopPolicy", "type": "Asynchronous I/O", "text": "\nThe default asyncio policy. Uses `SelectorEventLoop` on Unix and\n`ProactorEventLoop` on Windows.\n\nThere is no need to install the default policy manually. asyncio is configured\nto use the default policy automatically.\n\nChanged in version 3.8: On Windows, `ProactorEventLoop` is now used by\ndefault.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.ensure_future()", "path": "library/asyncio-future#asyncio.ensure_future", "type": "Asynchronous I/O", "text": "\nReturn:\n\nIf obj is neither of the above a `TypeError` is raised.\n\nImportant\n\nSee also the `create_task()` function which is the preferred way for creating\nnew Tasks.\n\nChanged in version 3.5.1: The function accepts any awaitable object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Event", "path": "library/asyncio-sync#asyncio.Event", "type": "Asynchronous I/O", "text": "\nAn event object. Not thread-safe.\n\nAn asyncio event can be used to notify multiple asyncio tasks that some event\nhas happened.\n\nAn Event object manages an internal flag that can be set to true with the\n`set()` method and reset to false with the `clear()` method. The `wait()`\nmethod blocks until the flag is set to true. The flag is set to false\ninitially.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample:\n\nWait until the event is set.\n\nIf the event is set, return `True` immediately. Otherwise block until another\ntask calls `set()`.\n\nSet the event.\n\nAll tasks waiting for event to be set will be immediately awakened.\n\nClear (unset) the event.\n\nTasks awaiting on `wait()` will now block until the `set()` method is called\nagain.\n\nReturn `True` if the event is set.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Event.clear()", "path": "library/asyncio-sync#asyncio.Event.clear", "type": "Asynchronous I/O", "text": "\nClear (unset) the event.\n\nTasks awaiting on `wait()` will now block until the `set()` method is called\nagain.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Event.is_set()", "path": "library/asyncio-sync#asyncio.Event.is_set", "type": "Asynchronous I/O", "text": "\nReturn `True` if the event is set.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Event.set()", "path": "library/asyncio-sync#asyncio.Event.set", "type": "Asynchronous I/O", "text": "\nSet the event.\n\nAll tasks waiting for event to be set will be immediately awakened.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Event.wait()", "path": "library/asyncio-sync#asyncio.Event.wait", "type": "Asynchronous I/O", "text": "\nWait until the event is set.\n\nIf the event is set, return `True` immediately. Otherwise block until another\ntask calls `set()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.FastChildWatcher", "path": "library/asyncio-policy#asyncio.FastChildWatcher", "type": "Asynchronous I/O", "text": "\nThis implementation reaps every terminated processes by calling\n`os.waitpid(-1)` directly, possibly breaking other code spawning processes and\nwaiting for their termination.\n\nThere is no noticeable overhead when handling a big number of children (O(1)\neach time a child terminates).\n\nThis solution requires a running event loop in the main thread to work, as\n`SafeChildWatcher`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future", "path": "library/asyncio-future#asyncio.Future", "type": "Asynchronous I/O", "text": "\nA Future represents an eventual result of an asynchronous operation. Not\nthread-safe.\n\nFuture is an awaitable object. Coroutines can await on Future objects until\nthey either have a result or an exception set, or until they are cancelled.\n\nTypically Futures are used to enable low-level callback-based code (e.g. in\nprotocols implemented using asyncio transports) to interoperate with high-\nlevel async/await code.\n\nThe rule of thumb is to never expose Future objects in user-facing APIs, and\nthe recommended way to create a Future object is to call\n`loop.create_future()`. This way alternative event loop implementations can\ninject their own optimized implementations of a Future object.\n\nChanged in version 3.7: Added support for the `contextvars` module.\n\nReturn the result of the Future.\n\nIf the Future is done and has a result set by the `set_result()` method, the\nresult value is returned.\n\nIf the Future is done and has an exception set by the `set_exception()`\nmethod, this method raises the exception.\n\nIf the Future has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Future\u2019s result isn\u2019t yet available, this method raises a\n`InvalidStateError` exception.\n\nMark the Future as done and set its result.\n\nRaises a `InvalidStateError` error if the Future is already done.\n\nMark the Future as done and set an exception.\n\nRaises a `InvalidStateError` error if the Future is already done.\n\nReturn `True` if the Future is done.\n\nA Future is done if it was cancelled or if it has a result or an exception set\nwith `set_result()` or `set_exception()` calls.\n\nReturn `True` if the Future was cancelled.\n\nThe method is usually used to check if a Future is not cancelled before\nsetting a result or an exception for it:\n\nAdd a callback to be run when the Future is done.\n\nThe callback is called with the Future object as its only argument.\n\nIf the Future is already done when this method is called, the callback is\nscheduled with `loop.call_soon()`.\n\nAn optional keyword-only context argument allows specifying a custom\n`contextvars.Context` for the callback to run in. The current context is used\nwhen no context is provided.\n\n`functools.partial()` can be used to pass parameters to the callback, e.g.:\n\nChanged in version 3.7: The context keyword-only parameter was added. See PEP\n567 for more details.\n\nRemove callback from the callbacks list.\n\nReturns the number of callbacks removed, which is typically 1, unless a\ncallback was added more than once.\n\nCancel the Future and schedule callbacks.\n\nIf the Future is already done or cancelled, return `False`. Otherwise, change\nthe Future\u2019s state to cancelled, schedule the callbacks, and return `True`.\n\nChanged in version 3.9: Added the `msg` parameter.\n\nReturn the exception that was set on this Future.\n\nThe exception (or `None` if no exception was set) is returned only if the\nFuture is done.\n\nIf the Future has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Future isn\u2019t done yet, this method raises an `InvalidStateError`\nexception.\n\nReturn the event loop the Future object is bound to.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.add_done_callback()", "path": "library/asyncio-future#asyncio.Future.add_done_callback", "type": "Asynchronous I/O", "text": "\nAdd a callback to be run when the Future is done.\n\nThe callback is called with the Future object as its only argument.\n\nIf the Future is already done when this method is called, the callback is\nscheduled with `loop.call_soon()`.\n\nAn optional keyword-only context argument allows specifying a custom\n`contextvars.Context` for the callback to run in. The current context is used\nwhen no context is provided.\n\n`functools.partial()` can be used to pass parameters to the callback, e.g.:\n\nChanged in version 3.7: The context keyword-only parameter was added. See PEP\n567 for more details.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.cancel()", "path": "library/asyncio-future#asyncio.Future.cancel", "type": "Asynchronous I/O", "text": "\nCancel the Future and schedule callbacks.\n\nIf the Future is already done or cancelled, return `False`. Otherwise, change\nthe Future\u2019s state to cancelled, schedule the callbacks, and return `True`.\n\nChanged in version 3.9: Added the `msg` parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.cancelled()", "path": "library/asyncio-future#asyncio.Future.cancelled", "type": "Asynchronous I/O", "text": "\nReturn `True` if the Future was cancelled.\n\nThe method is usually used to check if a Future is not cancelled before\nsetting a result or an exception for it:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.done()", "path": "library/asyncio-future#asyncio.Future.done", "type": "Asynchronous I/O", "text": "\nReturn `True` if the Future is done.\n\nA Future is done if it was cancelled or if it has a result or an exception set\nwith `set_result()` or `set_exception()` calls.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.exception()", "path": "library/asyncio-future#asyncio.Future.exception", "type": "Asynchronous I/O", "text": "\nReturn the exception that was set on this Future.\n\nThe exception (or `None` if no exception was set) is returned only if the\nFuture is done.\n\nIf the Future has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Future isn\u2019t done yet, this method raises an `InvalidStateError`\nexception.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.get_loop()", "path": "library/asyncio-future#asyncio.Future.get_loop", "type": "Asynchronous I/O", "text": "\nReturn the event loop the Future object is bound to.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.remove_done_callback()", "path": "library/asyncio-future#asyncio.Future.remove_done_callback", "type": "Asynchronous I/O", "text": "\nRemove callback from the callbacks list.\n\nReturns the number of callbacks removed, which is typically 1, unless a\ncallback was added more than once.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.result()", "path": "library/asyncio-future#asyncio.Future.result", "type": "Asynchronous I/O", "text": "\nReturn the result of the Future.\n\nIf the Future is done and has a result set by the `set_result()` method, the\nresult value is returned.\n\nIf the Future is done and has an exception set by the `set_exception()`\nmethod, this method raises the exception.\n\nIf the Future has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Future\u2019s result isn\u2019t yet available, this method raises a\n`InvalidStateError` exception.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.set_exception()", "path": "library/asyncio-future#asyncio.Future.set_exception", "type": "Asynchronous I/O", "text": "\nMark the Future as done and set an exception.\n\nRaises a `InvalidStateError` error if the Future is already done.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Future.set_result()", "path": "library/asyncio-future#asyncio.Future.set_result", "type": "Asynchronous I/O", "text": "\nMark the Future as done and set its result.\n\nRaises a `InvalidStateError` error if the Future is already done.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.gather()", "path": "library/asyncio-task#asyncio.gather", "type": "Asynchronous I/O", "text": "\nRun awaitable objects in the aws sequence concurrently.\n\nIf any awaitable in aws is a coroutine, it is automatically scheduled as a\nTask.\n\nIf all awaitables are completed successfully, the result is an aggregate list\nof returned values. The order of result values corresponds to the order of\nawaitables in aws.\n\nIf return_exceptions is `False` (default), the first raised exception is\nimmediately propagated to the task that awaits on `gather()`. Other awaitables\nin the aws sequence won\u2019t be cancelled and will continue to run.\n\nIf return_exceptions is `True`, exceptions are treated the same as successful\nresults, and aggregated in the result list.\n\nIf `gather()` is cancelled, all submitted awaitables (that have not completed\nyet) are also cancelled.\n\nIf any Task or Future from the aws sequence is cancelled, it is treated as if\nit raised `CancelledError` \u2013 the `gather()` call is not cancelled in this\ncase. This is to prevent the cancellation of one submitted Task/Future to\ncause other Tasks/Futures to be cancelled.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample:\n\nNote\n\nIf return_exceptions is False, cancelling gather() after it has been marked\ndone won\u2019t cancel any submitted awaitables. For instance, gather can be marked\ndone after propagating an exception to the caller, therefore, calling\n`gather.cancel()` after catching an exception (raised by one of the\nawaitables) from gather won\u2019t cancel any other awaitables.\n\nChanged in version 3.7: If the gather itself is cancelled, the cancellation is\npropagated regardless of return_exceptions.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.get_child_watcher()", "path": "library/asyncio-policy#asyncio.get_child_watcher", "type": "Asynchronous I/O", "text": "\nReturn the current child watcher for the current policy.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.get_event_loop()", "path": "library/asyncio-eventloop#asyncio.get_event_loop", "type": "Asynchronous I/O", "text": "\nGet the current event loop.\n\nIf there is no current event loop set in the current OS thread, the OS thread\nis main, and `set_event_loop()` has not yet been called, asyncio will create a\nnew event loop and set it as the current one.\n\nBecause this function has rather complex behavior (especially when custom\nevent loop policies are in use), using the `get_running_loop()` function is\npreferred to `get_event_loop()` in coroutines and callbacks.\n\nConsider also using the `asyncio.run()` function instead of using lower level\nfunctions to manually create and close an event loop.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.get_event_loop_policy()", "path": "library/asyncio-policy#asyncio.get_event_loop_policy", "type": "Asynchronous I/O", "text": "\nReturn the current process-wide policy.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.get_running_loop()", "path": "library/asyncio-eventloop#asyncio.get_running_loop", "type": "Asynchronous I/O", "text": "\nReturn the running event loop in the current OS thread.\n\nIf there is no running event loop a `RuntimeError` is raised. This function\ncan only be called from a coroutine or a callback.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Handle", "path": "library/asyncio-eventloop#asyncio.Handle", "type": "Asynchronous I/O", "text": "\nA callback wrapper object returned by `loop.call_soon()`,\n`loop.call_soon_threadsafe()`.\n\nCancel the callback. If the callback has already been canceled or executed,\nthis method has no effect.\n\nReturn `True` if the callback was cancelled.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Handle.cancel()", "path": "library/asyncio-eventloop#asyncio.Handle.cancel", "type": "Asynchronous I/O", "text": "\nCancel the callback. If the callback has already been canceled or executed,\nthis method has no effect.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Handle.cancelled()", "path": "library/asyncio-eventloop#asyncio.Handle.cancelled", "type": "Asynchronous I/O", "text": "\nReturn `True` if the callback was cancelled.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.IncompleteReadError", "path": "library/asyncio-exceptions#asyncio.IncompleteReadError", "type": "Asynchronous I/O", "text": "\nThe requested read operation did not complete fully.\n\nRaised by the asyncio stream APIs.\n\nThis exception is a subclass of `EOFError`.\n\nThe total number (`int`) of expected bytes.\n\nA string of `bytes` read before the end of stream was reached.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.IncompleteReadError.expected", "path": "library/asyncio-exceptions#asyncio.IncompleteReadError.expected", "type": "Asynchronous I/O", "text": "\nThe total number (`int`) of expected bytes.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.IncompleteReadError.partial", "path": "library/asyncio-exceptions#asyncio.IncompleteReadError.partial", "type": "Asynchronous I/O", "text": "\nA string of `bytes` read before the end of stream was reached.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.InvalidStateError", "path": "library/asyncio-exceptions#asyncio.InvalidStateError", "type": "Asynchronous I/O", "text": "\nInvalid internal state of `Task` or `Future`.\n\nCan be raised in situations like setting a result value for a Future object\nthat already has a result value set.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.iscoroutine()", "path": "library/asyncio-task#asyncio.iscoroutine", "type": "Asynchronous I/O", "text": "\nReturn `True` if obj is a coroutine object.\n\nThis method is different from `inspect.iscoroutine()` because it returns\n`True` for generator-based coroutines.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.iscoroutinefunction()", "path": "library/asyncio-task#asyncio.iscoroutinefunction", "type": "Asynchronous I/O", "text": "\nReturn `True` if func is a coroutine function.\n\nThis method is different from `inspect.iscoroutinefunction()` because it\nreturns `True` for generator-based coroutine functions decorated with\n`@coroutine`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.isfuture()", "path": "library/asyncio-future#asyncio.isfuture", "type": "Asynchronous I/O", "text": "\nReturn `True` if obj is either of:\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.LifoQueue", "path": "library/asyncio-queue#asyncio.LifoQueue", "type": "Asynchronous I/O", "text": "\nA variant of `Queue` that retrieves most recently added entries first (last\nin, first out).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.LimitOverrunError", "path": "library/asyncio-exceptions#asyncio.LimitOverrunError", "type": "Asynchronous I/O", "text": "\nReached the buffer size limit while looking for a separator.\n\nRaised by the asyncio stream APIs.\n\nThe total number of to be consumed bytes.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.LimitOverrunError.consumed", "path": "library/asyncio-exceptions#asyncio.LimitOverrunError.consumed", "type": "Asynchronous I/O", "text": "\nThe total number of to be consumed bytes.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Lock", "path": "library/asyncio-sync#asyncio.Lock", "type": "Asynchronous I/O", "text": "\nImplements a mutex lock for asyncio tasks. Not thread-safe.\n\nAn asyncio lock can be used to guarantee exclusive access to a shared\nresource.\n\nThe preferred way to use a Lock is an `async with` statement:\n\nwhich is equivalent to:\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nAcquire the lock.\n\nThis method waits until the lock is unlocked, sets it to locked and returns\n`True`.\n\nWhen more than one coroutine is blocked in `acquire()` waiting for the lock to\nbe unlocked, only one coroutine eventually proceeds.\n\nAcquiring a lock is fair: the coroutine that proceeds will be the first\ncoroutine that started waiting on the lock.\n\nRelease the lock.\n\nWhen the lock is locked, reset it to unlocked and return.\n\nIf the lock is unlocked, a `RuntimeError` is raised.\n\nReturn `True` if the lock is locked.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Lock.acquire()", "path": "library/asyncio-sync#asyncio.Lock.acquire", "type": "Asynchronous I/O", "text": "\nAcquire the lock.\n\nThis method waits until the lock is unlocked, sets it to locked and returns\n`True`.\n\nWhen more than one coroutine is blocked in `acquire()` waiting for the lock to\nbe unlocked, only one coroutine eventually proceeds.\n\nAcquiring a lock is fair: the coroutine that proceeds will be the first\ncoroutine that started waiting on the lock.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Lock.locked()", "path": "library/asyncio-sync#asyncio.Lock.locked", "type": "Asynchronous I/O", "text": "\nReturn `True` if the lock is locked.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Lock.release()", "path": "library/asyncio-sync#asyncio.Lock.release", "type": "Asynchronous I/O", "text": "\nRelease the lock.\n\nWhen the lock is locked, reset it to unlocked and return.\n\nIf the lock is unlocked, a `RuntimeError` is raised.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.add_reader()", "path": "library/asyncio-eventloop#asyncio.loop.add_reader", "type": "Asynchronous I/O", "text": "\nStart monitoring the fd file descriptor for read availability and invoke\ncallback with the specified arguments once fd is available for reading.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.add_signal_handler()", "path": "library/asyncio-eventloop#asyncio.loop.add_signal_handler", "type": "Asynchronous I/O", "text": "\nSet callback as the handler for the signum signal.\n\nThe callback will be invoked by loop, along with other queued callbacks and\nrunnable coroutines of that event loop. Unlike signal handlers registered\nusing `signal.signal()`, a callback registered with this function is allowed\nto interact with the event loop.\n\nRaise `ValueError` if the signal number is invalid or uncatchable. Raise\n`RuntimeError` if there is a problem setting up the handler.\n\nUse `functools.partial()` to pass keyword arguments to callback.\n\nLike `signal.signal()`, this function must be invoked in the main thread.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.add_writer()", "path": "library/asyncio-eventloop#asyncio.loop.add_writer", "type": "Asynchronous I/O", "text": "\nStart monitoring the fd file descriptor for write availability and invoke\ncallback with the specified arguments once fd is available for writing.\n\nUse `functools.partial()` to pass keyword arguments to callback.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.call_at()", "path": "library/asyncio-eventloop#asyncio.loop.call_at", "type": "Asynchronous I/O", "text": "\nSchedule callback to be called at the given absolute timestamp when (an int or\na float), using the same time reference as `loop.time()`.\n\nThis method\u2019s behavior is the same as `call_later()`.\n\nAn instance of `asyncio.TimerHandle` is returned which can be used to cancel\nthe callback.\n\nChanged in version 3.7: The context keyword-only parameter was added. See PEP\n567 for more details.\n\nChanged in version 3.8: In Python 3.7 and earlier with the default event loop\nimplementation, the difference between when and the current time could not\nexceed one day. This has been fixed in Python 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.call_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.call_exception_handler", "type": "Asynchronous I/O", "text": "\nCall the current event loop exception handler.\n\ncontext is a `dict` object containing the following keys (new keys may be\nintroduced in future Python versions):\n\nNote\n\nThis method should not be overloaded in subclassed event loops. For custom\nexception handling, use the `set_exception_handler()` method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.call_later()", "path": "library/asyncio-eventloop#asyncio.loop.call_later", "type": "Asynchronous I/O", "text": "\nSchedule callback to be called after the given delay number of seconds (can be\neither an int or a float).\n\nAn instance of `asyncio.TimerHandle` is returned which can be used to cancel\nthe callback.\n\ncallback will be called exactly once. If two callbacks are scheduled for\nexactly the same time, the order in which they are called is undefined.\n\nThe optional positional args will be passed to the callback when it is called.\nIf you want the callback to be called with keyword arguments use\n`functools.partial()`.\n\nAn optional keyword-only context argument allows specifying a custom\n`contextvars.Context` for the callback to run in. The current context is used\nwhen no context is provided.\n\nChanged in version 3.7: The context keyword-only parameter was added. See PEP\n567 for more details.\n\nChanged in version 3.8: In Python 3.7 and earlier with the default event loop\nimplementation, the delay could not exceed one day. This has been fixed in\nPython 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.call_soon()", "path": "library/asyncio-eventloop#asyncio.loop.call_soon", "type": "Asynchronous I/O", "text": "\nSchedule the callback callback to be called with args arguments at the next\niteration of the event loop.\n\nCallbacks are called in the order in which they are registered. Each callback\nwill be called exactly once.\n\nAn optional keyword-only context argument allows specifying a custom\n`contextvars.Context` for the callback to run in. The current context is used\nwhen no context is provided.\n\nAn instance of `asyncio.Handle` is returned, which can be used later to cancel\nthe callback.\n\nThis method is not thread-safe.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.call_soon_threadsafe()", "path": "library/asyncio-eventloop#asyncio.loop.call_soon_threadsafe", "type": "Asynchronous I/O", "text": "\nA thread-safe variant of `call_soon()`. Must be used to schedule callbacks\nfrom another thread.\n\nSee the concurrency and multithreading section of the documentation.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.close()", "path": "library/asyncio-eventloop#asyncio.loop.close", "type": "Asynchronous I/O", "text": "\nClose the event loop.\n\nThe loop must not be running when this function is called. Any pending\ncallbacks will be discarded.\n\nThis method clears all queues and shuts down the executor, but does not wait\nfor the executor to finish.\n\nThis method is idempotent and irreversible. No other methods should be called\nafter the event loop is closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.connect_accepted_socket()", "path": "library/asyncio-eventloop#asyncio.loop.connect_accepted_socket", "type": "Asynchronous I/O", "text": "\nWrap an already accepted connection into a transport/protocol pair.\n\nThis method can be used by servers that accept connections outside of asyncio\nbut that use asyncio to handle them.\n\nParameters:\n\nReturns a `(transport, protocol)` pair.\n\nNew in version 3.7: The ssl_handshake_timeout parameter.\n\nNew in version 3.5.3.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.connect_read_pipe()", "path": "library/asyncio-eventloop#asyncio.loop.connect_read_pipe", "type": "Asynchronous I/O", "text": "\nRegister the read end of pipe in the event loop.\n\nprotocol_factory must be a callable returning an asyncio protocol\nimplementation.\n\npipe is a file-like object.\n\nReturn pair `(transport, protocol)`, where transport supports the\n`ReadTransport` interface and protocol is an object instantiated by the\nprotocol_factory.\n\nWith `SelectorEventLoop` event loop, the pipe is set to non-blocking mode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.connect_write_pipe()", "path": "library/asyncio-eventloop#asyncio.loop.connect_write_pipe", "type": "Asynchronous I/O", "text": "\nRegister the write end of pipe in the event loop.\n\nprotocol_factory must be a callable returning an asyncio protocol\nimplementation.\n\npipe is file-like object.\n\nReturn pair `(transport, protocol)`, where transport supports `WriteTransport`\ninterface and protocol is an object instantiated by the protocol_factory.\n\nWith `SelectorEventLoop` event loop, the pipe is set to non-blocking mode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.create_connection()", "path": "library/asyncio-eventloop#asyncio.loop.create_connection", "type": "Asynchronous I/O", "text": "\nOpen a streaming transport connection to a given address specified by host and\nport.\n\nThe socket family can be either `AF_INET` or `AF_INET6` depending on host (or\nthe family argument, if provided).\n\nThe socket type will be `SOCK_STREAM`.\n\nprotocol_factory must be a callable returning an asyncio protocol\nimplementation.\n\nThis method will try to establish the connection in the background. When\nsuccessful, it returns a `(transport, protocol)` pair.\n\nThe chronological synopsis of the underlying operation is as follows:\n\nThe created transport is an implementation-dependent bidirectional stream.\n\nOther arguments:\n\nssl: if given and not false, a SSL/TLS transport is created (by default a\nplain TCP transport is created). If ssl is a `ssl.SSLContext` object, this\ncontext is used to create the transport; if ssl is `True`, a default context\nreturned from `ssl.create_default_context()` is used.\n\nSee also\n\nSSL/TLS security considerations\n\nNew in version 3.8: Added the happy_eyeballs_delay and interleave parameters.\n\nHappy Eyeballs Algorithm: Success with Dual-Stack Hosts. When a server\u2019s IPv4\npath and protocol are working, but the server\u2019s IPv6 path and protocol are not\nworking, a dual-stack client application experiences significant connection\ndelay compared to an IPv4-only client. This is undesirable because it causes\nthe dual- stack client to have a worse user experience. This document\nspecifies requirements for algorithms that reduce this user-visible delay and\nprovides an algorithm.\n\nFor more information: https://tools.ietf.org/html/rfc6555\n\nNew in version 3.7: The ssl_handshake_timeout parameter.\n\nChanged in version 3.6: The socket option `TCP_NODELAY` is set by default for\nall TCP connections.\n\nChanged in version 3.5: Added support for SSL/TLS in `ProactorEventLoop`.\n\nSee also\n\nThe `open_connection()` function is a high-level alternative API. It returns a\npair of (`StreamReader`, `StreamWriter`) that can be used directly in\nasync/await code.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.create_datagram_endpoint()", "path": "library/asyncio-eventloop#asyncio.loop.create_datagram_endpoint", "type": "Asynchronous I/O", "text": "\nNote\n\nThe parameter reuse_address is no longer supported, as using `SO_REUSEADDR`\nposes a significant security concern for UDP. Explicitly passing\n`reuse_address=True` will raise an exception.\n\nWhen multiple processes with differing UIDs assign sockets to an identical UDP\nsocket address with `SO_REUSEADDR`, incoming packets can become randomly\ndistributed among the sockets.\n\nFor supported platforms, reuse_port can be used as a replacement for similar\nfunctionality. With reuse_port, `SO_REUSEPORT` is used instead, which\nspecifically prevents processes with differing UIDs from assigning sockets to\nthe same socket address.\n\nCreate a datagram connection.\n\nThe socket family can be either `AF_INET`, `AF_INET6`, or `AF_UNIX`, depending\non host (or the family argument, if provided).\n\nThe socket type will be `SOCK_DGRAM`.\n\nprotocol_factory must be a callable returning a protocol implementation.\n\nA tuple of `(transport, protocol)` is returned on success.\n\nOther arguments:\n\nSee UDP echo client protocol and UDP echo server protocol examples.\n\nChanged in version 3.4.4: The family, proto, flags, reuse_address, reuse_port,\n*allow_broadcast, and sock parameters were added.\n\nChanged in version 3.8.1: The reuse_address parameter is no longer supported\ndue to security concerns.\n\nChanged in version 3.8: Added support for Windows.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.create_future()", "path": "library/asyncio-eventloop#asyncio.loop.create_future", "type": "Asynchronous I/O", "text": "\nCreate an `asyncio.Future` object attached to the event loop.\n\nThis is the preferred way to create Futures in asyncio. This lets third-party\nevent loops provide alternative implementations of the Future object (with\nbetter performance or instrumentation).\n\nNew in version 3.5.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.create_server()", "path": "library/asyncio-eventloop#asyncio.loop.create_server", "type": "Asynchronous I/O", "text": "\nCreate a TCP server (socket type `SOCK_STREAM`) listening on port of the host\naddress.\n\nReturns a `Server` object.\n\nArguments:\n\nThe host parameter can be set to several types which determine where the\nserver would be listening:\n\nNew in version 3.7: Added ssl_handshake_timeout and start_serving parameters.\n\nChanged in version 3.6: The socket option `TCP_NODELAY` is set by default for\nall TCP connections.\n\nChanged in version 3.5: Added support for SSL/TLS in `ProactorEventLoop`.\n\nChanged in version 3.5.1: The host parameter can be a sequence of strings.\n\nSee also\n\nThe `start_server()` function is a higher-level alternative API that returns a\npair of `StreamReader` and `StreamWriter` that can be used in an async/await\ncode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.create_task()", "path": "library/asyncio-eventloop#asyncio.loop.create_task", "type": "Asynchronous I/O", "text": "\nSchedule the execution of a Coroutines. Return a `Task` object.\n\nThird-party event loops can use their own subclass of `Task` for\ninteroperability. In this case, the result type is a subclass of `Task`.\n\nIf the name argument is provided and not `None`, it is set as the name of the\ntask using `Task.set_name()`.\n\nChanged in version 3.8: Added the `name` parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.create_unix_connection()", "path": "library/asyncio-eventloop#asyncio.loop.create_unix_connection", "type": "Asynchronous I/O", "text": "\nCreate a Unix connection.\n\nThe socket family will be `AF_UNIX`; socket type will be `SOCK_STREAM`.\n\nA tuple of `(transport, protocol)` is returned on success.\n\npath is the name of a Unix domain socket and is required, unless a sock\nparameter is specified. Abstract Unix sockets, `str`, `bytes`, and `Path`\npaths are supported.\n\nSee the documentation of the `loop.create_connection()` method for information\nabout arguments to this method.\n\nAvailability: Unix.\n\nNew in version 3.7: The ssl_handshake_timeout parameter.\n\nChanged in version 3.7: The path parameter can now be a path-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.create_unix_server()", "path": "library/asyncio-eventloop#asyncio.loop.create_unix_server", "type": "Asynchronous I/O", "text": "\nSimilar to `loop.create_server()` but works with the `AF_UNIX` socket family.\n\npath is the name of a Unix domain socket, and is required, unless a sock\nargument is provided. Abstract Unix sockets, `str`, `bytes`, and `Path` paths\nare supported.\n\nSee the documentation of the `loop.create_server()` method for information\nabout arguments to this method.\n\nAvailability: Unix.\n\nNew in version 3.7: The ssl_handshake_timeout and start_serving parameters.\n\nChanged in version 3.7: The path parameter can now be a `Path` object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.default_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.default_exception_handler", "type": "Asynchronous I/O", "text": "\nDefault exception handler.\n\nThis is called when an exception occurs and no exception handler is set. This\ncan be called by a custom exception handler that wants to defer to the default\nhandler behavior.\n\ncontext parameter has the same meaning as in `call_exception_handler()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.getaddrinfo()", "path": "library/asyncio-eventloop#asyncio.loop.getaddrinfo", "type": "Asynchronous I/O", "text": "\nAsynchronous version of `socket.getaddrinfo()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.getnameinfo()", "path": "library/asyncio-eventloop#asyncio.loop.getnameinfo", "type": "Asynchronous I/O", "text": "\nAsynchronous version of `socket.getnameinfo()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.get_debug()", "path": "library/asyncio-eventloop#asyncio.loop.get_debug", "type": "Asynchronous I/O", "text": "\nGet the debug mode (`bool`) of the event loop.\n\nThe default value is `True` if the environment variable `PYTHONASYNCIODEBUG`\nis set to a non-empty string, `False` otherwise.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.get_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.get_exception_handler", "type": "Asynchronous I/O", "text": "\nReturn the current exception handler, or `None` if no custom exception handler\nwas set.\n\nNew in version 3.5.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.get_task_factory()", "path": "library/asyncio-eventloop#asyncio.loop.get_task_factory", "type": "Asynchronous I/O", "text": "\nReturn a task factory or `None` if the default one is in use.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.is_closed()", "path": "library/asyncio-eventloop#asyncio.loop.is_closed", "type": "Asynchronous I/O", "text": "\nReturn `True` if the event loop was closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.is_running()", "path": "library/asyncio-eventloop#asyncio.loop.is_running", "type": "Asynchronous I/O", "text": "\nReturn `True` if the event loop is currently running.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.remove_reader()", "path": "library/asyncio-eventloop#asyncio.loop.remove_reader", "type": "Asynchronous I/O", "text": "\nStop monitoring the fd file descriptor for read availability.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.remove_signal_handler()", "path": "library/asyncio-eventloop#asyncio.loop.remove_signal_handler", "type": "Asynchronous I/O", "text": "\nRemove the handler for the sig signal.\n\nReturn `True` if the signal handler was removed, or `False` if no handler was\nset for the given signal.\n\nAvailability: Unix.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.remove_writer()", "path": "library/asyncio-eventloop#asyncio.loop.remove_writer", "type": "Asynchronous I/O", "text": "\nStop monitoring the fd file descriptor for write availability.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.run_forever()", "path": "library/asyncio-eventloop#asyncio.loop.run_forever", "type": "Asynchronous I/O", "text": "\nRun the event loop until `stop()` is called.\n\nIf `stop()` is called before `run_forever()` is called, the loop will poll the\nI/O selector once with a timeout of zero, run all callbacks scheduled in\nresponse to I/O events (and those that were already scheduled), and then exit.\n\nIf `stop()` is called while `run_forever()` is running, the loop will run the\ncurrent batch of callbacks and then exit. Note that new callbacks scheduled by\ncallbacks will not run in this case; instead, they will run the next time\n`run_forever()` or `run_until_complete()` is called.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.run_in_executor()", "path": "library/asyncio-eventloop#asyncio.loop.run_in_executor", "type": "Asynchronous I/O", "text": "\nArrange for func to be called in the specified executor.\n\nThe executor argument should be an `concurrent.futures.Executor` instance. The\ndefault executor is used if executor is `None`.\n\nExample:\n\nThis method returns a `asyncio.Future` object.\n\nUse `functools.partial()` to pass keyword arguments to func.\n\nChanged in version 3.5.3: `loop.run_in_executor()` no longer configures the\n`max_workers` of the thread pool executor it creates, instead leaving it up to\nthe thread pool executor (`ThreadPoolExecutor`) to set the default.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.run_until_complete()", "path": "library/asyncio-eventloop#asyncio.loop.run_until_complete", "type": "Asynchronous I/O", "text": "\nRun until the future (an instance of `Future`) has completed.\n\nIf the argument is a coroutine object it is implicitly scheduled to run as a\n`asyncio.Task`.\n\nReturn the Future\u2019s result or raise its exception.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.sendfile()", "path": "library/asyncio-eventloop#asyncio.loop.sendfile", "type": "Asynchronous I/O", "text": "\nSend a file over a transport. Return the total number of bytes sent.\n\nThe method uses high-performance `os.sendfile()` if available.\n\nfile must be a regular file object opened in binary mode.\n\noffset tells from where to start reading the file. If specified, count is the\ntotal number of bytes to transmit as opposed to sending the file until EOF is\nreached. File position is always updated, even when this method raises an\nerror, and `file.tell()` can be used to obtain the actual number of bytes\nsent.\n\nfallback set to `True` makes asyncio to manually read and send the file when\nthe platform does not support the sendfile system call (e.g. Windows or SSL\nsocket on Unix).\n\nRaise `SendfileNotAvailableError` if the system does not support the sendfile\nsyscall and fallback is `False`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.set_debug()", "path": "library/asyncio-eventloop#asyncio.loop.set_debug", "type": "Asynchronous I/O", "text": "\nSet the debug mode of the event loop.\n\nChanged in version 3.7: The new Python Development Mode can now also be used\nto enable the debug mode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.set_default_executor()", "path": "library/asyncio-eventloop#asyncio.loop.set_default_executor", "type": "Asynchronous I/O", "text": "\nSet executor as the default executor used by `run_in_executor()`. executor\nshould be an instance of `ThreadPoolExecutor`.\n\nDeprecated since version 3.8: Using an executor that is not an instance of\n`ThreadPoolExecutor` is deprecated and will trigger an error in Python 3.9.\n\nexecutor must be an instance of `concurrent.futures.ThreadPoolExecutor`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.set_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.set_exception_handler", "type": "Asynchronous I/O", "text": "\nSet handler as the new event loop exception handler.\n\nIf handler is `None`, the default exception handler will be set. Otherwise,\nhandler must be a callable with the signature matching `(loop, context)`,\nwhere `loop` is a reference to the active event loop, and `context` is a\n`dict` object containing the details of the exception (see\n`call_exception_handler()` documentation for details about context).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.set_task_factory()", "path": "library/asyncio-eventloop#asyncio.loop.set_task_factory", "type": "Asynchronous I/O", "text": "\nSet a task factory that will be used by `loop.create_task()`.\n\nIf factory is `None` the default task factory will be set. Otherwise, factory\nmust be a callable with the signature matching `(loop, coro)`, where loop is a\nreference to the active event loop, and coro is a coroutine object. The\ncallable must return a `asyncio.Future`-compatible object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.shutdown_asyncgens()", "path": "library/asyncio-eventloop#asyncio.loop.shutdown_asyncgens", "type": "Asynchronous I/O", "text": "\nSchedule all currently open asynchronous generator objects to close with an\n`aclose()` call. After calling this method, the event loop will issue a\nwarning if a new asynchronous generator is iterated. This should be used to\nreliably finalize all scheduled asynchronous generators.\n\nNote that there is no need to call this function when `asyncio.run()` is used.\n\nExample:\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.shutdown_default_executor()", "path": "library/asyncio-eventloop#asyncio.loop.shutdown_default_executor", "type": "Asynchronous I/O", "text": "\nSchedule the closure of the default executor and wait for it to join all of\nthe threads in the `ThreadPoolExecutor`. After calling this method, a\n`RuntimeError` will be raised if `loop.run_in_executor()` is called while\nusing the default executor.\n\nNote that there is no need to call this function when `asyncio.run()` is used.\n\nNew in version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.sock_accept()", "path": "library/asyncio-eventloop#asyncio.loop.sock_accept", "type": "Asynchronous I/O", "text": "\nAccept a connection. Modeled after the blocking `socket.accept()` method.\n\nThe socket must be bound to an address and listening for connections. The\nreturn value is a pair `(conn, address)` where conn is a new socket object\nusable to send and receive data on the connection, and address is the address\nbound to the socket on the other end of the connection.\n\nsock must be a non-blocking socket.\n\nChanged in version 3.7: Even though the method was always documented as a\ncoroutine method, before Python 3.7 it returned a `Future`. Since Python 3.7,\nthis is an `async def` method.\n\nSee also\n\n`loop.create_server()` and `start_server()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.sock_connect()", "path": "library/asyncio-eventloop#asyncio.loop.sock_connect", "type": "Asynchronous I/O", "text": "\nConnect sock to a remote socket at address.\n\nAsynchronous version of `socket.connect()`.\n\nsock must be a non-blocking socket.\n\nChanged in version 3.5.2: `address` no longer needs to be resolved.\n`sock_connect` will try to check if the address is already resolved by calling\n`socket.inet_pton()`. If not, `loop.getaddrinfo()` will be used to resolve the\naddress.\n\nSee also\n\n`loop.create_connection()` and `asyncio.open_connection()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.sock_recv()", "path": "library/asyncio-eventloop#asyncio.loop.sock_recv", "type": "Asynchronous I/O", "text": "\nReceive up to nbytes from sock. Asynchronous version of `socket.recv()`.\n\nReturn the received data as a bytes object.\n\nsock must be a non-blocking socket.\n\nChanged in version 3.7: Even though this method was always documented as a\ncoroutine method, releases before Python 3.7 returned a `Future`. Since Python\n3.7 this is an `async def` method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.sock_recv_into()", "path": "library/asyncio-eventloop#asyncio.loop.sock_recv_into", "type": "Asynchronous I/O", "text": "\nReceive data from sock into the buf buffer. Modeled after the blocking\n`socket.recv_into()` method.\n\nReturn the number of bytes written to the buffer.\n\nsock must be a non-blocking socket.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.sock_sendall()", "path": "library/asyncio-eventloop#asyncio.loop.sock_sendall", "type": "Asynchronous I/O", "text": "\nSend data to the sock socket. Asynchronous version of `socket.sendall()`.\n\nThis method continues to send to the socket until either all data in data has\nbeen sent or an error occurs. `None` is returned on success. On error, an\nexception is raised. Additionally, there is no way to determine how much data,\nif any, was successfully processed by the receiving end of the connection.\n\nsock must be a non-blocking socket.\n\nChanged in version 3.7: Even though the method was always documented as a\ncoroutine method, before Python 3.7 it returned an `Future`. Since Python 3.7,\nthis is an `async def` method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.sock_sendfile()", "path": "library/asyncio-eventloop#asyncio.loop.sock_sendfile", "type": "Asynchronous I/O", "text": "\nSend a file using high-performance `os.sendfile` if possible. Return the total\nnumber of bytes sent.\n\nAsynchronous version of `socket.sendfile()`.\n\nsock must be a non-blocking `socket.SOCK_STREAM` `socket`.\n\nfile must be a regular file object open in binary mode.\n\noffset tells from where to start reading the file. If specified, count is the\ntotal number of bytes to transmit as opposed to sending the file until EOF is\nreached. File position is always updated, even when this method raises an\nerror, and `file.tell()` can be used to obtain the actual number of bytes\nsent.\n\nfallback, when set to `True`, makes asyncio manually read and send the file\nwhen the platform does not support the sendfile syscall (e.g. Windows or SSL\nsocket on Unix).\n\nRaise `SendfileNotAvailableError` if the system does not support sendfile\nsyscall and fallback is `False`.\n\nsock must be a non-blocking socket.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.start_tls()", "path": "library/asyncio-eventloop#asyncio.loop.start_tls", "type": "Asynchronous I/O", "text": "\nUpgrade an existing transport-based connection to TLS.\n\nReturn a new transport instance, that the protocol must start using\nimmediately after the await. The transport instance passed to the start_tls\nmethod should never be used again.\n\nParameters:\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.stop()", "path": "library/asyncio-eventloop#asyncio.loop.stop", "type": "Asynchronous I/O", "text": "\nStop the event loop.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.subprocess_exec()", "path": "library/asyncio-eventloop#asyncio.loop.subprocess_exec", "type": "Asynchronous I/O", "text": "\nCreate a subprocess from one or more string arguments specified by args.\n\nargs must be a list of strings represented by:\n\nThe first string specifies the program executable, and the remaining strings\nspecify the arguments. Together, string arguments form the `argv` of the\nprogram.\n\nThis is similar to the standard library `subprocess.Popen` class called with\n`shell=False` and the list of strings passed as the first argument; however,\nwhere `Popen` takes a single argument which is list of strings,\nsubprocess_exec takes multiple string arguments.\n\nThe protocol_factory must be a callable returning a subclass of the\n`asyncio.SubprocessProtocol` class.\n\nOther parameters:\n\nstdin can be any of these:\n\nstdout can be any of these:\n\nstderr can be any of these:\n\nAll other keyword arguments are passed to `subprocess.Popen` without\ninterpretation, except for bufsize, universal_newlines, shell, text, encoding\nand errors, which should not be specified at all.\n\nThe `asyncio` subprocess API does not support decoding the streams as text.\n`bytes.decode()` can be used to convert the bytes returned from the stream to\ntext.\n\nSee the constructor of the `subprocess.Popen` class for documentation on other\narguments.\n\nReturns a pair of `(transport, protocol)`, where transport conforms to the\n`asyncio.SubprocessTransport` base class and protocol is an object\ninstantiated by the protocol_factory.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.subprocess_shell()", "path": "library/asyncio-eventloop#asyncio.loop.subprocess_shell", "type": "Asynchronous I/O", "text": "\nCreate a subprocess from cmd, which can be a `str` or a `bytes` string encoded\nto the filesystem encoding, using the platform\u2019s \u201cshell\u201d syntax.\n\nThis is similar to the standard library `subprocess.Popen` class called with\n`shell=True`.\n\nThe protocol_factory must be a callable returning a subclass of the\n`SubprocessProtocol` class.\n\nSee `subprocess_exec()` for more details about the remaining arguments.\n\nReturns a pair of `(transport, protocol)`, where transport conforms to the\n`SubprocessTransport` base class and protocol is an object instantiated by the\nprotocol_factory.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.loop.time()", "path": "library/asyncio-eventloop#asyncio.loop.time", "type": "Asynchronous I/O", "text": "\nReturn the current time, as a `float` value, according to the event loop\u2019s\ninternal monotonic clock.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.MultiLoopChildWatcher", "path": "library/asyncio-policy#asyncio.MultiLoopChildWatcher", "type": "Asynchronous I/O", "text": "\nThis implementation registers a `SIGCHLD` signal handler on instantiation.\nThat can break third-party code that installs a custom handler for `SIGCHLD`\nsignal.\n\nThe watcher avoids disrupting other code spawning processes by polling every\nprocess explicitly on a `SIGCHLD` signal.\n\nThere is no limitation for running subprocesses from different threads once\nthe watcher is installed.\n\nThe solution is safe but it has a significant overhead when handling a big\nnumber of processes (O(n) each time a `SIGCHLD` is received).\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.new_event_loop()", "path": "library/asyncio-eventloop#asyncio.new_event_loop", "type": "Asynchronous I/O", "text": "\nCreate a new event loop object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.open_connection()", "path": "library/asyncio-stream#asyncio.open_connection", "type": "Asynchronous I/O", "text": "\nEstablish a network connection and return a pair of `(reader, writer)`\nobjects.\n\nThe returned reader and writer objects are instances of `StreamReader` and\n`StreamWriter` classes.\n\nThe loop argument is optional and can always be determined automatically when\nthis function is awaited from a coroutine.\n\nlimit determines the buffer size limit used by the returned `StreamReader`\ninstance. By default the limit is set to 64 KiB.\n\nThe rest of the arguments are passed directly to `loop.create_connection()`.\n\nNew in version 3.7: The ssl_handshake_timeout parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.open_unix_connection()", "path": "library/asyncio-stream#asyncio.open_unix_connection", "type": "Asynchronous I/O", "text": "\nEstablish a Unix socket connection and return a pair of `(reader, writer)`.\n\nSimilar to `open_connection()` but operates on Unix sockets.\n\nSee also the documentation of `loop.create_unix_connection()`.\n\nAvailability: Unix.\n\nNew in version 3.7: The ssl_handshake_timeout parameter.\n\nChanged in version 3.7: The path parameter can now be a path-like object\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.PidfdChildWatcher", "path": "library/asyncio-policy#asyncio.PidfdChildWatcher", "type": "Asynchronous I/O", "text": "\nThis implementation polls process file descriptors (pidfds) to await child\nprocess termination. In some respects, `PidfdChildWatcher` is a \u201cGoldilocks\u201d\nchild watcher implementation. It doesn\u2019t require signals or threads, doesn\u2019t\ninterfere with any processes launched outside the event loop, and scales\nlinearly with the number of subprocesses launched by the event loop. The main\ndisadvantage is that pidfds are specific to Linux, and only work on recent\n(5.3+) kernels.\n\nNew in version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.PriorityQueue", "path": "library/asyncio-queue#asyncio.PriorityQueue", "type": "Asynchronous I/O", "text": "\nA variant of `Queue`; retrieves entries in priority order (lowest first).\n\nEntries are typically tuples of the form `(priority_number, data)`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.ProactorEventLoop", "path": "library/asyncio-eventloop#asyncio.ProactorEventLoop", "type": "Asynchronous I/O", "text": "\nAn event loop for Windows that uses \u201cI/O Completion Ports\u201d (IOCP).\n\nAvailability: Windows.\n\nSee also\n\nMSDN documentation on I/O Completion Ports.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Protocol", "path": "library/asyncio-protocol#asyncio.Protocol", "type": "Asynchronous I/O", "text": "\nThe base class for implementing streaming protocols (TCP, Unix sockets, etc).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Protocol.data_received()", "path": "library/asyncio-protocol#asyncio.Protocol.data_received", "type": "Asynchronous I/O", "text": "\nCalled when some data is received. data is a non-empty bytes object containing\nthe incoming data.\n\nWhether the data is buffered, chunked or reassembled depends on the transport.\nIn general, you shouldn\u2019t rely on specific semantics and instead make your\nparsing generic and flexible. However, data is always received in the correct\norder.\n\nThe method can be called an arbitrary number of times while a connection is\nopen.\n\nHowever, `protocol.eof_received()` is called at most once. Once\n`eof_received()` is called, `data_received()` is not called anymore.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Protocol.eof_received()", "path": "library/asyncio-protocol#asyncio.Protocol.eof_received", "type": "Asynchronous I/O", "text": "\nCalled when the other end signals it won\u2019t send any more data (for example by\ncalling `transport.write_eof()`, if the other end also uses asyncio).\n\nThis method may return a false value (including `None`), in which case the\ntransport will close itself. Conversely, if this method returns a true value,\nthe protocol used determines whether to close the transport. Since the default\nimplementation returns `None`, it implicitly closes the connection.\n\nSome transports, including SSL, don\u2019t support half-closed connections, in\nwhich case returning true from this method will result in the connection being\nclosed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue", "path": "library/asyncio-queue#asyncio.Queue", "type": "Asynchronous I/O", "text": "\nA first in, first out (FIFO) queue.\n\nIf maxsize is less than or equal to zero, the queue size is infinite. If it is\nan integer greater than `0`, then `await put()` blocks when the queue reaches\nmaxsize until an item is removed by `get()`.\n\nUnlike the standard library threading `queue`, the size of the queue is always\nknown and can be returned by calling the `qsize()` method.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nThis class is not thread safe.\n\nNumber of items allowed in the queue.\n\nReturn `True` if the queue is empty, `False` otherwise.\n\nReturn `True` if there are `maxsize` items in the queue.\n\nIf the queue was initialized with `maxsize=0` (the default), then `full()`\nnever returns `True`.\n\nRemove and return an item from the queue. If queue is empty, wait until an\nitem is available.\n\nReturn an item if one is immediately available, else raise `QueueEmpty`.\n\nBlock until all items in the queue have been received and processed.\n\nThe count of unfinished tasks goes up whenever an item is added to the queue.\nThe count goes down whenever a consumer coroutine calls `task_done()` to\nindicate that the item was retrieved and all work on it is complete. When the\ncount of unfinished tasks drops to zero, `join()` unblocks.\n\nPut an item into the queue. If the queue is full, wait until a free slot is\navailable before adding the item.\n\nPut an item into the queue without blocking.\n\nIf no free slot is immediately available, raise `QueueFull`.\n\nReturn the number of items in the queue.\n\nIndicate that a formerly enqueued task is complete.\n\nUsed by queue consumers. For each `get()` used to fetch a task, a subsequent\ncall to `task_done()` tells the queue that the processing on the task is\ncomplete.\n\nIf a `join()` is currently blocking, it will resume when all items have been\nprocessed (meaning that a `task_done()` call was received for every item that\nhad been `put()` into the queue).\n\nRaises `ValueError` if called more times than there were items placed in the\nqueue.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.empty()", "path": "library/asyncio-queue#asyncio.Queue.empty", "type": "Asynchronous I/O", "text": "\nReturn `True` if the queue is empty, `False` otherwise.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.full()", "path": "library/asyncio-queue#asyncio.Queue.full", "type": "Asynchronous I/O", "text": "\nReturn `True` if there are `maxsize` items in the queue.\n\nIf the queue was initialized with `maxsize=0` (the default), then `full()`\nnever returns `True`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.get()", "path": "library/asyncio-queue#asyncio.Queue.get", "type": "Asynchronous I/O", "text": "\nRemove and return an item from the queue. If queue is empty, wait until an\nitem is available.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.get_nowait()", "path": "library/asyncio-queue#asyncio.Queue.get_nowait", "type": "Asynchronous I/O", "text": "\nReturn an item if one is immediately available, else raise `QueueEmpty`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.join()", "path": "library/asyncio-queue#asyncio.Queue.join", "type": "Asynchronous I/O", "text": "\nBlock until all items in the queue have been received and processed.\n\nThe count of unfinished tasks goes up whenever an item is added to the queue.\nThe count goes down whenever a consumer coroutine calls `task_done()` to\nindicate that the item was retrieved and all work on it is complete. When the\ncount of unfinished tasks drops to zero, `join()` unblocks.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.maxsize", "path": "library/asyncio-queue#asyncio.Queue.maxsize", "type": "Asynchronous I/O", "text": "\nNumber of items allowed in the queue.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.put()", "path": "library/asyncio-queue#asyncio.Queue.put", "type": "Asynchronous I/O", "text": "\nPut an item into the queue. If the queue is full, wait until a free slot is\navailable before adding the item.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.put_nowait()", "path": "library/asyncio-queue#asyncio.Queue.put_nowait", "type": "Asynchronous I/O", "text": "\nPut an item into the queue without blocking.\n\nIf no free slot is immediately available, raise `QueueFull`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.qsize()", "path": "library/asyncio-queue#asyncio.Queue.qsize", "type": "Asynchronous I/O", "text": "\nReturn the number of items in the queue.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Queue.task_done()", "path": "library/asyncio-queue#asyncio.Queue.task_done", "type": "Asynchronous I/O", "text": "\nIndicate that a formerly enqueued task is complete.\n\nUsed by queue consumers. For each `get()` used to fetch a task, a subsequent\ncall to `task_done()` tells the queue that the processing on the task is\ncomplete.\n\nIf a `join()` is currently blocking, it will resume when all items have been\nprocessed (meaning that a `task_done()` call was received for every item that\nhad been `put()` into the queue).\n\nRaises `ValueError` if called more times than there were items placed in the\nqueue.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.QueueEmpty", "path": "library/asyncio-queue#asyncio.QueueEmpty", "type": "Asynchronous I/O", "text": "\nThis exception is raised when the `get_nowait()` method is called on an empty\nqueue.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.QueueFull", "path": "library/asyncio-queue#asyncio.QueueFull", "type": "Asynchronous I/O", "text": "\nException raised when the `put_nowait()` method is called on a queue that has\nreached its maxsize.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.ReadTransport", "path": "library/asyncio-protocol#asyncio.ReadTransport", "type": "Asynchronous I/O", "text": "\nA base transport for read-only connections.\n\nInstances of the ReadTransport class are returned from the\n`loop.connect_read_pipe()` event loop method and are also used by subprocess-\nrelated methods like `loop.subprocess_exec()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.ReadTransport.is_reading()", "path": "library/asyncio-protocol#asyncio.ReadTransport.is_reading", "type": "Asynchronous I/O", "text": "\nReturn `True` if the transport is receiving new data.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.ReadTransport.pause_reading()", "path": "library/asyncio-protocol#asyncio.ReadTransport.pause_reading", "type": "Asynchronous I/O", "text": "\nPause the receiving end of the transport. No data will be passed to the\nprotocol\u2019s `protocol.data_received()` method until `resume_reading()` is\ncalled.\n\nChanged in version 3.7: The method is idempotent, i.e. it can be called when\nthe transport is already paused or closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.ReadTransport.resume_reading()", "path": "library/asyncio-protocol#asyncio.ReadTransport.resume_reading", "type": "Asynchronous I/O", "text": "\nResume the receiving end. The protocol\u2019s `protocol.data_received()` method\nwill be called once again if some data is available for reading.\n\nChanged in version 3.7: The method is idempotent, i.e. it can be called when\nthe transport is already reading.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.run()", "path": "library/asyncio-task#asyncio.run", "type": "Asynchronous I/O", "text": "\nExecute the coroutine coro and return the result.\n\nThis function runs the passed coroutine, taking care of managing the asyncio\nevent loop, finalizing asynchronous generators, and closing the threadpool.\n\nThis function cannot be called when another asyncio event loop is running in\nthe same thread.\n\nIf debug is `True`, the event loop will be run in debug mode.\n\nThis function always creates a new event loop and closes it at the end. It\nshould be used as a main entry point for asyncio programs, and should ideally\nonly be called once.\n\nExample:\n\nNew in version 3.7.\n\nChanged in version 3.9: Updated to use `loop.shutdown_default_executor()`.\n\nNote\n\nThe source code for `asyncio.run()` can be found in Lib/asyncio/runners.py.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.run_coroutine_threadsafe()", "path": "library/asyncio-task#asyncio.run_coroutine_threadsafe", "type": "Asynchronous I/O", "text": "\nSubmit a coroutine to the given event loop. Thread-safe.\n\nReturn a `concurrent.futures.Future` to wait for the result from another OS\nthread.\n\nThis function is meant to be called from a different OS thread than the one\nwhere the event loop is running. Example:\n\nIf an exception is raised in the coroutine, the returned Future will be\nnotified. It can also be used to cancel the task in the event loop:\n\nSee the concurrency and multithreading section of the documentation.\n\nUnlike other asyncio functions this function requires the loop argument to be\npassed explicitly.\n\nNew in version 3.5.1.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SafeChildWatcher", "path": "library/asyncio-policy#asyncio.SafeChildWatcher", "type": "Asynchronous I/O", "text": "\nThis implementation uses active event loop from the main thread to handle\n`SIGCHLD` signal. If the main thread has no running event loop another thread\ncannot spawn a subprocess (`RuntimeError` is raised).\n\nThe watcher avoids disrupting other code spawning processes by polling every\nprocess explicitly on a `SIGCHLD` signal.\n\nThis solution is as safe as `MultiLoopChildWatcher` and has the same O(N)\ncomplexity but requires a running event loop in the main thread to work.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SelectorEventLoop", "path": "library/asyncio-eventloop#asyncio.SelectorEventLoop", "type": "Asynchronous I/O", "text": "\nAn event loop based on the `selectors` module.\n\nUses the most efficient selector available for the given platform. It is also\npossible to manually configure the exact selector implementation to be used:\n\nAvailability: Unix, Windows.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Semaphore", "path": "library/asyncio-sync#asyncio.Semaphore", "type": "Asynchronous I/O", "text": "\nA Semaphore object. Not thread-safe.\n\nA semaphore manages an internal counter which is decremented by each\n`acquire()` call and incremented by each `release()` call. The counter can\nnever go below zero; when `acquire()` finds that it is zero, it blocks,\nwaiting until some task calls `release()`.\n\nThe optional value argument gives the initial value for the internal counter\n(`1` by default). If the given value is less than `0` a `ValueError` is\nraised.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nThe preferred way to use a Semaphore is an `async with` statement:\n\nwhich is equivalent to:\n\nAcquire a semaphore.\n\nIf the internal counter is greater than zero, decrement it by one and return\n`True` immediately. If it is zero, wait until a `release()` is called and\nreturn `True`.\n\nReturns `True` if semaphore can not be acquired immediately.\n\nRelease a semaphore, incrementing the internal counter by one. Can wake up a\ntask waiting to acquire the semaphore.\n\nUnlike `BoundedSemaphore`, `Semaphore` allows making more `release()` calls\nthan `acquire()` calls.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Semaphore.acquire()", "path": "library/asyncio-sync#asyncio.Semaphore.acquire", "type": "Asynchronous I/O", "text": "\nAcquire a semaphore.\n\nIf the internal counter is greater than zero, decrement it by one and return\n`True` immediately. If it is zero, wait until a `release()` is called and\nreturn `True`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Semaphore.locked()", "path": "library/asyncio-sync#asyncio.Semaphore.locked", "type": "Asynchronous I/O", "text": "\nReturns `True` if semaphore can not be acquired immediately.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Semaphore.release()", "path": "library/asyncio-sync#asyncio.Semaphore.release", "type": "Asynchronous I/O", "text": "\nRelease a semaphore, incrementing the internal counter by one. Can wake up a\ntask waiting to acquire the semaphore.\n\nUnlike `BoundedSemaphore`, `Semaphore` allows making more `release()` calls\nthan `acquire()` calls.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SendfileNotAvailableError", "path": "library/asyncio-exceptions#asyncio.SendfileNotAvailableError", "type": "Asynchronous I/O", "text": "\nThe \u201csendfile\u201d syscall is not available for the given socket or file type.\n\nA subclass of `RuntimeError`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server", "path": "library/asyncio-eventloop#asyncio.Server", "type": "Asynchronous I/O", "text": "\nServer objects are asynchronous context managers. When used in an `async with`\nstatement, it\u2019s guaranteed that the Server object is closed and not accepting\nnew connections when the `async with` statement is completed:\n\nChanged in version 3.7: Server object is an asynchronous context manager since\nPython 3.7.\n\nStop serving: close listening sockets and set the `sockets` attribute to\n`None`.\n\nThe sockets that represent existing incoming client connections are left open.\n\nThe server is closed asynchronously, use the `wait_closed()` coroutine to wait\nuntil the server is closed.\n\nReturn the event loop associated with the server object.\n\nNew in version 3.7.\n\nStart accepting connections.\n\nThis method is idempotent, so it can be called when the server is already\nbeing serving.\n\nThe start_serving keyword-only parameter to `loop.create_server()` and\n`asyncio.start_server()` allows creating a Server object that is not accepting\nconnections initially. In this case `Server.start_serving()`, or\n`Server.serve_forever()` can be used to make the Server start accepting\nconnections.\n\nNew in version 3.7.\n\nStart accepting connections until the coroutine is cancelled. Cancellation of\n`serve_forever` task causes the server to be closed.\n\nThis method can be called if the server is already accepting connections. Only\none `serve_forever` task can exist per one Server object.\n\nExample:\n\nNew in version 3.7.\n\nReturn `True` if the server is accepting new connections.\n\nNew in version 3.7.\n\nWait until the `close()` method completes.\n\nList of `socket.socket` objects the server is listening on.\n\nChanged in version 3.7: Prior to Python 3.7 `Server.sockets` used to return an\ninternal list of server sockets directly. In 3.7 a copy of that list is\nreturned.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server.close()", "path": "library/asyncio-eventloop#asyncio.Server.close", "type": "Asynchronous I/O", "text": "\nStop serving: close listening sockets and set the `sockets` attribute to\n`None`.\n\nThe sockets that represent existing incoming client connections are left open.\n\nThe server is closed asynchronously, use the `wait_closed()` coroutine to wait\nuntil the server is closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server.get_loop()", "path": "library/asyncio-eventloop#asyncio.Server.get_loop", "type": "Asynchronous I/O", "text": "\nReturn the event loop associated with the server object.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server.is_serving()", "path": "library/asyncio-eventloop#asyncio.Server.is_serving", "type": "Asynchronous I/O", "text": "\nReturn `True` if the server is accepting new connections.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server.serve_forever()", "path": "library/asyncio-eventloop#asyncio.Server.serve_forever", "type": "Asynchronous I/O", "text": "\nStart accepting connections until the coroutine is cancelled. Cancellation of\n`serve_forever` task causes the server to be closed.\n\nThis method can be called if the server is already accepting connections. Only\none `serve_forever` task can exist per one Server object.\n\nExample:\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server.sockets", "path": "library/asyncio-eventloop#asyncio.Server.sockets", "type": "Asynchronous I/O", "text": "\nList of `socket.socket` objects the server is listening on.\n\nChanged in version 3.7: Prior to Python 3.7 `Server.sockets` used to return an\ninternal list of server sockets directly. In 3.7 a copy of that list is\nreturned.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server.start_serving()", "path": "library/asyncio-eventloop#asyncio.Server.start_serving", "type": "Asynchronous I/O", "text": "\nStart accepting connections.\n\nThis method is idempotent, so it can be called when the server is already\nbeing serving.\n\nThe start_serving keyword-only parameter to `loop.create_server()` and\n`asyncio.start_server()` allows creating a Server object that is not accepting\nconnections initially. In this case `Server.start_serving()`, or\n`Server.serve_forever()` can be used to make the Server start accepting\nconnections.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Server.wait_closed()", "path": "library/asyncio-eventloop#asyncio.Server.wait_closed", "type": "Asynchronous I/O", "text": "\nWait until the `close()` method completes.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.set_child_watcher()", "path": "library/asyncio-policy#asyncio.set_child_watcher", "type": "Asynchronous I/O", "text": "\nSet the current child watcher to watcher for the current policy. watcher must\nimplement methods defined in the `AbstractChildWatcher` base class.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.set_event_loop()", "path": "library/asyncio-eventloop#asyncio.set_event_loop", "type": "Asynchronous I/O", "text": "\nSet loop as a current event loop for the current OS thread.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.set_event_loop_policy()", "path": "library/asyncio-policy#asyncio.set_event_loop_policy", "type": "Asynchronous I/O", "text": "\nSet the current process-wide policy to policy.\n\nIf policy is set to `None`, the default policy is restored.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.shield()", "path": "library/asyncio-task#asyncio.shield", "type": "Asynchronous I/O", "text": "\nProtect an awaitable object from being `cancelled`.\n\nIf aw is a coroutine it is automatically scheduled as a Task.\n\nThe statement:\n\nis equivalent to:\n\nexcept that if the coroutine containing it is cancelled, the Task running in\n`something()` is not cancelled. From the point of view of `something()`, the\ncancellation did not happen. Although its caller is still cancelled, so the\n\u201cawait\u201d expression still raises a `CancelledError`.\n\nIf `something()` is cancelled by other means (i.e. from within itself) that\nwould also cancel `shield()`.\n\nIf it is desired to completely ignore cancellation (not recommended) the\n`shield()` function should be combined with a try/except clause, as follows:\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.sleep()", "path": "library/asyncio-task#asyncio.sleep", "type": "Asynchronous I/O", "text": "\nBlock for delay seconds.\n\nIf result is provided, it is returned to the caller when the coroutine\ncompletes.\n\n`sleep()` always suspends the current task, allowing other tasks to run.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample of coroutine displaying the current date every second for 5 seconds:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.start_server()", "path": "library/asyncio-stream#asyncio.start_server", "type": "Asynchronous I/O", "text": "\nStart a socket server.\n\nThe client_connected_cb callback is called whenever a new client connection is\nestablished. It receives a `(reader, writer)` pair as two arguments, instances\nof the `StreamReader` and `StreamWriter` classes.\n\nclient_connected_cb can be a plain callable or a coroutine function; if it is\na coroutine function, it will be automatically scheduled as a `Task`.\n\nThe loop argument is optional and can always be determined automatically when\nthis method is awaited from a coroutine.\n\nlimit determines the buffer size limit used by the returned `StreamReader`\ninstance. By default the limit is set to 64 KiB.\n\nThe rest of the arguments are passed directly to `loop.create_server()`.\n\nNew in version 3.7: The ssl_handshake_timeout and start_serving parameters.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.start_unix_server()", "path": "library/asyncio-stream#asyncio.start_unix_server", "type": "Asynchronous I/O", "text": "\nStart a Unix socket server.\n\nSimilar to `start_server()` but works with Unix sockets.\n\nSee also the documentation of `loop.create_unix_server()`.\n\nAvailability: Unix.\n\nNew in version 3.7: The ssl_handshake_timeout and start_serving parameters.\n\nChanged in version 3.7: The path parameter can now be a path-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamReader", "path": "library/asyncio-stream#asyncio.StreamReader", "type": "Asynchronous I/O", "text": "\nRepresents a reader object that provides APIs to read data from the IO stream.\n\nIt is not recommended to instantiate StreamReader objects directly; use\n`open_connection()` and `start_server()` instead.\n\nRead up to n bytes. If n is not provided, or set to `-1`, read until EOF and\nreturn all read bytes.\n\nIf EOF was received and the internal buffer is empty, return an empty `bytes`\nobject.\n\nRead one line, where \u201cline\u201d is a sequence of bytes ending with `\\n`.\n\nIf EOF is received and `\\n` was not found, the method returns partially read\ndata.\n\nIf EOF is received and the internal buffer is empty, return an empty `bytes`\nobject.\n\nRead exactly n bytes.\n\nRaise an `IncompleteReadError` if EOF is reached before n can be read. Use the\n`IncompleteReadError.partial` attribute to get the partially read data.\n\nRead data from the stream until separator is found.\n\nOn success, the data and separator will be removed from the internal buffer\n(consumed). Returned data will include the separator at the end.\n\nIf the amount of data read exceeds the configured stream limit, a\n`LimitOverrunError` exception is raised, and the data is left in the internal\nbuffer and can be read again.\n\nIf EOF is reached before the complete separator is found, an\n`IncompleteReadError` exception is raised, and the internal buffer is reset.\nThe `IncompleteReadError.partial` attribute may contain a portion of the\nseparator.\n\nNew in version 3.5.2.\n\nReturn `True` if the buffer is empty and `feed_eof()` was called.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamReader.at_eof()", "path": "library/asyncio-stream#asyncio.StreamReader.at_eof", "type": "Asynchronous I/O", "text": "\nReturn `True` if the buffer is empty and `feed_eof()` was called.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamReader.read()", "path": "library/asyncio-stream#asyncio.StreamReader.read", "type": "Asynchronous I/O", "text": "\nRead up to n bytes. If n is not provided, or set to `-1`, read until EOF and\nreturn all read bytes.\n\nIf EOF was received and the internal buffer is empty, return an empty `bytes`\nobject.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamReader.readexactly()", "path": "library/asyncio-stream#asyncio.StreamReader.readexactly", "type": "Asynchronous I/O", "text": "\nRead exactly n bytes.\n\nRaise an `IncompleteReadError` if EOF is reached before n can be read. Use the\n`IncompleteReadError.partial` attribute to get the partially read data.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamReader.readline()", "path": "library/asyncio-stream#asyncio.StreamReader.readline", "type": "Asynchronous I/O", "text": "\nRead one line, where \u201cline\u201d is a sequence of bytes ending with `\\n`.\n\nIf EOF is received and `\\n` was not found, the method returns partially read\ndata.\n\nIf EOF is received and the internal buffer is empty, return an empty `bytes`\nobject.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamReader.readuntil()", "path": "library/asyncio-stream#asyncio.StreamReader.readuntil", "type": "Asynchronous I/O", "text": "\nRead data from the stream until separator is found.\n\nOn success, the data and separator will be removed from the internal buffer\n(consumed). Returned data will include the separator at the end.\n\nIf the amount of data read exceeds the configured stream limit, a\n`LimitOverrunError` exception is raised, and the data is left in the internal\nbuffer and can be read again.\n\nIf EOF is reached before the complete separator is found, an\n`IncompleteReadError` exception is raised, and the internal buffer is reset.\nThe `IncompleteReadError.partial` attribute may contain a portion of the\nseparator.\n\nNew in version 3.5.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter", "path": "library/asyncio-stream#asyncio.StreamWriter", "type": "Asynchronous I/O", "text": "\nRepresents a writer object that provides APIs to write data to the IO stream.\n\nIt is not recommended to instantiate StreamWriter objects directly; use\n`open_connection()` and `start_server()` instead.\n\nThe method attempts to write the data to the underlying socket immediately. If\nthat fails, the data is queued in an internal write buffer until it can be\nsent.\n\nThe method should be used along with the `drain()` method:\n\nThe method writes a list (or any iterable) of bytes to the underlying socket\nimmediately. If that fails, the data is queued in an internal write buffer\nuntil it can be sent.\n\nThe method should be used along with the `drain()` method:\n\nThe method closes the stream and the underlying socket.\n\nThe method should be used along with the `wait_closed()` method:\n\nReturn `True` if the underlying transport supports the `write_eof()` method,\n`False` otherwise.\n\nClose the write end of the stream after the buffered write data is flushed.\n\nReturn the underlying asyncio transport.\n\nAccess optional transport information; see `BaseTransport.get_extra_info()`\nfor details.\n\nWait until it is appropriate to resume writing to the stream. Example:\n\nThis is a flow control method that interacts with the underlying IO write\nbuffer. When the size of the buffer reaches the high watermark, drain() blocks\nuntil the size of the buffer is drained down to the low watermark and writing\ncan be resumed. When there is nothing to wait for, the `drain()` returns\nimmediately.\n\nReturn `True` if the stream is closed or in the process of being closed.\n\nNew in version 3.7.\n\nWait until the stream is closed.\n\nShould be called after `close()` to wait until the underlying connection is\nclosed.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.can_write_eof()", "path": "library/asyncio-stream#asyncio.StreamWriter.can_write_eof", "type": "Asynchronous I/O", "text": "\nReturn `True` if the underlying transport supports the `write_eof()` method,\n`False` otherwise.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.close()", "path": "library/asyncio-stream#asyncio.StreamWriter.close", "type": "Asynchronous I/O", "text": "\nThe method closes the stream and the underlying socket.\n\nThe method should be used along with the `wait_closed()` method:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.drain()", "path": "library/asyncio-stream#asyncio.StreamWriter.drain", "type": "Asynchronous I/O", "text": "\nWait until it is appropriate to resume writing to the stream. Example:\n\nThis is a flow control method that interacts with the underlying IO write\nbuffer. When the size of the buffer reaches the high watermark, drain() blocks\nuntil the size of the buffer is drained down to the low watermark and writing\ncan be resumed. When there is nothing to wait for, the `drain()` returns\nimmediately.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.get_extra_info()", "path": "library/asyncio-stream#asyncio.StreamWriter.get_extra_info", "type": "Asynchronous I/O", "text": "\nAccess optional transport information; see `BaseTransport.get_extra_info()`\nfor details.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.is_closing()", "path": "library/asyncio-stream#asyncio.StreamWriter.is_closing", "type": "Asynchronous I/O", "text": "\nReturn `True` if the stream is closed or in the process of being closed.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.transport", "path": "library/asyncio-stream#asyncio.StreamWriter.transport", "type": "Asynchronous I/O", "text": "\nReturn the underlying asyncio transport.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.wait_closed()", "path": "library/asyncio-stream#asyncio.StreamWriter.wait_closed", "type": "Asynchronous I/O", "text": "\nWait until the stream is closed.\n\nShould be called after `close()` to wait until the underlying connection is\nclosed.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.write()", "path": "library/asyncio-stream#asyncio.StreamWriter.write", "type": "Asynchronous I/O", "text": "\nThe method attempts to write the data to the underlying socket immediately. If\nthat fails, the data is queued in an internal write buffer until it can be\nsent.\n\nThe method should be used along with the `drain()` method:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.writelines()", "path": "library/asyncio-stream#asyncio.StreamWriter.writelines", "type": "Asynchronous I/O", "text": "\nThe method writes a list (or any iterable) of bytes to the underlying socket\nimmediately. If that fails, the data is queued in an internal write buffer\nuntil it can be sent.\n\nThe method should be used along with the `drain()` method:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.StreamWriter.write_eof()", "path": "library/asyncio-stream#asyncio.StreamWriter.write_eof", "type": "Asynchronous I/O", "text": "\nClose the write end of the stream after the buffered write data is flushed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessProtocol", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol", "type": "Asynchronous I/O", "text": "\nThe base class for implementing protocols communicating with child processes\n(unidirectional pipes).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessProtocol.pipe_connection_lost()", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol.pipe_connection_lost", "type": "Asynchronous I/O", "text": "\nCalled when one of the pipes communicating with the child process is closed.\n\nfd is the integer file descriptor that was closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessProtocol.pipe_data_received()", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol.pipe_data_received", "type": "Asynchronous I/O", "text": "\nCalled when the child process writes data into its stdout or stderr pipe.\n\nfd is the integer file descriptor of the pipe.\n\ndata is a non-empty bytes object containing the received data.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessProtocol.process_exited()", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol.process_exited", "type": "Asynchronous I/O", "text": "\nCalled when the child process has exited.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport", "path": "library/asyncio-protocol#asyncio.SubprocessTransport", "type": "Asynchronous I/O", "text": "\nAn abstraction to represent a connection between a parent and its child OS\nprocess.\n\nInstances of the SubprocessTransport class are returned from event loop\nmethods `loop.subprocess_shell()` and `loop.subprocess_exec()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport.close()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.close", "type": "Asynchronous I/O", "text": "\nKill the subprocess by calling the `kill()` method.\n\nIf the subprocess hasn\u2019t returned yet, and close transports of stdin, stdout,\nand stderr pipes.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport.get_pid()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.get_pid", "type": "Asynchronous I/O", "text": "\nReturn the subprocess process id as an integer.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport.get_pipe_transport()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.get_pipe_transport", "type": "Asynchronous I/O", "text": "\nReturn the transport for the communication pipe corresponding to the integer\nfile descriptor fd:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport.get_returncode()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.get_returncode", "type": "Asynchronous I/O", "text": "\nReturn the subprocess return code as an integer or `None` if it hasn\u2019t\nreturned, which is similar to the `subprocess.Popen.returncode` attribute.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport.kill()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.kill", "type": "Asynchronous I/O", "text": "\nKill the subprocess.\n\nOn POSIX systems, the function sends SIGKILL to the subprocess. On Windows,\nthis method is an alias for `terminate()`.\n\nSee also `subprocess.Popen.kill()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport.send_signal()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.send_signal", "type": "Asynchronous I/O", "text": "\nSend the signal number to the subprocess, as in\n`subprocess.Popen.send_signal()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.SubprocessTransport.terminate()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.terminate", "type": "Asynchronous I/O", "text": "\nStop the subprocess.\n\nOn POSIX systems, this method sends SIGTERM to the subprocess. On Windows, the\nWindows API function TerminateProcess() is called to stop the subprocess.\n\nSee also `subprocess.Popen.terminate()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task", "path": "library/asyncio-task#asyncio.Task", "type": "Asynchronous I/O", "text": "\nA `Future-like` object that runs a Python coroutine. Not thread-safe.\n\nTasks are used to run coroutines in event loops. If a coroutine awaits on a\nFuture, the Task suspends the execution of the coroutine and waits for the\ncompletion of the Future. When the Future is done, the execution of the\nwrapped coroutine resumes.\n\nEvent loops use cooperative scheduling: an event loop runs one Task at a time.\nWhile a Task awaits for the completion of a Future, the event loop runs other\nTasks, callbacks, or performs IO operations.\n\nUse the high-level `asyncio.create_task()` function to create Tasks, or the\nlow-level `loop.create_task()` or `ensure_future()` functions. Manual\ninstantiation of Tasks is discouraged.\n\nTo cancel a running Task use the `cancel()` method. Calling it will cause the\nTask to throw a `CancelledError` exception into the wrapped coroutine. If a\ncoroutine is awaiting on a Future object during cancellation, the Future\nobject will be cancelled.\n\n`cancelled()` can be used to check if the Task was cancelled. The method\nreturns `True` if the wrapped coroutine did not suppress the `CancelledError`\nexception and was actually cancelled.\n\n`asyncio.Task` inherits from `Future` all of its APIs except\n`Future.set_result()` and `Future.set_exception()`.\n\nTasks support the `contextvars` module. When a Task is created it copies the\ncurrent context and later runs its coroutine in the copied context.\n\nChanged in version 3.7: Added support for the `contextvars` module.\n\nChanged in version 3.8: Added the `name` parameter.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nRequest the Task to be cancelled.\n\nThis arranges for a `CancelledError` exception to be thrown into the wrapped\ncoroutine on the next cycle of the event loop.\n\nThe coroutine then has a chance to clean up or even deny the request by\nsuppressing the exception with a `try` \u2026 \u2026 `except CancelledError` \u2026 `finally`\nblock. Therefore, unlike `Future.cancel()`, `Task.cancel()` does not guarantee\nthat the Task will be cancelled, although suppressing cancellation completely\nis not common and is actively discouraged.\n\nChanged in version 3.9: Added the `msg` parameter.\n\nThe following example illustrates how coroutines can intercept the\ncancellation request:\n\nReturn `True` if the Task is cancelled.\n\nThe Task is cancelled when the cancellation was requested with `cancel()` and\nthe wrapped coroutine propagated the `CancelledError` exception thrown into\nit.\n\nReturn `True` if the Task is done.\n\nA Task is done when the wrapped coroutine either returned a value, raised an\nexception, or the Task was cancelled.\n\nReturn the result of the Task.\n\nIf the Task is done, the result of the wrapped coroutine is returned (or if\nthe coroutine raised an exception, that exception is re-raised.)\n\nIf the Task has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Task\u2019s result isn\u2019t yet available, this method raises a\n`InvalidStateError` exception.\n\nReturn the exception of the Task.\n\nIf the wrapped coroutine raised an exception that exception is returned. If\nthe wrapped coroutine returned normally this method returns `None`.\n\nIf the Task has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Task isn\u2019t done yet, this method raises an `InvalidStateError`\nexception.\n\nAdd a callback to be run when the Task is done.\n\nThis method should only be used in low-level callback-based code.\n\nSee the documentation of `Future.add_done_callback()` for more details.\n\nRemove callback from the callbacks list.\n\nThis method should only be used in low-level callback-based code.\n\nSee the documentation of `Future.remove_done_callback()` for more details.\n\nReturn the list of stack frames for this Task.\n\nIf the wrapped coroutine is not done, this returns the stack where it is\nsuspended. If the coroutine has completed successfully or was cancelled, this\nreturns an empty list. If the coroutine was terminated by an exception, this\nreturns the list of traceback frames.\n\nThe frames are always ordered from oldest to newest.\n\nOnly one stack frame is returned for a suspended coroutine.\n\nThe optional limit argument sets the maximum number of frames to return; by\ndefault all available frames are returned. The ordering of the returned list\ndiffers depending on whether a stack or a traceback is returned: the newest\nframes of a stack are returned, but the oldest frames of a traceback are\nreturned. (This matches the behavior of the traceback module.)\n\nPrint the stack or traceback for this Task.\n\nThis produces output similar to that of the traceback module for the frames\nretrieved by `get_stack()`.\n\nThe limit argument is passed to `get_stack()` directly.\n\nThe file argument is an I/O stream to which the output is written; by default\noutput is written to `sys.stderr`.\n\nReturn the coroutine object wrapped by the `Task`.\n\nNew in version 3.8.\n\nReturn the name of the Task.\n\nIf no name has been explicitly assigned to the Task, the default asyncio Task\nimplementation generates a default name during instantiation.\n\nNew in version 3.8.\n\nSet the name of the Task.\n\nThe value argument can be any object, which is then converted to a string.\n\nIn the default Task implementation, the name will be visible in the `repr()`\noutput of a task object.\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.add_done_callback()", "path": "library/asyncio-task#asyncio.Task.add_done_callback", "type": "Asynchronous I/O", "text": "\nAdd a callback to be run when the Task is done.\n\nThis method should only be used in low-level callback-based code.\n\nSee the documentation of `Future.add_done_callback()` for more details.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.cancel()", "path": "library/asyncio-task#asyncio.Task.cancel", "type": "Asynchronous I/O", "text": "\nRequest the Task to be cancelled.\n\nThis arranges for a `CancelledError` exception to be thrown into the wrapped\ncoroutine on the next cycle of the event loop.\n\nThe coroutine then has a chance to clean up or even deny the request by\nsuppressing the exception with a `try` \u2026 \u2026 `except CancelledError` \u2026 `finally`\nblock. Therefore, unlike `Future.cancel()`, `Task.cancel()` does not guarantee\nthat the Task will be cancelled, although suppressing cancellation completely\nis not common and is actively discouraged.\n\nChanged in version 3.9: Added the `msg` parameter.\n\nThe following example illustrates how coroutines can intercept the\ncancellation request:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.cancelled()", "path": "library/asyncio-task#asyncio.Task.cancelled", "type": "Asynchronous I/O", "text": "\nReturn `True` if the Task is cancelled.\n\nThe Task is cancelled when the cancellation was requested with `cancel()` and\nthe wrapped coroutine propagated the `CancelledError` exception thrown into\nit.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.done()", "path": "library/asyncio-task#asyncio.Task.done", "type": "Asynchronous I/O", "text": "\nReturn `True` if the Task is done.\n\nA Task is done when the wrapped coroutine either returned a value, raised an\nexception, or the Task was cancelled.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.exception()", "path": "library/asyncio-task#asyncio.Task.exception", "type": "Asynchronous I/O", "text": "\nReturn the exception of the Task.\n\nIf the wrapped coroutine raised an exception that exception is returned. If\nthe wrapped coroutine returned normally this method returns `None`.\n\nIf the Task has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Task isn\u2019t done yet, this method raises an `InvalidStateError`\nexception.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.get_coro()", "path": "library/asyncio-task#asyncio.Task.get_coro", "type": "Asynchronous I/O", "text": "\nReturn the coroutine object wrapped by the `Task`.\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.get_name()", "path": "library/asyncio-task#asyncio.Task.get_name", "type": "Asynchronous I/O", "text": "\nReturn the name of the Task.\n\nIf no name has been explicitly assigned to the Task, the default asyncio Task\nimplementation generates a default name during instantiation.\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.get_stack()", "path": "library/asyncio-task#asyncio.Task.get_stack", "type": "Asynchronous I/O", "text": "\nReturn the list of stack frames for this Task.\n\nIf the wrapped coroutine is not done, this returns the stack where it is\nsuspended. If the coroutine has completed successfully or was cancelled, this\nreturns an empty list. If the coroutine was terminated by an exception, this\nreturns the list of traceback frames.\n\nThe frames are always ordered from oldest to newest.\n\nOnly one stack frame is returned for a suspended coroutine.\n\nThe optional limit argument sets the maximum number of frames to return; by\ndefault all available frames are returned. The ordering of the returned list\ndiffers depending on whether a stack or a traceback is returned: the newest\nframes of a stack are returned, but the oldest frames of a traceback are\nreturned. (This matches the behavior of the traceback module.)\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.print_stack()", "path": "library/asyncio-task#asyncio.Task.print_stack", "type": "Asynchronous I/O", "text": "\nPrint the stack or traceback for this Task.\n\nThis produces output similar to that of the traceback module for the frames\nretrieved by `get_stack()`.\n\nThe limit argument is passed to `get_stack()` directly.\n\nThe file argument is an I/O stream to which the output is written; by default\noutput is written to `sys.stderr`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.remove_done_callback()", "path": "library/asyncio-task#asyncio.Task.remove_done_callback", "type": "Asynchronous I/O", "text": "\nRemove callback from the callbacks list.\n\nThis method should only be used in low-level callback-based code.\n\nSee the documentation of `Future.remove_done_callback()` for more details.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.result()", "path": "library/asyncio-task#asyncio.Task.result", "type": "Asynchronous I/O", "text": "\nReturn the result of the Task.\n\nIf the Task is done, the result of the wrapped coroutine is returned (or if\nthe coroutine raised an exception, that exception is re-raised.)\n\nIf the Task has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Task\u2019s result isn\u2019t yet available, this method raises a\n`InvalidStateError` exception.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Task.set_name()", "path": "library/asyncio-task#asyncio.Task.set_name", "type": "Asynchronous I/O", "text": "\nSet the name of the Task.\n\nThe value argument can be any object, which is then converted to a string.\n\nIn the default Task implementation, the name will be visible in the `repr()`\noutput of a task object.\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.ThreadedChildWatcher", "path": "library/asyncio-policy#asyncio.ThreadedChildWatcher", "type": "Asynchronous I/O", "text": "\nThis implementation starts a new waiting thread for every subprocess spawn.\n\nIt works reliably even when the asyncio event loop is run in a non-main OS\nthread.\n\nThere is no noticeable overhead when handling a big number of children (O(1)\neach time a child terminates), but starting a thread per process requires\nextra memory.\n\nThis watcher is used by default.\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.TimeoutError", "path": "library/asyncio-exceptions#asyncio.TimeoutError", "type": "Asynchronous I/O", "text": "\nThe operation has exceeded the given deadline.\n\nImportant\n\nThis exception is different from the builtin `TimeoutError` exception.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.TimerHandle", "path": "library/asyncio-eventloop#asyncio.TimerHandle", "type": "Asynchronous I/O", "text": "\nA callback wrapper object returned by `loop.call_later()`, and\n`loop.call_at()`.\n\nThis class is a subclass of `Handle`.\n\nReturn a scheduled callback time as `float` seconds.\n\nThe time is an absolute timestamp, using the same time reference as\n`loop.time()`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.TimerHandle.when()", "path": "library/asyncio-eventloop#asyncio.TimerHandle.when", "type": "Asynchronous I/O", "text": "\nReturn a scheduled callback time as `float` seconds.\n\nThe time is an absolute timestamp, using the same time reference as\n`loop.time()`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.to_thread()", "path": "library/asyncio-task#asyncio.to_thread", "type": "Asynchronous I/O", "text": "\nAsynchronously run function func in a separate thread.\n\nAny *args and **kwargs supplied for this function are directly passed to func.\nAlso, the current `contextvars.Context` is propagated, allowing context\nvariables from the event loop thread to be accessed in the separate thread.\n\nReturn a coroutine that can be awaited to get the eventual result of func.\n\nThis coroutine function is primarily intended to be used for executing IO-\nbound functions/methods that would otherwise block the event loop if they were\nran in the main thread. For example:\n\nDirectly calling `blocking_io()` in any coroutine would block the event loop\nfor its duration, resulting in an additional 1 second of run time. Instead, by\nusing `asyncio.to_thread()`, we can run it in a separate thread without\nblocking the event loop.\n\nNote\n\nDue to the GIL, `asyncio.to_thread()` can typically only be used to make IO-\nbound functions non-blocking. However, for extension modules that release the\nGIL or alternative Python implementations that don\u2019t have one,\n`asyncio.to_thread()` can also be used for CPU-bound functions.\n\nNew in version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.Transport", "path": "library/asyncio-protocol#asyncio.Transport", "type": "Asynchronous I/O", "text": "\nInterface representing a bidirectional transport, such as a TCP connection.\n\nThe user does not instantiate a transport directly; they call a utility\nfunction, passing it a protocol factory and other information necessary to\ncreate the transport and protocol.\n\nInstances of the Transport class are returned from or used by event loop\nmethods like `loop.create_connection()`, `loop.create_unix_connection()`,\n`loop.create_server()`, `loop.sendfile()`, etc.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.wait()", "path": "library/asyncio-task#asyncio.wait", "type": "Asynchronous I/O", "text": "\nRun awaitable objects in the aws iterable concurrently and block until the\ncondition specified by return_when.\n\nThe aws iterable must not be empty.\n\nReturns two sets of Tasks/Futures: `(done, pending)`.\n\nUsage:\n\ntimeout (a float or int), if specified, can be used to control the maximum\nnumber of seconds to wait before returning.\n\nNote that this function does not raise `asyncio.TimeoutError`. Futures or\nTasks that aren\u2019t done when the timeout occurs are simply returned in the\nsecond set.\n\nreturn_when indicates when this function should return. It must be one of the\nfollowing constants:\n\nConstant\n\nDescription\n\n`FIRST_COMPLETED`\n\nThe function will return when any future finishes or is cancelled.\n\n`FIRST_EXCEPTION`\n\nThe function will return when any future finishes by raising an exception. If\nno future raises an exception then it is equivalent to `ALL_COMPLETED`.\n\n`ALL_COMPLETED`\n\nThe function will return when all futures finish or are cancelled.\n\nUnlike `wait_for()`, `wait()` does not cancel the futures when a timeout\noccurs.\n\nDeprecated since version 3.8: If any awaitable in aws is a coroutine, it is\nautomatically scheduled as a Task. Passing coroutines objects to `wait()`\ndirectly is deprecated as it leads to confusing behavior.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nNote\n\n`wait()` schedules coroutines as Tasks automatically and later returns those\nimplicitly created Task objects in `(done, pending)` sets. Therefore the\nfollowing code won\u2019t work as expected:\n\nHere is how the above snippet can be fixed:\n\nDeprecated since version 3.8, will be removed in version 3.11: Passing\ncoroutine objects to `wait()` directly is deprecated.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.wait_for()", "path": "library/asyncio-task#asyncio.wait_for", "type": "Asynchronous I/O", "text": "\nWait for the aw awaitable to complete with a timeout.\n\nIf aw is a coroutine it is automatically scheduled as a Task.\n\ntimeout can either be `None` or a float or int number of seconds to wait for.\nIf timeout is `None`, block until the future completes.\n\nIf a timeout occurs, it cancels the task and raises `asyncio.TimeoutError`.\n\nTo avoid the task `cancellation`, wrap it in `shield()`.\n\nThe function will wait until the future is actually cancelled, so the total\nwait time may exceed the timeout. If an exception happens during cancellation,\nit is propagated.\n\nIf the wait is cancelled, the future aw is also cancelled.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample:\n\nChanged in version 3.7: When aw is cancelled due to a timeout, `wait_for`\nwaits for aw to be cancelled. Previously, it raised `asyncio.TimeoutError`\nimmediately.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WindowsProactorEventLoopPolicy", "path": "library/asyncio-policy#asyncio.WindowsProactorEventLoopPolicy", "type": "Asynchronous I/O", "text": "\nAn alternative event loop policy that uses the `ProactorEventLoop` event loop\nimplementation.\n\nAvailability: Windows.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WindowsSelectorEventLoopPolicy", "path": "library/asyncio-policy#asyncio.WindowsSelectorEventLoopPolicy", "type": "Asynchronous I/O", "text": "\nAn alternative event loop policy that uses the `SelectorEventLoop` event loop\nimplementation.\n\nAvailability: Windows.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.wrap_future()", "path": "library/asyncio-future#asyncio.wrap_future", "type": "Asynchronous I/O", "text": "\nWrap a `concurrent.futures.Future` object in a `asyncio.Future` object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport", "path": "library/asyncio-protocol#asyncio.WriteTransport", "type": "Asynchronous I/O", "text": "\nA base transport for write-only connections.\n\nInstances of the WriteTransport class are returned from the\n`loop.connect_write_pipe()` event loop method and are also used by subprocess-\nrelated methods like `loop.subprocess_exec()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.abort()", "path": "library/asyncio-protocol#asyncio.WriteTransport.abort", "type": "Asynchronous I/O", "text": "\nClose the transport immediately, without waiting for pending operations to\ncomplete. Buffered data will be lost. No more data will be received. The\nprotocol\u2019s `protocol.connection_lost()` method will eventually be called with\n`None` as its argument.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.can_write_eof()", "path": "library/asyncio-protocol#asyncio.WriteTransport.can_write_eof", "type": "Asynchronous I/O", "text": "\nReturn `True` if the transport supports `write_eof()`, `False` if not.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.get_write_buffer_limits()", "path": "library/asyncio-protocol#asyncio.WriteTransport.get_write_buffer_limits", "type": "Asynchronous I/O", "text": "\nGet the high and low watermarks for write flow control. Return a tuple `(low,\nhigh)` where low and high are positive number of bytes.\n\nUse `set_write_buffer_limits()` to set the limits.\n\nNew in version 3.4.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.get_write_buffer_size()", "path": "library/asyncio-protocol#asyncio.WriteTransport.get_write_buffer_size", "type": "Asynchronous I/O", "text": "\nReturn the current size of the output buffer used by the transport.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.set_write_buffer_limits()", "path": "library/asyncio-protocol#asyncio.WriteTransport.set_write_buffer_limits", "type": "Asynchronous I/O", "text": "\nSet the high and low watermarks for write flow control.\n\nThese two values (measured in number of bytes) control when the protocol\u2019s\n`protocol.pause_writing()` and `protocol.resume_writing()` methods are called.\nIf specified, the low watermark must be less than or equal to the high\nwatermark. Neither high nor low can be negative.\n\n`pause_writing()` is called when the buffer size becomes greater than or equal\nto the high value. If writing has been paused, `resume_writing()` is called\nwhen the buffer size becomes less than or equal to the low value.\n\nThe defaults are implementation-specific. If only the high watermark is given,\nthe low watermark defaults to an implementation-specific value less than or\nequal to the high watermark. Setting high to zero forces low to zero as well,\nand causes `pause_writing()` to be called whenever the buffer becomes non-\nempty. Setting low to zero causes `resume_writing()` to be called only once\nthe buffer is empty. Use of zero for either limit is generally sub-optimal as\nit reduces opportunities for doing I/O and computation concurrently.\n\nUse `get_write_buffer_limits()` to get the limits.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.write()", "path": "library/asyncio-protocol#asyncio.WriteTransport.write", "type": "Asynchronous I/O", "text": "\nWrite some data bytes to the transport.\n\nThis method does not block; it buffers the data and arranges for it to be sent\nout asynchronously.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.writelines()", "path": "library/asyncio-protocol#asyncio.WriteTransport.writelines", "type": "Asynchronous I/O", "text": "\nWrite a list (or any iterable) of data bytes to the transport. This is\nfunctionally equivalent to calling `write()` on each element yielded by the\niterable, but may be implemented more efficiently.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncio.WriteTransport.write_eof()", "path": "library/asyncio-protocol#asyncio.WriteTransport.write_eof", "type": "Asynchronous I/O", "text": "\nClose the write end of the transport after flushing all buffered data. Data\nmay still be received.\n\nThis method can raise `NotImplementedError` if the transport (e.g. SSL)\ndoesn\u2019t support half-closed connections.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore", "path": "library/asyncore", "type": "Networking & Interprocess Communication", "text": "\nSource code: Lib/asyncore.py\n\nDeprecated since version 3.6: Please use `asyncio` instead.\n\nNote\n\nThis module exists for backwards compatibility only. For new code we recommend\nusing `asyncio`.\n\nThis module provides the basic infrastructure for writing asynchronous socket\nservice clients and servers.\n\nThere are only two ways to have a program on a single processor do \u201cmore than\none thing at a time.\u201d Multi-threaded programming is the simplest and most\npopular way to do it, but there is another very different technique, that lets\nyou have nearly all the advantages of multi-threading, without actually using\nmultiple threads. It\u2019s really only practical if your program is largely I/O\nbound. If your program is processor bound, then pre-emptive scheduled threads\nare probably what you really need. Network servers are rarely processor bound,\nhowever.\n\nIf your operating system supports the `select()` system call in its I/O\nlibrary (and nearly all do), then you can use it to juggle multiple\ncommunication channels at once; doing other work while your I/O is taking\nplace in the \u201cbackground.\u201d Although this strategy can seem strange and\ncomplex, especially at first, it is in many ways easier to understand and\ncontrol than multi-threaded programming. The `asyncore` module solves many of\nthe difficult problems for you, making the task of building sophisticated\nhigh-performance network servers and clients a snap. For \u201cconversational\u201d\napplications and protocols the companion `asynchat` module is invaluable.\n\nThe basic idea behind both modules is to create one or more network channels,\ninstances of class `asyncore.dispatcher` and `asynchat.async_chat`. Creating\nthe channels adds them to a global map, used by the `loop()` function if you\ndo not provide it with your own map.\n\nOnce the initial channel(s) is(are) created, calling the `loop()` function\nactivates channel service, which continues until the last channel (including\nany that have been added to the map during asynchronous service) is closed.\n\nEnter a polling loop that terminates after count passes or all open channels\nhave been closed. All arguments are optional. The count parameter defaults to\n`None`, resulting in the loop terminating only when all channels have been\nclosed. The timeout argument sets the timeout parameter for the appropriate\n`select()` or `poll()` call, measured in seconds; the default is 30 seconds.\nThe use_poll parameter, if true, indicates that `poll()` should be used in\npreference to `select()` (the default is `False`).\n\nThe map parameter is a dictionary whose items are the channels to watch. As\nchannels are closed they are deleted from their map. If map is omitted, a\nglobal map is used. Channels (instances of `asyncore.dispatcher`,\n`asynchat.async_chat` and subclasses thereof) can freely be mixed in the map.\n\nThe `dispatcher` class is a thin wrapper around a low-level socket object. To\nmake it more useful, it has a few methods for event-handling which are called\nfrom the asynchronous loop. Otherwise, it can be treated as a normal non-\nblocking socket object.\n\nThe firing of low-level events at certain times or in certain connection\nstates tells the asynchronous loop that certain higher-level events have taken\nplace. For example, if we have asked for a socket to connect to another host,\nwe know that the connection has been made when the socket becomes writable for\nthe first time (at this point you know that you may write to it with the\nexpectation of success). The implied higher-level events are:\n\nEvent\n\nDescription\n\n`handle_connect()`\n\nImplied by the first read or write event\n\n`handle_close()`\n\nImplied by a read event with no data available\n\n`handle_accepted()`\n\nImplied by a read event on a listening socket\n\nDuring asynchronous processing, each mapped channel\u2019s `readable()` and\n`writable()` methods are used to determine whether the channel\u2019s socket should\nbe added to the list of channels `select()`ed or `poll()`ed for read and write\nevents.\n\nThus, the set of channel events is larger than the basic socket events. The\nfull set of methods that can be overridden in your subclass follows:\n\nCalled when the asynchronous loop detects that a `read()` call on the\nchannel\u2019s socket will succeed.\n\nCalled when the asynchronous loop detects that a writable socket can be\nwritten. Often this method will implement the necessary buffering for\nperformance. For example:\n\nCalled when there is out of band (OOB) data for a socket connection. This will\nalmost never happen, as OOB is tenuously supported and rarely used.\n\nCalled when the active opener\u2019s socket actually makes a connection. Might send\na \u201cwelcome\u201d banner, or initiate a protocol negotiation with the remote\nendpoint, for example.\n\nCalled when the socket is closed.\n\nCalled when an exception is raised and not otherwise handled. The default\nversion prints a condensed traceback.\n\nCalled on listening channels (passive openers) when a connection can be\nestablished with a new remote endpoint that has issued a `connect()` call for\nthe local endpoint. Deprecated in version 3.2; use `handle_accepted()`\ninstead.\n\nDeprecated since version 3.2.\n\nCalled on listening channels (passive openers) when a connection has been\nestablished with a new remote endpoint that has issued a `connect()` call for\nthe local endpoint. sock is a new socket object usable to send and receive\ndata on the connection, and addr is the address bound to the socket on the\nother end of the connection.\n\nNew in version 3.2.\n\nCalled each time around the asynchronous loop to determine whether a channel\u2019s\nsocket should be added to the list on which read events can occur. The default\nmethod simply returns `True`, indicating that by default, all channels will be\ninterested in read events.\n\nCalled each time around the asynchronous loop to determine whether a channel\u2019s\nsocket should be added to the list on which write events can occur. The\ndefault method simply returns `True`, indicating that by default, all channels\nwill be interested in write events.\n\nIn addition, each channel delegates or extends many of the socket methods.\nMost of these are nearly identical to their socket partners.\n\nThis is identical to the creation of a normal socket, and will use the same\noptions for creation. Refer to the `socket` documentation for information on\ncreating sockets.\n\nChanged in version 3.3: family and type arguments can be omitted.\n\nAs with the normal socket object, address is a tuple with the first element\nthe host to connect to, and the second the port number.\n\nSend data to the remote end-point of the socket.\n\nRead at most buffer_size bytes from the socket\u2019s remote end-point. An empty\nbytes object implies that the channel has been closed from the other end.\n\nNote that `recv()` may raise `BlockingIOError` , even though `select.select()`\nor `select.poll()` has reported the socket ready for reading.\n\nListen for connections made to the socket. The backlog argument specifies the\nmaximum number of queued connections and should be at least 1; the maximum\nvalue is system-dependent (usually 5).\n\nBind the socket to address. The socket must not already be bound. (The format\nof address depends on the address family \u2014 refer to the `socket` documentation\nfor more information.) To mark the socket as re-usable (setting the\n`SO_REUSEADDR` option), call the `dispatcher` object\u2019s `set_reuse_addr()`\nmethod.\n\nAccept a connection. The socket must be bound to an address and listening for\nconnections. The return value can be either `None` or a pair `(conn, address)`\nwhere conn is a new socket object usable to send and receive data on the\nconnection, and address is the address bound to the socket on the other end of\nthe connection. When `None` is returned it means the connection didn\u2019t take\nplace, in which case the server should just ignore this event and keep\nlistening for further incoming connections.\n\nClose the socket. All future operations on the socket object will fail. The\nremote end-point will receive no more data (after queued data is flushed).\nSockets are automatically closed when they are garbage-collected.\n\nA `dispatcher` subclass which adds simple buffered output capability, useful\nfor simple clients. For more sophisticated usage use `asynchat.async_chat`.\n\nA file_dispatcher takes a file descriptor or file object along with an\noptional map argument and wraps it for use with the `poll()` or `loop()`\nfunctions. If provided a file object or anything with a `fileno()` method,\nthat method will be called and passed to the `file_wrapper` constructor.\n\nAvailability: Unix.\n\nA file_wrapper takes an integer file descriptor and calls `os.dup()` to\nduplicate the handle so that the original handle may be closed independently\nof the file_wrapper. This class implements sufficient methods to emulate a\nsocket for use by the `file_dispatcher` class.\n\nAvailability: Unix.\n\nHere is a very basic HTTP client that uses the `dispatcher` class to implement\nits socket handling:\n\nHere is a basic echo server that uses the `dispatcher` class to accept\nconnections and dispatches the incoming connections to a handler:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher", "path": "library/asyncore#asyncore.dispatcher", "type": "Networking & Interprocess Communication", "text": "\nThe `dispatcher` class is a thin wrapper around a low-level socket object. To\nmake it more useful, it has a few methods for event-handling which are called\nfrom the asynchronous loop. Otherwise, it can be treated as a normal non-\nblocking socket object.\n\nThe firing of low-level events at certain times or in certain connection\nstates tells the asynchronous loop that certain higher-level events have taken\nplace. For example, if we have asked for a socket to connect to another host,\nwe know that the connection has been made when the socket becomes writable for\nthe first time (at this point you know that you may write to it with the\nexpectation of success). The implied higher-level events are:\n\nEvent\n\nDescription\n\n`handle_connect()`\n\nImplied by the first read or write event\n\n`handle_close()`\n\nImplied by a read event with no data available\n\n`handle_accepted()`\n\nImplied by a read event on a listening socket\n\nDuring asynchronous processing, each mapped channel\u2019s `readable()` and\n`writable()` methods are used to determine whether the channel\u2019s socket should\nbe added to the list of channels `select()`ed or `poll()`ed for read and write\nevents.\n\nThus, the set of channel events is larger than the basic socket events. The\nfull set of methods that can be overridden in your subclass follows:\n\nCalled when the asynchronous loop detects that a `read()` call on the\nchannel\u2019s socket will succeed.\n\nCalled when the asynchronous loop detects that a writable socket can be\nwritten. Often this method will implement the necessary buffering for\nperformance. For example:\n\nCalled when there is out of band (OOB) data for a socket connection. This will\nalmost never happen, as OOB is tenuously supported and rarely used.\n\nCalled when the active opener\u2019s socket actually makes a connection. Might send\na \u201cwelcome\u201d banner, or initiate a protocol negotiation with the remote\nendpoint, for example.\n\nCalled when the socket is closed.\n\nCalled when an exception is raised and not otherwise handled. The default\nversion prints a condensed traceback.\n\nCalled on listening channels (passive openers) when a connection can be\nestablished with a new remote endpoint that has issued a `connect()` call for\nthe local endpoint. Deprecated in version 3.2; use `handle_accepted()`\ninstead.\n\nDeprecated since version 3.2.\n\nCalled on listening channels (passive openers) when a connection has been\nestablished with a new remote endpoint that has issued a `connect()` call for\nthe local endpoint. sock is a new socket object usable to send and receive\ndata on the connection, and addr is the address bound to the socket on the\nother end of the connection.\n\nNew in version 3.2.\n\nCalled each time around the asynchronous loop to determine whether a channel\u2019s\nsocket should be added to the list on which read events can occur. The default\nmethod simply returns `True`, indicating that by default, all channels will be\ninterested in read events.\n\nCalled each time around the asynchronous loop to determine whether a channel\u2019s\nsocket should be added to the list on which write events can occur. The\ndefault method simply returns `True`, indicating that by default, all channels\nwill be interested in write events.\n\nIn addition, each channel delegates or extends many of the socket methods.\nMost of these are nearly identical to their socket partners.\n\nThis is identical to the creation of a normal socket, and will use the same\noptions for creation. Refer to the `socket` documentation for information on\ncreating sockets.\n\nChanged in version 3.3: family and type arguments can be omitted.\n\nAs with the normal socket object, address is a tuple with the first element\nthe host to connect to, and the second the port number.\n\nSend data to the remote end-point of the socket.\n\nRead at most buffer_size bytes from the socket\u2019s remote end-point. An empty\nbytes object implies that the channel has been closed from the other end.\n\nNote that `recv()` may raise `BlockingIOError` , even though `select.select()`\nor `select.poll()` has reported the socket ready for reading.\n\nListen for connections made to the socket. The backlog argument specifies the\nmaximum number of queued connections and should be at least 1; the maximum\nvalue is system-dependent (usually 5).\n\nBind the socket to address. The socket must not already be bound. (The format\nof address depends on the address family \u2014 refer to the `socket` documentation\nfor more information.) To mark the socket as re-usable (setting the\n`SO_REUSEADDR` option), call the `dispatcher` object\u2019s `set_reuse_addr()`\nmethod.\n\nAccept a connection. The socket must be bound to an address and listening for\nconnections. The return value can be either `None` or a pair `(conn, address)`\nwhere conn is a new socket object usable to send and receive data on the\nconnection, and address is the address bound to the socket on the other end of\nthe connection. When `None` is returned it means the connection didn\u2019t take\nplace, in which case the server should just ignore this event and keep\nlistening for further incoming connections.\n\nClose the socket. All future operations on the socket object will fail. The\nremote end-point will receive no more data (after queued data is flushed).\nSockets are automatically closed when they are garbage-collected.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.accept()", "path": "library/asyncore#asyncore.dispatcher.accept", "type": "Networking & Interprocess Communication", "text": "\nAccept a connection. The socket must be bound to an address and listening for\nconnections. The return value can be either `None` or a pair `(conn, address)`\nwhere conn is a new socket object usable to send and receive data on the\nconnection, and address is the address bound to the socket on the other end of\nthe connection. When `None` is returned it means the connection didn\u2019t take\nplace, in which case the server should just ignore this event and keep\nlistening for further incoming connections.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.bind()", "path": "library/asyncore#asyncore.dispatcher.bind", "type": "Networking & Interprocess Communication", "text": "\nBind the socket to address. The socket must not already be bound. (The format\nof address depends on the address family \u2014 refer to the `socket` documentation\nfor more information.) To mark the socket as re-usable (setting the\n`SO_REUSEADDR` option), call the `dispatcher` object\u2019s `set_reuse_addr()`\nmethod.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.close()", "path": "library/asyncore#asyncore.dispatcher.close", "type": "Networking & Interprocess Communication", "text": "\nClose the socket. All future operations on the socket object will fail. The\nremote end-point will receive no more data (after queued data is flushed).\nSockets are automatically closed when they are garbage-collected.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.connect()", "path": "library/asyncore#asyncore.dispatcher.connect", "type": "Networking & Interprocess Communication", "text": "\nAs with the normal socket object, address is a tuple with the first element\nthe host to connect to, and the second the port number.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.create_socket()", "path": "library/asyncore#asyncore.dispatcher.create_socket", "type": "Networking & Interprocess Communication", "text": "\nThis is identical to the creation of a normal socket, and will use the same\noptions for creation. Refer to the `socket` documentation for information on\ncreating sockets.\n\nChanged in version 3.3: family and type arguments can be omitted.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_accept()", "path": "library/asyncore#asyncore.dispatcher.handle_accept", "type": "Networking & Interprocess Communication", "text": "\nCalled on listening channels (passive openers) when a connection can be\nestablished with a new remote endpoint that has issued a `connect()` call for\nthe local endpoint. Deprecated in version 3.2; use `handle_accepted()`\ninstead.\n\nDeprecated since version 3.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_accepted()", "path": "library/asyncore#asyncore.dispatcher.handle_accepted", "type": "Networking & Interprocess Communication", "text": "\nCalled on listening channels (passive openers) when a connection has been\nestablished with a new remote endpoint that has issued a `connect()` call for\nthe local endpoint. sock is a new socket object usable to send and receive\ndata on the connection, and addr is the address bound to the socket on the\nother end of the connection.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_close()", "path": "library/asyncore#asyncore.dispatcher.handle_close", "type": "Networking & Interprocess Communication", "text": "\nCalled when the socket is closed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_connect()", "path": "library/asyncore#asyncore.dispatcher.handle_connect", "type": "Networking & Interprocess Communication", "text": "\nCalled when the active opener\u2019s socket actually makes a connection. Might send\na \u201cwelcome\u201d banner, or initiate a protocol negotiation with the remote\nendpoint, for example.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_error()", "path": "library/asyncore#asyncore.dispatcher.handle_error", "type": "Networking & Interprocess Communication", "text": "\nCalled when an exception is raised and not otherwise handled. The default\nversion prints a condensed traceback.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_expt()", "path": "library/asyncore#asyncore.dispatcher.handle_expt", "type": "Networking & Interprocess Communication", "text": "\nCalled when there is out of band (OOB) data for a socket connection. This will\nalmost never happen, as OOB is tenuously supported and rarely used.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_read()", "path": "library/asyncore#asyncore.dispatcher.handle_read", "type": "Networking & Interprocess Communication", "text": "\nCalled when the asynchronous loop detects that a `read()` call on the\nchannel\u2019s socket will succeed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.handle_write()", "path": "library/asyncore#asyncore.dispatcher.handle_write", "type": "Networking & Interprocess Communication", "text": "\nCalled when the asynchronous loop detects that a writable socket can be\nwritten. Often this method will implement the necessary buffering for\nperformance. For example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.listen()", "path": "library/asyncore#asyncore.dispatcher.listen", "type": "Networking & Interprocess Communication", "text": "\nListen for connections made to the socket. The backlog argument specifies the\nmaximum number of queued connections and should be at least 1; the maximum\nvalue is system-dependent (usually 5).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.readable()", "path": "library/asyncore#asyncore.dispatcher.readable", "type": "Networking & Interprocess Communication", "text": "\nCalled each time around the asynchronous loop to determine whether a channel\u2019s\nsocket should be added to the list on which read events can occur. The default\nmethod simply returns `True`, indicating that by default, all channels will be\ninterested in read events.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.recv()", "path": "library/asyncore#asyncore.dispatcher.recv", "type": "Networking & Interprocess Communication", "text": "\nRead at most buffer_size bytes from the socket\u2019s remote end-point. An empty\nbytes object implies that the channel has been closed from the other end.\n\nNote that `recv()` may raise `BlockingIOError` , even though `select.select()`\nor `select.poll()` has reported the socket ready for reading.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.send()", "path": "library/asyncore#asyncore.dispatcher.send", "type": "Networking & Interprocess Communication", "text": "\nSend data to the remote end-point of the socket.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher.writable()", "path": "library/asyncore#asyncore.dispatcher.writable", "type": "Networking & Interprocess Communication", "text": "\nCalled each time around the asynchronous loop to determine whether a channel\u2019s\nsocket should be added to the list on which write events can occur. The\ndefault method simply returns `True`, indicating that by default, all channels\nwill be interested in write events.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.dispatcher_with_send", "path": "library/asyncore#asyncore.dispatcher_with_send", "type": "Networking & Interprocess Communication", "text": "\nA `dispatcher` subclass which adds simple buffered output capability, useful\nfor simple clients. For more sophisticated usage use `asynchat.async_chat`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.file_dispatcher", "path": "library/asyncore#asyncore.file_dispatcher", "type": "Networking & Interprocess Communication", "text": "\nA file_dispatcher takes a file descriptor or file object along with an\noptional map argument and wraps it for use with the `poll()` or `loop()`\nfunctions. If provided a file object or anything with a `fileno()` method,\nthat method will be called and passed to the `file_wrapper` constructor.\n\nAvailability: Unix.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.file_wrapper", "path": "library/asyncore#asyncore.file_wrapper", "type": "Networking & Interprocess Communication", "text": "\nA file_wrapper takes an integer file descriptor and calls `os.dup()` to\nduplicate the handle so that the original handle may be closed independently\nof the file_wrapper. This class implements sufficient methods to emulate a\nsocket for use by the `file_dispatcher` class.\n\nAvailability: Unix.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "asyncore.loop()", "path": "library/asyncore#asyncore.loop", "type": "Networking & Interprocess Communication", "text": "\nEnter a polling loop that terminates after count passes or all open channels\nhave been closed. All arguments are optional. The count parameter defaults to\n`None`, resulting in the loop terminating only when all channels have been\nclosed. The timeout argument sets the timeout parameter for the appropriate\n`select()` or `poll()` call, measured in seconds; the default is 30 seconds.\nThe use_poll parameter, if true, indicates that `poll()` should be used in\npreference to `select()` (the default is `False`).\n\nThe map parameter is a dictionary whose items are the channels to watch. As\nchannels are closed they are deleted from their map. If map is omitted, a\nglobal map is used. Channels (instances of `asyncore.dispatcher`,\n`asynchat.async_chat` and subclasses thereof) can freely be mixed in the map.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "atexit", "path": "library/atexit", "type": "Runtime", "text": "\nThe `atexit` module defines functions to register and unregister cleanup\nfunctions. Functions thus registered are automatically executed upon normal\ninterpreter termination. `atexit` runs these functions in the reverse order in\nwhich they were registered; if you register `A`, `B`, and `C`, at interpreter\ntermination time they will be run in the order `C`, `B`, `A`.\n\nNote: The functions registered via this module are not called when the program\nis killed by a signal not handled by Python, when a Python fatal internal\nerror is detected, or when `os._exit()` is called.\n\nChanged in version 3.7: When used with C-API subinterpreters, registered\nfunctions are local to the interpreter they were registered in.\n\nRegister func as a function to be executed at termination. Any optional\narguments that are to be passed to func must be passed as arguments to\n`register()`. It is possible to register the same function and arguments more\nthan once.\n\nAt normal program termination (for instance, if `sys.exit()` is called or the\nmain module\u2019s execution completes), all functions registered are called in\nlast in, first out order. The assumption is that lower level modules will\nnormally be imported before higher level modules and thus must be cleaned up\nlater.\n\nIf an exception is raised during execution of the exit handlers, a traceback\nis printed (unless `SystemExit` is raised) and the exception information is\nsaved. After all exit handlers have had a chance to run the last exception to\nbe raised is re-raised.\n\nThis function returns func, which makes it possible to use it as a decorator.\n\nRemove func from the list of functions to be run at interpreter shutdown.\nAfter calling `unregister()`, func is guaranteed not to be called when the\ninterpreter shuts down, even if it was registered more than once.\n`unregister()` silently does nothing if func was not previously registered.\n\nSee also\n\nUseful example of `atexit` to read and write `readline` history files.\n\nThe following simple example demonstrates how a module can initialize a\ncounter from a file when it is imported and save the counter\u2019s updated value\nautomatically when the program terminates without relying on the application\nmaking an explicit call into this module at termination.\n\nPositional and keyword arguments may also be passed to `register()` to be\npassed along to the registered function when it is called:\n\nUsage as a decorator:\n\nThis only works with functions that can be called without arguments.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "atexit.register()", "path": "library/atexit#atexit.register", "type": "Runtime", "text": "\nRegister func as a function to be executed at termination. Any optional\narguments that are to be passed to func must be passed as arguments to\n`register()`. It is possible to register the same function and arguments more\nthan once.\n\nAt normal program termination (for instance, if `sys.exit()` is called or the\nmain module\u2019s execution completes), all functions registered are called in\nlast in, first out order. The assumption is that lower level modules will\nnormally be imported before higher level modules and thus must be cleaned up\nlater.\n\nIf an exception is raised during execution of the exit handlers, a traceback\nis printed (unless `SystemExit` is raised) and the exception information is\nsaved. After all exit handlers have had a chance to run the last exception to\nbe raised is re-raised.\n\nThis function returns func, which makes it possible to use it as a decorator.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "atexit.unregister()", "path": "library/atexit#atexit.unregister", "type": "Runtime", "text": "\nRemove func from the list of functions to be run at interpreter shutdown.\nAfter calling `unregister()`, func is guaranteed not to be called when the\ninterpreter shuts down, even if it was registered more than once.\n`unregister()` silently does nothing if func was not previously registered.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "AttributeError", "path": "library/exceptions#AttributeError", "type": "Built-in Exceptions", "text": "\nRaised when an attribute reference (see Attribute references) or assignment\nfails. (When an object does not support attribute references or attribute\nassignments at all, `TypeError` is raised.)\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop", "path": "library/audioop", "type": "Multimedia", "text": "\nThe `audioop` module contains some useful operations on sound fragments. It\noperates on sound fragments consisting of signed integer samples 8, 16, 24 or\n32 bits wide, stored in bytes-like objects. All scalar items are integers,\nunless specified otherwise.\n\nChanged in version 3.4: Support for 24-bit samples was added. All functions\nnow accept any bytes-like object. String input now results in an immediate\nerror.\n\nThis module provides support for a-LAW, u-LAW and Intel/DVI ADPCM encodings.\n\nA few of the more complicated operations only take 16-bit samples, otherwise\nthe sample size (in bytes) is always a parameter of the operation.\n\nThe module defines the following variables and functions:\n\nThis exception is raised on all errors, such as unknown number of bytes per\nsample, etc.\n\nReturn a fragment which is the addition of the two samples passed as\nparameters. width is the sample width in bytes, either `1`, `2`, `3` or `4`.\nBoth fragments should have the same length. Samples are truncated in case of\noverflow.\n\nDecode an Intel/DVI ADPCM coded fragment to a linear fragment. See the\ndescription of `lin2adpcm()` for details on ADPCM coding. Return a tuple\n`(sample, newstate)` where the sample has the width specified in width.\n\nConvert sound fragments in a-LAW encoding to linearly encoded sound fragments.\na-LAW encoding always uses 8 bits samples, so width refers only to the sample\nwidth of the output fragment here.\n\nReturn the average over all samples in the fragment.\n\nReturn the average peak-peak value over all samples in the fragment. No\nfiltering is done, so the usefulness of this routine is questionable.\n\nReturn a fragment that is the original fragment with a bias added to each\nsample. Samples wrap around in case of overflow.\n\n\u201cByteswap\u201d all samples in a fragment and returns the modified fragment.\nConverts big-endian samples to little-endian and vice versa.\n\nNew in version 3.4.\n\nReturn the number of zero crossings in the fragment passed as an argument.\n\nReturn a factor F such that `rms(add(fragment, mul(reference, -F)))` is\nminimal, i.e., return the factor with which you should multiply reference to\nmake it match as well as possible to fragment. The fragments should both\ncontain 2-byte samples.\n\nThe time taken by this routine is proportional to `len(fragment)`.\n\nTry to match reference as well as possible to a portion of fragment (which\nshould be the longer fragment). This is (conceptually) done by taking slices\nout of fragment, using `findfactor()` to compute the best match, and\nminimizing the result. The fragments should both contain 2-byte samples.\nReturn a tuple `(offset, factor)` where offset is the (integer) offset into\nfragment where the optimal match started and factor is the (floating-point)\nfactor as per `findfactor()`.\n\nSearch fragment for a slice of length length samples (not bytes!) with maximum\nenergy, i.e., return i for which `rms(fragment[i*2:(i+length)*2])` is maximal.\nThe fragments should both contain 2-byte samples.\n\nThe routine takes time proportional to `len(fragment)`.\n\nReturn the value of sample index from the fragment.\n\nConvert samples to 4 bit Intel/DVI ADPCM encoding. ADPCM coding is an adaptive\ncoding scheme, whereby each 4 bit number is the difference between one sample\nand the next, divided by a (varying) step. The Intel/DVI ADPCM algorithm has\nbeen selected for use by the IMA, so it may well become a standard.\n\nstate is a tuple containing the state of the coder. The coder returns a tuple\n`(adpcmfrag, newstate)`, and the newstate should be passed to the next call of\n`lin2adpcm()`. In the initial call, `None` can be passed as the state.\nadpcmfrag is the ADPCM coded fragment packed 2 4-bit values per byte.\n\nConvert samples in the audio fragment to a-LAW encoding and return this as a\nbytes object. a-LAW is an audio encoding format whereby you get a dynamic\nrange of about 13 bits using only 8 bit samples. It is used by the Sun audio\nhardware, among others.\n\nConvert samples between 1-, 2-, 3- and 4-byte formats.\n\nNote\n\nIn some audio formats, such as .WAV files, 16, 24 and 32 bit samples are\nsigned, but 8 bit samples are unsigned. So when converting to 8 bit wide\nsamples for these formats, you need to also add 128 to the result:\n\nThe same, in reverse, has to be applied when converting from 8 to 16, 24 or 32\nbit width samples.\n\nConvert samples in the audio fragment to u-LAW encoding and return this as a\nbytes object. u-LAW is an audio encoding format whereby you get a dynamic\nrange of about 14 bits using only 8 bit samples. It is used by the Sun audio\nhardware, among others.\n\nReturn the maximum of the absolute value of all samples in a fragment.\n\nReturn the maximum peak-peak value in the sound fragment.\n\nReturn a tuple consisting of the minimum and maximum values of all samples in\nthe sound fragment.\n\nReturn a fragment that has all samples in the original fragment multiplied by\nthe floating-point value factor. Samples are truncated in case of overflow.\n\nConvert the frame rate of the input fragment.\n\nstate is a tuple containing the state of the converter. The converter returns\na tuple `(newfragment, newstate)`, and newstate should be passed to the next\ncall of `ratecv()`. The initial call should pass `None` as the state.\n\nThe weightA and weightB arguments are parameters for a simple digital filter\nand default to `1` and `0` respectively.\n\nReverse the samples in a fragment and returns the modified fragment.\n\nReturn the root-mean-square of the fragment, i.e. `sqrt(sum(S_i^2)/n)`.\n\nThis is a measure of the power in an audio signal.\n\nConvert a stereo fragment to a mono fragment. The left channel is multiplied\nby lfactor and the right channel by rfactor before adding the two channels to\ngive a mono signal.\n\nGenerate a stereo fragment from a mono fragment. Each pair of samples in the\nstereo fragment are computed from the mono sample, whereby left channel\nsamples are multiplied by lfactor and right channel samples by rfactor.\n\nConvert sound fragments in u-LAW encoding to linearly encoded sound fragments.\nu-LAW encoding always uses 8 bits samples, so width refers only to the sample\nwidth of the output fragment here.\n\nNote that operations such as `mul()` or `max()` make no distinction between\nmono and stereo fragments, i.e. all samples are treated equal. If this is a\nproblem the stereo fragment should be split into two mono fragments first and\nrecombined later. Here is an example of how to do that:\n\nIf you use the ADPCM coder to build network packets and you want your protocol\nto be stateless (i.e. to be able to tolerate packet loss) you should not only\ntransmit the data but also the state. Note that you should send the initial\nstate (the one you passed to `lin2adpcm()`) along to the decoder, not the\nfinal state (as returned by the coder). If you want to use `struct.Struct` to\nstore the state in binary you can code the first element (the predicted value)\nin 16 bits and the second (the delta index) in 8.\n\nThe ADPCM coders have never been tried against other ADPCM coders, only\nagainst themselves. It could well be that I misinterpreted the standards in\nwhich case they will not be interoperable with the respective standards.\n\nThe `find*()` routines might look a bit funny at first sight. They are\nprimarily meant to do echo cancellation. A reasonably fast way to do this is\nto pick the most energetic piece of the output sample, locate that in the\ninput sample and subtract the whole output sample from the input sample:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.add()", "path": "library/audioop#audioop.add", "type": "Multimedia", "text": "\nReturn a fragment which is the addition of the two samples passed as\nparameters. width is the sample width in bytes, either `1`, `2`, `3` or `4`.\nBoth fragments should have the same length. Samples are truncated in case of\noverflow.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.adpcm2lin()", "path": "library/audioop#audioop.adpcm2lin", "type": "Multimedia", "text": "\nDecode an Intel/DVI ADPCM coded fragment to a linear fragment. See the\ndescription of `lin2adpcm()` for details on ADPCM coding. Return a tuple\n`(sample, newstate)` where the sample has the width specified in width.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.alaw2lin()", "path": "library/audioop#audioop.alaw2lin", "type": "Multimedia", "text": "\nConvert sound fragments in a-LAW encoding to linearly encoded sound fragments.\na-LAW encoding always uses 8 bits samples, so width refers only to the sample\nwidth of the output fragment here.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.avg()", "path": "library/audioop#audioop.avg", "type": "Multimedia", "text": "\nReturn the average over all samples in the fragment.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.avgpp()", "path": "library/audioop#audioop.avgpp", "type": "Multimedia", "text": "\nReturn the average peak-peak value over all samples in the fragment. No\nfiltering is done, so the usefulness of this routine is questionable.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.bias()", "path": "library/audioop#audioop.bias", "type": "Multimedia", "text": "\nReturn a fragment that is the original fragment with a bias added to each\nsample. Samples wrap around in case of overflow.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.byteswap()", "path": "library/audioop#audioop.byteswap", "type": "Multimedia", "text": "\n\u201cByteswap\u201d all samples in a fragment and returns the modified fragment.\nConverts big-endian samples to little-endian and vice versa.\n\nNew in version 3.4.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.cross()", "path": "library/audioop#audioop.cross", "type": "Multimedia", "text": "\nReturn the number of zero crossings in the fragment passed as an argument.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.error", "path": "library/audioop#audioop.error", "type": "Multimedia", "text": "\nThis exception is raised on all errors, such as unknown number of bytes per\nsample, etc.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.findfactor()", "path": "library/audioop#audioop.findfactor", "type": "Multimedia", "text": "\nReturn a factor F such that `rms(add(fragment, mul(reference, -F)))` is\nminimal, i.e., return the factor with which you should multiply reference to\nmake it match as well as possible to fragment. The fragments should both\ncontain 2-byte samples.\n\nThe time taken by this routine is proportional to `len(fragment)`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.findfit()", "path": "library/audioop#audioop.findfit", "type": "Multimedia", "text": "\nTry to match reference as well as possible to a portion of fragment (which\nshould be the longer fragment). This is (conceptually) done by taking slices\nout of fragment, using `findfactor()` to compute the best match, and\nminimizing the result. The fragments should both contain 2-byte samples.\nReturn a tuple `(offset, factor)` where offset is the (integer) offset into\nfragment where the optimal match started and factor is the (floating-point)\nfactor as per `findfactor()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.findmax()", "path": "library/audioop#audioop.findmax", "type": "Multimedia", "text": "\nSearch fragment for a slice of length length samples (not bytes!) with maximum\nenergy, i.e., return i for which `rms(fragment[i*2:(i+length)*2])` is maximal.\nThe fragments should both contain 2-byte samples.\n\nThe routine takes time proportional to `len(fragment)`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.getsample()", "path": "library/audioop#audioop.getsample", "type": "Multimedia", "text": "\nReturn the value of sample index from the fragment.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.lin2adpcm()", "path": "library/audioop#audioop.lin2adpcm", "type": "Multimedia", "text": "\nConvert samples to 4 bit Intel/DVI ADPCM encoding. ADPCM coding is an adaptive\ncoding scheme, whereby each 4 bit number is the difference between one sample\nand the next, divided by a (varying) step. The Intel/DVI ADPCM algorithm has\nbeen selected for use by the IMA, so it may well become a standard.\n\nstate is a tuple containing the state of the coder. The coder returns a tuple\n`(adpcmfrag, newstate)`, and the newstate should be passed to the next call of\n`lin2adpcm()`. In the initial call, `None` can be passed as the state.\nadpcmfrag is the ADPCM coded fragment packed 2 4-bit values per byte.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.lin2alaw()", "path": "library/audioop#audioop.lin2alaw", "type": "Multimedia", "text": "\nConvert samples in the audio fragment to a-LAW encoding and return this as a\nbytes object. a-LAW is an audio encoding format whereby you get a dynamic\nrange of about 13 bits using only 8 bit samples. It is used by the Sun audio\nhardware, among others.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.lin2lin()", "path": "library/audioop#audioop.lin2lin", "type": "Multimedia", "text": "\nConvert samples between 1-, 2-, 3- and 4-byte formats.\n\nNote\n\nIn some audio formats, such as .WAV files, 16, 24 and 32 bit samples are\nsigned, but 8 bit samples are unsigned. So when converting to 8 bit wide\nsamples for these formats, you need to also add 128 to the result:\n\nThe same, in reverse, has to be applied when converting from 8 to 16, 24 or 32\nbit width samples.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.lin2ulaw()", "path": "library/audioop#audioop.lin2ulaw", "type": "Multimedia", "text": "\nConvert samples in the audio fragment to u-LAW encoding and return this as a\nbytes object. u-LAW is an audio encoding format whereby you get a dynamic\nrange of about 14 bits using only 8 bit samples. It is used by the Sun audio\nhardware, among others.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.max()", "path": "library/audioop#audioop.max", "type": "Multimedia", "text": "\nReturn the maximum of the absolute value of all samples in a fragment.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.maxpp()", "path": "library/audioop#audioop.maxpp", "type": "Multimedia", "text": "\nReturn the maximum peak-peak value in the sound fragment.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.minmax()", "path": "library/audioop#audioop.minmax", "type": "Multimedia", "text": "\nReturn a tuple consisting of the minimum and maximum values of all samples in\nthe sound fragment.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.mul()", "path": "library/audioop#audioop.mul", "type": "Multimedia", "text": "\nReturn a fragment that has all samples in the original fragment multiplied by\nthe floating-point value factor. Samples are truncated in case of overflow.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.ratecv()", "path": "library/audioop#audioop.ratecv", "type": "Multimedia", "text": "\nConvert the frame rate of the input fragment.\n\nstate is a tuple containing the state of the converter. The converter returns\na tuple `(newfragment, newstate)`, and newstate should be passed to the next\ncall of `ratecv()`. The initial call should pass `None` as the state.\n\nThe weightA and weightB arguments are parameters for a simple digital filter\nand default to `1` and `0` respectively.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.reverse()", "path": "library/audioop#audioop.reverse", "type": "Multimedia", "text": "\nReverse the samples in a fragment and returns the modified fragment.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.rms()", "path": "library/audioop#audioop.rms", "type": "Multimedia", "text": "\nReturn the root-mean-square of the fragment, i.e. `sqrt(sum(S_i^2)/n)`.\n\nThis is a measure of the power in an audio signal.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.tomono()", "path": "library/audioop#audioop.tomono", "type": "Multimedia", "text": "\nConvert a stereo fragment to a mono fragment. The left channel is multiplied\nby lfactor and the right channel by rfactor before adding the two channels to\ngive a mono signal.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.tostereo()", "path": "library/audioop#audioop.tostereo", "type": "Multimedia", "text": "\nGenerate a stereo fragment from a mono fragment. Each pair of samples in the\nstereo fragment are computed from the mono sample, whereby left channel\nsamples are multiplied by lfactor and right channel samples by rfactor.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "audioop.ulaw2lin()", "path": "library/audioop#audioop.ulaw2lin", "type": "Multimedia", "text": "\nConvert sound fragments in u-LAW encoding to linearly encoded sound fragments.\nu-LAW encoding always uses 8 bits samples, so width refers only to the sample\nwidth of the output fragment here.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "Audit events table", "path": "library/audit_events", "type": "Debugging & Profiling", "text": "\nThis table contains all events raised by `sys.audit()` or `PySys_Audit()`\ncalls throughout the CPython runtime and the standard library. These calls\nwere added in 3.8.0 or later.\n\nSee `sys.addaudithook()` and `PySys_AddAuditHook()` for information on\nhandling these events.\n\nCPython implementation detail: This table is generated from the CPython\ndocumentation, and may not represent events raised by other implementations.\nSee your runtime specific documentation for actual events raised.\n\nAudit event\n\nArguments\n\nReferences\n\narray.__new__\n\n`typecode`, `initializer`\n\n[1]\n\nbuiltins.breakpoint\n\n`breakpointhook`\n\n[1]\n\nbuiltins.id\n\n`id`\n\n[1]\n\nbuiltins.input\n\n`prompt`\n\n[1]\n\nbuiltins.input/result\n\n`result`\n\n[1]\n\ncode.__new__\n\n`code`, `filename`, `name`, `argcount`, `posonlyargcount`, `kwonlyargcount`,\n`nlocals`, `stacksize`, `flags`\n\n[1]\n\ncompile\n\n`source`, `filename`\n\n[1]\n\ncpython.PyInterpreterState_Clear\n\n[1]\n\ncpython.PyInterpreterState_New\n\n[1]\n\ncpython._PySys_ClearAuditHooks\n\n[1]\n\ncpython.run_command\n\n`command`\n\n[1]\n\ncpython.run_file\n\n`filename`\n\n[1]\n\ncpython.run_interactivehook\n\n`hook`\n\n[1]\n\ncpython.run_module\n\n`module-name`\n\n[1]\n\ncpython.run_startup\n\n`filename`\n\n[1]\n\ncpython.run_stdin\n\n[1]\n\nctypes.addressof\n\n`obj`\n\n[1]\n\nctypes.call_function\n\n`func_pointer`, `arguments`\n\n[1]\n\nctypes.cdata\n\n`address`\n\n[1]\n\nctypes.cdata/buffer\n\n`pointer`, `size`, `offset`\n\n[1][2]\n\nctypes.create_string_buffer\n\n`init`, `size`\n\n[1]\n\nctypes.create_unicode_buffer\n\n`init`, `size`\n\n[1]\n\nctypes.dlopen\n\n`name`\n\n[1]\n\nctypes.dlsym\n\n`library`, `name`\n\n[1]\n\nctypes.dlsym/handle\n\n`handle`, `name`\n\n[1]\n\nctypes.get_errno\n\n[1]\n\nctypes.get_last_error\n\n[1]\n\nctypes.seh_exception\n\n`code`\n\n[1]\n\nctypes.set_errno\n\n`errno`\n\n[1]\n\nctypes.set_last_error\n\n`error`\n\n[1]\n\nctypes.string_at\n\n`address`, `size`\n\n[1]\n\nctypes.wstring_at\n\n`address`, `size`\n\n[1]\n\nensurepip.bootstrap\n\n`root`\n\n[1]\n\nexec\n\n`code_object`\n\n[1][2]\n\nfcntl.fcntl\n\n`fd`, `cmd`, `arg`\n\n[1]\n\nfcntl.flock\n\n`fd`, `operation`\n\n[1]\n\nfcntl.ioctl\n\n`fd`, `request`, `arg`\n\n[1]\n\nfcntl.lockf\n\n`fd`, `cmd`, `len`, `start`, `whence`\n\n[1]\n\nftplib.connect\n\n`self`, `host`, `port`\n\n[1]\n\nftplib.sendcmd\n\n`self`, `cmd`\n\n[1][2]\n\nfunction.__new__\n\n`code`\n\n[1]\n\ngc.get_objects\n\n`generation`\n\n[1]\n\ngc.get_referents\n\n`objs`\n\n[1]\n\ngc.get_referrers\n\n`objs`\n\n[1]\n\nglob.glob\n\n`pathname`, `recursive`\n\n[1][2]\n\nimaplib.open\n\n`self`, `host`, `port`\n\n[1]\n\nimaplib.send\n\n`self`, `data`\n\n[1]\n\nimport\n\n`module`, `filename`, `sys.path`, `sys.meta_path`, `sys.path_hooks`\n\n[1]\n\nmmap.__new__\n\n`fileno`, `length`, `access`, `offset`\n\n[1]\n\nmsvcrt.get_osfhandle\n\n`fd`\n\n[1]\n\nmsvcrt.locking\n\n`fd`, `mode`, `nbytes`\n\n[1]\n\nmsvcrt.open_osfhandle\n\n`handle`, `flags`\n\n[1]\n\nnntplib.connect\n\n`self`, `host`, `port`\n\n[1][2]\n\nnntplib.putline\n\n`self`, `line`\n\n[1][2]\n\nobject.__delattr__\n\n`obj`, `name`\n\n[1]\n\nobject.__getattr__\n\n`obj`, `name`\n\n[1]\n\nobject.__setattr__\n\n`obj`, `name`, `value`\n\n[1]\n\nopen\n\n`file`, `mode`, `flags`\n\n[1][2][3]\n\nos.add_dll_directory\n\n`path`\n\n[1]\n\nos.chdir\n\n`path`\n\n[1][2]\n\nos.chflags\n\n`path`, `flags`\n\n[1][2]\n\nos.chmod\n\n`path`, `mode`, `dir_fd`\n\n[1][2][3]\n\nos.chown\n\n`path`, `uid`, `gid`, `dir_fd`\n\n[1][2][3]\n\nos.exec\n\n`path`, `args`, `env`\n\n[1]\n\nos.fork\n\n[1]\n\nos.forkpty\n\n[1]\n\nos.fwalk\n\n`top`, `topdown`, `onerror`, `follow_symlinks`, `dir_fd`\n\n[1]\n\nos.getxattr\n\n`path`, `attribute`\n\n[1]\n\nos.kill\n\n`pid`, `sig`\n\n[1]\n\nos.killpg\n\n`pgid`, `sig`\n\n[1]\n\nos.link\n\n`src`, `dst`, `src_dir_fd`, `dst_dir_fd`\n\n[1]\n\nos.listdir\n\n`path`\n\n[1]\n\nos.listxattr\n\n`path`\n\n[1]\n\nos.lockf\n\n`fd`, `cmd`, `len`\n\n[1]\n\nos.mkdir\n\n`path`, `mode`, `dir_fd`\n\n[1][2]\n\nos.posix_spawn\n\n`path`, `argv`, `env`\n\n[1][2]\n\nos.putenv\n\n`key`, `value`\n\n[1]\n\nos.remove\n\n`path`, `dir_fd`\n\n[1][2][3]\n\nos.removexattr\n\n`path`, `attribute`\n\n[1]\n\nos.rename\n\n`src`, `dst`, `src_dir_fd`, `dst_dir_fd`\n\n[1][2][3]\n\nos.rmdir\n\n`path`, `dir_fd`\n\n[1]\n\nos.scandir\n\n`path`\n\n[1]\n\nos.setxattr\n\n`path`, `attribute`, `value`, `flags`\n\n[1]\n\nos.spawn\n\n`mode`, `path`, `args`, `env`\n\n[1]\n\nos.startfile\n\n`path`, `operation`\n\n[1]\n\nos.symlink\n\n`src`, `dst`, `dir_fd`\n\n[1]\n\nos.system\n\n`command`\n\n[1]\n\nos.truncate\n\n`fd`, `length`\n\n[1][2]\n\nos.unsetenv\n\n`key`\n\n[1]\n\nos.utime\n\n`path`, `times`, `ns`, `dir_fd`\n\n[1]\n\nos.walk\n\n`top`, `topdown`, `onerror`, `followlinks`\n\n[1]\n\npathlib.Path.glob\n\n`self`, `pattern`\n\n[1]\n\npathlib.Path.rglob\n\n`self`, `pattern`\n\n[1]\n\npdb.Pdb\n\n[1]\n\npickle.find_class\n\n`module`, `name`\n\n[1]\n\npoplib.connect\n\n`self`, `host`, `port`\n\n[1][2]\n\npoplib.putline\n\n`self`, `line`\n\n[1][2]\n\npty.spawn\n\n`argv`\n\n[1]\n\nresource.prlimit\n\n`pid`, `resource`, `limits`\n\n[1]\n\nresource.setrlimit\n\n`resource`, `limits`\n\n[1]\n\nsetopencodehook\n\n[1]\n\nshutil.chown\n\n`path`, `user`, `group`\n\n[1]\n\nshutil.copyfile\n\n`src`, `dst`\n\n[1][2][3]\n\nshutil.copymode\n\n`src`, `dst`\n\n[1][2]\n\nshutil.copystat\n\n`src`, `dst`\n\n[1][2]\n\nshutil.copytree\n\n`src`, `dst`\n\n[1]\n\nshutil.make_archive\n\n`base_name`, `format`, `root_dir`, `base_dir`\n\n[1]\n\nshutil.move\n\n`src`, `dst`\n\n[1]\n\nshutil.rmtree\n\n`path`\n\n[1]\n\nshutil.unpack_archive\n\n`filename`, `extract_dir`, `format`\n\n[1]\n\nsignal.pthread_kill\n\n`thread_id`, `signalnum`\n\n[1]\n\nsmtplib.connect\n\n`self`, `host`, `port`\n\n[1]\n\nsmtplib.send\n\n`self`, `data`\n\n[1]\n\nsocket.__new__\n\n`self`, `family`, `type`, `protocol`\n\n[1]\n\nsocket.bind\n\n`self`, `address`\n\n[1]\n\nsocket.connect\n\n`self`, `address`\n\n[1][2]\n\nsocket.getaddrinfo\n\n`host`, `port`, `family`, `type`, `protocol`\n\n[1]\n\nsocket.gethostbyaddr\n\n`ip_address`\n\n[1]\n\nsocket.gethostbyname\n\n`hostname`\n\n[1][2]\n\nsocket.gethostname\n\n[1]\n\nsocket.getnameinfo\n\n`sockaddr`\n\n[1]\n\nsocket.getservbyname\n\n`servicename`, `protocolname`\n\n[1]\n\nsocket.getservbyport\n\n`port`, `protocolname`\n\n[1]\n\nsocket.sendmsg\n\n`self`, `address`\n\n[1]\n\nsocket.sendto\n\n`self`, `address`\n\n[1]\n\nsocket.sethostname\n\n`name`\n\n[1]\n\nsqlite3.connect\n\n`database`\n\n[1]\n\nsubprocess.Popen\n\n`executable`, `args`, `cwd`, `env`\n\n[1]\n\nsys._current_frames\n\n[1]\n\nsys._getframe\n\n[1]\n\nsys.addaudithook\n\n[1][2]\n\nsys.excepthook\n\n`hook`, `type`, `value`, `traceback`\n\n[1]\n\nsys.set_asyncgen_hooks_finalizer\n\n[1]\n\nsys.set_asyncgen_hooks_firstiter\n\n[1]\n\nsys.setprofile\n\n[1]\n\nsys.settrace\n\n[1]\n\nsys.unraisablehook\n\n`hook`, `unraisable`\n\n[1]\n\nsyslog.closelog\n\n[1]\n\nsyslog.openlog\n\n`ident`, `logoption`, `facility`\n\n[1]\n\nsyslog.setlogmask\n\n`maskpri`\n\n[1]\n\nsyslog.syslog\n\n`priority`, `message`\n\n[1]\n\ntelnetlib.Telnet.open\n\n`self`, `host`, `port`\n\n[1]\n\ntelnetlib.Telnet.write\n\n`self`, `buffer`\n\n[1]\n\ntempfile.mkdtemp\n\n`fullpath`\n\n[1][2]\n\ntempfile.mkstemp\n\n`fullpath`\n\n[1][2][3]\n\nurllib.Request\n\n`fullurl`, `data`, `headers`, `method`\n\n[1]\n\nwebbrowser.open\n\n`url`\n\n[1]\n\nwinreg.ConnectRegistry\n\n`computer_name`, `key`\n\n[1]\n\nwinreg.CreateKey\n\n`key`, `sub_key`, `access`\n\n[1][2]\n\nwinreg.DeleteKey\n\n`key`, `sub_key`, `access`\n\n[1][2]\n\nwinreg.DeleteValue\n\n`key`, `value`\n\n[1]\n\nwinreg.DisableReflectionKey\n\n`key`\n\n[1]\n\nwinreg.EnableReflectionKey\n\n`key`\n\n[1]\n\nwinreg.EnumKey\n\n`key`, `index`\n\n[1]\n\nwinreg.EnumValue\n\n`key`, `index`\n\n[1]\n\nwinreg.ExpandEnvironmentStrings\n\n`str`\n\n[1]\n\nwinreg.LoadKey\n\n`key`, `sub_key`, `file_name`\n\n[1]\n\nwinreg.OpenKey\n\n`key`, `sub_key`, `access`\n\n[1]\n\nwinreg.OpenKey/result\n\n`key`\n\n[1][2][3]\n\nwinreg.PyHKEY.Detach\n\n`key`\n\n[1]\n\nwinreg.QueryInfoKey\n\n`key`\n\n[1]\n\nwinreg.QueryReflectionKey\n\n`key`\n\n[1]\n\nwinreg.QueryValue\n\n`key`, `sub_key`, `value_name`\n\n[1][2]\n\nwinreg.SaveKey\n\n`key`, `file_name`\n\n[1]\n\nwinreg.SetValue\n\n`key`, `sub_key`, `type`, `value`\n\n[1][2]\n\nThe following events are raised internally and do not correspond to any public\nAPI of CPython:\n\nAudit event\n\nArguments\n\n_winapi.CreateFile\n\n`file_name`, `desired_access`, `share_mode`, `creation_disposition`,\n`flags_and_attributes`\n\n_winapi.CreateJunction\n\n`src_path`, `dst_path`\n\n_winapi.CreateNamedPipe\n\n`name`, `open_mode`, `pipe_mode`\n\n_winapi.CreatePipe\n\n_winapi.CreateProcess\n\n`application_name`, `command_line`, `current_directory`\n\n_winapi.OpenProcess\n\n`process_id`, `desired_access`\n\n_winapi.TerminateProcess\n\n`handle`, `exit_code`\n\nctypes.PyObj_FromPtr\n\n`obj`\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64", "path": "library/base64", "type": "Internet Data", "text": "\nSource code: Lib/base64.py\n\nThis module provides functions for encoding binary data to printable ASCII\ncharacters and decoding such encodings back to binary data. It provides\nencoding and decoding functions for the encodings specified in RFC 3548, which\ndefines the Base16, Base32, and Base64 algorithms, and for the de-facto\nstandard Ascii85 and Base85 encodings.\n\nThe RFC 3548 encodings are suitable for encoding binary data so that it can\nsafely sent by email, used as parts of URLs, or included as part of an HTTP\nPOST request. The encoding algorithm is not the same as the uuencode program.\n\nThere are two interfaces provided by this module. The modern interface\nsupports encoding bytes-like objects to ASCII `bytes`, and decoding bytes-like\nobjects or strings containing ASCII to `bytes`. Both base-64 alphabets defined\nin RFC 3548 (normal, and URL- and filesystem-safe) are supported.\n\nThe legacy interface does not support decoding from strings, but it does\nprovide functions for encoding and decoding to and from file objects. It only\nsupports the Base64 standard alphabet, and it adds newlines every 76\ncharacters as per RFC 2045. Note that if you are looking for RFC 2045 support\nyou probably want to be looking at the `email` package instead.\n\nChanged in version 3.3: ASCII-only Unicode strings are now accepted by the\ndecoding functions of the modern interface.\n\nChanged in version 3.4: Any bytes-like objects are now accepted by all\nencoding and decoding functions in this module. Ascii85/Base85 support added.\n\nThe modern interface provides:\n\nEncode the bytes-like object s using Base64 and return the encoded `bytes`.\n\nOptional altchars must be a bytes-like object of at least length 2 (additional\ncharacters are ignored) which specifies an alternative alphabet for the `+`\nand `/` characters. This allows an application to e.g. generate URL or\nfilesystem safe Base64 strings. The default is `None`, for which the standard\nBase64 alphabet is used.\n\nDecode the Base64 encoded bytes-like object or ASCII string s and return the\ndecoded `bytes`.\n\nOptional altchars must be a bytes-like object or ASCII string of at least\nlength 2 (additional characters are ignored) which specifies the alternative\nalphabet used instead of the `+` and `/` characters.\n\nA `binascii.Error` exception is raised if s is incorrectly padded.\n\nIf validate is `False` (the default), characters that are neither in the\nnormal base-64 alphabet nor the alternative alphabet are discarded prior to\nthe padding check. If validate is `True`, these non-alphabet characters in the\ninput result in a `binascii.Error`.\n\nEncode bytes-like object s using the standard Base64 alphabet and return the\nencoded `bytes`.\n\nDecode bytes-like object or ASCII string s using the standard Base64 alphabet\nand return the decoded `bytes`.\n\nEncode bytes-like object s using the URL- and filesystem-safe alphabet, which\nsubstitutes `-` instead of `+` and `_` instead of `/` in the standard Base64\nalphabet, and return the encoded `bytes`. The result can still contain `=`.\n\nDecode bytes-like object or ASCII string s using the URL- and filesystem-safe\nalphabet, which substitutes `-` instead of `+` and `_` instead of `/` in the\nstandard Base64 alphabet, and return the decoded `bytes`.\n\nEncode the bytes-like object s using Base32 and return the encoded `bytes`.\n\nDecode the Base32 encoded bytes-like object or ASCII string s and return the\ndecoded `bytes`.\n\nOptional casefold is a flag specifying whether a lowercase alphabet is\nacceptable as input. For security purposes, the default is `False`.\n\nRFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O\n(oh), and for optional mapping of the digit 1 (one) to either the letter I\n(eye) or letter L (el). The optional argument map01 when not `None`, specifies\nwhich letter the digit 1 should be mapped to (when map01 is not `None`, the\ndigit 0 is always mapped to the letter O). For security purposes the default\nis `None`, so that 0 and 1 are not allowed in the input.\n\nA `binascii.Error` is raised if s is incorrectly padded or if there are non-\nalphabet characters present in the input.\n\nEncode the bytes-like object s using Base16 and return the encoded `bytes`.\n\nDecode the Base16 encoded bytes-like object or ASCII string s and return the\ndecoded `bytes`.\n\nOptional casefold is a flag specifying whether a lowercase alphabet is\nacceptable as input. For security purposes, the default is `False`.\n\nA `binascii.Error` is raised if s is incorrectly padded or if there are non-\nalphabet characters present in the input.\n\nEncode the bytes-like object b using Ascii85 and return the encoded `bytes`.\n\nfoldspaces is an optional flag that uses the special short sequence \u2018y\u2019\ninstead of 4 consecutive spaces (ASCII 0x20) as supported by \u2018btoa\u2019. This\nfeature is not supported by the \u201cstandard\u201d Ascii85 encoding.\n\nwrapcol controls whether the output should have newline (`b'\\n'`) characters\nadded to it. If this is non-zero, each output line will be at most this many\ncharacters long.\n\npad controls whether the input is padded to a multiple of 4 before encoding.\nNote that the `btoa` implementation always pads.\n\nadobe controls whether the encoded byte sequence is framed with `<~` and `~>`,\nwhich is used by the Adobe implementation.\n\nNew in version 3.4.\n\nDecode the Ascii85 encoded bytes-like object or ASCII string b and return the\ndecoded `bytes`.\n\nfoldspaces is a flag that specifies whether the \u2018y\u2019 short sequence should be\naccepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is\nnot supported by the \u201cstandard\u201d Ascii85 encoding.\n\nadobe controls whether the input sequence is in Adobe Ascii85 format (i.e. is\nframed with <~ and ~>).\n\nignorechars should be a bytes-like object or ASCII string containing\ncharacters to ignore from the input. This should only contain whitespace\ncharacters, and by default contains all whitespace characters in ASCII.\n\nNew in version 3.4.\n\nEncode the bytes-like object b using base85 (as used in e.g. git-style binary\ndiffs) and return the encoded `bytes`.\n\nIf pad is true, the input is padded with `b'\\0'` so its length is a multiple\nof 4 bytes before encoding.\n\nNew in version 3.4.\n\nDecode the base85-encoded bytes-like object or ASCII string b and return the\ndecoded `bytes`. Padding is implicitly removed, if necessary.\n\nNew in version 3.4.\n\nThe legacy interface:\n\nDecode the contents of the binary input file and write the resulting binary\ndata to the output file. input and output must be file objects. input will be\nread until `input.readline()` returns an empty bytes object.\n\nDecode the bytes-like object s, which must contain one or more lines of base64\nencoded data, and return the decoded `bytes`.\n\nNew in version 3.1.\n\nEncode the contents of the binary input file and write the resulting base64\nencoded data to the output file. input and output must be file objects. input\nwill be read until `input.read()` returns an empty bytes object. `encode()`\ninserts a newline character (`b'\\n'`) after every 76 bytes of the output, as\nwell as ensuring that the output always ends with a newline, as per RFC 2045\n(MIME).\n\nEncode the bytes-like object s, which can contain arbitrary binary data, and\nreturn `bytes` containing the base64-encoded data, with newlines (`b'\\n'`)\ninserted after every 76 bytes of output, and ensuring that there is a trailing\nnewline, as per RFC 2045 (MIME).\n\nNew in version 3.1.\n\nAn example usage of the module:\n\nSee also\n\nSupport module containing ASCII-to-binary and binary-to-ASCII conversions.\n\nSection 5.2, \u201cBase64 Content-Transfer-Encoding,\u201d provides the definition of\nthe base64 encoding.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.a85decode()", "path": "library/base64#base64.a85decode", "type": "Internet Data", "text": "\nDecode the Ascii85 encoded bytes-like object or ASCII string b and return the\ndecoded `bytes`.\n\nfoldspaces is a flag that specifies whether the \u2018y\u2019 short sequence should be\naccepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is\nnot supported by the \u201cstandard\u201d Ascii85 encoding.\n\nadobe controls whether the input sequence is in Adobe Ascii85 format (i.e. is\nframed with <~ and ~>).\n\nignorechars should be a bytes-like object or ASCII string containing\ncharacters to ignore from the input. This should only contain whitespace\ncharacters, and by default contains all whitespace characters in ASCII.\n\nNew in version 3.4.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.a85encode()", "path": "library/base64#base64.a85encode", "type": "Internet Data", "text": "\nEncode the bytes-like object b using Ascii85 and return the encoded `bytes`.\n\nfoldspaces is an optional flag that uses the special short sequence \u2018y\u2019\ninstead of 4 consecutive spaces (ASCII 0x20) as supported by \u2018btoa\u2019. This\nfeature is not supported by the \u201cstandard\u201d Ascii85 encoding.\n\nwrapcol controls whether the output should have newline (`b'\\n'`) characters\nadded to it. If this is non-zero, each output line will be at most this many\ncharacters long.\n\npad controls whether the input is padded to a multiple of 4 before encoding.\nNote that the `btoa` implementation always pads.\n\nadobe controls whether the encoded byte sequence is framed with `<~` and `~>`,\nwhich is used by the Adobe implementation.\n\nNew in version 3.4.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b16decode()", "path": "library/base64#base64.b16decode", "type": "Internet Data", "text": "\nDecode the Base16 encoded bytes-like object or ASCII string s and return the\ndecoded `bytes`.\n\nOptional casefold is a flag specifying whether a lowercase alphabet is\nacceptable as input. For security purposes, the default is `False`.\n\nA `binascii.Error` is raised if s is incorrectly padded or if there are non-\nalphabet characters present in the input.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b16encode()", "path": "library/base64#base64.b16encode", "type": "Internet Data", "text": "\nEncode the bytes-like object s using Base16 and return the encoded `bytes`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b32decode()", "path": "library/base64#base64.b32decode", "type": "Internet Data", "text": "\nDecode the Base32 encoded bytes-like object or ASCII string s and return the\ndecoded `bytes`.\n\nOptional casefold is a flag specifying whether a lowercase alphabet is\nacceptable as input. For security purposes, the default is `False`.\n\nRFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O\n(oh), and for optional mapping of the digit 1 (one) to either the letter I\n(eye) or letter L (el). The optional argument map01 when not `None`, specifies\nwhich letter the digit 1 should be mapped to (when map01 is not `None`, the\ndigit 0 is always mapped to the letter O). For security purposes the default\nis `None`, so that 0 and 1 are not allowed in the input.\n\nA `binascii.Error` is raised if s is incorrectly padded or if there are non-\nalphabet characters present in the input.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b32encode()", "path": "library/base64#base64.b32encode", "type": "Internet Data", "text": "\nEncode the bytes-like object s using Base32 and return the encoded `bytes`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b64decode()", "path": "library/base64#base64.b64decode", "type": "Internet Data", "text": "\nDecode the Base64 encoded bytes-like object or ASCII string s and return the\ndecoded `bytes`.\n\nOptional altchars must be a bytes-like object or ASCII string of at least\nlength 2 (additional characters are ignored) which specifies the alternative\nalphabet used instead of the `+` and `/` characters.\n\nA `binascii.Error` exception is raised if s is incorrectly padded.\n\nIf validate is `False` (the default), characters that are neither in the\nnormal base-64 alphabet nor the alternative alphabet are discarded prior to\nthe padding check. If validate is `True`, these non-alphabet characters in the\ninput result in a `binascii.Error`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b64encode()", "path": "library/base64#base64.b64encode", "type": "Internet Data", "text": "\nEncode the bytes-like object s using Base64 and return the encoded `bytes`.\n\nOptional altchars must be a bytes-like object of at least length 2 (additional\ncharacters are ignored) which specifies an alternative alphabet for the `+`\nand `/` characters. This allows an application to e.g. generate URL or\nfilesystem safe Base64 strings. The default is `None`, for which the standard\nBase64 alphabet is used.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b85decode()", "path": "library/base64#base64.b85decode", "type": "Internet Data", "text": "\nDecode the base85-encoded bytes-like object or ASCII string b and return the\ndecoded `bytes`. Padding is implicitly removed, if necessary.\n\nNew in version 3.4.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.b85encode()", "path": "library/base64#base64.b85encode", "type": "Internet Data", "text": "\nEncode the bytes-like object b using base85 (as used in e.g. git-style binary\ndiffs) and return the encoded `bytes`.\n\nIf pad is true, the input is padded with `b'\\0'` so its length is a multiple\nof 4 bytes before encoding.\n\nNew in version 3.4.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.decode()", "path": "library/base64#base64.decode", "type": "Internet Data", "text": "\nDecode the contents of the binary input file and write the resulting binary\ndata to the output file. input and output must be file objects. input will be\nread until `input.readline()` returns an empty bytes object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.decodebytes()", "path": "library/base64#base64.decodebytes", "type": "Internet Data", "text": "\nDecode the bytes-like object s, which must contain one or more lines of base64\nencoded data, and return the decoded `bytes`.\n\nNew in version 3.1.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.encode()", "path": "library/base64#base64.encode", "type": "Internet Data", "text": "\nEncode the contents of the binary input file and write the resulting base64\nencoded data to the output file. input and output must be file objects. input\nwill be read until `input.read()` returns an empty bytes object. `encode()`\ninserts a newline character (`b'\\n'`) after every 76 bytes of the output, as\nwell as ensuring that the output always ends with a newline, as per RFC 2045\n(MIME).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.encodebytes()", "path": "library/base64#base64.encodebytes", "type": "Internet Data", "text": "\nEncode the bytes-like object s, which can contain arbitrary binary data, and\nreturn `bytes` containing the base64-encoded data, with newlines (`b'\\n'`)\ninserted after every 76 bytes of output, and ensuring that there is a trailing\nnewline, as per RFC 2045 (MIME).\n\nNew in version 3.1.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.standard_b64decode()", "path": "library/base64#base64.standard_b64decode", "type": "Internet Data", "text": "\nDecode bytes-like object or ASCII string s using the standard Base64 alphabet\nand return the decoded `bytes`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.standard_b64encode()", "path": "library/base64#base64.standard_b64encode", "type": "Internet Data", "text": "\nEncode bytes-like object s using the standard Base64 alphabet and return the\nencoded `bytes`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.urlsafe_b64decode()", "path": "library/base64#base64.urlsafe_b64decode", "type": "Internet Data", "text": "\nDecode bytes-like object or ASCII string s using the URL- and filesystem-safe\nalphabet, which substitutes `-` instead of `+` and `_` instead of `/` in the\nstandard Base64 alphabet, and return the decoded `bytes`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "base64.urlsafe_b64encode()", "path": "library/base64#base64.urlsafe_b64encode", "type": "Internet Data", "text": "\nEncode bytes-like object s using the URL- and filesystem-safe alphabet, which\nsubstitutes `-` instead of `+` and `_` instead of `/` in the standard Base64\nalphabet, and return the encoded `bytes`. The result can still contain `=`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BaseException", "path": "library/exceptions#BaseException", "type": "Built-in Exceptions", "text": "\nThe base class for all built-in exceptions. It is not meant to be directly\ninherited by user-defined classes (for that, use `Exception`). If `str()` is\ncalled on an instance of this class, the representation of the argument(s) to\nthe instance are returned, or the empty string when there were no arguments.\n\nThe tuple of arguments given to the exception constructor. Some built-in\nexceptions (like `OSError`) expect a certain number of arguments and assign a\nspecial meaning to the elements of this tuple, while others are usually called\nonly with a single string giving an error message.\n\nThis method sets tb as the new traceback for the exception and returns the\nexception object. It is usually used in exception handling code like this:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BaseException.args", "path": "library/exceptions#BaseException.args", "type": "Built-in Exceptions", "text": "\nThe tuple of arguments given to the exception constructor. Some built-in\nexceptions (like `OSError`) expect a certain number of arguments and assign a\nspecial meaning to the elements of this tuple, while others are usually called\nonly with a single string giving an error message.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BaseException.with_traceback()", "path": "library/exceptions#BaseException.with_traceback", "type": "Built-in Exceptions", "text": "\nThis method sets tb as the new traceback for the exception and returns the\nexception object. It is usually used in exception handling code like this:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb", "path": "library/bdb", "type": "Debugging & Profiling", "text": "\nSource code: Lib/bdb.py\n\nThe `bdb` module handles basic debugger functions, like setting breakpoints or\nmanaging execution via the debugger.\n\nThe following exception is defined:\n\nException raised by the `Bdb` class for quitting the debugger.\n\nThe `bdb` module also defines two classes:\n\nThis class implements temporary breakpoints, ignore counts, disabling and\n(re-)enabling, and conditionals.\n\nBreakpoints are indexed by number through a list called `bpbynumber` and by\n`(file, line)` pairs through `bplist`. The former points to a single instance\nof class `Breakpoint`. The latter points to a list of such instances since\nthere may be more than one breakpoint per line.\n\nWhen creating a breakpoint, its associated filename should be in canonical\nform. If a funcname is defined, a breakpoint hit will be counted when the\nfirst line of that function is executed. A conditional breakpoint always\ncounts a hit.\n\n`Breakpoint` instances have the following methods:\n\nDelete the breakpoint from the list associated to a file/line. If it is the\nlast breakpoint in that position, it also deletes the entry for the file/line.\n\nMark the breakpoint as enabled.\n\nMark the breakpoint as disabled.\n\nReturn a string with all the information about the breakpoint, nicely\nformatted:\n\nNew in version 3.2.\n\nPrint the output of `bpformat()` to the file out, or if it is `None`, to\nstandard output.\n\nThe `Bdb` class acts as a generic Python debugger base class.\n\nThis class takes care of the details of the trace facility; a derived class\nshould implement user interaction. The standard debugger class (`pdb.Pdb`) is\nan example.\n\nThe skip argument, if given, must be an iterable of glob-style module name\npatterns. The debugger will not step into frames that originate in a module\nthat matches one of these patterns. Whether a frame is considered to originate\nin a certain module is determined by the `__name__` in the frame globals.\n\nNew in version 3.1: The skip argument.\n\nThe following methods of `Bdb` normally don\u2019t need to be overridden.\n\nAuxiliary method for getting a filename in a canonical form, that is, as a\ncase-normalized (on case-insensitive filesystems) absolute path, stripped of\nsurrounding angle brackets.\n\nSet the `botframe`, `stopframe`, `returnframe` and `quitting` attributes with\nvalues ready to start debugging.\n\nThis function is installed as the trace function of debugged frames. Its\nreturn value is the new trace function (in most cases, that is, itself).\n\nThe default implementation decides how to dispatch a frame, depending on the\ntype of event (passed as a string) that is about to be executed. event can be\none of the following:\n\nFor the Python events, specialized functions (see below) are called. For the C\nevents, no action is taken.\n\nThe arg parameter depends on the previous event.\n\nSee the documentation for `sys.settrace()` for more information on the trace\nfunction. For more information on code and frame objects, refer to The\nstandard type hierarchy.\n\nIf the debugger should stop on the current line, invoke the `user_line()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_line()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\nIf the debugger should stop on this function call, invoke the `user_call()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_call()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\nIf the debugger should stop on this function return, invoke the\n`user_return()` method (which should be overridden in subclasses). Raise a\n`BdbQuit` exception if the `Bdb.quitting` flag is set (which can be set from\n`user_return()`). Return a reference to the `trace_dispatch()` method for\nfurther tracing in that scope.\n\nIf the debugger should stop at this exception, invokes the `user_exception()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_exception()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\nNormally derived classes don\u2019t override the following methods, but they may if\nthey want to redefine the definition of stopping and breakpoints.\n\nThis method checks if the frame is somewhere below `botframe` in the call\nstack. `botframe` is the frame in which debugging started.\n\nThis method checks if there is a breakpoint in the filename and line belonging\nto frame or, at least, in the current function. If the breakpoint is a\ntemporary one, this method deletes it.\n\nThis method checks if there is a breakpoint in the filename of the current\nframe.\n\nDerived classes should override these methods to gain control over debugger\noperation.\n\nThis method is called from `dispatch_call()` when there is the possibility\nthat a break might be necessary anywhere inside the called function.\n\nThis method is called from `dispatch_line()` when either `stop_here()` or\n`break_here()` yields `True`.\n\nThis method is called from `dispatch_return()` when `stop_here()` yields\n`True`.\n\nThis method is called from `dispatch_exception()` when `stop_here()` yields\n`True`.\n\nHandle how a breakpoint must be removed when it is a temporary one.\n\nThis method must be implemented by derived classes.\n\nDerived classes and clients can call the following methods to affect the\nstepping state.\n\nStop after one line of code.\n\nStop on the next line in or below the given frame.\n\nStop when returning from the given frame.\n\nStop when the line with the line no greater than the current one is reached or\nwhen returning from current frame.\n\nStart debugging from frame. If frame is not specified, debugging starts from\ncaller\u2019s frame.\n\nStop only at breakpoints or when finished. If there are no breakpoints, set\nthe system trace function to `None`.\n\nSet the `quitting` attribute to `True`. This raises `BdbQuit` in the next call\nto one of the `dispatch_*()` methods.\n\nDerived classes and clients can call the following methods to manipulate\nbreakpoints. These methods return a string containing an error message if\nsomething went wrong, or `None` if all is well.\n\nSet a new breakpoint. If the lineno line doesn\u2019t exist for the filename passed\nas argument, return an error message. The filename should be in canonical\nform, as described in the `canonic()` method.\n\nDelete the breakpoints in filename and lineno. If none were set, an error\nmessage is returned.\n\nDelete the breakpoint which has the index arg in the `Breakpoint.bpbynumber`.\nIf arg is not numeric or out of range, return an error message.\n\nDelete all breakpoints in filename. If none were set, an error message is\nreturned.\n\nDelete all existing breakpoints.\n\nReturn a breakpoint specified by the given number. If arg is a string, it will\nbe converted to a number. If arg is a non-numeric string, if the given\nbreakpoint never existed or has been deleted, a `ValueError` is raised.\n\nNew in version 3.2.\n\nCheck if there is a breakpoint for lineno of filename.\n\nReturn all breakpoints for lineno in filename, or an empty list if none are\nset.\n\nReturn all breakpoints in filename, or an empty list if none are set.\n\nReturn all breakpoints that are set.\n\nDerived classes and clients can call the following methods to get a data\nstructure representing a stack trace.\n\nGet a list of records for a frame and all higher (calling) and lower frames,\nand the size of the higher part.\n\nReturn a string with information about a stack entry, identified by a `(frame,\nlineno)` tuple:\n\nThe following two methods can be called by clients to use a debugger to debug\na statement, given as a string.\n\nDebug a statement executed via the `exec()` function. globals defaults to\n`__main__.__dict__`, locals defaults to globals.\n\nDebug an expression executed via the `eval()` function. globals and locals\nhave the same meaning as in `run()`.\n\nFor backwards compatibility. Calls the `run()` method.\n\nDebug a single function call, and return its result.\n\nFinally, the module defines the following functions:\n\nCheck whether we should break here, depending on the way the breakpoint b was\nset.\n\nIf it was set via line number, it checks if `b.line` is the same as the one in\nthe frame also passed as argument. If the breakpoint was set via function\nname, we have to check we are in the right frame (the right function) and if\nwe are in its first executable line.\n\nDetermine if there is an effective (active) breakpoint at this line of code.\nReturn a tuple of the breakpoint and a boolean that indicates if it is ok to\ndelete a temporary breakpoint. Return `(None, None)` if there is no matching\nbreakpoint.\n\nStart debugging with a `Bdb` instance from caller\u2019s frame.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb", "path": "library/bdb#bdb.Bdb", "type": "Debugging & Profiling", "text": "\nThe `Bdb` class acts as a generic Python debugger base class.\n\nThis class takes care of the details of the trace facility; a derived class\nshould implement user interaction. The standard debugger class (`pdb.Pdb`) is\nan example.\n\nThe skip argument, if given, must be an iterable of glob-style module name\npatterns. The debugger will not step into frames that originate in a module\nthat matches one of these patterns. Whether a frame is considered to originate\nin a certain module is determined by the `__name__` in the frame globals.\n\nNew in version 3.1: The skip argument.\n\nThe following methods of `Bdb` normally don\u2019t need to be overridden.\n\nAuxiliary method for getting a filename in a canonical form, that is, as a\ncase-normalized (on case-insensitive filesystems) absolute path, stripped of\nsurrounding angle brackets.\n\nSet the `botframe`, `stopframe`, `returnframe` and `quitting` attributes with\nvalues ready to start debugging.\n\nThis function is installed as the trace function of debugged frames. Its\nreturn value is the new trace function (in most cases, that is, itself).\n\nThe default implementation decides how to dispatch a frame, depending on the\ntype of event (passed as a string) that is about to be executed. event can be\none of the following:\n\nFor the Python events, specialized functions (see below) are called. For the C\nevents, no action is taken.\n\nThe arg parameter depends on the previous event.\n\nSee the documentation for `sys.settrace()` for more information on the trace\nfunction. For more information on code and frame objects, refer to The\nstandard type hierarchy.\n\nIf the debugger should stop on the current line, invoke the `user_line()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_line()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\nIf the debugger should stop on this function call, invoke the `user_call()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_call()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\nIf the debugger should stop on this function return, invoke the\n`user_return()` method (which should be overridden in subclasses). Raise a\n`BdbQuit` exception if the `Bdb.quitting` flag is set (which can be set from\n`user_return()`). Return a reference to the `trace_dispatch()` method for\nfurther tracing in that scope.\n\nIf the debugger should stop at this exception, invokes the `user_exception()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_exception()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\nNormally derived classes don\u2019t override the following methods, but they may if\nthey want to redefine the definition of stopping and breakpoints.\n\nThis method checks if the frame is somewhere below `botframe` in the call\nstack. `botframe` is the frame in which debugging started.\n\nThis method checks if there is a breakpoint in the filename and line belonging\nto frame or, at least, in the current function. If the breakpoint is a\ntemporary one, this method deletes it.\n\nThis method checks if there is a breakpoint in the filename of the current\nframe.\n\nDerived classes should override these methods to gain control over debugger\noperation.\n\nThis method is called from `dispatch_call()` when there is the possibility\nthat a break might be necessary anywhere inside the called function.\n\nThis method is called from `dispatch_line()` when either `stop_here()` or\n`break_here()` yields `True`.\n\nThis method is called from `dispatch_return()` when `stop_here()` yields\n`True`.\n\nThis method is called from `dispatch_exception()` when `stop_here()` yields\n`True`.\n\nHandle how a breakpoint must be removed when it is a temporary one.\n\nThis method must be implemented by derived classes.\n\nDerived classes and clients can call the following methods to affect the\nstepping state.\n\nStop after one line of code.\n\nStop on the next line in or below the given frame.\n\nStop when returning from the given frame.\n\nStop when the line with the line no greater than the current one is reached or\nwhen returning from current frame.\n\nStart debugging from frame. If frame is not specified, debugging starts from\ncaller\u2019s frame.\n\nStop only at breakpoints or when finished. If there are no breakpoints, set\nthe system trace function to `None`.\n\nSet the `quitting` attribute to `True`. This raises `BdbQuit` in the next call\nto one of the `dispatch_*()` methods.\n\nDerived classes and clients can call the following methods to manipulate\nbreakpoints. These methods return a string containing an error message if\nsomething went wrong, or `None` if all is well.\n\nSet a new breakpoint. If the lineno line doesn\u2019t exist for the filename passed\nas argument, return an error message. The filename should be in canonical\nform, as described in the `canonic()` method.\n\nDelete the breakpoints in filename and lineno. If none were set, an error\nmessage is returned.\n\nDelete the breakpoint which has the index arg in the `Breakpoint.bpbynumber`.\nIf arg is not numeric or out of range, return an error message.\n\nDelete all breakpoints in filename. If none were set, an error message is\nreturned.\n\nDelete all existing breakpoints.\n\nReturn a breakpoint specified by the given number. If arg is a string, it will\nbe converted to a number. If arg is a non-numeric string, if the given\nbreakpoint never existed or has been deleted, a `ValueError` is raised.\n\nNew in version 3.2.\n\nCheck if there is a breakpoint for lineno of filename.\n\nReturn all breakpoints for lineno in filename, or an empty list if none are\nset.\n\nReturn all breakpoints in filename, or an empty list if none are set.\n\nReturn all breakpoints that are set.\n\nDerived classes and clients can call the following methods to get a data\nstructure representing a stack trace.\n\nGet a list of records for a frame and all higher (calling) and lower frames,\nand the size of the higher part.\n\nReturn a string with information about a stack entry, identified by a `(frame,\nlineno)` tuple:\n\nThe following two methods can be called by clients to use a debugger to debug\na statement, given as a string.\n\nDebug a statement executed via the `exec()` function. globals defaults to\n`__main__.__dict__`, locals defaults to globals.\n\nDebug an expression executed via the `eval()` function. globals and locals\nhave the same meaning as in `run()`.\n\nFor backwards compatibility. Calls the `run()` method.\n\nDebug a single function call, and return its result.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.break_anywhere()", "path": "library/bdb#bdb.Bdb.break_anywhere", "type": "Debugging & Profiling", "text": "\nThis method checks if there is a breakpoint in the filename of the current\nframe.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.break_here()", "path": "library/bdb#bdb.Bdb.break_here", "type": "Debugging & Profiling", "text": "\nThis method checks if there is a breakpoint in the filename and line belonging\nto frame or, at least, in the current function. If the breakpoint is a\ntemporary one, this method deletes it.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.canonic()", "path": "library/bdb#bdb.Bdb.canonic", "type": "Debugging & Profiling", "text": "\nAuxiliary method for getting a filename in a canonical form, that is, as a\ncase-normalized (on case-insensitive filesystems) absolute path, stripped of\nsurrounding angle brackets.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.clear_all_breaks()", "path": "library/bdb#bdb.Bdb.clear_all_breaks", "type": "Debugging & Profiling", "text": "\nDelete all existing breakpoints.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.clear_all_file_breaks()", "path": "library/bdb#bdb.Bdb.clear_all_file_breaks", "type": "Debugging & Profiling", "text": "\nDelete all breakpoints in filename. If none were set, an error message is\nreturned.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.clear_bpbynumber()", "path": "library/bdb#bdb.Bdb.clear_bpbynumber", "type": "Debugging & Profiling", "text": "\nDelete the breakpoint which has the index arg in the `Breakpoint.bpbynumber`.\nIf arg is not numeric or out of range, return an error message.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.clear_break()", "path": "library/bdb#bdb.Bdb.clear_break", "type": "Debugging & Profiling", "text": "\nDelete the breakpoints in filename and lineno. If none were set, an error\nmessage is returned.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.dispatch_call()", "path": "library/bdb#bdb.Bdb.dispatch_call", "type": "Debugging & Profiling", "text": "\nIf the debugger should stop on this function call, invoke the `user_call()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_call()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.dispatch_exception()", "path": "library/bdb#bdb.Bdb.dispatch_exception", "type": "Debugging & Profiling", "text": "\nIf the debugger should stop at this exception, invokes the `user_exception()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_exception()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.dispatch_line()", "path": "library/bdb#bdb.Bdb.dispatch_line", "type": "Debugging & Profiling", "text": "\nIf the debugger should stop on the current line, invoke the `user_line()`\nmethod (which should be overridden in subclasses). Raise a `BdbQuit` exception\nif the `Bdb.quitting` flag is set (which can be set from `user_line()`).\nReturn a reference to the `trace_dispatch()` method for further tracing in\nthat scope.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.dispatch_return()", "path": "library/bdb#bdb.Bdb.dispatch_return", "type": "Debugging & Profiling", "text": "\nIf the debugger should stop on this function return, invoke the\n`user_return()` method (which should be overridden in subclasses). Raise a\n`BdbQuit` exception if the `Bdb.quitting` flag is set (which can be set from\n`user_return()`). Return a reference to the `trace_dispatch()` method for\nfurther tracing in that scope.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.do_clear()", "path": "library/bdb#bdb.Bdb.do_clear", "type": "Debugging & Profiling", "text": "\nHandle how a breakpoint must be removed when it is a temporary one.\n\nThis method must be implemented by derived classes.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.format_stack_entry()", "path": "library/bdb#bdb.Bdb.format_stack_entry", "type": "Debugging & Profiling", "text": "\nReturn a string with information about a stack entry, identified by a `(frame,\nlineno)` tuple:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.get_all_breaks()", "path": "library/bdb#bdb.Bdb.get_all_breaks", "type": "Debugging & Profiling", "text": "\nReturn all breakpoints that are set.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.get_bpbynumber()", "path": "library/bdb#bdb.Bdb.get_bpbynumber", "type": "Debugging & Profiling", "text": "\nReturn a breakpoint specified by the given number. If arg is a string, it will\nbe converted to a number. If arg is a non-numeric string, if the given\nbreakpoint never existed or has been deleted, a `ValueError` is raised.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.get_break()", "path": "library/bdb#bdb.Bdb.get_break", "type": "Debugging & Profiling", "text": "\nCheck if there is a breakpoint for lineno of filename.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.get_breaks()", "path": "library/bdb#bdb.Bdb.get_breaks", "type": "Debugging & Profiling", "text": "\nReturn all breakpoints for lineno in filename, or an empty list if none are\nset.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.get_file_breaks()", "path": "library/bdb#bdb.Bdb.get_file_breaks", "type": "Debugging & Profiling", "text": "\nReturn all breakpoints in filename, or an empty list if none are set.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.get_stack()", "path": "library/bdb#bdb.Bdb.get_stack", "type": "Debugging & Profiling", "text": "\nGet a list of records for a frame and all higher (calling) and lower frames,\nand the size of the higher part.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.reset()", "path": "library/bdb#bdb.Bdb.reset", "type": "Debugging & Profiling", "text": "\nSet the `botframe`, `stopframe`, `returnframe` and `quitting` attributes with\nvalues ready to start debugging.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.run()", "path": "library/bdb#bdb.Bdb.run", "type": "Debugging & Profiling", "text": "\nDebug a statement executed via the `exec()` function. globals defaults to\n`__main__.__dict__`, locals defaults to globals.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.runcall()", "path": "library/bdb#bdb.Bdb.runcall", "type": "Debugging & Profiling", "text": "\nDebug a single function call, and return its result.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.runctx()", "path": "library/bdb#bdb.Bdb.runctx", "type": "Debugging & Profiling", "text": "\nFor backwards compatibility. Calls the `run()` method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.runeval()", "path": "library/bdb#bdb.Bdb.runeval", "type": "Debugging & Profiling", "text": "\nDebug an expression executed via the `eval()` function. globals and locals\nhave the same meaning as in `run()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_break()", "path": "library/bdb#bdb.Bdb.set_break", "type": "Debugging & Profiling", "text": "\nSet a new breakpoint. If the lineno line doesn\u2019t exist for the filename passed\nas argument, return an error message. The filename should be in canonical\nform, as described in the `canonic()` method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_continue()", "path": "library/bdb#bdb.Bdb.set_continue", "type": "Debugging & Profiling", "text": "\nStop only at breakpoints or when finished. If there are no breakpoints, set\nthe system trace function to `None`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_next()", "path": "library/bdb#bdb.Bdb.set_next", "type": "Debugging & Profiling", "text": "\nStop on the next line in or below the given frame.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_quit()", "path": "library/bdb#bdb.Bdb.set_quit", "type": "Debugging & Profiling", "text": "\nSet the `quitting` attribute to `True`. This raises `BdbQuit` in the next call\nto one of the `dispatch_*()` methods.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_return()", "path": "library/bdb#bdb.Bdb.set_return", "type": "Debugging & Profiling", "text": "\nStop when returning from the given frame.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_step()", "path": "library/bdb#bdb.Bdb.set_step", "type": "Debugging & Profiling", "text": "\nStop after one line of code.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_trace()", "path": "library/bdb#bdb.Bdb.set_trace", "type": "Debugging & Profiling", "text": "\nStart debugging from frame. If frame is not specified, debugging starts from\ncaller\u2019s frame.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.set_until()", "path": "library/bdb#bdb.Bdb.set_until", "type": "Debugging & Profiling", "text": "\nStop when the line with the line no greater than the current one is reached or\nwhen returning from current frame.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.stop_here()", "path": "library/bdb#bdb.Bdb.stop_here", "type": "Debugging & Profiling", "text": "\nThis method checks if the frame is somewhere below `botframe` in the call\nstack. `botframe` is the frame in which debugging started.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.trace_dispatch()", "path": "library/bdb#bdb.Bdb.trace_dispatch", "type": "Debugging & Profiling", "text": "\nThis function is installed as the trace function of debugged frames. Its\nreturn value is the new trace function (in most cases, that is, itself).\n\nThe default implementation decides how to dispatch a frame, depending on the\ntype of event (passed as a string) that is about to be executed. event can be\none of the following:\n\nFor the Python events, specialized functions (see below) are called. For the C\nevents, no action is taken.\n\nThe arg parameter depends on the previous event.\n\nSee the documentation for `sys.settrace()` for more information on the trace\nfunction. For more information on code and frame objects, refer to The\nstandard type hierarchy.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.user_call()", "path": "library/bdb#bdb.Bdb.user_call", "type": "Debugging & Profiling", "text": "\nThis method is called from `dispatch_call()` when there is the possibility\nthat a break might be necessary anywhere inside the called function.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.user_exception()", "path": "library/bdb#bdb.Bdb.user_exception", "type": "Debugging & Profiling", "text": "\nThis method is called from `dispatch_exception()` when `stop_here()` yields\n`True`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.user_line()", "path": "library/bdb#bdb.Bdb.user_line", "type": "Debugging & Profiling", "text": "\nThis method is called from `dispatch_line()` when either `stop_here()` or\n`break_here()` yields `True`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Bdb.user_return()", "path": "library/bdb#bdb.Bdb.user_return", "type": "Debugging & Profiling", "text": "\nThis method is called from `dispatch_return()` when `stop_here()` yields\n`True`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.BdbQuit", "path": "library/bdb#bdb.BdbQuit", "type": "Debugging & Profiling", "text": "\nException raised by the `Bdb` class for quitting the debugger.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Breakpoint", "path": "library/bdb#bdb.Breakpoint", "type": "Debugging & Profiling", "text": "\nThis class implements temporary breakpoints, ignore counts, disabling and\n(re-)enabling, and conditionals.\n\nBreakpoints are indexed by number through a list called `bpbynumber` and by\n`(file, line)` pairs through `bplist`. The former points to a single instance\nof class `Breakpoint`. The latter points to a list of such instances since\nthere may be more than one breakpoint per line.\n\nWhen creating a breakpoint, its associated filename should be in canonical\nform. If a funcname is defined, a breakpoint hit will be counted when the\nfirst line of that function is executed. A conditional breakpoint always\ncounts a hit.\n\n`Breakpoint` instances have the following methods:\n\nDelete the breakpoint from the list associated to a file/line. If it is the\nlast breakpoint in that position, it also deletes the entry for the file/line.\n\nMark the breakpoint as enabled.\n\nMark the breakpoint as disabled.\n\nReturn a string with all the information about the breakpoint, nicely\nformatted:\n\nNew in version 3.2.\n\nPrint the output of `bpformat()` to the file out, or if it is `None`, to\nstandard output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Breakpoint.bpformat()", "path": "library/bdb#bdb.Breakpoint.bpformat", "type": "Debugging & Profiling", "text": "\nReturn a string with all the information about the breakpoint, nicely\nformatted:\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Breakpoint.bpprint()", "path": "library/bdb#bdb.Breakpoint.bpprint", "type": "Debugging & Profiling", "text": "\nPrint the output of `bpformat()` to the file out, or if it is `None`, to\nstandard output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Breakpoint.deleteMe()", "path": "library/bdb#bdb.Breakpoint.deleteMe", "type": "Debugging & Profiling", "text": "\nDelete the breakpoint from the list associated to a file/line. If it is the\nlast breakpoint in that position, it also deletes the entry for the file/line.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Breakpoint.disable()", "path": "library/bdb#bdb.Breakpoint.disable", "type": "Debugging & Profiling", "text": "\nMark the breakpoint as disabled.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.Breakpoint.enable()", "path": "library/bdb#bdb.Breakpoint.enable", "type": "Debugging & Profiling", "text": "\nMark the breakpoint as enabled.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.checkfuncname()", "path": "library/bdb#bdb.checkfuncname", "type": "Debugging & Profiling", "text": "\nCheck whether we should break here, depending on the way the breakpoint b was\nset.\n\nIf it was set via line number, it checks if `b.line` is the same as the one in\nthe frame also passed as argument. If the breakpoint was set via function\nname, we have to check we are in the right frame (the right function) and if\nwe are in its first executable line.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.effective()", "path": "library/bdb#bdb.effective", "type": "Debugging & Profiling", "text": "\nDetermine if there is an effective (active) breakpoint at this line of code.\nReturn a tuple of the breakpoint and a boolean that indicates if it is ok to\ndelete a temporary breakpoint. Return `(None, None)` if there is no matching\nbreakpoint.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bdb.set_trace()", "path": "library/bdb#bdb.set_trace", "type": "Debugging & Profiling", "text": "\nStart debugging with a `Bdb` instance from caller\u2019s frame.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bin()", "path": "library/functions#bin", "type": "Built-in Functions", "text": "\nConvert an integer number to a binary string prefixed with \u201c0b\u201d. The result is\na valid Python expression. If x is not a Python `int` object, it has to define\nan `__index__()` method that returns an integer. Some examples:\n\nIf prefix \u201c0b\u201d is desired or not, you can use either of the following ways.\n\nSee also `format()` for more information.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii", "path": "library/binascii", "type": "Internet Data", "text": "\nThe `binascii` module contains a number of methods to convert between binary\nand various ASCII-encoded binary representations. Normally, you will not use\nthese functions directly but use wrapper modules like `uu`, `base64`, or\n`binhex` instead. The `binascii` module contains low-level functions written\nin C for greater speed that are used by the higher-level modules.\n\nNote\n\n`a2b_*` functions accept Unicode strings containing only ASCII characters.\nOther functions only accept bytes-like objects (such as `bytes`, `bytearray`\nand other objects that support the buffer protocol).\n\nChanged in version 3.3: ASCII-only unicode strings are now accepted by the\n`a2b_*` functions.\n\nThe `binascii` module defines the following functions:\n\nConvert a single line of uuencoded data back to binary and return the binary\ndata. Lines normally contain 45 (binary) bytes, except for the last line. Line\ndata may be followed by whitespace.\n\nConvert binary data to a line of ASCII characters, the return value is the\nconverted line, including a newline char. The length of data should be at most\n45. If backtick is true, zeros are represented by `'`'` instead of spaces.\n\nChanged in version 3.7: Added the backtick parameter.\n\nConvert a block of base64 data back to binary and return the binary data. More\nthan one line may be passed at a time.\n\nConvert binary data to a line of ASCII characters in base64 coding. The return\nvalue is the converted line, including a newline char if newline is true. The\noutput of this function conforms to RFC 3548.\n\nChanged in version 3.6: Added the newline parameter.\n\nConvert a block of quoted-printable data back to binary and return the binary\ndata. More than one line may be passed at a time. If the optional argument\nheader is present and true, underscores will be decoded as spaces.\n\nConvert binary data to a line(s) of ASCII characters in quoted-printable\nencoding. The return value is the converted line(s). If the optional argument\nquotetabs is present and true, all tabs and spaces will be encoded. If the\noptional argument istext is present and true, newlines are not encoded but\ntrailing whitespace will be encoded. If the optional argument header is\npresent and true, spaces will be encoded as underscores per RFC 1522. If the\noptional argument header is present and false, newline characters will be\nencoded as well; otherwise linefeed conversion might corrupt the binary data\nstream.\n\nConvert binhex4 formatted ASCII data to binary, without doing RLE-\ndecompression. The string should contain a complete number of binary bytes, or\n(in case of the last portion of the binhex4 data) have the remaining bits\nzero.\n\nDeprecated since version 3.9.\n\nPerform RLE-decompression on the data, as per the binhex4 standard. The\nalgorithm uses `0x90` after a byte as a repeat indicator, followed by a count.\nA count of `0` specifies a byte value of `0x90`. The routine returns the\ndecompressed data, unless data input data ends in an orphaned repeat\nindicator, in which case the `Incomplete` exception is raised.\n\nChanged in version 3.2: Accept only bytestring or bytearray objects as input.\n\nDeprecated since version 3.9.\n\nPerform binhex4 style RLE-compression on data and return the result.\n\nDeprecated since version 3.9.\n\nPerform hexbin4 binary-to-ASCII translation and return the resulting string.\nThe argument should already be RLE-coded, and have a length divisible by 3\n(except possibly the last fragment).\n\nDeprecated since version 3.9.\n\nCompute a 16-bit CRC value of data, starting with value as the initial CRC,\nand return the result. This uses the CRC-CCITT polynomial x16 \\+ x12 \\+ x5 \\+\n1, often represented as 0x1021. This CRC is used in the binhex4 format.\n\nCompute CRC-32, the 32-bit checksum of data, starting with an initial CRC of\nvalue. The default initial CRC is zero. The algorithm is consistent with the\nZIP file checksum. Since the algorithm is designed for use as a checksum\nalgorithm, it is not suitable for use as a general hash algorithm. Use as\nfollows:\n\nChanged in version 3.0: The result is always unsigned. To generate the same\nnumeric value across all Python versions and platforms, use `crc32(data) &\n0xffffffff`.\n\nReturn the hexadecimal representation of the binary data. Every byte of data\nis converted into the corresponding 2-digit hex representation. The returned\nbytes object is therefore twice as long as the length of data.\n\nSimilar functionality (but returning a text string) is also conveniently\naccessible using the `bytes.hex()` method.\n\nIf sep is specified, it must be a single character str or bytes object. It\nwill be inserted in the output after every bytes_per_sep input bytes.\nSeparator placement is counted from the right end of the output by default, if\nyou wish to count from the left, supply a negative bytes_per_sep value.\n\nChanged in version 3.8: The sep and bytes_per_sep parameters were added.\n\nReturn the binary data represented by the hexadecimal string hexstr. This\nfunction is the inverse of `b2a_hex()`. hexstr must contain an even number of\nhexadecimal digits (which can be upper or lower case), otherwise an `Error`\nexception is raised.\n\nSimilar functionality (accepting only text string arguments, but more liberal\ntowards whitespace) is also accessible using the `bytes.fromhex()` class\nmethod.\n\nException raised on errors. These are usually programming errors.\n\nException raised on incomplete data. These are usually not programming errors,\nbut may be handled by reading a little more data and trying again.\n\nSee also\n\nSupport for RFC compliant base64-style encoding in base 16, 32, 64, and 85.\n\nSupport for the binhex format used on the Macintosh.\n\nSupport for UU encoding used on Unix.\n\nSupport for quoted-printable encoding used in MIME email messages.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.a2b_base64()", "path": "library/binascii#binascii.a2b_base64", "type": "Internet Data", "text": "\nConvert a block of base64 data back to binary and return the binary data. More\nthan one line may be passed at a time.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.a2b_hex()", "path": "library/binascii#binascii.a2b_hex", "type": "Internet Data", "text": "\nReturn the binary data represented by the hexadecimal string hexstr. This\nfunction is the inverse of `b2a_hex()`. hexstr must contain an even number of\nhexadecimal digits (which can be upper or lower case), otherwise an `Error`\nexception is raised.\n\nSimilar functionality (accepting only text string arguments, but more liberal\ntowards whitespace) is also accessible using the `bytes.fromhex()` class\nmethod.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.a2b_hqx()", "path": "library/binascii#binascii.a2b_hqx", "type": "Internet Data", "text": "\nConvert binhex4 formatted ASCII data to binary, without doing RLE-\ndecompression. The string should contain a complete number of binary bytes, or\n(in case of the last portion of the binhex4 data) have the remaining bits\nzero.\n\nDeprecated since version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.a2b_qp()", "path": "library/binascii#binascii.a2b_qp", "type": "Internet Data", "text": "\nConvert a block of quoted-printable data back to binary and return the binary\ndata. More than one line may be passed at a time. If the optional argument\nheader is present and true, underscores will be decoded as spaces.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.a2b_uu()", "path": "library/binascii#binascii.a2b_uu", "type": "Internet Data", "text": "\nConvert a single line of uuencoded data back to binary and return the binary\ndata. Lines normally contain 45 (binary) bytes, except for the last line. Line\ndata may be followed by whitespace.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.b2a_base64()", "path": "library/binascii#binascii.b2a_base64", "type": "Internet Data", "text": "\nConvert binary data to a line of ASCII characters in base64 coding. The return\nvalue is the converted line, including a newline char if newline is true. The\noutput of this function conforms to RFC 3548.\n\nChanged in version 3.6: Added the newline parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.b2a_hex()", "path": "library/binascii#binascii.b2a_hex", "type": "Internet Data", "text": "\nReturn the hexadecimal representation of the binary data. Every byte of data\nis converted into the corresponding 2-digit hex representation. The returned\nbytes object is therefore twice as long as the length of data.\n\nSimilar functionality (but returning a text string) is also conveniently\naccessible using the `bytes.hex()` method.\n\nIf sep is specified, it must be a single character str or bytes object. It\nwill be inserted in the output after every bytes_per_sep input bytes.\nSeparator placement is counted from the right end of the output by default, if\nyou wish to count from the left, supply a negative bytes_per_sep value.\n\nChanged in version 3.8: The sep and bytes_per_sep parameters were added.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.b2a_hqx()", "path": "library/binascii#binascii.b2a_hqx", "type": "Internet Data", "text": "\nPerform hexbin4 binary-to-ASCII translation and return the resulting string.\nThe argument should already be RLE-coded, and have a length divisible by 3\n(except possibly the last fragment).\n\nDeprecated since version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.b2a_qp()", "path": "library/binascii#binascii.b2a_qp", "type": "Internet Data", "text": "\nConvert binary data to a line(s) of ASCII characters in quoted-printable\nencoding. The return value is the converted line(s). If the optional argument\nquotetabs is present and true, all tabs and spaces will be encoded. If the\noptional argument istext is present and true, newlines are not encoded but\ntrailing whitespace will be encoded. If the optional argument header is\npresent and true, spaces will be encoded as underscores per RFC 1522. If the\noptional argument header is present and false, newline characters will be\nencoded as well; otherwise linefeed conversion might corrupt the binary data\nstream.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.b2a_uu()", "path": "library/binascii#binascii.b2a_uu", "type": "Internet Data", "text": "\nConvert binary data to a line of ASCII characters, the return value is the\nconverted line, including a newline char. The length of data should be at most\n45. If backtick is true, zeros are represented by `'`'` instead of spaces.\n\nChanged in version 3.7: Added the backtick parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.crc32()", "path": "library/binascii#binascii.crc32", "type": "Internet Data", "text": "\nCompute CRC-32, the 32-bit checksum of data, starting with an initial CRC of\nvalue. The default initial CRC is zero. The algorithm is consistent with the\nZIP file checksum. Since the algorithm is designed for use as a checksum\nalgorithm, it is not suitable for use as a general hash algorithm. Use as\nfollows:\n\nChanged in version 3.0: The result is always unsigned. To generate the same\nnumeric value across all Python versions and platforms, use `crc32(data) &\n0xffffffff`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.crc_hqx()", "path": "library/binascii#binascii.crc_hqx", "type": "Internet Data", "text": "\nCompute a 16-bit CRC value of data, starting with value as the initial CRC,\nand return the result. This uses the CRC-CCITT polynomial x16 \\+ x12 \\+ x5 \\+\n1, often represented as 0x1021. This CRC is used in the binhex4 format.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.Error", "path": "library/binascii#binascii.Error", "type": "Internet Data", "text": "\nException raised on errors. These are usually programming errors.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.hexlify()", "path": "library/binascii#binascii.hexlify", "type": "Internet Data", "text": "\nReturn the hexadecimal representation of the binary data. Every byte of data\nis converted into the corresponding 2-digit hex representation. The returned\nbytes object is therefore twice as long as the length of data.\n\nSimilar functionality (but returning a text string) is also conveniently\naccessible using the `bytes.hex()` method.\n\nIf sep is specified, it must be a single character str or bytes object. It\nwill be inserted in the output after every bytes_per_sep input bytes.\nSeparator placement is counted from the right end of the output by default, if\nyou wish to count from the left, supply a negative bytes_per_sep value.\n\nChanged in version 3.8: The sep and bytes_per_sep parameters were added.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.Incomplete", "path": "library/binascii#binascii.Incomplete", "type": "Internet Data", "text": "\nException raised on incomplete data. These are usually not programming errors,\nbut may be handled by reading a little more data and trying again.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.rlecode_hqx()", "path": "library/binascii#binascii.rlecode_hqx", "type": "Internet Data", "text": "\nPerform binhex4 style RLE-compression on data and return the result.\n\nDeprecated since version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.rledecode_hqx()", "path": "library/binascii#binascii.rledecode_hqx", "type": "Internet Data", "text": "\nPerform RLE-decompression on the data, as per the binhex4 standard. The\nalgorithm uses `0x90` after a byte as a repeat indicator, followed by a count.\nA count of `0` specifies a byte value of `0x90`. The routine returns the\ndecompressed data, unless data input data ends in an orphaned repeat\nindicator, in which case the `Incomplete` exception is raised.\n\nChanged in version 3.2: Accept only bytestring or bytearray objects as input.\n\nDeprecated since version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binascii.unhexlify()", "path": "library/binascii#binascii.unhexlify", "type": "Internet Data", "text": "\nReturn the binary data represented by the hexadecimal string hexstr. This\nfunction is the inverse of `b2a_hex()`. hexstr must contain an even number of\nhexadecimal digits (which can be upper or lower case), otherwise an `Error`\nexception is raised.\n\nSimilar functionality (accepting only text string arguments, but more liberal\ntowards whitespace) is also accessible using the `bytes.fromhex()` class\nmethod.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binhex", "path": "library/binhex", "type": "Internet Data", "text": "\nSource code: Lib/binhex.py\n\nDeprecated since version 3.9.\n\nThis module encodes and decodes files in binhex4 format, a format allowing\nrepresentation of Macintosh files in ASCII. Only the data fork is handled.\n\nThe `binhex` module defines the following functions:\n\nConvert a binary file with filename input to binhex file output. The output\nparameter can either be a filename or a file-like object (any object\nsupporting a `write()` and `close()` method).\n\nDecode a binhex file input. input may be a filename or a file-like object\nsupporting `read()` and `close()` methods. The resulting file is written to a\nfile named output, unless the argument is `None` in which case the output\nfilename is read from the binhex file.\n\nThe following exception is also defined:\n\nException raised when something can\u2019t be encoded using the binhex format (for\nexample, a filename is too long to fit in the filename field), or when input\nis not properly encoded binhex data.\n\nSee also\n\nSupport module containing ASCII-to-binary and binary-to-ASCII conversions.\n\nThere is an alternative, more powerful interface to the coder and decoder, see\nthe source for details.\n\nIf you code or decode textfiles on non-Macintosh platforms they will still use\nthe old Macintosh newline convention (carriage-return as end of line).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binhex.binhex()", "path": "library/binhex#binhex.binhex", "type": "Internet Data", "text": "\nConvert a binary file with filename input to binhex file output. The output\nparameter can either be a filename or a file-like object (any object\nsupporting a `write()` and `close()` method).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binhex.Error", "path": "library/binhex#binhex.Error", "type": "Internet Data", "text": "\nException raised when something can\u2019t be encoded using the binhex format (for\nexample, a filename is too long to fit in the filename field), or when input\nis not properly encoded binhex data.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "binhex.hexbin()", "path": "library/binhex#binhex.hexbin", "type": "Internet Data", "text": "\nDecode a binhex file input. input may be a filename or a file-like object\nsupporting `read()` and `close()` methods. The resulting file is written to a\nfile named output, unless the argument is `None` in which case the output\nfilename is read from the binhex file.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bisect", "path": "library/bisect", "type": "Data Types", "text": "\nSource code: Lib/bisect.py\n\nThis module provides support for maintaining a list in sorted order without\nhaving to sort the list after each insertion. For long lists of items with\nexpensive comparison operations, this can be an improvement over the more\ncommon approach. The module is called `bisect` because it uses a basic\nbisection algorithm to do its work. The source code may be most useful as a\nworking example of the algorithm (the boundary conditions are already right!).\n\nThe following functions are provided:\n\nLocate the insertion point for x in a to maintain sorted order. The parameters\nlo and hi may be used to specify a subset of the list which should be\nconsidered; by default the entire list is used. If x is already present in a,\nthe insertion point will be before (to the left of) any existing entries. The\nreturn value is suitable for use as the first parameter to `list.insert()`\nassuming that a is already sorted.\n\nThe returned insertion point i partitions the array a into two halves so that\n`all(val < x for val in a[lo:i])` for the left side and `all(val >= x for val\nin a[i:hi])` for the right side.\n\nSimilar to `bisect_left()`, but returns an insertion point which comes after\n(to the right of) any existing entries of x in a.\n\nThe returned insertion point i partitions the array a into two halves so that\n`all(val <= x for val in a[lo:i])` for the left side and `all(val > x for val\nin a[i:hi])` for the right side.\n\nInsert x in a in sorted order. This is equivalent to\n`a.insert(bisect.bisect_left(a, x, lo, hi), x)` assuming that a is already\nsorted. Keep in mind that the O(log n) search is dominated by the slow O(n)\ninsertion step.\n\nSimilar to `insort_left()`, but inserting x in a after any existing entries of\nx.\n\nSee also\n\nSortedCollection recipe that uses bisect to build a full-featured collection\nclass with straight-forward search methods and support for a key-function. The\nkeys are precomputed to save unnecessary calls to the key function during\nsearches.\n\nThe above `bisect()` functions are useful for finding insertion points but can\nbe tricky or awkward to use for common searching tasks. The following five\nfunctions show how to transform them into the standard lookups for sorted\nlists:\n\nThe `bisect()` function can be useful for numeric table lookups. This example\nuses `bisect()` to look up a letter grade for an exam score (say) based on a\nset of ordered numeric breakpoints: 90 and up is an \u2018A\u2019, 80 to 89 is a \u2018B\u2019,\nand so on:\n\nUnlike the `sorted()` function, it does not make sense for the `bisect()`\nfunctions to have key or reversed arguments because that would lead to an\ninefficient design (successive calls to bisect functions would not \u201cremember\u201d\nall of the previous key lookups).\n\nInstead, it is better to search a list of precomputed keys to find the index\nof the record in question:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bisect.bisect()", "path": "library/bisect#bisect.bisect", "type": "Data Types", "text": "\nSimilar to `bisect_left()`, but returns an insertion point which comes after\n(to the right of) any existing entries of x in a.\n\nThe returned insertion point i partitions the array a into two halves so that\n`all(val <= x for val in a[lo:i])` for the left side and `all(val > x for val\nin a[i:hi])` for the right side.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bisect.bisect_left()", "path": "library/bisect#bisect.bisect_left", "type": "Data Types", "text": "\nLocate the insertion point for x in a to maintain sorted order. The parameters\nlo and hi may be used to specify a subset of the list which should be\nconsidered; by default the entire list is used. If x is already present in a,\nthe insertion point will be before (to the left of) any existing entries. The\nreturn value is suitable for use as the first parameter to `list.insert()`\nassuming that a is already sorted.\n\nThe returned insertion point i partitions the array a into two halves so that\n`all(val < x for val in a[lo:i])` for the left side and `all(val >= x for val\nin a[i:hi])` for the right side.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bisect.bisect_right()", "path": "library/bisect#bisect.bisect_right", "type": "Data Types", "text": "\nSimilar to `bisect_left()`, but returns an insertion point which comes after\n(to the right of) any existing entries of x in a.\n\nThe returned insertion point i partitions the array a into two halves so that\n`all(val <= x for val in a[lo:i])` for the left side and `all(val > x for val\nin a[i:hi])` for the right side.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bisect.insort()", "path": "library/bisect#bisect.insort", "type": "Data Types", "text": "\nSimilar to `insort_left()`, but inserting x in a after any existing entries of\nx.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bisect.insort_left()", "path": "library/bisect#bisect.insort_left", "type": "Data Types", "text": "\nInsert x in a in sorted order. This is equivalent to\n`a.insert(bisect.bisect_left(a, x, lo, hi), x)` assuming that a is already\nsorted. Keep in mind that the O(log n) search is dominated by the slow O(n)\ninsertion step.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bisect.insort_right()", "path": "library/bisect#bisect.insort_right", "type": "Data Types", "text": "\nSimilar to `insort_left()`, but inserting x in a after any existing entries of\nx.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BlockingIOError", "path": "library/exceptions#BlockingIOError", "type": "Built-in Exceptions", "text": "\nRaised when an operation would block on an object (e.g. socket) set for non-\nblocking operation. Corresponds to `errno` `EAGAIN`, `EALREADY`, `EWOULDBLOCK`\nand `EINPROGRESS`.\n\nIn addition to those of `OSError`, `BlockingIOError` can have one more\nattribute:\n\nAn integer containing the number of characters written to the stream before it\nblocked. This attribute is available when using the buffered I/O classes from\nthe `io` module.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BlockingIOError.characters_written", "path": "library/exceptions#BlockingIOError.characters_written", "type": "Built-in Exceptions", "text": "\nAn integer containing the number of characters written to the stream before it\nblocked. This attribute is available when using the buffered I/O classes from\nthe `io` module.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bool", "path": "library/functions#bool", "type": "Built-in Functions", "text": "\nReturn a Boolean value, i.e. one of `True` or `False`. x is converted using\nthe standard truth testing procedure. If x is false or omitted, this returns\n`False`; otherwise it returns `True`. The `bool` class is a subclass of `int`\n(see Numeric Types \u2014 int, float, complex). It cannot be subclassed further.\nIts only instances are `False` and `True` (see Boolean Values).\n\nChanged in version 3.7: x is now a positional-only parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "breakpoint()", "path": "library/functions#breakpoint", "type": "Built-in Functions", "text": "\nThis function drops you into the debugger at the call site. Specifically, it\ncalls `sys.breakpointhook()`, passing `args` and `kws` straight through. By\ndefault, `sys.breakpointhook()` calls `pdb.set_trace()` expecting no\narguments. In this case, it is purely a convenience function so you don\u2019t have\nto explicitly import `pdb` or type as much code to enter the debugger.\nHowever, `sys.breakpointhook()` can be set to some other function and\n`breakpoint()` will automatically call that, allowing you to drop into the\ndebugger of choice.\n\nRaises an auditing event `builtins.breakpoint` with argument `breakpointhook`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BrokenPipeError", "path": "library/exceptions#BrokenPipeError", "type": "Built-in Exceptions", "text": "\nA subclass of `ConnectionError`, raised when trying to write on a pipe while\nthe other end has been closed, or trying to write on a socket which has been\nshutdown for writing. Corresponds to `errno` `EPIPE` and `ESHUTDOWN`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BufferError", "path": "library/exceptions#BufferError", "type": "Built-in Exceptions", "text": "\nRaised when a buffer related operation cannot be performed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "builtins", "path": "library/builtins", "type": "Runtime", "text": "\nThis module provides direct access to all \u2018built-in\u2019 identifiers of Python;\nfor example, `builtins.open` is the full name for the built-in function\n`open()`. See Built-in Functions and Built-in Constants for documentation.\n\nThis module is not normally accessed explicitly by most applications, but can\nbe useful in modules that provide objects with the same name as a built-in\nvalue, but in which the built-in of that name is also needed. For example, in\na module that wants to implement an `open()` function that wraps the built-in\n`open()`, this module can be used directly:\n\nAs an implementation detail, most modules have the name `__builtins__` made\navailable as part of their globals. The value of `__builtins__` is normally\neither this module or the value of this module\u2019s `__dict__` attribute. Since\nthis is an implementation detail, it may not be used by alternate\nimplementations of Python.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray", "path": "library/functions#bytearray", "type": "Built-in Functions", "text": "\nReturn a new array of bytes. The `bytearray` class is a mutable sequence of\nintegers in the range 0 <= x < 256\\. It has most of the usual methods of\nmutable sequences, described in Mutable Sequence Types, as well as most\nmethods that the `bytes` type has, see Bytes and Bytearray Operations.\n\nThe optional source parameter can be used to initialize the array in a few\ndifferent ways:\n\nWithout an argument, an array of size 0 is created.\n\nSee also Binary Sequence Types \u2014 bytes, bytearray, memoryview and Bytearray\nObjects.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray", "path": "library/stdtypes#bytearray", "type": "Built-in Types", "text": "\nThere is no dedicated literal syntax for bytearray objects, instead they are\nalways created by calling the constructor:\n\nAs bytearray objects are mutable, they support the mutable sequence operations\nin addition to the common bytes and bytearray operations described in Bytes\nand Bytearray Operations.\n\nAlso see the bytearray built-in.\n\nSince 2 hexadecimal digits correspond precisely to a single byte, hexadecimal\nnumbers are a commonly used format for describing binary data. Accordingly,\nthe bytearray type has an additional class method to read data in that format:\n\nThis `bytearray` class method returns bytearray object, decoding the given\nstring object. The string must contain two hexadecimal digits per byte, with\nASCII whitespace being ignored.\n\nChanged in version 3.7: `bytearray.fromhex()` now skips all ASCII whitespace\nin the string, not just spaces.\n\nA reverse conversion function exists to transform a bytearray object into its\nhexadecimal representation.\n\nReturn a string object containing two hexadecimal digits for each byte in the\ninstance.\n\nNew in version 3.5.\n\nChanged in version 3.8: Similar to `bytes.hex()`, `bytearray.hex()` now\nsupports optional sep and bytes_per_sep parameters to insert separators\nbetween bytes in the hex output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.capitalize()", "path": "library/stdtypes#bytearray.capitalize", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with each byte interpreted as an ASCII\ncharacter, and the first byte capitalized and the rest lowercased. Non-ASCII\nbyte values are passed through unchanged.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.center()", "path": "library/stdtypes#bytearray.center", "type": "Built-in Types", "text": "\nReturn a copy of the object centered in a sequence of length width. Padding is\ndone using the specified fillbyte (default is an ASCII space). For `bytes`\nobjects, the original sequence is returned if width is less than or equal to\n`len(s)`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.count()", "path": "library/stdtypes#bytearray.count", "type": "Built-in Types", "text": "\nReturn the number of non-overlapping occurrences of subsequence sub in the\nrange [start, end]. Optional arguments start and end are interpreted as in\nslice notation.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.decode()", "path": "library/stdtypes#bytearray.decode", "type": "Built-in Types", "text": "\nReturn a string decoded from the given bytes. Default encoding is `'utf-8'`.\nerrors may be given to set a different error handling scheme. The default for\nerrors is `'strict'`, meaning that encoding errors raise a `UnicodeError`.\nOther possible values are `'ignore'`, `'replace'` and any other name\nregistered via `codecs.register_error()`, see section Error Handlers. For a\nlist of possible encodings, see section Standard Encodings.\n\nBy default, the errors argument is not checked for best performances, but only\nused at the first decoding error. Enable the Python Development Mode, or use a\ndebug build to check errors.\n\nNote\n\nPassing the encoding argument to `str` allows decoding any bytes-like object\ndirectly, without needing to make a temporary bytes or bytearray object.\n\nChanged in version 3.1: Added support for keyword arguments.\n\nChanged in version 3.9: The errors is now checked in development mode and in\ndebug mode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.endswith()", "path": "library/stdtypes#bytearray.endswith", "type": "Built-in Types", "text": "\nReturn `True` if the binary data ends with the specified suffix, otherwise\nreturn `False`. suffix can also be a tuple of suffixes to look for. With\noptional start, test beginning at that position. With optional end, stop\ncomparing at that position.\n\nThe suffix(es) to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.expandtabs()", "path": "library/stdtypes#bytearray.expandtabs", "type": "Built-in Types", "text": "\nReturn a copy of the sequence where all ASCII tab characters are replaced by\none or more ASCII spaces, depending on the current column and the given tab\nsize. Tab positions occur every tabsize bytes (default is 8, giving tab\npositions at columns 0, 8, 16 and so on). To expand the sequence, the current\ncolumn is set to zero and the sequence is examined byte by byte. If the byte\nis an ASCII tab character (`b'\\t'`), one or more space characters are inserted\nin the result until the current column is equal to the next tab position. (The\ntab character itself is not copied.) If the current byte is an ASCII newline\n(`b'\\n'`) or carriage return (`b'\\r'`), it is copied and the current column is\nreset to zero. Any other byte value is copied unchanged and the current column\nis incremented by one regardless of how the byte value is represented when\nprinted:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.find()", "path": "library/stdtypes#bytearray.find", "type": "Built-in Types", "text": "\nReturn the lowest index in the data where the subsequence sub is found, such\nthat sub is contained in the slice `s[start:end]`. Optional arguments start\nand end are interpreted as in slice notation. Return `-1` if sub is not found.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nNote\n\nThe `find()` method should be used only if you need to know the position of\nsub. To check if sub is a substring or not, use the `in` operator:\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.fromhex()", "path": "library/stdtypes#bytearray.fromhex", "type": "Built-in Types", "text": "\nThis `bytearray` class method returns bytearray object, decoding the given\nstring object. The string must contain two hexadecimal digits per byte, with\nASCII whitespace being ignored.\n\nChanged in version 3.7: `bytearray.fromhex()` now skips all ASCII whitespace\nin the string, not just spaces.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.hex()", "path": "library/stdtypes#bytearray.hex", "type": "Built-in Types", "text": "\nReturn a string object containing two hexadecimal digits for each byte in the\ninstance.\n\nNew in version 3.5.\n\nChanged in version 3.8: Similar to `bytes.hex()`, `bytearray.hex()` now\nsupports optional sep and bytes_per_sep parameters to insert separators\nbetween bytes in the hex output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.index()", "path": "library/stdtypes#bytearray.index", "type": "Built-in Types", "text": "\nLike `find()`, but raise `ValueError` when the subsequence is not found.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.isalnum()", "path": "library/stdtypes#bytearray.isalnum", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are alphabetical ASCII characters\nor ASCII decimal digits and the sequence is not empty, `False` otherwise.\nAlphabetic ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'`. ASCII decimal\ndigits are those byte values in the sequence `b'0123456789'`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.isalpha()", "path": "library/stdtypes#bytearray.isalpha", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are alphabetic ASCII characters and\nthe sequence is not empty, `False` otherwise. Alphabetic ASCII characters are\nthose byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.isascii()", "path": "library/stdtypes#bytearray.isascii", "type": "Built-in Types", "text": "\nReturn `True` if the sequence is empty or all bytes in the sequence are ASCII,\n`False` otherwise. ASCII bytes are in the range 0-0x7F.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.isdigit()", "path": "library/stdtypes#bytearray.isdigit", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are ASCII decimal digits and the\nsequence is not empty, `False` otherwise. ASCII decimal digits are those byte\nvalues in the sequence `b'0123456789'`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.islower()", "path": "library/stdtypes#bytearray.islower", "type": "Built-in Types", "text": "\nReturn `True` if there is at least one lowercase ASCII character in the\nsequence and no uppercase ASCII characters, `False` otherwise.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.isspace()", "path": "library/stdtypes#bytearray.isspace", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are ASCII whitespace and the\nsequence is not empty, `False` otherwise. ASCII whitespace characters are\nthose byte values in the sequence `b' \\t\\n\\r\\x0b\\f'` (space, tab, newline,\ncarriage return, vertical tab, form feed).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.istitle()", "path": "library/stdtypes#bytearray.istitle", "type": "Built-in Types", "text": "\nReturn `True` if the sequence is ASCII titlecase and the sequence is not\nempty, `False` otherwise. See `bytes.title()` for more details on the\ndefinition of \u201ctitlecase\u201d.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.isupper()", "path": "library/stdtypes#bytearray.isupper", "type": "Built-in Types", "text": "\nReturn `True` if there is at least one uppercase alphabetic ASCII character in\nthe sequence and no lowercase ASCII characters, `False` otherwise.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.join()", "path": "library/stdtypes#bytearray.join", "type": "Built-in Types", "text": "\nReturn a bytes or bytearray object which is the concatenation of the binary\ndata sequences in iterable. A `TypeError` will be raised if there are any\nvalues in iterable that are not bytes-like objects, including `str` objects.\nThe separator between elements is the contents of the bytes or bytearray\nobject providing this method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.ljust()", "path": "library/stdtypes#bytearray.ljust", "type": "Built-in Types", "text": "\nReturn a copy of the object left justified in a sequence of length width.\nPadding is done using the specified fillbyte (default is an ASCII space). For\n`bytes` objects, the original sequence is returned if width is less than or\nequal to `len(s)`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.lower()", "path": "library/stdtypes#bytearray.lower", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all the uppercase ASCII characters\nconverted to their corresponding lowercase counterpart.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.lstrip()", "path": "library/stdtypes#bytearray.lstrip", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with specified leading bytes removed. The chars\nargument is a binary sequence specifying the set of byte values to be removed\n- the name refers to the fact this method is usually used with ASCII\ncharacters. If omitted or `None`, the chars argument defaults to removing\nASCII whitespace. The chars argument is not a prefix; rather, all combinations\nof its values are stripped:\n\nThe binary sequence of byte values to remove may be any bytes-like object. See\n`removeprefix()` for a method that will remove a single prefix string rather\nthan all of a set of characters. For example:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.maketrans()", "path": "library/stdtypes#bytearray.maketrans", "type": "Built-in Types", "text": "\nThis static method returns a translation table usable for `bytes.translate()`\nthat will map each character in from into the character at the same position\nin to; from and to must both be bytes-like objects and have the same length.\n\nNew in version 3.1.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.partition()", "path": "library/stdtypes#bytearray.partition", "type": "Built-in Types", "text": "\nSplit the sequence at the first occurrence of sep, and return a 3-tuple\ncontaining the part before the separator, the separator itself or its\nbytearray copy, and the part after the separator. If the separator is not\nfound, return a 3-tuple containing a copy of the original sequence, followed\nby two empty bytes or bytearray objects.\n\nThe separator to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.removeprefix()", "path": "library/stdtypes#bytearray.removeprefix", "type": "Built-in Types", "text": "\nIf the binary data starts with the prefix string, return\n`bytes[len(prefix):]`. Otherwise, return a copy of the original binary data:\n\nThe prefix may be any bytes-like object.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\nNew in version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.removesuffix()", "path": "library/stdtypes#bytearray.removesuffix", "type": "Built-in Types", "text": "\nIf the binary data ends with the suffix string and that suffix is not empty,\nreturn `bytes[:-len(suffix)]`. Otherwise, return a copy of the original binary\ndata:\n\nThe suffix may be any bytes-like object.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\nNew in version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.replace()", "path": "library/stdtypes#bytearray.replace", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all occurrences of subsequence old replaced\nby new. If the optional argument count is given, only the first count\noccurrences are replaced.\n\nThe subsequence to search for and its replacement may be any bytes-like\nobject.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.rfind()", "path": "library/stdtypes#bytearray.rfind", "type": "Built-in Types", "text": "\nReturn the highest index in the sequence where the subsequence sub is found,\nsuch that sub is contained within `s[start:end]`. Optional arguments start and\nend are interpreted as in slice notation. Return `-1` on failure.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.rindex()", "path": "library/stdtypes#bytearray.rindex", "type": "Built-in Types", "text": "\nLike `rfind()` but raises `ValueError` when the subsequence sub is not found.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.rjust()", "path": "library/stdtypes#bytearray.rjust", "type": "Built-in Types", "text": "\nReturn a copy of the object right justified in a sequence of length width.\nPadding is done using the specified fillbyte (default is an ASCII space). For\n`bytes` objects, the original sequence is returned if width is less than or\nequal to `len(s)`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.rpartition()", "path": "library/stdtypes#bytearray.rpartition", "type": "Built-in Types", "text": "\nSplit the sequence at the last occurrence of sep, and return a 3-tuple\ncontaining the part before the separator, the separator itself or its\nbytearray copy, and the part after the separator. If the separator is not\nfound, return a 3-tuple containing two empty bytes or bytearray objects,\nfollowed by a copy of the original sequence.\n\nThe separator to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.rsplit()", "path": "library/stdtypes#bytearray.rsplit", "type": "Built-in Types", "text": "\nSplit the binary sequence into subsequences of the same type, using sep as the\ndelimiter string. If maxsplit is given, at most maxsplit splits are done, the\nrightmost ones. If sep is not specified or `None`, any subsequence consisting\nsolely of ASCII whitespace is a separator. Except for splitting from the\nright, `rsplit()` behaves like `split()` which is described in detail below.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.rstrip()", "path": "library/stdtypes#bytearray.rstrip", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with specified trailing bytes removed. The chars\nargument is a binary sequence specifying the set of byte values to be removed\n- the name refers to the fact this method is usually used with ASCII\ncharacters. If omitted or `None`, the chars argument defaults to removing\nASCII whitespace. The chars argument is not a suffix; rather, all combinations\nof its values are stripped:\n\nThe binary sequence of byte values to remove may be any bytes-like object. See\n`removesuffix()` for a method that will remove a single suffix string rather\nthan all of a set of characters. For example:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.split()", "path": "library/stdtypes#bytearray.split", "type": "Built-in Types", "text": "\nSplit the binary sequence into subsequences of the same type, using sep as the\ndelimiter string. If maxsplit is given and non-negative, at most maxsplit\nsplits are done (thus, the list will have at most `maxsplit+1` elements). If\nmaxsplit is not specified or is `-1`, then there is no limit on the number of\nsplits (all possible splits are made).\n\nIf sep is given, consecutive delimiters are not grouped together and are\ndeemed to delimit empty subsequences (for example, `b'1,,2'.split(b',')`\nreturns `[b'1', b'', b'2']`). The sep argument may consist of a multibyte\nsequence (for example, `b'1<>2<>3'.split(b'<>')` returns `[b'1', b'2',\nb'3']`). Splitting an empty sequence with a specified separator returns\n`[b'']` or `[bytearray(b'')]` depending on the type of object being split. The\nsep argument may be any bytes-like object.\n\nFor example:\n\nIf sep is not specified or is `None`, a different splitting algorithm is\napplied: runs of consecutive ASCII whitespace are regarded as a single\nseparator, and the result will contain no empty strings at the start or end if\nthe sequence has leading or trailing whitespace. Consequently, splitting an\nempty sequence or a sequence consisting solely of ASCII whitespace without a\nspecified separator returns `[]`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.splitlines()", "path": "library/stdtypes#bytearray.splitlines", "type": "Built-in Types", "text": "\nReturn a list of the lines in the binary sequence, breaking at ASCII line\nboundaries. This method uses the universal newlines approach to splitting\nlines. Line breaks are not included in the resulting list unless keepends is\ngiven and true.\n\nFor example:\n\nUnlike `split()` when a delimiter string sep is given, this method returns an\nempty list for the empty string, and a terminal line break does not result in\nan extra line:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.startswith()", "path": "library/stdtypes#bytearray.startswith", "type": "Built-in Types", "text": "\nReturn `True` if the binary data starts with the specified prefix, otherwise\nreturn `False`. prefix can also be a tuple of prefixes to look for. With\noptional start, test beginning at that position. With optional end, stop\ncomparing at that position.\n\nThe prefix(es) to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.strip()", "path": "library/stdtypes#bytearray.strip", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with specified leading and trailing bytes\nremoved. The chars argument is a binary sequence specifying the set of byte\nvalues to be removed - the name refers to the fact this method is usually used\nwith ASCII characters. If omitted or `None`, the chars argument defaults to\nremoving ASCII whitespace. The chars argument is not a prefix or suffix;\nrather, all combinations of its values are stripped:\n\nThe binary sequence of byte values to remove may be any bytes-like object.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.swapcase()", "path": "library/stdtypes#bytearray.swapcase", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all the lowercase ASCII characters\nconverted to their corresponding uppercase counterpart and vice-versa.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nUnlike `str.swapcase()`, it is always the case that `bin.swapcase().swapcase()\n== bin` for the binary versions. Case conversions are symmetrical in ASCII,\neven though that is not generally true for arbitrary Unicode code points.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.title()", "path": "library/stdtypes#bytearray.title", "type": "Built-in Types", "text": "\nReturn a titlecased version of the binary sequence where words start with an\nuppercase ASCII character and the remaining characters are lowercase. Uncased\nbyte values are left unmodified.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`. All other byte values\nare uncased.\n\nThe algorithm uses a simple language-independent definition of a word as\ngroups of consecutive letters. The definition works in many contexts but it\nmeans that apostrophes in contractions and possessives form word boundaries,\nwhich may not be the desired result:\n\nA workaround for apostrophes can be constructed using regular expressions:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.translate()", "path": "library/stdtypes#bytearray.translate", "type": "Built-in Types", "text": "\nReturn a copy of the bytes or bytearray object where all bytes occurring in\nthe optional argument delete are removed, and the remaining bytes have been\nmapped through the given translation table, which must be a bytes object of\nlength 256.\n\nYou can use the `bytes.maketrans()` method to create a translation table.\n\nSet the table argument to `None` for translations that only delete characters:\n\nChanged in version 3.6: delete is now supported as a keyword argument.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.upper()", "path": "library/stdtypes#bytearray.upper", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all the lowercase ASCII characters\nconverted to their corresponding uppercase counterpart.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytearray.zfill()", "path": "library/stdtypes#bytearray.zfill", "type": "Built-in Types", "text": "\nReturn a copy of the sequence left filled with ASCII `b'0'` digits to make a\nsequence of length width. A leading sign prefix (`b'+'`/ `b'-'`) is handled by\ninserting the padding after the sign character rather than before. For `bytes`\nobjects, the original sequence is returned if width is less than or equal to\n`len(seq)`.\n\nFor example:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes", "path": "library/stdtypes#bytes", "type": "Built-in Types", "text": "\nFirstly, the syntax for bytes literals is largely the same as that for string\nliterals, except that a `b` prefix is added:\n\nOnly ASCII characters are permitted in bytes literals (regardless of the\ndeclared source code encoding). Any binary values over 127 must be entered\ninto bytes literals using the appropriate escape sequence.\n\nAs with string literals, bytes literals may also use a `r` prefix to disable\nprocessing of escape sequences. See String and Bytes literals for more about\nthe various forms of bytes literal, including supported escape sequences.\n\nWhile bytes literals and representations are based on ASCII text, bytes\nobjects actually behave like immutable sequences of integers, with each value\nin the sequence restricted such that `0 <= x < 256` (attempts to violate this\nrestriction will trigger `ValueError`). This is done deliberately to emphasise\nthat while many binary formats include ASCII based elements and can be\nusefully manipulated with some text-oriented algorithms, this is not generally\nthe case for arbitrary binary data (blindly applying text processing\nalgorithms to binary data formats that are not ASCII compatible will usually\nlead to data corruption).\n\nIn addition to the literal forms, bytes objects can be created in a number of\nother ways:\n\nAlso see the bytes built-in.\n\nSince 2 hexadecimal digits correspond precisely to a single byte, hexadecimal\nnumbers are a commonly used format for describing binary data. Accordingly,\nthe bytes type has an additional class method to read data in that format:\n\nThis `bytes` class method returns a bytes object, decoding the given string\nobject. The string must contain two hexadecimal digits per byte, with ASCII\nwhitespace being ignored.\n\nChanged in version 3.7: `bytes.fromhex()` now skips all ASCII whitespace in\nthe string, not just spaces.\n\nA reverse conversion function exists to transform a bytes object into its\nhexadecimal representation.\n\nReturn a string object containing two hexadecimal digits for each byte in the\ninstance.\n\nIf you want to make the hex string easier to read, you can specify a single\ncharacter separator sep parameter to include in the output. By default between\neach byte. A second optional bytes_per_sep parameter controls the spacing.\nPositive values calculate the separator position from the right, negative\nvalues from the left.\n\nNew in version 3.5.\n\nChanged in version 3.8: `bytes.hex()` now supports optional sep and\nbytes_per_sep parameters to insert separators between bytes in the hex output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes", "path": "library/functions#bytes", "type": "Built-in Functions", "text": "\nReturn a new \u201cbytes\u201d object, which is an immutable sequence of integers in the\nrange `0 <= x < 256`. `bytes` is an immutable version of `bytearray` \u2013 it has\nthe same non-mutating methods and the same indexing and slicing behavior.\n\nAccordingly, constructor arguments are interpreted as for `bytearray()`.\n\nBytes objects can also be created with literals, see String and Bytes\nliterals.\n\nSee also Binary Sequence Types \u2014 bytes, bytearray, memoryview, Bytes Objects,\nand Bytes and Bytearray Operations.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.capitalize()", "path": "library/stdtypes#bytes.capitalize", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with each byte interpreted as an ASCII\ncharacter, and the first byte capitalized and the rest lowercased. Non-ASCII\nbyte values are passed through unchanged.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.center()", "path": "library/stdtypes#bytes.center", "type": "Built-in Types", "text": "\nReturn a copy of the object centered in a sequence of length width. Padding is\ndone using the specified fillbyte (default is an ASCII space). For `bytes`\nobjects, the original sequence is returned if width is less than or equal to\n`len(s)`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.count()", "path": "library/stdtypes#bytes.count", "type": "Built-in Types", "text": "\nReturn the number of non-overlapping occurrences of subsequence sub in the\nrange [start, end]. Optional arguments start and end are interpreted as in\nslice notation.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.decode()", "path": "library/stdtypes#bytes.decode", "type": "Built-in Types", "text": "\nReturn a string decoded from the given bytes. Default encoding is `'utf-8'`.\nerrors may be given to set a different error handling scheme. The default for\nerrors is `'strict'`, meaning that encoding errors raise a `UnicodeError`.\nOther possible values are `'ignore'`, `'replace'` and any other name\nregistered via `codecs.register_error()`, see section Error Handlers. For a\nlist of possible encodings, see section Standard Encodings.\n\nBy default, the errors argument is not checked for best performances, but only\nused at the first decoding error. Enable the Python Development Mode, or use a\ndebug build to check errors.\n\nNote\n\nPassing the encoding argument to `str` allows decoding any bytes-like object\ndirectly, without needing to make a temporary bytes or bytearray object.\n\nChanged in version 3.1: Added support for keyword arguments.\n\nChanged in version 3.9: The errors is now checked in development mode and in\ndebug mode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.endswith()", "path": "library/stdtypes#bytes.endswith", "type": "Built-in Types", "text": "\nReturn `True` if the binary data ends with the specified suffix, otherwise\nreturn `False`. suffix can also be a tuple of suffixes to look for. With\noptional start, test beginning at that position. With optional end, stop\ncomparing at that position.\n\nThe suffix(es) to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.expandtabs()", "path": "library/stdtypes#bytes.expandtabs", "type": "Built-in Types", "text": "\nReturn a copy of the sequence where all ASCII tab characters are replaced by\none or more ASCII spaces, depending on the current column and the given tab\nsize. Tab positions occur every tabsize bytes (default is 8, giving tab\npositions at columns 0, 8, 16 and so on). To expand the sequence, the current\ncolumn is set to zero and the sequence is examined byte by byte. If the byte\nis an ASCII tab character (`b'\\t'`), one or more space characters are inserted\nin the result until the current column is equal to the next tab position. (The\ntab character itself is not copied.) If the current byte is an ASCII newline\n(`b'\\n'`) or carriage return (`b'\\r'`), it is copied and the current column is\nreset to zero. Any other byte value is copied unchanged and the current column\nis incremented by one regardless of how the byte value is represented when\nprinted:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.find()", "path": "library/stdtypes#bytes.find", "type": "Built-in Types", "text": "\nReturn the lowest index in the data where the subsequence sub is found, such\nthat sub is contained in the slice `s[start:end]`. Optional arguments start\nand end are interpreted as in slice notation. Return `-1` if sub is not found.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nNote\n\nThe `find()` method should be used only if you need to know the position of\nsub. To check if sub is a substring or not, use the `in` operator:\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.fromhex()", "path": "library/stdtypes#bytes.fromhex", "type": "Built-in Types", "text": "\nThis `bytes` class method returns a bytes object, decoding the given string\nobject. The string must contain two hexadecimal digits per byte, with ASCII\nwhitespace being ignored.\n\nChanged in version 3.7: `bytes.fromhex()` now skips all ASCII whitespace in\nthe string, not just spaces.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.hex()", "path": "library/stdtypes#bytes.hex", "type": "Built-in Types", "text": "\nReturn a string object containing two hexadecimal digits for each byte in the\ninstance.\n\nIf you want to make the hex string easier to read, you can specify a single\ncharacter separator sep parameter to include in the output. By default between\neach byte. A second optional bytes_per_sep parameter controls the spacing.\nPositive values calculate the separator position from the right, negative\nvalues from the left.\n\nNew in version 3.5.\n\nChanged in version 3.8: `bytes.hex()` now supports optional sep and\nbytes_per_sep parameters to insert separators between bytes in the hex output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.index()", "path": "library/stdtypes#bytes.index", "type": "Built-in Types", "text": "\nLike `find()`, but raise `ValueError` when the subsequence is not found.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.isalnum()", "path": "library/stdtypes#bytes.isalnum", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are alphabetical ASCII characters\nor ASCII decimal digits and the sequence is not empty, `False` otherwise.\nAlphabetic ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'`. ASCII decimal\ndigits are those byte values in the sequence `b'0123456789'`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.isalpha()", "path": "library/stdtypes#bytes.isalpha", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are alphabetic ASCII characters and\nthe sequence is not empty, `False` otherwise. Alphabetic ASCII characters are\nthose byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.isascii()", "path": "library/stdtypes#bytes.isascii", "type": "Built-in Types", "text": "\nReturn `True` if the sequence is empty or all bytes in the sequence are ASCII,\n`False` otherwise. ASCII bytes are in the range 0-0x7F.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.isdigit()", "path": "library/stdtypes#bytes.isdigit", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are ASCII decimal digits and the\nsequence is not empty, `False` otherwise. ASCII decimal digits are those byte\nvalues in the sequence `b'0123456789'`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.islower()", "path": "library/stdtypes#bytes.islower", "type": "Built-in Types", "text": "\nReturn `True` if there is at least one lowercase ASCII character in the\nsequence and no uppercase ASCII characters, `False` otherwise.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.isspace()", "path": "library/stdtypes#bytes.isspace", "type": "Built-in Types", "text": "\nReturn `True` if all bytes in the sequence are ASCII whitespace and the\nsequence is not empty, `False` otherwise. ASCII whitespace characters are\nthose byte values in the sequence `b' \\t\\n\\r\\x0b\\f'` (space, tab, newline,\ncarriage return, vertical tab, form feed).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.istitle()", "path": "library/stdtypes#bytes.istitle", "type": "Built-in Types", "text": "\nReturn `True` if the sequence is ASCII titlecase and the sequence is not\nempty, `False` otherwise. See `bytes.title()` for more details on the\ndefinition of \u201ctitlecase\u201d.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.isupper()", "path": "library/stdtypes#bytes.isupper", "type": "Built-in Types", "text": "\nReturn `True` if there is at least one uppercase alphabetic ASCII character in\nthe sequence and no lowercase ASCII characters, `False` otherwise.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.join()", "path": "library/stdtypes#bytes.join", "type": "Built-in Types", "text": "\nReturn a bytes or bytearray object which is the concatenation of the binary\ndata sequences in iterable. A `TypeError` will be raised if there are any\nvalues in iterable that are not bytes-like objects, including `str` objects.\nThe separator between elements is the contents of the bytes or bytearray\nobject providing this method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.ljust()", "path": "library/stdtypes#bytes.ljust", "type": "Built-in Types", "text": "\nReturn a copy of the object left justified in a sequence of length width.\nPadding is done using the specified fillbyte (default is an ASCII space). For\n`bytes` objects, the original sequence is returned if width is less than or\nequal to `len(s)`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.lower()", "path": "library/stdtypes#bytes.lower", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all the uppercase ASCII characters\nconverted to their corresponding lowercase counterpart.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.lstrip()", "path": "library/stdtypes#bytes.lstrip", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with specified leading bytes removed. The chars\nargument is a binary sequence specifying the set of byte values to be removed\n- the name refers to the fact this method is usually used with ASCII\ncharacters. If omitted or `None`, the chars argument defaults to removing\nASCII whitespace. The chars argument is not a prefix; rather, all combinations\nof its values are stripped:\n\nThe binary sequence of byte values to remove may be any bytes-like object. See\n`removeprefix()` for a method that will remove a single prefix string rather\nthan all of a set of characters. For example:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.maketrans()", "path": "library/stdtypes#bytes.maketrans", "type": "Built-in Types", "text": "\nThis static method returns a translation table usable for `bytes.translate()`\nthat will map each character in from into the character at the same position\nin to; from and to must both be bytes-like objects and have the same length.\n\nNew in version 3.1.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.partition()", "path": "library/stdtypes#bytes.partition", "type": "Built-in Types", "text": "\nSplit the sequence at the first occurrence of sep, and return a 3-tuple\ncontaining the part before the separator, the separator itself or its\nbytearray copy, and the part after the separator. If the separator is not\nfound, return a 3-tuple containing a copy of the original sequence, followed\nby two empty bytes or bytearray objects.\n\nThe separator to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.removeprefix()", "path": "library/stdtypes#bytes.removeprefix", "type": "Built-in Types", "text": "\nIf the binary data starts with the prefix string, return\n`bytes[len(prefix):]`. Otherwise, return a copy of the original binary data:\n\nThe prefix may be any bytes-like object.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\nNew in version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.removesuffix()", "path": "library/stdtypes#bytes.removesuffix", "type": "Built-in Types", "text": "\nIf the binary data ends with the suffix string and that suffix is not empty,\nreturn `bytes[:-len(suffix)]`. Otherwise, return a copy of the original binary\ndata:\n\nThe suffix may be any bytes-like object.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\nNew in version 3.9.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.replace()", "path": "library/stdtypes#bytes.replace", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all occurrences of subsequence old replaced\nby new. If the optional argument count is given, only the first count\noccurrences are replaced.\n\nThe subsequence to search for and its replacement may be any bytes-like\nobject.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.rfind()", "path": "library/stdtypes#bytes.rfind", "type": "Built-in Types", "text": "\nReturn the highest index in the sequence where the subsequence sub is found,\nsuch that sub is contained within `s[start:end]`. Optional arguments start and\nend are interpreted as in slice notation. Return `-1` on failure.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.rindex()", "path": "library/stdtypes#bytes.rindex", "type": "Built-in Types", "text": "\nLike `rfind()` but raises `ValueError` when the subsequence sub is not found.\n\nThe subsequence to search for may be any bytes-like object or an integer in\nthe range 0 to 255.\n\nChanged in version 3.3: Also accept an integer in the range 0 to 255 as the\nsubsequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.rjust()", "path": "library/stdtypes#bytes.rjust", "type": "Built-in Types", "text": "\nReturn a copy of the object right justified in a sequence of length width.\nPadding is done using the specified fillbyte (default is an ASCII space). For\n`bytes` objects, the original sequence is returned if width is less than or\nequal to `len(s)`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.rpartition()", "path": "library/stdtypes#bytes.rpartition", "type": "Built-in Types", "text": "\nSplit the sequence at the last occurrence of sep, and return a 3-tuple\ncontaining the part before the separator, the separator itself or its\nbytearray copy, and the part after the separator. If the separator is not\nfound, return a 3-tuple containing two empty bytes or bytearray objects,\nfollowed by a copy of the original sequence.\n\nThe separator to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.rsplit()", "path": "library/stdtypes#bytes.rsplit", "type": "Built-in Types", "text": "\nSplit the binary sequence into subsequences of the same type, using sep as the\ndelimiter string. If maxsplit is given, at most maxsplit splits are done, the\nrightmost ones. If sep is not specified or `None`, any subsequence consisting\nsolely of ASCII whitespace is a separator. Except for splitting from the\nright, `rsplit()` behaves like `split()` which is described in detail below.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.rstrip()", "path": "library/stdtypes#bytes.rstrip", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with specified trailing bytes removed. The chars\nargument is a binary sequence specifying the set of byte values to be removed\n- the name refers to the fact this method is usually used with ASCII\ncharacters. If omitted or `None`, the chars argument defaults to removing\nASCII whitespace. The chars argument is not a suffix; rather, all combinations\nof its values are stripped:\n\nThe binary sequence of byte values to remove may be any bytes-like object. See\n`removesuffix()` for a method that will remove a single suffix string rather\nthan all of a set of characters. For example:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.split()", "path": "library/stdtypes#bytes.split", "type": "Built-in Types", "text": "\nSplit the binary sequence into subsequences of the same type, using sep as the\ndelimiter string. If maxsplit is given and non-negative, at most maxsplit\nsplits are done (thus, the list will have at most `maxsplit+1` elements). If\nmaxsplit is not specified or is `-1`, then there is no limit on the number of\nsplits (all possible splits are made).\n\nIf sep is given, consecutive delimiters are not grouped together and are\ndeemed to delimit empty subsequences (for example, `b'1,,2'.split(b',')`\nreturns `[b'1', b'', b'2']`). The sep argument may consist of a multibyte\nsequence (for example, `b'1<>2<>3'.split(b'<>')` returns `[b'1', b'2',\nb'3']`). Splitting an empty sequence with a specified separator returns\n`[b'']` or `[bytearray(b'')]` depending on the type of object being split. The\nsep argument may be any bytes-like object.\n\nFor example:\n\nIf sep is not specified or is `None`, a different splitting algorithm is\napplied: runs of consecutive ASCII whitespace are regarded as a single\nseparator, and the result will contain no empty strings at the start or end if\nthe sequence has leading or trailing whitespace. Consequently, splitting an\nempty sequence or a sequence consisting solely of ASCII whitespace without a\nspecified separator returns `[]`.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.splitlines()", "path": "library/stdtypes#bytes.splitlines", "type": "Built-in Types", "text": "\nReturn a list of the lines in the binary sequence, breaking at ASCII line\nboundaries. This method uses the universal newlines approach to splitting\nlines. Line breaks are not included in the resulting list unless keepends is\ngiven and true.\n\nFor example:\n\nUnlike `split()` when a delimiter string sep is given, this method returns an\nempty list for the empty string, and a terminal line break does not result in\nan extra line:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.startswith()", "path": "library/stdtypes#bytes.startswith", "type": "Built-in Types", "text": "\nReturn `True` if the binary data starts with the specified prefix, otherwise\nreturn `False`. prefix can also be a tuple of prefixes to look for. With\noptional start, test beginning at that position. With optional end, stop\ncomparing at that position.\n\nThe prefix(es) to search for may be any bytes-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.strip()", "path": "library/stdtypes#bytes.strip", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with specified leading and trailing bytes\nremoved. The chars argument is a binary sequence specifying the set of byte\nvalues to be removed - the name refers to the fact this method is usually used\nwith ASCII characters. If omitted or `None`, the chars argument defaults to\nremoving ASCII whitespace. The chars argument is not a prefix or suffix;\nrather, all combinations of its values are stripped:\n\nThe binary sequence of byte values to remove may be any bytes-like object.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.swapcase()", "path": "library/stdtypes#bytes.swapcase", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all the lowercase ASCII characters\nconverted to their corresponding uppercase counterpart and vice-versa.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nUnlike `str.swapcase()`, it is always the case that `bin.swapcase().swapcase()\n== bin` for the binary versions. Case conversions are symmetrical in ASCII,\neven though that is not generally true for arbitrary Unicode code points.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.title()", "path": "library/stdtypes#bytes.title", "type": "Built-in Types", "text": "\nReturn a titlecased version of the binary sequence where words start with an\nuppercase ASCII character and the remaining characters are lowercase. Uncased\nbyte values are left unmodified.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`. All other byte values\nare uncased.\n\nThe algorithm uses a simple language-independent definition of a word as\ngroups of consecutive letters. The definition works in many contexts but it\nmeans that apostrophes in contractions and possessives form word boundaries,\nwhich may not be the desired result:\n\nA workaround for apostrophes can be constructed using regular expressions:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.translate()", "path": "library/stdtypes#bytes.translate", "type": "Built-in Types", "text": "\nReturn a copy of the bytes or bytearray object where all bytes occurring in\nthe optional argument delete are removed, and the remaining bytes have been\nmapped through the given translation table, which must be a bytes object of\nlength 256.\n\nYou can use the `bytes.maketrans()` method to create a translation table.\n\nSet the table argument to `None` for translations that only delete characters:\n\nChanged in version 3.6: delete is now supported as a keyword argument.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.upper()", "path": "library/stdtypes#bytes.upper", "type": "Built-in Types", "text": "\nReturn a copy of the sequence with all the lowercase ASCII characters\nconverted to their corresponding uppercase counterpart.\n\nFor example:\n\nLowercase ASCII characters are those byte values in the sequence\n`b'abcdefghijklmnopqrstuvwxyz'`. Uppercase ASCII characters are those byte\nvalues in the sequence `b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'`.\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bytes.zfill()", "path": "library/stdtypes#bytes.zfill", "type": "Built-in Types", "text": "\nReturn a copy of the sequence left filled with ASCII `b'0'` digits to make a\nsequence of length width. A leading sign prefix (`b'+'`/ `b'-'`) is handled by\ninserting the padding after the sign character rather than before. For `bytes`\nobjects, the original sequence is returned if width is less than or equal to\n`len(seq)`.\n\nFor example:\n\nNote\n\nThe bytearray version of this method does not operate in place - it always\nproduces a new object, even if no changes were made.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "BytesWarning", "path": "library/exceptions#BytesWarning", "type": "Built-in Exceptions", "text": "\nBase class for warnings related to `bytes` and `bytearray`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2", "path": "library/bz2", "type": "Data Compression", "text": "\nSource code: Lib/bz2.py\n\nThis module provides a comprehensive interface for compressing and\ndecompressing data using the bzip2 compression algorithm.\n\nThe `bz2` module contains:\n\nAll of the classes in this module may safely be accessed from multiple\nthreads.\n\nOpen a bzip2-compressed file in binary or text mode, returning a file object.\n\nAs with the constructor for `BZ2File`, the filename argument can be an actual\nfilename (a `str` or `bytes` object), or an existing file object to read from\nor write to.\n\nThe mode argument can be any of `'r'`, `'rb'`, `'w'`, `'wb'`, `'x'`, `'xb'`,\n`'a'` or `'ab'` for binary mode, or `'rt'`, `'wt'`, `'xt'`, or `'at'` for text\nmode. The default is `'rb'`.\n\nThe compresslevel argument is an integer from 1 to 9, as for the `BZ2File`\nconstructor.\n\nFor binary mode, this function is equivalent to the `BZ2File` constructor:\n`BZ2File(filename, mode, compresslevel=compresslevel)`. In this case, the\nencoding, errors and newline arguments must not be provided.\n\nFor text mode, a `BZ2File` object is created, and wrapped in an\n`io.TextIOWrapper` instance with the specified encoding, error handling\nbehavior, and line ending(s).\n\nNew in version 3.3.\n\nChanged in version 3.4: The `'x'` (exclusive creation) mode was added.\n\nChanged in version 3.6: Accepts a path-like object.\n\nOpen a bzip2-compressed file in binary mode.\n\nIf filename is a `str` or `bytes` object, open the named file directly.\nOtherwise, filename should be a file object, which will be used to read or\nwrite the compressed data.\n\nThe mode argument can be either `'r'` for reading (default), `'w'` for\noverwriting, `'x'` for exclusive creation, or `'a'` for appending. These can\nequivalently be given as `'rb'`, `'wb'`, `'xb'` and `'ab'` respectively.\n\nIf filename is a file object (rather than an actual file name), a mode of\n`'w'` does not truncate the file, and is instead equivalent to `'a'`.\n\nIf mode is `'w'` or `'a'`, compresslevel can be an integer between `1` and `9`\nspecifying the level of compression: `1` produces the least compression, and\n`9` (default) produces the most compression.\n\nIf mode is `'r'`, the input file may be the concatenation of multiple\ncompressed streams.\n\n`BZ2File` provides all of the members specified by the `io.BufferedIOBase`,\nexcept for `detach()` and `truncate()`. Iteration and the `with` statement are\nsupported.\n\n`BZ2File` also provides the following method:\n\nReturn buffered data without advancing the file position. At least one byte of\ndata will be returned (unless at EOF). The exact number of bytes returned is\nunspecified.\n\nNote\n\nWhile calling `peek()` does not change the file position of the `BZ2File`, it\nmay change the position of the underlying file object (e.g. if the `BZ2File`\nwas constructed by passing a file object for filename).\n\nNew in version 3.3.\n\nChanged in version 3.1: Support for the `with` statement was added.\n\nChanged in version 3.3: The `fileno()`, `readable()`, `seekable()`,\n`writable()`, `read1()` and `readinto()` methods were added.\n\nChanged in version 3.3: Support was added for filename being a file object\ninstead of an actual filename.\n\nChanged in version 3.3: The `'a'` (append) mode was added, along with support\nfor reading multi-stream files.\n\nChanged in version 3.4: The `'x'` (exclusive creation) mode was added.\n\nChanged in version 3.5: The `read()` method now accepts an argument of `None`.\n\nChanged in version 3.6: Accepts a path-like object.\n\nChanged in version 3.9: The buffering parameter has been removed. It was\nignored and deprecated since Python 3.0. Pass an open file object to control\nhow the file is opened.\n\nThe compresslevel parameter became keyword-only.\n\nCreate a new compressor object. This object may be used to compress data\nincrementally. For one-shot compression, use the `compress()` function\ninstead.\n\ncompresslevel, if given, must be an integer between `1` and `9`. The default\nis `9`.\n\nProvide data to the compressor object. Returns a chunk of compressed data if\npossible, or an empty byte string otherwise.\n\nWhen you have finished providing data to the compressor, call the `flush()`\nmethod to finish the compression process.\n\nFinish the compression process. Returns the compressed data left in internal\nbuffers.\n\nThe compressor object may not be used after this method has been called.\n\nCreate a new decompressor object. This object may be used to decompress data\nincrementally. For one-shot compression, use the `decompress()` function\ninstead.\n\nNote\n\nThis class does not transparently handle inputs containing multiple compressed\nstreams, unlike `decompress()` and `BZ2File`. If you need to decompress a\nmulti-stream input with `BZ2Decompressor`, you must use a new decompressor for\neach stream.\n\nDecompress data (a bytes-like object), returning uncompressed data as bytes.\nSome of data may be buffered internally, for use in later calls to\n`decompress()`. The returned data should be concatenated with the output of\nany previous calls to `decompress()`.\n\nIf max_length is nonnegative, returns at most max_length bytes of decompressed\ndata. If this limit is reached and further output can be produced, the\n`needs_input` attribute will be set to `False`. In this case, the next call to\n`decompress()` may provide data as `b''` to obtain more of the output.\n\nIf all of the input data was decompressed and returned (either because this\nwas less than max_length bytes, or because max_length was negative), the\n`needs_input` attribute will be set to `True`.\n\nAttempting to decompress data after the end of stream is reached raises an\n`EOFError`. Any data found after the end of the stream is ignored and saved in\nthe `unused_data` attribute.\n\nChanged in version 3.5: Added the max_length parameter.\n\n`True` if the end-of-stream marker has been reached.\n\nNew in version 3.3.\n\nData found after the end of the compressed stream.\n\nIf this attribute is accessed before the end of the stream has been reached,\nits value will be `b''`.\n\n`False` if the `decompress()` method can provide more decompressed data before\nrequiring new uncompressed input.\n\nNew in version 3.5.\n\nCompress data, a bytes-like object.\n\ncompresslevel, if given, must be an integer between `1` and `9`. The default\nis `9`.\n\nFor incremental compression, use a `BZ2Compressor` instead.\n\nDecompress data, a bytes-like object.\n\nIf data is the concatenation of multiple compressed streams, decompress all of\nthe streams.\n\nFor incremental decompression, use a `BZ2Decompressor` instead.\n\nChanged in version 3.3: Support for multi-stream inputs was added.\n\nBelow are some examples of typical usage of the `bz2` module.\n\nUsing `compress()` and `decompress()` to demonstrate round-trip compression:\n\nUsing `BZ2Compressor` for incremental compression:\n\nThe example above uses a very \u201cnonrandom\u201d stream of data (a stream of `b\u201dz\u201d`\nchunks). Random data tends to compress poorly, while ordered, repetitive data\nusually yields a high compression ratio.\n\nWriting and reading a bzip2-compressed file in binary mode:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Compressor", "path": "library/bz2#bz2.BZ2Compressor", "type": "Data Compression", "text": "\nCreate a new compressor object. This object may be used to compress data\nincrementally. For one-shot compression, use the `compress()` function\ninstead.\n\ncompresslevel, if given, must be an integer between `1` and `9`. The default\nis `9`.\n\nProvide data to the compressor object. Returns a chunk of compressed data if\npossible, or an empty byte string otherwise.\n\nWhen you have finished providing data to the compressor, call the `flush()`\nmethod to finish the compression process.\n\nFinish the compression process. Returns the compressed data left in internal\nbuffers.\n\nThe compressor object may not be used after this method has been called.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Compressor.compress()", "path": "library/bz2#bz2.BZ2Compressor.compress", "type": "Data Compression", "text": "\nProvide data to the compressor object. Returns a chunk of compressed data if\npossible, or an empty byte string otherwise.\n\nWhen you have finished providing data to the compressor, call the `flush()`\nmethod to finish the compression process.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Compressor.flush()", "path": "library/bz2#bz2.BZ2Compressor.flush", "type": "Data Compression", "text": "\nFinish the compression process. Returns the compressed data left in internal\nbuffers.\n\nThe compressor object may not be used after this method has been called.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Decompressor", "path": "library/bz2#bz2.BZ2Decompressor", "type": "Data Compression", "text": "\nCreate a new decompressor object. This object may be used to decompress data\nincrementally. For one-shot compression, use the `decompress()` function\ninstead.\n\nNote\n\nThis class does not transparently handle inputs containing multiple compressed\nstreams, unlike `decompress()` and `BZ2File`. If you need to decompress a\nmulti-stream input with `BZ2Decompressor`, you must use a new decompressor for\neach stream.\n\nDecompress data (a bytes-like object), returning uncompressed data as bytes.\nSome of data may be buffered internally, for use in later calls to\n`decompress()`. The returned data should be concatenated with the output of\nany previous calls to `decompress()`.\n\nIf max_length is nonnegative, returns at most max_length bytes of decompressed\ndata. If this limit is reached and further output can be produced, the\n`needs_input` attribute will be set to `False`. In this case, the next call to\n`decompress()` may provide data as `b''` to obtain more of the output.\n\nIf all of the input data was decompressed and returned (either because this\nwas less than max_length bytes, or because max_length was negative), the\n`needs_input` attribute will be set to `True`.\n\nAttempting to decompress data after the end of stream is reached raises an\n`EOFError`. Any data found after the end of the stream is ignored and saved in\nthe `unused_data` attribute.\n\nChanged in version 3.5: Added the max_length parameter.\n\n`True` if the end-of-stream marker has been reached.\n\nNew in version 3.3.\n\nData found after the end of the compressed stream.\n\nIf this attribute is accessed before the end of the stream has been reached,\nits value will be `b''`.\n\n`False` if the `decompress()` method can provide more decompressed data before\nrequiring new uncompressed input.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Decompressor.decompress()", "path": "library/bz2#bz2.BZ2Decompressor.decompress", "type": "Data Compression", "text": "\nDecompress data (a bytes-like object), returning uncompressed data as bytes.\nSome of data may be buffered internally, for use in later calls to\n`decompress()`. The returned data should be concatenated with the output of\nany previous calls to `decompress()`.\n\nIf max_length is nonnegative, returns at most max_length bytes of decompressed\ndata. If this limit is reached and further output can be produced, the\n`needs_input` attribute will be set to `False`. In this case, the next call to\n`decompress()` may provide data as `b''` to obtain more of the output.\n\nIf all of the input data was decompressed and returned (either because this\nwas less than max_length bytes, or because max_length was negative), the\n`needs_input` attribute will be set to `True`.\n\nAttempting to decompress data after the end of stream is reached raises an\n`EOFError`. Any data found after the end of the stream is ignored and saved in\nthe `unused_data` attribute.\n\nChanged in version 3.5: Added the max_length parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Decompressor.eof", "path": "library/bz2#bz2.BZ2Decompressor.eof", "type": "Data Compression", "text": "\n`True` if the end-of-stream marker has been reached.\n\nNew in version 3.3.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Decompressor.needs_input", "path": "library/bz2#bz2.BZ2Decompressor.needs_input", "type": "Data Compression", "text": "\n`False` if the `decompress()` method can provide more decompressed data before\nrequiring new uncompressed input.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2Decompressor.unused_data", "path": "library/bz2#bz2.BZ2Decompressor.unused_data", "type": "Data Compression", "text": "\nData found after the end of the compressed stream.\n\nIf this attribute is accessed before the end of the stream has been reached,\nits value will be `b''`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2File", "path": "library/bz2#bz2.BZ2File", "type": "Data Compression", "text": "\nOpen a bzip2-compressed file in binary mode.\n\nIf filename is a `str` or `bytes` object, open the named file directly.\nOtherwise, filename should be a file object, which will be used to read or\nwrite the compressed data.\n\nThe mode argument can be either `'r'` for reading (default), `'w'` for\noverwriting, `'x'` for exclusive creation, or `'a'` for appending. These can\nequivalently be given as `'rb'`, `'wb'`, `'xb'` and `'ab'` respectively.\n\nIf filename is a file object (rather than an actual file name), a mode of\n`'w'` does not truncate the file, and is instead equivalent to `'a'`.\n\nIf mode is `'w'` or `'a'`, compresslevel can be an integer between `1` and `9`\nspecifying the level of compression: `1` produces the least compression, and\n`9` (default) produces the most compression.\n\nIf mode is `'r'`, the input file may be the concatenation of multiple\ncompressed streams.\n\n`BZ2File` provides all of the members specified by the `io.BufferedIOBase`,\nexcept for `detach()` and `truncate()`. Iteration and the `with` statement are\nsupported.\n\n`BZ2File` also provides the following method:\n\nReturn buffered data without advancing the file position. At least one byte of\ndata will be returned (unless at EOF). The exact number of bytes returned is\nunspecified.\n\nNote\n\nWhile calling `peek()` does not change the file position of the `BZ2File`, it\nmay change the position of the underlying file object (e.g. if the `BZ2File`\nwas constructed by passing a file object for filename).\n\nNew in version 3.3.\n\nChanged in version 3.1: Support for the `with` statement was added.\n\nChanged in version 3.3: The `fileno()`, `readable()`, `seekable()`,\n`writable()`, `read1()` and `readinto()` methods were added.\n\nChanged in version 3.3: Support was added for filename being a file object\ninstead of an actual filename.\n\nChanged in version 3.3: The `'a'` (append) mode was added, along with support\nfor reading multi-stream files.\n\nChanged in version 3.4: The `'x'` (exclusive creation) mode was added.\n\nChanged in version 3.5: The `read()` method now accepts an argument of `None`.\n\nChanged in version 3.6: Accepts a path-like object.\n\nChanged in version 3.9: The buffering parameter has been removed. It was\nignored and deprecated since Python 3.0. Pass an open file object to control\nhow the file is opened.\n\nThe compresslevel parameter became keyword-only.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.BZ2File.peek()", "path": "library/bz2#bz2.BZ2File.peek", "type": "Data Compression", "text": "\nReturn buffered data without advancing the file position. At least one byte of\ndata will be returned (unless at EOF). The exact number of bytes returned is\nunspecified.\n\nNote\n\nWhile calling `peek()` does not change the file position of the `BZ2File`, it\nmay change the position of the underlying file object (e.g. if the `BZ2File`\nwas constructed by passing a file object for filename).\n\nNew in version 3.3.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.compress()", "path": "library/bz2#bz2.compress", "type": "Data Compression", "text": "\nCompress data, a bytes-like object.\n\ncompresslevel, if given, must be an integer between `1` and `9`. The default\nis `9`.\n\nFor incremental compression, use a `BZ2Compressor` instead.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.decompress()", "path": "library/bz2#bz2.decompress", "type": "Data Compression", "text": "\nDecompress data, a bytes-like object.\n\nIf data is the concatenation of multiple compressed streams, decompress all of\nthe streams.\n\nFor incremental decompression, use a `BZ2Decompressor` instead.\n\nChanged in version 3.3: Support for multi-stream inputs was added.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "bz2.open()", "path": "library/bz2#bz2.open", "type": "Data Compression", "text": "\nOpen a bzip2-compressed file in binary or text mode, returning a file object.\n\nAs with the constructor for `BZ2File`, the filename argument can be an actual\nfilename (a `str` or `bytes` object), or an existing file object to read from\nor write to.\n\nThe mode argument can be any of `'r'`, `'rb'`, `'w'`, `'wb'`, `'x'`, `'xb'`,\n`'a'` or `'ab'` for binary mode, or `'rt'`, `'wt'`, `'xt'`, or `'at'` for text\nmode. The default is `'rb'`.\n\nThe compresslevel argument is an integer from 1 to 9, as for the `BZ2File`\nconstructor.\n\nFor binary mode, this function is equivalent to the `BZ2File` constructor:\n`BZ2File(filename, mode, compresslevel=compresslevel)`. In this case, the\nencoding, errors and newline arguments must not be provided.\n\nFor text mode, a `BZ2File` object is created, and wrapped in an\n`io.TextIOWrapper` instance with the specified encoding, error handling\nbehavior, and line ending(s).\n\nNew in version 3.3.\n\nChanged in version 3.4: The `'x'` (exclusive creation) mode was added.\n\nChanged in version 3.6: Accepts a path-like object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar", "path": "library/calendar", "type": "Data Types", "text": "\nSource code: Lib/calendar.py\n\nThis module allows you to output calendars like the Unix cal program, and\nprovides additional useful functions related to the calendar. By default,\nthese calendars have Monday as the first day of the week, and Sunday as the\nlast (the European convention). Use `setfirstweekday()` to set the first day\nof the week to Sunday (6) or to any other weekday. Parameters that specify\ndates are given as integers. For related functionality, see also the\n`datetime` and `time` modules.\n\nThe functions and classes defined in this module use an idealized calendar,\nthe current Gregorian calendar extended indefinitely in both directions. This\nmatches the definition of the \u201cproleptic Gregorian\u201d calendar in Dershowitz and\nReingold\u2019s book \u201cCalendrical Calculations\u201d, where it\u2019s the base calendar for\nall computations. Zero and negative years are interpreted as prescribed by the\nISO 8601 standard. Year 0 is 1 BC, year -1 is 2 BC, and so on.\n\nCreates a `Calendar` object. firstweekday is an integer specifying the first\nday of the week. `0` is Monday (the default), `6` is Sunday.\n\nA `Calendar` object provides several methods that can be used for preparing\nthe calendar data for formatting. This class doesn\u2019t do any formatting itself.\nThis is the job of subclasses.\n\n`Calendar` instances have the following methods:\n\nReturn an iterator for the week day numbers that will be used for one week.\nThe first value from the iterator will be the same as the value of the\n`firstweekday` property.\n\nReturn an iterator for the month month (1\u201312) in the year year. This iterator\nwill return all days (as `datetime.date` objects) for the month and all days\nbefore the start of the month or after the end of the month that are required\nto get a complete week.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will simply be day of the month numbers. For the days outside of the\nspecified month, the day number is `0`.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a day of the month number and a week day\nnumber.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a year, a month and a day of the month\nnumbers.\n\nNew in version 3.7.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a year, a month, a day of the month, and\na day of the week numbers.\n\nNew in version 3.7.\n\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven `datetime.date` objects.\n\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven tuples of day numbers and weekday numbers.\n\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven day numbers.\n\nReturn the data for the specified year ready for formatting. The return value\nis a list of month rows. Each month row contains up to width months\n(defaulting to 3). Each month contains between 4 and 6 weeks and each week\ncontains 1\u20137 days. Days are `datetime.date` objects.\n\nReturn the data for the specified year ready for formatting (similar to\n`yeardatescalendar()`). Entries in the week lists are tuples of day numbers\nand weekday numbers. Day numbers outside this month are zero.\n\nReturn the data for the specified year ready for formatting (similar to\n`yeardatescalendar()`). Entries in the week lists are day numbers. Day numbers\noutside this month are zero.\n\nThis class can be used to generate plain text calendars.\n\n`TextCalendar` instances have the following methods:\n\nReturn a month\u2019s calendar in a multi-line string. If w is provided, it\nspecifies the width of the date columns, which are centered. If l is given, it\nspecifies the number of lines that each week will use. Depends on the first\nweekday as specified in the constructor or set by the `setfirstweekday()`\nmethod.\n\nPrint a month\u2019s calendar as returned by `formatmonth()`.\n\nReturn a m-column calendar for an entire year as a multi-line string. Optional\nparameters w, l, and c are for date column width, lines per week, and number\nof spaces between month columns, respectively. Depends on the first weekday as\nspecified in the constructor or set by the `setfirstweekday()` method. The\nearliest year for which a calendar can be generated is platform-dependent.\n\nPrint the calendar for an entire year as returned by `formatyear()`.\n\nThis class can be used to generate HTML calendars.\n\n`HTMLCalendar` instances have the following methods:\n\nReturn a month\u2019s calendar as an HTML table. If withyear is true the year will\nbe included in the header, otherwise just the month name will be used.\n\nReturn a year\u2019s calendar as an HTML table. width (defaulting to 3) specifies\nthe number of months per row.\n\nReturn a year\u2019s calendar as a complete HTML page. width (defaulting to 3)\nspecifies the number of months per row. css is the name for the cascading\nstyle sheet to be used. `None` can be passed if no style sheet should be used.\nencoding specifies the encoding to be used for the output (defaulting to the\nsystem default encoding).\n\n`HTMLCalendar` has the following attributes you can override to customize the\nCSS classes used by the calendar:\n\nA list of CSS classes used for each weekday. The default class list is:\n\nmore styles can be added for each day:\n\nNote that the length of this list must be seven items.\n\nThe CSS class for a weekday occurring in the previous or coming month.\n\nNew in version 3.7.\n\nA list of CSS classes used for weekday names in the header row. The default is\nthe same as `cssclasses`.\n\nNew in version 3.7.\n\nThe month\u2019s head CSS class (used by `formatmonthname()`). The default value is\n`\"month\"`.\n\nNew in version 3.7.\n\nThe CSS class for the whole month\u2019s table (used by `formatmonth()`). The\ndefault value is `\"month\"`.\n\nNew in version 3.7.\n\nThe CSS class for the whole year\u2019s table of tables (used by `formatyear()`).\nThe default value is `\"year\"`.\n\nNew in version 3.7.\n\nThe CSS class for the table head for the whole year (used by `formatyear()`).\nThe default value is `\"year\"`.\n\nNew in version 3.7.\n\nNote that although the naming for the above described class attributes is\nsingular (e.g. `cssclass_month` `cssclass_noday`), one can replace the single\nCSS class with a space separated list of CSS classes, for example:\n\nHere is an example how `HTMLCalendar` can be customized:\n\nThis subclass of `TextCalendar` can be passed a locale name in the constructor\nand will return month and weekday names in the specified locale. If this\nlocale includes an encoding all strings containing month and weekday names\nwill be returned as unicode.\n\nThis subclass of `HTMLCalendar` can be passed a locale name in the constructor\nand will return month and weekday names in the specified locale. If this\nlocale includes an encoding all strings containing month and weekday names\nwill be returned as unicode.\n\nNote\n\nThe `formatweekday()` and `formatmonthname()` methods of these two classes\ntemporarily change the current locale to the given locale. Because the current\nlocale is a process-wide setting, they are not thread-safe.\n\nFor simple text calendars this module provides the following functions.\n\nSets the weekday (`0` is Monday, `6` is Sunday) to start each week. The values\n`MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and\n`SUNDAY` are provided for convenience. For example, to set the first weekday\nto Sunday:\n\nReturns the current setting for the weekday to start each week.\n\nReturns `True` if year is a leap year, otherwise `False`.\n\nReturns the number of leap years in the range from y1 to y2 (exclusive), where\ny1 and y2 are years.\n\nThis function works for ranges spanning a century change.\n\nReturns the day of the week (`0` is Monday) for year (`1970`\u2013\u2026), month\n(`1`\u2013`12`), day (`1`\u2013`31`).\n\nReturn a header containing abbreviated weekday names. n specifies the width in\ncharacters for one weekday.\n\nReturns weekday of first day of the month and number of days in month, for the\nspecified year and month.\n\nReturns a matrix representing a month\u2019s calendar. Each row represents a week;\ndays outside of the month are represented by zeros. Each week begins with\nMonday unless set by `setfirstweekday()`.\n\nPrints a month\u2019s calendar as returned by `month()`.\n\nReturns a month\u2019s calendar in a multi-line string using the `formatmonth()` of\nthe `TextCalendar` class.\n\nPrints the calendar for an entire year as returned by `calendar()`.\n\nReturns a 3-column calendar for an entire year as a multi-line string using\nthe `formatyear()` of the `TextCalendar` class.\n\nAn unrelated but handy function that takes a time tuple such as returned by\nthe `gmtime()` function in the `time` module, and returns the corresponding\nUnix timestamp value, assuming an epoch of 1970, and the POSIX encoding. In\nfact, `time.gmtime()` and `timegm()` are each others\u2019 inverse.\n\nThe `calendar` module exports the following data attributes:\n\nAn array that represents the days of the week in the current locale.\n\nAn array that represents the abbreviated days of the week in the current\nlocale.\n\nAn array that represents the months of the year in the current locale. This\nfollows normal convention of January being month number 1, so it has a length\nof 13 and `month_name[0]` is the empty string.\n\nAn array that represents the abbreviated months of the year in the current\nlocale. This follows normal convention of January being month number 1, so it\nhas a length of 13 and `month_abbr[0]` is the empty string.\n\nSee also\n\nObject-oriented interface to dates and times with similar functionality to the\n`time` module.\n\nLow-level time related functions.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar", "path": "library/calendar#calendar.Calendar", "type": "Data Types", "text": "\nCreates a `Calendar` object. firstweekday is an integer specifying the first\nday of the week. `0` is Monday (the default), `6` is Sunday.\n\nA `Calendar` object provides several methods that can be used for preparing\nthe calendar data for formatting. This class doesn\u2019t do any formatting itself.\nThis is the job of subclasses.\n\n`Calendar` instances have the following methods:\n\nReturn an iterator for the week day numbers that will be used for one week.\nThe first value from the iterator will be the same as the value of the\n`firstweekday` property.\n\nReturn an iterator for the month month (1\u201312) in the year year. This iterator\nwill return all days (as `datetime.date` objects) for the month and all days\nbefore the start of the month or after the end of the month that are required\nto get a complete week.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will simply be day of the month numbers. For the days outside of the\nspecified month, the day number is `0`.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a day of the month number and a week day\nnumber.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a year, a month and a day of the month\nnumbers.\n\nNew in version 3.7.\n\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a year, a month, a day of the month, and\na day of the week numbers.\n\nNew in version 3.7.\n\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven `datetime.date` objects.\n\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven tuples of day numbers and weekday numbers.\n\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven day numbers.\n\nReturn the data for the specified year ready for formatting. The return value\nis a list of month rows. Each month row contains up to width months\n(defaulting to 3). Each month contains between 4 and 6 weeks and each week\ncontains 1\u20137 days. Days are `datetime.date` objects.\n\nReturn the data for the specified year ready for formatting (similar to\n`yeardatescalendar()`). Entries in the week lists are tuples of day numbers\nand weekday numbers. Day numbers outside this month are zero.\n\nReturn the data for the specified year ready for formatting (similar to\n`yeardatescalendar()`). Entries in the week lists are day numbers. Day numbers\noutside this month are zero.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.calendar()", "path": "library/calendar#calendar.calendar", "type": "Data Types", "text": "\nReturns a 3-column calendar for an entire year as a multi-line string using\nthe `formatyear()` of the `TextCalendar` class.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.itermonthdates()", "path": "library/calendar#calendar.Calendar.itermonthdates", "type": "Data Types", "text": "\nReturn an iterator for the month month (1\u201312) in the year year. This iterator\nwill return all days (as `datetime.date` objects) for the month and all days\nbefore the start of the month or after the end of the month that are required\nto get a complete week.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.itermonthdays()", "path": "library/calendar#calendar.Calendar.itermonthdays", "type": "Data Types", "text": "\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will simply be day of the month numbers. For the days outside of the\nspecified month, the day number is `0`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.itermonthdays2()", "path": "library/calendar#calendar.Calendar.itermonthdays2", "type": "Data Types", "text": "\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a day of the month number and a week day\nnumber.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.itermonthdays3()", "path": "library/calendar#calendar.Calendar.itermonthdays3", "type": "Data Types", "text": "\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a year, a month and a day of the month\nnumbers.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.itermonthdays4()", "path": "library/calendar#calendar.Calendar.itermonthdays4", "type": "Data Types", "text": "\nReturn an iterator for the month month in the year year similar to\n`itermonthdates()`, but not restricted by the `datetime.date` range. Days\nreturned will be tuples consisting of a year, a month, a day of the month, and\na day of the week numbers.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.iterweekdays()", "path": "library/calendar#calendar.Calendar.iterweekdays", "type": "Data Types", "text": "\nReturn an iterator for the week day numbers that will be used for one week.\nThe first value from the iterator will be the same as the value of the\n`firstweekday` property.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.monthdatescalendar()", "path": "library/calendar#calendar.Calendar.monthdatescalendar", "type": "Data Types", "text": "\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven `datetime.date` objects.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.monthdays2calendar()", "path": "library/calendar#calendar.Calendar.monthdays2calendar", "type": "Data Types", "text": "\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven tuples of day numbers and weekday numbers.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.monthdayscalendar()", "path": "library/calendar#calendar.Calendar.monthdayscalendar", "type": "Data Types", "text": "\nReturn a list of the weeks in the month month of the year as full weeks. Weeks\nare lists of seven day numbers.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.yeardatescalendar()", "path": "library/calendar#calendar.Calendar.yeardatescalendar", "type": "Data Types", "text": "\nReturn the data for the specified year ready for formatting. The return value\nis a list of month rows. Each month row contains up to width months\n(defaulting to 3). Each month contains between 4 and 6 weeks and each week\ncontains 1\u20137 days. Days are `datetime.date` objects.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.yeardays2calendar()", "path": "library/calendar#calendar.Calendar.yeardays2calendar", "type": "Data Types", "text": "\nReturn the data for the specified year ready for formatting (similar to\n`yeardatescalendar()`). Entries in the week lists are tuples of day numbers\nand weekday numbers. Day numbers outside this month are zero.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.Calendar.yeardayscalendar()", "path": "library/calendar#calendar.Calendar.yeardayscalendar", "type": "Data Types", "text": "\nReturn the data for the specified year ready for formatting (similar to\n`yeardatescalendar()`). Entries in the week lists are day numbers. Day numbers\noutside this month are zero.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.day_abbr", "path": "library/calendar#calendar.day_abbr", "type": "Data Types", "text": "\nAn array that represents the abbreviated days of the week in the current\nlocale.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.day_name", "path": "library/calendar#calendar.day_name", "type": "Data Types", "text": "\nAn array that represents the days of the week in the current locale.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.firstweekday()", "path": "library/calendar#calendar.firstweekday", "type": "Data Types", "text": "\nReturns the current setting for the weekday to start each week.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar", "path": "library/calendar#calendar.HTMLCalendar", "type": "Data Types", "text": "\nThis class can be used to generate HTML calendars.\n\n`HTMLCalendar` instances have the following methods:\n\nReturn a month\u2019s calendar as an HTML table. If withyear is true the year will\nbe included in the header, otherwise just the month name will be used.\n\nReturn a year\u2019s calendar as an HTML table. width (defaulting to 3) specifies\nthe number of months per row.\n\nReturn a year\u2019s calendar as a complete HTML page. width (defaulting to 3)\nspecifies the number of months per row. css is the name for the cascading\nstyle sheet to be used. `None` can be passed if no style sheet should be used.\nencoding specifies the encoding to be used for the output (defaulting to the\nsystem default encoding).\n\n`HTMLCalendar` has the following attributes you can override to customize the\nCSS classes used by the calendar:\n\nA list of CSS classes used for each weekday. The default class list is:\n\nmore styles can be added for each day:\n\nNote that the length of this list must be seven items.\n\nThe CSS class for a weekday occurring in the previous or coming month.\n\nNew in version 3.7.\n\nA list of CSS classes used for weekday names in the header row. The default is\nthe same as `cssclasses`.\n\nNew in version 3.7.\n\nThe month\u2019s head CSS class (used by `formatmonthname()`). The default value is\n`\"month\"`.\n\nNew in version 3.7.\n\nThe CSS class for the whole month\u2019s table (used by `formatmonth()`). The\ndefault value is `\"month\"`.\n\nNew in version 3.7.\n\nThe CSS class for the whole year\u2019s table of tables (used by `formatyear()`).\nThe default value is `\"year\"`.\n\nNew in version 3.7.\n\nThe CSS class for the table head for the whole year (used by `formatyear()`).\nThe default value is `\"year\"`.\n\nNew in version 3.7.\n\nNote that although the naming for the above described class attributes is\nsingular (e.g. `cssclass_month` `cssclass_noday`), one can replace the single\nCSS class with a space separated list of CSS classes, for example:\n\nHere is an example how `HTMLCalendar` can be customized:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.cssclasses", "path": "library/calendar#calendar.HTMLCalendar.cssclasses", "type": "Data Types", "text": "\nA list of CSS classes used for each weekday. The default class list is:\n\nmore styles can be added for each day:\n\nNote that the length of this list must be seven items.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.cssclasses_weekday_head", "path": "library/calendar#calendar.HTMLCalendar.cssclasses_weekday_head", "type": "Data Types", "text": "\nA list of CSS classes used for weekday names in the header row. The default is\nthe same as `cssclasses`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.cssclass_month", "path": "library/calendar#calendar.HTMLCalendar.cssclass_month", "type": "Data Types", "text": "\nThe CSS class for the whole month\u2019s table (used by `formatmonth()`). The\ndefault value is `\"month\"`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.cssclass_month_head", "path": "library/calendar#calendar.HTMLCalendar.cssclass_month_head", "type": "Data Types", "text": "\nThe month\u2019s head CSS class (used by `formatmonthname()`). The default value is\n`\"month\"`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.cssclass_noday", "path": "library/calendar#calendar.HTMLCalendar.cssclass_noday", "type": "Data Types", "text": "\nThe CSS class for a weekday occurring in the previous or coming month.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.cssclass_year", "path": "library/calendar#calendar.HTMLCalendar.cssclass_year", "type": "Data Types", "text": "\nThe CSS class for the whole year\u2019s table of tables (used by `formatyear()`).\nThe default value is `\"year\"`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.cssclass_year_head", "path": "library/calendar#calendar.HTMLCalendar.cssclass_year_head", "type": "Data Types", "text": "\nThe CSS class for the table head for the whole year (used by `formatyear()`).\nThe default value is `\"year\"`.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.formatmonth()", "path": "library/calendar#calendar.HTMLCalendar.formatmonth", "type": "Data Types", "text": "\nReturn a month\u2019s calendar as an HTML table. If withyear is true the year will\nbe included in the header, otherwise just the month name will be used.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.formatyear()", "path": "library/calendar#calendar.HTMLCalendar.formatyear", "type": "Data Types", "text": "\nReturn a year\u2019s calendar as an HTML table. width (defaulting to 3) specifies\nthe number of months per row.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.HTMLCalendar.formatyearpage()", "path": "library/calendar#calendar.HTMLCalendar.formatyearpage", "type": "Data Types", "text": "\nReturn a year\u2019s calendar as a complete HTML page. width (defaulting to 3)\nspecifies the number of months per row. css is the name for the cascading\nstyle sheet to be used. `None` can be passed if no style sheet should be used.\nencoding specifies the encoding to be used for the output (defaulting to the\nsystem default encoding).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.isleap()", "path": "library/calendar#calendar.isleap", "type": "Data Types", "text": "\nReturns `True` if year is a leap year, otherwise `False`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.leapdays()", "path": "library/calendar#calendar.leapdays", "type": "Data Types", "text": "\nReturns the number of leap years in the range from y1 to y2 (exclusive), where\ny1 and y2 are years.\n\nThis function works for ranges spanning a century change.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.LocaleHTMLCalendar", "path": "library/calendar#calendar.LocaleHTMLCalendar", "type": "Data Types", "text": "\nThis subclass of `HTMLCalendar` can be passed a locale name in the constructor\nand will return month and weekday names in the specified locale. If this\nlocale includes an encoding all strings containing month and weekday names\nwill be returned as unicode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.LocaleTextCalendar", "path": "library/calendar#calendar.LocaleTextCalendar", "type": "Data Types", "text": "\nThis subclass of `TextCalendar` can be passed a locale name in the constructor\nand will return month and weekday names in the specified locale. If this\nlocale includes an encoding all strings containing month and weekday names\nwill be returned as unicode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.month()", "path": "library/calendar#calendar.month", "type": "Data Types", "text": "\nReturns a month\u2019s calendar in a multi-line string using the `formatmonth()` of\nthe `TextCalendar` class.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.monthcalendar()", "path": "library/calendar#calendar.monthcalendar", "type": "Data Types", "text": "\nReturns a matrix representing a month\u2019s calendar. Each row represents a week;\ndays outside of the month are represented by zeros. Each week begins with\nMonday unless set by `setfirstweekday()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.monthrange()", "path": "library/calendar#calendar.monthrange", "type": "Data Types", "text": "\nReturns weekday of first day of the month and number of days in month, for the\nspecified year and month.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.month_abbr", "path": "library/calendar#calendar.month_abbr", "type": "Data Types", "text": "\nAn array that represents the abbreviated months of the year in the current\nlocale. This follows normal convention of January being month number 1, so it\nhas a length of 13 and `month_abbr[0]` is the empty string.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.month_name", "path": "library/calendar#calendar.month_name", "type": "Data Types", "text": "\nAn array that represents the months of the year in the current locale. This\nfollows normal convention of January being month number 1, so it has a length\nof 13 and `month_name[0]` is the empty string.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.prcal()", "path": "library/calendar#calendar.prcal", "type": "Data Types", "text": "\nPrints the calendar for an entire year as returned by `calendar()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.prmonth()", "path": "library/calendar#calendar.prmonth", "type": "Data Types", "text": "\nPrints a month\u2019s calendar as returned by `month()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.setfirstweekday()", "path": "library/calendar#calendar.setfirstweekday", "type": "Data Types", "text": "\nSets the weekday (`0` is Monday, `6` is Sunday) to start each week. The values\n`MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, and\n`SUNDAY` are provided for convenience. For example, to set the first weekday\nto Sunday:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.TextCalendar", "path": "library/calendar#calendar.TextCalendar", "type": "Data Types", "text": "\nThis class can be used to generate plain text calendars.\n\n`TextCalendar` instances have the following methods:\n\nReturn a month\u2019s calendar in a multi-line string. If w is provided, it\nspecifies the width of the date columns, which are centered. If l is given, it\nspecifies the number of lines that each week will use. Depends on the first\nweekday as specified in the constructor or set by the `setfirstweekday()`\nmethod.\n\nPrint a month\u2019s calendar as returned by `formatmonth()`.\n\nReturn a m-column calendar for an entire year as a multi-line string. Optional\nparameters w, l, and c are for date column width, lines per week, and number\nof spaces between month columns, respectively. Depends on the first weekday as\nspecified in the constructor or set by the `setfirstweekday()` method. The\nearliest year for which a calendar can be generated is platform-dependent.\n\nPrint the calendar for an entire year as returned by `formatyear()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.TextCalendar.formatmonth()", "path": "library/calendar#calendar.TextCalendar.formatmonth", "type": "Data Types", "text": "\nReturn a month\u2019s calendar in a multi-line string. If w is provided, it\nspecifies the width of the date columns, which are centered. If l is given, it\nspecifies the number of lines that each week will use. Depends on the first\nweekday as specified in the constructor or set by the `setfirstweekday()`\nmethod.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.TextCalendar.formatyear()", "path": "library/calendar#calendar.TextCalendar.formatyear", "type": "Data Types", "text": "\nReturn a m-column calendar for an entire year as a multi-line string. Optional\nparameters w, l, and c are for date column width, lines per week, and number\nof spaces between month columns, respectively. Depends on the first weekday as\nspecified in the constructor or set by the `setfirstweekday()` method. The\nearliest year for which a calendar can be generated is platform-dependent.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.TextCalendar.prmonth()", "path": "library/calendar#calendar.TextCalendar.prmonth", "type": "Data Types", "text": "\nPrint a month\u2019s calendar as returned by `formatmonth()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.TextCalendar.pryear()", "path": "library/calendar#calendar.TextCalendar.pryear", "type": "Data Types", "text": "\nPrint the calendar for an entire year as returned by `formatyear()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.timegm()", "path": "library/calendar#calendar.timegm", "type": "Data Types", "text": "\nAn unrelated but handy function that takes a time tuple such as returned by\nthe `gmtime()` function in the `time` module, and returns the corresponding\nUnix timestamp value, assuming an epoch of 1970, and the POSIX encoding. In\nfact, `time.gmtime()` and `timegm()` are each others\u2019 inverse.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.weekday()", "path": "library/calendar#calendar.weekday", "type": "Data Types", "text": "\nReturns the day of the week (`0` is Monday) for year (`1970`\u2013\u2026), month\n(`1`\u2013`12`), day (`1`\u2013`31`).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "calendar.weekheader()", "path": "library/calendar#calendar.weekheader", "type": "Data Types", "text": "\nReturn a header containing abbreviated weekday names. n specifies the width in\ncharacters for one weekday.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "callable()", "path": "library/functions#callable", "type": "Built-in Functions", "text": "\nReturn `True` if the object argument appears callable, `False` if not. If this\nreturns `True`, it is still possible that a call fails, but if it is `False`,\ncalling object will never succeed. Note that classes are callable (calling a\nclass returns a new instance); instances are callable if their class has a\n`__call__()` method.\n\nNew in version 3.2: This function was first removed in Python 3.0 and then\nbrought back in Python 3.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi", "path": "library/cgi", "type": "Internet", "text": "\nSource code: Lib/cgi.py\n\nSupport module for Common Gateway Interface (CGI) scripts.\n\nThis module defines a number of utilities for use by CGI scripts written in\nPython.\n\nA CGI script is invoked by an HTTP server, usually to process user input\nsubmitted through an HTML `<FORM>` or `<ISINDEX>` element.\n\nMost often, CGI scripts live in the server\u2019s special `cgi-bin` directory. The\nHTTP server places all sorts of information about the request (such as the\nclient\u2019s hostname, the requested URL, the query string, and lots of other\ngoodies) in the script\u2019s shell environment, executes the script, and sends the\nscript\u2019s output back to the client.\n\nThe script\u2019s input is connected to the client too, and sometimes the form data\nis read this way; at other times the form data is passed via the \u201cquery\nstring\u201d part of the URL. This module is intended to take care of the different\ncases and provide a simpler interface to the Python script. It also provides a\nnumber of utilities that help in debugging scripts, and the latest addition is\nsupport for file uploads from a form (if your browser supports it).\n\nThe output of a CGI script should consist of two sections, separated by a\nblank line. The first section contains a number of headers, telling the client\nwhat kind of data is following. Python code to generate a minimal header\nsection looks like this:\n\nThe second section is usually HTML, which allows the client software to\ndisplay nicely formatted text with header, in-line images, etc. Here\u2019s Python\ncode that prints a simple piece of HTML:\n\nBegin by writing `import cgi`.\n\nWhen you write a new script, consider adding these lines:\n\nThis activates a special exception handler that will display detailed reports\nin the Web browser if any errors occur. If you\u2019d rather not show the guts of\nyour program to users of your script, you can have the reports saved to files\ninstead, with code like this:\n\nIt\u2019s very helpful to use this feature during script development. The reports\nproduced by `cgitb` provide information that can save you a lot of time in\ntracking down bugs. You can always remove the `cgitb` line later when you have\ntested your script and are confident that it works correctly.\n\nTo get at submitted form data, use the `FieldStorage` class. If the form\ncontains non-ASCII characters, use the encoding keyword parameter set to the\nvalue of the encoding defined for the document. It is usually contained in the\nMETA tag in the HEAD section of the HTML document or by the Content-Type\nheader). This reads the form contents from the standard input or the\nenvironment (depending on the value of various environment variables set\naccording to the CGI standard). Since it may consume standard input, it should\nbe instantiated only once.\n\nThe `FieldStorage` instance can be indexed like a Python dictionary. It allows\nmembership testing with the `in` operator, and also supports the standard\ndictionary method `keys()` and the built-in function `len()`. Form fields\ncontaining empty strings are ignored and do not appear in the dictionary; to\nkeep such values, provide a true value for the optional keep_blank_values\nkeyword parameter when creating the `FieldStorage` instance.\n\nFor instance, the following code (which assumes that the Content-Type header\nand blank line have already been printed) checks that the fields `name` and\n`addr` are both set to a non-empty string:\n\nHere the fields, accessed through `form[key]`, are themselves instances of\n`FieldStorage` (or `MiniFieldStorage`, depending on the form encoding). The\n`value` attribute of the instance yields the string value of the field. The\n`getvalue()` method returns this string value directly; it also accepts an\noptional second argument as a default to return if the requested key is not\npresent.\n\nIf the submitted form data contains more than one field with the same name,\nthe object retrieved by `form[key]` is not a `FieldStorage` or\n`MiniFieldStorage` instance but a list of such instances. Similarly, in this\nsituation, `form.getvalue(key)` would return a list of strings. If you expect\nthis possibility (when your HTML form contains multiple fields with the same\nname), use the `getlist()` method, which always returns a list of values (so\nthat you do not need to special-case the single item case). For example, this\ncode concatenates any number of username fields, separated by commas:\n\nIf a field represents an uploaded file, accessing the value via the `value`\nattribute or the `getvalue()` method reads the entire file in memory as bytes.\nThis may not be what you want. You can test for an uploaded file by testing\neither the `filename` attribute or the `file` attribute. You can then read the\ndata from the `file` attribute before it is automatically closed as part of\nthe garbage collection of the `FieldStorage` instance (the `read()` and\n`readline()` methods will return bytes):\n\n`FieldStorage` objects also support being used in a `with` statement, which\nwill automatically close them when done.\n\nIf an error is encountered when obtaining the contents of an uploaded file\n(for example, when the user interrupts the form submission by clicking on a\nBack or Cancel button) the `done` attribute of the object for the field will\nbe set to the value -1.\n\nThe file upload draft standard entertains the possibility of uploading\nmultiple files from one field (using a recursive multipart/* encoding). When\nthis occurs, the item will be a dictionary-like `FieldStorage` item. This can\nbe determined by testing its `type` attribute, which should be multipart/form-\ndata (or perhaps another MIME type matching multipart/*). In this case, it can\nbe iterated over recursively just like the top-level form object.\n\nWhen a form is submitted in the \u201cold\u201d format (as the query string or as a\nsingle data part of type application/x-www-form-urlencoded), the items will\nactually be instances of the class `MiniFieldStorage`. In this case, the\n`list`, `file`, and `filename` attributes are always `None`.\n\nA form submitted via POST that also has a query string will contain both\n`FieldStorage` and `MiniFieldStorage` items.\n\nChanged in version 3.4: The `file` attribute is automatically closed upon the\ngarbage collection of the creating `FieldStorage` instance.\n\nChanged in version 3.5: Added support for the context management protocol to\nthe `FieldStorage` class.\n\nThe previous section explains how to read CGI form data using the\n`FieldStorage` class. This section describes a higher level interface which\nwas added to this class to allow one to do it in a more readable and intuitive\nway. The interface doesn\u2019t make the techniques described in previous sections\nobsolete \u2014 they are still useful to process file uploads efficiently, for\nexample.\n\nThe interface consists of two simple methods. Using the methods you can\nprocess form data in a generic way, without the need to worry whether only one\nor more values were posted under one name.\n\nIn the previous section, you learned to write following code anytime you\nexpected a user to post more than one value under one name:\n\nThis situation is common for example when a form contains a group of multiple\ncheckboxes with the same name:\n\nIn most situations, however, there\u2019s only one form control with a particular\nname in a form and then you expect and need only one value associated with\nthis name. So you write a script containing for example this code:\n\nThe problem with the code is that you should never expect that a client will\nprovide valid input to your scripts. For example, if a curious user appends\nanother `user=foo` pair to the query string, then the script would crash,\nbecause in this situation the `getvalue(\"user\")` method call returns a list\ninstead of a string. Calling the `upper()` method on a list is not valid\n(since lists do not have a method of this name) and results in an\n`AttributeError` exception.\n\nTherefore, the appropriate way to read form data values was to always use the\ncode which checks whether the obtained value is a single value or a list of\nvalues. That\u2019s annoying and leads to less readable scripts.\n\nA more convenient approach is to use the methods `getfirst()` and `getlist()`\nprovided by this higher level interface.\n\nThis method always returns only one value associated with form field name. The\nmethod returns only the first value in case that more values were posted under\nsuch name. Please note that the order in which the values are received may\nvary from browser to browser and should not be counted on. 1 If no such form\nfield or value exists then the method returns the value specified by the\noptional parameter default. This parameter defaults to `None` if not\nspecified.\n\nThis method always returns a list of values associated with form field name.\nThe method returns an empty list if no such form field or value exists for\nname. It returns a list consisting of one item if only one such value exists.\n\nUsing these methods you can write nice compact code:\n\nThese are useful if you want more control, or if you want to employ some of\nthe algorithms implemented in this module in other circumstances.\n\nParse a query in the environment or from a file (the file defaults to\n`sys.stdin`). The keep_blank_values, strict_parsing and separator parameters\nare passed to `urllib.parse.parse_qs()` unchanged.\n\nParse input of type multipart/form-data (for file uploads). Arguments are fp\nfor the input file, pdict for a dictionary containing other parameters in the\nContent-Type header, and encoding, the request encoding.\n\nReturns a dictionary just like `urllib.parse.parse_qs()`: keys are the field\nnames, each value is a list of values for that field. For non-file fields, the\nvalue is a list of strings.\n\nThis is easy to use but not much good if you are expecting megabytes to be\nuploaded \u2014 in that case, use the `FieldStorage` class instead which is much\nmore flexible.\n\nChanged in version 3.7: Added the encoding and errors parameters. For non-file\nfields, the value is now a list of strings, not bytes.\n\nChanged in version 3.9.2: Added the separator parameter.\n\nParse a MIME header (such as Content-Type) into a main value and a dictionary\nof parameters.\n\nRobust test CGI script, usable as main program. Writes minimal HTTP headers\nand formats all information provided to the script in HTML form.\n\nFormat the shell environment in HTML.\n\nFormat a form in HTML.\n\nFormat the current directory in HTML.\n\nPrint a list of useful (used by CGI) environment variables in HTML.\n\nThere\u2019s one important rule: if you invoke an external program (via the\n`os.system()` or `os.popen()` functions. or others with similar\nfunctionality), make very sure you don\u2019t pass arbitrary strings received from\nthe client to the shell. This is a well-known security hole whereby clever\nhackers anywhere on the Web can exploit a gullible CGI script to invoke\narbitrary shell commands. Even parts of the URL or field names cannot be\ntrusted, since the request doesn\u2019t have to come from your form!\n\nTo be on the safe side, if you must pass a string gotten from a form to a\nshell command, you should make sure the string contains only alphanumeric\ncharacters, dashes, underscores, and periods.\n\nRead the documentation for your HTTP server and check with your local system\nadministrator to find the directory where CGI scripts should be installed;\nusually this is in a directory `cgi-bin` in the server tree.\n\nMake sure that your script is readable and executable by \u201cothers\u201d; the Unix\nfile mode should be `0o755` octal (use `chmod 0755 filename`). Make sure that\nthe first line of the script contains `#!` starting in column 1 followed by\nthe pathname of the Python interpreter, for instance:\n\nMake sure the Python interpreter exists and is executable by \u201cothers\u201d.\n\nMake sure that any files your script needs to read or write are readable or\nwritable, respectively, by \u201cothers\u201d \u2014 their mode should be `0o644` for\nreadable and `0o666` for writable. This is because, for security reasons, the\nHTTP server executes your script as user \u201cnobody\u201d, without any special\nprivileges. It can only read (write, execute) files that everybody can read\n(write, execute). The current directory at execution time is also different\n(it is usually the server\u2019s cgi-bin directory) and the set of environment\nvariables is also different from what you get when you log in. In particular,\ndon\u2019t count on the shell\u2019s search path for executables (`PATH`) or the Python\nmodule search path (`PYTHONPATH`) to be set to anything interesting.\n\nIf you need to load modules from a directory which is not on Python\u2019s default\nmodule search path, you can change the path in your script, before importing\nother modules. For example:\n\n(This way, the directory inserted last will be searched first!)\n\nInstructions for non-Unix systems will vary; check your HTTP server\u2019s\ndocumentation (it will usually have a section on CGI scripts).\n\nUnfortunately, a CGI script will generally not run when you try it from the\ncommand line, and a script that works perfectly from the command line may fail\nmysteriously when run from the server. There\u2019s one reason why you should still\ntest your script from the command line: if it contains a syntax error, the\nPython interpreter won\u2019t execute it at all, and the HTTP server will most\nlikely send a cryptic error to the client.\n\nAssuming your script has no syntax errors, yet it does not work, you have no\nchoice but to read the next section.\n\nFirst of all, check for trivial installation errors \u2014 reading the section\nabove on installing your CGI script carefully can save you a lot of time. If\nyou wonder whether you have understood the installation procedure correctly,\ntry installing a copy of this module file (`cgi.py`) as a CGI script. When\ninvoked as a script, the file will dump its environment and the contents of\nthe form in HTML form. Give it the right mode etc, and send it a request. If\nit\u2019s installed in the standard `cgi-bin` directory, it should be possible to\nsend it a request by entering a URL into your browser of the form:\n\nIf this gives an error of type 404, the server cannot find the script \u2013\nperhaps you need to install it in a different directory. If it gives another\nerror, there\u2019s an installation problem that you should fix before trying to go\nany further. If you get a nicely formatted listing of the environment and form\ncontent (in this example, the fields should be listed as \u201caddr\u201d with value \u201cAt\nHome\u201d and \u201cname\u201d with value \u201cJoe Blow\u201d), the `cgi.py` script has been\ninstalled correctly. If you follow the same procedure for your own script, you\nshould now be able to debug it.\n\nThe next step could be to call the `cgi` module\u2019s `test()` function from your\nscript: replace its main code with the single statement\n\nThis should produce the same results as those gotten from installing the\n`cgi.py` file itself.\n\nWhen an ordinary Python script raises an unhandled exception (for whatever\nreason: of a typo in a module name, a file that can\u2019t be opened, etc.), the\nPython interpreter prints a nice traceback and exits. While the Python\ninterpreter will still do this when your CGI script raises an exception, most\nlikely the traceback will end up in one of the HTTP server\u2019s log files, or be\ndiscarded altogether.\n\nFortunately, once you have managed to get your script to execute some code,\nyou can easily send tracebacks to the Web browser using the `cgitb` module. If\nyou haven\u2019t done so already, just add the lines:\n\nto the top of your script. Then try running it again; when a problem occurs,\nyou should see a detailed report that will likely make apparent the cause of\nthe crash.\n\nIf you suspect that there may be a problem in importing the `cgitb` module,\nyou can use an even more robust approach (which only uses built-in modules):\n\nThis relies on the Python interpreter to print the traceback. The content type\nof the output is set to plain text, which disables all HTML processing. If\nyour script works, the raw HTML will be displayed by your client. If it raises\nan exception, most likely after the first two lines have been printed, a\ntraceback will be displayed. Because no HTML interpretation is going on, the\ntraceback will be readable.\n\nNote that some recent versions of the HTML specification do state what order\nthe field values should be supplied in, but knowing whether a request was\nreceived from a conforming browser, or even from a browser at all, is tedious\nand error-prone.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.FieldStorage.getfirst()", "path": "library/cgi#cgi.FieldStorage.getfirst", "type": "Internet", "text": "\nThis method always returns only one value associated with form field name. The\nmethod returns only the first value in case that more values were posted under\nsuch name. Please note that the order in which the values are received may\nvary from browser to browser and should not be counted on. 1 If no such form\nfield or value exists then the method returns the value specified by the\noptional parameter default. This parameter defaults to `None` if not\nspecified.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.FieldStorage.getlist()", "path": "library/cgi#cgi.FieldStorage.getlist", "type": "Internet", "text": "\nThis method always returns a list of values associated with form field name.\nThe method returns an empty list if no such form field or value exists for\nname. It returns a list consisting of one item if only one such value exists.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.parse()", "path": "library/cgi#cgi.parse", "type": "Internet", "text": "\nParse a query in the environment or from a file (the file defaults to\n`sys.stdin`). The keep_blank_values, strict_parsing and separator parameters\nare passed to `urllib.parse.parse_qs()` unchanged.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.parse_header()", "path": "library/cgi#cgi.parse_header", "type": "Internet", "text": "\nParse a MIME header (such as Content-Type) into a main value and a dictionary\nof parameters.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.parse_multipart()", "path": "library/cgi#cgi.parse_multipart", "type": "Internet", "text": "\nParse input of type multipart/form-data (for file uploads). Arguments are fp\nfor the input file, pdict for a dictionary containing other parameters in the\nContent-Type header, and encoding, the request encoding.\n\nReturns a dictionary just like `urllib.parse.parse_qs()`: keys are the field\nnames, each value is a list of values for that field. For non-file fields, the\nvalue is a list of strings.\n\nThis is easy to use but not much good if you are expecting megabytes to be\nuploaded \u2014 in that case, use the `FieldStorage` class instead which is much\nmore flexible.\n\nChanged in version 3.7: Added the encoding and errors parameters. For non-file\nfields, the value is now a list of strings, not bytes.\n\nChanged in version 3.9.2: Added the separator parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.print_directory()", "path": "library/cgi#cgi.print_directory", "type": "Internet", "text": "\nFormat the current directory in HTML.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.print_environ()", "path": "library/cgi#cgi.print_environ", "type": "Internet", "text": "\nFormat the shell environment in HTML.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.print_environ_usage()", "path": "library/cgi#cgi.print_environ_usage", "type": "Internet", "text": "\nPrint a list of useful (used by CGI) environment variables in HTML.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.print_form()", "path": "library/cgi#cgi.print_form", "type": "Internet", "text": "\nFormat a form in HTML.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgi.test()", "path": "library/cgi#cgi.test", "type": "Internet", "text": "\nRobust test CGI script, usable as main program. Writes minimal HTTP headers\nand formats all information provided to the script in HTML form.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgitb", "path": "library/cgitb", "type": "Internet", "text": "\nSource code: Lib/cgitb.py\n\nThe `cgitb` module provides a special exception handler for Python scripts.\n(Its name is a bit misleading. It was originally designed to display extensive\ntraceback information in HTML for CGI scripts. It was later generalized to\nalso display this information in plain text.) After this module is activated,\nif an uncaught exception occurs, a detailed, formatted report will be\ndisplayed. The report includes a traceback showing excerpts of the source code\nfor each level, as well as the values of the arguments and local variables to\ncurrently running functions, to help you debug the problem. Optionally, you\ncan save this information to a file instead of sending it to the browser.\n\nTo enable this feature, simply add this to the top of your CGI script:\n\nThe options to the `enable()` function control whether the report is displayed\nin the browser and whether the report is logged to a file for later analysis.\n\nThis function causes the `cgitb` module to take over the interpreter\u2019s default\nhandling for exceptions by setting the value of `sys.excepthook`.\n\nThe optional argument display defaults to `1` and can be set to `0` to\nsuppress sending the traceback to the browser. If the argument logdir is\npresent, the traceback reports are written to files. The value of logdir\nshould be a directory where these files will be placed. The optional argument\ncontext is the number of lines of context to display around the current line\nof source code in the traceback; this defaults to `5`. If the optional\nargument format is `\"html\"`, the output is formatted as HTML. Any other value\nforces plain text output. The default value is `\"html\"`.\n\nThis function handles the exception described by info (a 3-tuple containing\nthe result of `sys.exc_info()`), formatting its traceback as text and\nreturning the result as a string. The optional argument context is the number\nof lines of context to display around the current line of source code in the\ntraceback; this defaults to `5`.\n\nThis function handles the exception described by info (a 3-tuple containing\nthe result of `sys.exc_info()`), formatting its traceback as HTML and\nreturning the result as a string. The optional argument context is the number\nof lines of context to display around the current line of source code in the\ntraceback; this defaults to `5`.\n\nThis function handles an exception using the default settings (that is, show a\nreport in the browser, but don\u2019t log to a file). This can be used when you\u2019ve\ncaught an exception and want to report it using `cgitb`. The optional info\nargument should be a 3-tuple containing an exception type, exception value,\nand traceback object, exactly like the tuple returned by `sys.exc_info()`. If\nthe info argument is not supplied, the current exception is obtained from\n`sys.exc_info()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgitb.enable()", "path": "library/cgitb#cgitb.enable", "type": "Internet", "text": "\nThis function causes the `cgitb` module to take over the interpreter\u2019s default\nhandling for exceptions by setting the value of `sys.excepthook`.\n\nThe optional argument display defaults to `1` and can be set to `0` to\nsuppress sending the traceback to the browser. If the argument logdir is\npresent, the traceback reports are written to files. The value of logdir\nshould be a directory where these files will be placed. The optional argument\ncontext is the number of lines of context to display around the current line\nof source code in the traceback; this defaults to `5`. If the optional\nargument format is `\"html\"`, the output is formatted as HTML. Any other value\nforces plain text output. The default value is `\"html\"`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgitb.handler()", "path": "library/cgitb#cgitb.handler", "type": "Internet", "text": "\nThis function handles an exception using the default settings (that is, show a\nreport in the browser, but don\u2019t log to a file). This can be used when you\u2019ve\ncaught an exception and want to report it using `cgitb`. The optional info\nargument should be a 3-tuple containing an exception type, exception value,\nand traceback object, exactly like the tuple returned by `sys.exc_info()`. If\nthe info argument is not supplied, the current exception is obtained from\n`sys.exc_info()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgitb.html()", "path": "library/cgitb#cgitb.html", "type": "Internet", "text": "\nThis function handles the exception described by info (a 3-tuple containing\nthe result of `sys.exc_info()`), formatting its traceback as HTML and\nreturning the result as a string. The optional argument context is the number\nof lines of context to display around the current line of source code in the\ntraceback; this defaults to `5`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cgitb.text()", "path": "library/cgitb#cgitb.text", "type": "Internet", "text": "\nThis function handles the exception described by info (a 3-tuple containing\nthe result of `sys.exc_info()`), formatting its traceback as text and\nreturning the result as a string. The optional argument context is the number\nof lines of context to display around the current line of source code in the\ntraceback; this defaults to `5`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "ChildProcessError", "path": "library/exceptions#ChildProcessError", "type": "Built-in Exceptions", "text": "\nRaised when an operation on a child process failed. Corresponds to `errno`\n`ECHILD`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chr()", "path": "library/functions#chr", "type": "Built-in Functions", "text": "\nReturn the string representing a character whose Unicode code point is the\ninteger i. For example, `chr(97)` returns the string `'a'`, while `chr(8364)`\nreturns the string `'\u20ac'`. This is the inverse of `ord()`.\n\nThe valid range for the argument is from 0 through 1,114,111 (0x10FFFF in base\n16). `ValueError` will be raised if i is outside that range.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk", "path": "library/chunk", "type": "Multimedia", "text": "\nSource code: Lib/chunk.py\n\nThis module provides an interface for reading files that use EA IFF 85 chunks.\n1 This format is used in at least the Audio Interchange File Format\n(AIFF/AIFF-C) and the Real Media File Format (RMFF). The WAVE audio file\nformat is closely related and can also be read using this module.\n\nA chunk has the following structure:\n\nOffset\n\nLength\n\nContents\n\n0\n\n4\n\nChunk ID\n\n4\n\n4\n\nSize of chunk in big-endian byte order, not including the header\n\n8\n\nn\n\nData bytes, where n is the size given in the preceding field\n\n8 + n\n\n0 or 1\n\nPad byte needed if n is odd and chunk alignment is used\n\nThe ID is a 4-byte string which identifies the type of chunk.\n\nThe size field (a 32-bit value, encoded using big-endian byte order) gives the\nsize of the chunk data, not including the 8-byte header.\n\nUsually an IFF-type file consists of one or more chunks. The proposed usage of\nthe `Chunk` class defined here is to instantiate an instance at the start of\neach chunk and read from the instance until it reaches the end, after which a\nnew instance can be instantiated. At the end of the file, creating a new\ninstance will fail with an `EOFError` exception.\n\nClass which represents a chunk. The file argument is expected to be a file-\nlike object. An instance of this class is specifically allowed. The only\nmethod that is needed is `read()`. If the methods `seek()` and `tell()` are\npresent and don\u2019t raise an exception, they are also used. If these methods are\npresent and raise an exception, they are expected to not have altered the\nobject. If the optional argument align is true, chunks are assumed to be\naligned on 2-byte boundaries. If align is false, no alignment is assumed. The\ndefault value is true. If the optional argument bigendian is false, the chunk\nsize is assumed to be in little-endian order. This is needed for WAVE audio\nfiles. The default value is true. If the optional argument inclheader is true,\nthe size given in the chunk header includes the size of the header. The\ndefault value is false.\n\nA `Chunk` object supports the following methods:\n\nReturns the name (ID) of the chunk. This is the first 4 bytes of the chunk.\n\nReturns the size of the chunk.\n\nClose and skip to the end of the chunk. This does not close the underlying\nfile.\n\nThe remaining methods will raise `OSError` if called after the `close()`\nmethod has been called. Before Python 3.3, they used to raise `IOError`, now\nan alias of `OSError`.\n\nReturns `False`.\n\nSet the chunk\u2019s current position. The whence argument is optional and defaults\nto `0` (absolute file positioning); other values are `1` (seek relative to the\ncurrent position) and `2` (seek relative to the file\u2019s end). There is no\nreturn value. If the underlying file does not allow seek, only forward seeks\nare allowed.\n\nReturn the current position into the chunk.\n\nRead at most size bytes from the chunk (less if the read hits the end of the\nchunk before obtaining size bytes). If the size argument is negative or\nomitted, read all data until the end of the chunk. An empty bytes object is\nreturned when the end of the chunk is encountered immediately.\n\nSkip to the end of the chunk. All further calls to `read()` for the chunk will\nreturn `b''`. If you are not interested in the contents of the chunk, this\nmethod should be called so that the file points to the start of the next\nchunk.\n\n\u201cEA IFF 85\u201d Standard for Interchange Format Files, Jerry Morrison, Electronic\nArts, January 1985.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk", "path": "library/chunk#chunk.Chunk", "type": "Multimedia", "text": "\nClass which represents a chunk. The file argument is expected to be a file-\nlike object. An instance of this class is specifically allowed. The only\nmethod that is needed is `read()`. If the methods `seek()` and `tell()` are\npresent and don\u2019t raise an exception, they are also used. If these methods are\npresent and raise an exception, they are expected to not have altered the\nobject. If the optional argument align is true, chunks are assumed to be\naligned on 2-byte boundaries. If align is false, no alignment is assumed. The\ndefault value is true. If the optional argument bigendian is false, the chunk\nsize is assumed to be in little-endian order. This is needed for WAVE audio\nfiles. The default value is true. If the optional argument inclheader is true,\nthe size given in the chunk header includes the size of the header. The\ndefault value is false.\n\nA `Chunk` object supports the following methods:\n\nReturns the name (ID) of the chunk. This is the first 4 bytes of the chunk.\n\nReturns the size of the chunk.\n\nClose and skip to the end of the chunk. This does not close the underlying\nfile.\n\nThe remaining methods will raise `OSError` if called after the `close()`\nmethod has been called. Before Python 3.3, they used to raise `IOError`, now\nan alias of `OSError`.\n\nReturns `False`.\n\nSet the chunk\u2019s current position. The whence argument is optional and defaults\nto `0` (absolute file positioning); other values are `1` (seek relative to the\ncurrent position) and `2` (seek relative to the file\u2019s end). There is no\nreturn value. If the underlying file does not allow seek, only forward seeks\nare allowed.\n\nReturn the current position into the chunk.\n\nRead at most size bytes from the chunk (less if the read hits the end of the\nchunk before obtaining size bytes). If the size argument is negative or\nomitted, read all data until the end of the chunk. An empty bytes object is\nreturned when the end of the chunk is encountered immediately.\n\nSkip to the end of the chunk. All further calls to `read()` for the chunk will\nreturn `b''`. If you are not interested in the contents of the chunk, this\nmethod should be called so that the file points to the start of the next\nchunk.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.close()", "path": "library/chunk#chunk.Chunk.close", "type": "Multimedia", "text": "\nClose and skip to the end of the chunk. This does not close the underlying\nfile.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.getname()", "path": "library/chunk#chunk.Chunk.getname", "type": "Multimedia", "text": "\nReturns the name (ID) of the chunk. This is the first 4 bytes of the chunk.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.getsize()", "path": "library/chunk#chunk.Chunk.getsize", "type": "Multimedia", "text": "\nReturns the size of the chunk.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.isatty()", "path": "library/chunk#chunk.Chunk.isatty", "type": "Multimedia", "text": "\nReturns `False`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.read()", "path": "library/chunk#chunk.Chunk.read", "type": "Multimedia", "text": "\nRead at most size bytes from the chunk (less if the read hits the end of the\nchunk before obtaining size bytes). If the size argument is negative or\nomitted, read all data until the end of the chunk. An empty bytes object is\nreturned when the end of the chunk is encountered immediately.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.seek()", "path": "library/chunk#chunk.Chunk.seek", "type": "Multimedia", "text": "\nSet the chunk\u2019s current position. The whence argument is optional and defaults\nto `0` (absolute file positioning); other values are `1` (seek relative to the\ncurrent position) and `2` (seek relative to the file\u2019s end). There is no\nreturn value. If the underlying file does not allow seek, only forward seeks\nare allowed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.skip()", "path": "library/chunk#chunk.Chunk.skip", "type": "Multimedia", "text": "\nSkip to the end of the chunk. All further calls to `read()` for the chunk will\nreturn `b''`. If you are not interested in the contents of the chunk, this\nmethod should be called so that the file points to the start of the next\nchunk.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "chunk.Chunk.tell()", "path": "library/chunk#chunk.Chunk.tell", "type": "Multimedia", "text": "\nReturn the current position into the chunk.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "class.mro()", "path": "library/stdtypes#class.mro", "type": "Built-in Types", "text": "\nThis method can be overridden by a metaclass to customize the method\nresolution order for its instances. It is called at class instantiation, and\nits result is stored in `__mro__`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "class.__bases__", "path": "library/stdtypes#class.__bases__", "type": "Built-in Types", "text": "\nThe tuple of base classes of a class object.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "class.__mro__", "path": "library/stdtypes#class.__mro__", "type": "Built-in Types", "text": "\nThis attribute is a tuple of classes that are considered when looking for base\nclasses during method resolution.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "class.__subclasses__()", "path": "library/stdtypes#class.__subclasses__", "type": "Built-in Types", "text": "\nEach class keeps a list of weak references to its immediate subclasses. This\nmethod returns a list of all those references still alive. The list is in\ndefinition order. Example:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "classmethod()", "path": "library/functions#classmethod", "type": "Built-in Functions", "text": "\nTransform a method into a class method.\n\nA class method receives the class as implicit first argument, just like an\ninstance method receives the instance. To declare a class method, use this\nidiom:\n\nThe `@classmethod` form is a function decorator \u2013 see Function definitions for\ndetails.\n\nA class method can be called either on the class (such as `C.f()`) or on an\ninstance (such as `C().f()`). The instance is ignored except for its class. If\na class method is called for a derived class, the derived class object is\npassed as the implied first argument.\n\nClass methods are different than C++ or Java static methods. If you want\nthose, see `staticmethod()` in this section. For more information on class\nmethods, see The standard type hierarchy.\n\nChanged in version 3.9: Class methods can now wrap other descriptors such as\n`property()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath", "path": "library/cmath", "type": "Numeric & Mathematical", "text": "\nThis module provides access to mathematical functions for complex numbers. The\nfunctions in this module accept integers, floating-point numbers or complex\nnumbers as arguments. They will also accept any Python object that has either\na `__complex__()` or a `__float__()` method: these methods are used to convert\nthe object to a complex or floating-point number, respectively, and the\nfunction is then applied to the result of the conversion.\n\nNote\n\nOn platforms with hardware and system-level support for signed zeros,\nfunctions involving branch cuts are continuous on both sides of the branch\ncut: the sign of the zero distinguishes one side of the branch cut from the\nother. On platforms that do not support signed zeros the continuity is as\nspecified below.\n\nA Python complex number `z` is stored internally using rectangular or\nCartesian coordinates. It is completely determined by its real part `z.real`\nand its imaginary part `z.imag`. In other words:\n\nPolar coordinates give an alternative way to represent a complex number. In\npolar coordinates, a complex number z is defined by the modulus r and the\nphase angle phi. The modulus r is the distance from z to the origin, while the\nphase phi is the counterclockwise angle, measured in radians, from the\npositive x-axis to the line segment that joins the origin to z.\n\nThe following functions can be used to convert from the native rectangular\ncoordinates to polar coordinates and back.\n\nReturn the phase of x (also known as the argument of x), as a float.\n`phase(x)` is equivalent to `math.atan2(x.imag, x.real)`. The result lies in\nthe range [-\u03c0, \u03c0], and the branch cut for this operation lies along the\nnegative real axis, continuous from above. On systems with support for signed\nzeros (which includes most systems in current use), this means that the sign\nof the result is the same as the sign of `x.imag`, even when `x.imag` is zero:\n\nNote\n\nThe modulus (absolute value) of a complex number x can be computed using the\nbuilt-in `abs()` function. There is no separate `cmath` module function for\nthis operation.\n\nReturn the representation of x in polar coordinates. Returns a pair `(r, phi)`\nwhere r is the modulus of x and phi is the phase of x. `polar(x)` is\nequivalent to `(abs(x), phase(x))`.\n\nReturn the complex number x with polar coordinates r and phi. Equivalent to `r\n* (math.cos(phi) + math.sin(phi)*1j)`.\n\nReturn e raised to the power x, where e is the base of natural logarithms.\n\nReturns the logarithm of x to the given base. If the base is not specified,\nreturns the natural logarithm of x. There is one branch cut, from 0 along the\nnegative real axis to -\u221e, continuous from above.\n\nReturn the base-10 logarithm of x. This has the same branch cut as `log()`.\n\nReturn the square root of x. This has the same branch cut as `log()`.\n\nReturn the arc cosine of x. There are two branch cuts: One extends right from\n1 along the real axis to \u221e, continuous from below. The other extends left from\n-1 along the real axis to -\u221e, continuous from above.\n\nReturn the arc sine of x. This has the same branch cuts as `acos()`.\n\nReturn the arc tangent of x. There are two branch cuts: One extends from `1j`\nalong the imaginary axis to `\u221ej`, continuous from the right. The other extends\nfrom `-1j` along the imaginary axis to `-\u221ej`, continuous from the left.\n\nReturn the cosine of x.\n\nReturn the sine of x.\n\nReturn the tangent of x.\n\nReturn the inverse hyperbolic cosine of x. There is one branch cut, extending\nleft from 1 along the real axis to -\u221e, continuous from above.\n\nReturn the inverse hyperbolic sine of x. There are two branch cuts: One\nextends from `1j` along the imaginary axis to `\u221ej`, continuous from the right.\nThe other extends from `-1j` along the imaginary axis to `-\u221ej`, continuous\nfrom the left.\n\nReturn the inverse hyperbolic tangent of x. There are two branch cuts: One\nextends from `1` along the real axis to `\u221e`, continuous from below. The other\nextends from `-1` along the real axis to `-\u221e`, continuous from above.\n\nReturn the hyperbolic cosine of x.\n\nReturn the hyperbolic sine of x.\n\nReturn the hyperbolic tangent of x.\n\nReturn `True` if both the real and imaginary parts of x are finite, and\n`False` otherwise.\n\nNew in version 3.2.\n\nReturn `True` if either the real or the imaginary part of x is an infinity,\nand `False` otherwise.\n\nReturn `True` if either the real or the imaginary part of x is a NaN, and\n`False` otherwise.\n\nReturn `True` if the values a and b are close to each other and `False`\notherwise.\n\nWhether or not two values are considered close is determined according to\ngiven absolute and relative tolerances.\n\nrel_tol is the relative tolerance \u2013 it is the maximum allowed difference\nbetween a and b, relative to the larger absolute value of a or b. For example,\nto set a tolerance of 5%, pass `rel_tol=0.05`. The default tolerance is\n`1e-09`, which assures that the two values are the same within about 9 decimal\ndigits. rel_tol must be greater than zero.\n\nabs_tol is the minimum absolute tolerance \u2013 useful for comparisons near zero.\nabs_tol must be at least zero.\n\nIf no errors occur, the result will be: `abs(a-b) <= max(rel_tol * max(abs(a),\nabs(b)), abs_tol)`.\n\nThe IEEE 754 special values of `NaN`, `inf`, and `-inf` will be handled\naccording to IEEE rules. Specifically, `NaN` is not considered close to any\nother value, including `NaN`. `inf` and `-inf` are only considered close to\nthemselves.\n\nNew in version 3.5.\n\nSee also\n\nPEP 485 \u2013 A function for testing approximate equality\n\nThe mathematical constant \u03c0, as a float.\n\nThe mathematical constant e, as a float.\n\nThe mathematical constant \u03c4, as a float.\n\nNew in version 3.6.\n\nFloating-point positive infinity. Equivalent to `float('inf')`.\n\nNew in version 3.6.\n\nComplex number with zero real part and positive infinity imaginary part.\nEquivalent to `complex(0.0, float('inf'))`.\n\nNew in version 3.6.\n\nA floating-point \u201cnot a number\u201d (NaN) value. Equivalent to `float('nan')`.\n\nNew in version 3.6.\n\nComplex number with zero real part and NaN imaginary part. Equivalent to\n`complex(0.0, float('nan'))`.\n\nNew in version 3.6.\n\nNote that the selection of functions is similar, but not identical, to that in\nmodule `math`. The reason for having two modules is that some users aren\u2019t\ninterested in complex numbers, and perhaps don\u2019t even know what they are. They\nwould rather have `math.sqrt(-1)` raise an exception than return a complex\nnumber. Also note that the functions defined in `cmath` always return a\ncomplex number, even if the answer can be expressed as a real number (in which\ncase the complex number has an imaginary part of zero).\n\nA note on branch cuts: They are curves along which the given function fails to\nbe continuous. They are a necessary feature of many complex functions. It is\nassumed that if you need to compute with complex functions, you will\nunderstand about branch cuts. Consult almost any (not too elementary) book on\ncomplex variables for enlightenment. For information of the proper choice of\nbranch cuts for numerical purposes, a good reference should be the following:\n\nSee also\n\nKahan, W: Branch cuts for complex elementary functions; or, Much ado about\nnothing\u2019s sign bit. In Iserles, A., and Powell, M. (eds.), The state of the\nart in numerical analysis. Clarendon Press (1987) pp165\u2013211.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.acos()", "path": "library/cmath#cmath.acos", "type": "Numeric & Mathematical", "text": "\nReturn the arc cosine of x. There are two branch cuts: One extends right from\n1 along the real axis to \u221e, continuous from below. The other extends left from\n-1 along the real axis to -\u221e, continuous from above.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.acosh()", "path": "library/cmath#cmath.acosh", "type": "Numeric & Mathematical", "text": "\nReturn the inverse hyperbolic cosine of x. There is one branch cut, extending\nleft from 1 along the real axis to -\u221e, continuous from above.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.asin()", "path": "library/cmath#cmath.asin", "type": "Numeric & Mathematical", "text": "\nReturn the arc sine of x. This has the same branch cuts as `acos()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.asinh()", "path": "library/cmath#cmath.asinh", "type": "Numeric & Mathematical", "text": "\nReturn the inverse hyperbolic sine of x. There are two branch cuts: One\nextends from `1j` along the imaginary axis to `\u221ej`, continuous from the right.\nThe other extends from `-1j` along the imaginary axis to `-\u221ej`, continuous\nfrom the left.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.atan()", "path": "library/cmath#cmath.atan", "type": "Numeric & Mathematical", "text": "\nReturn the arc tangent of x. There are two branch cuts: One extends from `1j`\nalong the imaginary axis to `\u221ej`, continuous from the right. The other extends\nfrom `-1j` along the imaginary axis to `-\u221ej`, continuous from the left.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.atanh()", "path": "library/cmath#cmath.atanh", "type": "Numeric & Mathematical", "text": "\nReturn the inverse hyperbolic tangent of x. There are two branch cuts: One\nextends from `1` along the real axis to `\u221e`, continuous from below. The other\nextends from `-1` along the real axis to `-\u221e`, continuous from above.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.cos()", "path": "library/cmath#cmath.cos", "type": "Numeric & Mathematical", "text": "\nReturn the cosine of x.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.cosh()", "path": "library/cmath#cmath.cosh", "type": "Numeric & Mathematical", "text": "\nReturn the hyperbolic cosine of x.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.e", "path": "library/cmath#cmath.e", "type": "Numeric & Mathematical", "text": "\nThe mathematical constant e, as a float.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.exp()", "path": "library/cmath#cmath.exp", "type": "Numeric & Mathematical", "text": "\nReturn e raised to the power x, where e is the base of natural logarithms.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.inf", "path": "library/cmath#cmath.inf", "type": "Numeric & Mathematical", "text": "\nFloating-point positive infinity. Equivalent to `float('inf')`.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.infj", "path": "library/cmath#cmath.infj", "type": "Numeric & Mathematical", "text": "\nComplex number with zero real part and positive infinity imaginary part.\nEquivalent to `complex(0.0, float('inf'))`.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.isclose()", "path": "library/cmath#cmath.isclose", "type": "Numeric & Mathematical", "text": "\nReturn `True` if the values a and b are close to each other and `False`\notherwise.\n\nWhether or not two values are considered close is determined according to\ngiven absolute and relative tolerances.\n\nrel_tol is the relative tolerance \u2013 it is the maximum allowed difference\nbetween a and b, relative to the larger absolute value of a or b. For example,\nto set a tolerance of 5%, pass `rel_tol=0.05`. The default tolerance is\n`1e-09`, which assures that the two values are the same within about 9 decimal\ndigits. rel_tol must be greater than zero.\n\nabs_tol is the minimum absolute tolerance \u2013 useful for comparisons near zero.\nabs_tol must be at least zero.\n\nIf no errors occur, the result will be: `abs(a-b) <= max(rel_tol * max(abs(a),\nabs(b)), abs_tol)`.\n\nThe IEEE 754 special values of `NaN`, `inf`, and `-inf` will be handled\naccording to IEEE rules. Specifically, `NaN` is not considered close to any\nother value, including `NaN`. `inf` and `-inf` are only considered close to\nthemselves.\n\nNew in version 3.5.\n\nSee also\n\nPEP 485 \u2013 A function for testing approximate equality\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.isfinite()", "path": "library/cmath#cmath.isfinite", "type": "Numeric & Mathematical", "text": "\nReturn `True` if both the real and imaginary parts of x are finite, and\n`False` otherwise.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.isinf()", "path": "library/cmath#cmath.isinf", "type": "Numeric & Mathematical", "text": "\nReturn `True` if either the real or the imaginary part of x is an infinity,\nand `False` otherwise.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.isnan()", "path": "library/cmath#cmath.isnan", "type": "Numeric & Mathematical", "text": "\nReturn `True` if either the real or the imaginary part of x is a NaN, and\n`False` otherwise.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.log()", "path": "library/cmath#cmath.log", "type": "Numeric & Mathematical", "text": "\nReturns the logarithm of x to the given base. If the base is not specified,\nreturns the natural logarithm of x. There is one branch cut, from 0 along the\nnegative real axis to -\u221e, continuous from above.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.log10()", "path": "library/cmath#cmath.log10", "type": "Numeric & Mathematical", "text": "\nReturn the base-10 logarithm of x. This has the same branch cut as `log()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.nan", "path": "library/cmath#cmath.nan", "type": "Numeric & Mathematical", "text": "\nA floating-point \u201cnot a number\u201d (NaN) value. Equivalent to `float('nan')`.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.nanj", "path": "library/cmath#cmath.nanj", "type": "Numeric & Mathematical", "text": "\nComplex number with zero real part and NaN imaginary part. Equivalent to\n`complex(0.0, float('nan'))`.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.phase()", "path": "library/cmath#cmath.phase", "type": "Numeric & Mathematical", "text": "\nReturn the phase of x (also known as the argument of x), as a float.\n`phase(x)` is equivalent to `math.atan2(x.imag, x.real)`. The result lies in\nthe range [-\u03c0, \u03c0], and the branch cut for this operation lies along the\nnegative real axis, continuous from above. On systems with support for signed\nzeros (which includes most systems in current use), this means that the sign\nof the result is the same as the sign of `x.imag`, even when `x.imag` is zero:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.pi", "path": "library/cmath#cmath.pi", "type": "Numeric & Mathematical", "text": "\nThe mathematical constant \u03c0, as a float.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.polar()", "path": "library/cmath#cmath.polar", "type": "Numeric & Mathematical", "text": "\nReturn the representation of x in polar coordinates. Returns a pair `(r, phi)`\nwhere r is the modulus of x and phi is the phase of x. `polar(x)` is\nequivalent to `(abs(x), phase(x))`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.rect()", "path": "library/cmath#cmath.rect", "type": "Numeric & Mathematical", "text": "\nReturn the complex number x with polar coordinates r and phi. Equivalent to `r\n* (math.cos(phi) + math.sin(phi)*1j)`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.sin()", "path": "library/cmath#cmath.sin", "type": "Numeric & Mathematical", "text": "\nReturn the sine of x.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.sinh()", "path": "library/cmath#cmath.sinh", "type": "Numeric & Mathematical", "text": "\nReturn the hyperbolic sine of x.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.sqrt()", "path": "library/cmath#cmath.sqrt", "type": "Numeric & Mathematical", "text": "\nReturn the square root of x. This has the same branch cut as `log()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.tan()", "path": "library/cmath#cmath.tan", "type": "Numeric & Mathematical", "text": "\nReturn the tangent of x.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.tanh()", "path": "library/cmath#cmath.tanh", "type": "Numeric & Mathematical", "text": "\nReturn the hyperbolic tangent of x.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmath.tau", "path": "library/cmath#cmath.tau", "type": "Numeric & Mathematical", "text": "\nThe mathematical constant \u03c4, as a float.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd", "path": "library/cmd", "type": "Frameworks", "text": "\nSource code: Lib/cmd.py\n\nThe `Cmd` class provides a simple framework for writing line-oriented command\ninterpreters. These are often useful for test harnesses, administrative tools,\nand prototypes that will later be wrapped in a more sophisticated interface.\n\nA `Cmd` instance or subclass instance is a line-oriented interpreter\nframework. There is no good reason to instantiate `Cmd` itself; rather, it\u2019s\nuseful as a superclass of an interpreter class you define yourself in order to\ninherit `Cmd`\u2019s methods and encapsulate action methods.\n\nThe optional argument completekey is the `readline` name of a completion key;\nit defaults to `Tab`. If completekey is not `None` and `readline` is\navailable, command completion is done automatically.\n\nThe optional arguments stdin and stdout specify the input and output file\nobjects that the Cmd instance or subclass instance will use for input and\noutput. If not specified, they will default to `sys.stdin` and `sys.stdout`.\n\nIf you want a given stdin to be used, make sure to set the instance\u2019s\n`use_rawinput` attribute to `False`, otherwise stdin will be ignored.\n\nA `Cmd` instance has the following methods:\n\nRepeatedly issue a prompt, accept input, parse an initial prefix off the\nreceived input, and dispatch to action methods, passing them the remainder of\nthe line as argument.\n\nThe optional argument is a banner or intro string to be issued before the\nfirst prompt (this overrides the `intro` class attribute).\n\nIf the `readline` module is loaded, input will automatically inherit bash-like\nhistory-list editing (e.g. `Control-P` scrolls back to the last command,\n`Control-N` forward to the next one, `Control-F` moves the cursor to the right\nnon-destructively, `Control-B` moves the cursor to the left non-destructively,\netc.).\n\nAn end-of-file on input is passed back as the string `'EOF'`.\n\nAn interpreter instance will recognize a command name `foo` if and only if it\nhas a method `do_foo()`. As a special case, a line beginning with the\ncharacter `'?'` is dispatched to the method `do_help()`. As another special\ncase, a line beginning with the character `'!'` is dispatched to the method\n`do_shell()` (if such a method is defined).\n\nThis method will return when the `postcmd()` method returns a true value. The\nstop argument to `postcmd()` is the return value from the command\u2019s\ncorresponding `do_*()` method.\n\nIf completion is enabled, completing commands will be done automatically, and\ncompleting of commands args is done by calling `complete_foo()` with arguments\ntext, line, begidx, and endidx. text is the string prefix we are attempting to\nmatch: all returned matches must begin with it. line is the current input line\nwith leading whitespace removed, begidx and endidx are the beginning and\nending indexes of the prefix text, which could be used to provide different\ncompletion depending upon which position the argument is in.\n\nAll subclasses of `Cmd` inherit a predefined `do_help()`. This method, called\nwith an argument `'bar'`, invokes the corresponding method `help_bar()`, and\nif that is not present, prints the docstring of `do_bar()`, if available. With\nno argument, `do_help()` lists all available help topics (that is, all\ncommands with corresponding `help_*()` methods or commands that have\ndocstrings), and also lists any undocumented commands.\n\nInterpret the argument as though it had been typed in response to the prompt.\nThis may be overridden, but should not normally need to be; see the `precmd()`\nand `postcmd()` methods for useful execution hooks. The return value is a flag\nindicating whether interpretation of commands by the interpreter should stop.\nIf there is a `do_*()` method for the command str, the return value of that\nmethod is returned, otherwise the return value from the `default()` method is\nreturned.\n\nMethod called when an empty line is entered in response to the prompt. If this\nmethod is not overridden, it repeats the last nonempty command entered.\n\nMethod called on an input line when the command prefix is not recognized. If\nthis method is not overridden, it prints an error message and returns.\n\nMethod called to complete an input line when no command-specific\n`complete_*()` method is available. By default, it returns an empty list.\n\nHook method executed just before the command line line is interpreted, but\nafter the input prompt is generated and issued. This method is a stub in\n`Cmd`; it exists to be overridden by subclasses. The return value is used as\nthe command which will be executed by the `onecmd()` method; the `precmd()`\nimplementation may re-write the command or simply return line unchanged.\n\nHook method executed just after a command dispatch is finished. This method is\na stub in `Cmd`; it exists to be overridden by subclasses. line is the command\nline which was executed, and stop is a flag which indicates whether execution\nwill be terminated after the call to `postcmd()`; this will be the return\nvalue of the `onecmd()` method. The return value of this method will be used\nas the new value for the internal flag which corresponds to stop; returning\nfalse will cause interpretation to continue.\n\nHook method executed once when `cmdloop()` is called. This method is a stub in\n`Cmd`; it exists to be overridden by subclasses.\n\nHook method executed once when `cmdloop()` is about to return. This method is\na stub in `Cmd`; it exists to be overridden by subclasses.\n\nInstances of `Cmd` subclasses have some public instance variables:\n\nThe prompt issued to solicit input.\n\nThe string of characters accepted for the command prefix.\n\nThe last nonempty command prefix seen.\n\nA list of queued input lines. The cmdqueue list is checked in `cmdloop()` when\nnew input is needed; if it is nonempty, its elements will be processed in\norder, as if entered at the prompt.\n\nA string to issue as an intro or banner. May be overridden by giving the\n`cmdloop()` method an argument.\n\nThe header to issue if the help output has a section for documented commands.\n\nThe header to issue if the help output has a section for miscellaneous help\ntopics (that is, there are `help_*()` methods without corresponding `do_*()`\nmethods).\n\nThe header to issue if the help output has a section for undocumented commands\n(that is, there are `do_*()` methods without corresponding `help_*()`\nmethods).\n\nThe character used to draw separator lines under the help-message headers. If\nempty, no ruler line is drawn. It defaults to `'='`.\n\nA flag, defaulting to true. If true, `cmdloop()` uses `input()` to display a\nprompt and read the next command; if false, `sys.stdout.write()` and\n`sys.stdin.readline()` are used. (This means that by importing `readline`, on\nsystems that support it, the interpreter will automatically support Emacs-like\nline editing and command-history keystrokes.)\n\nThe `cmd` module is mainly useful for building custom shells that let a user\nwork with a program interactively.\n\nThis section presents a simple example of how to build a shell around a few of\nthe commands in the `turtle` module.\n\nBasic turtle commands such as `forward()` are added to a `Cmd` subclass with\nmethod named `do_forward()`. The argument is converted to a number and\ndispatched to the turtle module. The docstring is used in the help utility\nprovided by the shell.\n\nThe example also includes a basic record and playback facility implemented\nwith the `precmd()` method which is responsible for converting the input to\nlowercase and writing the commands to a file. The `do_playback()` method reads\nthe file and adds the recorded commands to the `cmdqueue` for immediate\nplayback:\n\nHere is a sample session with the turtle shell showing the help functions,\nusing blank lines to repeat commands, and the simple record and playback\nfacility:\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd", "path": "library/cmd#cmd.Cmd", "type": "Frameworks", "text": "\nA `Cmd` instance or subclass instance is a line-oriented interpreter\nframework. There is no good reason to instantiate `Cmd` itself; rather, it\u2019s\nuseful as a superclass of an interpreter class you define yourself in order to\ninherit `Cmd`\u2019s methods and encapsulate action methods.\n\nThe optional argument completekey is the `readline` name of a completion key;\nit defaults to `Tab`. If completekey is not `None` and `readline` is\navailable, command completion is done automatically.\n\nThe optional arguments stdin and stdout specify the input and output file\nobjects that the Cmd instance or subclass instance will use for input and\noutput. If not specified, they will default to `sys.stdin` and `sys.stdout`.\n\nIf you want a given stdin to be used, make sure to set the instance\u2019s\n`use_rawinput` attribute to `False`, otherwise stdin will be ignored.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.cmdloop()", "path": "library/cmd#cmd.Cmd.cmdloop", "type": "Frameworks", "text": "\nRepeatedly issue a prompt, accept input, parse an initial prefix off the\nreceived input, and dispatch to action methods, passing them the remainder of\nthe line as argument.\n\nThe optional argument is a banner or intro string to be issued before the\nfirst prompt (this overrides the `intro` class attribute).\n\nIf the `readline` module is loaded, input will automatically inherit bash-like\nhistory-list editing (e.g. `Control-P` scrolls back to the last command,\n`Control-N` forward to the next one, `Control-F` moves the cursor to the right\nnon-destructively, `Control-B` moves the cursor to the left non-destructively,\netc.).\n\nAn end-of-file on input is passed back as the string `'EOF'`.\n\nAn interpreter instance will recognize a command name `foo` if and only if it\nhas a method `do_foo()`. As a special case, a line beginning with the\ncharacter `'?'` is dispatched to the method `do_help()`. As another special\ncase, a line beginning with the character `'!'` is dispatched to the method\n`do_shell()` (if such a method is defined).\n\nThis method will return when the `postcmd()` method returns a true value. The\nstop argument to `postcmd()` is the return value from the command\u2019s\ncorresponding `do_*()` method.\n\nIf completion is enabled, completing commands will be done automatically, and\ncompleting of commands args is done by calling `complete_foo()` with arguments\ntext, line, begidx, and endidx. text is the string prefix we are attempting to\nmatch: all returned matches must begin with it. line is the current input line\nwith leading whitespace removed, begidx and endidx are the beginning and\nending indexes of the prefix text, which could be used to provide different\ncompletion depending upon which position the argument is in.\n\nAll subclasses of `Cmd` inherit a predefined `do_help()`. This method, called\nwith an argument `'bar'`, invokes the corresponding method `help_bar()`, and\nif that is not present, prints the docstring of `do_bar()`, if available. With\nno argument, `do_help()` lists all available help topics (that is, all\ncommands with corresponding `help_*()` methods or commands that have\ndocstrings), and also lists any undocumented commands.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.cmdqueue", "path": "library/cmd#cmd.Cmd.cmdqueue", "type": "Frameworks", "text": "\nA list of queued input lines. The cmdqueue list is checked in `cmdloop()` when\nnew input is needed; if it is nonempty, its elements will be processed in\norder, as if entered at the prompt.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.completedefault()", "path": "library/cmd#cmd.Cmd.completedefault", "type": "Frameworks", "text": "\nMethod called to complete an input line when no command-specific\n`complete_*()` method is available. By default, it returns an empty list.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.default()", "path": "library/cmd#cmd.Cmd.default", "type": "Frameworks", "text": "\nMethod called on an input line when the command prefix is not recognized. If\nthis method is not overridden, it prints an error message and returns.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.doc_header", "path": "library/cmd#cmd.Cmd.doc_header", "type": "Frameworks", "text": "\nThe header to issue if the help output has a section for documented commands.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.emptyline()", "path": "library/cmd#cmd.Cmd.emptyline", "type": "Frameworks", "text": "\nMethod called when an empty line is entered in response to the prompt. If this\nmethod is not overridden, it repeats the last nonempty command entered.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.identchars", "path": "library/cmd#cmd.Cmd.identchars", "type": "Frameworks", "text": "\nThe string of characters accepted for the command prefix.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.intro", "path": "library/cmd#cmd.Cmd.intro", "type": "Frameworks", "text": "\nA string to issue as an intro or banner. May be overridden by giving the\n`cmdloop()` method an argument.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.lastcmd", "path": "library/cmd#cmd.Cmd.lastcmd", "type": "Frameworks", "text": "\nThe last nonempty command prefix seen.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.misc_header", "path": "library/cmd#cmd.Cmd.misc_header", "type": "Frameworks", "text": "\nThe header to issue if the help output has a section for miscellaneous help\ntopics (that is, there are `help_*()` methods without corresponding `do_*()`\nmethods).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.onecmd()", "path": "library/cmd#cmd.Cmd.onecmd", "type": "Frameworks", "text": "\nInterpret the argument as though it had been typed in response to the prompt.\nThis may be overridden, but should not normally need to be; see the `precmd()`\nand `postcmd()` methods for useful execution hooks. The return value is a flag\nindicating whether interpretation of commands by the interpreter should stop.\nIf there is a `do_*()` method for the command str, the return value of that\nmethod is returned, otherwise the return value from the `default()` method is\nreturned.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.postcmd()", "path": "library/cmd#cmd.Cmd.postcmd", "type": "Frameworks", "text": "\nHook method executed just after a command dispatch is finished. This method is\na stub in `Cmd`; it exists to be overridden by subclasses. line is the command\nline which was executed, and stop is a flag which indicates whether execution\nwill be terminated after the call to `postcmd()`; this will be the return\nvalue of the `onecmd()` method. The return value of this method will be used\nas the new value for the internal flag which corresponds to stop; returning\nfalse will cause interpretation to continue.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.postloop()", "path": "library/cmd#cmd.Cmd.postloop", "type": "Frameworks", "text": "\nHook method executed once when `cmdloop()` is about to return. This method is\na stub in `Cmd`; it exists to be overridden by subclasses.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.precmd()", "path": "library/cmd#cmd.Cmd.precmd", "type": "Frameworks", "text": "\nHook method executed just before the command line line is interpreted, but\nafter the input prompt is generated and issued. This method is a stub in\n`Cmd`; it exists to be overridden by subclasses. The return value is used as\nthe command which will be executed by the `onecmd()` method; the `precmd()`\nimplementation may re-write the command or simply return line unchanged.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.preloop()", "path": "library/cmd#cmd.Cmd.preloop", "type": "Frameworks", "text": "\nHook method executed once when `cmdloop()` is called. This method is a stub in\n`Cmd`; it exists to be overridden by subclasses.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.prompt", "path": "library/cmd#cmd.Cmd.prompt", "type": "Frameworks", "text": "\nThe prompt issued to solicit input.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.ruler", "path": "library/cmd#cmd.Cmd.ruler", "type": "Frameworks", "text": "\nThe character used to draw separator lines under the help-message headers. If\nempty, no ruler line is drawn. It defaults to `'='`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.undoc_header", "path": "library/cmd#cmd.Cmd.undoc_header", "type": "Frameworks", "text": "\nThe header to issue if the help output has a section for undocumented commands\n(that is, there are `do_*()` methods without corresponding `help_*()`\nmethods).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "cmd.Cmd.use_rawinput", "path": "library/cmd#cmd.Cmd.use_rawinput", "type": "Frameworks", "text": "\nA flag, defaulting to true. If true, `cmdloop()` uses `input()` to display a\nprompt and read the next command; if false, `sys.stdout.write()` and\n`sys.stdin.readline()` are used. (This means that by importing `readline`, on\nsystems that support it, the interpreter will automatically support Emacs-like\nline editing and command-history keystrokes.)\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code", "path": "library/code", "type": "Interpreters", "text": "\nSource code: Lib/code.py\n\nThe `code` module provides facilities to implement read-eval-print loops in\nPython. Two classes and convenience functions are included which can be used\nto build applications which provide an interactive interpreter prompt.\n\nThis class deals with parsing and interpreter state (the user\u2019s namespace); it\ndoes not deal with input buffering or prompting or input file naming (the\nfilename is always passed in explicitly). The optional locals argument\nspecifies the dictionary in which code will be executed; it defaults to a\nnewly created dictionary with key `'__name__'` set to `'__console__'` and key\n`'__doc__'` set to `None`.\n\nClosely emulate the behavior of the interactive Python interpreter. This class\nbuilds on `InteractiveInterpreter` and adds prompting using the familiar\n`sys.ps1` and `sys.ps2`, and input buffering.\n\nConvenience function to run a read-eval-print loop. This creates a new\ninstance of `InteractiveConsole` and sets readfunc to be used as the\n`InteractiveConsole.raw_input()` method, if provided. If local is provided, it\nis passed to the `InteractiveConsole` constructor for use as the default\nnamespace for the interpreter loop. The `interact()` method of the instance is\nthen run with banner and exitmsg passed as the banner and exit message to use,\nif provided. The console object is discarded after use.\n\nChanged in version 3.6: Added exitmsg parameter.\n\nThis function is useful for programs that want to emulate Python\u2019s interpreter\nmain loop (a.k.a. the read-eval-print loop). The tricky part is to determine\nwhen the user has entered an incomplete command that can be completed by\nentering more text (as opposed to a complete command or a syntax error). This\nfunction almost always makes the same decision as the real interpreter main\nloop.\n\nsource is the source string; filename is the optional filename from which\nsource was read, defaulting to `'<input>'`; and symbol is the optional grammar\nstart symbol, which should be `'single'` (the default), `'eval'` or `'exec'`.\n\nReturns a code object (the same as `compile(source, filename, symbol)`) if the\ncommand is complete and valid; `None` if the command is incomplete; raises\n`SyntaxError` if the command is complete and contains a syntax error, or\nraises `OverflowError` or `ValueError` if the command contains an invalid\nliteral.\n\nCompile and run some source in the interpreter. Arguments are the same as for\n`compile_command()`; the default for filename is `'<input>'`, and for symbol\nis `'single'`. One of several things can happen:\n\nThe return value can be used to decide whether to use `sys.ps1` or `sys.ps2`\nto prompt the next line.\n\nExecute a code object. When an exception occurs, `showtraceback()` is called\nto display a traceback. All exceptions are caught except `SystemExit`, which\nis allowed to propagate.\n\nA note about `KeyboardInterrupt`: this exception may occur elsewhere in this\ncode, and may not always be caught. The caller should be prepared to deal with\nit.\n\nDisplay the syntax error that just occurred. This does not display a stack\ntrace because there isn\u2019t one for syntax errors. If filename is given, it is\nstuffed into the exception instead of the default filename provided by\nPython\u2019s parser, because it always uses `'<string>'` when reading from a\nstring. The output is written by the `write()` method.\n\nDisplay the exception that just occurred. We remove the first stack item\nbecause it is within the interpreter object implementation. The output is\nwritten by the `write()` method.\n\nChanged in version 3.5: The full chained traceback is displayed instead of\njust the primary traceback.\n\nWrite a string to the standard error stream (`sys.stderr`). Derived classes\nshould override this to provide the appropriate output handling as needed.\n\nThe `InteractiveConsole` class is a subclass of `InteractiveInterpreter`, and\nso offers all the methods of the interpreter objects as well as the following\nadditions.\n\nClosely emulate the interactive Python console. The optional banner argument\nspecify the banner to print before the first interaction; by default it prints\na banner similar to the one printed by the standard Python interpreter,\nfollowed by the class name of the console object in parentheses (so as not to\nconfuse this with the real interpreter \u2013 since it\u2019s so close!).\n\nThe optional exitmsg argument specifies an exit message printed when exiting.\nPass the empty string to suppress the exit message. If exitmsg is not given or\n`None`, a default message is printed.\n\nChanged in version 3.4: To suppress printing any banner, pass an empty string.\n\nChanged in version 3.6: Print an exit message when exiting.\n\nPush a line of source text to the interpreter. The line should not have a\ntrailing newline; it may have internal newlines. The line is appended to a\nbuffer and the interpreter\u2019s `runsource()` method is called with the\nconcatenated contents of the buffer as source. If this indicates that the\ncommand was executed or invalid, the buffer is reset; otherwise, the command\nis incomplete, and the buffer is left as it was after the line was appended.\nThe return value is `True` if more input is required, `False` if the line was\ndealt with in some way (this is the same as `runsource()`).\n\nRemove any unhandled source text from the input buffer.\n\nWrite a prompt and read a line. The returned line does not include the\ntrailing newline. When the user enters the EOF key sequence, `EOFError` is\nraised. The base implementation reads from `sys.stdin`; a subclass may replace\nthis with a different implementation.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.compile_command()", "path": "library/code#code.compile_command", "type": "Interpreters", "text": "\nThis function is useful for programs that want to emulate Python\u2019s interpreter\nmain loop (a.k.a. the read-eval-print loop). The tricky part is to determine\nwhen the user has entered an incomplete command that can be completed by\nentering more text (as opposed to a complete command or a syntax error). This\nfunction almost always makes the same decision as the real interpreter main\nloop.\n\nsource is the source string; filename is the optional filename from which\nsource was read, defaulting to `'<input>'`; and symbol is the optional grammar\nstart symbol, which should be `'single'` (the default), `'eval'` or `'exec'`.\n\nReturns a code object (the same as `compile(source, filename, symbol)`) if the\ncommand is complete and valid; `None` if the command is incomplete; raises\n`SyntaxError` if the command is complete and contains a syntax error, or\nraises `OverflowError` or `ValueError` if the command contains an invalid\nliteral.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.interact()", "path": "library/code#code.interact", "type": "Interpreters", "text": "\nConvenience function to run a read-eval-print loop. This creates a new\ninstance of `InteractiveConsole` and sets readfunc to be used as the\n`InteractiveConsole.raw_input()` method, if provided. If local is provided, it\nis passed to the `InteractiveConsole` constructor for use as the default\nnamespace for the interpreter loop. The `interact()` method of the instance is\nthen run with banner and exitmsg passed as the banner and exit message to use,\nif provided. The console object is discarded after use.\n\nChanged in version 3.6: Added exitmsg parameter.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveConsole", "path": "library/code#code.InteractiveConsole", "type": "Interpreters", "text": "\nClosely emulate the behavior of the interactive Python interpreter. This class\nbuilds on `InteractiveInterpreter` and adds prompting using the familiar\n`sys.ps1` and `sys.ps2`, and input buffering.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveConsole.interact()", "path": "library/code#code.InteractiveConsole.interact", "type": "Interpreters", "text": "\nClosely emulate the interactive Python console. The optional banner argument\nspecify the banner to print before the first interaction; by default it prints\na banner similar to the one printed by the standard Python interpreter,\nfollowed by the class name of the console object in parentheses (so as not to\nconfuse this with the real interpreter \u2013 since it\u2019s so close!).\n\nThe optional exitmsg argument specifies an exit message printed when exiting.\nPass the empty string to suppress the exit message. If exitmsg is not given or\n`None`, a default message is printed.\n\nChanged in version 3.4: To suppress printing any banner, pass an empty string.\n\nChanged in version 3.6: Print an exit message when exiting.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveConsole.push()", "path": "library/code#code.InteractiveConsole.push", "type": "Interpreters", "text": "\nPush a line of source text to the interpreter. The line should not have a\ntrailing newline; it may have internal newlines. The line is appended to a\nbuffer and the interpreter\u2019s `runsource()` method is called with the\nconcatenated contents of the buffer as source. If this indicates that the\ncommand was executed or invalid, the buffer is reset; otherwise, the command\nis incomplete, and the buffer is left as it was after the line was appended.\nThe return value is `True` if more input is required, `False` if the line was\ndealt with in some way (this is the same as `runsource()`).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveConsole.raw_input()", "path": "library/code#code.InteractiveConsole.raw_input", "type": "Interpreters", "text": "\nWrite a prompt and read a line. The returned line does not include the\ntrailing newline. When the user enters the EOF key sequence, `EOFError` is\nraised. The base implementation reads from `sys.stdin`; a subclass may replace\nthis with a different implementation.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveConsole.resetbuffer()", "path": "library/code#code.InteractiveConsole.resetbuffer", "type": "Interpreters", "text": "\nRemove any unhandled source text from the input buffer.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveInterpreter", "path": "library/code#code.InteractiveInterpreter", "type": "Interpreters", "text": "\nThis class deals with parsing and interpreter state (the user\u2019s namespace); it\ndoes not deal with input buffering or prompting or input file naming (the\nfilename is always passed in explicitly). The optional locals argument\nspecifies the dictionary in which code will be executed; it defaults to a\nnewly created dictionary with key `'__name__'` set to `'__console__'` and key\n`'__doc__'` set to `None`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveInterpreter.runcode()", "path": "library/code#code.InteractiveInterpreter.runcode", "type": "Interpreters", "text": "\nExecute a code object. When an exception occurs, `showtraceback()` is called\nto display a traceback. All exceptions are caught except `SystemExit`, which\nis allowed to propagate.\n\nA note about `KeyboardInterrupt`: this exception may occur elsewhere in this\ncode, and may not always be caught. The caller should be prepared to deal with\nit.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveInterpreter.runsource()", "path": "library/code#code.InteractiveInterpreter.runsource", "type": "Interpreters", "text": "\nCompile and run some source in the interpreter. Arguments are the same as for\n`compile_command()`; the default for filename is `'<input>'`, and for symbol\nis `'single'`. One of several things can happen:\n\nThe return value can be used to decide whether to use `sys.ps1` or `sys.ps2`\nto prompt the next line.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveInterpreter.showsyntaxerror()", "path": "library/code#code.InteractiveInterpreter.showsyntaxerror", "type": "Interpreters", "text": "\nDisplay the syntax error that just occurred. This does not display a stack\ntrace because there isn\u2019t one for syntax errors. If filename is given, it is\nstuffed into the exception instead of the default filename provided by\nPython\u2019s parser, because it always uses `'<string>'` when reading from a\nstring. The output is written by the `write()` method.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveInterpreter.showtraceback()", "path": "library/code#code.InteractiveInterpreter.showtraceback", "type": "Interpreters", "text": "\nDisplay the exception that just occurred. We remove the first stack item\nbecause it is within the interpreter object implementation. The output is\nwritten by the `write()` method.\n\nChanged in version 3.5: The full chained traceback is displayed instead of\njust the primary traceback.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "code.InteractiveInterpreter.write()", "path": "library/code#code.InteractiveInterpreter.write", "type": "Interpreters", "text": "\nWrite a string to the standard error stream (`sys.stderr`). Derived classes\nshould override this to provide the appropriate output handling as needed.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs", "path": "library/codecs", "type": "Binary Data", "text": "\nSource code: Lib/codecs.py\n\nThis module defines base classes for standard Python codecs (encoders and\ndecoders) and provides access to the internal Python codec registry, which\nmanages the codec and error handling lookup process. Most standard codecs are\ntext encodings, which encode text to bytes, but there are also codecs provided\nthat encode text to text, and bytes to bytes. Custom codecs may encode and\ndecode between arbitrary types, but some module features are restricted to use\nspecifically with text encodings, or with codecs that encode to `bytes`.\n\nThe module defines the following functions for encoding and decoding with any\ncodec:\n\nEncodes obj using the codec registered for encoding.\n\nErrors may be given to set the desired error handling scheme. The default\nerror handler is `'strict'` meaning that encoding errors raise `ValueError`\n(or a more codec specific subclass, such as `UnicodeEncodeError`). Refer to\nCodec Base Classes for more information on codec error handling.\n\nDecodes obj using the codec registered for encoding.\n\nErrors may be given to set the desired error handling scheme. The default\nerror handler is `'strict'` meaning that decoding errors raise `ValueError`\n(or a more codec specific subclass, such as `UnicodeDecodeError`). Refer to\nCodec Base Classes for more information on codec error handling.\n\nThe full details for each codec can also be looked up directly:\n\nLooks up the codec info in the Python codec registry and returns a `CodecInfo`\nobject as defined below.\n\nEncodings are first looked up in the registry\u2019s cache. If not found, the list\nof registered search functions is scanned. If no `CodecInfo` object is found,\na `LookupError` is raised. Otherwise, the `CodecInfo` object is stored in the\ncache and returned to the caller.\n\nCodec details when looking up the codec registry. The constructor arguments\nare stored in attributes of the same name:\n\nThe name of the encoding.\n\nThe stateless encoding and decoding functions. These must be functions or\nmethods which have the same interface as the `encode()` and `decode()` methods\nof Codec instances (see Codec Interface). The functions or methods are\nexpected to work in a stateless mode.\n\nIncremental encoder and decoder classes or factory functions. These have to\nprovide the interface defined by the base classes `IncrementalEncoder` and\n`IncrementalDecoder`, respectively. Incremental codecs can maintain state.\n\nStream writer and reader classes or factory functions. These have to provide\nthe interface defined by the base classes `StreamWriter` and `StreamReader`,\nrespectively. Stream codecs can maintain state.\n\nTo simplify access to the various codec components, the module provides these\nadditional functions which use `lookup()` for the codec lookup:\n\nLook up the codec for the given encoding and return its encoder function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\nLook up the codec for the given encoding and return its decoder function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\nLook up the codec for the given encoding and return its incremental encoder\nclass or factory function.\n\nRaises a `LookupError` in case the encoding cannot be found or the codec\ndoesn\u2019t support an incremental encoder.\n\nLook up the codec for the given encoding and return its incremental decoder\nclass or factory function.\n\nRaises a `LookupError` in case the encoding cannot be found or the codec\ndoesn\u2019t support an incremental decoder.\n\nLook up the codec for the given encoding and return its `StreamReader` class\nor factory function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\nLook up the codec for the given encoding and return its `StreamWriter` class\nor factory function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\nCustom codecs are made available by registering a suitable codec search\nfunction:\n\nRegister a codec search function. Search functions are expected to take one\nargument, being the encoding name in all lower case letters with hyphens and\nspaces converted to underscores, and return a `CodecInfo` object. In case a\nsearch function cannot find a given encoding, it should return `None`.\n\nChanged in version 3.9: Hyphens and spaces are converted to underscore.\n\nNote\n\nSearch function registration is not currently reversible, which may cause\nproblems in some cases, such as unit testing or module reloading.\n\nWhile the builtin `open()` and the associated `io` module are the recommended\napproach for working with encoded text files, this module provides additional\nutility functions and classes that allow the use of a wider range of codecs\nwhen working with binary files:\n\nOpen an encoded file using the given mode and return an instance of\n`StreamReaderWriter`, providing transparent encoding/decoding. The default\nfile mode is `'r'`, meaning to open the file in read mode.\n\nNote\n\nUnderlying encoded files are always opened in binary mode. No automatic\nconversion of `'\\n'` is done on reading and writing. The mode argument may be\nany binary mode acceptable to the built-in `open()` function; the `'b'` is\nautomatically added.\n\nencoding specifies the encoding which is to be used for the file. Any encoding\nthat encodes to and decodes from bytes is allowed, and the data types\nsupported by the file methods depend on the codec used.\n\nerrors may be given to define the error handling. It defaults to `'strict'`\nwhich causes a `ValueError` to be raised in case an encoding error occurs.\n\nbuffering has the same meaning as for the built-in `open()` function. It\ndefaults to -1 which means that the default buffer size will be used.\n\nReturn a `StreamRecoder` instance, a wrapped version of file which provides\ntransparent transcoding. The original file is closed when the wrapped version\nis closed.\n\nData written to the wrapped file is decoded according to the given\ndata_encoding and then written to the original file as bytes using\nfile_encoding. Bytes read from the original file are decoded according to\nfile_encoding, and the result is encoded using data_encoding.\n\nIf file_encoding is not given, it defaults to data_encoding.\n\nerrors may be given to define the error handling. It defaults to `'strict'`,\nwhich causes `ValueError` to be raised in case an encoding error occurs.\n\nUses an incremental encoder to iteratively encode the input provided by\niterator. This function is a generator. The errors argument (as well as any\nother keyword argument) is passed through to the incremental encoder.\n\nThis function requires that the codec accept text `str` objects to encode.\nTherefore it does not support bytes-to-bytes encoders such as `base64_codec`.\n\nUses an incremental decoder to iteratively decode the input provided by\niterator. This function is a generator. The errors argument (as well as any\nother keyword argument) is passed through to the incremental decoder.\n\nThis function requires that the codec accept `bytes` objects to decode.\nTherefore it does not support text-to-text encoders such as `rot_13`, although\n`rot_13` may be used equivalently with `iterencode()`.\n\nThe module also provides the following constants which are useful for reading\nand writing to platform dependent files:\n\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\nThe `codecs` module defines a set of base classes which define the interfaces\nfor working with codec objects, and can also be used as the basis for custom\ncodec implementations.\n\nEach codec has to define four interfaces to make it usable as codec in Python:\nstateless encoder, stateless decoder, stream reader and stream writer. The\nstream reader and writers typically reuse the stateless encoder/decoder to\nimplement the file protocols. Codec authors also need to define how the codec\nwill handle encoding and decoding errors.\n\nTo simplify and standardize error handling, codecs may implement different\nerror handling schemes by accepting the errors string argument. The following\nstring values are defined and implemented by all standard Python codecs:\n\nValue\n\nMeaning\n\n`'strict'`\n\nRaise `UnicodeError` (or a subclass); this is the default. Implemented in\n`strict_errors()`.\n\n`'ignore'`\n\nIgnore the malformed data and continue without further notice. Implemented in\n`ignore_errors()`.\n\nThe following error handlers are only applicable to text encodings:\n\nValue\n\nMeaning\n\n`'replace'`\n\nReplace with a suitable replacement marker; Python will use the official\n`U+FFFD` REPLACEMENT CHARACTER for the built-in codecs on decoding, and \u2018?\u2019 on\nencoding. Implemented in `replace_errors()`.\n\n`'xmlcharrefreplace'`\n\nReplace with the appropriate XML character reference (only for encoding).\nImplemented in `xmlcharrefreplace_errors()`.\n\n`'backslashreplace'`\n\nReplace with backslashed escape sequences. Implemented in\n`backslashreplace_errors()`.\n\n`'namereplace'`\n\nReplace with `\\N{...}` escape sequences (only for encoding). Implemented in\n`namereplace_errors()`.\n\n`'surrogateescape'`\n\nOn decoding, replace byte with individual surrogate code ranging from `U+DC80`\nto `U+DCFF`. This code will then be turned back into the same byte when the\n`'surrogateescape'` error handler is used when encoding the data. (See PEP 383\nfor more.)\n\nIn addition, the following error handler is specific to the given codecs:\n\nValue\n\nCodecs\n\nMeaning\n\n`'surrogatepass'`\n\nutf-8, utf-16, utf-32, utf-16-be, utf-16-le, utf-32-be, utf-32-le\n\nAllow encoding and decoding of surrogate codes. These codecs normally treat\nthe presence of surrogates as an error.\n\nNew in version 3.1: The `'surrogateescape'` and `'surrogatepass'` error\nhandlers.\n\nChanged in version 3.4: The `'surrogatepass'` error handlers now works with\nutf-16* and utf-32* codecs.\n\nNew in version 3.5: The `'namereplace'` error handler.\n\nChanged in version 3.5: The `'backslashreplace'` error handlers now works with\ndecoding and translating.\n\nThe set of allowed values can be extended by registering a new named error\nhandler:\n\nRegister the error handling function error_handler under the name name. The\nerror_handler argument will be called during encoding and decoding in case of\nan error, when name is specified as the errors parameter.\n\nFor encoding, error_handler will be called with a `UnicodeEncodeError`\ninstance, which contains information about the location of the error. The\nerror handler must either raise this or a different exception, or return a\ntuple with a replacement for the unencodable part of the input and a position\nwhere encoding should continue. The replacement may be either `str` or\n`bytes`. If the replacement is bytes, the encoder will simply copy them into\nthe output buffer. If the replacement is a string, the encoder will encode the\nreplacement. Encoding continues on original input at the specified position.\nNegative position values will be treated as being relative to the end of the\ninput string. If the resulting position is out of bound an `IndexError` will\nbe raised.\n\nDecoding and translating works similarly, except `UnicodeDecodeError` or\n`UnicodeTranslateError` will be passed to the handler and that the replacement\nfrom the error handler will be put into the output directly.\n\nPreviously registered error handlers (including the standard error handlers)\ncan be looked up by name:\n\nReturn the error handler previously registered under the name name.\n\nRaises a `LookupError` in case the handler cannot be found.\n\nThe following standard error handlers are also made available as module level\nfunctions:\n\nImplements the `'strict'` error handling: each encoding or decoding error\nraises a `UnicodeError`.\n\nImplements the `'replace'` error handling (for text encodings only):\nsubstitutes `'?'` for encoding errors (to be encoded by the codec), and\n`'\\ufffd'` (the Unicode replacement character) for decoding errors.\n\nImplements the `'ignore'` error handling: malformed data is ignored and\nencoding or decoding is continued without further notice.\n\nImplements the `'xmlcharrefreplace'` error handling (for encoding with text\nencodings only): the unencodable character is replaced by an appropriate XML\ncharacter reference.\n\nImplements the `'backslashreplace'` error handling (for text encodings only):\nmalformed data is replaced by a backslashed escape sequence.\n\nImplements the `'namereplace'` error handling (for encoding with text\nencodings only): the unencodable character is replaced by a `\\N{...}` escape\nsequence.\n\nNew in version 3.5.\n\nThe base `Codec` class defines these methods which also define the function\ninterfaces of the stateless encoder and decoder:\n\nEncodes the object input and returns a tuple (output object, length consumed).\nFor instance, text encoding converts a string object to a bytes object using a\nparticular character set encoding (e.g., `cp1252` or `iso-8859-1`).\n\nThe errors argument defines the error handling to apply. It defaults to\n`'strict'` handling.\n\nThe method may not store state in the `Codec` instance. Use `StreamWriter` for\ncodecs which have to keep state in order to make encoding efficient.\n\nThe encoder must be able to handle zero length input and return an empty\nobject of the output object type in this situation.\n\nDecodes the object input and returns a tuple (output object, length consumed).\nFor instance, for a text encoding, decoding converts a bytes object encoded\nusing a particular character set encoding to a string object.\n\nFor text encodings and bytes-to-bytes codecs, input must be a bytes object or\none which provides the read-only buffer interface \u2013 for example, buffer\nobjects and memory mapped files.\n\nThe errors argument defines the error handling to apply. It defaults to\n`'strict'` handling.\n\nThe method may not store state in the `Codec` instance. Use `StreamReader` for\ncodecs which have to keep state in order to make decoding efficient.\n\nThe decoder must be able to handle zero length input and return an empty\nobject of the output object type in this situation.\n\nThe `IncrementalEncoder` and `IncrementalDecoder` classes provide the basic\ninterface for incremental encoding and decoding. Encoding/decoding the input\nisn\u2019t done with one call to the stateless encoder/decoder function, but with\nmultiple calls to the `encode()`/`decode()` method of the incremental\nencoder/decoder. The incremental encoder/decoder keeps track of the\nencoding/decoding process during method calls.\n\nThe joined output of calls to the `encode()`/`decode()` method is the same as\nif all the single inputs were joined into one, and this input was\nencoded/decoded with the stateless encoder/decoder.\n\nThe `IncrementalEncoder` class is used for encoding an input in multiple\nsteps. It defines the following methods which every incremental encoder must\ndefine in order to be compatible with the Python codec registry.\n\nConstructor for an `IncrementalEncoder` instance.\n\nAll incremental encoders must provide this constructor interface. They are\nfree to add additional keyword arguments, but only the ones defined here are\nused by the Python codec registry.\n\nThe `IncrementalEncoder` may implement different error handling schemes by\nproviding the errors keyword argument. See Error Handlers for possible values.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `IncrementalEncoder`\nobject.\n\nEncodes object (taking the current state of the encoder into account) and\nreturns the resulting encoded object. If this is the last call to `encode()`\nfinal must be true (the default is false).\n\nReset the encoder to the initial state. The output is discarded: call\n`.encode(object, final=True)`, passing an empty byte or text string if\nnecessary, to reset the encoder and to get the output.\n\nReturn the current state of the encoder which must be an integer. The\nimplementation should make sure that `0` is the most common state. (States\nthat are more complicated than integers can be converted into an integer by\nmarshaling/pickling the state and encoding the bytes of the resulting string\ninto an integer.)\n\nSet the state of the encoder to state. state must be an encoder state returned\nby `getstate()`.\n\nThe `IncrementalDecoder` class is used for decoding an input in multiple\nsteps. It defines the following methods which every incremental decoder must\ndefine in order to be compatible with the Python codec registry.\n\nConstructor for an `IncrementalDecoder` instance.\n\nAll incremental decoders must provide this constructor interface. They are\nfree to add additional keyword arguments, but only the ones defined here are\nused by the Python codec registry.\n\nThe `IncrementalDecoder` may implement different error handling schemes by\nproviding the errors keyword argument. See Error Handlers for possible values.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `IncrementalDecoder`\nobject.\n\nDecodes object (taking the current state of the decoder into account) and\nreturns the resulting decoded object. If this is the last call to `decode()`\nfinal must be true (the default is false). If final is true the decoder must\ndecode the input completely and must flush all buffers. If this isn\u2019t possible\n(e.g. because of incomplete byte sequences at the end of the input) it must\ninitiate error handling just like in the stateless case (which might raise an\nexception).\n\nReset the decoder to the initial state.\n\nReturn the current state of the decoder. This must be a tuple with two items,\nthe first must be the buffer containing the still undecoded input. The second\nmust be an integer and can be additional state info. (The implementation\nshould make sure that `0` is the most common additional state info.) If this\nadditional state info is `0` it must be possible to set the decoder to the\nstate which has no input buffered and `0` as the additional state info, so\nthat feeding the previously buffered input to the decoder returns it to the\nprevious state without producing any output. (Additional state info that is\nmore complicated than integers can be converted into an integer by\nmarshaling/pickling the info and encoding the bytes of the resulting string\ninto an integer.)\n\nSet the state of the decoder to state. state must be a decoder state returned\nby `getstate()`.\n\nThe `StreamWriter` and `StreamReader` classes provide generic working\ninterfaces which can be used to implement new encoding submodules very easily.\nSee `encodings.utf_8` for an example of how this is done.\n\nThe `StreamWriter` class is a subclass of `Codec` and defines the following\nmethods which every stream writer must define in order to be compatible with\nthe Python codec registry.\n\nConstructor for a `StreamWriter` instance.\n\nAll stream writers must provide this constructor interface. They are free to\nadd additional keyword arguments, but only the ones defined here are used by\nthe Python codec registry.\n\nThe stream argument must be a file-like object open for writing text or binary\ndata, as appropriate for the specific codec.\n\nThe `StreamWriter` may implement different error handling schemes by providing\nthe errors keyword argument. See Error Handlers for the standard error\nhandlers the underlying stream codec may support.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `StreamWriter` object.\n\nWrites the object\u2019s contents encoded to the stream.\n\nWrites the concatenated list of strings to the stream (possibly by reusing the\n`write()` method). The standard bytes-to-bytes codecs do not support this\nmethod.\n\nResets the codec buffers used for keeping internal state.\n\nCalling this method should ensure that the data on the output is put into a\nclean state that allows appending of new fresh data without having to rescan\nthe whole stream to recover state.\n\nIn addition to the above methods, the `StreamWriter` must also inherit all\nother methods and attributes from the underlying stream.\n\nThe `StreamReader` class is a subclass of `Codec` and defines the following\nmethods which every stream reader must define in order to be compatible with\nthe Python codec registry.\n\nConstructor for a `StreamReader` instance.\n\nAll stream readers must provide this constructor interface. They are free to\nadd additional keyword arguments, but only the ones defined here are used by\nthe Python codec registry.\n\nThe stream argument must be a file-like object open for reading text or binary\ndata, as appropriate for the specific codec.\n\nThe `StreamReader` may implement different error handling schemes by providing\nthe errors keyword argument. See Error Handlers for the standard error\nhandlers the underlying stream codec may support.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `StreamReader` object.\n\nThe set of allowed values for the errors argument can be extended with\n`register_error()`.\n\nDecodes data from the stream and returns the resulting object.\n\nThe chars argument indicates the number of decoded code points or bytes to\nreturn. The `read()` method will never return more data than requested, but it\nmight return less, if there is not enough available.\n\nThe size argument indicates the approximate maximum number of encoded bytes or\ncode points to read for decoding. The decoder can modify this setting as\nappropriate. The default value -1 indicates to read and decode as much as\npossible. This parameter is intended to prevent having to decode huge files in\none step.\n\nThe firstline flag indicates that it would be sufficient to only return the\nfirst line, if there are decoding errors on later lines.\n\nThe method should use a greedy read strategy meaning that it should read as\nmuch data as is allowed within the definition of the encoding and the given\nsize, e.g. if optional encoding endings or state markers are available on the\nstream, these should be read too.\n\nRead one line from the input stream and return the decoded data.\n\nsize, if given, is passed as size argument to the stream\u2019s `read()` method.\n\nIf keepends is false line-endings will be stripped from the lines returned.\n\nRead all lines available on the input stream and return them as a list of\nlines.\n\nLine-endings are implemented using the codec\u2019s `decode()` method and are\nincluded in the list entries if keepends is true.\n\nsizehint, if given, is passed as the size argument to the stream\u2019s `read()`\nmethod.\n\nResets the codec buffers used for keeping internal state.\n\nNote that no stream repositioning should take place. This method is primarily\nintended to be able to recover from decoding errors.\n\nIn addition to the above methods, the `StreamReader` must also inherit all\nother methods and attributes from the underlying stream.\n\nThe `StreamReaderWriter` is a convenience class that allows wrapping streams\nwhich work in both read and write modes.\n\nThe design is such that one can use the factory functions returned by the\n`lookup()` function to construct the instance.\n\nCreates a `StreamReaderWriter` instance. stream must be a file-like object.\nReader and Writer must be factory functions or classes providing the\n`StreamReader` and `StreamWriter` interface resp. Error handling is done in\nthe same way as defined for the stream readers and writers.\n\n`StreamReaderWriter` instances define the combined interfaces of\n`StreamReader` and `StreamWriter` classes. They inherit all other methods and\nattributes from the underlying stream.\n\nThe `StreamRecoder` translates data from one encoding to another, which is\nsometimes useful when dealing with different encoding environments.\n\nThe design is such that one can use the factory functions returned by the\n`lookup()` function to construct the instance.\n\nCreates a `StreamRecoder` instance which implements a two-way conversion:\nencode and decode work on the frontend \u2014 the data visible to code calling\n`read()` and `write()`, while Reader and Writer work on the backend \u2014 the data\nin stream.\n\nYou can use these objects to do transparent transcodings, e.g., from Latin-1\nto UTF-8 and back.\n\nThe stream argument must be a file-like object.\n\nThe encode and decode arguments must adhere to the `Codec` interface. Reader\nand Writer must be factory functions or classes providing objects of the\n`StreamReader` and `StreamWriter` interface respectively.\n\nError handling is done in the same way as defined for the stream readers and\nwriters.\n\n`StreamRecoder` instances define the combined interfaces of `StreamReader` and\n`StreamWriter` classes. They inherit all other methods and attributes from the\nunderlying stream.\n\nStrings are stored internally as sequences of code points in range\n`0x0`\u2013`0x10FFFF`. (See PEP 393 for more details about the implementation.)\nOnce a string object is used outside of CPU and memory, endianness and how\nthese arrays are stored as bytes become an issue. As with other codecs,\nserialising a string into a sequence of bytes is known as encoding, and\nrecreating the string from the sequence of bytes is known as decoding. There\nare a variety of different text serialisation codecs, which are collectivity\nreferred to as text encodings.\n\nThe simplest text encoding (called `'latin-1'` or `'iso-8859-1'`) maps the\ncode points 0\u2013255 to the bytes `0x0`\u2013`0xff`, which means that a string object\nthat contains code points above `U+00FF` can\u2019t be encoded with this codec.\nDoing so will raise a `UnicodeEncodeError` that looks like the following\n(although the details of the error message may differ): `UnicodeEncodeError:\n'latin-1' codec can't encode character '\\u1234' in position 3: ordinal not in\nrange(256)`.\n\nThere\u2019s another group of encodings (the so called charmap encodings) that\nchoose a different subset of all Unicode code points and how these code points\nare mapped to the bytes `0x0`\u2013`0xff`. To see how this is done simply open e.g.\n`encodings/cp1252.py` (which is an encoding that is used primarily on\nWindows). There\u2019s a string constant with 256 characters that shows you which\ncharacter is mapped to which byte value.\n\nAll of these encodings can only encode 256 of the 1114112 code points defined\nin Unicode. A simple and straightforward way that can store each Unicode code\npoint, is to store each code point as four consecutive bytes. There are two\npossibilities: store the bytes in big endian or in little endian order. These\ntwo encodings are called `UTF-32-BE` and `UTF-32-LE` respectively. Their\ndisadvantage is that if e.g. you use `UTF-32-BE` on a little endian machine\nyou will always have to swap bytes on encoding and decoding. `UTF-32` avoids\nthis problem: bytes will always be in natural endianness. When these bytes are\nread by a CPU with a different endianness, then bytes have to be swapped\nthough. To be able to detect the endianness of a `UTF-16` or `UTF-32` byte\nsequence, there\u2019s the so called BOM (\u201cByte Order Mark\u201d). This is the Unicode\ncharacter `U+FEFF`. This character can be prepended to every `UTF-16` or\n`UTF-32` byte sequence. The byte swapped version of this character (`0xFFFE`)\nis an illegal character that may not appear in a Unicode text. So when the\nfirst character in an `UTF-16` or `UTF-32` byte sequence appears to be a\n`U+FFFE` the bytes have to be swapped on decoding. Unfortunately the character\n`U+FEFF` had a second purpose as a `ZERO WIDTH NO-BREAK SPACE`: a character\nthat has no width and doesn\u2019t allow a word to be split. It can e.g. be used to\ngive hints to a ligature algorithm. With Unicode 4.0 using `U+FEFF` as a `ZERO\nWIDTH NO-BREAK SPACE` has been deprecated (with `U+2060` (`WORD JOINER`)\nassuming this role). Nevertheless Unicode software still must be able to\nhandle `U+FEFF` in both roles: as a BOM it\u2019s a device to determine the storage\nlayout of the encoded bytes, and vanishes once the byte sequence has been\ndecoded into a string; as a `ZERO WIDTH NO-BREAK SPACE` it\u2019s a normal\ncharacter that will be decoded like any other.\n\nThere\u2019s another encoding that is able to encoding the full range of Unicode\ncharacters: UTF-8. UTF-8 is an 8-bit encoding, which means there are no issues\nwith byte order in UTF-8. Each byte in a UTF-8 byte sequence consists of two\nparts: marker bits (the most significant bits) and payload bits. The marker\nbits are a sequence of zero to four `1` bits followed by a `0` bit. Unicode\ncharacters are encoded like this (with x being payload bits, which when\nconcatenated give the Unicode character):\n\nRange\n\nEncoding\n\n`U-00000000` \u2026 `U-0000007F`\n\n0xxxxxxx\n\n`U-00000080` \u2026 `U-000007FF`\n\n110xxxxx 10xxxxxx\n\n`U-00000800` \u2026 `U-0000FFFF`\n\n1110xxxx 10xxxxxx 10xxxxxx\n\n`U-00010000` \u2026 `U-0010FFFF`\n\n11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n\nThe least significant bit of the Unicode character is the rightmost x bit.\n\nAs UTF-8 is an 8-bit encoding no BOM is required and any `U+FEFF` character in\nthe decoded string (even if it\u2019s the first character) is treated as a `ZERO\nWIDTH NO-BREAK SPACE`.\n\nWithout external information it\u2019s impossible to reliably determine which\nencoding was used for encoding a string. Each charmap encoding can decode any\nrandom byte sequence. However that\u2019s not possible with UTF-8, as UTF-8 byte\nsequences have a structure that doesn\u2019t allow arbitrary byte sequences. To\nincrease the reliability with which a UTF-8 encoding can be detected,\nMicrosoft invented a variant of UTF-8 (that Python 2.5 calls `\"utf-8-sig\"`)\nfor its Notepad program: Before any of the Unicode characters is written to\nthe file, a UTF-8 encoded BOM (which looks like this as a byte sequence:\n`0xef`, `0xbb`, `0xbf`) is written. As it\u2019s rather improbable that any charmap\nencoded file starts with these byte values (which would e.g. map to\n\nin iso-8859-1), this increases the probability that a `utf-8-sig` encoding can\nbe correctly guessed from the byte sequence. So here the BOM is not used to be\nable to determine the byte order used for generating the byte sequence, but as\na signature that helps in guessing the encoding. On encoding the utf-8-sig\ncodec will write `0xef`, `0xbb`, `0xbf` as the first three bytes to the file.\nOn decoding `utf-8-sig` will skip those three bytes if they appear as the\nfirst three bytes in the file. In UTF-8, the use of the BOM is discouraged and\nshould generally be avoided.\n\nPython comes with a number of codecs built-in, either implemented as C\nfunctions or with dictionaries as mapping tables. The following table lists\nthe codecs by name, together with a few common aliases, and the languages for\nwhich the encoding is likely used. Neither the list of aliases nor the list of\nlanguages is meant to be exhaustive. Notice that spelling alternatives that\nonly differ in case or use a hyphen instead of an underscore are also valid\naliases; therefore, e.g. `'utf-8'` is a valid alias for the `'utf_8'` codec.\n\nCPython implementation detail: Some common encodings can bypass the codecs\nlookup machinery to improve performance. These optimization opportunities are\nonly recognized by CPython for a limited set of (case insensitive) aliases:\nutf-8, utf8, latin-1, latin1, iso-8859-1, iso8859-1, mbcs (Windows only),\nascii, us-ascii, utf-16, utf16, utf-32, utf32, and the same using underscores\ninstead of dashes. Using alternative aliases for these encodings may result in\nslower execution.\n\nChanged in version 3.6: Optimization opportunity recognized for us-ascii.\n\nMany of the character sets support the same languages. They vary in individual\ncharacters (e.g. whether the EURO SIGN is supported or not), and in the\nassignment of characters to code positions. For the European languages in\nparticular, the following variants typically exist:\n\nCodec\n\nAliases\n\nLanguages\n\nascii\n\n646, us-ascii\n\nEnglish\n\nbig5\n\nbig5-tw, csbig5\n\nTraditional Chinese\n\nbig5hkscs\n\nbig5-hkscs, hkscs\n\nTraditional Chinese\n\ncp037\n\nIBM037, IBM039\n\nEnglish\n\ncp273\n\n273, IBM273, csIBM273\n\nGerman\n\nNew in version 3.4.\n\ncp424\n\nEBCDIC-CP-HE, IBM424\n\nHebrew\n\ncp437\n\n437, IBM437\n\nEnglish\n\ncp500\n\nEBCDIC-CP-BE, EBCDIC-CP-CH, IBM500\n\nWestern Europe\n\ncp720\n\nArabic\n\ncp737\n\nGreek\n\ncp775\n\nIBM775\n\nBaltic languages\n\ncp850\n\n850, IBM850\n\nWestern Europe\n\ncp852\n\n852, IBM852\n\nCentral and Eastern Europe\n\ncp855\n\n855, IBM855\n\nBulgarian, Byelorussian, Macedonian, Russian, Serbian\n\ncp856\n\nHebrew\n\ncp857\n\n857, IBM857\n\nTurkish\n\ncp858\n\n858, IBM858\n\nWestern Europe\n\ncp860\n\n860, IBM860\n\nPortuguese\n\ncp861\n\n861, CP-IS, IBM861\n\nIcelandic\n\ncp862\n\n862, IBM862\n\nHebrew\n\ncp863\n\n863, IBM863\n\nCanadian\n\ncp864\n\nIBM864\n\nArabic\n\ncp865\n\n865, IBM865\n\nDanish, Norwegian\n\ncp866\n\n866, IBM866\n\nRussian\n\ncp869\n\n869, CP-GR, IBM869\n\nGreek\n\ncp874\n\nThai\n\ncp875\n\nGreek\n\ncp932\n\n932, ms932, mskanji, ms-kanji\n\nJapanese\n\ncp949\n\n949, ms949, uhc\n\nKorean\n\ncp950\n\n950, ms950\n\nTraditional Chinese\n\ncp1006\n\nUrdu\n\ncp1026\n\nibm1026\n\nTurkish\n\ncp1125\n\n1125, ibm1125, cp866u, ruscii\n\nUkrainian\n\nNew in version 3.4.\n\ncp1140\n\nibm1140\n\nWestern Europe\n\ncp1250\n\nwindows-1250\n\nCentral and Eastern Europe\n\ncp1251\n\nwindows-1251\n\nBulgarian, Byelorussian, Macedonian, Russian, Serbian\n\ncp1252\n\nwindows-1252\n\nWestern Europe\n\ncp1253\n\nwindows-1253\n\nGreek\n\ncp1254\n\nwindows-1254\n\nTurkish\n\ncp1255\n\nwindows-1255\n\nHebrew\n\ncp1256\n\nwindows-1256\n\nArabic\n\ncp1257\n\nwindows-1257\n\nBaltic languages\n\ncp1258\n\nwindows-1258\n\nVietnamese\n\neuc_jp\n\neucjp, ujis, u-jis\n\nJapanese\n\neuc_jis_2004\n\njisx0213, eucjis2004\n\nJapanese\n\neuc_jisx0213\n\neucjisx0213\n\nJapanese\n\neuc_kr\n\neuckr, korean, ksc5601, ks_c-5601, ks_c-5601-1987, ksx1001, ks_x-1001\n\nKorean\n\ngb2312\n\nchinese, csiso58gb231280, euc-cn, euccn, eucgb2312-cn, gb2312-1980, gb2312-80,\niso-ir-58\n\nSimplified Chinese\n\ngbk\n\n936, cp936, ms936\n\nUnified Chinese\n\ngb18030\n\ngb18030-2000\n\nUnified Chinese\n\nhz\n\nhzgb, hz-gb, hz-gb-2312\n\nSimplified Chinese\n\niso2022_jp\n\ncsiso2022jp, iso2022jp, iso-2022-jp\n\nJapanese\n\niso2022_jp_1\n\niso2022jp-1, iso-2022-jp-1\n\nJapanese\n\niso2022_jp_2\n\niso2022jp-2, iso-2022-jp-2\n\nJapanese, Korean, Simplified Chinese, Western Europe, Greek\n\niso2022_jp_2004\n\niso2022jp-2004, iso-2022-jp-2004\n\nJapanese\n\niso2022_jp_3\n\niso2022jp-3, iso-2022-jp-3\n\nJapanese\n\niso2022_jp_ext\n\niso2022jp-ext, iso-2022-jp-ext\n\nJapanese\n\niso2022_kr\n\ncsiso2022kr, iso2022kr, iso-2022-kr\n\nKorean\n\nlatin_1\n\niso-8859-1, iso8859-1, 8859, cp819, latin, latin1, L1\n\nWestern Europe\n\niso8859_2\n\niso-8859-2, latin2, L2\n\nCentral and Eastern Europe\n\niso8859_3\n\niso-8859-3, latin3, L3\n\nEsperanto, Maltese\n\niso8859_4\n\niso-8859-4, latin4, L4\n\nBaltic languages\n\niso8859_5\n\niso-8859-5, cyrillic\n\nBulgarian, Byelorussian, Macedonian, Russian, Serbian\n\niso8859_6\n\niso-8859-6, arabic\n\nArabic\n\niso8859_7\n\niso-8859-7, greek, greek8\n\nGreek\n\niso8859_8\n\niso-8859-8, hebrew\n\nHebrew\n\niso8859_9\n\niso-8859-9, latin5, L5\n\nTurkish\n\niso8859_10\n\niso-8859-10, latin6, L6\n\nNordic languages\n\niso8859_11\n\niso-8859-11, thai\n\nThai languages\n\niso8859_13\n\niso-8859-13, latin7, L7\n\nBaltic languages\n\niso8859_14\n\niso-8859-14, latin8, L8\n\nCeltic languages\n\niso8859_15\n\niso-8859-15, latin9, L9\n\nWestern Europe\n\niso8859_16\n\niso-8859-16, latin10, L10\n\nSouth-Eastern Europe\n\njohab\n\ncp1361, ms1361\n\nKorean\n\nkoi8_r\n\nRussian\n\nkoi8_t\n\nTajik\n\nNew in version 3.5.\n\nkoi8_u\n\nUkrainian\n\nkz1048\n\nkz_1048, strk1048_2002, rk1048\n\nKazakh\n\nNew in version 3.5.\n\nmac_cyrillic\n\nmaccyrillic\n\nBulgarian, Byelorussian, Macedonian, Russian, Serbian\n\nmac_greek\n\nmacgreek\n\nGreek\n\nmac_iceland\n\nmaciceland\n\nIcelandic\n\nmac_latin2\n\nmaclatin2, maccentraleurope, mac_centeuro\n\nCentral and Eastern Europe\n\nmac_roman\n\nmacroman, macintosh\n\nWestern Europe\n\nmac_turkish\n\nmacturkish\n\nTurkish\n\nptcp154\n\ncsptcp154, pt154, cp154, cyrillic-asian\n\nKazakh\n\nshift_jis\n\ncsshiftjis, shiftjis, sjis, s_jis\n\nJapanese\n\nshift_jis_2004\n\nshiftjis2004, sjis_2004, sjis2004\n\nJapanese\n\nshift_jisx0213\n\nshiftjisx0213, sjisx0213, s_jisx0213\n\nJapanese\n\nutf_32\n\nU32, utf32\n\nall languages\n\nutf_32_be\n\nUTF-32BE\n\nall languages\n\nutf_32_le\n\nUTF-32LE\n\nall languages\n\nutf_16\n\nU16, utf16\n\nall languages\n\nutf_16_be\n\nUTF-16BE\n\nall languages\n\nutf_16_le\n\nUTF-16LE\n\nall languages\n\nutf_7\n\nU7, unicode-1-1-utf-7\n\nall languages\n\nutf_8\n\nU8, UTF, utf8, cp65001\n\nall languages\n\nutf_8_sig\n\nall languages\n\nChanged in version 3.4: The utf-16* and utf-32* encoders no longer allow\nsurrogate code points (`U+D800`\u2013`U+DFFF`) to be encoded. The utf-32* decoders\nno longer decode byte sequences that correspond to surrogate code points.\n\nChanged in version 3.8: `cp65001` is now an alias to `utf_8`.\n\nA number of predefined codecs are specific to Python, so their codec names\nhave no meaning outside Python. These are listed in the tables below based on\nthe expected input and output types (note that while text encodings are the\nmost common use case for codecs, the underlying codec infrastructure supports\narbitrary data transforms rather than just text encodings). For asymmetric\ncodecs, the stated meaning describes the encoding direction.\n\nThe following codecs provide `str` to `bytes` encoding and bytes-like object\nto `str` decoding, similar to the Unicode text encodings.\n\nCodec\n\nAliases\n\nMeaning\n\nidna\n\nImplement RFC 3490, see also `encodings.idna`. Only `errors='strict'` is\nsupported.\n\nmbcs\n\nansi, dbcs\n\nWindows only: Encode the operand according to the ANSI codepage (CP_ACP).\n\noem\n\nWindows only: Encode the operand according to the OEM codepage (CP_OEMCP).\n\nNew in version 3.6.\n\npalmos\n\nEncoding of PalmOS 3.5.\n\npunycode\n\nImplement RFC 3492. Stateful codecs are not supported.\n\nraw_unicode_escape\n\nLatin-1 encoding with `\\uXXXX` and `\\UXXXXXXXX` for other code points.\nExisting backslashes are not escaped in any way. It is used in the Python\npickle protocol.\n\nundefined\n\nRaise an exception for all conversions, even empty strings. The error handler\nis ignored.\n\nunicode_escape\n\nEncoding suitable as the contents of a Unicode literal in ASCII-encoded Python\nsource code, except that quotes are not escaped. Decode from Latin-1 source\ncode. Beware that Python source code actually uses UTF-8 by default.\n\nChanged in version 3.8: \u201cunicode_internal\u201d codec is removed.\n\nThe following codecs provide binary transforms: bytes-like object to `bytes`\nmappings. They are not supported by `bytes.decode()` (which only produces\n`str` output).\n\nCodec\n\nAliases\n\nMeaning\n\nEncoder / decoder\n\nbase64_codec 1\n\nbase64, base_64\n\nConvert the operand to multiline MIME base64 (the result always includes a\ntrailing `'\\n'`).\n\nChanged in version 3.4: accepts any bytes-like object as input for encoding\nand decoding\n\n`base64.encodebytes()` / `base64.decodebytes()`\n\nbz2_codec\n\nbz2\n\nCompress the operand using bz2.\n\n`bz2.compress()` / `bz2.decompress()`\n\nhex_codec\n\nhex\n\nConvert the operand to hexadecimal representation, with two digits per byte.\n\n`binascii.b2a_hex()` / `binascii.a2b_hex()`\n\nquopri_codec\n\nquopri, quotedprintable, quoted_printable\n\nConvert the operand to MIME quoted printable.\n\n`quopri.encode()` with `quotetabs=True` / `quopri.decode()`\n\nuu_codec\n\nuu\n\nConvert the operand using uuencode.\n\n`uu.encode()` / `uu.decode()`\n\nzlib_codec\n\nzip, zlib\n\nCompress the operand using gzip.\n\n`zlib.compress()` / `zlib.decompress()`\n\nIn addition to bytes-like objects, `'base64_codec'` also accepts ASCII-only\ninstances of `str` for decoding\n\nNew in version 3.2: Restoration of the binary transforms.\n\nChanged in version 3.4: Restoration of the aliases for the binary transforms.\n\nThe following codec provides a text transform: a `str` to `str` mapping. It is\nnot supported by `str.encode()` (which only produces `bytes` output).\n\nCodec\n\nAliases\n\nMeaning\n\nrot_13\n\nrot13\n\nReturn the Caesar-cypher encryption of the operand.\n\nNew in version 3.2: Restoration of the `rot_13` text transform.\n\nChanged in version 3.4: Restoration of the `rot13` alias.\n\nThis module implements RFC 3490 (Internationalized Domain Names in\nApplications) and RFC 3492 (Nameprep: A Stringprep Profile for\nInternationalized Domain Names (IDN)). It builds upon the `punycode` encoding\nand `stringprep`.\n\nIf you need the IDNA 2008 standard from RFC 5891 and RFC 5895, use the third-\nparty `idna module <https://pypi.org/project/idna/>_`.\n\nThese RFCs together define a protocol to support non-ASCII characters in\ndomain names. A domain name containing non-ASCII characters (such as\n`www.Alliancefran\u00e7aise.nu`) is converted into an ASCII-compatible encoding\n(ACE, such as `www.xn--alliancefranaise-npb.nu`). The ACE form of the domain\nname is then used in all places where arbitrary characters are not allowed by\nthe protocol, such as DNS queries, HTTP Host fields, and so on. This\nconversion is carried out in the application; if possible invisible to the\nuser: The application should transparently convert Unicode domain labels to\nIDNA on the wire, and convert back ACE labels to Unicode before presenting\nthem to the user.\n\nPython supports this conversion in several ways: the `idna` codec performs\nconversion between Unicode and ACE, separating an input string into labels\nbased on the separator characters defined in section 3.1 of RFC 3490 and\nconverting each label to ACE as required, and conversely separating an input\nbyte string into labels based on the `.` separator and converting any ACE\nlabels found into unicode. Furthermore, the `socket` module transparently\nconverts Unicode host names to ACE, so that applications need not be concerned\nabout converting host names themselves when they pass them to the socket\nmodule. On top of that, modules that have host names as function parameters,\nsuch as `http.client` and `ftplib`, accept Unicode host names (`http.client`\nthen also transparently sends an IDNA hostname in the Host field if it sends\nthat field at all).\n\nWhen receiving host names from the wire (such as in reverse name lookup), no\nautomatic conversion to Unicode is performed: applications wishing to present\nsuch host names to the user should decode them to Unicode.\n\nThe module `encodings.idna` also implements the nameprep procedure, which\nperforms certain normalizations on host names, to achieve case-insensitivity\nof international domain names, and to unify similar characters. The nameprep\nfunctions can be used directly if desired.\n\nReturn the nameprepped version of label. The implementation currently assumes\nquery strings, so `AllowUnassigned` is true.\n\nConvert a label to ASCII, as specified in RFC 3490. `UseSTD3ASCIIRules` is\nassumed to be false.\n\nConvert a label to Unicode, as specified in RFC 3490.\n\nThis module implements the ANSI codepage (CP_ACP).\n\nAvailability: Windows only.\n\nChanged in version 3.3: Support any error handler.\n\nChanged in version 3.2: Before 3.2, the errors argument was ignored;\n`'replace'` was always used to encode, and `'ignore'` to decode.\n\nThis module implements a variant of the UTF-8 codec. On encoding, a UTF-8\nencoded BOM will be prepended to the UTF-8 encoded bytes. For the stateful\nencoder this is only done once (on the first write to the byte stream). On\ndecoding, an optional UTF-8 encoded BOM at the start of the data will be\nskipped.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.backslashreplace_errors()", "path": "library/codecs#codecs.backslashreplace_errors", "type": "Binary Data", "text": "\nImplements the `'backslashreplace'` error handling (for text encodings only):\nmalformed data is replaced by a backslashed escape sequence.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM", "path": "library/codecs#codecs.BOM", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_BE", "path": "library/codecs#codecs.BOM_BE", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_LE", "path": "library/codecs#codecs.BOM_LE", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_UTF16", "path": "library/codecs#codecs.BOM_UTF16", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_UTF16_BE", "path": "library/codecs#codecs.BOM_UTF16_BE", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_UTF16_LE", "path": "library/codecs#codecs.BOM_UTF16_LE", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_UTF32", "path": "library/codecs#codecs.BOM_UTF32", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_UTF32_BE", "path": "library/codecs#codecs.BOM_UTF32_BE", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_UTF32_LE", "path": "library/codecs#codecs.BOM_UTF32_LE", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.BOM_UTF8", "path": "library/codecs#codecs.BOM_UTF8", "type": "Binary Data", "text": "\nThese constants define various byte sequences, being Unicode byte order marks\n(BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams\nto indicate the byte order used, and in UTF-8 as a Unicode signature.\n`BOM_UTF16` is either `BOM_UTF16_BE` or `BOM_UTF16_LE` depending on the\nplatform\u2019s native byte order, `BOM` is an alias for `BOM_UTF16`, `BOM_LE` for\n`BOM_UTF16_LE` and `BOM_BE` for `BOM_UTF16_BE`. The others represent the BOM\nin UTF-8 and UTF-32 encodings.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.Codec.decode()", "path": "library/codecs#codecs.Codec.decode", "type": "Binary Data", "text": "\nDecodes the object input and returns a tuple (output object, length consumed).\nFor instance, for a text encoding, decoding converts a bytes object encoded\nusing a particular character set encoding to a string object.\n\nFor text encodings and bytes-to-bytes codecs, input must be a bytes object or\none which provides the read-only buffer interface \u2013 for example, buffer\nobjects and memory mapped files.\n\nThe errors argument defines the error handling to apply. It defaults to\n`'strict'` handling.\n\nThe method may not store state in the `Codec` instance. Use `StreamReader` for\ncodecs which have to keep state in order to make decoding efficient.\n\nThe decoder must be able to handle zero length input and return an empty\nobject of the output object type in this situation.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.Codec.encode()", "path": "library/codecs#codecs.Codec.encode", "type": "Binary Data", "text": "\nEncodes the object input and returns a tuple (output object, length consumed).\nFor instance, text encoding converts a string object to a bytes object using a\nparticular character set encoding (e.g., `cp1252` or `iso-8859-1`).\n\nThe errors argument defines the error handling to apply. It defaults to\n`'strict'` handling.\n\nThe method may not store state in the `Codec` instance. Use `StreamWriter` for\ncodecs which have to keep state in order to make encoding efficient.\n\nThe encoder must be able to handle zero length input and return an empty\nobject of the output object type in this situation.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo", "path": "library/codecs#codecs.CodecInfo", "type": "Binary Data", "text": "\nCodec details when looking up the codec registry. The constructor arguments\nare stored in attributes of the same name:\n\nThe name of the encoding.\n\nThe stateless encoding and decoding functions. These must be functions or\nmethods which have the same interface as the `encode()` and `decode()` methods\nof Codec instances (see Codec Interface). The functions or methods are\nexpected to work in a stateless mode.\n\nIncremental encoder and decoder classes or factory functions. These have to\nprovide the interface defined by the base classes `IncrementalEncoder` and\n`IncrementalDecoder`, respectively. Incremental codecs can maintain state.\n\nStream writer and reader classes or factory functions. These have to provide\nthe interface defined by the base classes `StreamWriter` and `StreamReader`,\nrespectively. Stream codecs can maintain state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo.decode", "path": "library/codecs#codecs.CodecInfo.decode", "type": "Binary Data", "text": "\nThe stateless encoding and decoding functions. These must be functions or\nmethods which have the same interface as the `encode()` and `decode()` methods\nof Codec instances (see Codec Interface). The functions or methods are\nexpected to work in a stateless mode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo.encode", "path": "library/codecs#codecs.CodecInfo.encode", "type": "Binary Data", "text": "\nThe stateless encoding and decoding functions. These must be functions or\nmethods which have the same interface as the `encode()` and `decode()` methods\nof Codec instances (see Codec Interface). The functions or methods are\nexpected to work in a stateless mode.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo.incrementaldecoder", "path": "library/codecs#codecs.CodecInfo.incrementaldecoder", "type": "Binary Data", "text": "\nIncremental encoder and decoder classes or factory functions. These have to\nprovide the interface defined by the base classes `IncrementalEncoder` and\n`IncrementalDecoder`, respectively. Incremental codecs can maintain state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo.incrementalencoder", "path": "library/codecs#codecs.CodecInfo.incrementalencoder", "type": "Binary Data", "text": "\nIncremental encoder and decoder classes or factory functions. These have to\nprovide the interface defined by the base classes `IncrementalEncoder` and\n`IncrementalDecoder`, respectively. Incremental codecs can maintain state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo.name", "path": "library/codecs#codecs.CodecInfo.name", "type": "Binary Data", "text": "\nThe name of the encoding.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo.streamreader", "path": "library/codecs#codecs.CodecInfo.streamreader", "type": "Binary Data", "text": "\nStream writer and reader classes or factory functions. These have to provide\nthe interface defined by the base classes `StreamWriter` and `StreamReader`,\nrespectively. Stream codecs can maintain state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.CodecInfo.streamwriter", "path": "library/codecs#codecs.CodecInfo.streamwriter", "type": "Binary Data", "text": "\nStream writer and reader classes or factory functions. These have to provide\nthe interface defined by the base classes `StreamWriter` and `StreamReader`,\nrespectively. Stream codecs can maintain state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.decode()", "path": "library/codecs#codecs.decode", "type": "Binary Data", "text": "\nDecodes obj using the codec registered for encoding.\n\nErrors may be given to set the desired error handling scheme. The default\nerror handler is `'strict'` meaning that decoding errors raise `ValueError`\n(or a more codec specific subclass, such as `UnicodeDecodeError`). Refer to\nCodec Base Classes for more information on codec error handling.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.encode()", "path": "library/codecs#codecs.encode", "type": "Binary Data", "text": "\nEncodes obj using the codec registered for encoding.\n\nErrors may be given to set the desired error handling scheme. The default\nerror handler is `'strict'` meaning that encoding errors raise `ValueError`\n(or a more codec specific subclass, such as `UnicodeEncodeError`). Refer to\nCodec Base Classes for more information on codec error handling.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.EncodedFile()", "path": "library/codecs#codecs.EncodedFile", "type": "Binary Data", "text": "\nReturn a `StreamRecoder` instance, a wrapped version of file which provides\ntransparent transcoding. The original file is closed when the wrapped version\nis closed.\n\nData written to the wrapped file is decoded according to the given\ndata_encoding and then written to the original file as bytes using\nfile_encoding. Bytes read from the original file are decoded according to\nfile_encoding, and the result is encoded using data_encoding.\n\nIf file_encoding is not given, it defaults to data_encoding.\n\nerrors may be given to define the error handling. It defaults to `'strict'`,\nwhich causes `ValueError` to be raised in case an encoding error occurs.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.getdecoder()", "path": "library/codecs#codecs.getdecoder", "type": "Binary Data", "text": "\nLook up the codec for the given encoding and return its decoder function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.getencoder()", "path": "library/codecs#codecs.getencoder", "type": "Binary Data", "text": "\nLook up the codec for the given encoding and return its encoder function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.getincrementaldecoder()", "path": "library/codecs#codecs.getincrementaldecoder", "type": "Binary Data", "text": "\nLook up the codec for the given encoding and return its incremental decoder\nclass or factory function.\n\nRaises a `LookupError` in case the encoding cannot be found or the codec\ndoesn\u2019t support an incremental decoder.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.getincrementalencoder()", "path": "library/codecs#codecs.getincrementalencoder", "type": "Binary Data", "text": "\nLook up the codec for the given encoding and return its incremental encoder\nclass or factory function.\n\nRaises a `LookupError` in case the encoding cannot be found or the codec\ndoesn\u2019t support an incremental encoder.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.getreader()", "path": "library/codecs#codecs.getreader", "type": "Binary Data", "text": "\nLook up the codec for the given encoding and return its `StreamReader` class\nor factory function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.getwriter()", "path": "library/codecs#codecs.getwriter", "type": "Binary Data", "text": "\nLook up the codec for the given encoding and return its `StreamWriter` class\nor factory function.\n\nRaises a `LookupError` in case the encoding cannot be found.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.ignore_errors()", "path": "library/codecs#codecs.ignore_errors", "type": "Binary Data", "text": "\nImplements the `'ignore'` error handling: malformed data is ignored and\nencoding or decoding is continued without further notice.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalDecoder", "path": "library/codecs#codecs.IncrementalDecoder", "type": "Binary Data", "text": "\nConstructor for an `IncrementalDecoder` instance.\n\nAll incremental decoders must provide this constructor interface. They are\nfree to add additional keyword arguments, but only the ones defined here are\nused by the Python codec registry.\n\nThe `IncrementalDecoder` may implement different error handling schemes by\nproviding the errors keyword argument. See Error Handlers for possible values.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `IncrementalDecoder`\nobject.\n\nDecodes object (taking the current state of the decoder into account) and\nreturns the resulting decoded object. If this is the last call to `decode()`\nfinal must be true (the default is false). If final is true the decoder must\ndecode the input completely and must flush all buffers. If this isn\u2019t possible\n(e.g. because of incomplete byte sequences at the end of the input) it must\ninitiate error handling just like in the stateless case (which might raise an\nexception).\n\nReset the decoder to the initial state.\n\nReturn the current state of the decoder. This must be a tuple with two items,\nthe first must be the buffer containing the still undecoded input. The second\nmust be an integer and can be additional state info. (The implementation\nshould make sure that `0` is the most common additional state info.) If this\nadditional state info is `0` it must be possible to set the decoder to the\nstate which has no input buffered and `0` as the additional state info, so\nthat feeding the previously buffered input to the decoder returns it to the\nprevious state without producing any output. (Additional state info that is\nmore complicated than integers can be converted into an integer by\nmarshaling/pickling the info and encoding the bytes of the resulting string\ninto an integer.)\n\nSet the state of the decoder to state. state must be a decoder state returned\nby `getstate()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalDecoder.decode()", "path": "library/codecs#codecs.IncrementalDecoder.decode", "type": "Binary Data", "text": "\nDecodes object (taking the current state of the decoder into account) and\nreturns the resulting decoded object. If this is the last call to `decode()`\nfinal must be true (the default is false). If final is true the decoder must\ndecode the input completely and must flush all buffers. If this isn\u2019t possible\n(e.g. because of incomplete byte sequences at the end of the input) it must\ninitiate error handling just like in the stateless case (which might raise an\nexception).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalDecoder.getstate()", "path": "library/codecs#codecs.IncrementalDecoder.getstate", "type": "Binary Data", "text": "\nReturn the current state of the decoder. This must be a tuple with two items,\nthe first must be the buffer containing the still undecoded input. The second\nmust be an integer and can be additional state info. (The implementation\nshould make sure that `0` is the most common additional state info.) If this\nadditional state info is `0` it must be possible to set the decoder to the\nstate which has no input buffered and `0` as the additional state info, so\nthat feeding the previously buffered input to the decoder returns it to the\nprevious state without producing any output. (Additional state info that is\nmore complicated than integers can be converted into an integer by\nmarshaling/pickling the info and encoding the bytes of the resulting string\ninto an integer.)\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalDecoder.reset()", "path": "library/codecs#codecs.IncrementalDecoder.reset", "type": "Binary Data", "text": "\nReset the decoder to the initial state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalDecoder.setstate()", "path": "library/codecs#codecs.IncrementalDecoder.setstate", "type": "Binary Data", "text": "\nSet the state of the decoder to state. state must be a decoder state returned\nby `getstate()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalEncoder", "path": "library/codecs#codecs.IncrementalEncoder", "type": "Binary Data", "text": "\nConstructor for an `IncrementalEncoder` instance.\n\nAll incremental encoders must provide this constructor interface. They are\nfree to add additional keyword arguments, but only the ones defined here are\nused by the Python codec registry.\n\nThe `IncrementalEncoder` may implement different error handling schemes by\nproviding the errors keyword argument. See Error Handlers for possible values.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `IncrementalEncoder`\nobject.\n\nEncodes object (taking the current state of the encoder into account) and\nreturns the resulting encoded object. If this is the last call to `encode()`\nfinal must be true (the default is false).\n\nReset the encoder to the initial state. The output is discarded: call\n`.encode(object, final=True)`, passing an empty byte or text string if\nnecessary, to reset the encoder and to get the output.\n\nReturn the current state of the encoder which must be an integer. The\nimplementation should make sure that `0` is the most common state. (States\nthat are more complicated than integers can be converted into an integer by\nmarshaling/pickling the state and encoding the bytes of the resulting string\ninto an integer.)\n\nSet the state of the encoder to state. state must be an encoder state returned\nby `getstate()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalEncoder.encode()", "path": "library/codecs#codecs.IncrementalEncoder.encode", "type": "Binary Data", "text": "\nEncodes object (taking the current state of the encoder into account) and\nreturns the resulting encoded object. If this is the last call to `encode()`\nfinal must be true (the default is false).\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalEncoder.getstate()", "path": "library/codecs#codecs.IncrementalEncoder.getstate", "type": "Binary Data", "text": "\nReturn the current state of the encoder which must be an integer. The\nimplementation should make sure that `0` is the most common state. (States\nthat are more complicated than integers can be converted into an integer by\nmarshaling/pickling the state and encoding the bytes of the resulting string\ninto an integer.)\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalEncoder.reset()", "path": "library/codecs#codecs.IncrementalEncoder.reset", "type": "Binary Data", "text": "\nReset the encoder to the initial state. The output is discarded: call\n`.encode(object, final=True)`, passing an empty byte or text string if\nnecessary, to reset the encoder and to get the output.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.IncrementalEncoder.setstate()", "path": "library/codecs#codecs.IncrementalEncoder.setstate", "type": "Binary Data", "text": "\nSet the state of the encoder to state. state must be an encoder state returned\nby `getstate()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.iterdecode()", "path": "library/codecs#codecs.iterdecode", "type": "Binary Data", "text": "\nUses an incremental decoder to iteratively decode the input provided by\niterator. This function is a generator. The errors argument (as well as any\nother keyword argument) is passed through to the incremental decoder.\n\nThis function requires that the codec accept `bytes` objects to decode.\nTherefore it does not support text-to-text encoders such as `rot_13`, although\n`rot_13` may be used equivalently with `iterencode()`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.iterencode()", "path": "library/codecs#codecs.iterencode", "type": "Binary Data", "text": "\nUses an incremental encoder to iteratively encode the input provided by\niterator. This function is a generator. The errors argument (as well as any\nother keyword argument) is passed through to the incremental encoder.\n\nThis function requires that the codec accept text `str` objects to encode.\nTherefore it does not support bytes-to-bytes encoders such as `base64_codec`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.lookup()", "path": "library/codecs#codecs.lookup", "type": "Binary Data", "text": "\nLooks up the codec info in the Python codec registry and returns a `CodecInfo`\nobject as defined below.\n\nEncodings are first looked up in the registry\u2019s cache. If not found, the list\nof registered search functions is scanned. If no `CodecInfo` object is found,\na `LookupError` is raised. Otherwise, the `CodecInfo` object is stored in the\ncache and returned to the caller.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.lookup_error()", "path": "library/codecs#codecs.lookup_error", "type": "Binary Data", "text": "\nReturn the error handler previously registered under the name name.\n\nRaises a `LookupError` in case the handler cannot be found.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.namereplace_errors()", "path": "library/codecs#codecs.namereplace_errors", "type": "Binary Data", "text": "\nImplements the `'namereplace'` error handling (for encoding with text\nencodings only): the unencodable character is replaced by a `\\N{...}` escape\nsequence.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.open()", "path": "library/codecs#codecs.open", "type": "Binary Data", "text": "\nOpen an encoded file using the given mode and return an instance of\n`StreamReaderWriter`, providing transparent encoding/decoding. The default\nfile mode is `'r'`, meaning to open the file in read mode.\n\nNote\n\nUnderlying encoded files are always opened in binary mode. No automatic\nconversion of `'\\n'` is done on reading and writing. The mode argument may be\nany binary mode acceptable to the built-in `open()` function; the `'b'` is\nautomatically added.\n\nencoding specifies the encoding which is to be used for the file. Any encoding\nthat encodes to and decodes from bytes is allowed, and the data types\nsupported by the file methods depend on the codec used.\n\nerrors may be given to define the error handling. It defaults to `'strict'`\nwhich causes a `ValueError` to be raised in case an encoding error occurs.\n\nbuffering has the same meaning as for the built-in `open()` function. It\ndefaults to -1 which means that the default buffer size will be used.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.register()", "path": "library/codecs#codecs.register", "type": "Binary Data", "text": "\nRegister a codec search function. Search functions are expected to take one\nargument, being the encoding name in all lower case letters with hyphens and\nspaces converted to underscores, and return a `CodecInfo` object. In case a\nsearch function cannot find a given encoding, it should return `None`.\n\nChanged in version 3.9: Hyphens and spaces are converted to underscore.\n\nNote\n\nSearch function registration is not currently reversible, which may cause\nproblems in some cases, such as unit testing or module reloading.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.register_error()", "path": "library/codecs#codecs.register_error", "type": "Binary Data", "text": "\nRegister the error handling function error_handler under the name name. The\nerror_handler argument will be called during encoding and decoding in case of\nan error, when name is specified as the errors parameter.\n\nFor encoding, error_handler will be called with a `UnicodeEncodeError`\ninstance, which contains information about the location of the error. The\nerror handler must either raise this or a different exception, or return a\ntuple with a replacement for the unencodable part of the input and a position\nwhere encoding should continue. The replacement may be either `str` or\n`bytes`. If the replacement is bytes, the encoder will simply copy them into\nthe output buffer. If the replacement is a string, the encoder will encode the\nreplacement. Encoding continues on original input at the specified position.\nNegative position values will be treated as being relative to the end of the\ninput string. If the resulting position is out of bound an `IndexError` will\nbe raised.\n\nDecoding and translating works similarly, except `UnicodeDecodeError` or\n`UnicodeTranslateError` will be passed to the handler and that the replacement\nfrom the error handler will be put into the output directly.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.replace_errors()", "path": "library/codecs#codecs.replace_errors", "type": "Binary Data", "text": "\nImplements the `'replace'` error handling (for text encodings only):\nsubstitutes `'?'` for encoding errors (to be encoded by the codec), and\n`'\\ufffd'` (the Unicode replacement character) for decoding errors.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamReader", "path": "library/codecs#codecs.StreamReader", "type": "Binary Data", "text": "\nConstructor for a `StreamReader` instance.\n\nAll stream readers must provide this constructor interface. They are free to\nadd additional keyword arguments, but only the ones defined here are used by\nthe Python codec registry.\n\nThe stream argument must be a file-like object open for reading text or binary\ndata, as appropriate for the specific codec.\n\nThe `StreamReader` may implement different error handling schemes by providing\nthe errors keyword argument. See Error Handlers for the standard error\nhandlers the underlying stream codec may support.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `StreamReader` object.\n\nThe set of allowed values for the errors argument can be extended with\n`register_error()`.\n\nDecodes data from the stream and returns the resulting object.\n\nThe chars argument indicates the number of decoded code points or bytes to\nreturn. The `read()` method will never return more data than requested, but it\nmight return less, if there is not enough available.\n\nThe size argument indicates the approximate maximum number of encoded bytes or\ncode points to read for decoding. The decoder can modify this setting as\nappropriate. The default value -1 indicates to read and decode as much as\npossible. This parameter is intended to prevent having to decode huge files in\none step.\n\nThe firstline flag indicates that it would be sufficient to only return the\nfirst line, if there are decoding errors on later lines.\n\nThe method should use a greedy read strategy meaning that it should read as\nmuch data as is allowed within the definition of the encoding and the given\nsize, e.g. if optional encoding endings or state markers are available on the\nstream, these should be read too.\n\nRead one line from the input stream and return the decoded data.\n\nsize, if given, is passed as size argument to the stream\u2019s `read()` method.\n\nIf keepends is false line-endings will be stripped from the lines returned.\n\nRead all lines available on the input stream and return them as a list of\nlines.\n\nLine-endings are implemented using the codec\u2019s `decode()` method and are\nincluded in the list entries if keepends is true.\n\nsizehint, if given, is passed as the size argument to the stream\u2019s `read()`\nmethod.\n\nResets the codec buffers used for keeping internal state.\n\nNote that no stream repositioning should take place. This method is primarily\nintended to be able to recover from decoding errors.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamReader.read()", "path": "library/codecs#codecs.StreamReader.read", "type": "Binary Data", "text": "\nDecodes data from the stream and returns the resulting object.\n\nThe chars argument indicates the number of decoded code points or bytes to\nreturn. The `read()` method will never return more data than requested, but it\nmight return less, if there is not enough available.\n\nThe size argument indicates the approximate maximum number of encoded bytes or\ncode points to read for decoding. The decoder can modify this setting as\nappropriate. The default value -1 indicates to read and decode as much as\npossible. This parameter is intended to prevent having to decode huge files in\none step.\n\nThe firstline flag indicates that it would be sufficient to only return the\nfirst line, if there are decoding errors on later lines.\n\nThe method should use a greedy read strategy meaning that it should read as\nmuch data as is allowed within the definition of the encoding and the given\nsize, e.g. if optional encoding endings or state markers are available on the\nstream, these should be read too.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamReader.readline()", "path": "library/codecs#codecs.StreamReader.readline", "type": "Binary Data", "text": "\nRead one line from the input stream and return the decoded data.\n\nsize, if given, is passed as size argument to the stream\u2019s `read()` method.\n\nIf keepends is false line-endings will be stripped from the lines returned.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamReader.readlines()", "path": "library/codecs#codecs.StreamReader.readlines", "type": "Binary Data", "text": "\nRead all lines available on the input stream and return them as a list of\nlines.\n\nLine-endings are implemented using the codec\u2019s `decode()` method and are\nincluded in the list entries if keepends is true.\n\nsizehint, if given, is passed as the size argument to the stream\u2019s `read()`\nmethod.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamReader.reset()", "path": "library/codecs#codecs.StreamReader.reset", "type": "Binary Data", "text": "\nResets the codec buffers used for keeping internal state.\n\nNote that no stream repositioning should take place. This method is primarily\nintended to be able to recover from decoding errors.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamReaderWriter", "path": "library/codecs#codecs.StreamReaderWriter", "type": "Binary Data", "text": "\nCreates a `StreamReaderWriter` instance. stream must be a file-like object.\nReader and Writer must be factory functions or classes providing the\n`StreamReader` and `StreamWriter` interface resp. Error handling is done in\nthe same way as defined for the stream readers and writers.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamRecoder", "path": "library/codecs#codecs.StreamRecoder", "type": "Binary Data", "text": "\nCreates a `StreamRecoder` instance which implements a two-way conversion:\nencode and decode work on the frontend \u2014 the data visible to code calling\n`read()` and `write()`, while Reader and Writer work on the backend \u2014 the data\nin stream.\n\nYou can use these objects to do transparent transcodings, e.g., from Latin-1\nto UTF-8 and back.\n\nThe stream argument must be a file-like object.\n\nThe encode and decode arguments must adhere to the `Codec` interface. Reader\nand Writer must be factory functions or classes providing objects of the\n`StreamReader` and `StreamWriter` interface respectively.\n\nError handling is done in the same way as defined for the stream readers and\nwriters.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamWriter", "path": "library/codecs#codecs.StreamWriter", "type": "Binary Data", "text": "\nConstructor for a `StreamWriter` instance.\n\nAll stream writers must provide this constructor interface. They are free to\nadd additional keyword arguments, but only the ones defined here are used by\nthe Python codec registry.\n\nThe stream argument must be a file-like object open for writing text or binary\ndata, as appropriate for the specific codec.\n\nThe `StreamWriter` may implement different error handling schemes by providing\nthe errors keyword argument. See Error Handlers for the standard error\nhandlers the underlying stream codec may support.\n\nThe errors argument will be assigned to an attribute of the same name.\nAssigning to this attribute makes it possible to switch between different\nerror handling strategies during the lifetime of the `StreamWriter` object.\n\nWrites the object\u2019s contents encoded to the stream.\n\nWrites the concatenated list of strings to the stream (possibly by reusing the\n`write()` method). The standard bytes-to-bytes codecs do not support this\nmethod.\n\nResets the codec buffers used for keeping internal state.\n\nCalling this method should ensure that the data on the output is put into a\nclean state that allows appending of new fresh data without having to rescan\nthe whole stream to recover state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamWriter.reset()", "path": "library/codecs#codecs.StreamWriter.reset", "type": "Binary Data", "text": "\nResets the codec buffers used for keeping internal state.\n\nCalling this method should ensure that the data on the output is put into a\nclean state that allows appending of new fresh data without having to rescan\nthe whole stream to recover state.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamWriter.write()", "path": "library/codecs#codecs.StreamWriter.write", "type": "Binary Data", "text": "\nWrites the object\u2019s contents encoded to the stream.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.StreamWriter.writelines()", "path": "library/codecs#codecs.StreamWriter.writelines", "type": "Binary Data", "text": "\nWrites the concatenated list of strings to the stream (possibly by reusing the\n`write()` method). The standard bytes-to-bytes codecs do not support this\nmethod.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.strict_errors()", "path": "library/codecs#codecs.strict_errors", "type": "Binary Data", "text": "\nImplements the `'strict'` error handling: each encoding or decoding error\nraises a `UnicodeError`.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codecs.xmlcharrefreplace_errors()", "path": "library/codecs#codecs.xmlcharrefreplace_errors", "type": "Binary Data", "text": "\nImplements the `'xmlcharrefreplace'` error handling (for encoding with text\nencodings only): the unencodable character is replaced by an appropriate XML\ncharacter reference.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codeop", "path": "library/codeop", "type": "Interpreters", "text": "\nSource code: Lib/codeop.py\n\nThe `codeop` module provides utilities upon which the Python read-eval-print\nloop can be emulated, as is done in the `code` module. As a result, you\nprobably don\u2019t want to use the module directly; if you want to include such a\nloop in your program you probably want to use the `code` module instead.\n\nThere are two parts to this job:\n\nThe `codeop` module provides a way of doing each of these things, and a way of\ndoing them both.\n\nTo do just the former:\n\nTries to compile source, which should be a string of Python code and return a\ncode object if source is valid Python code. In that case, the filename\nattribute of the code object will be filename, which defaults to `'<input>'`.\nReturns `None` if source is not valid Python code, but is a prefix of valid\nPython code.\n\nIf there is a problem with source, an exception will be raised. `SyntaxError`\nis raised if there is invalid Python syntax, and `OverflowError` or\n`ValueError` if there is an invalid literal.\n\nThe symbol argument determines whether source is compiled as a statement\n(`'single'`, the default), as a sequence of statements (`'exec'`) or as an\nexpression (`'eval'`). Any other value will cause `ValueError` to be raised.\n\nNote\n\nIt is possible (but not likely) that the parser stops parsing with a\nsuccessful outcome before reaching the end of the source; in this case,\ntrailing symbols may be ignored instead of causing an error. For example, a\nbackslash followed by two newlines may be followed by arbitrary garbage. This\nwill be fixed once the API for the parser is better.\n\nInstances of this class have `__call__()` methods identical in signature to\nthe built-in function `compile()`, but with the difference that if the\ninstance compiles program text containing a `__future__` statement, the\ninstance \u2018remembers\u2019 and compiles all subsequent program texts with the\nstatement in force.\n\nInstances of this class have `__call__()` methods identical in signature to\n`compile_command()`; the difference is that if the instance compiles program\ntext containing a `__future__` statement, the instance \u2018remembers\u2019 and\ncompiles all subsequent program texts with the statement in force.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codeop.CommandCompiler", "path": "library/codeop#codeop.CommandCompiler", "type": "Interpreters", "text": "\nInstances of this class have `__call__()` methods identical in signature to\n`compile_command()`; the difference is that if the instance compiles program\ntext containing a `__future__` statement, the instance \u2018remembers\u2019 and\ncompiles all subsequent program texts with the statement in force.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codeop.Compile", "path": "library/codeop#codeop.Compile", "type": "Interpreters", "text": "\nInstances of this class have `__call__()` methods identical in signature to\nthe built-in function `compile()`, but with the difference that if the\ninstance compiles program text containing a `__future__` statement, the\ninstance \u2018remembers\u2019 and compiles all subsequent program texts with the\nstatement in force.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "codeop.compile_command()", "path": "library/codeop#codeop.compile_command", "type": "Interpreters", "text": "\nTries to compile source, which should be a string of Python code and return a\ncode object if source is valid Python code. In that case, the filename\nattribute of the code object will be filename, which defaults to `'<input>'`.\nReturns `None` if source is not valid Python code, but is a prefix of valid\nPython code.\n\nIf there is a problem with source, an exception will be raised. `SyntaxError`\nis raised if there is invalid Python syntax, and `OverflowError` or\n`ValueError` if there is an invalid literal.\n\nThe symbol argument determines whether source is compiled as a statement\n(`'single'`, the default), as a sequence of statements (`'exec'`) or as an\nexpression (`'eval'`). Any other value will cause `ValueError` to be raised.\n\nNote\n\nIt is possible (but not likely) that the parser stops parsing with a\nsuccessful outcome before reaching the end of the source; in this case,\ntrailing symbols may be ignored instead of causing an error. For example, a\nbackslash followed by two newlines may be followed by arbitrary garbage. This\nwill be fixed once the API for the parser is better.\n\n  *[FIFO]: first-in, first-out\n\n"}, {"name": "collections", "path": "library/collections", "type": "Data Types", "text": "\nSource code: Lib/collections/__init__.py\n\nThis module implements specialized container datatypes providing alternatives\nto Python\u2019s general purpose built-in containers, `dict`, `list`, `set`, and\n`tuple`.\n\n`namedtuple()`\n\nfactory function for creating tuple subclasses with named fields\n\n`deque`\n\nlist-like container with fast appends and pops on either end\n\n`ChainMap`\n\ndict-like class for creating a single view of multiple mappings\n\n`Counter`\n\ndict subclass for counting hashable objects\n\n`OrderedDict`\n\ndict subclass that remembers the order entries were added\n\n`defaultdict`\n\ndict subclass that calls a factory function to supply missing values\n\n`UserDict`\n\nwrapper around dictionary objects for easier dict subclassing\n\n`UserList`\n\nwrapper around list objects for easier list subclassing\n\n`UserString`\n\nwrapper around string objects for easier string subclassing\n\nDeprecated since version 3.3, will be removed in version 3.10: Moved\nCollections Abstract Base Classes to the `collections.abc` module. For\nbackwards compatibility, they continue to be visible in this module through\nPython 3.9.\n\nNew in version 3.3.\n\nA `ChainMap` class is provided for quickly linking a number of mappings so\nthey can be treated as a single unit. It is often much faster than creating a\nnew dictionary and running multiple `update()` calls.\n\nThe class can be used to simulate nested scopes and is useful in templating.\n\nA `ChainMap` groups multiple dicts or other mappings together to create a\nsingle, updateable view. If no maps are specified, a single empty dictionary\nis provided so that a new chain always has at least one mapping.\n\nThe underlying mappings are stored in a list. That list is public and can be\naccessed or updated using the maps attribute. There is no other state.\n\nLookups search the underlying mappings successively until a key is found. In\ncontrast, writes, updates, and deletions only operate on the first mapping.\n\nA `ChainMap` incorporates the underlying mappings by reference. So, if one of\nthe underlying mappings gets updated, those changes will be reflected in\n`ChainMap`.\n\nAll of the usual dictionary methods are supported. In addition, there is a\nmaps attribute, a method for creating new subcontexts, and a property for\naccessing all but the first mapping:\n\nA user updateable list of mappings. The list is ordered from first-searched to\nlast-searched. It is the only stored state and can be modified to change which\nmappings are searched. The list should always contain at least one mapping.\n\nReturns a new `ChainMap` containing a new map followed by all of the maps in\nthe current instance. If `m` is specified, it becomes the new map at the front\nof the list of mappings; if not specified, an empty dict is used, so that a\ncall to `d.new_child()` is equivalent to: `ChainMap({}, *d.maps)`. This method\nis used for creating subcontexts that can be updated without altering values\nin any of the parent mappings.\n\nChanged in version 3.4: The optional `m` parameter was added.\n\nProperty returning a new `ChainMap` containing all of the maps in the current\ninstance except the first one. This is useful for skipping the first map in\nthe search. Use cases are similar to those for the `nonlocal` keyword used in\nnested scopes. The use cases also parallel those for the built-in `super()`\nfunction. A reference to `d.parents` is equivalent to:\n`ChainMap(*d.maps[1:])`.\n\nNote, the iteration order of a `ChainMap()` is determined by scanning the\nmappings last to first:\n\nThis gives the same ordering as a series of `dict.update()` calls starting\nwith the last mapping:\n\nChanged in version 3.9: Added support for `|` and `|=` operators, specified in\nPEP 584.\n\nSee also\n\nThis section shows various approaches to working with chained maps.\n\nExample of simulating Python\u2019s internal lookup chain:\n\nExample of letting user specified command-line arguments take precedence over\nenvironment variables which in turn take precedence over default values:\n\nExample patterns for using the `ChainMap` class to simulate nested contexts:\n\nThe `ChainMap` class only makes updates (writes and deletions) to the first\nmapping in the chain while lookups will search the full chain. However, if\ndeep writes and deletions are desired, it is easy to make a subclass that\nupdates keys found deeper in the chain:\n\nA counter tool is provided to support convenient and rapid tallies. For\nexample:\n\nA `Counter` is a `dict` subclass for counting hashable objects. It is a\ncollection where elements are stored as dictionary keys and their counts are\nstored as dictionary values. Counts are allowed to be any integer value\nincluding zero or negative counts. The `Counter` class is similar to bags or\nmultisets in other languages.\n\nElements are counted from an iterable or initialized from another mapping (or\ncounter):\n\nCounter objects have a dictionary interface except that they return a zero\ncount for missing items instead of raising a `KeyError`:\n\nSetting a count to zero does not remove an element from a counter. Use `del`\nto remove it entirely:\n\nNew in version 3.1.\n\nChanged in version 3.7: As a `dict` subclass, `Counter` Inherited the\ncapability to remember insertion order. Math operations on Counter objects\nalso preserve order. Results are ordered according to when an element is first\nencountered in the left operand and then by the order encountered in the right\noperand.\n\nCounter objects support three methods beyond those available for all\ndictionaries:\n\nReturn an iterator over elements repeating each as many times as its count.\nElements are returned in the order first encountered. If an element\u2019s count is\nless than one, `elements()` will ignore it.\n\nReturn a list of the n most common elements and their counts from the most\ncommon to the least. If n is omitted or `None`, `most_common()` returns all\nelements in the counter. Elements with equal counts are ordered in the order\nfirst encountered:\n\nElements are subtracted from an iterable or from another mapping (or counter).\nLike `dict.update()` but subtracts counts instead of replacing them. Both\ninputs and outputs may be zero or negative.\n\nNew in version 3.2.\n\nThe usual dictionary methods are available for `Counter` objects except for\ntwo which work differently for counters.\n\nThis class method is not implemented for `Counter` objects.\n\nElements are counted from an iterable or added-in from another mapping (or\ncounter). Like `dict.update()` but adds counts instead of replacing them.\nAlso, the iterable is expected to be a sequence of elements, not a sequence of\n`(key, value)` pairs.\n\nCommon patterns for working with `Counter` objects:\n\nSeveral mathematical operations are provided for combining `Counter` objects\nto produce multisets (counters that have counts greater than zero). Addition\nand subtraction combine counters by adding or subtracting the counts of\ncorresponding elements. Intersection and union return the minimum and maximum\nof corresponding counts. Each operation can accept inputs with signed counts,\nbut the output will exclude results with counts of zero or less.\n\nUnary addition and subtraction are shortcuts for adding an empty counter or\nsubtracting from an empty counter.\n\nNew in version 3.3: Added support for unary plus, unary minus, and in-place\nmultiset operations.\n\nNote\n\nCounters were primarily designed to work with positive integers to represent\nrunning counts; however, care was taken to not unnecessarily preclude use\ncases needing other types or negative values. To help with those use cases,\nthis section documents the minimum range and type restrictions.\n\nSee also\n\nTo enumerate all distinct multisets of a given size over a given set of\nelements, see `itertools.combinations_with_replacement()`:\n\nReturns a new deque object initialized left-to-right (using `append()`) with\ndata from iterable. If iterable is not specified, the new deque is empty.\n\nDeques are a generalization of stacks and queues (the name is pronounced\n\u201cdeck\u201d and is short for \u201cdouble-ended queue\u201d). Deques support thread-safe,\nmemory efficient appends and pops from either side of the deque with\napproximately the same O(1) performance in either direction.\n\nThough `list` objects support similar operations, they are optimized for fast\nfixed-length operations and incur O(n) memory movement costs for `pop(0)` and\n`insert(0, v)` operations which change both the size and position of the\nunderlying data representation.\n\nIf maxlen is not specified or is `None`, deques may grow to an arbitrary\nlength. Otherwise, the deque is bounded to the specified maximum length. Once\na bounded length deque is full, when new items are added, a corresponding\nnumber of items are discarded from the opposite end. Bounded length deques\nprovide functionality similar to the `tail` filter in Unix. They are also\nuseful for tracking transactions and other pools of data where only the most\nrecent activity is of interest.\n\nDeque objects support the following methods:\n\nAdd x to the right side of the deque.\n\nAdd x to the left side of the deque.\n\nRemove all elements from the deque leaving it with length 0.\n\nCreate a shallow copy of the deque.\n\nNew in version 3.5.\n\nCount the number of deque elements equal to x.\n\nNew in version 3.2.\n\nExtend the right side of the deque by appending elements from the iterable\nargument.\n\nExtend the left side of the deque by appending elements from iterable. Note,\nthe series of left appends results in reversing the order of elements in the\niterable argument.\n\nReturn the position of x in the deque (at or after index start and before\nindex stop). Returns the first match or raises `ValueError` if not found.\n\nNew in version 3.5.\n\nInsert x into the deque at position i.\n\nIf the insertion would cause a bounded deque to grow beyond maxlen, an\n`IndexError` is raised.\n\nNew in version 3.5.\n\nRemove and return an element from the right side of the deque. If no elements\nare present, raises an `IndexError`.\n\nRemove and return an element from the left side of the deque. If no elements\nare present, raises an `IndexError`.\n\nRemove the first occurrence of value. If not found, raises a `ValueError`.\n\nReverse the elements of the deque in-place and then return `None`.\n\nNew in version 3.2.\n\nRotate the deque n steps to the right. If n is negative, rotate to the left.\n\nWhen the deque is not empty, rotating one step to the right is equivalent to\n`d.appendleft(d.pop())`, and rotating one step to the left is equivalent to\n`d.append(d.popleft())`.\n\nDeque objects also provide one read-only attribute:\n\nMaximum size of a deque or `None` if unbounded.\n\nNew in version 3.1.\n\nIn addition to the above, deques support iteration, pickling, `len(d)`,\n`reversed(d)`, `copy.copy(d)`, `copy.deepcopy(d)`, membership testing with the\n`in` operator, and subscript references such as `d[0]` to access the first\nelement. Indexed access is O(1) at both ends but slows to O(n) in the middle.\nFor fast random access, use lists instead.\n\nStarting in version 3.5, deques support `__add__()`, `__mul__()`, and\n`__imul__()`.\n\nExample:\n\nThis section shows various approaches to working with deques.\n\nBounded length deques provide functionality similar to the `tail` filter in\nUnix:\n\nAnother approach to using deques is to maintain a sequence of recently added\nelements by appending to the right and popping to the left:\n\nA round-robin scheduler can be implemented with input iterators stored in a\n`deque`. Values are yielded from the active iterator in position zero. If that\niterator is exhausted, it can be removed with `popleft()`; otherwise, it can\nbe cycled back to the end with the `rotate()` method:\n\nThe `rotate()` method provides a way to implement `deque` slicing and\ndeletion. For example, a pure Python implementation of `del d[n]` relies on\nthe `rotate()` method to position elements to be popped:\n\nTo implement `deque` slicing, use a similar approach applying `rotate()` to\nbring a target element to the left side of the deque. Remove old entries with\n`popleft()`, add new entries with `extend()`, and then reverse the rotation.\nWith minor variations on that approach, it is easy to implement Forth style\nstack manipulations such as `dup`, `drop`, `swap`, `over`, `pick`, `rot`, and\n`roll`.\n\nReturns a new dictionary-like object. `defaultdict` is a subclass of the\nbuilt-in `dict` class. It overrides one method and adds one writable instance\nvariable. The remaining functionality is the same as for the `dict` class and\nis not documented here.\n\nThe first argument provides the initial value for the `default_factory`\nattribute; it defaults to `None`. All remaining arguments are treated the same\nas if they were passed to the `dict` constructor, including keyword arguments.\n\n`defaultdict` objects support the following method in addition to the standard\n`dict` operations:\n\nIf the `default_factory` attribute is `None`, this raises a `KeyError`\nexception with the key as argument.\n\nIf `default_factory` is not `None`, it is called without arguments to provide\na default value for the given key, this value is inserted in the dictionary\nfor the key, and returned.\n\nIf calling `default_factory` raises an exception this exception is propagated\nunchanged.\n\nThis method is called by the `__getitem__()` method of the `dict` class when\nthe requested key is not found; whatever it returns or raises is then returned\nor raised by `__getitem__()`.\n\nNote that `__missing__()` is not called for any operations besides\n`__getitem__()`. This means that `get()` will, like normal dictionaries,\nreturn `None` as a default rather than using `default_factory`.\n\n`defaultdict` objects support the following instance variable:\n\nThis attribute is used by the `__missing__()` method; it is initialized from\nthe first argument to the constructor, if present, or to `None`, if absent.\n\nChanged in version 3.9: Added merge (`|`) and update (`|=`) operators,\nspecified in PEP 584.\n\nUsing `list` as the `default_factory`, it is easy to group a sequence of key-\nvalue pairs into a dictionary of lists:\n\nWhen each key is encountered for the first time, it is not already in the\nmapping; so an entry is automatically created using the `default_factory`\nfunction which returns an empty `list`. The `list.append()` operation then\nattaches the value to the new list. When keys are encountered again, the look-\nup proceeds normally (returning the list for that key) and the `list.append()`\noperation adds another value to the list. This technique is simpler and faster\nthan an equivalent technique using `dict.setdefault()`:\n\nSetting the `default_factory` to `int` makes the `defaultdict` useful for\ncounting (like a bag or multiset in other languages):\n\nWhen a letter is first encountered, it is missing from the mapping, so the\n`default_factory` function calls `int()` to supply a default count of zero.\nThe increment operation then builds up the count for each letter.\n\nThe function `int()` which always returns zero is just a special case of\nconstant functions. A faster and more flexible way to create constant\nfunctions is to use a lambda function which can supply any constant value (not\njust zero):\n\nSetting the `default_factory` to `set` makes the `defaultdict` useful for\nbuilding a dictionary of sets:\n\nNamed tuples assign meaning to each position in a tuple and allow for more\nreadable, self-documenting code. They can be used wherever regular tuples are\nused, and they add the ability to access fields by name instead of position\nindex.\n\nReturns a new tuple subclass named typename. The new subclass is used to\ncreate tuple-like objects that have fields accessible by attribute lookup as\nwell as being indexable and iterable. Instances of the subclass also have a\nhelpful docstring (with typename and field_names) and a helpful `__repr__()`\nmethod which lists the tuple contents in a `name=value` format.\n\nThe field_names are a sequence of strings such as `['x', 'y']`. Alternatively,\nfield_names can be a single string with each fieldname separated by whitespace\nand/or commas, for example `'x y'` or `'x, y'`.\n\nAny valid Python identifier may be used for a fieldname except for names\nstarting with an underscore. Valid identifiers consist of letters, digits, and\nunderscores but do not start with a digit or underscore and cannot be a\n`keyword` such as class, for, return, global, pass, or raise.\n\nIf rename is true, invalid fieldnames are automatically replaced with\npositional names. For example, `['abc', 'def', 'ghi', 'abc']` is converted to\n`['abc', '_1', 'ghi', '_3']`, eliminating the keyword `def` and the duplicate\nfieldname `abc`.\n\ndefaults can be `None` or an iterable of default values. Since fields with a\ndefault value must come after any fields without a default, the defaults are\napplied to the rightmost parameters. For example, if the fieldnames are `['x',\n'y', 'z']` and the defaults are `(1, 2)`, then `x` will be a required\nargument, `y` will default to `1`, and `z` will default to `2`.\n\nIf module is defined, the `__module__` attribute of the named tuple is set to\nthat value.\n\nNamed tuple instances do not have per-instance dictionaries, so they are\nlightweight and require no more memory than regular tuples.\n\nTo support pickling, the named tuple class should be assigned to a variable\nthat matches typename.\n\nChanged in version 3.1: Added support for rename.\n\nChanged in version 3.6: The verbose and rename parameters became keyword-only\narguments.\n\nChanged in version 3.6: Added the module parameter.\n\nChanged in version 3.7: Removed the verbose parameter and the `_source`\nattribute.\n\nChanged in version 3.7: Added the defaults parameter and the `_field_defaults`\nattribute.\n\nNamed tuples are especially useful for assigning field names to result tuples\nreturned by the `csv` or `sqlite3` modules:\n\nIn addition to the methods inherited from tuples, named tuples support three\nadditional methods and two attributes. To prevent conflicts with field names,\nthe method and attribute names start with an underscore.\n\nClass method that makes a new instance from an existing sequence or iterable.\n\nReturn a new `dict` which maps field names to their corresponding values:\n\nChanged in version 3.1: Returns an `OrderedDict` instead of a regular `dict`.\n\nChanged in version 3.8: Returns a regular `dict` instead of an `OrderedDict`.\nAs of Python 3.7, regular dicts are guaranteed to be ordered. If the extra\nfeatures of `OrderedDict` are required, the suggested remediation is to cast\nthe result to the desired type: `OrderedDict(nt._asdict())`.\n\nReturn a new instance of the named tuple replacing specified fields with new\nvalues:\n\nTuple of strings listing the field names. Useful for introspection and for\ncreating new named tuple types from existing named tuples.\n\nDictionary mapping field names to default values.\n\nTo retrieve a field whose name is stored in a string, use the `getattr()`\nfunction:\n\nTo convert a dictionary to a named tuple, use the double-star-operator (as\ndescribed in Unpacking Argument Lists):\n\nSince a named tuple is a regular Python class, it is easy to add or change\nfunctionality with a subclass. Here is how to add a calculated field and a\nfixed-width print format:\n\nThe subclass shown above sets `__slots__` to an empty tuple. This helps keep\nmemory requirements low by preventing the creation of instance dictionaries.\n\nSubclassing is not useful for adding new, stored fields. Instead, simply\ncreate a new named tuple type from the `_fields` attribute:\n\nDocstrings can be customized by making direct assignments to the `__doc__`\nfields:\n\nChanged in version 3.5: Property docstrings became writeable.\n\nSee also\n\nSee `typing.NamedTuple` for a way to add type hints for named tuples. It also\nprovides an elegant notation using the `class` keyword:\n\nOrdered dictionaries are just like regular dictionaries but have some extra\ncapabilities relating to ordering operations. They have become less important\nnow that the built-in `dict` class gained the ability to remember insertion\norder (this new behavior became guaranteed in Python 3.7).\n\nSome differences from `dict` still remain:\n\nReturn an instance of a `dict` subclass that has methods specialized for\nrearranging dictionary order.\n\nNew in version 3.1.\n\nThe `popitem()` method for ordered dictionaries returns and removes a (key,\nvalue) pair. The pairs are returned in LIFO order if last is true or FIFO\norder if false.\n\nMove an existing key to either end of an ordered dictionary. The item is moved\nto the right end if last is true (the default) or to the beginning if last is\nfalse. Raises `KeyError` if the key does not exist:\n\nNew in version 3.2.\n\nIn addition to the usual mapping methods, ordered dictionaries also support\nreverse iteration using `reversed()`.\n\nEquality tests between `OrderedDict` objects are order-sensitive and are\nimplemented as `list(od1.items())==list(od2.items())`. Equality tests between\n`OrderedDict` objects and other `Mapping` objects are order-insensitive like\nregular dictionaries. This allows `OrderedDict` objects to be substituted\nanywhere a regular dictionary is used.\n\nChanged in version 3.5: The items, keys, and values views of `OrderedDict` now\nsupport reverse iteration using `reversed()`.\n\nChanged in version 3.6: With the acceptance of PEP 468, order is retained for\nkeyword arguments passed to the `OrderedDict` constructor and its `update()`\nmethod.\n\nChanged in version 3.9: Added merge (`|`) and update (`|=`) operators,\nspecified in PEP 584.\n\nIt is straightforward to create an ordered dictionary variant that remembers\nthe order the keys were last inserted. If a new entry overwrites an existing\nentry, the original insertion position is changed and moved to the end:\n\nAn `OrderedDict` would also be useful for implementing variants of\n`functools.lru_cache()`:\n\nThe class, `UserDict` acts as a wrapper around dictionary objects. The need\nfor this class has been partially supplanted by the ability to subclass\ndirectly from `dict`; however, this class can be easier to work with because\nthe underlying dictionary is accessible as an attribute.\n\nClass that simulates a dictionary. The instance\u2019s contents are kept in a\nregular dictionary, which is accessible via the `data` attribute of `UserDict`\ninstances. If initialdata is provided, `data` is initialized with its\ncontents; note that a reference to initialdata will not be kept, allowing it\nbe used for other purposes.\n\nIn addition to supporting the methods and operations of mappings, `UserDict`\ninstances provide the following attribute:\n\nA real dictionary used to store the contents of the `UserDict` class.\n\nThis class acts as a wrapper around list objects. It is a useful base class\nfor your own list-like classes which can inherit from them and override\nexisting methods or add new ones. In this way, one can add new behaviors to\nlists.\n\nThe need for this class has been partially supplanted by the ability to\nsubclass directly from `list`; however, this class can be easier to work with\nbecause the underlying list is accessible as an attribute.\n\nClass that simulates a list. The instance\u2019s contents are kept in a regular\nlist, which is accessible via the `data` attribute of `UserList` instances.\nThe instance\u2019s contents are initially set to a copy of list, defaulting to the\nempty list `[]`. list can be any iterable, for example a real Python list or a\n`UserList` object.\n\nIn addition to supporting the methods and operations of mutable sequences,\n`UserList` instances provide the following attribute:\n\nA real `list` object used to store the contents of the `UserList` class.\n\nSubclassing requirements: Subclasses of `UserList` are expected to offer a\nconstructor which can be called with either no arguments or one argument. List\noperations which return a new sequence attempt to create an instance of the\nactual implementation class. To do so, it assumes that the constructor can be\ncalled with a single parameter, which is a sequence object used as a data\nsource.\n\nIf a derived class does not wish to comply with this requirement, all of the\nspecial methods supported by this class will need to be overridden; please\nconsult the sources for information about the methods which need to be\nprovided in that case.\n\nThe class, `UserString` acts as a wrapper around string objects. The need for\nthis class has been partially supplanted by the ability to subclass directly\nfrom `str`; however, this class can be easier to work with because the\nunderlying string is accessible as an attribute.\n\nClass that simulates a string object. The instance\u2019s content is kept in a\nregular string object, which is accessible via the `data` attribute of\n`UserString` instances. The instance\u2019s contents are initially set to a copy of\nseq. The seq argument can be any object which can be converted into a string\nusing the built-in `str()` function.\n\nIn addition to supporting the methods and operations of strings, `UserString`\ninstances provide the following attribute:\n\nA real `str` object used to store the contents of the `UserString` class.\n\nChanged in version 3.5: New methods `__getnewargs__`, `__rmod__`, `casefold`,\n`format_map`, `isprintable`, and `maketrans`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc", "path": "library/collections.abc", "type": "Data Types", "text": "\nNew in version 3.3: Formerly, this module was part of the `collections`\nmodule.\n\nSource code: Lib/_collections_abc.py\n\nThis module provides abstract base classes that can be used to test whether a\nclass provides a particular interface; for example, whether it is hashable or\nwhether it is a mapping.\n\nThe collections module offers the following ABCs:\n\nABC\n\nInherits from\n\nAbstract Methods\n\nMixin Methods\n\n`Container`\n\n`__contains__`\n\n`Hashable`\n\n`__hash__`\n\n`Iterable`\n\n`__iter__`\n\n`Iterator`\n\n`Iterable`\n\n`__next__`\n\n`__iter__`\n\n`Reversible`\n\n`Iterable`\n\n`__reversed__`\n\n`Generator`\n\n`Iterator`\n\n`send`, `throw`\n\n`close`, `__iter__`, `__next__`\n\n`Sized`\n\n`__len__`\n\n`Callable`\n\n`__call__`\n\n`Collection`\n\n`Sized`, `Iterable`, `Container`\n\n`__contains__`, `__iter__`, `__len__`\n\n`Sequence`\n\n`Reversible`, `Collection`\n\n`__getitem__`, `__len__`\n\n`__contains__`, `__iter__`, `__reversed__`, `index`, and `count`\n\n`MutableSequence`\n\n`Sequence`\n\n`__getitem__`, `__setitem__`, `__delitem__`, `__len__`, `insert`\n\nInherited `Sequence` methods and `append`, `reverse`, `extend`, `pop`,\n`remove`, and `__iadd__`\n\n`ByteString`\n\n`Sequence`\n\n`__getitem__`, `__len__`\n\nInherited `Sequence` methods\n\n`Set`\n\n`Collection`\n\n`__contains__`, `__iter__`, `__len__`\n\n`__le__`, `__lt__`, `__eq__`, `__ne__`, `__gt__`, `__ge__`, `__and__`,\n`__or__`, `__sub__`, `__xor__`, and `isdisjoint`\n\n`MutableSet`\n\n`Set`\n\n`__contains__`, `__iter__`, `__len__`, `add`, `discard`\n\nInherited `Set` methods and `clear`, `pop`, `remove`, `__ior__`, `__iand__`,\n`__ixor__`, and `__isub__`\n\n`Mapping`\n\n`Collection`\n\n`__getitem__`, `__iter__`, `__len__`\n\n`__contains__`, `keys`, `items`, `values`, `get`, `__eq__`, and `__ne__`\n\n`MutableMapping`\n\n`Mapping`\n\n`__getitem__`, `__setitem__`, `__delitem__`, `__iter__`, `__len__`\n\nInherited `Mapping` methods and `pop`, `popitem`, `clear`, `update`, and\n`setdefault`\n\n`MappingView`\n\n`Sized`\n\n`__len__`\n\n`ItemsView`\n\n`MappingView`, `Set`\n\n`__contains__`, `__iter__`\n\n`KeysView`\n\n`MappingView`, `Set`\n\n`__contains__`, `__iter__`\n\n`ValuesView`\n\n`MappingView`, `Collection`\n\n`__contains__`, `__iter__`\n\n`Awaitable`\n\n`__await__`\n\n`Coroutine`\n\n`Awaitable`\n\n`send`, `throw`\n\n`close`\n\n`AsyncIterable`\n\n`__aiter__`\n\n`AsyncIterator`\n\n`AsyncIterable`\n\n`__anext__`\n\n`__aiter__`\n\n`AsyncGenerator`\n\n`AsyncIterator`\n\n`asend`, `athrow`\n\n`aclose`, `__aiter__`, `__anext__`\n\nABC for classes that provide the `__contains__()` method.\n\nABC for classes that provide the `__hash__()` method.\n\nABC for classes that provide the `__len__()` method.\n\nABC for classes that provide the `__call__()` method.\n\nABC for classes that provide the `__iter__()` method.\n\nChecking `isinstance(obj, Iterable)` detects classes that are registered as\n`Iterable` or that have an `__iter__()` method, but it does not detect classes\nthat iterate with the `__getitem__()` method. The only reliable way to\ndetermine whether an object is iterable is to call `iter(obj)`.\n\nABC for sized iterable container classes.\n\nNew in version 3.6.\n\nABC for classes that provide the `__iter__()` and `__next__()` methods. See\nalso the definition of iterator.\n\nABC for iterable classes that also provide the `__reversed__()` method.\n\nNew in version 3.6.\n\nABC for generator classes that implement the protocol defined in PEP 342 that\nextends iterators with the `send()`, `throw()` and `close()` methods. See also\nthe definition of generator.\n\nNew in version 3.5.\n\nABCs for read-only and mutable sequences.\n\nImplementation note: Some of the mixin methods, such as `__iter__()`,\n`__reversed__()` and `index()`, make repeated calls to the underlying\n`__getitem__()` method. Consequently, if `__getitem__()` is implemented with\nconstant access speed, the mixin methods will have linear performance;\nhowever, if the underlying method is linear (as it would be with a linked\nlist), the mixins will have quadratic performance and will likely need to be\noverridden.\n\nChanged in version 3.5: The index() method added support for stop and start\narguments.\n\nABCs for read-only and mutable sets.\n\nABCs for read-only and mutable mappings.\n\nABCs for mapping, items, keys, and values views.\n\nABC for awaitable objects, which can be used in `await` expressions. Custom\nimplementations must provide the `__await__()` method.\n\nCoroutine objects and instances of the `Coroutine` ABC are all instances of\nthis ABC.\n\nNote\n\nIn CPython, generator-based coroutines (generators decorated with\n`types.coroutine()` or `asyncio.coroutine()`) are awaitables, even though they\ndo not have an `__await__()` method. Using `isinstance(gencoro, Awaitable)`\nfor them will return `False`. Use `inspect.isawaitable()` to detect them.\n\nNew in version 3.5.\n\nABC for coroutine compatible classes. These implement the following methods,\ndefined in Coroutine Objects: `send()`, `throw()`, and `close()`. Custom\nimplementations must also implement `__await__()`. All `Coroutine` instances\nare also instances of `Awaitable`. See also the definition of coroutine.\n\nNote\n\nIn CPython, generator-based coroutines (generators decorated with\n`types.coroutine()` or `asyncio.coroutine()`) are awaitables, even though they\ndo not have an `__await__()` method. Using `isinstance(gencoro, Coroutine)`\nfor them will return `False`. Use `inspect.isawaitable()` to detect them.\n\nNew in version 3.5.\n\nABC for classes that provide `__aiter__` method. See also the definition of\nasynchronous iterable.\n\nNew in version 3.5.\n\nABC for classes that provide `__aiter__` and `__anext__` methods. See also the\ndefinition of asynchronous iterator.\n\nNew in version 3.5.\n\nABC for asynchronous generator classes that implement the protocol defined in\nPEP 525 and PEP 492.\n\nNew in version 3.6.\n\nThese ABCs allow us to ask classes or instances if they provide particular\nfunctionality, for example:\n\nSeveral of the ABCs are also useful as mixins that make it easier to develop\nclasses supporting container APIs. For example, to write a class supporting\nthe full `Set` API, it is only necessary to supply the three underlying\nabstract methods: `__contains__()`, `__iter__()`, and `__len__()`. The ABC\nsupplies the remaining methods such as `__and__()` and `isdisjoint()`:\n\nNotes on using `Set` and `MutableSet` as a mixin:\n\nSee also\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.AsyncGenerator", "path": "library/collections.abc#collections.abc.AsyncGenerator", "type": "Data Types", "text": "\nABC for asynchronous generator classes that implement the protocol defined in\nPEP 525 and PEP 492.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.AsyncIterable", "path": "library/collections.abc#collections.abc.AsyncIterable", "type": "Data Types", "text": "\nABC for classes that provide `__aiter__` method. See also the definition of\nasynchronous iterable.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.AsyncIterator", "path": "library/collections.abc#collections.abc.AsyncIterator", "type": "Data Types", "text": "\nABC for classes that provide `__aiter__` and `__anext__` methods. See also the\ndefinition of asynchronous iterator.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Awaitable", "path": "library/collections.abc#collections.abc.Awaitable", "type": "Data Types", "text": "\nABC for awaitable objects, which can be used in `await` expressions. Custom\nimplementations must provide the `__await__()` method.\n\nCoroutine objects and instances of the `Coroutine` ABC are all instances of\nthis ABC.\n\nNote\n\nIn CPython, generator-based coroutines (generators decorated with\n`types.coroutine()` or `asyncio.coroutine()`) are awaitables, even though they\ndo not have an `__await__()` method. Using `isinstance(gencoro, Awaitable)`\nfor them will return `False`. Use `inspect.isawaitable()` to detect them.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.ByteString", "path": "library/collections.abc#collections.abc.ByteString", "type": "Data Types", "text": "\nABCs for read-only and mutable sequences.\n\nImplementation note: Some of the mixin methods, such as `__iter__()`,\n`__reversed__()` and `index()`, make repeated calls to the underlying\n`__getitem__()` method. Consequently, if `__getitem__()` is implemented with\nconstant access speed, the mixin methods will have linear performance;\nhowever, if the underlying method is linear (as it would be with a linked\nlist), the mixins will have quadratic performance and will likely need to be\noverridden.\n\nChanged in version 3.5: The index() method added support for stop and start\narguments.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Callable", "path": "library/collections.abc#collections.abc.Callable", "type": "Data Types", "text": "\nABC for classes that provide the `__call__()` method.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Collection", "path": "library/collections.abc#collections.abc.Collection", "type": "Data Types", "text": "\nABC for sized iterable container classes.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Container", "path": "library/collections.abc#collections.abc.Container", "type": "Data Types", "text": "\nABC for classes that provide the `__contains__()` method.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Coroutine", "path": "library/collections.abc#collections.abc.Coroutine", "type": "Data Types", "text": "\nABC for coroutine compatible classes. These implement the following methods,\ndefined in Coroutine Objects: `send()`, `throw()`, and `close()`. Custom\nimplementations must also implement `__await__()`. All `Coroutine` instances\nare also instances of `Awaitable`. See also the definition of coroutine.\n\nNote\n\nIn CPython, generator-based coroutines (generators decorated with\n`types.coroutine()` or `asyncio.coroutine()`) are awaitables, even though they\ndo not have an `__await__()` method. Using `isinstance(gencoro, Coroutine)`\nfor them will return `False`. Use `inspect.isawaitable()` to detect them.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Generator", "path": "library/collections.abc#collections.abc.Generator", "type": "Data Types", "text": "\nABC for generator classes that implement the protocol defined in PEP 342 that\nextends iterators with the `send()`, `throw()` and `close()` methods. See also\nthe definition of generator.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Hashable", "path": "library/collections.abc#collections.abc.Hashable", "type": "Data Types", "text": "\nABC for classes that provide the `__hash__()` method.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.ItemsView", "path": "library/collections.abc#collections.abc.ItemsView", "type": "Data Types", "text": "\nABCs for mapping, items, keys, and values views.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Iterable", "path": "library/collections.abc#collections.abc.Iterable", "type": "Data Types", "text": "\nABC for classes that provide the `__iter__()` method.\n\nChecking `isinstance(obj, Iterable)` detects classes that are registered as\n`Iterable` or that have an `__iter__()` method, but it does not detect classes\nthat iterate with the `__getitem__()` method. The only reliable way to\ndetermine whether an object is iterable is to call `iter(obj)`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Iterator", "path": "library/collections.abc#collections.abc.Iterator", "type": "Data Types", "text": "\nABC for classes that provide the `__iter__()` and `__next__()` methods. See\nalso the definition of iterator.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.KeysView", "path": "library/collections.abc#collections.abc.KeysView", "type": "Data Types", "text": "\nABCs for mapping, items, keys, and values views.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Mapping", "path": "library/collections.abc#collections.abc.Mapping", "type": "Data Types", "text": "\nABCs for read-only and mutable mappings.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.MappingView", "path": "library/collections.abc#collections.abc.MappingView", "type": "Data Types", "text": "\nABCs for mapping, items, keys, and values views.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.MutableMapping", "path": "library/collections.abc#collections.abc.MutableMapping", "type": "Data Types", "text": "\nABCs for read-only and mutable mappings.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.MutableSequence", "path": "library/collections.abc#collections.abc.MutableSequence", "type": "Data Types", "text": "\nABCs for read-only and mutable sequences.\n\nImplementation note: Some of the mixin methods, such as `__iter__()`,\n`__reversed__()` and `index()`, make repeated calls to the underlying\n`__getitem__()` method. Consequently, if `__getitem__()` is implemented with\nconstant access speed, the mixin methods will have linear performance;\nhowever, if the underlying method is linear (as it would be with a linked\nlist), the mixins will have quadratic performance and will likely need to be\noverridden.\n\nChanged in version 3.5: The index() method added support for stop and start\narguments.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.MutableSet", "path": "library/collections.abc#collections.abc.MutableSet", "type": "Data Types", "text": "\nABCs for read-only and mutable sets.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Reversible", "path": "library/collections.abc#collections.abc.Reversible", "type": "Data Types", "text": "\nABC for iterable classes that also provide the `__reversed__()` method.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Sequence", "path": "library/collections.abc#collections.abc.Sequence", "type": "Data Types", "text": "\nABCs for read-only and mutable sequences.\n\nImplementation note: Some of the mixin methods, such as `__iter__()`,\n`__reversed__()` and `index()`, make repeated calls to the underlying\n`__getitem__()` method. Consequently, if `__getitem__()` is implemented with\nconstant access speed, the mixin methods will have linear performance;\nhowever, if the underlying method is linear (as it would be with a linked\nlist), the mixins will have quadratic performance and will likely need to be\noverridden.\n\nChanged in version 3.5: The index() method added support for stop and start\narguments.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Set", "path": "library/collections.abc#collections.abc.Set", "type": "Data Types", "text": "\nABCs for read-only and mutable sets.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.Sized", "path": "library/collections.abc#collections.abc.Sized", "type": "Data Types", "text": "\nABC for classes that provide the `__len__()` method.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.abc.ValuesView", "path": "library/collections.abc#collections.abc.ValuesView", "type": "Data Types", "text": "\nABCs for mapping, items, keys, and values views.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.ChainMap", "path": "library/collections#collections.ChainMap", "type": "Data Types", "text": "\nA `ChainMap` groups multiple dicts or other mappings together to create a\nsingle, updateable view. If no maps are specified, a single empty dictionary\nis provided so that a new chain always has at least one mapping.\n\nThe underlying mappings are stored in a list. That list is public and can be\naccessed or updated using the maps attribute. There is no other state.\n\nLookups search the underlying mappings successively until a key is found. In\ncontrast, writes, updates, and deletions only operate on the first mapping.\n\nA `ChainMap` incorporates the underlying mappings by reference. So, if one of\nthe underlying mappings gets updated, those changes will be reflected in\n`ChainMap`.\n\nAll of the usual dictionary methods are supported. In addition, there is a\nmaps attribute, a method for creating new subcontexts, and a property for\naccessing all but the first mapping:\n\nA user updateable list of mappings. The list is ordered from first-searched to\nlast-searched. It is the only stored state and can be modified to change which\nmappings are searched. The list should always contain at least one mapping.\n\nReturns a new `ChainMap` containing a new map followed by all of the maps in\nthe current instance. If `m` is specified, it becomes the new map at the front\nof the list of mappings; if not specified, an empty dict is used, so that a\ncall to `d.new_child()` is equivalent to: `ChainMap({}, *d.maps)`. This method\nis used for creating subcontexts that can be updated without altering values\nin any of the parent mappings.\n\nChanged in version 3.4: The optional `m` parameter was added.\n\nProperty returning a new `ChainMap` containing all of the maps in the current\ninstance except the first one. This is useful for skipping the first map in\nthe search. Use cases are similar to those for the `nonlocal` keyword used in\nnested scopes. The use cases also parallel those for the built-in `super()`\nfunction. A reference to `d.parents` is equivalent to:\n`ChainMap(*d.maps[1:])`.\n\nNote, the iteration order of a `ChainMap()` is determined by scanning the\nmappings last to first:\n\nThis gives the same ordering as a series of `dict.update()` calls starting\nwith the last mapping:\n\nChanged in version 3.9: Added support for `|` and `|=` operators, specified in\nPEP 584.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.ChainMap.maps", "path": "library/collections#collections.ChainMap.maps", "type": "Data Types", "text": "\nA user updateable list of mappings. The list is ordered from first-searched to\nlast-searched. It is the only stored state and can be modified to change which\nmappings are searched. The list should always contain at least one mapping.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.ChainMap.new_child()", "path": "library/collections#collections.ChainMap.new_child", "type": "Data Types", "text": "\nReturns a new `ChainMap` containing a new map followed by all of the maps in\nthe current instance. If `m` is specified, it becomes the new map at the front\nof the list of mappings; if not specified, an empty dict is used, so that a\ncall to `d.new_child()` is equivalent to: `ChainMap({}, *d.maps)`. This method\nis used for creating subcontexts that can be updated without altering values\nin any of the parent mappings.\n\nChanged in version 3.4: The optional `m` parameter was added.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.ChainMap.parents", "path": "library/collections#collections.ChainMap.parents", "type": "Data Types", "text": "\nProperty returning a new `ChainMap` containing all of the maps in the current\ninstance except the first one. This is useful for skipping the first map in\nthe search. Use cases are similar to those for the `nonlocal` keyword used in\nnested scopes. The use cases also parallel those for the built-in `super()`\nfunction. A reference to `d.parents` is equivalent to:\n`ChainMap(*d.maps[1:])`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.Counter", "path": "library/collections#collections.Counter", "type": "Data Types", "text": "\nA `Counter` is a `dict` subclass for counting hashable objects. It is a\ncollection where elements are stored as dictionary keys and their counts are\nstored as dictionary values. Counts are allowed to be any integer value\nincluding zero or negative counts. The `Counter` class is similar to bags or\nmultisets in other languages.\n\nElements are counted from an iterable or initialized from another mapping (or\ncounter):\n\nCounter objects have a dictionary interface except that they return a zero\ncount for missing items instead of raising a `KeyError`:\n\nSetting a count to zero does not remove an element from a counter. Use `del`\nto remove it entirely:\n\nNew in version 3.1.\n\nChanged in version 3.7: As a `dict` subclass, `Counter` Inherited the\ncapability to remember insertion order. Math operations on Counter objects\nalso preserve order. Results are ordered according to when an element is first\nencountered in the left operand and then by the order encountered in the right\noperand.\n\nCounter objects support three methods beyond those available for all\ndictionaries:\n\nReturn an iterator over elements repeating each as many times as its count.\nElements are returned in the order first encountered. If an element\u2019s count is\nless than one, `elements()` will ignore it.\n\nReturn a list of the n most common elements and their counts from the most\ncommon to the least. If n is omitted or `None`, `most_common()` returns all\nelements in the counter. Elements with equal counts are ordered in the order\nfirst encountered:\n\nElements are subtracted from an iterable or from another mapping (or counter).\nLike `dict.update()` but subtracts counts instead of replacing them. Both\ninputs and outputs may be zero or negative.\n\nNew in version 3.2.\n\nThe usual dictionary methods are available for `Counter` objects except for\ntwo which work differently for counters.\n\nThis class method is not implemented for `Counter` objects.\n\nElements are counted from an iterable or added-in from another mapping (or\ncounter). Like `dict.update()` but adds counts instead of replacing them.\nAlso, the iterable is expected to be a sequence of elements, not a sequence of\n`(key, value)` pairs.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.Counter.elements()", "path": "library/collections#collections.Counter.elements", "type": "Data Types", "text": "\nReturn an iterator over elements repeating each as many times as its count.\nElements are returned in the order first encountered. If an element\u2019s count is\nless than one, `elements()` will ignore it.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.Counter.fromkeys()", "path": "library/collections#collections.Counter.fromkeys", "type": "Data Types", "text": "\nThis class method is not implemented for `Counter` objects.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.Counter.most_common()", "path": "library/collections#collections.Counter.most_common", "type": "Data Types", "text": "\nReturn a list of the n most common elements and their counts from the most\ncommon to the least. If n is omitted or `None`, `most_common()` returns all\nelements in the counter. Elements with equal counts are ordered in the order\nfirst encountered:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.Counter.subtract()", "path": "library/collections#collections.Counter.subtract", "type": "Data Types", "text": "\nElements are subtracted from an iterable or from another mapping (or counter).\nLike `dict.update()` but subtracts counts instead of replacing them. Both\ninputs and outputs may be zero or negative.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.Counter.update()", "path": "library/collections#collections.Counter.update", "type": "Data Types", "text": "\nElements are counted from an iterable or added-in from another mapping (or\ncounter). Like `dict.update()` but adds counts instead of replacing them.\nAlso, the iterable is expected to be a sequence of elements, not a sequence of\n`(key, value)` pairs.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.defaultdict", "path": "library/collections#collections.defaultdict", "type": "Data Types", "text": "\nReturns a new dictionary-like object. `defaultdict` is a subclass of the\nbuilt-in `dict` class. It overrides one method and adds one writable instance\nvariable. The remaining functionality is the same as for the `dict` class and\nis not documented here.\n\nThe first argument provides the initial value for the `default_factory`\nattribute; it defaults to `None`. All remaining arguments are treated the same\nas if they were passed to the `dict` constructor, including keyword arguments.\n\n`defaultdict` objects support the following method in addition to the standard\n`dict` operations:\n\nIf the `default_factory` attribute is `None`, this raises a `KeyError`\nexception with the key as argument.\n\nIf `default_factory` is not `None`, it is called without arguments to provide\na default value for the given key, this value is inserted in the dictionary\nfor the key, and returned.\n\nIf calling `default_factory` raises an exception this exception is propagated\nunchanged.\n\nThis method is called by the `__getitem__()` method of the `dict` class when\nthe requested key is not found; whatever it returns or raises is then returned\nor raised by `__getitem__()`.\n\nNote that `__missing__()` is not called for any operations besides\n`__getitem__()`. This means that `get()` will, like normal dictionaries,\nreturn `None` as a default rather than using `default_factory`.\n\n`defaultdict` objects support the following instance variable:\n\nThis attribute is used by the `__missing__()` method; it is initialized from\nthe first argument to the constructor, if present, or to `None`, if absent.\n\nChanged in version 3.9: Added merge (`|`) and update (`|=`) operators,\nspecified in PEP 584.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.defaultdict.default_factory", "path": "library/collections#collections.defaultdict.default_factory", "type": "Data Types", "text": "\nThis attribute is used by the `__missing__()` method; it is initialized from\nthe first argument to the constructor, if present, or to `None`, if absent.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.defaultdict.__missing__()", "path": "library/collections#collections.defaultdict.__missing__", "type": "Data Types", "text": "\nIf the `default_factory` attribute is `None`, this raises a `KeyError`\nexception with the key as argument.\n\nIf `default_factory` is not `None`, it is called without arguments to provide\na default value for the given key, this value is inserted in the dictionary\nfor the key, and returned.\n\nIf calling `default_factory` raises an exception this exception is propagated\nunchanged.\n\nThis method is called by the `__getitem__()` method of the `dict` class when\nthe requested key is not found; whatever it returns or raises is then returned\nor raised by `__getitem__()`.\n\nNote that `__missing__()` is not called for any operations besides\n`__getitem__()`. This means that `get()` will, like normal dictionaries,\nreturn `None` as a default rather than using `default_factory`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque", "path": "library/collections#collections.deque", "type": "Data Types", "text": "\nReturns a new deque object initialized left-to-right (using `append()`) with\ndata from iterable. If iterable is not specified, the new deque is empty.\n\nDeques are a generalization of stacks and queues (the name is pronounced\n\u201cdeck\u201d and is short for \u201cdouble-ended queue\u201d). Deques support thread-safe,\nmemory efficient appends and pops from either side of the deque with\napproximately the same O(1) performance in either direction.\n\nThough `list` objects support similar operations, they are optimized for fast\nfixed-length operations and incur O(n) memory movement costs for `pop(0)` and\n`insert(0, v)` operations which change both the size and position of the\nunderlying data representation.\n\nIf maxlen is not specified or is `None`, deques may grow to an arbitrary\nlength. Otherwise, the deque is bounded to the specified maximum length. Once\na bounded length deque is full, when new items are added, a corresponding\nnumber of items are discarded from the opposite end. Bounded length deques\nprovide functionality similar to the `tail` filter in Unix. They are also\nuseful for tracking transactions and other pools of data where only the most\nrecent activity is of interest.\n\nDeque objects support the following methods:\n\nAdd x to the right side of the deque.\n\nAdd x to the left side of the deque.\n\nRemove all elements from the deque leaving it with length 0.\n\nCreate a shallow copy of the deque.\n\nNew in version 3.5.\n\nCount the number of deque elements equal to x.\n\nNew in version 3.2.\n\nExtend the right side of the deque by appending elements from the iterable\nargument.\n\nExtend the left side of the deque by appending elements from iterable. Note,\nthe series of left appends results in reversing the order of elements in the\niterable argument.\n\nReturn the position of x in the deque (at or after index start and before\nindex stop). Returns the first match or raises `ValueError` if not found.\n\nNew in version 3.5.\n\nInsert x into the deque at position i.\n\nIf the insertion would cause a bounded deque to grow beyond maxlen, an\n`IndexError` is raised.\n\nNew in version 3.5.\n\nRemove and return an element from the right side of the deque. If no elements\nare present, raises an `IndexError`.\n\nRemove and return an element from the left side of the deque. If no elements\nare present, raises an `IndexError`.\n\nRemove the first occurrence of value. If not found, raises a `ValueError`.\n\nReverse the elements of the deque in-place and then return `None`.\n\nNew in version 3.2.\n\nRotate the deque n steps to the right. If n is negative, rotate to the left.\n\nWhen the deque is not empty, rotating one step to the right is equivalent to\n`d.appendleft(d.pop())`, and rotating one step to the left is equivalent to\n`d.append(d.popleft())`.\n\nDeque objects also provide one read-only attribute:\n\nMaximum size of a deque or `None` if unbounded.\n\nNew in version 3.1.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.append()", "path": "library/collections#collections.deque.append", "type": "Data Types", "text": "\nAdd x to the right side of the deque.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.appendleft()", "path": "library/collections#collections.deque.appendleft", "type": "Data Types", "text": "\nAdd x to the left side of the deque.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.clear()", "path": "library/collections#collections.deque.clear", "type": "Data Types", "text": "\nRemove all elements from the deque leaving it with length 0.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.copy()", "path": "library/collections#collections.deque.copy", "type": "Data Types", "text": "\nCreate a shallow copy of the deque.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.count()", "path": "library/collections#collections.deque.count", "type": "Data Types", "text": "\nCount the number of deque elements equal to x.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.extend()", "path": "library/collections#collections.deque.extend", "type": "Data Types", "text": "\nExtend the right side of the deque by appending elements from the iterable\nargument.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.extendleft()", "path": "library/collections#collections.deque.extendleft", "type": "Data Types", "text": "\nExtend the left side of the deque by appending elements from iterable. Note,\nthe series of left appends results in reversing the order of elements in the\niterable argument.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.index()", "path": "library/collections#collections.deque.index", "type": "Data Types", "text": "\nReturn the position of x in the deque (at or after index start and before\nindex stop). Returns the first match or raises `ValueError` if not found.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.insert()", "path": "library/collections#collections.deque.insert", "type": "Data Types", "text": "\nInsert x into the deque at position i.\n\nIf the insertion would cause a bounded deque to grow beyond maxlen, an\n`IndexError` is raised.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.maxlen", "path": "library/collections#collections.deque.maxlen", "type": "Data Types", "text": "\nMaximum size of a deque or `None` if unbounded.\n\nNew in version 3.1.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.pop()", "path": "library/collections#collections.deque.pop", "type": "Data Types", "text": "\nRemove and return an element from the right side of the deque. If no elements\nare present, raises an `IndexError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.popleft()", "path": "library/collections#collections.deque.popleft", "type": "Data Types", "text": "\nRemove and return an element from the left side of the deque. If no elements\nare present, raises an `IndexError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.remove()", "path": "library/collections#collections.deque.remove", "type": "Data Types", "text": "\nRemove the first occurrence of value. If not found, raises a `ValueError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.reverse()", "path": "library/collections#collections.deque.reverse", "type": "Data Types", "text": "\nReverse the elements of the deque in-place and then return `None`.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.deque.rotate()", "path": "library/collections#collections.deque.rotate", "type": "Data Types", "text": "\nRotate the deque n steps to the right. If n is negative, rotate to the left.\n\nWhen the deque is not empty, rotating one step to the right is equivalent to\n`d.appendleft(d.pop())`, and rotating one step to the left is equivalent to\n`d.append(d.popleft())`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.namedtuple()", "path": "library/collections#collections.namedtuple", "type": "Data Types", "text": "\nReturns a new tuple subclass named typename. The new subclass is used to\ncreate tuple-like objects that have fields accessible by attribute lookup as\nwell as being indexable and iterable. Instances of the subclass also have a\nhelpful docstring (with typename and field_names) and a helpful `__repr__()`\nmethod which lists the tuple contents in a `name=value` format.\n\nThe field_names are a sequence of strings such as `['x', 'y']`. Alternatively,\nfield_names can be a single string with each fieldname separated by whitespace\nand/or commas, for example `'x y'` or `'x, y'`.\n\nAny valid Python identifier may be used for a fieldname except for names\nstarting with an underscore. Valid identifiers consist of letters, digits, and\nunderscores but do not start with a digit or underscore and cannot be a\n`keyword` such as class, for, return, global, pass, or raise.\n\nIf rename is true, invalid fieldnames are automatically replaced with\npositional names. For example, `['abc', 'def', 'ghi', 'abc']` is converted to\n`['abc', '_1', 'ghi', '_3']`, eliminating the keyword `def` and the duplicate\nfieldname `abc`.\n\ndefaults can be `None` or an iterable of default values. Since fields with a\ndefault value must come after any fields without a default, the defaults are\napplied to the rightmost parameters. For example, if the fieldnames are `['x',\n'y', 'z']` and the defaults are `(1, 2)`, then `x` will be a required\nargument, `y` will default to `1`, and `z` will default to `2`.\n\nIf module is defined, the `__module__` attribute of the named tuple is set to\nthat value.\n\nNamed tuple instances do not have per-instance dictionaries, so they are\nlightweight and require no more memory than regular tuples.\n\nTo support pickling, the named tuple class should be assigned to a variable\nthat matches typename.\n\nChanged in version 3.1: Added support for rename.\n\nChanged in version 3.6: The verbose and rename parameters became keyword-only\narguments.\n\nChanged in version 3.6: Added the module parameter.\n\nChanged in version 3.7: Removed the verbose parameter and the `_source`\nattribute.\n\nChanged in version 3.7: Added the defaults parameter and the `_field_defaults`\nattribute.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.OrderedDict", "path": "library/collections#collections.OrderedDict", "type": "Data Types", "text": "\nReturn an instance of a `dict` subclass that has methods specialized for\nrearranging dictionary order.\n\nNew in version 3.1.\n\nThe `popitem()` method for ordered dictionaries returns and removes a (key,\nvalue) pair. The pairs are returned in LIFO order if last is true or FIFO\norder if false.\n\nMove an existing key to either end of an ordered dictionary. The item is moved\nto the right end if last is true (the default) or to the beginning if last is\nfalse. Raises `KeyError` if the key does not exist:\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.OrderedDict.move_to_end()", "path": "library/collections#collections.OrderedDict.move_to_end", "type": "Data Types", "text": "\nMove an existing key to either end of an ordered dictionary. The item is moved\nto the right end if last is true (the default) or to the beginning if last is\nfalse. Raises `KeyError` if the key does not exist:\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.OrderedDict.popitem()", "path": "library/collections#collections.OrderedDict.popitem", "type": "Data Types", "text": "\nThe `popitem()` method for ordered dictionaries returns and removes a (key,\nvalue) pair. The pairs are returned in LIFO order if last is true or FIFO\norder if false.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.somenamedtuple._asdict()", "path": "library/collections#collections.somenamedtuple._asdict", "type": "Data Types", "text": "\nReturn a new `dict` which maps field names to their corresponding values:\n\nChanged in version 3.1: Returns an `OrderedDict` instead of a regular `dict`.\n\nChanged in version 3.8: Returns a regular `dict` instead of an `OrderedDict`.\nAs of Python 3.7, regular dicts are guaranteed to be ordered. If the extra\nfeatures of `OrderedDict` are required, the suggested remediation is to cast\nthe result to the desired type: `OrderedDict(nt._asdict())`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.somenamedtuple._fields", "path": "library/collections#collections.somenamedtuple._fields", "type": "Data Types", "text": "\nTuple of strings listing the field names. Useful for introspection and for\ncreating new named tuple types from existing named tuples.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.somenamedtuple._field_defaults", "path": "library/collections#collections.somenamedtuple._field_defaults", "type": "Data Types", "text": "\nDictionary mapping field names to default values.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.somenamedtuple._make()", "path": "library/collections#collections.somenamedtuple._make", "type": "Data Types", "text": "\nClass method that makes a new instance from an existing sequence or iterable.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.somenamedtuple._replace()", "path": "library/collections#collections.somenamedtuple._replace", "type": "Data Types", "text": "\nReturn a new instance of the named tuple replacing specified fields with new\nvalues:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.UserDict", "path": "library/collections#collections.UserDict", "type": "Data Types", "text": "\nClass that simulates a dictionary. The instance\u2019s contents are kept in a\nregular dictionary, which is accessible via the `data` attribute of `UserDict`\ninstances. If initialdata is provided, `data` is initialized with its\ncontents; note that a reference to initialdata will not be kept, allowing it\nbe used for other purposes.\n\nIn addition to supporting the methods and operations of mappings, `UserDict`\ninstances provide the following attribute:\n\nA real dictionary used to store the contents of the `UserDict` class.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.UserDict.data", "path": "library/collections#collections.UserDict.data", "type": "Data Types", "text": "\nA real dictionary used to store the contents of the `UserDict` class.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.UserList", "path": "library/collections#collections.UserList", "type": "Data Types", "text": "\nClass that simulates a list. The instance\u2019s contents are kept in a regular\nlist, which is accessible via the `data` attribute of `UserList` instances.\nThe instance\u2019s contents are initially set to a copy of list, defaulting to the\nempty list `[]`. list can be any iterable, for example a real Python list or a\n`UserList` object.\n\nIn addition to supporting the methods and operations of mutable sequences,\n`UserList` instances provide the following attribute:\n\nA real `list` object used to store the contents of the `UserList` class.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.UserList.data", "path": "library/collections#collections.UserList.data", "type": "Data Types", "text": "\nA real `list` object used to store the contents of the `UserList` class.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.UserString", "path": "library/collections#collections.UserString", "type": "Data Types", "text": "\nClass that simulates a string object. The instance\u2019s content is kept in a\nregular string object, which is accessible via the `data` attribute of\n`UserString` instances. The instance\u2019s contents are initially set to a copy of\nseq. The seq argument can be any object which can be converted into a string\nusing the built-in `str()` function.\n\nIn addition to supporting the methods and operations of strings, `UserString`\ninstances provide the following attribute:\n\nA real `str` object used to store the contents of the `UserString` class.\n\nChanged in version 3.5: New methods `__getnewargs__`, `__rmod__`, `casefold`,\n`format_map`, `isprintable`, and `maketrans`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "collections.UserString.data", "path": "library/collections#collections.UserString.data", "type": "Data Types", "text": "\nA real `str` object used to store the contents of the `UserString` class.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "colorsys", "path": "library/colorsys", "type": "Multimedia", "text": "\nSource code: Lib/colorsys.py\n\nThe `colorsys` module defines bidirectional conversions of color values\nbetween colors expressed in the RGB (Red Green Blue) color space used in\ncomputer monitors and three other coordinate systems: YIQ, HLS (Hue Lightness\nSaturation) and HSV (Hue Saturation Value). Coordinates in all of these color\nspaces are floating point values. In the YIQ space, the Y coordinate is\nbetween 0 and 1, but the I and Q coordinates can be positive or negative. In\nall other spaces, the coordinates are all between 0 and 1.\n\nSee also\n\nMore information about color spaces can be found at\nhttps://poynton.ca/ColorFAQ.html and\nhttps://www.cambridgeincolour.com/tutorials/color-spaces.htm.\n\nThe `colorsys` module defines the following functions:\n\nConvert the color from RGB coordinates to YIQ coordinates.\n\nConvert the color from YIQ coordinates to RGB coordinates.\n\nConvert the color from RGB coordinates to HLS coordinates.\n\nConvert the color from HLS coordinates to RGB coordinates.\n\nConvert the color from RGB coordinates to HSV coordinates.\n\nConvert the color from HSV coordinates to RGB coordinates.\n\nExample:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "colorsys.hls_to_rgb()", "path": "library/colorsys#colorsys.hls_to_rgb", "type": "Multimedia", "text": "\nConvert the color from HLS coordinates to RGB coordinates.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "colorsys.hsv_to_rgb()", "path": "library/colorsys#colorsys.hsv_to_rgb", "type": "Multimedia", "text": "\nConvert the color from HSV coordinates to RGB coordinates.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "colorsys.rgb_to_hls()", "path": "library/colorsys#colorsys.rgb_to_hls", "type": "Multimedia", "text": "\nConvert the color from RGB coordinates to HLS coordinates.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "colorsys.rgb_to_hsv()", "path": "library/colorsys#colorsys.rgb_to_hsv", "type": "Multimedia", "text": "\nConvert the color from RGB coordinates to HSV coordinates.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "colorsys.rgb_to_yiq()", "path": "library/colorsys#colorsys.rgb_to_yiq", "type": "Multimedia", "text": "\nConvert the color from RGB coordinates to YIQ coordinates.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "colorsys.yiq_to_rgb()", "path": "library/colorsys#colorsys.yiq_to_rgb", "type": "Multimedia", "text": "\nConvert the color from YIQ coordinates to RGB coordinates.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "compile()", "path": "library/functions#compile", "type": "Built-in Functions", "text": "\nCompile the source into a code or AST object. Code objects can be executed by\n`exec()` or `eval()`. source can either be a normal string, a byte string, or\nan AST object. Refer to the `ast` module documentation for information on how\nto work with AST objects.\n\nThe filename argument should give the file from which the code was read; pass\nsome recognizable value if it wasn\u2019t read from a file (`'<string>'` is\ncommonly used).\n\nThe mode argument specifies what kind of code must be compiled; it can be\n`'exec'` if source consists of a sequence of statements, `'eval'` if it\nconsists of a single expression, or `'single'` if it consists of a single\ninteractive statement (in the latter case, expression statements that evaluate\nto something other than `None` will be printed).\n\nThe optional arguments flags and dont_inherit control which compiler options\nshould be activated and which future features should be allowed. If neither is\npresent (or both are zero) the code is compiled with the same flags that\naffect the code that is calling `compile()`. If the flags argument is given\nand dont_inherit is not (or is zero) then the compiler options and the future\nstatements specified by the flags argument are used in addition to those that\nwould be used anyway. If dont_inherit is a non-zero integer then the flags\nargument is it \u2013 the flags (future features and compiler options) in the\nsurrounding code are ignored.\n\nCompiler options and future statements are specified by bits which can be\nbitwise ORed together to specify multiple options. The bitfield required to\nspecify a given future feature can be found as the `compiler_flag` attribute\non the `_Feature` instance in the `__future__` module. Compiler flags can be\nfound in `ast` module, with `PyCF_` prefix.\n\nThe argument optimize specifies the optimization level of the compiler; the\ndefault value of `-1` selects the optimization level of the interpreter as\ngiven by `-O` options. Explicit levels are `0` (no optimization; `__debug__`\nis true), `1` (asserts are removed, `__debug__` is false) or `2` (docstrings\nare removed too).\n\nThis function raises `SyntaxError` if the compiled source is invalid, and\n`ValueError` if the source contains null bytes.\n\nIf you want to parse Python code into its AST representation, see\n`ast.parse()`.\n\nRaises an auditing event `compile` with arguments `source` and `filename`.\nThis event may also be raised by implicit compilation.\n\nNote\n\nWhen compiling a string with multi-line code in `'single'` or `'eval'` mode,\ninput must be terminated by at least one newline character. This is to\nfacilitate detection of incomplete and complete statements in the `code`\nmodule.\n\nWarning\n\nIt is possible to crash the Python interpreter with a sufficiently\nlarge/complex string when compiling to an AST object due to stack depth\nlimitations in Python\u2019s AST compiler.\n\nChanged in version 3.2: Allowed use of Windows and Mac newlines. Also input in\n`'exec'` mode does not have to end in a newline anymore. Added the optimize\nparameter.\n\nChanged in version 3.5: Previously, `TypeError` was raised when null bytes\nwere encountered in source.\n\nNew in version 3.8: `ast.PyCF_ALLOW_TOP_LEVEL_AWAIT` can now be passed in\nflags to enable support for top-level `await`, `async for`, and `async with`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "compileall", "path": "library/compileall", "type": "Language", "text": "\nSource code: Lib/compileall.py\n\nThis module provides some utility functions to support installing Python\nlibraries. These functions compile Python source files in a directory tree.\nThis module can be used to create the cached byte-code files at library\ninstallation time, which makes them available for use even by users who don\u2019t\nhave write permission to the library directories.\n\nThis module can work as a script (using python -m compileall) to compile\nPython sources.\n\nPositional arguments are files to compile or directories that contain source\nfiles, traversed recursively. If no argument is given, behave as if the\ncommand line was `-l <directories from sys.path>`.\n\nDo not recurse into subdirectories, only compile source code files directly\ncontained in the named or implied directories.\n\nForce rebuild even if timestamps are up-to-date.\n\nDo not print the list of files compiled. If passed once, error messages will\nstill be printed. If passed twice (`-qq`), all output is suppressed.\n\nDirectory prepended to the path to each file being compiled. This will appear\nin compilation time tracebacks, and is also compiled in to the byte-code file,\nwhere it will be used in tracebacks and other messages in cases where the\nsource file does not exist at the time the byte-code file is executed.\n\nRemove (`-s`) or append (`-p`) the given prefix of paths recorded in the\n`.pyc` files. Cannot be combined with `-d`.\n\nregex is used to search the full path to each file considered for compilation,\nand if the regex produces a match, the file is skipped.\n\nRead the file `list` and add each line that it contains to the list of files\nand directories to compile. If `list` is `-`, read lines from `stdin`.\n\nWrite the byte-code files to their legacy locations and names, which may\noverwrite byte-code files created by another version of Python. The default is\nto write files to their PEP 3147 locations and names, which allows byte-code\nfiles from multiple versions of Python to coexist.\n\nControl the maximum recursion level for subdirectories. If this is given, then\n`-l` option will not be taken into account. python -m compileall <directory>\n-r 0 is equivalent to python -m compileall <directory> -l.\n\nUse N workers to compile the files within the given directory. If `0` is used,\nthen the result of `os.cpu_count()` will be used.\n\nControl how the generated byte-code files are invalidated at runtime. The\n`timestamp` value, means that `.pyc` files with the source timestamp and size\nembedded will be generated. The `checked-hash` and `unchecked-hash` values\ncause hash-based pycs to be generated. Hash-based pycs embed a hash of the\nsource file contents rather than a timestamp. See Cached bytecode invalidation\nfor more information on how Python validates bytecode cache files at runtime.\nThe default is `timestamp` if the `SOURCE_DATE_EPOCH` environment variable is\nnot set, and `checked-hash` if the `SOURCE_DATE_EPOCH` environment variable is\nset.\n\nCompile with the given optimization level. May be used multiple times to\ncompile for multiple levels at a time (for example, `compileall -o 1 -o 2`).\n\nIgnore symlinks pointing outside the given directory.\n\nIf two `.pyc` files with different optimization level have the same content,\nuse hard links to consolidate duplicate files.\n\nChanged in version 3.2: Added the `-i`, `-b` and `-h` options.\n\nChanged in version 3.5: Added the `-j`, `-r`, and `-qq` options. `-q` option\nwas changed to a multilevel value. `-b` will always produce a byte-code file\nending in `.pyc`, never `.pyo`.\n\nChanged in version 3.7: Added the `--invalidation-mode` option.\n\nChanged in version 3.9: Added the `-s`, `-p`, `-e` and `--hardlink-dupes`\noptions. Raised the default recursion limit from 10 to\n`sys.getrecursionlimit()`. Added the possibility to specify the `-o` option\nmultiple times.\n\nThere is no command-line option to control the optimization level used by the\n`compile()` function, because the Python interpreter itself already provides\nthe option: python -O -m compileall.\n\nSimilarly, the `compile()` function respects the `sys.pycache_prefix` setting.\nThe generated bytecode cache will only be useful if `compile()` is run with\nthe same `sys.pycache_prefix` (if any) that will be used at runtime.\n\nRecursively descend the directory tree named by dir, compiling all `.py` files\nalong the way. Return a true value if all the files compiled successfully, and\na false value otherwise.\n\nThe maxlevels parameter is used to limit the depth of the recursion; it\ndefaults to `sys.getrecursionlimit()`.\n\nIf ddir is given, it is prepended to the path to each file being compiled for\nuse in compilation time tracebacks, and is also compiled in to the byte-code\nfile, where it will be used in tracebacks and other messages in cases where\nthe source file does not exist at the time the byte-code file is executed.\n\nIf force is true, modules are re-compiled even if the timestamps are up to\ndate.\n\nIf rx is given, its search method is called on the complete path to each file\nconsidered for compilation, and if it returns a true value, the file is\nskipped.\n\nIf quiet is `False` or `0` (the default), the filenames and other information\nare printed to standard out. Set to `1`, only errors are printed. Set to `2`,\nall output is suppressed.\n\nIf legacy is true, byte-code files are written to their legacy locations and\nnames, which may overwrite byte-code files created by another version of\nPython. The default is to write files to their PEP 3147 locations and names,\nwhich allows byte-code files from multiple versions of Python to coexist.\n\noptimize specifies the optimization level for the compiler. It is passed to\nthe built-in `compile()` function. Accepts also a sequence of optimization\nlevels which lead to multiple compilations of one `.py` file in one call.\n\nThe argument workers specifies how many workers are used to compile files in\nparallel. The default is to not use multiple workers. If the platform can\u2019t\nuse multiple workers and workers argument is given, then sequential\ncompilation will be used as a fallback. If workers is 0, the number of cores\nin the system is used. If workers is lower than `0`, a `ValueError` will be\nraised.\n\ninvalidation_mode should be a member of the `py_compile.PycInvalidationMode`\nenum and controls how the generated pycs are invalidated at runtime.\n\nThe stripdir, prependdir and limit_sl_dest arguments correspond to the `-s`,\n`-p` and `-e` options described above. They may be specified as `str`, `bytes`\nor `os.PathLike`.\n\nIf hardlink_dupes is true and two `.pyc` files with different optimization\nlevel have the same content, use hard links to consolidate duplicate files.\n\nChanged in version 3.2: Added the legacy and optimize parameter.\n\nChanged in version 3.5: Added the workers parameter.\n\nChanged in version 3.5: quiet parameter was changed to a multilevel value.\n\nChanged in version 3.5: The legacy parameter only writes out `.pyc` files, not\n`.pyo` files no matter what the value of optimize is.\n\nChanged in version 3.6: Accepts a path-like object.\n\nChanged in version 3.7: The invalidation_mode parameter was added.\n\nChanged in version 3.7.2: The invalidation_mode parameter\u2019s default value is\nupdated to None.\n\nChanged in version 3.8: Setting workers to 0 now chooses the optimal number of\ncores.\n\nChanged in version 3.9: Added stripdir, prependdir, limit_sl_dest and\nhardlink_dupes arguments. Default value of maxlevels was changed from `10` to\n`sys.getrecursionlimit()`\n\nCompile the file with path fullname. Return a true value if the file compiled\nsuccessfully, and a false value otherwise.\n\nIf ddir is given, it is prepended to the path to the file being compiled for\nuse in compilation time tracebacks, and is also compiled in to the byte-code\nfile, where it will be used in tracebacks and other messages in cases where\nthe source file does not exist at the time the byte-code file is executed.\n\nIf rx is given, its search method is passed the full path name to the file\nbeing compiled, and if it returns a true value, the file is not compiled and\n`True` is returned.\n\nIf quiet is `False` or `0` (the default), the filenames and other information\nare printed to standard out. Set to `1`, only errors are printed. Set to `2`,\nall output is suppressed.\n\nIf legacy is true, byte-code files are written to their legacy locations and\nnames, which may overwrite byte-code files created by another version of\nPython. The default is to write files to their PEP 3147 locations and names,\nwhich allows byte-code files from multiple versions of Python to coexist.\n\noptimize specifies the optimization level for the compiler. It is passed to\nthe built-in `compile()` function. Accepts also a sequence of optimization\nlevels which lead to multiple compilations of one `.py` file in one call.\n\ninvalidation_mode should be a member of the `py_compile.PycInvalidationMode`\nenum and controls how the generated pycs are invalidated at runtime.\n\nThe stripdir, prependdir and limit_sl_dest arguments correspond to the `-s`,\n`-p` and `-e` options described above. They may be specified as `str`, `bytes`\nor `os.PathLike`.\n\nIf hardlink_dupes is true and two `.pyc` files with different optimization\nlevel have the same content, use hard links to consolidate duplicate files.\n\nNew in version 3.2.\n\nChanged in version 3.5: quiet parameter was changed to a multilevel value.\n\nChanged in version 3.5: The legacy parameter only writes out `.pyc` files, not\n`.pyo` files no matter what the value of optimize is.\n\nChanged in version 3.7: The invalidation_mode parameter was added.\n\nChanged in version 3.7.2: The invalidation_mode parameter\u2019s default value is\nupdated to None.\n\nChanged in version 3.9: Added stripdir, prependdir, limit_sl_dest and\nhardlink_dupes arguments.\n\nByte-compile all the `.py` files found along `sys.path`. Return a true value\nif all the files compiled successfully, and a false value otherwise.\n\nIf skip_curdir is true (the default), the current directory is not included in\nthe search. All other parameters are passed to the `compile_dir()` function.\nNote that unlike the other compile functions, `maxlevels` defaults to `0`.\n\nChanged in version 3.2: Added the legacy and optimize parameter.\n\nChanged in version 3.5: quiet parameter was changed to a multilevel value.\n\nChanged in version 3.5: The legacy parameter only writes out `.pyc` files, not\n`.pyo` files no matter what the value of optimize is.\n\nChanged in version 3.7: The invalidation_mode parameter was added.\n\nChanged in version 3.7.2: The invalidation_mode parameter\u2019s default value is\nupdated to None.\n\nTo force a recompile of all the `.py` files in the `Lib/` subdirectory and all\nits subdirectories:\n\nSee also\n\nByte-compile a single source file.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "compileall.compile_dir()", "path": "library/compileall#compileall.compile_dir", "type": "Language", "text": "\nRecursively descend the directory tree named by dir, compiling all `.py` files\nalong the way. Return a true value if all the files compiled successfully, and\na false value otherwise.\n\nThe maxlevels parameter is used to limit the depth of the recursion; it\ndefaults to `sys.getrecursionlimit()`.\n\nIf ddir is given, it is prepended to the path to each file being compiled for\nuse in compilation time tracebacks, and is also compiled in to the byte-code\nfile, where it will be used in tracebacks and other messages in cases where\nthe source file does not exist at the time the byte-code file is executed.\n\nIf force is true, modules are re-compiled even if the timestamps are up to\ndate.\n\nIf rx is given, its search method is called on the complete path to each file\nconsidered for compilation, and if it returns a true value, the file is\nskipped.\n\nIf quiet is `False` or `0` (the default), the filenames and other information\nare printed to standard out. Set to `1`, only errors are printed. Set to `2`,\nall output is suppressed.\n\nIf legacy is true, byte-code files are written to their legacy locations and\nnames, which may overwrite byte-code files created by another version of\nPython. The default is to write files to their PEP 3147 locations and names,\nwhich allows byte-code files from multiple versions of Python to coexist.\n\noptimize specifies the optimization level for the compiler. It is passed to\nthe built-in `compile()` function. Accepts also a sequence of optimization\nlevels which lead to multiple compilations of one `.py` file in one call.\n\nThe argument workers specifies how many workers are used to compile files in\nparallel. The default is to not use multiple workers. If the platform can\u2019t\nuse multiple workers and workers argument is given, then sequential\ncompilation will be used as a fallback. If workers is 0, the number of cores\nin the system is used. If workers is lower than `0`, a `ValueError` will be\nraised.\n\ninvalidation_mode should be a member of the `py_compile.PycInvalidationMode`\nenum and controls how the generated pycs are invalidated at runtime.\n\nThe stripdir, prependdir and limit_sl_dest arguments correspond to the `-s`,\n`-p` and `-e` options described above. They may be specified as `str`, `bytes`\nor `os.PathLike`.\n\nIf hardlink_dupes is true and two `.pyc` files with different optimization\nlevel have the same content, use hard links to consolidate duplicate files.\n\nChanged in version 3.2: Added the legacy and optimize parameter.\n\nChanged in version 3.5: Added the workers parameter.\n\nChanged in version 3.5: quiet parameter was changed to a multilevel value.\n\nChanged in version 3.5: The legacy parameter only writes out `.pyc` files, not\n`.pyo` files no matter what the value of optimize is.\n\nChanged in version 3.6: Accepts a path-like object.\n\nChanged in version 3.7: The invalidation_mode parameter was added.\n\nChanged in version 3.7.2: The invalidation_mode parameter\u2019s default value is\nupdated to None.\n\nChanged in version 3.8: Setting workers to 0 now chooses the optimal number of\ncores.\n\nChanged in version 3.9: Added stripdir, prependdir, limit_sl_dest and\nhardlink_dupes arguments. Default value of maxlevels was changed from `10` to\n`sys.getrecursionlimit()`\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "compileall.compile_file()", "path": "library/compileall#compileall.compile_file", "type": "Language", "text": "\nCompile the file with path fullname. Return a true value if the file compiled\nsuccessfully, and a false value otherwise.\n\nIf ddir is given, it is prepended to the path to the file being compiled for\nuse in compilation time tracebacks, and is also compiled in to the byte-code\nfile, where it will be used in tracebacks and other messages in cases where\nthe source file does not exist at the time the byte-code file is executed.\n\nIf rx is given, its search method is passed the full path name to the file\nbeing compiled, and if it returns a true value, the file is not compiled and\n`True` is returned.\n\nIf quiet is `False` or `0` (the default), the filenames and other information\nare printed to standard out. Set to `1`, only errors are printed. Set to `2`,\nall output is suppressed.\n\nIf legacy is true, byte-code files are written to their legacy locations and\nnames, which may overwrite byte-code files created by another version of\nPython. The default is to write files to their PEP 3147 locations and names,\nwhich allows byte-code files from multiple versions of Python to coexist.\n\noptimize specifies the optimization level for the compiler. It is passed to\nthe built-in `compile()` function. Accepts also a sequence of optimization\nlevels which lead to multiple compilations of one `.py` file in one call.\n\ninvalidation_mode should be a member of the `py_compile.PycInvalidationMode`\nenum and controls how the generated pycs are invalidated at runtime.\n\nThe stripdir, prependdir and limit_sl_dest arguments correspond to the `-s`,\n`-p` and `-e` options described above. They may be specified as `str`, `bytes`\nor `os.PathLike`.\n\nIf hardlink_dupes is true and two `.pyc` files with different optimization\nlevel have the same content, use hard links to consolidate duplicate files.\n\nNew in version 3.2.\n\nChanged in version 3.5: quiet parameter was changed to a multilevel value.\n\nChanged in version 3.5: The legacy parameter only writes out `.pyc` files, not\n`.pyo` files no matter what the value of optimize is.\n\nChanged in version 3.7: The invalidation_mode parameter was added.\n\nChanged in version 3.7.2: The invalidation_mode parameter\u2019s default value is\nupdated to None.\n\nChanged in version 3.9: Added stripdir, prependdir, limit_sl_dest and\nhardlink_dupes arguments.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "compileall.compile_path()", "path": "library/compileall#compileall.compile_path", "type": "Language", "text": "\nByte-compile all the `.py` files found along `sys.path`. Return a true value\nif all the files compiled successfully, and a false value otherwise.\n\nIf skip_curdir is true (the default), the current directory is not included in\nthe search. All other parameters are passed to the `compile_dir()` function.\nNote that unlike the other compile functions, `maxlevels` defaults to `0`.\n\nChanged in version 3.2: Added the legacy and optimize parameter.\n\nChanged in version 3.5: quiet parameter was changed to a multilevel value.\n\nChanged in version 3.5: The legacy parameter only writes out `.pyc` files, not\n`.pyo` files no matter what the value of optimize is.\n\nChanged in version 3.7: The invalidation_mode parameter was added.\n\nChanged in version 3.7.2: The invalidation_mode parameter\u2019s default value is\nupdated to None.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "complex", "path": "library/functions#complex", "type": "Built-in Functions", "text": "\nReturn a complex number with the value real \\+ imag*1j or convert a string or\nnumber to a complex number. If the first parameter is a string, it will be\ninterpreted as a complex number and the function must be called without a\nsecond parameter. The second parameter can never be a string. Each argument\nmay be any numeric type (including complex). If imag is omitted, it defaults\nto zero and the constructor serves as a numeric conversion like `int` and\n`float`. If both arguments are omitted, returns `0j`.\n\nFor a general Python object `x`, `complex(x)` delegates to `x.__complex__()`.\nIf `__complex__()` is not defined then it falls back to `__float__()`. If\n`__float__()` is not defined then it falls back to `__index__()`.\n\nNote\n\nWhen converting from a string, the string must not contain whitespace around\nthe central `+` or `-` operator. For example, `complex('1+2j')` is fine, but\n`complex('1 + 2j')` raises `ValueError`.\n\nThe complex type is described in Numeric Types \u2014 int, float, complex.\n\nChanged in version 3.6: Grouping digits with underscores as in code literals\nis allowed.\n\nChanged in version 3.8: Falls back to `__index__()` if `__complex__()` and\n`__float__()` are not defined.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures", "path": "library/concurrent.futures", "type": "Concurrent Execution", "text": "\nNew in version 3.2.\n\nSource code: Lib/concurrent/futures/thread.py and\nLib/concurrent/futures/process.py\n\nThe `concurrent.futures` module provides a high-level interface for\nasynchronously executing callables.\n\nThe asynchronous execution can be performed with threads, using\n`ThreadPoolExecutor`, or separate processes, using `ProcessPoolExecutor`. Both\nimplement the same interface, which is defined by the abstract `Executor`\nclass.\n\nAn abstract class that provides methods to execute calls asynchronously. It\nshould not be used directly, but through its concrete subclasses.\n\nSchedules the callable, fn, to be executed as `fn(*args **kwargs)` and returns\na `Future` object representing the execution of the callable.\n\nSimilar to `map(func, *iterables)` except:\n\nThe returned iterator raises a `concurrent.futures.TimeoutError` if\n`__next__()` is called and the result isn\u2019t available after timeout seconds\nfrom the original call to `Executor.map()`. timeout can be an int or a float.\nIf timeout is not specified or `None`, there is no limit to the wait time.\n\nIf a func call raises an exception, then that exception will be raised when\nits value is retrieved from the iterator.\n\nWhen using `ProcessPoolExecutor`, this method chops iterables into a number of\nchunks which it submits to the pool as separate tasks. The (approximate) size\nof these chunks can be specified by setting chunksize to a positive integer.\nFor very long iterables, using a large value for chunksize can significantly\nimprove performance compared to the default size of 1. With\n`ThreadPoolExecutor`, chunksize has no effect.\n\nChanged in version 3.5: Added the chunksize argument.\n\nSignal the executor that it should free any resources that it is using when\nthe currently pending futures are done executing. Calls to `Executor.submit()`\nand `Executor.map()` made after shutdown will raise `RuntimeError`.\n\nIf wait is `True` then this method will not return until all the pending\nfutures are done executing and the resources associated with the executor have\nbeen freed. If wait is `False` then this method will return immediately and\nthe resources associated with the executor will be freed when all pending\nfutures are done executing. Regardless of the value of wait, the entire Python\nprogram will not exit until all pending futures are done executing.\n\nIf cancel_futures is `True`, this method will cancel all pending futures that\nthe executor has not started running. Any futures that are completed or\nrunning won\u2019t be cancelled, regardless of the value of cancel_futures.\n\nIf both cancel_futures and wait are `True`, all futures that the executor has\nstarted running will be completed prior to this method returning. The\nremaining futures are cancelled.\n\nYou can avoid having to call this method explicitly if you use the `with`\nstatement, which will shutdown the `Executor` (waiting as if\n`Executor.shutdown()` were called with wait set to `True`):\n\nChanged in version 3.9: Added cancel_futures.\n\n`ThreadPoolExecutor` is an `Executor` subclass that uses a pool of threads to\nexecute calls asynchronously.\n\nDeadlocks can occur when the callable associated with a `Future` waits on the\nresults of another `Future`. For example:\n\nAnd:\n\nAn `Executor` subclass that uses a pool of at most max_workers threads to\nexecute calls asynchronously.\n\ninitializer is an optional callable that is called at the start of each worker\nthread; initargs is a tuple of arguments passed to the initializer. Should\ninitializer raise an exception, all currently pending jobs will raise a\n`BrokenThreadPool`, as well as any attempt to submit more jobs to the pool.\n\nChanged in version 3.5: If max_workers is `None` or not given, it will default\nto the number of processors on the machine, multiplied by `5`, assuming that\n`ThreadPoolExecutor` is often used to overlap I/O instead of CPU work and the\nnumber of workers should be higher than the number of workers for\n`ProcessPoolExecutor`.\n\nNew in version 3.6: The thread_name_prefix argument was added to allow users\nto control the `threading.Thread` names for worker threads created by the pool\nfor easier debugging.\n\nChanged in version 3.7: Added the initializer and initargs arguments.\n\nChanged in version 3.8: Default value of max_workers is changed to `min(32,\nos.cpu_count() + 4)`. This default value preserves at least 5 workers for I/O\nbound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which\nrelease the GIL. And it avoids using very large resources implicitly on many-\ncore machines.\n\nThreadPoolExecutor now reuses idle worker threads before starting max_workers\nworker threads too.\n\nThe `ProcessPoolExecutor` class is an `Executor` subclass that uses a pool of\nprocesses to execute calls asynchronously. `ProcessPoolExecutor` uses the\n`multiprocessing` module, which allows it to side-step the Global Interpreter\nLock but also means that only picklable objects can be executed and returned.\n\nThe `__main__` module must be importable by worker subprocesses. This means\nthat `ProcessPoolExecutor` will not work in the interactive interpreter.\n\nCalling `Executor` or `Future` methods from a callable submitted to a\n`ProcessPoolExecutor` will result in deadlock.\n\nAn `Executor` subclass that executes calls asynchronously using a pool of at\nmost max_workers processes. If max_workers is `None` or not given, it will\ndefault to the number of processors on the machine. If max_workers is less\nthan or equal to `0`, then a `ValueError` will be raised. On Windows,\nmax_workers must be less than or equal to `61`. If it is not then `ValueError`\nwill be raised. If max_workers is `None`, then the default chosen will be at\nmost `61`, even if more processors are available. mp_context can be a\nmultiprocessing context or None. It will be used to launch the workers. If\nmp_context is `None` or not given, the default multiprocessing context is\nused.\n\ninitializer is an optional callable that is called at the start of each worker\nprocess; initargs is a tuple of arguments passed to the initializer. Should\ninitializer raise an exception, all currently pending jobs will raise a\n`BrokenProcessPool`, as well as any attempt to submit more jobs to the pool.\n\nChanged in version 3.3: When one of the worker processes terminates abruptly,\na `BrokenProcessPool` error is now raised. Previously, behaviour was undefined\nbut operations on the executor or its futures would often freeze or deadlock.\n\nChanged in version 3.7: The mp_context argument was added to allow users to\ncontrol the start_method for worker processes created by the pool.\n\nAdded the initializer and initargs arguments.\n\nThe `Future` class encapsulates the asynchronous execution of a callable.\n`Future` instances are created by `Executor.submit()`.\n\nEncapsulates the asynchronous execution of a callable. `Future` instances are\ncreated by `Executor.submit()` and should not be created directly except for\ntesting.\n\nAttempt to cancel the call. If the call is currently being executed or\nfinished running and cannot be cancelled then the method will return `False`,\notherwise the call will be cancelled and the method will return `True`.\n\nReturn `True` if the call was successfully cancelled.\n\nReturn `True` if the call is currently being executed and cannot be cancelled.\n\nReturn `True` if the call was successfully cancelled or finished running.\n\nReturn the value returned by the call. If the call hasn\u2019t yet completed then\nthis method will wait up to timeout seconds. If the call hasn\u2019t completed in\ntimeout seconds, then a `concurrent.futures.TimeoutError` will be raised.\ntimeout can be an int or float. If timeout is not specified or `None`, there\nis no limit to the wait time.\n\nIf the future is cancelled before completing then `CancelledError` will be\nraised.\n\nIf the call raised, this method will raise the same exception.\n\nReturn the exception raised by the call. If the call hasn\u2019t yet completed then\nthis method will wait up to timeout seconds. If the call hasn\u2019t completed in\ntimeout seconds, then a `concurrent.futures.TimeoutError` will be raised.\ntimeout can be an int or float. If timeout is not specified or `None`, there\nis no limit to the wait time.\n\nIf the future is cancelled before completing then `CancelledError` will be\nraised.\n\nIf the call completed without raising, `None` is returned.\n\nAttaches the callable fn to the future. fn will be called, with the future as\nits only argument, when the future is cancelled or finishes running.\n\nAdded callables are called in the order that they were added and are always\ncalled in a thread belonging to the process that added them. If the callable\nraises an `Exception` subclass, it will be logged and ignored. If the callable\nraises a `BaseException` subclass, the behavior is undefined.\n\nIf the future has already completed or been cancelled, fn will be called\nimmediately.\n\nThe following `Future` methods are meant for use in unit tests and `Executor`\nimplementations.\n\nThis method should only be called by `Executor` implementations before\nexecuting the work associated with the `Future` and by unit tests.\n\nIf the method returns `False` then the `Future` was cancelled, i.e.\n`Future.cancel()` was called and returned `True`. Any threads waiting on the\n`Future` completing (i.e. through `as_completed()` or `wait()`) will be woken\nup.\n\nIf the method returns `True` then the `Future` was not cancelled and has been\nput in the running state, i.e. calls to `Future.running()` will return `True`.\n\nThis method can only be called once and cannot be called after\n`Future.set_result()` or `Future.set_exception()` have been called.\n\nSets the result of the work associated with the `Future` to result.\n\nThis method should only be used by `Executor` implementations and unit tests.\n\nChanged in version 3.8: This method raises\n`concurrent.futures.InvalidStateError` if the `Future` is already done.\n\nSets the result of the work associated with the `Future` to the `Exception`\nexception.\n\nThis method should only be used by `Executor` implementations and unit tests.\n\nChanged in version 3.8: This method raises\n`concurrent.futures.InvalidStateError` if the `Future` is already done.\n\nWait for the `Future` instances (possibly created by different `Executor`\ninstances) given by fs to complete. Returns a named 2-tuple of sets. The first\nset, named `done`, contains the futures that completed (finished or cancelled\nfutures) before the wait completed. The second set, named `not_done`, contains\nthe futures that did not complete (pending or running futures).\n\ntimeout can be used to control the maximum number of seconds to wait before\nreturning. timeout can be an int or float. If timeout is not specified or\n`None`, there is no limit to the wait time.\n\nreturn_when indicates when this function should return. It must be one of the\nfollowing constants:\n\nConstant\n\nDescription\n\n`FIRST_COMPLETED`\n\nThe function will return when any future finishes or is cancelled.\n\n`FIRST_EXCEPTION`\n\nThe function will return when any future finishes by raising an exception. If\nno future raises an exception then it is equivalent to `ALL_COMPLETED`.\n\n`ALL_COMPLETED`\n\nThe function will return when all futures finish or are cancelled.\n\nReturns an iterator over the `Future` instances (possibly created by different\n`Executor` instances) given by fs that yields futures as they complete\n(finished or cancelled futures). Any futures given by fs that are duplicated\nwill be returned once. Any futures that completed before `as_completed()` is\ncalled will be yielded first. The returned iterator raises a\n`concurrent.futures.TimeoutError` if `__next__()` is called and the result\nisn\u2019t available after timeout seconds from the original call to\n`as_completed()`. timeout can be an int or float. If timeout is not specified\nor `None`, there is no limit to the wait time.\n\nSee also\n\nThe proposal which described this feature for inclusion in the Python standard\nlibrary.\n\nRaised when a future is cancelled.\n\nRaised when a future operation exceeds the given timeout.\n\nDerived from `RuntimeError`, this exception class is raised when an executor\nis broken for some reason, and cannot be used to submit or execute new tasks.\n\nNew in version 3.7.\n\nRaised when an operation is performed on a future that is not allowed in the\ncurrent state.\n\nNew in version 3.8.\n\nDerived from `BrokenExecutor`, this exception class is raised when one of the\nworkers of a `ThreadPoolExecutor` has failed initializing.\n\nNew in version 3.7.\n\nDerived from `BrokenExecutor` (formerly `RuntimeError`), this exception class\nis raised when one of the workers of a `ProcessPoolExecutor` has terminated in\na non-clean fashion (for example, if it was killed from the outside).\n\nNew in version 3.3.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.as_completed()", "path": "library/concurrent.futures#concurrent.futures.as_completed", "type": "Concurrent Execution", "text": "\nReturns an iterator over the `Future` instances (possibly created by different\n`Executor` instances) given by fs that yields futures as they complete\n(finished or cancelled futures). Any futures given by fs that are duplicated\nwill be returned once. Any futures that completed before `as_completed()` is\ncalled will be yielded first. The returned iterator raises a\n`concurrent.futures.TimeoutError` if `__next__()` is called and the result\nisn\u2019t available after timeout seconds from the original call to\n`as_completed()`. timeout can be an int or float. If timeout is not specified\nor `None`, there is no limit to the wait time.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.BrokenExecutor", "path": "library/concurrent.futures#concurrent.futures.BrokenExecutor", "type": "Concurrent Execution", "text": "\nDerived from `RuntimeError`, this exception class is raised when an executor\nis broken for some reason, and cannot be used to submit or execute new tasks.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.CancelledError", "path": "library/concurrent.futures#concurrent.futures.CancelledError", "type": "Concurrent Execution", "text": "\nRaised when a future is cancelled.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Executor", "path": "library/concurrent.futures#concurrent.futures.Executor", "type": "Concurrent Execution", "text": "\nAn abstract class that provides methods to execute calls asynchronously. It\nshould not be used directly, but through its concrete subclasses.\n\nSchedules the callable, fn, to be executed as `fn(*args **kwargs)` and returns\na `Future` object representing the execution of the callable.\n\nSimilar to `map(func, *iterables)` except:\n\nThe returned iterator raises a `concurrent.futures.TimeoutError` if\n`__next__()` is called and the result isn\u2019t available after timeout seconds\nfrom the original call to `Executor.map()`. timeout can be an int or a float.\nIf timeout is not specified or `None`, there is no limit to the wait time.\n\nIf a func call raises an exception, then that exception will be raised when\nits value is retrieved from the iterator.\n\nWhen using `ProcessPoolExecutor`, this method chops iterables into a number of\nchunks which it submits to the pool as separate tasks. The (approximate) size\nof these chunks can be specified by setting chunksize to a positive integer.\nFor very long iterables, using a large value for chunksize can significantly\nimprove performance compared to the default size of 1. With\n`ThreadPoolExecutor`, chunksize has no effect.\n\nChanged in version 3.5: Added the chunksize argument.\n\nSignal the executor that it should free any resources that it is using when\nthe currently pending futures are done executing. Calls to `Executor.submit()`\nand `Executor.map()` made after shutdown will raise `RuntimeError`.\n\nIf wait is `True` then this method will not return until all the pending\nfutures are done executing and the resources associated with the executor have\nbeen freed. If wait is `False` then this method will return immediately and\nthe resources associated with the executor will be freed when all pending\nfutures are done executing. Regardless of the value of wait, the entire Python\nprogram will not exit until all pending futures are done executing.\n\nIf cancel_futures is `True`, this method will cancel all pending futures that\nthe executor has not started running. Any futures that are completed or\nrunning won\u2019t be cancelled, regardless of the value of cancel_futures.\n\nIf both cancel_futures and wait are `True`, all futures that the executor has\nstarted running will be completed prior to this method returning. The\nremaining futures are cancelled.\n\nYou can avoid having to call this method explicitly if you use the `with`\nstatement, which will shutdown the `Executor` (waiting as if\n`Executor.shutdown()` were called with wait set to `True`):\n\nChanged in version 3.9: Added cancel_futures.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Executor.map()", "path": "library/concurrent.futures#concurrent.futures.Executor.map", "type": "Concurrent Execution", "text": "\nSimilar to `map(func, *iterables)` except:\n\nThe returned iterator raises a `concurrent.futures.TimeoutError` if\n`__next__()` is called and the result isn\u2019t available after timeout seconds\nfrom the original call to `Executor.map()`. timeout can be an int or a float.\nIf timeout is not specified or `None`, there is no limit to the wait time.\n\nIf a func call raises an exception, then that exception will be raised when\nits value is retrieved from the iterator.\n\nWhen using `ProcessPoolExecutor`, this method chops iterables into a number of\nchunks which it submits to the pool as separate tasks. The (approximate) size\nof these chunks can be specified by setting chunksize to a positive integer.\nFor very long iterables, using a large value for chunksize can significantly\nimprove performance compared to the default size of 1. With\n`ThreadPoolExecutor`, chunksize has no effect.\n\nChanged in version 3.5: Added the chunksize argument.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Executor.shutdown()", "path": "library/concurrent.futures#concurrent.futures.Executor.shutdown", "type": "Concurrent Execution", "text": "\nSignal the executor that it should free any resources that it is using when\nthe currently pending futures are done executing. Calls to `Executor.submit()`\nand `Executor.map()` made after shutdown will raise `RuntimeError`.\n\nIf wait is `True` then this method will not return until all the pending\nfutures are done executing and the resources associated with the executor have\nbeen freed. If wait is `False` then this method will return immediately and\nthe resources associated with the executor will be freed when all pending\nfutures are done executing. Regardless of the value of wait, the entire Python\nprogram will not exit until all pending futures are done executing.\n\nIf cancel_futures is `True`, this method will cancel all pending futures that\nthe executor has not started running. Any futures that are completed or\nrunning won\u2019t be cancelled, regardless of the value of cancel_futures.\n\nIf both cancel_futures and wait are `True`, all futures that the executor has\nstarted running will be completed prior to this method returning. The\nremaining futures are cancelled.\n\nYou can avoid having to call this method explicitly if you use the `with`\nstatement, which will shutdown the `Executor` (waiting as if\n`Executor.shutdown()` were called with wait set to `True`):\n\nChanged in version 3.9: Added cancel_futures.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Executor.submit()", "path": "library/concurrent.futures#concurrent.futures.Executor.submit", "type": "Concurrent Execution", "text": "\nSchedules the callable, fn, to be executed as `fn(*args **kwargs)` and returns\na `Future` object representing the execution of the callable.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future", "path": "library/concurrent.futures#concurrent.futures.Future", "type": "Concurrent Execution", "text": "\nEncapsulates the asynchronous execution of a callable. `Future` instances are\ncreated by `Executor.submit()` and should not be created directly except for\ntesting.\n\nAttempt to cancel the call. If the call is currently being executed or\nfinished running and cannot be cancelled then the method will return `False`,\notherwise the call will be cancelled and the method will return `True`.\n\nReturn `True` if the call was successfully cancelled.\n\nReturn `True` if the call is currently being executed and cannot be cancelled.\n\nReturn `True` if the call was successfully cancelled or finished running.\n\nReturn the value returned by the call. If the call hasn\u2019t yet completed then\nthis method will wait up to timeout seconds. If the call hasn\u2019t completed in\ntimeout seconds, then a `concurrent.futures.TimeoutError` will be raised.\ntimeout can be an int or float. If timeout is not specified or `None`, there\nis no limit to the wait time.\n\nIf the future is cancelled before completing then `CancelledError` will be\nraised.\n\nIf the call raised, this method will raise the same exception.\n\nReturn the exception raised by the call. If the call hasn\u2019t yet completed then\nthis method will wait up to timeout seconds. If the call hasn\u2019t completed in\ntimeout seconds, then a `concurrent.futures.TimeoutError` will be raised.\ntimeout can be an int or float. If timeout is not specified or `None`, there\nis no limit to the wait time.\n\nIf the future is cancelled before completing then `CancelledError` will be\nraised.\n\nIf the call completed without raising, `None` is returned.\n\nAttaches the callable fn to the future. fn will be called, with the future as\nits only argument, when the future is cancelled or finishes running.\n\nAdded callables are called in the order that they were added and are always\ncalled in a thread belonging to the process that added them. If the callable\nraises an `Exception` subclass, it will be logged and ignored. If the callable\nraises a `BaseException` subclass, the behavior is undefined.\n\nIf the future has already completed or been cancelled, fn will be called\nimmediately.\n\nThe following `Future` methods are meant for use in unit tests and `Executor`\nimplementations.\n\nThis method should only be called by `Executor` implementations before\nexecuting the work associated with the `Future` and by unit tests.\n\nIf the method returns `False` then the `Future` was cancelled, i.e.\n`Future.cancel()` was called and returned `True`. Any threads waiting on the\n`Future` completing (i.e. through `as_completed()` or `wait()`) will be woken\nup.\n\nIf the method returns `True` then the `Future` was not cancelled and has been\nput in the running state, i.e. calls to `Future.running()` will return `True`.\n\nThis method can only be called once and cannot be called after\n`Future.set_result()` or `Future.set_exception()` have been called.\n\nSets the result of the work associated with the `Future` to result.\n\nThis method should only be used by `Executor` implementations and unit tests.\n\nChanged in version 3.8: This method raises\n`concurrent.futures.InvalidStateError` if the `Future` is already done.\n\nSets the result of the work associated with the `Future` to the `Exception`\nexception.\n\nThis method should only be used by `Executor` implementations and unit tests.\n\nChanged in version 3.8: This method raises\n`concurrent.futures.InvalidStateError` if the `Future` is already done.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.add_done_callback()", "path": "library/concurrent.futures#concurrent.futures.Future.add_done_callback", "type": "Concurrent Execution", "text": "\nAttaches the callable fn to the future. fn will be called, with the future as\nits only argument, when the future is cancelled or finishes running.\n\nAdded callables are called in the order that they were added and are always\ncalled in a thread belonging to the process that added them. If the callable\nraises an `Exception` subclass, it will be logged and ignored. If the callable\nraises a `BaseException` subclass, the behavior is undefined.\n\nIf the future has already completed or been cancelled, fn will be called\nimmediately.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.cancel()", "path": "library/concurrent.futures#concurrent.futures.Future.cancel", "type": "Concurrent Execution", "text": "\nAttempt to cancel the call. If the call is currently being executed or\nfinished running and cannot be cancelled then the method will return `False`,\notherwise the call will be cancelled and the method will return `True`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.cancelled()", "path": "library/concurrent.futures#concurrent.futures.Future.cancelled", "type": "Concurrent Execution", "text": "\nReturn `True` if the call was successfully cancelled.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.done()", "path": "library/concurrent.futures#concurrent.futures.Future.done", "type": "Concurrent Execution", "text": "\nReturn `True` if the call was successfully cancelled or finished running.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.exception()", "path": "library/concurrent.futures#concurrent.futures.Future.exception", "type": "Concurrent Execution", "text": "\nReturn the exception raised by the call. If the call hasn\u2019t yet completed then\nthis method will wait up to timeout seconds. If the call hasn\u2019t completed in\ntimeout seconds, then a `concurrent.futures.TimeoutError` will be raised.\ntimeout can be an int or float. If timeout is not specified or `None`, there\nis no limit to the wait time.\n\nIf the future is cancelled before completing then `CancelledError` will be\nraised.\n\nIf the call completed without raising, `None` is returned.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.result()", "path": "library/concurrent.futures#concurrent.futures.Future.result", "type": "Concurrent Execution", "text": "\nReturn the value returned by the call. If the call hasn\u2019t yet completed then\nthis method will wait up to timeout seconds. If the call hasn\u2019t completed in\ntimeout seconds, then a `concurrent.futures.TimeoutError` will be raised.\ntimeout can be an int or float. If timeout is not specified or `None`, there\nis no limit to the wait time.\n\nIf the future is cancelled before completing then `CancelledError` will be\nraised.\n\nIf the call raised, this method will raise the same exception.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.running()", "path": "library/concurrent.futures#concurrent.futures.Future.running", "type": "Concurrent Execution", "text": "\nReturn `True` if the call is currently being executed and cannot be cancelled.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.set_exception()", "path": "library/concurrent.futures#concurrent.futures.Future.set_exception", "type": "Concurrent Execution", "text": "\nSets the result of the work associated with the `Future` to the `Exception`\nexception.\n\nThis method should only be used by `Executor` implementations and unit tests.\n\nChanged in version 3.8: This method raises\n`concurrent.futures.InvalidStateError` if the `Future` is already done.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.set_result()", "path": "library/concurrent.futures#concurrent.futures.Future.set_result", "type": "Concurrent Execution", "text": "\nSets the result of the work associated with the `Future` to result.\n\nThis method should only be used by `Executor` implementations and unit tests.\n\nChanged in version 3.8: This method raises\n`concurrent.futures.InvalidStateError` if the `Future` is already done.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.Future.set_running_or_notify_cancel()", "path": "library/concurrent.futures#concurrent.futures.Future.set_running_or_notify_cancel", "type": "Concurrent Execution", "text": "\nThis method should only be called by `Executor` implementations before\nexecuting the work associated with the `Future` and by unit tests.\n\nIf the method returns `False` then the `Future` was cancelled, i.e.\n`Future.cancel()` was called and returned `True`. Any threads waiting on the\n`Future` completing (i.e. through `as_completed()` or `wait()`) will be woken\nup.\n\nIf the method returns `True` then the `Future` was not cancelled and has been\nput in the running state, i.e. calls to `Future.running()` will return `True`.\n\nThis method can only be called once and cannot be called after\n`Future.set_result()` or `Future.set_exception()` have been called.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.InvalidStateError", "path": "library/concurrent.futures#concurrent.futures.InvalidStateError", "type": "Concurrent Execution", "text": "\nRaised when an operation is performed on a future that is not allowed in the\ncurrent state.\n\nNew in version 3.8.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.process.BrokenProcessPool", "path": "library/concurrent.futures#concurrent.futures.process.BrokenProcessPool", "type": "Concurrent Execution", "text": "\nDerived from `BrokenExecutor` (formerly `RuntimeError`), this exception class\nis raised when one of the workers of a `ProcessPoolExecutor` has terminated in\na non-clean fashion (for example, if it was killed from the outside).\n\nNew in version 3.3.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.ProcessPoolExecutor", "path": "library/concurrent.futures#concurrent.futures.ProcessPoolExecutor", "type": "Concurrent Execution", "text": "\nAn `Executor` subclass that executes calls asynchronously using a pool of at\nmost max_workers processes. If max_workers is `None` or not given, it will\ndefault to the number of processors on the machine. If max_workers is less\nthan or equal to `0`, then a `ValueError` will be raised. On Windows,\nmax_workers must be less than or equal to `61`. If it is not then `ValueError`\nwill be raised. If max_workers is `None`, then the default chosen will be at\nmost `61`, even if more processors are available. mp_context can be a\nmultiprocessing context or None. It will be used to launch the workers. If\nmp_context is `None` or not given, the default multiprocessing context is\nused.\n\ninitializer is an optional callable that is called at the start of each worker\nprocess; initargs is a tuple of arguments passed to the initializer. Should\ninitializer raise an exception, all currently pending jobs will raise a\n`BrokenProcessPool`, as well as any attempt to submit more jobs to the pool.\n\nChanged in version 3.3: When one of the worker processes terminates abruptly,\na `BrokenProcessPool` error is now raised. Previously, behaviour was undefined\nbut operations on the executor or its futures would often freeze or deadlock.\n\nChanged in version 3.7: The mp_context argument was added to allow users to\ncontrol the start_method for worker processes created by the pool.\n\nAdded the initializer and initargs arguments.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.thread.BrokenThreadPool", "path": "library/concurrent.futures#concurrent.futures.thread.BrokenThreadPool", "type": "Concurrent Execution", "text": "\nDerived from `BrokenExecutor`, this exception class is raised when one of the\nworkers of a `ThreadPoolExecutor` has failed initializing.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.ThreadPoolExecutor", "path": "library/concurrent.futures#concurrent.futures.ThreadPoolExecutor", "type": "Concurrent Execution", "text": "\nAn `Executor` subclass that uses a pool of at most max_workers threads to\nexecute calls asynchronously.\n\ninitializer is an optional callable that is called at the start of each worker\nthread; initargs is a tuple of arguments passed to the initializer. Should\ninitializer raise an exception, all currently pending jobs will raise a\n`BrokenThreadPool`, as well as any attempt to submit more jobs to the pool.\n\nChanged in version 3.5: If max_workers is `None` or not given, it will default\nto the number of processors on the machine, multiplied by `5`, assuming that\n`ThreadPoolExecutor` is often used to overlap I/O instead of CPU work and the\nnumber of workers should be higher than the number of workers for\n`ProcessPoolExecutor`.\n\nNew in version 3.6: The thread_name_prefix argument was added to allow users\nto control the `threading.Thread` names for worker threads created by the pool\nfor easier debugging.\n\nChanged in version 3.7: Added the initializer and initargs arguments.\n\nChanged in version 3.8: Default value of max_workers is changed to `min(32,\nos.cpu_count() + 4)`. This default value preserves at least 5 workers for I/O\nbound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which\nrelease the GIL. And it avoids using very large resources implicitly on many-\ncore machines.\n\nThreadPoolExecutor now reuses idle worker threads before starting max_workers\nworker threads too.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.TimeoutError", "path": "library/concurrent.futures#concurrent.futures.TimeoutError", "type": "Concurrent Execution", "text": "\nRaised when a future operation exceeds the given timeout.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "concurrent.futures.wait()", "path": "library/concurrent.futures#concurrent.futures.wait", "type": "Concurrent Execution", "text": "\nWait for the `Future` instances (possibly created by different `Executor`\ninstances) given by fs to complete. Returns a named 2-tuple of sets. The first\nset, named `done`, contains the futures that completed (finished or cancelled\nfutures) before the wait completed. The second set, named `not_done`, contains\nthe futures that did not complete (pending or running futures).\n\ntimeout can be used to control the maximum number of seconds to wait before\nreturning. timeout can be an int or float. If timeout is not specified or\n`None`, there is no limit to the wait time.\n\nreturn_when indicates when this function should return. It must be one of the\nfollowing constants:\n\nConstant\n\nDescription\n\n`FIRST_COMPLETED`\n\nThe function will return when any future finishes or is cancelled.\n\n`FIRST_EXCEPTION`\n\nThe function will return when any future finishes by raising an exception. If\nno future raises an exception then it is equivalent to `ALL_COMPLETED`.\n\n`ALL_COMPLETED`\n\nThe function will return when all futures finish or are cancelled.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser", "path": "library/configparser", "type": "File Formats", "text": "\nSource code: Lib/configparser.py\n\nThis module provides the `ConfigParser` class which implements a basic\nconfiguration language which provides a structure similar to what\u2019s found in\nMicrosoft Windows INI files. You can use this to write Python programs which\ncan be customized by end users easily.\n\nNote\n\nThis library does not interpret or write the value-type prefixes used in the\nWindows Registry extended version of INI syntax.\n\nSee also\n\nSupport for creating Unix shell-like mini-languages which can be used as an\nalternate format for application configuration files.\n\nThe json module implements a subset of JavaScript syntax which can also be\nused for this purpose.\n\nLet\u2019s take a very basic configuration file that looks like this:\n\nThe structure of INI files is described in the following section. Essentially,\nthe file consists of sections, each of which contains keys with values.\n`configparser` classes can read and write such files. Let\u2019s start by creating\nthe above configuration file programmatically.\n\nAs you can see, we can treat a config parser much like a dictionary. There are\ndifferences, outlined later, but the behavior is very close to what you would\nexpect from a dictionary.\n\nNow that we have created and saved a configuration file, let\u2019s read it back\nand explore the data it holds.\n\nAs we can see above, the API is pretty straightforward. The only bit of magic\ninvolves the `DEFAULT` section which provides default values for all other\nsections 1. Note also that keys in sections are case-insensitive and stored in\nlowercase 1.\n\nConfig parsers do not guess datatypes of values in configuration files, always\nstoring them internally as strings. This means that if you need other\ndatatypes, you should convert on your own:\n\nSince this task is so common, config parsers provide a range of handy getter\nmethods to handle integers, floats and booleans. The last one is the most\ninteresting because simply passing the value to `bool()` would do no good\nsince `bool('False')` is still `True`. This is why config parsers also provide\n`getboolean()`. This method is case-insensitive and recognizes Boolean values\nfrom `'yes'`/`'no'`, `'on'`/`'off'`, `'true'`/`'false'` and `'1'`/`'0'` 1. For\nexample:\n\nApart from `getboolean()`, config parsers also provide equivalent `getint()`\nand `getfloat()` methods. You can register your own converters and customize\nthe provided ones. 1\n\nAs with a dictionary, you can use a section\u2019s `get()` method to provide\nfallback values:\n\nPlease note that default values have precedence over fallback values. For\ninstance, in our example the `'CompressionLevel'` key was specified only in\nthe `'DEFAULT'` section. If we try to get it from the section\n`'topsecret.server.com'`, we will always get the default, even if we specify a\nfallback:\n\nOne more thing to be aware of is that the parser-level `get()` method provides\na custom, more complex interface, maintained for backwards compatibility. When\nusing this method, a fallback value can be provided via the `fallback`\nkeyword-only argument:\n\nThe same `fallback` argument can be used with the `getint()`, `getfloat()` and\n`getboolean()` methods, for example:\n\nA configuration file consists of sections, each led by a `[section]` header,\nfollowed by key/value entries separated by a specific string (`=` or `:` by\ndefault 1). By default, section names are case sensitive but keys are not 1.\nLeading and trailing whitespace is removed from keys and values. Values can be\nomitted, in which case the key/value delimiter may also be left out. Values\ncan also span multiple lines, as long as they are indented deeper than the\nfirst line of the value. Depending on the parser\u2019s mode, blank lines may be\ntreated as parts of multiline values or ignored.\n\nConfiguration files may include comments, prefixed by specific characters (`#`\nand `;` by default 1). Comments may appear on their own on an otherwise empty\nline, possibly indented. 1\n\nFor example:\n\nOn top of the core functionality, `ConfigParser` supports interpolation. This\nmeans values can be preprocessed before returning them from `get()` calls.\n\nThe default implementation used by `ConfigParser`. It enables values to\ncontain format strings which refer to other values in the same section, or\nvalues in the special default section 1. Additional default values can be\nprovided on initialization.\n\nFor example:\n\nIn the example above, `ConfigParser` with interpolation set to\n`BasicInterpolation()` would resolve `%(home_dir)s` to the value of `home_dir`\n(`/Users` in this case). `%(my_dir)s` in effect would resolve to\n`/Users/lumberjack`. All interpolations are done on demand so keys used in the\nchain of references do not have to be specified in any specific order in the\nconfiguration file.\n\nWith `interpolation` set to `None`, the parser would simply return\n`%(my_dir)s/Pictures` as the value of `my_pictures` and\n`%(home_dir)s/lumberjack` as the value of `my_dir`.\n\nAn alternative handler for interpolation which implements a more advanced\nsyntax, used for instance in `zc.buildout`. Extended interpolation is using\n`${section:option}` to denote a value from a foreign section. Interpolation\ncan span multiple levels. For convenience, if the `section:` part is omitted,\ninterpolation defaults to the current section (and possibly the default values\nfrom the special section).\n\nFor example, the configuration specified above with basic interpolation, would\nlook like this with extended interpolation:\n\nValues from other sections can be fetched as well:\n\nNew in version 3.2.\n\nMapping protocol access is a generic name for functionality that enables using\ncustom objects as if they were dictionaries. In case of `configparser`, the\nmapping interface implementation is using the `parser['section']['option']`\nnotation.\n\n`parser['section']` in particular returns a proxy for the section\u2019s data in\nthe parser. This means that the values are not copied but they are taken from\nthe original parser on demand. What\u2019s even more important is that when values\nare changed on a section proxy, they are actually mutated in the original\nparser.\n\n`configparser` objects behave as close to actual dictionaries as possible. The\nmapping interface is complete and adheres to the `MutableMapping` ABC.\nHowever, there are a few differences that should be taken into account:\n\nBy default, all keys in sections are accessible in a case-insensitive manner\n1. E.g. `for option in parser[\"section\"]` yields only `optionxform`\u2019ed option\nkey names. This means lowercased keys by default. At the same time, for a\nsection that holds the key `'a'`, both expressions return `True`:\n\n`DEFAULTSECT` cannot be removed from the parser:\n\nThe mapping protocol is implemented on top of the existing legacy API so that\nsubclasses overriding the original interface still should have mappings\nworking as expected.\n\nThere are nearly as many INI format variants as there are applications using\nit. `configparser` goes a long way to provide support for the largest sensible\nset of INI styles available. The default functionality is mainly dictated by\nhistorical background and it\u2019s very likely that you will want to customize\nsome of the features.\n\nThe most common way to change the way a specific config parser works is to use\nthe `__init__()` options:\n\ndefaults, default value: `None`\n\nThis option accepts a dictionary of key-value pairs which will be initially\nput in the `DEFAULT` section. This makes for an elegant way to support concise\nconfiguration files that don\u2019t specify values which are the same as the\ndocumented default.\n\nHint: if you want to specify default values for a specific section, use\n`read_dict()` before you read the actual file.\n\ndict_type, default value: `dict`\n\nThis option has a major impact on how the mapping protocol will behave and how\nthe written configuration files look. With the standard dictionary, every\nsection is stored in the order they were added to the parser. Same goes for\noptions within sections.\n\nAn alternative dictionary type can be used for example to sort sections and\noptions on write-back.\n\nPlease note: there are ways to add a set of key-value pairs in a single\noperation. When you use a regular dictionary in those operations, the order of\nthe keys will be ordered. For example:\n\nallow_no_value, default value: `False`\n\nSome configuration files are known to include settings without values, but\nwhich otherwise conform to the syntax supported by `configparser`. The\nallow_no_value parameter to the constructor can be used to indicate that such\nvalues should be accepted:\n\ndelimiters, default value: `('=', ':')`\n\nDelimiters are substrings that delimit keys from values within a section. The\nfirst occurrence of a delimiting substring on a line is considered a\ndelimiter. This means values (but not keys) can contain the delimiters.\n\nSee also the space_around_delimiters argument to `ConfigParser.write()`.\n\ninline_comment_prefixes, default value: `None`\n\nComment prefixes are strings that indicate the start of a valid comment within\na config file. comment_prefixes are used only on otherwise empty lines\n(optionally indented) whereas inline_comment_prefixes can be used after every\nvalid value (e.g. section names, options and empty lines as well). By default\ninline comments are disabled and `'#'` and `';'` are used as prefixes for\nwhole line comments.\n\nChanged in version 3.2: In previous versions of `configparser` behaviour\nmatched `comment_prefixes=('#',';')` and `inline_comment_prefixes=(';',)`.\n\nPlease note that config parsers don\u2019t support escaping of comment prefixes so\nusing inline_comment_prefixes may prevent users from specifying option values\nwith characters used as comment prefixes. When in doubt, avoid setting\ninline_comment_prefixes. In any circumstances, the only way of storing comment\nprefix characters at the beginning of a line in multiline values is to\ninterpolate the prefix, for example:\n\nstrict, default value: `True`\n\nWhen set to `True`, the parser will not allow for any section or option\nduplicates while reading from a single source (using `read_file()`,\n`read_string()` or `read_dict()`). It is recommended to use strict parsers in\nnew applications.\n\nChanged in version 3.2: In previous versions of `configparser` behaviour\nmatched `strict=False`.\n\nempty_lines_in_values, default value: `True`\n\nIn config parsers, values can span multiple lines as long as they are indented\nmore than the key that holds them. By default parsers also let empty lines to\nbe parts of values. At the same time, keys can be arbitrarily indented\nthemselves to improve readability. In consequence, when configuration files\nget big and complex, it is easy for the user to lose track of the file\nstructure. Take for instance:\n\nThis can be especially problematic for the user to see if she\u2019s using a\nproportional font to edit the file. That is why when your application does not\nneed values with empty lines, you should consider disallowing them. This will\nmake empty lines split keys every time. In the example above, it would produce\ntwo keys, `key` and `this`.\n\ndefault_section, default value: `configparser.DEFAULTSECT` (that is:\n`\"DEFAULT\"`)\n\nThe convention of allowing a special section of default values for other\nsections or interpolation purposes is a powerful concept of this library,\nletting users create complex declarative configurations. This section is\nnormally called `\"DEFAULT\"` but this can be customized to point to any other\nvalid section name. Some typical values include: `\"general\"` or `\"common\"`.\nThe name provided is used for recognizing default sections when reading from\nany source and is used when writing configuration back to a file. Its current\nvalue can be retrieved using the `parser_instance.default_section` attribute\nand may be modified at runtime (i.e. to convert files from one format to\nanother).\n\ninterpolation, default value: `configparser.BasicInterpolation`\n\nInterpolation behaviour may be customized by providing a custom handler\nthrough the interpolation argument. `None` can be used to turn off\ninterpolation completely, `ExtendedInterpolation()` provides a more advanced\nvariant inspired by `zc.buildout`. More on the subject in the dedicated\ndocumentation section. `RawConfigParser` has a default value of `None`.\n\nconverters, default value: not set\n\nConfig parsers provide option value getters that perform type conversion. By\ndefault `getint()`, `getfloat()`, and `getboolean()` are implemented. Should\nother getters be desirable, users may define them in a subclass or pass a\ndictionary where each key is a name of the converter and each value is a\ncallable implementing said conversion. For instance, passing `{'decimal':\ndecimal.Decimal}` would add `getdecimal()` on both the parser object and all\nsection proxies. In other words, it will be possible to write both\n`parser_instance.getdecimal('section', 'key', fallback=0)` and\n`parser_instance['section'].getdecimal('key', 0)`.\n\nIf the converter needs to access the state of the parser, it can be\nimplemented as a method on a config parser subclass. If the name of this\nmethod starts with `get`, it will be available on all section proxies, in the\ndict-compatible form (see the `getdecimal()` example above).\n\nMore advanced customization may be achieved by overriding default values of\nthese parser attributes. The defaults are defined on the classes, so they may\nbe overridden by subclasses or by attribute assignment.\n\nBy default when using `getboolean()`, config parsers consider the following\nvalues `True`: `'1'`, `'yes'`, `'true'`, `'on'` and the following values\n`False`: `'0'`, `'no'`, `'false'`, `'off'`. You can override this by\nspecifying a custom dictionary of strings and their Boolean outcomes. For\nexample:\n\nOther typical Boolean pairs include `accept`/`reject` or `enabled`/`disabled`.\n\nThis method transforms option names on every read, get, or set operation. The\ndefault converts the name to lowercase. This also means that when a\nconfiguration file gets written, all keys will be lowercase. Override this\nmethod if that\u2019s unsuitable. For example:\n\nNote\n\nThe optionxform function transforms option names to a canonical form. This\nshould be an idempotent function: if the name is already in canonical form, it\nshould be returned unchanged.\n\nA compiled regular expression used to parse section headers. The default\nmatches `[section]` to the name `\"section\"`. Whitespace is considered part of\nthe section name, thus `[ larch ]` will be read as a section of name `\" larch\n\"`. Override this attribute if that\u2019s unsuitable. For example:\n\nNote\n\nWhile ConfigParser objects also use an `OPTCRE` attribute for recognizing\noption lines, it\u2019s not recommended to override it because that would interfere\nwith constructor options allow_no_value and delimiters.\n\nMainly because of backwards compatibility concerns, `configparser` provides\nalso a legacy API with explicit `get`/`set` methods. While there are valid use\ncases for the methods outlined below, mapping protocol access is preferred for\nnew projects. The legacy API is at times more advanced, low-level and\ndownright counterintuitive.\n\nAn example of writing to a configuration file:\n\nAn example of reading the configuration file again:\n\nTo get interpolation, use `ConfigParser`:\n\nDefault values are available in both types of ConfigParsers. They are used in\ninterpolation if an option used is not defined elsewhere.\n\nThe main configuration parser. When defaults is given, it is initialized into\nthe dictionary of intrinsic defaults. When dict_type is given, it will be used\nto create the dictionary objects for the list of sections, for the options\nwithin a section, and for the default values.\n\nWhen delimiters is given, it is used as the set of substrings that divide keys\nfrom values. When comment_prefixes is given, it will be used as the set of\nsubstrings that prefix comments in otherwise empty lines. Comments can be\nindented. When inline_comment_prefixes is given, it will be used as the set of\nsubstrings that prefix comments in non-empty lines.\n\nWhen strict is `True` (the default), the parser won\u2019t allow for any section or\noption duplicates while reading from a single source (file, string or\ndictionary), raising `DuplicateSectionError` or `DuplicateOptionError`. When\nempty_lines_in_values is `False` (default: `True`), each empty line marks the\nend of an option. Otherwise, internal empty lines of a multiline option are\nkept as part of the value. When allow_no_value is `True` (default: `False`),\noptions without values are accepted; the value held for these is `None` and\nthey are serialized without the trailing delimiter.\n\nWhen default_section is given, it specifies the name for the special section\nholding default values for other sections and interpolation purposes (normally\nnamed `\"DEFAULT\"`). This value can be retrieved and changed on runtime using\nthe `default_section` instance attribute.\n\nInterpolation behaviour may be customized by providing a custom handler\nthrough the interpolation argument. `None` can be used to turn off\ninterpolation completely, `ExtendedInterpolation()` provides a more advanced\nvariant inspired by `zc.buildout`. More on the subject in the dedicated\ndocumentation section.\n\nAll option names used in interpolation will be passed through the\n`optionxform()` method just like any other option name reference. For example,\nusing the default implementation of `optionxform()` (which converts option\nnames to lower case), the values `foo %(bar)s` and `foo %(BAR)s` are\nequivalent.\n\nWhen converters is given, it should be a dictionary where each key represents\nthe name of a type converter and each value is a callable implementing the\nconversion from string to the desired datatype. Every converter gets its own\ncorresponding `get*()` method on the parser object and section proxies.\n\nChanged in version 3.1: The default dict_type is `collections.OrderedDict`.\n\nChanged in version 3.2: allow_no_value, delimiters, comment_prefixes, strict,\nempty_lines_in_values, default_section and interpolation were added.\n\nChanged in version 3.5: The converters argument was added.\n\nChanged in version 3.7: The defaults argument is read with `read_dict()`,\nproviding consistent behavior across the parser: non-string keys and values\nare implicitly converted to strings.\n\nChanged in version 3.8: The default dict_type is `dict`, since it now\npreserves insertion order.\n\nReturn a dictionary containing the instance-wide defaults.\n\nReturn a list of the sections available; the default section is not included\nin the list.\n\nAdd a section named section to the instance. If a section by the given name\nalready exists, `DuplicateSectionError` is raised. If the default section name\nis passed, `ValueError` is raised. The name of the section must be a string;\nif not, `TypeError` is raised.\n\nChanged in version 3.2: Non-string section names raise `TypeError`.\n\nIndicates whether the named section is present in the configuration. The\ndefault section is not acknowledged.\n\nReturn a list of options available in the specified section.\n\nIf the given section exists, and contains the given option, return `True`;\notherwise return `False`. If the specified section is `None` or an empty\nstring, DEFAULT is assumed.\n\nAttempt to read and parse an iterable of filenames, returning a list of\nfilenames which were successfully parsed.\n\nIf filenames is a string, a `bytes` object or a path-like object, it is\ntreated as a single filename. If a file named in filenames cannot be opened,\nthat file will be ignored. This is designed so that you can specify an\niterable of potential configuration file locations (for example, the current\ndirectory, the user\u2019s home directory, and some system-wide directory), and all\nexisting configuration files in the iterable will be read.\n\nIf none of the named files exist, the `ConfigParser` instance will contain an\nempty dataset. An application which requires initial values to be loaded from\na file should load the required file or files using `read_file()` before\ncalling `read()` for any optional files:\n\nNew in version 3.2: The encoding parameter. Previously, all files were read\nusing the default encoding for `open()`.\n\nNew in version 3.6.1: The filenames parameter accepts a path-like object.\n\nNew in version 3.7: The filenames parameter accepts a `bytes` object.\n\nRead and parse configuration data from f which must be an iterable yielding\nUnicode strings (for example files opened in text mode).\n\nOptional argument source specifies the name of the file being read. If not\ngiven and f has a `name` attribute, that is used for source; the default is\n`'<???>'`.\n\nNew in version 3.2: Replaces `readfp()`.\n\nParse configuration data from a string.\n\nOptional argument source specifies a context-specific name of the string\npassed. If not given, `'<string>'` is used. This should commonly be a\nfilesystem path or a URL.\n\nNew in version 3.2.\n\nLoad configuration from any object that provides a dict-like `items()` method.\nKeys are section names, values are dictionaries with keys and values that\nshould be present in the section. If the used dictionary type preserves order,\nsections and their keys will be added in order. Values are automatically\nconverted to strings.\n\nOptional argument source specifies a context-specific name of the dictionary\npassed. If not given, `<dict>` is used.\n\nThis method can be used to copy state between parsers.\n\nNew in version 3.2.\n\nGet an option value for the named section. If vars is provided, it must be a\ndictionary. The option is looked up in vars (if provided), section, and in\nDEFAULTSECT in that order. If the key is not found and fallback is provided,\nit is used as a fallback value. `None` can be provided as a fallback value.\n\nAll the `'%'` interpolations are expanded in the return values, unless the raw\nargument is true. Values for interpolation keys are looked up in the same\nmanner as the option.\n\nChanged in version 3.2: Arguments raw, vars and fallback are keyword only to\nprotect users from trying to use the third argument as the fallback fallback\n(especially when using the mapping protocol).\n\nA convenience method which coerces the option in the specified section to an\ninteger. See `get()` for explanation of raw, vars and fallback.\n\nA convenience method which coerces the option in the specified section to a\nfloating point number. See `get()` for explanation of raw, vars and fallback.\n\nA convenience method which coerces the option in the specified section to a\nBoolean value. Note that the accepted values for the option are `'1'`,\n`'yes'`, `'true'`, and `'on'`, which cause this method to return `True`, and\n`'0'`, `'no'`, `'false'`, and `'off'`, which cause it to return `False`. These\nstring values are checked in a case-insensitive manner. Any other value will\ncause it to raise `ValueError`. See `get()` for explanation of raw, vars and\nfallback.\n\nWhen section is not given, return a list of section_name, section_proxy pairs,\nincluding DEFAULTSECT.\n\nOtherwise, return a list of name, value pairs for the options in the given\nsection. Optional arguments have the same meaning as for the `get()` method.\n\nChanged in version 3.8: Items present in vars no longer appear in the result.\nThe previous behaviour mixed actual parser options with variables provided for\ninterpolation.\n\nIf the given section exists, set the given option to the specified value;\notherwise raise `NoSectionError`. option and value must be strings; if not,\n`TypeError` is raised.\n\nWrite a representation of the configuration to the specified file object,\nwhich must be opened in text mode (accepting strings). This representation can\nbe parsed by a future `read()` call. If space_around_delimiters is true,\ndelimiters between keys and values are surrounded by spaces.\n\nRemove the specified option from the specified section. If the section does\nnot exist, raise `NoSectionError`. If the option existed to be removed, return\n`True`; otherwise return `False`.\n\nRemove the specified section from the configuration. If the section in fact\nexisted, return `True`. Otherwise return `False`.\n\nTransforms the option name option as found in an input file or as passed in by\nclient code to the form that should be used in the internal structures. The\ndefault implementation returns a lower-case version of option; subclasses may\noverride this or client code can set an attribute of this name on instances to\naffect this behavior.\n\nYou don\u2019t need to subclass the parser to use this method, you can also set it\non an instance, to a function that takes a string argument and returns a\nstring. Setting it to `str`, for example, would make option names case\nsensitive:\n\nNote that when reading configuration files, whitespace around the option names\nis stripped before `optionxform()` is called.\n\nDeprecated since version 3.2: Use `read_file()` instead.\n\nChanged in version 3.2: `readfp()` now iterates on fp instead of calling\n`fp.readline()`.\n\nFor existing code calling `readfp()` with arguments which don\u2019t support\niteration, the following generator may be used as a wrapper around the file-\nlike object:\n\nInstead of `parser.readfp(fp)` use `parser.read_file(readline_generator(fp))`.\n\nThe maximum depth for recursive interpolation for `get()` when the raw\nparameter is false. This is relevant only when the default interpolation is\nused.\n\nLegacy variant of the `ConfigParser`. It has interpolation disabled by default\nand allows for non-string section names, option names, and values via its\nunsafe `add_section` and `set` methods, as well as the legacy `defaults=`\nkeyword argument handling.\n\nChanged in version 3.8: The default dict_type is `dict`, since it now\npreserves insertion order.\n\nNote\n\nConsider using `ConfigParser` instead which checks types of the values to be\nstored internally. If you don\u2019t want interpolation, you can use\n`ConfigParser(interpolation=None)`.\n\nAdd a section named section to the instance. If a section by the given name\nalready exists, `DuplicateSectionError` is raised. If the default section name\nis passed, `ValueError` is raised.\n\nType of section is not checked which lets users create non-string named\nsections. This behaviour is unsupported and may cause internal errors.\n\nIf the given section exists, set the given option to the specified value;\notherwise raise `NoSectionError`. While it is possible to use\n`RawConfigParser` (or `ConfigParser` with raw parameters set to true) for\ninternal storage of non-string values, full functionality (including\ninterpolation and output to files) can only be achieved using string values.\n\nThis method lets users assign non-string values to keys internally. This\nbehaviour is unsupported and will cause errors when attempting to write to a\nfile or get it in non-raw mode. Use the mapping protocol API which does not\nallow such assignments to take place.\n\nBase class for all other `configparser` exceptions.\n\nException raised when a specified section is not found.\n\nException raised if `add_section()` is called with the name of a section that\nis already present or in strict parsers when a section if found more than once\nin a single input file, string or dictionary.\n\nNew in version 3.2: Optional `source` and `lineno` attributes and arguments to\n`__init__()` were added.\n\nException raised by strict parsers if a single option appears twice during\nreading from a single file, string or dictionary. This catches misspellings\nand case sensitivity-related errors, e.g. a dictionary may have two keys\nrepresenting the same case-insensitive configuration key.\n\nException raised when a specified option is not found in the specified\nsection.\n\nBase class for exceptions raised when problems occur performing string\ninterpolation.\n\nException raised when string interpolation cannot be completed because the\nnumber of iterations exceeds `MAX_INTERPOLATION_DEPTH`. Subclass of\n`InterpolationError`.\n\nException raised when an option referenced from a value does not exist.\nSubclass of `InterpolationError`.\n\nException raised when the source text into which substitutions are made does\nnot conform to the required syntax. Subclass of `InterpolationError`.\n\nException raised when attempting to parse a file which has no section headers.\n\nException raised when errors occur attempting to parse a file.\n\nChanged in version 3.2: The `filename` attribute and `__init__()` argument\nwere renamed to `source` for consistency.\n\nConfig parsers allow for heavy customization. If you are interested in\nchanging the behaviour outlined by the footnote reference, consult the\nCustomizing Parser Behaviour section.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.BasicInterpolation", "path": "library/configparser#configparser.BasicInterpolation", "type": "File Formats", "text": "\nThe default implementation used by `ConfigParser`. It enables values to\ncontain format strings which refer to other values in the same section, or\nvalues in the special default section 1. Additional default values can be\nprovided on initialization.\n\nFor example:\n\nIn the example above, `ConfigParser` with interpolation set to\n`BasicInterpolation()` would resolve `%(home_dir)s` to the value of `home_dir`\n(`/Users` in this case). `%(my_dir)s` in effect would resolve to\n`/Users/lumberjack`. All interpolations are done on demand so keys used in the\nchain of references do not have to be specified in any specific order in the\nconfiguration file.\n\nWith `interpolation` set to `None`, the parser would simply return\n`%(my_dir)s/Pictures` as the value of `my_pictures` and\n`%(home_dir)s/lumberjack` as the value of `my_dir`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser", "path": "library/configparser#configparser.ConfigParser", "type": "File Formats", "text": "\nThe main configuration parser. When defaults is given, it is initialized into\nthe dictionary of intrinsic defaults. When dict_type is given, it will be used\nto create the dictionary objects for the list of sections, for the options\nwithin a section, and for the default values.\n\nWhen delimiters is given, it is used as the set of substrings that divide keys\nfrom values. When comment_prefixes is given, it will be used as the set of\nsubstrings that prefix comments in otherwise empty lines. Comments can be\nindented. When inline_comment_prefixes is given, it will be used as the set of\nsubstrings that prefix comments in non-empty lines.\n\nWhen strict is `True` (the default), the parser won\u2019t allow for any section or\noption duplicates while reading from a single source (file, string or\ndictionary), raising `DuplicateSectionError` or `DuplicateOptionError`. When\nempty_lines_in_values is `False` (default: `True`), each empty line marks the\nend of an option. Otherwise, internal empty lines of a multiline option are\nkept as part of the value. When allow_no_value is `True` (default: `False`),\noptions without values are accepted; the value held for these is `None` and\nthey are serialized without the trailing delimiter.\n\nWhen default_section is given, it specifies the name for the special section\nholding default values for other sections and interpolation purposes (normally\nnamed `\"DEFAULT\"`). This value can be retrieved and changed on runtime using\nthe `default_section` instance attribute.\n\nInterpolation behaviour may be customized by providing a custom handler\nthrough the interpolation argument. `None` can be used to turn off\ninterpolation completely, `ExtendedInterpolation()` provides a more advanced\nvariant inspired by `zc.buildout`. More on the subject in the dedicated\ndocumentation section.\n\nAll option names used in interpolation will be passed through the\n`optionxform()` method just like any other option name reference. For example,\nusing the default implementation of `optionxform()` (which converts option\nnames to lower case), the values `foo %(bar)s` and `foo %(BAR)s` are\nequivalent.\n\nWhen converters is given, it should be a dictionary where each key represents\nthe name of a type converter and each value is a callable implementing the\nconversion from string to the desired datatype. Every converter gets its own\ncorresponding `get*()` method on the parser object and section proxies.\n\nChanged in version 3.1: The default dict_type is `collections.OrderedDict`.\n\nChanged in version 3.2: allow_no_value, delimiters, comment_prefixes, strict,\nempty_lines_in_values, default_section and interpolation were added.\n\nChanged in version 3.5: The converters argument was added.\n\nChanged in version 3.7: The defaults argument is read with `read_dict()`,\nproviding consistent behavior across the parser: non-string keys and values\nare implicitly converted to strings.\n\nChanged in version 3.8: The default dict_type is `dict`, since it now\npreserves insertion order.\n\nReturn a dictionary containing the instance-wide defaults.\n\nReturn a list of the sections available; the default section is not included\nin the list.\n\nAdd a section named section to the instance. If a section by the given name\nalready exists, `DuplicateSectionError` is raised. If the default section name\nis passed, `ValueError` is raised. The name of the section must be a string;\nif not, `TypeError` is raised.\n\nChanged in version 3.2: Non-string section names raise `TypeError`.\n\nIndicates whether the named section is present in the configuration. The\ndefault section is not acknowledged.\n\nReturn a list of options available in the specified section.\n\nIf the given section exists, and contains the given option, return `True`;\notherwise return `False`. If the specified section is `None` or an empty\nstring, DEFAULT is assumed.\n\nAttempt to read and parse an iterable of filenames, returning a list of\nfilenames which were successfully parsed.\n\nIf filenames is a string, a `bytes` object or a path-like object, it is\ntreated as a single filename. If a file named in filenames cannot be opened,\nthat file will be ignored. This is designed so that you can specify an\niterable of potential configuration file locations (for example, the current\ndirectory, the user\u2019s home directory, and some system-wide directory), and all\nexisting configuration files in the iterable will be read.\n\nIf none of the named files exist, the `ConfigParser` instance will contain an\nempty dataset. An application which requires initial values to be loaded from\na file should load the required file or files using `read_file()` before\ncalling `read()` for any optional files:\n\nNew in version 3.2: The encoding parameter. Previously, all files were read\nusing the default encoding for `open()`.\n\nNew in version 3.6.1: The filenames parameter accepts a path-like object.\n\nNew in version 3.7: The filenames parameter accepts a `bytes` object.\n\nRead and parse configuration data from f which must be an iterable yielding\nUnicode strings (for example files opened in text mode).\n\nOptional argument source specifies the name of the file being read. If not\ngiven and f has a `name` attribute, that is used for source; the default is\n`'<???>'`.\n\nNew in version 3.2: Replaces `readfp()`.\n\nParse configuration data from a string.\n\nOptional argument source specifies a context-specific name of the string\npassed. If not given, `'<string>'` is used. This should commonly be a\nfilesystem path or a URL.\n\nNew in version 3.2.\n\nLoad configuration from any object that provides a dict-like `items()` method.\nKeys are section names, values are dictionaries with keys and values that\nshould be present in the section. If the used dictionary type preserves order,\nsections and their keys will be added in order. Values are automatically\nconverted to strings.\n\nOptional argument source specifies a context-specific name of the dictionary\npassed. If not given, `<dict>` is used.\n\nThis method can be used to copy state between parsers.\n\nNew in version 3.2.\n\nGet an option value for the named section. If vars is provided, it must be a\ndictionary. The option is looked up in vars (if provided), section, and in\nDEFAULTSECT in that order. If the key is not found and fallback is provided,\nit is used as a fallback value. `None` can be provided as a fallback value.\n\nAll the `'%'` interpolations are expanded in the return values, unless the raw\nargument is true. Values for interpolation keys are looked up in the same\nmanner as the option.\n\nChanged in version 3.2: Arguments raw, vars and fallback are keyword only to\nprotect users from trying to use the third argument as the fallback fallback\n(especially when using the mapping protocol).\n\nA convenience method which coerces the option in the specified section to an\ninteger. See `get()` for explanation of raw, vars and fallback.\n\nA convenience method which coerces the option in the specified section to a\nfloating point number. See `get()` for explanation of raw, vars and fallback.\n\nA convenience method which coerces the option in the specified section to a\nBoolean value. Note that the accepted values for the option are `'1'`,\n`'yes'`, `'true'`, and `'on'`, which cause this method to return `True`, and\n`'0'`, `'no'`, `'false'`, and `'off'`, which cause it to return `False`. These\nstring values are checked in a case-insensitive manner. Any other value will\ncause it to raise `ValueError`. See `get()` for explanation of raw, vars and\nfallback.\n\nWhen section is not given, return a list of section_name, section_proxy pairs,\nincluding DEFAULTSECT.\n\nOtherwise, return a list of name, value pairs for the options in the given\nsection. Optional arguments have the same meaning as for the `get()` method.\n\nChanged in version 3.8: Items present in vars no longer appear in the result.\nThe previous behaviour mixed actual parser options with variables provided for\ninterpolation.\n\nIf the given section exists, set the given option to the specified value;\notherwise raise `NoSectionError`. option and value must be strings; if not,\n`TypeError` is raised.\n\nWrite a representation of the configuration to the specified file object,\nwhich must be opened in text mode (accepting strings). This representation can\nbe parsed by a future `read()` call. If space_around_delimiters is true,\ndelimiters between keys and values are surrounded by spaces.\n\nRemove the specified option from the specified section. If the section does\nnot exist, raise `NoSectionError`. If the option existed to be removed, return\n`True`; otherwise return `False`.\n\nRemove the specified section from the configuration. If the section in fact\nexisted, return `True`. Otherwise return `False`.\n\nTransforms the option name option as found in an input file or as passed in by\nclient code to the form that should be used in the internal structures. The\ndefault implementation returns a lower-case version of option; subclasses may\noverride this or client code can set an attribute of this name on instances to\naffect this behavior.\n\nYou don\u2019t need to subclass the parser to use this method, you can also set it\non an instance, to a function that takes a string argument and returns a\nstring. Setting it to `str`, for example, would make option names case\nsensitive:\n\nNote that when reading configuration files, whitespace around the option names\nis stripped before `optionxform()` is called.\n\nDeprecated since version 3.2: Use `read_file()` instead.\n\nChanged in version 3.2: `readfp()` now iterates on fp instead of calling\n`fp.readline()`.\n\nFor existing code calling `readfp()` with arguments which don\u2019t support\niteration, the following generator may be used as a wrapper around the file-\nlike object:\n\nInstead of `parser.readfp(fp)` use `parser.read_file(readline_generator(fp))`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.add_section()", "path": "library/configparser#configparser.ConfigParser.add_section", "type": "File Formats", "text": "\nAdd a section named section to the instance. If a section by the given name\nalready exists, `DuplicateSectionError` is raised. If the default section name\nis passed, `ValueError` is raised. The name of the section must be a string;\nif not, `TypeError` is raised.\n\nChanged in version 3.2: Non-string section names raise `TypeError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.BOOLEAN_STATES", "path": "library/configparser#configparser.ConfigParser.BOOLEAN_STATES", "type": "File Formats", "text": "\nBy default when using `getboolean()`, config parsers consider the following\nvalues `True`: `'1'`, `'yes'`, `'true'`, `'on'` and the following values\n`False`: `'0'`, `'no'`, `'false'`, `'off'`. You can override this by\nspecifying a custom dictionary of strings and their Boolean outcomes. For\nexample:\n\nOther typical Boolean pairs include `accept`/`reject` or `enabled`/`disabled`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.defaults()", "path": "library/configparser#configparser.ConfigParser.defaults", "type": "File Formats", "text": "\nReturn a dictionary containing the instance-wide defaults.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.get()", "path": "library/configparser#configparser.ConfigParser.get", "type": "File Formats", "text": "\nGet an option value for the named section. If vars is provided, it must be a\ndictionary. The option is looked up in vars (if provided), section, and in\nDEFAULTSECT in that order. If the key is not found and fallback is provided,\nit is used as a fallback value. `None` can be provided as a fallback value.\n\nAll the `'%'` interpolations are expanded in the return values, unless the raw\nargument is true. Values for interpolation keys are looked up in the same\nmanner as the option.\n\nChanged in version 3.2: Arguments raw, vars and fallback are keyword only to\nprotect users from trying to use the third argument as the fallback fallback\n(especially when using the mapping protocol).\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.getboolean()", "path": "library/configparser#configparser.ConfigParser.getboolean", "type": "File Formats", "text": "\nA convenience method which coerces the option in the specified section to a\nBoolean value. Note that the accepted values for the option are `'1'`,\n`'yes'`, `'true'`, and `'on'`, which cause this method to return `True`, and\n`'0'`, `'no'`, `'false'`, and `'off'`, which cause it to return `False`. These\nstring values are checked in a case-insensitive manner. Any other value will\ncause it to raise `ValueError`. See `get()` for explanation of raw, vars and\nfallback.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.getfloat()", "path": "library/configparser#configparser.ConfigParser.getfloat", "type": "File Formats", "text": "\nA convenience method which coerces the option in the specified section to a\nfloating point number. See `get()` for explanation of raw, vars and fallback.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.getint()", "path": "library/configparser#configparser.ConfigParser.getint", "type": "File Formats", "text": "\nA convenience method which coerces the option in the specified section to an\ninteger. See `get()` for explanation of raw, vars and fallback.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.has_option()", "path": "library/configparser#configparser.ConfigParser.has_option", "type": "File Formats", "text": "\nIf the given section exists, and contains the given option, return `True`;\notherwise return `False`. If the specified section is `None` or an empty\nstring, DEFAULT is assumed.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.has_section()", "path": "library/configparser#configparser.ConfigParser.has_section", "type": "File Formats", "text": "\nIndicates whether the named section is present in the configuration. The\ndefault section is not acknowledged.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.items()", "path": "library/configparser#configparser.ConfigParser.items", "type": "File Formats", "text": "\nWhen section is not given, return a list of section_name, section_proxy pairs,\nincluding DEFAULTSECT.\n\nOtherwise, return a list of name, value pairs for the options in the given\nsection. Optional arguments have the same meaning as for the `get()` method.\n\nChanged in version 3.8: Items present in vars no longer appear in the result.\nThe previous behaviour mixed actual parser options with variables provided for\ninterpolation.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.options()", "path": "library/configparser#configparser.ConfigParser.options", "type": "File Formats", "text": "\nReturn a list of options available in the specified section.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.optionxform()", "path": "library/configparser#configparser.ConfigParser.optionxform", "type": "File Formats", "text": "\nTransforms the option name option as found in an input file or as passed in by\nclient code to the form that should be used in the internal structures. The\ndefault implementation returns a lower-case version of option; subclasses may\noverride this or client code can set an attribute of this name on instances to\naffect this behavior.\n\nYou don\u2019t need to subclass the parser to use this method, you can also set it\non an instance, to a function that takes a string argument and returns a\nstring. Setting it to `str`, for example, would make option names case\nsensitive:\n\nNote that when reading configuration files, whitespace around the option names\nis stripped before `optionxform()` is called.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.read()", "path": "library/configparser#configparser.ConfigParser.read", "type": "File Formats", "text": "\nAttempt to read and parse an iterable of filenames, returning a list of\nfilenames which were successfully parsed.\n\nIf filenames is a string, a `bytes` object or a path-like object, it is\ntreated as a single filename. If a file named in filenames cannot be opened,\nthat file will be ignored. This is designed so that you can specify an\niterable of potential configuration file locations (for example, the current\ndirectory, the user\u2019s home directory, and some system-wide directory), and all\nexisting configuration files in the iterable will be read.\n\nIf none of the named files exist, the `ConfigParser` instance will contain an\nempty dataset. An application which requires initial values to be loaded from\na file should load the required file or files using `read_file()` before\ncalling `read()` for any optional files:\n\nNew in version 3.2: The encoding parameter. Previously, all files were read\nusing the default encoding for `open()`.\n\nNew in version 3.6.1: The filenames parameter accepts a path-like object.\n\nNew in version 3.7: The filenames parameter accepts a `bytes` object.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.readfp()", "path": "library/configparser#configparser.ConfigParser.readfp", "type": "File Formats", "text": "\nDeprecated since version 3.2: Use `read_file()` instead.\n\nChanged in version 3.2: `readfp()` now iterates on fp instead of calling\n`fp.readline()`.\n\nFor existing code calling `readfp()` with arguments which don\u2019t support\niteration, the following generator may be used as a wrapper around the file-\nlike object:\n\nInstead of `parser.readfp(fp)` use `parser.read_file(readline_generator(fp))`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.read_dict()", "path": "library/configparser#configparser.ConfigParser.read_dict", "type": "File Formats", "text": "\nLoad configuration from any object that provides a dict-like `items()` method.\nKeys are section names, values are dictionaries with keys and values that\nshould be present in the section. If the used dictionary type preserves order,\nsections and their keys will be added in order. Values are automatically\nconverted to strings.\n\nOptional argument source specifies a context-specific name of the dictionary\npassed. If not given, `<dict>` is used.\n\nThis method can be used to copy state between parsers.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.read_file()", "path": "library/configparser#configparser.ConfigParser.read_file", "type": "File Formats", "text": "\nRead and parse configuration data from f which must be an iterable yielding\nUnicode strings (for example files opened in text mode).\n\nOptional argument source specifies the name of the file being read. If not\ngiven and f has a `name` attribute, that is used for source; the default is\n`'<???>'`.\n\nNew in version 3.2: Replaces `readfp()`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.read_string()", "path": "library/configparser#configparser.ConfigParser.read_string", "type": "File Formats", "text": "\nParse configuration data from a string.\n\nOptional argument source specifies a context-specific name of the string\npassed. If not given, `'<string>'` is used. This should commonly be a\nfilesystem path or a URL.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.remove_option()", "path": "library/configparser#configparser.ConfigParser.remove_option", "type": "File Formats", "text": "\nRemove the specified option from the specified section. If the section does\nnot exist, raise `NoSectionError`. If the option existed to be removed, return\n`True`; otherwise return `False`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.remove_section()", "path": "library/configparser#configparser.ConfigParser.remove_section", "type": "File Formats", "text": "\nRemove the specified section from the configuration. If the section in fact\nexisted, return `True`. Otherwise return `False`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.SECTCRE", "path": "library/configparser#configparser.ConfigParser.SECTCRE", "type": "File Formats", "text": "\nA compiled regular expression used to parse section headers. The default\nmatches `[section]` to the name `\"section\"`. Whitespace is considered part of\nthe section name, thus `[ larch ]` will be read as a section of name `\" larch\n\"`. Override this attribute if that\u2019s unsuitable. For example:\n\nNote\n\nWhile ConfigParser objects also use an `OPTCRE` attribute for recognizing\noption lines, it\u2019s not recommended to override it because that would interfere\nwith constructor options allow_no_value and delimiters.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.sections()", "path": "library/configparser#configparser.ConfigParser.sections", "type": "File Formats", "text": "\nReturn a list of the sections available; the default section is not included\nin the list.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.set()", "path": "library/configparser#configparser.ConfigParser.set", "type": "File Formats", "text": "\nIf the given section exists, set the given option to the specified value;\notherwise raise `NoSectionError`. option and value must be strings; if not,\n`TypeError` is raised.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ConfigParser.write()", "path": "library/configparser#configparser.ConfigParser.write", "type": "File Formats", "text": "\nWrite a representation of the configuration to the specified file object,\nwhich must be opened in text mode (accepting strings). This representation can\nbe parsed by a future `read()` call. If space_around_delimiters is true,\ndelimiters between keys and values are surrounded by spaces.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.DuplicateOptionError", "path": "library/configparser#configparser.DuplicateOptionError", "type": "File Formats", "text": "\nException raised by strict parsers if a single option appears twice during\nreading from a single file, string or dictionary. This catches misspellings\nand case sensitivity-related errors, e.g. a dictionary may have two keys\nrepresenting the same case-insensitive configuration key.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.DuplicateSectionError", "path": "library/configparser#configparser.DuplicateSectionError", "type": "File Formats", "text": "\nException raised if `add_section()` is called with the name of a section that\nis already present or in strict parsers when a section if found more than once\nin a single input file, string or dictionary.\n\nNew in version 3.2: Optional `source` and `lineno` attributes and arguments to\n`__init__()` were added.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.Error", "path": "library/configparser#configparser.Error", "type": "File Formats", "text": "\nBase class for all other `configparser` exceptions.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ExtendedInterpolation", "path": "library/configparser#configparser.ExtendedInterpolation", "type": "File Formats", "text": "\nAn alternative handler for interpolation which implements a more advanced\nsyntax, used for instance in `zc.buildout`. Extended interpolation is using\n`${section:option}` to denote a value from a foreign section. Interpolation\ncan span multiple levels. For convenience, if the `section:` part is omitted,\ninterpolation defaults to the current section (and possibly the default values\nfrom the special section).\n\nFor example, the configuration specified above with basic interpolation, would\nlook like this with extended interpolation:\n\nValues from other sections can be fetched as well:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.InterpolationDepthError", "path": "library/configparser#configparser.InterpolationDepthError", "type": "File Formats", "text": "\nException raised when string interpolation cannot be completed because the\nnumber of iterations exceeds `MAX_INTERPOLATION_DEPTH`. Subclass of\n`InterpolationError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.InterpolationError", "path": "library/configparser#configparser.InterpolationError", "type": "File Formats", "text": "\nBase class for exceptions raised when problems occur performing string\ninterpolation.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.InterpolationMissingOptionError", "path": "library/configparser#configparser.InterpolationMissingOptionError", "type": "File Formats", "text": "\nException raised when an option referenced from a value does not exist.\nSubclass of `InterpolationError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.InterpolationSyntaxError", "path": "library/configparser#configparser.InterpolationSyntaxError", "type": "File Formats", "text": "\nException raised when the source text into which substitutions are made does\nnot conform to the required syntax. Subclass of `InterpolationError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.MAX_INTERPOLATION_DEPTH", "path": "library/configparser#configparser.MAX_INTERPOLATION_DEPTH", "type": "File Formats", "text": "\nThe maximum depth for recursive interpolation for `get()` when the raw\nparameter is false. This is relevant only when the default interpolation is\nused.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.MissingSectionHeaderError", "path": "library/configparser#configparser.MissingSectionHeaderError", "type": "File Formats", "text": "\nException raised when attempting to parse a file which has no section headers.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.NoOptionError", "path": "library/configparser#configparser.NoOptionError", "type": "File Formats", "text": "\nException raised when a specified option is not found in the specified\nsection.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.NoSectionError", "path": "library/configparser#configparser.NoSectionError", "type": "File Formats", "text": "\nException raised when a specified section is not found.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.ParsingError", "path": "library/configparser#configparser.ParsingError", "type": "File Formats", "text": "\nException raised when errors occur attempting to parse a file.\n\nChanged in version 3.2: The `filename` attribute and `__init__()` argument\nwere renamed to `source` for consistency.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.RawConfigParser", "path": "library/configparser#configparser.RawConfigParser", "type": "File Formats", "text": "\nLegacy variant of the `ConfigParser`. It has interpolation disabled by default\nand allows for non-string section names, option names, and values via its\nunsafe `add_section` and `set` methods, as well as the legacy `defaults=`\nkeyword argument handling.\n\nChanged in version 3.8: The default dict_type is `dict`, since it now\npreserves insertion order.\n\nNote\n\nConsider using `ConfigParser` instead which checks types of the values to be\nstored internally. If you don\u2019t want interpolation, you can use\n`ConfigParser(interpolation=None)`.\n\nAdd a section named section to the instance. If a section by the given name\nalready exists, `DuplicateSectionError` is raised. If the default section name\nis passed, `ValueError` is raised.\n\nType of section is not checked which lets users create non-string named\nsections. This behaviour is unsupported and may cause internal errors.\n\nIf the given section exists, set the given option to the specified value;\notherwise raise `NoSectionError`. While it is possible to use\n`RawConfigParser` (or `ConfigParser` with raw parameters set to true) for\ninternal storage of non-string values, full functionality (including\ninterpolation and output to files) can only be achieved using string values.\n\nThis method lets users assign non-string values to keys internally. This\nbehaviour is unsupported and will cause errors when attempting to write to a\nfile or get it in non-raw mode. Use the mapping protocol API which does not\nallow such assignments to take place.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.RawConfigParser.add_section()", "path": "library/configparser#configparser.RawConfigParser.add_section", "type": "File Formats", "text": "\nAdd a section named section to the instance. If a section by the given name\nalready exists, `DuplicateSectionError` is raised. If the default section name\nis passed, `ValueError` is raised.\n\nType of section is not checked which lets users create non-string named\nsections. This behaviour is unsupported and may cause internal errors.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "configparser.RawConfigParser.set()", "path": "library/configparser#configparser.RawConfigParser.set", "type": "File Formats", "text": "\nIf the given section exists, set the given option to the specified value;\notherwise raise `NoSectionError`. While it is possible to use\n`RawConfigParser` (or `ConfigParser` with raw parameters set to true) for\ninternal storage of non-string values, full functionality (including\ninterpolation and output to files) can only be achieved using string values.\n\nThis method lets users assign non-string values to keys internally. This\nbehaviour is unsupported and will cause errors when attempting to write to a\nfile or get it in non-raw mode. Use the mapping protocol API which does not\nallow such assignments to take place.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "ConnectionAbortedError", "path": "library/exceptions#ConnectionAbortedError", "type": "Built-in Exceptions", "text": "\nA subclass of `ConnectionError`, raised when a connection attempt is aborted\nby the peer. Corresponds to `errno` `ECONNABORTED`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "ConnectionError", "path": "library/exceptions#ConnectionError", "type": "Built-in Exceptions", "text": "\nA base class for connection-related issues.\n\nSubclasses are `BrokenPipeError`, `ConnectionAbortedError`,\n`ConnectionRefusedError` and `ConnectionResetError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "ConnectionRefusedError", "path": "library/exceptions#ConnectionRefusedError", "type": "Built-in Exceptions", "text": "\nA subclass of `ConnectionError`, raised when a connection attempt is refused\nby the peer. Corresponds to `errno` `ECONNREFUSED`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "ConnectionResetError", "path": "library/exceptions#ConnectionResetError", "type": "Built-in Exceptions", "text": "\nA subclass of `ConnectionError`, raised when a connection is reset by the\npeer. Corresponds to `errno` `ECONNRESET`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "Constants", "path": "library/constants", "type": "Built-in Constants", "text": "\nA small number of constants live in the built-in namespace. They are:\n\nThe false value of the `bool` type. Assignments to `False` are illegal and\nraise a `SyntaxError`.\n\nThe true value of the `bool` type. Assignments to `True` are illegal and raise\na `SyntaxError`.\n\nThe sole value of the type `NoneType`. `None` is frequently used to represent\nthe absence of a value, as when default arguments are not passed to a\nfunction. Assignments to `None` are illegal and raise a `SyntaxError`.\n\nSpecial value which should be returned by the binary special methods (e.g.\n`__eq__()`, `__lt__()`, `__add__()`, `__rsub__()`, etc.) to indicate that the\noperation is not implemented with respect to the other type; may be returned\nby the in-place binary special methods (e.g. `__imul__()`, `__iand__()`, etc.)\nfor the same purpose. It should not be evaluated in a boolean context.\n\nNote\n\nWhen a binary (or in-place) method returns `NotImplemented` the interpreter\nwill try the reflected operation on the other type (or some other fallback,\ndepending on the operator). If all attempts return `NotImplemented`, the\ninterpreter will raise an appropriate exception. Incorrectly returning\n`NotImplemented` will result in a misleading error message or the\n`NotImplemented` value being returned to Python code.\n\nSee Implementing the arithmetic operations for examples.\n\nNote\n\n`NotImplementedError` and `NotImplemented` are not interchangeable, even\nthough they have similar names and purposes. See `NotImplementedError` for\ndetails on when to use it.\n\nChanged in version 3.9: Evaluating `NotImplemented` in a boolean context is\ndeprecated. While it currently evaluates as true, it will emit a\n`DeprecationWarning`. It will raise a `TypeError` in a future version of\nPython.\n\nThe same as the ellipsis literal \u201c`...`\u201d. Special value used mostly in\nconjunction with extended slicing syntax for user-defined container data\ntypes.\n\nThis constant is true if Python was not started with an `-O` option. See also\nthe `assert` statement.\n\nNote\n\nThe names `None`, `False`, `True` and `__debug__` cannot be reassigned\n(assignments to them, even as an attribute name, raise `SyntaxError`), so they\ncan be considered \u201ctrue\u201d constants.\n\nThe `site` module (which is imported automatically during startup, except if\nthe `-S` command-line option is given) adds several constants to the built-in\nnamespace. They are useful for the interactive interpreter shell and should\nnot be used in programs.\n\nObjects that when printed, print a message like \u201cUse quit() or Ctrl-D (i.e.\nEOF) to exit\u201d, and when called, raise `SystemExit` with the specified exit\ncode.\n\nObjects that when printed or called, print the text of copyright or credits,\nrespectively.\n\nObject that when printed, prints the message \u201cType license() to see the full\nlicense text\u201d, and when called, displays the full license text in a pager-like\nfashion (one screen at a time).\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "container.__iter__()", "path": "library/stdtypes#container.__iter__", "type": "Built-in Types", "text": "\nReturn an iterator object. The object is required to support the iterator\nprotocol described below. If a container supports different types of\niteration, additional methods can be provided to specifically request\niterators for those iteration types. (An example of an object supporting\nmultiple forms of iteration would be a tree structure which supports both\nbreadth-first and depth-first traversal.) This method corresponds to the\n`tp_iter` slot of the type structure for Python objects in the Python/C API.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib", "path": "library/contextlib", "type": "Runtime", "text": "\nSource code: Lib/contextlib.py\n\nThis module provides utilities for common tasks involving the `with`\nstatement. For more information see also Context Manager Types and With\nStatement Context Managers.\n\nFunctions and classes provided:\n\nAn abstract base class for classes that implement `object.__enter__()` and\n`object.__exit__()`. A default implementation for `object.__enter__()` is\nprovided which returns `self` while `object.__exit__()` is an abstract method\nwhich by default returns `None`. See also the definition of Context Manager\nTypes.\n\nNew in version 3.6.\n\nAn abstract base class for classes that implement `object.__aenter__()` and\n`object.__aexit__()`. A default implementation for `object.__aenter__()` is\nprovided which returns `self` while `object.__aexit__()` is an abstract method\nwhich by default returns `None`. See also the definition of Asynchronous\nContext Managers.\n\nNew in version 3.7.\n\nThis function is a decorator that can be used to define a factory function for\n`with` statement context managers, without needing to create a class or\nseparate `__enter__()` and `__exit__()` methods.\n\nWhile many objects natively support use in with statements, sometimes a\nresource needs to be managed that isn\u2019t a context manager in its own right,\nand doesn\u2019t implement a `close()` method for use with `contextlib.closing`\n\nAn abstract example would be the following to ensure correct resource\nmanagement:\n\nThe function being decorated must return a generator-iterator when called.\nThis iterator must yield exactly one value, which will be bound to the targets\nin the `with` statement\u2019s `as` clause, if any.\n\nAt the point where the generator yields, the block nested in the `with`\nstatement is executed. The generator is then resumed after the block is\nexited. If an unhandled exception occurs in the block, it is reraised inside\nthe generator at the point where the yield occurred. Thus, you can use a\n`try`\u2026`except`\u2026`finally` statement to trap the error (if any), or ensure that\nsome cleanup takes place. If an exception is trapped merely in order to log it\nor to perform some action (rather than to suppress it entirely), the generator\nmust reraise that exception. Otherwise the generator context manager will\nindicate to the `with` statement that the exception has been handled, and\nexecution will resume with the statement immediately following the `with`\nstatement.\n\n`contextmanager()` uses `ContextDecorator` so the context managers it creates\ncan be used as decorators as well as in `with` statements. When used as a\ndecorator, a new generator instance is implicitly created on each function\ncall (this allows the otherwise \u201cone-shot\u201d context managers created by\n`contextmanager()` to meet the requirement that context managers support\nmultiple invocations in order to be used as decorators).\n\nChanged in version 3.2: Use of `ContextDecorator`.\n\nSimilar to `contextmanager()`, but creates an asynchronous context manager.\n\nThis function is a decorator that can be used to define a factory function for\n`async with` statement asynchronous context managers, without needing to\ncreate a class or separate `__aenter__()` and `__aexit__()` methods. It must\nbe applied to an asynchronous generator function.\n\nA simple example:\n\nNew in version 3.7.\n\nReturn a context manager that closes thing upon completion of the block. This\nis basically equivalent to:\n\nAnd lets you write code like this:\n\nwithout needing to explicitly close `page`. Even if an error occurs,\n`page.close()` will be called when the `with` block is exited.\n\nReturn a context manager that returns enter_result from `__enter__`, but\notherwise does nothing. It is intended to be used as a stand-in for an\noptional context manager, for example:\n\nAn example using enter_result:\n\nNew in version 3.7.\n\nReturn a context manager that suppresses any of the specified exceptions if\nthey occur in the body of a with statement and then resumes execution with the\nfirst statement following the end of the with statement.\n\nAs with any other mechanism that completely suppresses exceptions, this\ncontext manager should be used only to cover very specific errors where\nsilently continuing with program execution is known to be the right thing to\ndo.\n\nFor example:\n\nThis code is equivalent to:\n\nThis context manager is reentrant.\n\nNew in version 3.4.\n\nContext manager for temporarily redirecting `sys.stdout` to another file or\nfile-like object.\n\nThis tool adds flexibility to existing functions or classes whose output is\nhardwired to stdout.\n\nFor example, the output of `help()` normally is sent to sys.stdout. You can\ncapture that output in a string by redirecting the output to an `io.StringIO`\nobject:\n\nTo send the output of `help()` to a file on disk, redirect the output to a\nregular file:\n\nTo send the output of `help()` to sys.stderr:\n\nNote that the global side effect on `sys.stdout` means that this context\nmanager is not suitable for use in library code and most threaded\napplications. It also has no effect on the output of subprocesses. However, it\nis still a useful approach for many utility scripts.\n\nThis context manager is reentrant.\n\nNew in version 3.4.\n\nSimilar to `redirect_stdout()` but redirecting `sys.stderr` to another file or\nfile-like object.\n\nThis context manager is reentrant.\n\nNew in version 3.5.\n\nA base class that enables a context manager to also be used as a decorator.\n\nContext managers inheriting from `ContextDecorator` have to implement\n`__enter__` and `__exit__` as normal. `__exit__` retains its optional\nexception handling even when used as a decorator.\n\n`ContextDecorator` is used by `contextmanager()`, so you get this\nfunctionality automatically.\n\nExample of `ContextDecorator`:\n\nThis change is just syntactic sugar for any construct of the following form:\n\n`ContextDecorator` lets you instead write:\n\nIt makes it clear that the `cm` applies to the whole function, rather than\njust a piece of it (and saving an indentation level is nice, too).\n\nExisting context managers that already have a base class can be extended by\nusing `ContextDecorator` as a mixin class:\n\nNote\n\nAs the decorated function must be able to be called multiple times, the\nunderlying context manager must support use in multiple `with` statements. If\nthis is not the case, then the original construct with the explicit `with`\nstatement inside the function should be used.\n\nNew in version 3.2.\n\nA context manager that is designed to make it easy to programmatically combine\nother context managers and cleanup functions, especially those that are\noptional or otherwise driven by input data.\n\nFor example, a set of files may easily be handled in a single with statement\nas follows:\n\nEach instance maintains a stack of registered callbacks that are called in\nreverse order when the instance is closed (either explicitly or implicitly at\nthe end of a `with` statement). Note that callbacks are not invoked implicitly\nwhen the context stack instance is garbage collected.\n\nThis stack model is used so that context managers that acquire their resources\nin their `__init__` method (such as file objects) can be handled correctly.\n\nSince registered callbacks are invoked in the reverse order of registration,\nthis ends up behaving as if multiple nested `with` statements had been used\nwith the registered set of callbacks. This even extends to exception handling\n- if an inner callback suppresses or replaces an exception, then outer\ncallbacks will be passed arguments based on that updated state.\n\nThis is a relatively low level API that takes care of the details of correctly\nunwinding the stack of exit callbacks. It provides a suitable foundation for\nhigher level context managers that manipulate the exit stack in application\nspecific ways.\n\nNew in version 3.3.\n\nEnters a new context manager and adds its `__exit__()` method to the callback\nstack. The return value is the result of the context manager\u2019s own\n`__enter__()` method.\n\nThese context managers may suppress exceptions just as they normally would if\nused directly as part of a `with` statement.\n\nAdds a context manager\u2019s `__exit__()` method to the callback stack.\n\nAs `__enter__` is not invoked, this method can be used to cover part of an\n`__enter__()` implementation with a context manager\u2019s own `__exit__()` method.\n\nIf passed an object that is not a context manager, this method assumes it is a\ncallback with the same signature as a context manager\u2019s `__exit__()` method\nand adds it directly to the callback stack.\n\nBy returning true values, these callbacks can suppress exceptions the same way\ncontext manager `__exit__()` methods can.\n\nThe passed in object is returned from the function, allowing this method to be\nused as a function decorator.\n\nAccepts an arbitrary callback function and arguments and adds it to the\ncallback stack.\n\nUnlike the other methods, callbacks added this way cannot suppress exceptions\n(as they are never passed the exception details).\n\nThe passed in callback is returned from the function, allowing this method to\nbe used as a function decorator.\n\nTransfers the callback stack to a fresh `ExitStack` instance and returns it.\nNo callbacks are invoked by this operation - instead, they will now be invoked\nwhen the new stack is closed (either explicitly or implicitly at the end of a\n`with` statement).\n\nFor example, a group of files can be opened as an \u201call or nothing\u201d operation\nas follows:\n\nImmediately unwinds the callback stack, invoking callbacks in the reverse\norder of registration. For any context managers and exit callbacks registered,\nthe arguments passed in will indicate that no exception occurred.\n\nAn asynchronous context manager, similar to `ExitStack`, that supports\ncombining both synchronous and asynchronous context managers, as well as\nhaving coroutines for cleanup logic.\n\nThe `close()` method is not implemented, `aclose()` must be used instead.\n\nSimilar to `enter_context()` but expects an asynchronous context manager.\n\nSimilar to `push()` but expects either an asynchronous context manager or a\ncoroutine function.\n\nSimilar to `callback()` but expects a coroutine function.\n\nSimilar to `close()` but properly handles awaitables.\n\nContinuing the example for `asynccontextmanager()`:\n\nNew in version 3.7.\n\nThis section describes some examples and recipes for making effective use of\nthe tools provided by `contextlib`.\n\nThe primary use case for `ExitStack` is the one given in the class\ndocumentation: supporting a variable number of context managers and other\ncleanup operations in a single `with` statement. The variability may come from\nthe number of context managers needed being driven by user input (such as\nopening a user specified collection of files), or from some of the context\nmanagers being optional:\n\nAs shown, `ExitStack` also makes it quite easy to use `with` statements to\nmanage arbitrary resources that don\u2019t natively support the context management\nprotocol.\n\nIt is occasionally desirable to catch exceptions from an `__enter__` method\nimplementation, without inadvertently catching exceptions from the `with`\nstatement body or the context manager\u2019s `__exit__` method. By using\n`ExitStack` the steps in the context management protocol can be separated\nslightly in order to allow this:\n\nActually needing to do this is likely to indicate that the underlying API\nshould be providing a direct resource management interface for use with\n`try`/`except`/`finally` statements, but not all APIs are well designed in\nthat regard. When a context manager is the only resource management API\nprovided, then `ExitStack` can make it easier to handle various situations\nthat can\u2019t be handled directly in a `with` statement.\n\nAs noted in the documentation of `ExitStack.push()`, this method can be useful\nin cleaning up an already allocated resource if later steps in the\n`__enter__()` implementation fail.\n\nHere\u2019s an example of doing this for a context manager that accepts resource\nacquisition and release functions, along with an optional validation function,\nand maps them to the context management protocol:\n\nA pattern you will sometimes see is a `try-finally` statement with a flag\nvariable to indicate whether or not the body of the `finally` clause should be\nexecuted. In its simplest form (that can\u2019t already be handled just by using an\n`except` clause instead), it looks something like this:\n\nAs with any `try` statement based code, this can cause problems for\ndevelopment and review, because the setup code and the cleanup code can end up\nbeing separated by arbitrarily long sections of code.\n\n`ExitStack` makes it possible to instead register a callback for execution at\nthe end of a `with` statement, and then later decide to skip executing that\ncallback:\n\nThis allows the intended cleanup up behaviour to be made explicit up front,\nrather than requiring a separate flag variable.\n\nIf a particular application uses this pattern a lot, it can be simplified even\nfurther by means of a small helper class:\n\nIf the resource cleanup isn\u2019t already neatly bundled into a standalone\nfunction, then it is still possible to use the decorator form of\n`ExitStack.callback()` to declare the resource cleanup in advance:\n\nDue to the way the decorator protocol works, a callback function declared this\nway cannot take any parameters. Instead, any resources to be released must be\naccessed as closure variables.\n\n`ContextDecorator` makes it possible to use a context manager in both an\nordinary `with` statement and also as a function decorator.\n\nFor example, it is sometimes useful to wrap functions or groups of statements\nwith a logger that can track the time of entry and time of exit. Rather than\nwriting both a function decorator and a context manager for the task,\ninheriting from `ContextDecorator` provides both capabilities in a single\ndefinition:\n\nInstances of this class can be used as both a context manager:\n\nAnd also as a function decorator:\n\nNote that there is one additional limitation when using context managers as\nfunction decorators: there\u2019s no way to access the return value of\n`__enter__()`. If that value is needed, then it is still necessary to use an\nexplicit `with` statement.\n\nSee also\n\nThe specification, background, and examples for the Python `with` statement.\n\nMost context managers are written in a way that means they can only be used\neffectively in a `with` statement once. These single use context managers must\nbe created afresh each time they\u2019re used - attempting to use them a second\ntime will trigger an exception or otherwise not work correctly.\n\nThis common limitation means that it is generally advisable to create context\nmanagers directly in the header of the `with` statement where they are used\n(as shown in all of the usage examples above).\n\nFiles are an example of effectively single use context managers, since the\nfirst `with` statement will close the file, preventing any further IO\noperations using that file object.\n\nContext managers created using `contextmanager()` are also single use context\nmanagers, and will complain about the underlying generator failing to yield if\nan attempt is made to use them a second time:\n\nMore sophisticated context managers may be \u201creentrant\u201d. These context managers\ncan not only be used in multiple `with` statements, but may also be used\ninside a `with` statement that is already using the same context manager.\n\n`threading.RLock` is an example of a reentrant context manager, as are\n`suppress()` and `redirect_stdout()`. Here\u2019s a very simple example of\nreentrant use:\n\nReal world examples of reentrancy are more likely to involve multiple\nfunctions calling each other and hence be far more complicated than this\nexample.\n\nNote also that being reentrant is not the same thing as being thread safe.\n`redirect_stdout()`, for example, is definitely not thread safe, as it makes a\nglobal modification to the system state by binding `sys.stdout` to a different\nstream.\n\nDistinct from both single use and reentrant context managers are \u201creusable\u201d\ncontext managers (or, to be completely explicit, \u201creusable, but not reentrant\u201d\ncontext managers, since reentrant context managers are also reusable). These\ncontext managers support being used multiple times, but will fail (or\notherwise not work correctly) if the specific context manager instance has\nalready been used in a containing with statement.\n\n`threading.Lock` is an example of a reusable, but not reentrant, context\nmanager (for a reentrant lock, it is necessary to use `threading.RLock`\ninstead).\n\nAnother example of a reusable, but not reentrant, context manager is\n`ExitStack`, as it invokes all currently registered callbacks when leaving any\nwith statement, regardless of where those callbacks were added:\n\nAs the output from the example shows, reusing a single stack object across\nmultiple with statements works correctly, but attempting to nest them will\ncause the stack to be cleared at the end of the innermost with statement,\nwhich is unlikely to be desirable behaviour.\n\nUsing separate `ExitStack` instances instead of reusing a single instance\navoids that problem:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.AbstractAsyncContextManager", "path": "library/contextlib#contextlib.AbstractAsyncContextManager", "type": "Runtime", "text": "\nAn abstract base class for classes that implement `object.__aenter__()` and\n`object.__aexit__()`. A default implementation for `object.__aenter__()` is\nprovided which returns `self` while `object.__aexit__()` is an abstract method\nwhich by default returns `None`. See also the definition of Asynchronous\nContext Managers.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.AbstractContextManager", "path": "library/contextlib#contextlib.AbstractContextManager", "type": "Runtime", "text": "\nAn abstract base class for classes that implement `object.__enter__()` and\n`object.__exit__()`. A default implementation for `object.__enter__()` is\nprovided which returns `self` while `object.__exit__()` is an abstract method\nwhich by default returns `None`. See also the definition of Context Manager\nTypes.\n\nNew in version 3.6.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.asynccontextmanager()", "path": "library/contextlib#contextlib.asynccontextmanager", "type": "Runtime", "text": "\nSimilar to `contextmanager()`, but creates an asynchronous context manager.\n\nThis function is a decorator that can be used to define a factory function for\n`async with` statement asynchronous context managers, without needing to\ncreate a class or separate `__aenter__()` and `__aexit__()` methods. It must\nbe applied to an asynchronous generator function.\n\nA simple example:\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.AsyncExitStack", "path": "library/contextlib#contextlib.AsyncExitStack", "type": "Runtime", "text": "\nAn asynchronous context manager, similar to `ExitStack`, that supports\ncombining both synchronous and asynchronous context managers, as well as\nhaving coroutines for cleanup logic.\n\nThe `close()` method is not implemented, `aclose()` must be used instead.\n\nSimilar to `enter_context()` but expects an asynchronous context manager.\n\nSimilar to `push()` but expects either an asynchronous context manager or a\ncoroutine function.\n\nSimilar to `callback()` but expects a coroutine function.\n\nSimilar to `close()` but properly handles awaitables.\n\nContinuing the example for `asynccontextmanager()`:\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.AsyncExitStack.aclose()", "path": "library/contextlib#contextlib.AsyncExitStack.aclose", "type": "Runtime", "text": "\nSimilar to `close()` but properly handles awaitables.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.AsyncExitStack.enter_async_context()", "path": "library/contextlib#contextlib.AsyncExitStack.enter_async_context", "type": "Runtime", "text": "\nSimilar to `enter_context()` but expects an asynchronous context manager.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.AsyncExitStack.push_async_callback()", "path": "library/contextlib#contextlib.AsyncExitStack.push_async_callback", "type": "Runtime", "text": "\nSimilar to `callback()` but expects a coroutine function.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.AsyncExitStack.push_async_exit()", "path": "library/contextlib#contextlib.AsyncExitStack.push_async_exit", "type": "Runtime", "text": "\nSimilar to `push()` but expects either an asynchronous context manager or a\ncoroutine function.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.closing()", "path": "library/contextlib#contextlib.closing", "type": "Runtime", "text": "\nReturn a context manager that closes thing upon completion of the block. This\nis basically equivalent to:\n\nAnd lets you write code like this:\n\nwithout needing to explicitly close `page`. Even if an error occurs,\n`page.close()` will be called when the `with` block is exited.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.ContextDecorator", "path": "library/contextlib#contextlib.ContextDecorator", "type": "Runtime", "text": "\nA base class that enables a context manager to also be used as a decorator.\n\nContext managers inheriting from `ContextDecorator` have to implement\n`__enter__` and `__exit__` as normal. `__exit__` retains its optional\nexception handling even when used as a decorator.\n\n`ContextDecorator` is used by `contextmanager()`, so you get this\nfunctionality automatically.\n\nExample of `ContextDecorator`:\n\nThis change is just syntactic sugar for any construct of the following form:\n\n`ContextDecorator` lets you instead write:\n\nIt makes it clear that the `cm` applies to the whole function, rather than\njust a piece of it (and saving an indentation level is nice, too).\n\nExisting context managers that already have a base class can be extended by\nusing `ContextDecorator` as a mixin class:\n\nNote\n\nAs the decorated function must be able to be called multiple times, the\nunderlying context manager must support use in multiple `with` statements. If\nthis is not the case, then the original construct with the explicit `with`\nstatement inside the function should be used.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.contextmanager()", "path": "library/contextlib#contextlib.contextmanager", "type": "Runtime", "text": "\nThis function is a decorator that can be used to define a factory function for\n`with` statement context managers, without needing to create a class or\nseparate `__enter__()` and `__exit__()` methods.\n\nWhile many objects natively support use in with statements, sometimes a\nresource needs to be managed that isn\u2019t a context manager in its own right,\nand doesn\u2019t implement a `close()` method for use with `contextlib.closing`\n\nAn abstract example would be the following to ensure correct resource\nmanagement:\n\nThe function being decorated must return a generator-iterator when called.\nThis iterator must yield exactly one value, which will be bound to the targets\nin the `with` statement\u2019s `as` clause, if any.\n\nAt the point where the generator yields, the block nested in the `with`\nstatement is executed. The generator is then resumed after the block is\nexited. If an unhandled exception occurs in the block, it is reraised inside\nthe generator at the point where the yield occurred. Thus, you can use a\n`try`\u2026`except`\u2026`finally` statement to trap the error (if any), or ensure that\nsome cleanup takes place. If an exception is trapped merely in order to log it\nor to perform some action (rather than to suppress it entirely), the generator\nmust reraise that exception. Otherwise the generator context manager will\nindicate to the `with` statement that the exception has been handled, and\nexecution will resume with the statement immediately following the `with`\nstatement.\n\n`contextmanager()` uses `ContextDecorator` so the context managers it creates\ncan be used as decorators as well as in `with` statements. When used as a\ndecorator, a new generator instance is implicitly created on each function\ncall (this allows the otherwise \u201cone-shot\u201d context managers created by\n`contextmanager()` to meet the requirement that context managers support\nmultiple invocations in order to be used as decorators).\n\nChanged in version 3.2: Use of `ContextDecorator`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.ExitStack", "path": "library/contextlib#contextlib.ExitStack", "type": "Runtime", "text": "\nA context manager that is designed to make it easy to programmatically combine\nother context managers and cleanup functions, especially those that are\noptional or otherwise driven by input data.\n\nFor example, a set of files may easily be handled in a single with statement\nas follows:\n\nEach instance maintains a stack of registered callbacks that are called in\nreverse order when the instance is closed (either explicitly or implicitly at\nthe end of a `with` statement). Note that callbacks are not invoked implicitly\nwhen the context stack instance is garbage collected.\n\nThis stack model is used so that context managers that acquire their resources\nin their `__init__` method (such as file objects) can be handled correctly.\n\nSince registered callbacks are invoked in the reverse order of registration,\nthis ends up behaving as if multiple nested `with` statements had been used\nwith the registered set of callbacks. This even extends to exception handling\n- if an inner callback suppresses or replaces an exception, then outer\ncallbacks will be passed arguments based on that updated state.\n\nThis is a relatively low level API that takes care of the details of correctly\nunwinding the stack of exit callbacks. It provides a suitable foundation for\nhigher level context managers that manipulate the exit stack in application\nspecific ways.\n\nNew in version 3.3.\n\nEnters a new context manager and adds its `__exit__()` method to the callback\nstack. The return value is the result of the context manager\u2019s own\n`__enter__()` method.\n\nThese context managers may suppress exceptions just as they normally would if\nused directly as part of a `with` statement.\n\nAdds a context manager\u2019s `__exit__()` method to the callback stack.\n\nAs `__enter__` is not invoked, this method can be used to cover part of an\n`__enter__()` implementation with a context manager\u2019s own `__exit__()` method.\n\nIf passed an object that is not a context manager, this method assumes it is a\ncallback with the same signature as a context manager\u2019s `__exit__()` method\nand adds it directly to the callback stack.\n\nBy returning true values, these callbacks can suppress exceptions the same way\ncontext manager `__exit__()` methods can.\n\nThe passed in object is returned from the function, allowing this method to be\nused as a function decorator.\n\nAccepts an arbitrary callback function and arguments and adds it to the\ncallback stack.\n\nUnlike the other methods, callbacks added this way cannot suppress exceptions\n(as they are never passed the exception details).\n\nThe passed in callback is returned from the function, allowing this method to\nbe used as a function decorator.\n\nTransfers the callback stack to a fresh `ExitStack` instance and returns it.\nNo callbacks are invoked by this operation - instead, they will now be invoked\nwhen the new stack is closed (either explicitly or implicitly at the end of a\n`with` statement).\n\nFor example, a group of files can be opened as an \u201call or nothing\u201d operation\nas follows:\n\nImmediately unwinds the callback stack, invoking callbacks in the reverse\norder of registration. For any context managers and exit callbacks registered,\nthe arguments passed in will indicate that no exception occurred.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.ExitStack.callback()", "path": "library/contextlib#contextlib.ExitStack.callback", "type": "Runtime", "text": "\nAccepts an arbitrary callback function and arguments and adds it to the\ncallback stack.\n\nUnlike the other methods, callbacks added this way cannot suppress exceptions\n(as they are never passed the exception details).\n\nThe passed in callback is returned from the function, allowing this method to\nbe used as a function decorator.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.ExitStack.close()", "path": "library/contextlib#contextlib.ExitStack.close", "type": "Runtime", "text": "\nImmediately unwinds the callback stack, invoking callbacks in the reverse\norder of registration. For any context managers and exit callbacks registered,\nthe arguments passed in will indicate that no exception occurred.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.ExitStack.enter_context()", "path": "library/contextlib#contextlib.ExitStack.enter_context", "type": "Runtime", "text": "\nEnters a new context manager and adds its `__exit__()` method to the callback\nstack. The return value is the result of the context manager\u2019s own\n`__enter__()` method.\n\nThese context managers may suppress exceptions just as they normally would if\nused directly as part of a `with` statement.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.ExitStack.pop_all()", "path": "library/contextlib#contextlib.ExitStack.pop_all", "type": "Runtime", "text": "\nTransfers the callback stack to a fresh `ExitStack` instance and returns it.\nNo callbacks are invoked by this operation - instead, they will now be invoked\nwhen the new stack is closed (either explicitly or implicitly at the end of a\n`with` statement).\n\nFor example, a group of files can be opened as an \u201call or nothing\u201d operation\nas follows:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.ExitStack.push()", "path": "library/contextlib#contextlib.ExitStack.push", "type": "Runtime", "text": "\nAdds a context manager\u2019s `__exit__()` method to the callback stack.\n\nAs `__enter__` is not invoked, this method can be used to cover part of an\n`__enter__()` implementation with a context manager\u2019s own `__exit__()` method.\n\nIf passed an object that is not a context manager, this method assumes it is a\ncallback with the same signature as a context manager\u2019s `__exit__()` method\nand adds it directly to the callback stack.\n\nBy returning true values, these callbacks can suppress exceptions the same way\ncontext manager `__exit__()` methods can.\n\nThe passed in object is returned from the function, allowing this method to be\nused as a function decorator.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.nullcontext()", "path": "library/contextlib#contextlib.nullcontext", "type": "Runtime", "text": "\nReturn a context manager that returns enter_result from `__enter__`, but\notherwise does nothing. It is intended to be used as a stand-in for an\noptional context manager, for example:\n\nAn example using enter_result:\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.redirect_stderr()", "path": "library/contextlib#contextlib.redirect_stderr", "type": "Runtime", "text": "\nSimilar to `redirect_stdout()` but redirecting `sys.stderr` to another file or\nfile-like object.\n\nThis context manager is reentrant.\n\nNew in version 3.5.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.redirect_stdout()", "path": "library/contextlib#contextlib.redirect_stdout", "type": "Runtime", "text": "\nContext manager for temporarily redirecting `sys.stdout` to another file or\nfile-like object.\n\nThis tool adds flexibility to existing functions or classes whose output is\nhardwired to stdout.\n\nFor example, the output of `help()` normally is sent to sys.stdout. You can\ncapture that output in a string by redirecting the output to an `io.StringIO`\nobject:\n\nTo send the output of `help()` to a file on disk, redirect the output to a\nregular file:\n\nTo send the output of `help()` to sys.stderr:\n\nNote that the global side effect on `sys.stdout` means that this context\nmanager is not suitable for use in library code and most threaded\napplications. It also has no effect on the output of subprocesses. However, it\nis still a useful approach for many utility scripts.\n\nThis context manager is reentrant.\n\nNew in version 3.4.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextlib.suppress()", "path": "library/contextlib#contextlib.suppress", "type": "Runtime", "text": "\nReturn a context manager that suppresses any of the specified exceptions if\nthey occur in the body of a with statement and then resumes execution with the\nfirst statement following the end of the with statement.\n\nAs with any other mechanism that completely suppresses exceptions, this\ncontext manager should be used only to cover very specific errors where\nsilently continuing with program execution is known to be the right thing to\ndo.\n\nFor example:\n\nThis code is equivalent to:\n\nThis context manager is reentrant.\n\nNew in version 3.4.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextmanager.__enter__()", "path": "library/stdtypes#contextmanager.__enter__", "type": "Built-in Types", "text": "\nEnter the runtime context and return either this object or another object\nrelated to the runtime context. The value returned by this method is bound to\nthe identifier in the `as` clause of `with` statements using this context\nmanager.\n\nAn example of a context manager that returns itself is a file object. File\nobjects return themselves from __enter__() to allow `open()` to be used as the\ncontext expression in a `with` statement.\n\nAn example of a context manager that returns a related object is the one\nreturned by `decimal.localcontext()`. These managers set the active decimal\ncontext to a copy of the original decimal context and then return the copy.\nThis allows changes to be made to the current decimal context in the body of\nthe `with` statement without affecting code outside the `with` statement.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextmanager.__exit__()", "path": "library/stdtypes#contextmanager.__exit__", "type": "Built-in Types", "text": "\nExit the runtime context and return a Boolean flag indicating if any exception\nthat occurred should be suppressed. If an exception occurred while executing\nthe body of the `with` statement, the arguments contain the exception type,\nvalue and traceback information. Otherwise, all three arguments are `None`.\n\nReturning a true value from this method will cause the `with` statement to\nsuppress the exception and continue execution with the statement immediately\nfollowing the `with` statement. Otherwise the exception continues propagating\nafter this method has finished executing. Exceptions that occur during\nexecution of this method will replace any exception that occurred in the body\nof the `with` statement.\n\nThe exception passed in should never be reraised explicitly - instead, this\nmethod should return a false value to indicate that the method completed\nsuccessfully and does not want to suppress the raised exception. This allows\ncontext management code to easily detect whether or not an `__exit__()` method\nhas actually failed.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars", "path": "library/contextvars", "type": "Concurrent Execution", "text": "\nThis module provides APIs to manage, store, and access context-local state.\nThe `ContextVar` class is used to declare and work with Context Variables. The\n`copy_context()` function and the `Context` class should be used to manage the\ncurrent context in asynchronous frameworks.\n\nContext managers that have state should use Context Variables instead of\n`threading.local()` to prevent their state from bleeding to other code\nunexpectedly, when used in concurrent code.\n\nSee also PEP 567 for additional details.\n\nNew in version 3.7.\n\nThis class is used to declare a new Context Variable, e.g.:\n\nThe required name parameter is used for introspection and debug purposes.\n\nThe optional keyword-only default parameter is returned by `ContextVar.get()`\nwhen no value for the variable is found in the current context.\n\nImportant: Context Variables should be created at the top module level and\nnever in closures. `Context` objects hold strong references to context\nvariables which prevents context variables from being properly garbage\ncollected.\n\nThe name of the variable. This is a read-only property.\n\nNew in version 3.7.1.\n\nReturn a value for the context variable for the current context.\n\nIf there is no value for the variable in the current context, the method will:\n\nCall to set a new value for the context variable in the current context.\n\nThe required value argument is the new value for the context variable.\n\nReturns a `Token` object that can be used to restore the variable to its\nprevious value via the `ContextVar.reset()` method.\n\nReset the context variable to the value it had before the `ContextVar.set()`\nthat created the token was used.\n\nFor example:\n\nToken objects are returned by the `ContextVar.set()` method. They can be\npassed to the `ContextVar.reset()` method to revert the value of the variable\nto what it was before the corresponding set.\n\nA read-only property. Points to the `ContextVar` object that created the\ntoken.\n\nA read-only property. Set to the value the variable had before the\n`ContextVar.set()` method call that created the token. It points to\n`Token.MISSING` is the variable was not set before the call.\n\nA marker object used by `Token.old_value`.\n\nReturns a copy of the current `Context` object.\n\nThe following snippet gets a copy of the current context and prints all\nvariables and their values that are set in it:\n\nThe function has an O(1) complexity, i.e. works equally fast for contexts with\na few context variables and for contexts that have a lot of them.\n\nA mapping of `ContextVars` to their values.\n\n`Context()` creates an empty context with no values in it. To get a copy of\nthe current context use the `copy_context()` function.\n\nContext implements the `collections.abc.Mapping` interface.\n\nExecute `callable(*args, **kwargs)` code in the context object the run method\nis called on. Return the result of the execution or propagate an exception if\none occurred.\n\nAny changes to any context variables that callable makes will be contained in\nthe context object:\n\nThe method raises a `RuntimeError` when called on the same context object from\nmore than one OS thread, or when called recursively.\n\nReturn a shallow copy of the context object.\n\nReturn `True` if the context has a value for var set; return `False`\notherwise.\n\nReturn the value of the var `ContextVar` variable. If the variable is not set\nin the context object, a `KeyError` is raised.\n\nReturn the value for var if var has the value in the context object. Return\ndefault otherwise. If default is not given, return `None`.\n\nReturn an iterator over the variables stored in the context object.\n\nReturn the number of variables set in the context object.\n\nReturn a list of all variables in the context object.\n\nReturn a list of all variables\u2019 values in the context object.\n\nReturn a list of 2-tuples containing all variables and their values in the\ncontext object.\n\nContext variables are natively supported in `asyncio` and are ready to be used\nwithout any extra configuration. For example, here is a simple echo server,\nthat uses a context variable to make the address of a remote client available\nin the Task that handles that client:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.Context", "path": "library/contextvars#contextvars.Context", "type": "Concurrent Execution", "text": "\nA mapping of `ContextVars` to their values.\n\n`Context()` creates an empty context with no values in it. To get a copy of\nthe current context use the `copy_context()` function.\n\nContext implements the `collections.abc.Mapping` interface.\n\nExecute `callable(*args, **kwargs)` code in the context object the run method\nis called on. Return the result of the execution or propagate an exception if\none occurred.\n\nAny changes to any context variables that callable makes will be contained in\nthe context object:\n\nThe method raises a `RuntimeError` when called on the same context object from\nmore than one OS thread, or when called recursively.\n\nReturn a shallow copy of the context object.\n\nReturn `True` if the context has a value for var set; return `False`\notherwise.\n\nReturn the value of the var `ContextVar` variable. If the variable is not set\nin the context object, a `KeyError` is raised.\n\nReturn the value for var if var has the value in the context object. Return\ndefault otherwise. If default is not given, return `None`.\n\nReturn an iterator over the variables stored in the context object.\n\nReturn the number of variables set in the context object.\n\nReturn a list of all variables in the context object.\n\nReturn a list of all variables\u2019 values in the context object.\n\nReturn a list of 2-tuples containing all variables and their values in the\ncontext object.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.Context.copy()", "path": "library/contextvars#contextvars.Context.copy", "type": "Concurrent Execution", "text": "\nReturn a shallow copy of the context object.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.Context.get()", "path": "library/contextvars#contextvars.Context.get", "type": "Concurrent Execution", "text": "\nReturn the value for var if var has the value in the context object. Return\ndefault otherwise. If default is not given, return `None`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.Context.items()", "path": "library/contextvars#contextvars.Context.items", "type": "Concurrent Execution", "text": "\nReturn a list of 2-tuples containing all variables and their values in the\ncontext object.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.Context.keys()", "path": "library/contextvars#contextvars.Context.keys", "type": "Concurrent Execution", "text": "\nReturn a list of all variables in the context object.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.Context.run()", "path": "library/contextvars#contextvars.Context.run", "type": "Concurrent Execution", "text": "\nExecute `callable(*args, **kwargs)` code in the context object the run method\nis called on. Return the result of the execution or propagate an exception if\none occurred.\n\nAny changes to any context variables that callable makes will be contained in\nthe context object:\n\nThe method raises a `RuntimeError` when called on the same context object from\nmore than one OS thread, or when called recursively.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.Context.values()", "path": "library/contextvars#contextvars.Context.values", "type": "Concurrent Execution", "text": "\nReturn a list of all variables\u2019 values in the context object.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.ContextVar", "path": "library/contextvars#contextvars.ContextVar", "type": "Concurrent Execution", "text": "\nThis class is used to declare a new Context Variable, e.g.:\n\nThe required name parameter is used for introspection and debug purposes.\n\nThe optional keyword-only default parameter is returned by `ContextVar.get()`\nwhen no value for the variable is found in the current context.\n\nImportant: Context Variables should be created at the top module level and\nnever in closures. `Context` objects hold strong references to context\nvariables which prevents context variables from being properly garbage\ncollected.\n\nThe name of the variable. This is a read-only property.\n\nNew in version 3.7.1.\n\nReturn a value for the context variable for the current context.\n\nIf there is no value for the variable in the current context, the method will:\n\nCall to set a new value for the context variable in the current context.\n\nThe required value argument is the new value for the context variable.\n\nReturns a `Token` object that can be used to restore the variable to its\nprevious value via the `ContextVar.reset()` method.\n\nReset the context variable to the value it had before the `ContextVar.set()`\nthat created the token was used.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.ContextVar.get()", "path": "library/contextvars#contextvars.ContextVar.get", "type": "Concurrent Execution", "text": "\nReturn a value for the context variable for the current context.\n\nIf there is no value for the variable in the current context, the method will:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.ContextVar.name", "path": "library/contextvars#contextvars.ContextVar.name", "type": "Concurrent Execution", "text": "\nThe name of the variable. This is a read-only property.\n\nNew in version 3.7.1.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.ContextVar.reset()", "path": "library/contextvars#contextvars.ContextVar.reset", "type": "Concurrent Execution", "text": "\nReset the context variable to the value it had before the `ContextVar.set()`\nthat created the token was used.\n\nFor example:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.ContextVar.set()", "path": "library/contextvars#contextvars.ContextVar.set", "type": "Concurrent Execution", "text": "\nCall to set a new value for the context variable in the current context.\n\nThe required value argument is the new value for the context variable.\n\nReturns a `Token` object that can be used to restore the variable to its\nprevious value via the `ContextVar.reset()` method.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.contextvars.Token", "path": "library/contextvars#contextvars.contextvars.Token", "type": "Concurrent Execution", "text": "\nToken objects are returned by the `ContextVar.set()` method. They can be\npassed to the `ContextVar.reset()` method to revert the value of the variable\nto what it was before the corresponding set.\n\nA read-only property. Points to the `ContextVar` object that created the\ntoken.\n\nA read-only property. Set to the value the variable had before the\n`ContextVar.set()` method call that created the token. It points to\n`Token.MISSING` is the variable was not set before the call.\n\nA marker object used by `Token.old_value`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.contextvars.Token.Token.MISSING", "path": "library/contextvars#contextvars.contextvars.Token.Token.MISSING", "type": "Concurrent Execution", "text": "\nA marker object used by `Token.old_value`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.contextvars.Token.Token.old_value", "path": "library/contextvars#contextvars.contextvars.Token.Token.old_value", "type": "Concurrent Execution", "text": "\nA read-only property. Set to the value the variable had before the\n`ContextVar.set()` method call that created the token. It points to\n`Token.MISSING` is the variable was not set before the call.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.contextvars.Token.Token.var", "path": "library/contextvars#contextvars.contextvars.Token.Token.var", "type": "Concurrent Execution", "text": "\nA read-only property. Points to the `ContextVar` object that created the\ntoken.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "contextvars.copy_context()", "path": "library/contextvars#contextvars.copy_context", "type": "Concurrent Execution", "text": "\nReturns a copy of the current `Context` object.\n\nThe following snippet gets a copy of the current context and prints all\nvariables and their values that are set in it:\n\nThe function has an O(1) complexity, i.e. works equally fast for contexts with\na few context variables and for contexts that have a lot of them.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copy", "path": "library/copy", "type": "Data Types", "text": "\nSource code: Lib/copy.py\n\nAssignment statements in Python do not copy objects, they create bindings\nbetween a target and an object. For collections that are mutable or contain\nmutable items, a copy is sometimes needed so one can change one copy without\nchanging the other. This module provides generic shallow and deep copy\noperations (explained below).\n\nInterface summary:\n\nReturn a shallow copy of x.\n\nReturn a deep copy of x.\n\nRaised for module specific errors.\n\nThe difference between shallow and deep copying is only relevant for compound\nobjects (objects that contain other objects, like lists or class instances):\n\nTwo problems often exist with deep copy operations that don\u2019t exist with\nshallow copy operations:\n\nThe `deepcopy()` function avoids these problems by:\n\nThis module does not copy types like module, method, stack trace, stack frame,\nfile, socket, window, array, or any similar types. It does \u201ccopy\u201d functions\nand classes (shallow and deeply), by returning the original object unchanged;\nthis is compatible with the way these are treated by the `pickle` module.\n\nShallow copies of dictionaries can be made using `dict.copy()`, and of lists\nby assigning a slice of the entire list, for example, `copied_list =\noriginal_list[:]`.\n\nClasses can use the same interfaces to control copying that they use to\ncontrol pickling. See the description of module `pickle` for information on\nthese methods. In fact, the `copy` module uses the registered pickle functions\nfrom the `copyreg` module.\n\nIn order for a class to define its own copy implementation, it can define\nspecial methods `__copy__()` and `__deepcopy__()`. The former is called to\nimplement the shallow copy operation; no additional arguments are passed. The\nlatter is called to implement the deep copy operation; it is passed one\nargument, the `memo` dictionary. If the `__deepcopy__()` implementation needs\nto make a deep copy of a component, it should call the `deepcopy()` function\nwith the component as first argument and the memo dictionary as second\nargument.\n\nSee also\n\nDiscussion of the special methods used to support object state retrieval and\nrestoration.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copy.copy()", "path": "library/copy#copy.copy", "type": "Data Types", "text": "\nReturn a shallow copy of x.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copy.deepcopy()", "path": "library/copy#copy.deepcopy", "type": "Data Types", "text": "\nReturn a deep copy of x.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copy.Error", "path": "library/copy#copy.Error", "type": "Data Types", "text": "\nRaised for module specific errors.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copyreg", "path": "library/copyreg", "type": "Data Persistence", "text": "\nSource code: Lib/copyreg.py\n\nThe `copyreg` module offers a way to define functions used while pickling\nspecific objects. The `pickle` and `copy` modules use those functions when\npickling/copying those objects. The module provides configuration information\nabout object constructors which are not classes. Such constructors may be\nfactory functions or class instances.\n\nDeclares object to be a valid constructor. If object is not callable (and\nhence not valid as a constructor), raises `TypeError`.\n\nDeclares that function should be used as a \u201creduction\u201d function for objects of\ntype type. function should return either a string or a tuple containing two or\nthree elements.\n\nThe optional constructor parameter, if provided, is a callable object which\ncan be used to reconstruct the object when called with the tuple of arguments\nreturned by function at pickling time. `TypeError` will be raised if object is\na class or constructor is not callable.\n\nSee the `pickle` module for more details on the interface expected of function\nand constructor. Note that the `dispatch_table` attribute of a pickler object\nor subclass of `pickle.Pickler` can also be used for declaring reduction\nfunctions.\n\nThe example below would like to show how to register a pickle function and how\nit will be used:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copyreg.constructor()", "path": "library/copyreg#copyreg.constructor", "type": "Data Persistence", "text": "\nDeclares object to be a valid constructor. If object is not callable (and\nhence not valid as a constructor), raises `TypeError`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copyreg.pickle()", "path": "library/copyreg#copyreg.pickle", "type": "Data Persistence", "text": "\nDeclares that function should be used as a \u201creduction\u201d function for objects of\ntype type. function should return either a string or a tuple containing two or\nthree elements.\n\nThe optional constructor parameter, if provided, is a callable object which\ncan be used to reconstruct the object when called with the tuple of arguments\nreturned by function at pickling time. `TypeError` will be raised if object is\na class or constructor is not callable.\n\nSee the `pickle` module for more details on the interface expected of function\nand constructor. Note that the `dispatch_table` attribute of a pickler object\nor subclass of `pickle.Pickler` can also be used for declaring reduction\nfunctions.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "copyright", "path": "library/constants#copyright", "type": "Built-in Constants", "text": "\nObjects that when printed or called, print the text of copyright or credits,\nrespectively.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "Coroutines and Tasks", "path": "library/asyncio-task", "type": "Asynchronous I/O", "text": "\nThis section outlines high-level asyncio APIs to work with coroutines and\nTasks.\n\nCoroutines declared with the async/await syntax is the preferred way of\nwriting asyncio applications. For example, the following snippet of code\n(requires Python 3.7+) prints \u201chello\u201d, waits 1 second, and then prints\n\u201cworld\u201d:\n\nNote that simply calling a coroutine will not schedule it to be executed:\n\nTo actually run a coroutine, asyncio provides three main mechanisms:\n\nAwaiting on a coroutine. The following snippet of code will print \u201chello\u201d\nafter waiting for 1 second, and then print \u201cworld\u201d after waiting for another 2\nseconds:\n\nExpected output:\n\nThe `asyncio.create_task()` function to run coroutines concurrently as asyncio\n`Tasks`.\n\nLet\u2019s modify the above example and run two `say_after` coroutines\nconcurrently:\n\nNote that expected output now shows that the snippet runs 1 second faster than\nbefore:\n\nWe say that an object is an awaitable object if it can be used in an `await`\nexpression. Many asyncio APIs are designed to accept awaitables.\n\nThere are three main types of awaitable objects: coroutines, Tasks, and\nFutures.\n\nPython coroutines are awaitables and therefore can be awaited from other\ncoroutines:\n\nImportant\n\nIn this documentation the term \u201ccoroutine\u201d can be used for two closely related\nconcepts:\n\nasyncio also supports legacy generator-based coroutines.\n\nTasks are used to schedule coroutines concurrently.\n\nWhen a coroutine is wrapped into a Task with functions like\n`asyncio.create_task()` the coroutine is automatically scheduled to run soon:\n\nA `Future` is a special low-level awaitable object that represents an eventual\nresult of an asynchronous operation.\n\nWhen a Future object is awaited it means that the coroutine will wait until\nthe Future is resolved in some other place.\n\nFuture objects in asyncio are needed to allow callback-based code to be used\nwith async/await.\n\nNormally there is no need to create Future objects at the application level\ncode.\n\nFuture objects, sometimes exposed by libraries and some asyncio APIs, can be\nawaited:\n\nA good example of a low-level function that returns a Future object is\n`loop.run_in_executor()`.\n\nExecute the coroutine coro and return the result.\n\nThis function runs the passed coroutine, taking care of managing the asyncio\nevent loop, finalizing asynchronous generators, and closing the threadpool.\n\nThis function cannot be called when another asyncio event loop is running in\nthe same thread.\n\nIf debug is `True`, the event loop will be run in debug mode.\n\nThis function always creates a new event loop and closes it at the end. It\nshould be used as a main entry point for asyncio programs, and should ideally\nonly be called once.\n\nExample:\n\nNew in version 3.7.\n\nChanged in version 3.9: Updated to use `loop.shutdown_default_executor()`.\n\nNote\n\nThe source code for `asyncio.run()` can be found in Lib/asyncio/runners.py.\n\nWrap the coro coroutine into a `Task` and schedule its execution. Return the\nTask object.\n\nIf name is not `None`, it is set as the name of the task using\n`Task.set_name()`.\n\nThe task is executed in the loop returned by `get_running_loop()`,\n`RuntimeError` is raised if there is no running loop in current thread.\n\nThis function has been added in Python 3.7. Prior to Python 3.7, the low-level\n`asyncio.ensure_future()` function can be used instead:\n\nNew in version 3.7.\n\nChanged in version 3.8: Added the `name` parameter.\n\nBlock for delay seconds.\n\nIf result is provided, it is returned to the caller when the coroutine\ncompletes.\n\n`sleep()` always suspends the current task, allowing other tasks to run.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample of coroutine displaying the current date every second for 5 seconds:\n\nRun awaitable objects in the aws sequence concurrently.\n\nIf any awaitable in aws is a coroutine, it is automatically scheduled as a\nTask.\n\nIf all awaitables are completed successfully, the result is an aggregate list\nof returned values. The order of result values corresponds to the order of\nawaitables in aws.\n\nIf return_exceptions is `False` (default), the first raised exception is\nimmediately propagated to the task that awaits on `gather()`. Other awaitables\nin the aws sequence won\u2019t be cancelled and will continue to run.\n\nIf return_exceptions is `True`, exceptions are treated the same as successful\nresults, and aggregated in the result list.\n\nIf `gather()` is cancelled, all submitted awaitables (that have not completed\nyet) are also cancelled.\n\nIf any Task or Future from the aws sequence is cancelled, it is treated as if\nit raised `CancelledError` \u2013 the `gather()` call is not cancelled in this\ncase. This is to prevent the cancellation of one submitted Task/Future to\ncause other Tasks/Futures to be cancelled.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample:\n\nNote\n\nIf return_exceptions is False, cancelling gather() after it has been marked\ndone won\u2019t cancel any submitted awaitables. For instance, gather can be marked\ndone after propagating an exception to the caller, therefore, calling\n`gather.cancel()` after catching an exception (raised by one of the\nawaitables) from gather won\u2019t cancel any other awaitables.\n\nChanged in version 3.7: If the gather itself is cancelled, the cancellation is\npropagated regardless of return_exceptions.\n\nProtect an awaitable object from being `cancelled`.\n\nIf aw is a coroutine it is automatically scheduled as a Task.\n\nThe statement:\n\nis equivalent to:\n\nexcept that if the coroutine containing it is cancelled, the Task running in\n`something()` is not cancelled. From the point of view of `something()`, the\ncancellation did not happen. Although its caller is still cancelled, so the\n\u201cawait\u201d expression still raises a `CancelledError`.\n\nIf `something()` is cancelled by other means (i.e. from within itself) that\nwould also cancel `shield()`.\n\nIf it is desired to completely ignore cancellation (not recommended) the\n`shield()` function should be combined with a try/except clause, as follows:\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nWait for the aw awaitable to complete with a timeout.\n\nIf aw is a coroutine it is automatically scheduled as a Task.\n\ntimeout can either be `None` or a float or int number of seconds to wait for.\nIf timeout is `None`, block until the future completes.\n\nIf a timeout occurs, it cancels the task and raises `asyncio.TimeoutError`.\n\nTo avoid the task `cancellation`, wrap it in `shield()`.\n\nThe function will wait until the future is actually cancelled, so the total\nwait time may exceed the timeout. If an exception happens during cancellation,\nit is propagated.\n\nIf the wait is cancelled, the future aw is also cancelled.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample:\n\nChanged in version 3.7: When aw is cancelled due to a timeout, `wait_for`\nwaits for aw to be cancelled. Previously, it raised `asyncio.TimeoutError`\nimmediately.\n\nRun awaitable objects in the aws iterable concurrently and block until the\ncondition specified by return_when.\n\nThe aws iterable must not be empty.\n\nReturns two sets of Tasks/Futures: `(done, pending)`.\n\nUsage:\n\ntimeout (a float or int), if specified, can be used to control the maximum\nnumber of seconds to wait before returning.\n\nNote that this function does not raise `asyncio.TimeoutError`. Futures or\nTasks that aren\u2019t done when the timeout occurs are simply returned in the\nsecond set.\n\nreturn_when indicates when this function should return. It must be one of the\nfollowing constants:\n\nConstant\n\nDescription\n\n`FIRST_COMPLETED`\n\nThe function will return when any future finishes or is cancelled.\n\n`FIRST_EXCEPTION`\n\nThe function will return when any future finishes by raising an exception. If\nno future raises an exception then it is equivalent to `ALL_COMPLETED`.\n\n`ALL_COMPLETED`\n\nThe function will return when all futures finish or are cancelled.\n\nUnlike `wait_for()`, `wait()` does not cancel the futures when a timeout\noccurs.\n\nDeprecated since version 3.8: If any awaitable in aws is a coroutine, it is\nautomatically scheduled as a Task. Passing coroutines objects to `wait()`\ndirectly is deprecated as it leads to confusing behavior.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nNote\n\n`wait()` schedules coroutines as Tasks automatically and later returns those\nimplicitly created Task objects in `(done, pending)` sets. Therefore the\nfollowing code won\u2019t work as expected:\n\nHere is how the above snippet can be fixed:\n\nDeprecated since version 3.8, will be removed in version 3.11: Passing\ncoroutine objects to `wait()` directly is deprecated.\n\nRun awaitable objects in the aws iterable concurrently. Return an iterator of\ncoroutines. Each coroutine returned can be awaited to get the earliest next\nresult from the iterable of the remaining awaitables.\n\nRaises `asyncio.TimeoutError` if the timeout occurs before all Futures are\ndone.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nExample:\n\nAsynchronously run function func in a separate thread.\n\nAny *args and **kwargs supplied for this function are directly passed to func.\nAlso, the current `contextvars.Context` is propagated, allowing context\nvariables from the event loop thread to be accessed in the separate thread.\n\nReturn a coroutine that can be awaited to get the eventual result of func.\n\nThis coroutine function is primarily intended to be used for executing IO-\nbound functions/methods that would otherwise block the event loop if they were\nran in the main thread. For example:\n\nDirectly calling `blocking_io()` in any coroutine would block the event loop\nfor its duration, resulting in an additional 1 second of run time. Instead, by\nusing `asyncio.to_thread()`, we can run it in a separate thread without\nblocking the event loop.\n\nNote\n\nDue to the GIL, `asyncio.to_thread()` can typically only be used to make IO-\nbound functions non-blocking. However, for extension modules that release the\nGIL or alternative Python implementations that don\u2019t have one,\n`asyncio.to_thread()` can also be used for CPU-bound functions.\n\nNew in version 3.9.\n\nSubmit a coroutine to the given event loop. Thread-safe.\n\nReturn a `concurrent.futures.Future` to wait for the result from another OS\nthread.\n\nThis function is meant to be called from a different OS thread than the one\nwhere the event loop is running. Example:\n\nIf an exception is raised in the coroutine, the returned Future will be\nnotified. It can also be used to cancel the task in the event loop:\n\nSee the concurrency and multithreading section of the documentation.\n\nUnlike other asyncio functions this function requires the loop argument to be\npassed explicitly.\n\nNew in version 3.5.1.\n\nReturn the currently running `Task` instance, or `None` if no task is running.\n\nIf loop is `None` `get_running_loop()` is used to get the current loop.\n\nNew in version 3.7.\n\nReturn a set of not yet finished `Task` objects run by the loop.\n\nIf loop is `None`, `get_running_loop()` is used for getting current loop.\n\nNew in version 3.7.\n\nA `Future-like` object that runs a Python coroutine. Not thread-safe.\n\nTasks are used to run coroutines in event loops. If a coroutine awaits on a\nFuture, the Task suspends the execution of the coroutine and waits for the\ncompletion of the Future. When the Future is done, the execution of the\nwrapped coroutine resumes.\n\nEvent loops use cooperative scheduling: an event loop runs one Task at a time.\nWhile a Task awaits for the completion of a Future, the event loop runs other\nTasks, callbacks, or performs IO operations.\n\nUse the high-level `asyncio.create_task()` function to create Tasks, or the\nlow-level `loop.create_task()` or `ensure_future()` functions. Manual\ninstantiation of Tasks is discouraged.\n\nTo cancel a running Task use the `cancel()` method. Calling it will cause the\nTask to throw a `CancelledError` exception into the wrapped coroutine. If a\ncoroutine is awaiting on a Future object during cancellation, the Future\nobject will be cancelled.\n\n`cancelled()` can be used to check if the Task was cancelled. The method\nreturns `True` if the wrapped coroutine did not suppress the `CancelledError`\nexception and was actually cancelled.\n\n`asyncio.Task` inherits from `Future` all of its APIs except\n`Future.set_result()` and `Future.set_exception()`.\n\nTasks support the `contextvars` module. When a Task is created it copies the\ncurrent context and later runs its coroutine in the copied context.\n\nChanged in version 3.7: Added support for the `contextvars` module.\n\nChanged in version 3.8: Added the `name` parameter.\n\nDeprecated since version 3.8, will be removed in version 3.10: The loop\nparameter.\n\nRequest the Task to be cancelled.\n\nThis arranges for a `CancelledError` exception to be thrown into the wrapped\ncoroutine on the next cycle of the event loop.\n\nThe coroutine then has a chance to clean up or even deny the request by\nsuppressing the exception with a `try` \u2026 \u2026 `except CancelledError` \u2026 `finally`\nblock. Therefore, unlike `Future.cancel()`, `Task.cancel()` does not guarantee\nthat the Task will be cancelled, although suppressing cancellation completely\nis not common and is actively discouraged.\n\nChanged in version 3.9: Added the `msg` parameter.\n\nThe following example illustrates how coroutines can intercept the\ncancellation request:\n\nReturn `True` if the Task is cancelled.\n\nThe Task is cancelled when the cancellation was requested with `cancel()` and\nthe wrapped coroutine propagated the `CancelledError` exception thrown into\nit.\n\nReturn `True` if the Task is done.\n\nA Task is done when the wrapped coroutine either returned a value, raised an\nexception, or the Task was cancelled.\n\nReturn the result of the Task.\n\nIf the Task is done, the result of the wrapped coroutine is returned (or if\nthe coroutine raised an exception, that exception is re-raised.)\n\nIf the Task has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Task\u2019s result isn\u2019t yet available, this method raises a\n`InvalidStateError` exception.\n\nReturn the exception of the Task.\n\nIf the wrapped coroutine raised an exception that exception is returned. If\nthe wrapped coroutine returned normally this method returns `None`.\n\nIf the Task has been cancelled, this method raises a `CancelledError`\nexception.\n\nIf the Task isn\u2019t done yet, this method raises an `InvalidStateError`\nexception.\n\nAdd a callback to be run when the Task is done.\n\nThis method should only be used in low-level callback-based code.\n\nSee the documentation of `Future.add_done_callback()` for more details.\n\nRemove callback from the callbacks list.\n\nThis method should only be used in low-level callback-based code.\n\nSee the documentation of `Future.remove_done_callback()` for more details.\n\nReturn the list of stack frames for this Task.\n\nIf the wrapped coroutine is not done, this returns the stack where it is\nsuspended. If the coroutine has completed successfully or was cancelled, this\nreturns an empty list. If the coroutine was terminated by an exception, this\nreturns the list of traceback frames.\n\nThe frames are always ordered from oldest to newest.\n\nOnly one stack frame is returned for a suspended coroutine.\n\nThe optional limit argument sets the maximum number of frames to return; by\ndefault all available frames are returned. The ordering of the returned list\ndiffers depending on whether a stack or a traceback is returned: the newest\nframes of a stack are returned, but the oldest frames of a traceback are\nreturned. (This matches the behavior of the traceback module.)\n\nPrint the stack or traceback for this Task.\n\nThis produces output similar to that of the traceback module for the frames\nretrieved by `get_stack()`.\n\nThe limit argument is passed to `get_stack()` directly.\n\nThe file argument is an I/O stream to which the output is written; by default\noutput is written to `sys.stderr`.\n\nReturn the coroutine object wrapped by the `Task`.\n\nNew in version 3.8.\n\nReturn the name of the Task.\n\nIf no name has been explicitly assigned to the Task, the default asyncio Task\nimplementation generates a default name during instantiation.\n\nNew in version 3.8.\n\nSet the name of the Task.\n\nThe value argument can be any object, which is then converted to a string.\n\nIn the default Task implementation, the name will be visible in the `repr()`\noutput of a task object.\n\nNew in version 3.8.\n\nNote\n\nSupport for generator-based coroutines is deprecated and is scheduled for\nremoval in Python 3.10.\n\nGenerator-based coroutines predate async/await syntax. They are Python\ngenerators that use `yield from` expressions to await on Futures and other\ncoroutines.\n\nGenerator-based coroutines should be decorated with `@asyncio.coroutine`,\nalthough this is not enforced.\n\nDecorator to mark generator-based coroutines.\n\nThis decorator enables legacy generator-based coroutines to be compatible with\nasync/await code:\n\nThis decorator should not be used for `async def` coroutines.\n\nDeprecated since version 3.8, will be removed in version 3.10: Use `async def`\ninstead.\n\nReturn `True` if obj is a coroutine object.\n\nThis method is different from `inspect.iscoroutine()` because it returns\n`True` for generator-based coroutines.\n\nReturn `True` if func is a coroutine function.\n\nThis method is different from `inspect.iscoroutinefunction()` because it\nreturns `True` for generator-based coroutine functions decorated with\n`@coroutine`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "credits", "path": "library/constants#credits", "type": "Built-in Constants", "text": "\nObjects that when printed or called, print the text of copyright or credits,\nrespectively.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt", "path": "library/crypt", "type": "Unix", "text": "\nSource code: Lib/crypt.py\n\nThis module implements an interface to the crypt(3) routine, which is a one-\nway hash function based upon a modified DES algorithm; see the Unix man page\nfor further details. Possible uses include storing hashed passwords so you can\ncheck passwords without storing the actual password, or attempting to crack\nUnix passwords with a dictionary.\n\nNotice that the behavior of this module depends on the actual implementation\nof the crypt(3) routine in the running system. Therefore, any extensions\navailable on the current implementation will also be available on this module.\n\nAvailability: Unix. Not available on VxWorks.\n\nNew in version 3.3.\n\nThe `crypt` module defines the list of hashing methods (not all methods are\navailable on all platforms):\n\nA Modular Crypt Format method with 16 character salt and 86 character hash\nbased on the SHA-512 hash function. This is the strongest method.\n\nAnother Modular Crypt Format method with 16 character salt and 43 character\nhash based on the SHA-256 hash function.\n\nAnother Modular Crypt Format method with 22 character salt and 31 character\nhash based on the Blowfish cipher.\n\nNew in version 3.7.\n\nAnother Modular Crypt Format method with 8 character salt and 22 character\nhash based on the MD5 hash function.\n\nThe traditional method with a 2 character salt and 13 characters of hash. This\nis the weakest method.\n\nNew in version 3.3.\n\nA list of available password hashing algorithms, as `crypt.METHOD_*` objects.\nThis list is sorted from strongest to weakest.\n\nThe `crypt` module defines the following functions:\n\nword will usually be a user\u2019s password as typed at a prompt or in a graphical\ninterface. The optional salt is either a string as returned from `mksalt()`,\none of the `crypt.METHOD_*` values (though not all may be available on all\nplatforms), or a full encrypted password including salt, as returned by this\nfunction. If salt is not provided, the strongest method will be used (as\nreturned by `methods()`).\n\nChecking a password is usually done by passing the plain-text password as word\nand the full results of a previous `crypt()` call, which should be the same as\nthe results of this call.\n\nsalt (either a random 2 or 16 character string, possibly prefixed with\n`$digit$` to indicate the method) which will be used to perturb the encryption\nalgorithm. The characters in salt must be in the set `[./a-zA-Z0-9]`, with the\nexception of Modular Crypt Format which prefixes a `$digit$`.\n\nReturns the hashed password as a string, which will be composed of characters\nfrom the same alphabet as the salt.\n\nSince a few crypt(3) extensions allow different values, with different sizes\nin the salt, it is recommended to use the full crypted password as salt when\nchecking for a password.\n\nChanged in version 3.3: Accept `crypt.METHOD_*` values in addition to strings\nfor salt.\n\nReturn a randomly generated salt of the specified method. If no method is\ngiven, the strongest method available as returned by `methods()` is used.\n\nThe return value is a string suitable for passing as the salt argument to\n`crypt()`.\n\nrounds specifies the number of rounds for `METHOD_SHA256`, `METHOD_SHA512` and\n`METHOD_BLOWFISH`. For `METHOD_SHA256` and `METHOD_SHA512` it must be an\ninteger between `1000` and `999_999_999`, the default is `5000`. For\n`METHOD_BLOWFISH` it must be a power of two between `16` (24) and\n`2_147_483_648` (231), the default is `4096` (212).\n\nNew in version 3.3.\n\nChanged in version 3.7: Added the rounds parameter.\n\nA simple example illustrating typical use (a constant-time comparison\noperation is needed to limit exposure to timing attacks.\n`hmac.compare_digest()` is suitable for this purpose):\n\nTo generate a hash of a password using the strongest available method and\ncheck it against the original:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.crypt()", "path": "library/crypt#crypt.crypt", "type": "Unix", "text": "\nword will usually be a user\u2019s password as typed at a prompt or in a graphical\ninterface. The optional salt is either a string as returned from `mksalt()`,\none of the `crypt.METHOD_*` values (though not all may be available on all\nplatforms), or a full encrypted password including salt, as returned by this\nfunction. If salt is not provided, the strongest method will be used (as\nreturned by `methods()`).\n\nChecking a password is usually done by passing the plain-text password as word\nand the full results of a previous `crypt()` call, which should be the same as\nthe results of this call.\n\nsalt (either a random 2 or 16 character string, possibly prefixed with\n`$digit$` to indicate the method) which will be used to perturb the encryption\nalgorithm. The characters in salt must be in the set `[./a-zA-Z0-9]`, with the\nexception of Modular Crypt Format which prefixes a `$digit$`.\n\nReturns the hashed password as a string, which will be composed of characters\nfrom the same alphabet as the salt.\n\nSince a few crypt(3) extensions allow different values, with different sizes\nin the salt, it is recommended to use the full crypted password as salt when\nchecking for a password.\n\nChanged in version 3.3: Accept `crypt.METHOD_*` values in addition to strings\nfor salt.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.methods", "path": "library/crypt#crypt.methods", "type": "Unix", "text": "\nA list of available password hashing algorithms, as `crypt.METHOD_*` objects.\nThis list is sorted from strongest to weakest.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.METHOD_BLOWFISH", "path": "library/crypt#crypt.METHOD_BLOWFISH", "type": "Unix", "text": "\nAnother Modular Crypt Format method with 22 character salt and 31 character\nhash based on the Blowfish cipher.\n\nNew in version 3.7.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.METHOD_CRYPT", "path": "library/crypt#crypt.METHOD_CRYPT", "type": "Unix", "text": "\nThe traditional method with a 2 character salt and 13 characters of hash. This\nis the weakest method.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.METHOD_MD5", "path": "library/crypt#crypt.METHOD_MD5", "type": "Unix", "text": "\nAnother Modular Crypt Format method with 8 character salt and 22 character\nhash based on the MD5 hash function.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.METHOD_SHA256", "path": "library/crypt#crypt.METHOD_SHA256", "type": "Unix", "text": "\nAnother Modular Crypt Format method with 16 character salt and 43 character\nhash based on the SHA-256 hash function.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.METHOD_SHA512", "path": "library/crypt#crypt.METHOD_SHA512", "type": "Unix", "text": "\nA Modular Crypt Format method with 16 character salt and 86 character hash\nbased on the SHA-512 hash function. This is the strongest method.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "crypt.mksalt()", "path": "library/crypt#crypt.mksalt", "type": "Unix", "text": "\nReturn a randomly generated salt of the specified method. If no method is\ngiven, the strongest method available as returned by `methods()` is used.\n\nThe return value is a string suitable for passing as the salt argument to\n`crypt()`.\n\nrounds specifies the number of rounds for `METHOD_SHA256`, `METHOD_SHA512` and\n`METHOD_BLOWFISH`. For `METHOD_SHA256` and `METHOD_SHA512` it must be an\ninteger between `1000` and `999_999_999`, the default is `5000`. For\n`METHOD_BLOWFISH` it must be a power of two between `16` (24) and\n`2_147_483_648` (231), the default is `4096` (212).\n\nNew in version 3.3.\n\nChanged in version 3.7: Added the rounds parameter.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv", "path": "library/csv", "type": "File Formats", "text": "\nSource code: Lib/csv.py\n\nThe so-called CSV (Comma Separated Values) format is the most common import\nand export format for spreadsheets and databases. CSV format was used for many\nyears prior to attempts to describe the format in a standardized way in RFC\n4180. The lack of a well-defined standard means that subtle differences often\nexist in the data produced and consumed by different applications. These\ndifferences can make it annoying to process CSV files from multiple sources.\nStill, while the delimiters and quoting characters vary, the overall format is\nsimilar enough that it is possible to write a single module which can\nefficiently manipulate such data, hiding the details of reading and writing\nthe data from the programmer.\n\nThe `csv` module implements classes to read and write tabular data in CSV\nformat. It allows programmers to say, \u201cwrite this data in the format preferred\nby Excel,\u201d or \u201cread data from this file which was generated by Excel,\u201d without\nknowing the precise details of the CSV format used by Excel. Programmers can\nalso describe the CSV formats understood by other applications or define their\nown special-purpose CSV formats.\n\nThe `csv` module\u2019s `reader` and `writer` objects read and write sequences.\nProgrammers can also read and write data in dictionary form using the\n`DictReader` and `DictWriter` classes.\n\nSee also\n\nThe Python Enhancement Proposal which proposed this addition to Python.\n\nThe `csv` module defines the following functions:\n\nReturn a reader object which will iterate over lines in the given csvfile.\ncsvfile can be any object which supports the iterator protocol and returns a\nstring each time its `__next__()` method is called \u2014 file objects and list\nobjects are both suitable. If csvfile is a file object, it should be opened\nwith `newline=''`. 1 An optional dialect parameter can be given which is used\nto define a set of parameters specific to a particular CSV dialect. It may be\nan instance of a subclass of the `Dialect` class or one of the strings\nreturned by the `list_dialects()` function. The other optional fmtparams\nkeyword arguments can be given to override individual formatting parameters in\nthe current dialect. For full details about the dialect and formatting\nparameters, see section Dialects and Formatting Parameters.\n\nEach row read from the csv file is returned as a list of strings. No automatic\ndata type conversion is performed unless the `QUOTE_NONNUMERIC` format option\nis specified (in which case unquoted fields are transformed into floats).\n\nA short usage example:\n\nReturn a writer object responsible for converting the user\u2019s data into\ndelimited strings on the given file-like object. csvfile can be any object\nwith a `write()` method. If csvfile is a file object, it should be opened with\n`newline=''` 1. An optional dialect parameter can be given which is used to\ndefine a set of parameters specific to a particular CSV dialect. It may be an\ninstance of a subclass of the `Dialect` class or one of the strings returned\nby the `list_dialects()` function. The other optional fmtparams keyword\narguments can be given to override individual formatting parameters in the\ncurrent dialect. For full details about the dialect and formatting parameters,\nsee section Dialects and Formatting Parameters. To make it as easy as possible\nto interface with modules which implement the DB API, the value `None` is\nwritten as the empty string. While this isn\u2019t a reversible transformation, it\nmakes it easier to dump SQL NULL data values to CSV files without\npreprocessing the data returned from a `cursor.fetch*` call. All other non-\nstring data are stringified with `str()` before being written.\n\nA short usage example:\n\nAssociate dialect with name. name must be a string. The dialect can be\nspecified either by passing a sub-class of `Dialect`, or by fmtparams keyword\narguments, or both, with keyword arguments overriding parameters of the\ndialect. For full details about the dialect and formatting parameters, see\nsection Dialects and Formatting Parameters.\n\nDelete the dialect associated with name from the dialect registry. An `Error`\nis raised if name is not a registered dialect name.\n\nReturn the dialect associated with name. An `Error` is raised if name is not a\nregistered dialect name. This function returns an immutable `Dialect`.\n\nReturn the names of all registered dialects.\n\nReturns the current maximum field size allowed by the parser. If new_limit is\ngiven, this becomes the new limit.\n\nThe `csv` module defines the following classes:\n\nCreate an object that operates like a regular reader but maps the information\nin each row to a `dict` whose keys are given by the optional fieldnames\nparameter.\n\nThe fieldnames parameter is a sequence. If fieldnames is omitted, the values\nin the first row of file f will be used as the fieldnames. Regardless of how\nthe fieldnames are determined, the dictionary preserves their original\nordering.\n\nIf a row has more fields than fieldnames, the remaining data is put in a list\nand stored with the fieldname specified by restkey (which defaults to `None`).\nIf a non-blank row has fewer fields than fieldnames, the missing values are\nfilled-in with the value of restval (which defaults to `None`).\n\nAll other optional or keyword arguments are passed to the underlying `reader`\ninstance.\n\nChanged in version 3.6: Returned rows are now of type `OrderedDict`.\n\nChanged in version 3.8: Returned rows are now of type `dict`.\n\nA short usage example:\n\nCreate an object which operates like a regular writer but maps dictionaries\nonto output rows. The fieldnames parameter is a `sequence` of keys that\nidentify the order in which values in the dictionary passed to the\n`writerow()` method are written to file f. The optional restval parameter\nspecifies the value to be written if the dictionary is missing a key in\nfieldnames. If the dictionary passed to the `writerow()` method contains a key\nnot found in fieldnames, the optional extrasaction parameter indicates what\naction to take. If it is set to `'raise'`, the default value, a `ValueError`\nis raised. If it is set to `'ignore'`, extra values in the dictionary are\nignored. Any other optional or keyword arguments are passed to the underlying\n`writer` instance.\n\nNote that unlike the `DictReader` class, the fieldnames parameter of the\n`DictWriter` class is not optional.\n\nA short usage example:\n\nThe `Dialect` class is a container class relied on primarily for its\nattributes, which are used to define the parameters for a specific `reader` or\n`writer` instance.\n\nThe `excel` class defines the usual properties of an Excel-generated CSV file.\nIt is registered with the dialect name `'excel'`.\n\nThe `excel_tab` class defines the usual properties of an Excel-generated TAB-\ndelimited file. It is registered with the dialect name `'excel-tab'`.\n\nThe `unix_dialect` class defines the usual properties of a CSV file generated\non UNIX systems, i.e. using `'\\n'` as line terminator and quoting all fields.\nIt is registered with the dialect name `'unix'`.\n\nNew in version 3.2.\n\nThe `Sniffer` class is used to deduce the format of a CSV file.\n\nThe `Sniffer` class provides two methods:\n\nAnalyze the given sample and return a `Dialect` subclass reflecting the\nparameters found. If the optional delimiters parameter is given, it is\ninterpreted as a string containing possible valid delimiter characters.\n\nAnalyze the sample text (presumed to be in CSV format) and return `True` if\nthe first row appears to be a series of column headers.\n\nAn example for `Sniffer` use:\n\nThe `csv` module defines the following constants:\n\nInstructs `writer` objects to quote all fields.\n\nInstructs `writer` objects to only quote those fields which contain special\ncharacters such as delimiter, quotechar or any of the characters in\nlineterminator.\n\nInstructs `writer` objects to quote all non-numeric fields.\n\nInstructs the reader to convert all non-quoted fields to type float.\n\nInstructs `writer` objects to never quote fields. When the current delimiter\noccurs in output data it is preceded by the current escapechar character. If\nescapechar is not set, the writer will raise `Error` if any characters that\nrequire escaping are encountered.\n\nInstructs `reader` to perform no special processing of quote characters.\n\nThe `csv` module defines the following exception:\n\nRaised by any of the functions when an error is detected.\n\nTo make it easier to specify the format of input and output records, specific\nformatting parameters are grouped together into dialects. A dialect is a\nsubclass of the `Dialect` class having a set of specific methods and a single\n`validate()` method. When creating `reader` or `writer` objects, the\nprogrammer can specify a string or a subclass of the `Dialect` class as the\ndialect parameter. In addition to, or instead of, the dialect parameter, the\nprogrammer can also specify individual formatting parameters, which have the\nsame names as the attributes defined below for the `Dialect` class.\n\nDialects support the following attributes:\n\nA one-character string used to separate fields. It defaults to `','`.\n\nControls how instances of quotechar appearing inside a field should themselves\nbe quoted. When `True`, the character is doubled. When `False`, the escapechar\nis used as a prefix to the quotechar. It defaults to `True`.\n\nOn output, if doublequote is `False` and no escapechar is set, `Error` is\nraised if a quotechar is found in a field.\n\nA one-character string used by the writer to escape the delimiter if quoting\nis set to `QUOTE_NONE` and the quotechar if doublequote is `False`. On\nreading, the escapechar removes any special meaning from the following\ncharacter. It defaults to `None`, which disables escaping.\n\nThe string used to terminate lines produced by the `writer`. It defaults to\n`'\\r\\n'`.\n\nNote\n\nThe `reader` is hard-coded to recognise either `'\\r'` or `'\\n'` as end-of-\nline, and ignores lineterminator. This behavior may change in the future.\n\nA one-character string used to quote fields containing special characters,\nsuch as the delimiter or quotechar, or which contain new-line characters. It\ndefaults to `'\"'`.\n\nControls when quotes should be generated by the writer and recognised by the\nreader. It can take on any of the `QUOTE_*` constants (see section Module\nContents) and defaults to `QUOTE_MINIMAL`.\n\nWhen `True`, whitespace immediately following the delimiter is ignored. The\ndefault is `False`.\n\nWhen `True`, raise exception `Error` on bad CSV input. The default is `False`.\n\nReader objects (`DictReader` instances and objects returned by the `reader()`\nfunction) have the following public methods:\n\nReturn the next row of the reader\u2019s iterable object as a list (if the object\nwas returned from `reader()`) or a dict (if it is a `DictReader` instance),\nparsed according to the current dialect. Usually you should call this as\n`next(reader)`.\n\nReader objects have the following public attributes:\n\nA read-only description of the dialect in use by the parser.\n\nThe number of lines read from the source iterator. This is not the same as the\nnumber of records returned, as records can span multiple lines.\n\nDictReader objects have the following public attribute:\n\nIf not passed as a parameter when creating the object, this attribute is\ninitialized upon first access or when the first record is read from the file.\n\n`Writer` objects (`DictWriter` instances and objects returned by the\n`writer()` function) have the following public methods. A row must be an\niterable of strings or numbers for `Writer` objects and a dictionary mapping\nfieldnames to strings or numbers (by passing them through `str()` first) for\n`DictWriter` objects. Note that complex numbers are written out surrounded by\nparens. This may cause some problems for other programs which read CSV files\n(assuming they support complex numbers at all).\n\nWrite the row parameter to the writer\u2019s file object, formatted according to\nthe current dialect. Return the return value of the call to the write method\nof the underlying file object.\n\nChanged in version 3.5: Added support of arbitrary iterables.\n\nWrite all elements in rows (an iterable of row objects as described above) to\nthe writer\u2019s file object, formatted according to the current dialect.\n\nWriter objects have the following public attribute:\n\nA read-only description of the dialect in use by the writer.\n\nDictWriter objects have the following public method:\n\nWrite a row with the field names (as specified in the constructor) to the\nwriter\u2019s file object, formatted according to the current dialect. Return the\nreturn value of the `csvwriter.writerow()` call used internally.\n\nNew in version 3.2.\n\nChanged in version 3.8: `writeheader()` now also returns the value returned by\nthe `csvwriter.writerow()` method it uses internally.\n\nThe simplest example of reading a CSV file:\n\nReading a file with an alternate format:\n\nThe corresponding simplest possible writing example is:\n\nSince `open()` is used to open a CSV file for reading, the file will by\ndefault be decoded into unicode using the system default encoding (see\n`locale.getpreferredencoding()`). To decode a file using a different encoding,\nuse the `encoding` argument of open:\n\nThe same applies to writing in something other than the system default\nencoding: specify the encoding argument when opening the output file.\n\nRegistering a new dialect:\n\nA slightly more advanced use of the reader \u2014 catching and reporting errors:\n\nAnd while the module doesn\u2019t directly support parsing strings, it can easily\nbe done:\n\nIf `newline=''` is not specified, newlines embedded inside quoted fields will\nnot be interpreted correctly, and on platforms that use `\\r\\n` linendings on\nwrite an extra `\\r` will be added. It should always be safe to specify\n`newline=''`, since the csv module does its own (universal) newline handling.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.csvreader.dialect", "path": "library/csv#csv.csvreader.dialect", "type": "File Formats", "text": "\nA read-only description of the dialect in use by the parser.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.csvreader.fieldnames", "path": "library/csv#csv.csvreader.fieldnames", "type": "File Formats", "text": "\nIf not passed as a parameter when creating the object, this attribute is\ninitialized upon first access or when the first record is read from the file.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.csvreader.line_num", "path": "library/csv#csv.csvreader.line_num", "type": "File Formats", "text": "\nThe number of lines read from the source iterator. This is not the same as the\nnumber of records returned, as records can span multiple lines.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.csvreader.__next__()", "path": "library/csv#csv.csvreader.__next__", "type": "File Formats", "text": "\nReturn the next row of the reader\u2019s iterable object as a list (if the object\nwas returned from `reader()`) or a dict (if it is a `DictReader` instance),\nparsed according to the current dialect. Usually you should call this as\n`next(reader)`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.csvwriter.dialect", "path": "library/csv#csv.csvwriter.dialect", "type": "File Formats", "text": "\nA read-only description of the dialect in use by the writer.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.csvwriter.writerow()", "path": "library/csv#csv.csvwriter.writerow", "type": "File Formats", "text": "\nWrite the row parameter to the writer\u2019s file object, formatted according to\nthe current dialect. Return the return value of the call to the write method\nof the underlying file object.\n\nChanged in version 3.5: Added support of arbitrary iterables.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.csvwriter.writerows()", "path": "library/csv#csv.csvwriter.writerows", "type": "File Formats", "text": "\nWrite all elements in rows (an iterable of row objects as described above) to\nthe writer\u2019s file object, formatted according to the current dialect.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect", "path": "library/csv#csv.Dialect", "type": "File Formats", "text": "\nThe `Dialect` class is a container class relied on primarily for its\nattributes, which are used to define the parameters for a specific `reader` or\n`writer` instance.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.delimiter", "path": "library/csv#csv.Dialect.delimiter", "type": "File Formats", "text": "\nA one-character string used to separate fields. It defaults to `','`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.doublequote", "path": "library/csv#csv.Dialect.doublequote", "type": "File Formats", "text": "\nControls how instances of quotechar appearing inside a field should themselves\nbe quoted. When `True`, the character is doubled. When `False`, the escapechar\nis used as a prefix to the quotechar. It defaults to `True`.\n\nOn output, if doublequote is `False` and no escapechar is set, `Error` is\nraised if a quotechar is found in a field.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.escapechar", "path": "library/csv#csv.Dialect.escapechar", "type": "File Formats", "text": "\nA one-character string used by the writer to escape the delimiter if quoting\nis set to `QUOTE_NONE` and the quotechar if doublequote is `False`. On\nreading, the escapechar removes any special meaning from the following\ncharacter. It defaults to `None`, which disables escaping.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.lineterminator", "path": "library/csv#csv.Dialect.lineterminator", "type": "File Formats", "text": "\nThe string used to terminate lines produced by the `writer`. It defaults to\n`'\\r\\n'`.\n\nNote\n\nThe `reader` is hard-coded to recognise either `'\\r'` or `'\\n'` as end-of-\nline, and ignores lineterminator. This behavior may change in the future.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.quotechar", "path": "library/csv#csv.Dialect.quotechar", "type": "File Formats", "text": "\nA one-character string used to quote fields containing special characters,\nsuch as the delimiter or quotechar, or which contain new-line characters. It\ndefaults to `'\"'`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.quoting", "path": "library/csv#csv.Dialect.quoting", "type": "File Formats", "text": "\nControls when quotes should be generated by the writer and recognised by the\nreader. It can take on any of the `QUOTE_*` constants (see section Module\nContents) and defaults to `QUOTE_MINIMAL`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.skipinitialspace", "path": "library/csv#csv.Dialect.skipinitialspace", "type": "File Formats", "text": "\nWhen `True`, whitespace immediately following the delimiter is ignored. The\ndefault is `False`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Dialect.strict", "path": "library/csv#csv.Dialect.strict", "type": "File Formats", "text": "\nWhen `True`, raise exception `Error` on bad CSV input. The default is `False`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.DictReader", "path": "library/csv#csv.DictReader", "type": "File Formats", "text": "\nCreate an object that operates like a regular reader but maps the information\nin each row to a `dict` whose keys are given by the optional fieldnames\nparameter.\n\nThe fieldnames parameter is a sequence. If fieldnames is omitted, the values\nin the first row of file f will be used as the fieldnames. Regardless of how\nthe fieldnames are determined, the dictionary preserves their original\nordering.\n\nIf a row has more fields than fieldnames, the remaining data is put in a list\nand stored with the fieldname specified by restkey (which defaults to `None`).\nIf a non-blank row has fewer fields than fieldnames, the missing values are\nfilled-in with the value of restval (which defaults to `None`).\n\nAll other optional or keyword arguments are passed to the underlying `reader`\ninstance.\n\nChanged in version 3.6: Returned rows are now of type `OrderedDict`.\n\nChanged in version 3.8: Returned rows are now of type `dict`.\n\nA short usage example:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.DictWriter", "path": "library/csv#csv.DictWriter", "type": "File Formats", "text": "\nCreate an object which operates like a regular writer but maps dictionaries\nonto output rows. The fieldnames parameter is a `sequence` of keys that\nidentify the order in which values in the dictionary passed to the\n`writerow()` method are written to file f. The optional restval parameter\nspecifies the value to be written if the dictionary is missing a key in\nfieldnames. If the dictionary passed to the `writerow()` method contains a key\nnot found in fieldnames, the optional extrasaction parameter indicates what\naction to take. If it is set to `'raise'`, the default value, a `ValueError`\nis raised. If it is set to `'ignore'`, extra values in the dictionary are\nignored. Any other optional or keyword arguments are passed to the underlying\n`writer` instance.\n\nNote that unlike the `DictReader` class, the fieldnames parameter of the\n`DictWriter` class is not optional.\n\nA short usage example:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.DictWriter.writeheader()", "path": "library/csv#csv.DictWriter.writeheader", "type": "File Formats", "text": "\nWrite a row with the field names (as specified in the constructor) to the\nwriter\u2019s file object, formatted according to the current dialect. Return the\nreturn value of the `csvwriter.writerow()` call used internally.\n\nNew in version 3.2.\n\nChanged in version 3.8: `writeheader()` now also returns the value returned by\nthe `csvwriter.writerow()` method it uses internally.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Error", "path": "library/csv#csv.Error", "type": "File Formats", "text": "\nRaised by any of the functions when an error is detected.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.excel", "path": "library/csv#csv.excel", "type": "File Formats", "text": "\nThe `excel` class defines the usual properties of an Excel-generated CSV file.\nIt is registered with the dialect name `'excel'`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.excel_tab", "path": "library/csv#csv.excel_tab", "type": "File Formats", "text": "\nThe `excel_tab` class defines the usual properties of an Excel-generated TAB-\ndelimited file. It is registered with the dialect name `'excel-tab'`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.field_size_limit()", "path": "library/csv#csv.field_size_limit", "type": "File Formats", "text": "\nReturns the current maximum field size allowed by the parser. If new_limit is\ngiven, this becomes the new limit.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.get_dialect()", "path": "library/csv#csv.get_dialect", "type": "File Formats", "text": "\nReturn the dialect associated with name. An `Error` is raised if name is not a\nregistered dialect name. This function returns an immutable `Dialect`.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.list_dialects()", "path": "library/csv#csv.list_dialects", "type": "File Formats", "text": "\nReturn the names of all registered dialects.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.QUOTE_ALL", "path": "library/csv#csv.QUOTE_ALL", "type": "File Formats", "text": "\nInstructs `writer` objects to quote all fields.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.QUOTE_MINIMAL", "path": "library/csv#csv.QUOTE_MINIMAL", "type": "File Formats", "text": "\nInstructs `writer` objects to only quote those fields which contain special\ncharacters such as delimiter, quotechar or any of the characters in\nlineterminator.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.QUOTE_NONE", "path": "library/csv#csv.QUOTE_NONE", "type": "File Formats", "text": "\nInstructs `writer` objects to never quote fields. When the current delimiter\noccurs in output data it is preceded by the current escapechar character. If\nescapechar is not set, the writer will raise `Error` if any characters that\nrequire escaping are encountered.\n\nInstructs `reader` to perform no special processing of quote characters.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.QUOTE_NONNUMERIC", "path": "library/csv#csv.QUOTE_NONNUMERIC", "type": "File Formats", "text": "\nInstructs `writer` objects to quote all non-numeric fields.\n\nInstructs the reader to convert all non-quoted fields to type float.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.reader()", "path": "library/csv#csv.reader", "type": "File Formats", "text": "\nReturn a reader object which will iterate over lines in the given csvfile.\ncsvfile can be any object which supports the iterator protocol and returns a\nstring each time its `__next__()` method is called \u2014 file objects and list\nobjects are both suitable. If csvfile is a file object, it should be opened\nwith `newline=''`. 1 An optional dialect parameter can be given which is used\nto define a set of parameters specific to a particular CSV dialect. It may be\nan instance of a subclass of the `Dialect` class or one of the strings\nreturned by the `list_dialects()` function. The other optional fmtparams\nkeyword arguments can be given to override individual formatting parameters in\nthe current dialect. For full details about the dialect and formatting\nparameters, see section Dialects and Formatting Parameters.\n\nEach row read from the csv file is returned as a list of strings. No automatic\ndata type conversion is performed unless the `QUOTE_NONNUMERIC` format option\nis specified (in which case unquoted fields are transformed into floats).\n\nA short usage example:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.register_dialect()", "path": "library/csv#csv.register_dialect", "type": "File Formats", "text": "\nAssociate dialect with name. name must be a string. The dialect can be\nspecified either by passing a sub-class of `Dialect`, or by fmtparams keyword\narguments, or both, with keyword arguments overriding parameters of the\ndialect. For full details about the dialect and formatting parameters, see\nsection Dialects and Formatting Parameters.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Sniffer", "path": "library/csv#csv.Sniffer", "type": "File Formats", "text": "\nThe `Sniffer` class is used to deduce the format of a CSV file.\n\nThe `Sniffer` class provides two methods:\n\nAnalyze the given sample and return a `Dialect` subclass reflecting the\nparameters found. If the optional delimiters parameter is given, it is\ninterpreted as a string containing possible valid delimiter characters.\n\nAnalyze the sample text (presumed to be in CSV format) and return `True` if\nthe first row appears to be a series of column headers.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Sniffer.has_header()", "path": "library/csv#csv.Sniffer.has_header", "type": "File Formats", "text": "\nAnalyze the sample text (presumed to be in CSV format) and return `True` if\nthe first row appears to be a series of column headers.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.Sniffer.sniff()", "path": "library/csv#csv.Sniffer.sniff", "type": "File Formats", "text": "\nAnalyze the given sample and return a `Dialect` subclass reflecting the\nparameters found. If the optional delimiters parameter is given, it is\ninterpreted as a string containing possible valid delimiter characters.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.unix_dialect", "path": "library/csv#csv.unix_dialect", "type": "File Formats", "text": "\nThe `unix_dialect` class defines the usual properties of a CSV file generated\non UNIX systems, i.e. using `'\\n'` as line terminator and quoting all fields.\nIt is registered with the dialect name `'unix'`.\n\nNew in version 3.2.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.unregister_dialect()", "path": "library/csv#csv.unregister_dialect", "type": "File Formats", "text": "\nDelete the dialect associated with name from the dialect registry. An `Error`\nis raised if name is not a registered dialect name.\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "csv.writer()", "path": "library/csv#csv.writer", "type": "File Formats", "text": "\nReturn a writer object responsible for converting the user\u2019s data into\ndelimited strings on the given file-like object. csvfile can be any object\nwith a `write()` method. If csvfile is a file object, it should be opened with\n`newline=''` 1. An optional dialect parameter can be given which is used to\ndefine a set of parameters specific to a particular CSV dialect. It may be an\ninstance of a subclass of the `Dialect` class or one of the strings returned\nby the `list_dialects()` function. The other optional fmtparams keyword\narguments can be given to override individual formatting parameters in the\ncurrent dialect. For full details about the dialect and formatting parameters,\nsee section Dialects and Formatting Parameters. To make it as easy as possible\nto interface with modules which implement the DB API, the value `None` is\nwritten as the empty string. While this isn\u2019t a reversible transformation, it\nmakes it easier to dump SQL NULL data values to CSV files without\npreprocessing the data returned from a `cursor.fetch*` call. All other non-\nstring data are stringified with `str()` before being written.\n\nA short usage example:\n\n  *[FIFO]: first-in, first-out\n  *[LIFO]: last-in, first-out\n\n"}, {"name": "ctypes", "path": "library/ctypes", "type": "Operating System", "text": "\n`ctypes` is a foreign function library for Python. It provides C compatible\ndata types, and allows calling functions in DLLs or shared libraries. It can\nbe used to wrap these libraries in pure Python.\n\nNote: The code samples in this tutorial use `doctest` to make sure that they\nactually work. Since some code samples behave differently under Linux,\nWindows, or Mac OS X, they contain doctest directives in comments.\n\nNote: Some code samples reference the ctypes `c_int` type. On platforms where\n`sizeof(long) == sizeof(int)` it is an alias to `c_long`. So, you should not\nbe confused if `c_long` is printed if you would expect `c_int` \u2014 they are\nactually the same type.\n\n`ctypes` exports the cdll, and on Windows windll and oledll objects, for\nloading dynamic link libraries.\n\nYou load libraries by accessing them as attributes of these objects. cdll\nloads libraries which export functions using the standard `cdecl` calling\nconvention, while windll libraries call functions using the `stdcall` calling\nconvention. oledll also uses the `stdcall` calling convention, and assumes the\nfunctions return a Windows `HRESULT` error code. The error code is used to\nautomatically raise an `OSError` exception when the function call fails.\n\nChanged in version 3.3: Windows errors used to raise `WindowsError`, which is\nnow an alias of `OSError`.\n\nHere are some examples for Windows. Note that `msvcrt` is the MS standard C\nlibrary containing most standard C functions, and uses the cdecl calling\nconvention:\n\nWindows appends the usual `.dll` file suffix automatically.\n\nNote\n\nAccessing the standard C library through `cdll.msvcrt` will use an outdated\nversion of the library that may be incompatible with the one being used by\nPython. Where possible, use native Python functionality, or else import and\nuse the `msvcrt` module.\n\nOn Linux, it is required to specify the filename including the extension to\nload a library, so attribute access can not be used to load libraries. Either\nthe `LoadLibrary()` method of the dll loaders should be used, or you should\nload the library by creating an instance of CDLL by calling the constructor:\n\nFunctions are accessed as attributes of dll objects:\n\nNote that win32 system dlls like `kernel32` and `user32` often export ANSI as\nwell as UNICODE versions of a function. The UNICODE version is exported with\nan `W` appended to the name, while the ANSI version is exported with an `A`\nappended to the name. The win32 `GetModuleHandle` function, which returns a\nmodule handle for a given module name, has the following C prototype, and a\nmacro is used to expose one of them as `GetModuleHandle` depending on whether\nUNICODE is defined or not:\n\nwindll does not try to select one of them by magic, you must access the\nversion you need by specifying `GetModuleHandleA` or `GetModuleHandleW`\nexplicitly, and then call it with bytes or string objects respectively.\n\nSometimes, dlls export functions with names which aren\u2019t valid Python\nidentifiers, like `\"??2@YAPAXI@Z\"`. In this case you have to use `getattr()`\nto retrieve the function:\n\nOn Windows, some dlls export functions not by name but by ordinal. These\nfunctions can be accessed by indexing the dll object with the ordinal number:\n\nYou can call these functions like any other Python callable. This example uses\nthe `time()` function, which returns system time in seconds since the Unix\nepoch, and the `GetModuleHandleA()` function, which returns a win32 module\nhandle.\n\nThis example calls both functions with a `NULL` pointer (`None` should be used\nas the `NULL` pointer):\n\n`ValueError` is raised when you call an `stdcall` function with the `cdecl`\ncalling convention, or vice versa:\n\nTo find out the correct calling convention you have to look into the C header\nfile or the documentation for the function you want to call.\n\nOn Windows, `ctypes` uses win32 structured exception handling to prevent\ncrashes from general protection faults when functions are called with invalid\nargument values:\n\nThere are, however, enough ways to crash Python with `ctypes`, so you should\nbe careful anyway.