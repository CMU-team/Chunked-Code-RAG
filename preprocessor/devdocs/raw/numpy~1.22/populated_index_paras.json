[{"name": "()", "path": "glossary", "type": "Glossary", "text": ["A parenthesized number followed by a comma denotes a tuple with one element. The trailing comma distinguishes a one-element tuple from a parenthesized n.", "In a dimension entry, instructs NumPy to choose the length that will keep the total number of array elements the same.", "An Ellipsis.", "When indexing an array, shorthand that the missing axes, if they exist, are full slices.", "It can be used at most once; a[...,0,...] raises an IndexError.", "The Python slice operator. In ndarrays, slicing can be applied to every axis:", "Trailing slices can be omitted:", "In contrast to Python, where slicing creates a copy, in NumPy slicing creates a view.", "For details, see Combining advanced and basic indexing.", "In a dtype declaration, indicates that the data is little-endian (the bracket is big on the right).", "In a dtype declaration, indicates that the data is big-endian (the bracket is big on the left).", "Rather than using a scalar or slice as an index, an axis can be indexed with an array, providing fine-grained selection. This is known as advanced indexing or \u201cfancy indexing\u201d.", "An operation along axis n of array a behaves as if its argument were an array of slices of a where each slice has a successive index of axis n.", "For example, if a is a 3 x N array, an operation along axis 0 behaves as if its argument were an array containing slices of each row:", "To make it concrete, we can pick the operation to be the array-reversal function numpy.flip, which accepts an axis argument. We construct a 3 x 4 array a:", "Reversing along axis 0 (the row axis) yields", "Recalling the definition of along an axis, flip along axis 0 is treating its argument as if it were", "and the result of np.flip(a,axis=0) is to reverse the slices:", "Used synonymously in the NumPy docs with ndarray.", "Any scalar or sequence that can be interpreted as an ndarray. In addition to ndarrays and scalars this category includes lists (possibly nested and with different element types) and tuples. Any argument accepted by numpy.array is array_like.", "An array scalar is an instance of the types/classes float32, float64, etc.. For uniformity in handling operands, NumPy treats a scalar as an array of zero dimension. In contrast, a 0-dimensional array is an ndarray instance containing precisely one value.", "Another term for an array dimension. Axes are numbered left to right; axis 0 is the first element in the shape tuple.", "In a two-dimensional vector, the elements of axis 0 are rows and the elements of axis 1 are columns.", "In higher dimensions, the picture changes. NumPy prints higher-dimensional vectors as replications of row-by-column building blocks, as in this three-dimensional vector:", "a is depicted as a two-element array whose elements are 2x3 vectors. From this point of view, rows and columns are the final two axes, respectively, in any shape.", "This rule helps you anticipate how a vector will be printed, and conversely how to find the index of any of the printed elements. For instance, in the example, the last two values of 8\u2019s index must be 0 and 2. Since 8 appears in the second of the two 2x3\u2019s, the first index must be 1:", "A convenient way to count dimensions in a printed vector is to count [ symbols after the open-parenthesis. This is useful in distinguishing, say, a (1,2,3) shape from a (2,3) shape:", "If an array does not own its memory, then its base attribute returns the object whose memory the array is referencing. That object may be referencing the memory from still another object, so the owning object may be a.base.base.base.... Some writers erroneously claim that testing base determines if arrays are views. For the correct way, see numpy.shares_memory.", "See Endianness.", "Basic Linear Algebra Subprograms", "broadcasting is NumPy\u2019s ability to process ndarrays of different sizes as if all were the same size.", "It permits an elegant do-what-I-mean behavior where, for instance, adding a scalar to a vector adds the scalar value to every element.", "Ordinarly, vector operands must all be the same size, because NumPy works element by element \u2013 for instance, c = a * b is", "But in certain useful cases, NumPy can duplicate data along \u201cmissing\u201d axes or \u201ctoo-short\u201d dimensions so shapes will match. The duplication costs no memory or time. For details, see Broadcasting.", "Same as row-major.", "See Row- and column-major order.", "See view.", "See axis.", "The datatype describing the (identically typed) elements in an ndarray. It can be changed to reinterpret the array contents. For details, see Data type objects (dtype).", "Another term for advanced indexing.", "In a structured data type, each subtype is called a field. The field has a name (a string), a type (any valid dtype), and an optional title. See Data type objects (dtype).", "Same as column-major.", "See ravel.", "All elements of a homogeneous array have the same type. ndarrays, in contrast to Python lists, are homogeneous. The type can be complicated, as in a structured array, but all elements have that type.", "NumPy object arrays, which contain references to Python objects, fill the role of heterogeneous arrays.", "The size of the dtype element in bytes.", "See Endianness.", "A boolean array used to select only certain elements for an operation:", "Bad or missing data can be cleanly ignored by putting it in a masked array, which has an internal boolean array indicating invalid entries. Operations with masked arrays ignore these entries.", "For details, see Masked arrays.", "NumPy\u2019s two-dimensional matrix class should no longer be used; use regular ndarrays.", "NumPy\u2019s basic structure.", "An array whose dtype is object; that is, it contains references to Python objects. Indexing the array dereferences the Python objects, so unlike other ndarrays, an object array has the ability to hold heterogeneous objects.", "numpy.ravel  and numpy.flatten  both flatten an ndarray. ravel will return a view if possible; flatten always returns a copy.", "Flattening collapses a multimdimensional array to a single dimension; details of how this is done (for instance, whether a[n+1] should be the next row or next column) are parameters.", "A structured array with allowing access in an attribute style (a.field) in addition to a['field']. For details, see numpy.recarray.", "See Row- and column-major order. NumPy creates arrays in row-major order by default.", "In NumPy, usually a synonym for array scalar.", "A tuple showing the length of each dimension of an ndarray. The length of the tuple itself is the number of dimensions (numpy.ndim). The product of the tuple elements is the number of elements in the array. For details, see numpy.ndarray.shape.", "Physical memory is one-dimensional; strides provide a mechanism to map a given index to an address in memory. For an N-dimensional array, its strides attribute is an N-element tuple; advancing from index i to index i+1 on axis n means adding a.strides[n] bytes to the address.", "Strides are computed automatically from an array\u2019s dtype and shape, but can be directly specified using as_strided.", "For details, see numpy.ndarray.strides.", "To see how striding underlies the power of NumPy views, see The NumPy array: a structure for efficient numerical computation. ", "Array whose dtype is a structured data type.", "Users can create arbitrarily complex dtypes that can include other arrays and dtypes. These composite dtypes are called structured data types.", "An array nested in a structured data type, as b is here:", "An element of a structured datatype that behaves like an ndarray.", "An alias for a field name in a structured datatype.", "In NumPy, usually a synonym for dtype. For the more general Python meaning, see here.", "NumPy\u2019s fast element-by-element computation (vectorization) gives a choice which function gets applied. The general term for the function is ufunc, short for universal function. NumPy routines have built-in ufuncs, but users can also write their own.", "NumPy hands off array processing to C, where looping and computation are much faster than in Python. To exploit this, programmers using NumPy eliminate Python loops in favor of array-to-array operations. vectorization can refer both to the C offloading and to structuring NumPy code to leverage it.", "Without touching underlying data, NumPy can make one array appear to change its datatype and shape.", "An array created this way is a view, and NumPy often exploits the performance gain of using a view versus making a new array.", "A potential drawback is that writing to a view can alter the original as well. If this is a problem, NumPy instead needs to create a physically distinct array \u2013 a copy.", "Some NumPy routines always return views, some always return copies, some may return one or the other, and for some the choice can be specified. Responsibility for managing views and copies falls to the programmer. numpy.shares_memory will check whether b is a view of a, but an exact answer isn\u2019t always feasible, as the documentation page explains."]}, {"name": "--overwrite-signature", "path": "f2py/usage", "type": "Using F2PY", "text": ["F2PY can be used either as a command line tool f2py or as a Python module numpy.f2py. While we try to provide the command line tool as part of the numpy setup, some platforms like Windows make it difficult to reliably put the executables on the PATH. We will refer to f2py in this document but you may have to run it as a module:", "If you run f2py with no arguments, and the line numpy Version at the end matches the NumPy version printed from python -m numpy.f2py, then you can use the shorter version. If not, or if you cannot run f2py, you should replace all calls to f2py here with the longer version.", "When used as a command line tool, f2py has three major modes, distinguished by the usage of -c and -h switches:", "To scan Fortran sources and generate a signature file, use", "Note", "A Fortran source file can contain many routines, and it is often not necessary to allow all routines be usable from Python. In such cases, either specify which routines should be wrapped (in the only: .. : part) or which routines F2PY should ignored (in the skip: .. : part).", "If <filename.pyf> is specified as stdout then signatures are written to standard output instead of a file.", "Among other options (see below), the following can be used in this mode:", "Overwrites an existing signature file.", "To construct an extension module, use", "The constructed extension module is saved as <modulename>module.c to the current directory.", "Here <fortran files> may also contain signature files. Among other options (see below), the following options can be used in this mode:", "Adds debugging hooks to the extension module. When using this extension module, various diagnostic information about the wrapper is written to the standard output, for example, the values of variables, the steps taken, etc.", "Add a CPP #include statement to the extension module source. <includefile> should be given in one of the following forms", "The include statement is inserted just before the wrapper functions. This feature enables using arbitrary C functions (defined in <includefile>) in F2PY generated wrappers.", "Note", "This option is deprecated. Use usercode statement to specify C code snippets directly in signature files.", "Create Fortran subroutine wrappers to Fortran functions. --wrap-functions is default because it ensures maximum portability and compiler independence.", "Search include files from given directories.", "List system resources found by numpy_distutils/system_info.py. For example, try f2py --help-link lapack_opt.", "To build an extension module, use", "If <fortran files> contains a signature file, then the source for an extension module is constructed, all Fortran and C sources are compiled, and finally all object and library files are linked to the extension module <modulename>.so which is saved into the current directory.", "If <fortran files> does not contain a signature file, then an extension module is constructed by scanning all Fortran source codes for routine signatures, before proceeding to build the extension module.", "Among other options (see below) and options described for previous modes, the following options can be used in this mode:", "List the available Fortran compilers.", "List the available Fortran compilers.", "Specify a Fortran compiler type by vendor.", "Specify the path to a F77 compiler", "Specify the path to a F77 compiler", "Specify the path to a F90 compiler", "Specify the path to a F90 compiler", "Specify F77 compiler flags", "Specify F90 compiler flags", "Specify optimization flags", "Specify architecture specific optimization flags", "Compile without optimization flags", "Compile without arch-dependent optimization flags", "Compile with debugging information", "Use the library <libname> when linking.", "Define macro <macro> as <defn>.", "Define macro <macro>", "Append directory <dir> to the list of directories searched for include files.", "Add directory <dir> to the list of directories to be searched for -l.", "Link the extension module with <resource> as defined by numpy_distutils/system_info.py. E.g. to link with optimized LAPACK libraries (vecLib on MacOSX, ATLAS elsewhere), use --link-lapack_opt. See also --help-link switch.", "Note", "The f2py -c option must be applied either to an existing .pyf file (plus the source/object/library files) or one must specify the -m <modulename> option (plus the sources/object/library files). Use one of the following options:", "or", "For more information, see the Building C and C++ Extensions Python documentation for details.", "When building an extension module, a combination of the following macros may be required for non-gcc Fortran compilers:", "To test the performance of F2PY generated interfaces, use -DF2PY_REPORT_ATEXIT. Then a report of various timings is printed out at the exit of Python. This feature may not work on all platforms, currently only Linux platform is supported.", "To see whether F2PY generated interface performs copies of array arguments, use -DF2PY_REPORT_ON_ARRAY_COPY=<int>. When the size of an array argument is larger than <int>, a message about the coping is sent to stderr.", "Name of an extension module. Default is untitled.", "Warning", "Don\u2019t use this option if a signature file (*.pyf) is used.", "Do [not] lower the cases in <fortran files>. By default, --lower is assumed with -h switch, and --no-lower without the -h switch.", "All F2PY generated files are created in <dirname>. Default is tempfile.mkdtemp().", "Run quietly.", "Run with extra verbosity.", "Print the F2PY version and exit.", "Execute f2py without any options to get an up-to-date list of available options.", "Warning", "The current Python interface to the f2py module is not mature and may change in the future.", "Fortran to Python Interface Generator.", "Build extension module from a Fortran 77 source string with f2py.", "Fortran source of module / subroutine to compile", "Changed in version 1.16.0: Accept str as well as bytes", "The name of the compiled python module", "Additional parameters passed to f2py", "Changed in version 1.16.0: A list of args may also be provided.", "Print f2py output to screen", "Name of the file where the fortran source is written. The default is to use a temporary file with the extension provided by the extension parameter", "Filename extension if source_fn is not provided. The extension tells which fortran standard is used. The default is f, which implies F77 standard.", "New in version 1.11.0.", "If True, return a subprocess.CompletedProcess containing the stdout and stderr of the compile process, instead of just the status code.", "New in version 1.20.0.", "0 on success, or a subprocess.CompletedProcess if full_output=True", "Return the directory that contains the fortranobject.c and .h files.", "Note", "This function is not needed when building an extension with numpy.distutils directly from .f and/or .pyf files in one go.", "Python extension modules built with f2py-generated code need to use fortranobject.c as a source file, and include the fortranobject.h header. This function can be used to obtain the directory containing both of these files.", "Absolute path to the directory containing fortranobject.c and fortranobject.h.", "See also", "function that returns the numpy include directory", "New in version 1.22.0.", "Unless the build system you are using has specific support for f2py, building a Python extension using a .pyf signature file is a two-step process. For a module mymod:", "Step 2: build your Python extension module. This requires the following source files:", "Equivalent to running:", "where <args>=string.join(<list>,' '), but in Python. Unless -h is used, this function returns a dictionary containing information on generated modules and their dependencies on source files. For example, the command f2py -m scalar scalar.f can be executed from Python as follows", "You cannot build extension modules with this function, that is, using -c is not allowed. Use compile command instead"]}, {"name": "1", "path": "reference/arrays.scalars", "type": "Scalars", "text": ["Python defines only one type of a particular data class (there is only one integer type, one floating-point type, etc.). This can be convenient in applications that don\u2019t need to be concerned with all the ways data can be represented in a computer. For scientific computing, however, more control is often needed.", "In NumPy, there are 24 new fundamental Python types to describe different types of scalars. These type descriptors are mostly based on the types available in the C language that CPython is written in, with several additional types compatible with Python\u2019s types.", "Array scalars have the same attributes and methods as ndarrays. 1 This allows one to treat items of an array partly on the same footing as arrays, smoothing out rough edges that result when mixing scalar and array operations.", "Array scalars live in a hierarchy (see the Figure below) of data types. They can be detected using the hierarchy: For example, isinstance(val, np.generic) will return True if val is an array scalar object. Alternatively, what kind of array scalar is present can be determined using other members of the data type hierarchy. Thus, for example isinstance(val, np.complexfloating) will return True if val is a complex valued type, while isinstance(val, np.flexible) will return true if val is one of the flexible itemsize array types (str_, bytes_, void).", "Figure: Hierarchy of type objects representing the array data types. Not shown are the two integer types intp and uintp which just point to the integer type that holds a pointer for the platform. All the number types can be obtained using bit-width names as well.", "However, array scalars are immutable, so none of the array scalar attributes are settable.", "The built-in scalar types are shown below. The C-like names are associated with character codes, which are shown in their descriptions. Use of the character codes, however, is discouraged.", "Some of the scalar types are essentially equivalent to fundamental Python types and therefore inherit from them as well as from the generic array scalar type:", "Array scalar type", "Related Python type", "Inherits?", "int_", "int", "Python 2 only", "float_", "float", "yes", "complex_", "complex", "yes", "bytes_", "bytes", "yes", "str_", "str", "yes", "bool_", "bool", "no", "datetime64", "datetime.datetime", "no", "timedelta64", "datetime.timedelta", "no", "The bool_ data type is very similar to the Python bool but does not inherit from it because Python\u2019s bool does not allow itself to be inherited from, and on the C-level the size of the actual bool data is not the same as a Python Boolean scalar.", "Warning", "The int_ type does not inherit from the int built-in under Python 3, because type int is no longer a fixed-width integer type.", "Tip", "The default data type in NumPy is float_.", "Base class for numpy scalar types.", "Class from which most (all?) numpy scalar types are derived. For consistency, exposes the same API as ndarray, despite many consequent attributes being either \u201cget-only,\u201d or completely irrelevant. This is the class from which it is strongly suggested users should derive custom scalar types.", "Abstract base class of all numeric scalar types.", "Abstract base class of all integer scalar types.", "Note", "The numpy integer types mirror the behavior of C integers, and can therefore be subject to Overflow Errors.", "Abstract base class of all signed integer scalar types.", "Signed integer type, compatible with C char.", "'b'", "numpy.int8: 8-bit signed integer (-128 to 127).", "Signed integer type, compatible with C short.", "'h'", "numpy.int16: 16-bit signed integer (-32_768 to 32_767).", "Signed integer type, compatible with C int.", "'i'", "numpy.int32: 32-bit signed integer (-2_147_483_648 to 2_147_483_647).", "Signed integer type, compatible with Python int and C long.", "'l'", "numpy.int64: 64-bit signed integer (-9_223_372_036_854_775_808 to 9_223_372_036_854_775_807).", "numpy.intp: Signed integer large enough to fit pointer, compatible with C intptr_t.", "Signed integer type, compatible with C long long.", "'q'", "Abstract base class of all unsigned integer scalar types.", "Unsigned integer type, compatible with C unsigned char.", "'B'", "numpy.uint8: 8-bit unsigned integer (0 to 255).", "Unsigned integer type, compatible with C unsigned short.", "'H'", "numpy.uint16: 16-bit unsigned integer (0 to 65_535).", "Unsigned integer type, compatible with C unsigned int.", "'I'", "numpy.uint32: 32-bit unsigned integer (0 to 4_294_967_295).", "Unsigned integer type, compatible with C unsigned long.", "'L'", "numpy.uint64: 64-bit unsigned integer (0 to 18_446_744_073_709_551_615).", "numpy.uintp: Unsigned integer large enough to fit pointer, compatible with C uintptr_t.", "Signed integer type, compatible with C unsigned long long.", "'Q'", "Abstract base class of all numeric scalar types with a (potentially) inexact representation of the values in its range, such as floating-point numbers.", "Note", "Inexact scalars are printed using the fewest decimal digits needed to distinguish their value from other values of the same datatype, by judicious rounding. See the unique parameter of format_float_positional and format_float_scientific.", "This means that variables with equal binary values but whose datatypes are of different precisions may display differently:", "Note that none of these floats hold the exact value \\(\\frac{1}{10}\\); f16 prints as 0.1 because it is as close to that value as possible, whereas the other types do not as they have more precision and therefore have closer values.", "Conversely, floating-point scalars of different precisions which approximate the same decimal value may compare unequal despite printing identically:", "Abstract base class of all floating-point scalar types.", "Half-precision floating-point number type.", "'e'", "numpy.float16: 16-bit-precision floating-point number type: sign bit, 5 bits exponent, 10 bits mantissa.", "Single-precision floating-point number type, compatible with C float.", "'f'", "numpy.float32: 32-bit-precision floating-point number type: sign bit, 8 bits exponent, 23 bits mantissa.", "Double-precision floating-point number type, compatible with Python float and C double.", "'d'", "numpy.float_", "numpy.float64: 64-bit precision floating-point number type: sign bit, 11 bits exponent, 52 bits mantissa.", "Extended-precision floating-point number type, compatible with C long double but not necessarily with IEEE 754 quadruple-precision.", "'g'", "numpy.longfloat", "numpy.float128: 128-bit extended-precision floating-point number type.", "Abstract base class of all complex number scalar types that are made up of floating-point numbers.", "Complex number type composed of two single-precision floating-point numbers.", "'F'", "numpy.singlecomplex", "numpy.complex64: Complex number type composed of 2 32-bit-precision floating-point numbers.", "Complex number type composed of two double-precision floating-point numbers, compatible with Python complex.", "'D'", "numpy.cfloat", "numpy.complex_", "numpy.complex128: Complex number type composed of 2 64-bit-precision floating-point numbers.", "Complex number type composed of two extended-precision floating-point numbers.", "'G'", "numpy.clongfloat", "numpy.longcomplex", "numpy.complex256: Complex number type composed of 2 128-bit extended-precision floating-point numbers.", "Boolean type (True or False), stored as a byte.", "Warning", "The bool_ type is not a subclass of the int_ type (the bool_ is not even a number type). This is different than Python\u2019s default implementation of bool as a sub-class of int.", "'?'", "numpy.bool8", "If created from a 64-bit integer, it represents an offset from 1970-01-01T00:00:00. If created from string, the string can be in ISO 8601 date or datetime format.", "See Datetimes and Timedeltas for more information.", "'M'", "A timedelta stored as a 64-bit integer.", "See Datetimes and Timedeltas for more information.", "'m'", "Any Python object.", "'O'", "Note", "The data actually stored in object arrays (i.e., arrays having dtype object_) are references to Python objects, not the objects themselves. Hence, object arrays behave more like usual Python lists, in the sense that their contents need not be of the same Python type.", "The object type is also special because an array containing object_ items does not return an object_ object on item access, but instead returns the actual object that the array item refers to.", "The following data types are flexible: they have no predefined size and the data they describe can be of different length in different arrays. (In the character codes # is an integer denoting how many elements the data type consists of.)", "Abstract base class of all scalar types without predefined length. The actual size of these types depends on the specific np.dtype instantiation.", "A byte string.", "When used in arrays, this type strips trailing null bytes.", "'S'", "numpy.string_", "A unicode string.", "When used in arrays, this type strips trailing null codepoints.", "Unlike the builtin str, this supports the Buffer Protocol, exposing its contents as UCS4:", "'U'", "numpy.unicode_", "Either an opaque sequence of bytes, or a structure.", "Structured void scalars can only be constructed via extraction from Structured arrays:", "'V'", "Warning", "See Note on string types.", "Numeric Compatibility: If you used old typecode characters in your Numeric code (which was never recommended), you will need to change some of them to the new characters. In particular, the needed changes are c -> S1, b -> B, 1 -> b, s -> h, w ->\nH, and u -> I. These changes make the type character convention more consistent with other Python modules such as the struct module.", "Along with their (mostly) C-derived names, the integer, float, and complex data-types are also available using a bit-width convention so that an array of the right size can always be ensured. Two aliases (numpy.intp and numpy.uintp) pointing to the integer type that is sufficiently large to hold a C pointer are also provided.", "alias of numpy.bool_", "Aliases for the signed integer types (one of numpy.byte, numpy.short, numpy.intc, numpy.int_ and numpy.longlong) with the specified number of bits.", "Compatible with the C99 int8_t, int16_t, int32_t, and int64_t, respectively.", "Alias for the unsigned integer types (one of numpy.ubyte, numpy.ushort, numpy.uintc, numpy.uint and numpy.ulonglong) with the specified number of bits.", "Compatible with the C99 uint8_t, uint16_t, uint32_t, and uint64_t, respectively.", "Alias for the signed integer type (one of numpy.byte, numpy.short, numpy.intc, numpy.int_ and np.longlong) that is the same size as a pointer.", "Compatible with the C intptr_t.", "'p'", "Alias for the unsigned integer type (one of numpy.ubyte, numpy.ushort, numpy.uintc, numpy.uint and np.ulonglong) that is the same size as a pointer.", "Compatible with the C uintptr_t.", "'P'", "alias of numpy.half", "alias of numpy.single", "alias of numpy.double", "Alias for numpy.longdouble, named after its size in bits. The existence of these aliases depends on the platform.", "alias of numpy.csingle", "alias of numpy.cdouble", "Alias for numpy.clongdouble, named after its size in bits. The existence of these aliases depends on the platform.", "The first two of these are conveniences which resemble the names of the builtin types, in the same style as bool_, int_, str_, bytes_, and object_:", "alias of numpy.double", "alias of numpy.cdouble", "Some more use alternate naming conventions for extended-precision floats and complex numbers:", "alias of numpy.longdouble", "alias of numpy.csingle", "alias of numpy.cdouble", "alias of numpy.clongdouble", "alias of numpy.clongdouble", "The following aliases originate from Python 2, and it is recommended that they not be used in new code.", "alias of numpy.bytes_", "alias of numpy.str_", "The array scalar objects have an array priority of NPY_SCALAR_PRIORITY (-1,000,000.0). They also do not (yet) have a ctypes attribute. Otherwise, they share the same attributes as arrays:", "generic.flags", "The integer value of flags.", "generic.shape", "Tuple of array dimensions.", "generic.strides", "Tuple of bytes steps in each dimension.", "generic.ndim", "The number of array dimensions.", "generic.data", "Pointer to start of data.", "generic.size", "The number of elements in the gentype.", "generic.itemsize", "The length of one element in bytes.", "generic.base", "Scalar attribute identical to the corresponding array attribute.", "generic.dtype", "Get array data-descriptor.", "generic.real", "The real part of the scalar.", "generic.imag", "The imaginary part of the scalar.", "generic.flat", "A 1-D view of the scalar.", "generic.T", "Scalar attribute identical to the corresponding array attribute.", "generic.__array_interface__", "Array protocol: Python side", "generic.__array_struct__", "Array protocol: struct", "generic.__array_priority__", "Array priority.", "generic.__array_wrap__", "sc.__array_wrap__(obj) return scalar from array", "See also", "Indexing routines, Data type objects (dtype)", "Array scalars can be indexed like 0-dimensional arrays: if x is an array scalar,", "Array scalars have exactly the same methods as arrays. The default behavior of these methods is to internally convert the scalar to an equivalent 0-dimensional array and to call the corresponding array method. In addition, math operations on array scalars are defined so that the same hardware flags are set and used to interpret the results as for ufunc, so that the error state used for ufuncs also carries over to the math on array scalars.", "The exceptions to the above rules are given below:", "generic.__array__", "sc.__array__(dtype) return 0-dim array from scalar with specified dtype", "generic.__array_wrap__", "sc.__array_wrap__(obj) return scalar from array", "generic.squeeze", "Scalar method identical to the corresponding array attribute.", "generic.byteswap", "Scalar method identical to the corresponding array attribute.", "generic.__reduce__", "Helper for pickle.", "generic.__setstate__", "generic.setflags", "Scalar method identical to the corresponding array attribute.", "Utility method for typing:", "number.__class_getitem__(item, /)", "Return a parametrized wrapper around the number type.", "There are two ways to effectively define a new array scalar type (apart from composing structured types dtypes from the built-in scalar types): One way is to simply subclass the ndarray and overwrite the methods of interest. This will work to a degree, but internally certain behaviors are fixed by the data type of the array. To fully customize the data type of an array you need to define a new data-type, and register it with NumPy. Such new types can only be defined in C, using the NumPy C-API."]}, {"name": "1", "path": "reference/random/parallel", "type": "Parallel Applications", "text": ["There are three strategies implemented that can be used to produce repeatable pseudo-random numbers across multiple processes (local or distributed).", "SeedSequence implements an algorithm to process a user-provided seed, typically as an integer of some size, and to convert it into an initial state for a BitGenerator. It uses hashing techniques to ensure that low-quality seeds are turned into high quality initial states (at least, with very high probability).", "For example, MT19937 has a state consisting of 624 uint32 integers. A naive way to take a 32-bit integer seed would be to just set the last element of the state to the 32-bit seed and leave the rest 0s. This is a valid state for MT19937, but not a good one. The Mersenne Twister algorithm suffers if there are too many 0s. Similarly, two adjacent 32-bit integer seeds (i.e. 12345 and 12346) would produce very similar streams.", "SeedSequence avoids these problems by using successions of integer hashes with good avalanche properties to ensure that flipping any bit in the input input has about a 50% chance of flipping any bit in the output. Two input seeds that are very close to each other will produce initial states that are very far from each other (with very high probability). It is also constructed in such a way that you can provide arbitrary-sized integers or lists of integers. SeedSequence will take all of the bits that you provide and mix them together to produce however many bits the consuming BitGenerator needs to initialize itself.", "These properties together mean that we can safely mix together the usual user-provided seed with simple incrementing counters to get BitGenerator states that are (to very high probability) independent of each other. We can wrap this together into an API that is easy to use and difficult to misuse.", "Child SeedSequence objects can also spawn to make grandchildren, and so on. Each SeedSequence has its position in the tree of spawned SeedSequence objects mixed in with the user-provided seed to generate independent (with very high probability) streams.", "This feature lets you make local decisions about when and how to split up streams without coordination between processes. You do not have to preallocate space to avoid overlapping or request streams from a common global service. This general \u201ctree-hashing\u201d scheme is not unique to numpy but not yet widespread. Python has increasingly-flexible mechanisms for parallelization available, and this scheme fits in very well with that kind of use.", "Using this scheme, an upper bound on the probability of a collision can be estimated if one knows the number of streams that you derive. SeedSequence hashes its inputs, both the seed and the spawn-tree-path, down to a 128-bit pool by default. The probability that there is a collision in that pool, pessimistically-estimated (1), will be about \\(n^2*2^{-128}\\) where n is the number of streams spawned. If a program uses an aggressive million streams, about \\(2^{20}\\), then the probability that at least one pair of them are identical is about \\(2^{-88}\\), which is in solidly-ignorable territory (2).", "The algorithm is carefully designed to eliminate a number of possible ways to collide. For example, if one only does one level of spawning, it is guaranteed that all states will be unique. But it\u2019s easier to estimate the naive upper bound on a napkin and take comfort knowing that the probability is actually lower.", "In this calculation, we can mostly ignore the amount of numbers drawn from each stream. See Upgrading PCG64 with PCG64DXSM for the technical details about PCG64. The other PRNGs we provide have some extra protection built in that avoids overlaps if the SeedSequence pools differ in the slightest bit. PCG64DXSM has \\(2^{127}\\) separate cycles determined by the seed in addition to the position in the \\(2^{128}\\) long period for each cycle, so one has to both get on or near the same cycle and seed a nearby position in the cycle. Philox has completely independent cycles determined by the seed. SFC64 incorporates a 64-bit counter so every unique seed is at least \\(2^{64}\\) iterations away from any other seed. And finally, MT19937 has just an unimaginably huge period. Getting a collision internal to SeedSequence is the way a failure would be observed.", "Philox is a counter-based RNG based which generates values by encrypting an incrementing counter using weak cryptographic primitives. The seed determines the key that is used for the encryption. Unique keys create unique, independent streams. Philox lets you bypass the seeding algorithm to directly set the 128-bit key. Similar, but different, keys will still create independent streams.", "This scheme does require that you avoid reusing stream IDs. This may require coordination between the parallel processes.", "jumped advances the state of the BitGenerator as-if a large number of random numbers have been drawn, and returns a new instance with this state. The specific number of draws varies by BitGenerator, and ranges from \\(2^{64}\\) to \\(2^{128}\\). Additionally, the as-if draws also depend on the size of the default random number produced by the specific BitGenerator. The BitGenerators that support jumped, along with the period of the BitGenerator, the size of the jump and the bits in the default unsigned random are listed below.", "BitGenerator", "Period", "Jump Size", "Bits per Draw", "MT19937", "\\(2^{19937}-1\\)", "\\(2^{128}\\)", "32", "PCG64", "\\(2^{128}\\)", "\\(~2^{127}\\) (3)", "64", "PCG64DXSM", "\\(2^{128}\\)", "\\(~2^{127}\\) (3)", "64", "Philox", "\\(2^{256}\\)", "\\(2^{128}\\)", "64", "The jump size is \\((\\phi-1)*2^{128}\\) where \\(\\phi\\) is the golden ratio. As the jumps wrap around the period, the actual distances between neighboring streams will slowly grow smaller than the jump size, but using the golden ratio this way is a classic method of constructing a low-discrepancy sequence that spreads out the states around the period optimally. You will not be able to jump enough to make those distances small enough to overlap in your lifetime.", "jumped can be used to produce long blocks which should be long enough to not overlap.", "When using jumped, one does have to take care not to jump to a stream that was already used. In the above example, one could not later use blocked_rng[0].jumped() as it would overlap with blocked_rng[1]. Like with the independent streams, if the main process here wants to split off 10 more streams by jumping, then it needs to start with range(10, 20), otherwise it would recreate the same streams. On the other hand, if you carefully construct the streams, then you are guaranteed to have streams that do not overlap."]}, {"name": "1", "path": "user/basics.broadcasting", "type": "User Guide", "text": ["See also", "numpy.broadcast", "The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is \u201cbroadcast\u201d across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. There are, however, cases where broadcasting is a bad idea because it leads to inefficient use of memory that slows computation.", "NumPy operations are usually done on pairs of arrays on an element-by-element basis. In the simplest case, the two arrays must have exactly the same shape, as in the following example:", "NumPy\u2019s broadcasting rule relaxes this constraint when the arrays\u2019 shapes meet certain constraints. The simplest broadcasting example occurs when an array and a scalar value are combined in an operation:", "The result is equivalent to the previous example where b was an array. We can think of the scalar b being stretched during the arithmetic operation into an array with the same shape as a. The new elements in b, as shown in Figure 1, are simply copies of the original scalar. The stretching analogy is only conceptual. NumPy is smart enough to use the original scalar value without actually making copies so that broadcasting operations are as memory and computationally efficient as possible.", "Figure 1", "In the simplest example of broadcasting, the scalar b is stretched to become an array of same shape as a so the shapes are compatible for element-by-element multiplication.", "The code in the second example is more efficient than that in the first because broadcasting moves less memory around during the multiplication (b is a scalar rather than an array).", "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when", "If these conditions are not met, a ValueError: operands could not be broadcast together exception is thrown, indicating that the arrays have incompatible shapes. The size of the resulting array is the size that is not 1 along each axis of the inputs.", "Arrays do not need to have the same number of dimensions. For example, if you have a 256x256x3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:", "When either of the dimensions compared is one, the other is used. In other words, dimensions with size 1 are stretched or \u201ccopied\u201d to match the other.", "In the following example, both the A and B arrays have axes with length one that are expanded to a larger size during the broadcast operation:", "A set of arrays is called \u201cbroadcastable\u201d to the same shape if the above rules produce a valid result.", "For example, if a.shape is (5,1), b.shape is (1,6), c.shape is (6,) and d.shape is () so that d is a scalar, then a, b, c, and d are all broadcastable to dimension (5,6); and", "Here are some more examples:", "Here are examples of shapes that do not broadcast:", "An example of broadcasting when a 1-d array is added to a 2-d array:", "As shown in Figure 2, b is added to each row of a. In Figure 3, an exception is raised because of the incompatible shapes.", "Figure 2", "A one dimensional array added to a two dimensional array results in broadcasting if number of 1-d array elements matches the number of 2-d array columns.", "Figure 3", "When the trailing dimensions of the arrays are unequal, broadcasting fails because it is impossible to align the values in the rows of the 1st array with the elements of the 2nd arrays for element-by-element addition.", "Broadcasting provides a convenient way of taking the outer product (or any other outer operation) of two arrays. The following example shows an outer addition operation of two 1-d arrays:", "Figure 4", "In some cases, broadcasting stretches both arrays to form an output array larger than either of the initial arrays.", "Here the newaxis index operator inserts a new axis into a, making it a two-dimensional 4x1 array. Combining the 4x1 array with b, which has shape (3,), yields a 4x3 array.", "Broadcasting comes up quite often in real world problems. A typical example occurs in the vector quantization (VQ) algorithm used in information theory, classification, and other related areas. The basic operation in VQ finds the closest point in a set of points, called codes in VQ jargon, to a given point, called the observation. In the very simple, two-dimensional case shown below, the values in observation describe the weight and height of an athlete to be classified. The codes represent different classes of athletes. 1 Finding the closest point requires calculating the distance between observation and each of the codes. The shortest distance provides the best match. In this example, codes[0] is the closest class indicating that the athlete is likely a basketball player.", "In this example, the observation array is stretched to match the shape of the codes array:", "Figure 5", "The basic operation of vector quantization calculates the distance between an object to be classified, the dark square, and multiple known codes, the gray circles. In this simple case, the codes represent individual classes. More complex cases use multiple codes per class.", "Typically, a large number of observations, perhaps read from a database, are compared to a set of codes. Consider this scenario:", "The three-dimensional array, diff, is a consequence of broadcasting, not a necessity for the calculation. Large data sets will generate a large intermediate array that is computationally inefficient. Instead, if each observation is calculated individually using a Python loop around the code in the two-dimensional example above, a much smaller array is used.", "Broadcasting is a powerful tool for writing short and usually intuitive code that does its computations very efficiently in C. However, there are cases when broadcasting uses unnecessarily large amounts of memory for a particular algorithm. In these cases, it is better to write the algorithm\u2019s outer loop in Python. This may also produce more readable code, as algorithms that use broadcasting tend to become more difficult to interpret as the number of dimensions in the broadcast increases.", "In this example, weight has more impact on the distance calculation than height because of the larger values. In practice, it is important to normalize the height and weight, often by their standard deviation across the data set, so that both have equal influence on the distance calculation."]}, {"name": "1", "path": "reference/routines.polynomials", "type": "Polynomials", "text": ["Polynomials in NumPy can be created, manipulated, and even fitted using the convenience classes of the numpy.polynomial package, introduced in NumPy 1.4.", "Prior to NumPy 1.4, numpy.poly1d was the class of choice and it is still available in order to maintain backward compatibility. However, the newer polynomial package is more complete and its convenience classes provide a more consistent, better-behaved interface for working with polynomial expressions. Therefore numpy.polynomial is recommended for new coding.", "Note", "Terminology", "The term polynomial module refers to the old API defined in numpy.lib.polynomial, which includes the numpy.poly1d class and the polynomial functions prefixed with poly accessible from the numpy namespace (e.g. numpy.polyadd, numpy.polyval, numpy.polyfit, etc.).", "The term polynomial package refers to the new API defined in numpy.polynomial, which includes the convenience classes for the different kinds of polynomials (numpy.polynomial.Polynomial, numpy.polynomial.Chebyshev, etc.).", "As noted above, the poly1d class and associated functions defined in numpy.lib.polynomial, such as numpy.polyfit and numpy.poly, are considered legacy and should not be used in new code. Since NumPy version 1.4, the numpy.polynomial package is preferred for working with polynomials.", "The following table highlights some of the main differences between the legacy polynomial module and the polynomial package for common tasks. The Polynomial class is imported for brevity:", "How to\u2026", "Legacy (numpy.poly1d)", "numpy.polynomial", "Create a polynomial object from coefficients 1", "p = np.poly1d([1, 2, 3])", "p = Polynomial([3, 2, 1])", "Create a polynomial object from roots", "r = np.poly([-1, 1]) p = np.poly1d(r)", "p = Polynomial.fromroots([-1, 1])", "Fit a polynomial of degree deg to data", "np.polyfit(x, y, deg)", "Polynomial.fit(x, y, deg)", "Note the reversed ordering of the coefficients", "There are significant differences between numpy.lib.polynomial and numpy.polynomial. The most significant difference is the ordering of the coefficients for the polynomial expressions. The various routines in numpy.polynomial all deal with series whose coefficients go from degree zero upward, which is the reverse order of the poly1d convention. The easy way to remember this is that indices correspond to degree, i.e., coef[i] is the coefficient of the term of degree i.", "Though the difference in convention may be confusing, it is straightforward to convert from the legacy polynomial API to the new. For example, the following demonstrates how you would convert a numpy.poly1d instance representing the expression \\(x^{2} + 2x + 3\\) to a Polynomial instance representing the same expression:", "In addition to the coef attribute, polynomials from the polynomial package also have domain and window attributes. These attributes are most relevant when fitting polynomials to data, though it should be noted that polynomials with different domain and window attributes are not considered equal, and can\u2019t be mixed in arithmetic:", "See the documentation for the convenience classes for further details on the domain and window attributes.", "Another major difference between the legacy polynomial module and the polynomial package is polynomial fitting. In the old module, fitting was done via the polyfit function. In the polynomial package, the fit class method is preferred. For example, consider a simple linear fit to the following data:", "With the legacy polynomial module, a linear fit (i.e. polynomial of degree 1) could be applied to these data with polyfit:", "With the new polynomial API, the fit class method is preferred:", "Note that the coefficients are given in the scaled domain defined by the linear mapping between the window and domain. convert can be used to get the coefficients in the unscaled data domain.", "In addition to standard power series polynomials, the polynomial package provides several additional kinds of polynomials including Chebyshev, Hermite (two subtypes), Laguerre, and Legendre polynomials. Each of these has an associated convenience class available from the numpy.polynomial namespace that provides a consistent interface for working with polynomials regardless of their type.", "Documentation pertaining to specific functions defined for each kind of polynomial individually can be found in the corresponding module documentation:"]}, {"name": "1", "path": "reference/routines.polynomials.chebyshev", "type": "Chebyshev Series ( \n        \n         numpy.polynomial.chebyshev\n        \n        )", "text": ["This module provides a number of objects (mostly functions) useful for dealing with Chebyshev series, including a Chebyshev class that encapsulates the usual arithmetic operations. (General information on how this module represents and works with such polynomials is in the docstring for its \u201cparent\u201d sub-package, numpy.polynomial).", "Chebyshev(coef[, domain, window])", "A Chebyshev series class.", "chebdomain", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "chebzero", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "chebone", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "chebx", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "chebadd(c1, c2)", "Add one Chebyshev series to another.", "chebsub(c1, c2)", "Subtract one Chebyshev series from another.", "chebmulx(c)", "Multiply a Chebyshev series by x.", "chebmul(c1, c2)", "Multiply one Chebyshev series by another.", "chebdiv(c1, c2)", "Divide one Chebyshev series by another.", "chebpow(c, pow[, maxpower])", "Raise a Chebyshev series to a power.", "chebval(x, c[, tensor])", "Evaluate a Chebyshev series at points x.", "chebval2d(x, y, c)", "Evaluate a 2-D Chebyshev series at points (x, y).", "chebval3d(x, y, z, c)", "Evaluate a 3-D Chebyshev series at points (x, y, z).", "chebgrid2d(x, y, c)", "Evaluate a 2-D Chebyshev series on the Cartesian product of x and y.", "chebgrid3d(x, y, z, c)", "Evaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.", "chebder(c[, m, scl, axis])", "Differentiate a Chebyshev series.", "chebint(c[, m, k, lbnd, scl, axis])", "Integrate a Chebyshev series.", "chebfromroots(roots)", "Generate a Chebyshev series with given roots.", "chebroots(c)", "Compute the roots of a Chebyshev series.", "chebvander(x, deg)", "Pseudo-Vandermonde matrix of given degree.", "chebvander2d(x, y, deg)", "Pseudo-Vandermonde matrix of given degrees.", "chebvander3d(x, y, z, deg)", "Pseudo-Vandermonde matrix of given degrees.", "chebgauss(deg)", "Gauss-Chebyshev quadrature.", "chebweight(x)", "The weight function of the Chebyshev polynomials.", "chebcompanion(c)", "Return the scaled companion matrix of c.", "chebfit(x, y, deg[, rcond, full, w])", "Least squares fit of Chebyshev series to data.", "chebpts1(npts)", "Chebyshev points of the first kind.", "chebpts2(npts)", "Chebyshev points of the second kind.", "chebtrim(c[, tol])", "Remove \"small\" \"trailing\" coefficients from a polynomial.", "chebline(off, scl)", "Chebyshev series whose graph is a straight line.", "cheb2poly(c)", "Convert a Chebyshev series to a polynomial.", "poly2cheb(pol)", "Convert a polynomial to a Chebyshev series.", "chebinterpolate(func, deg[, args])", "Interpolate a function at the Chebyshev points of the first kind.", "numpy.polynomial", "The implementations of multiplication, division, integration, and differentiation use the algebraic identities [1]:", "where", "These identities allow a Chebyshev series to be expressed as a finite, symmetric Laurent series. In this module, this sort of Laurent series is referred to as a \u201cz-series.\u201d", "A. T. Benjamin, et al., \u201cCombinatorial Trigonometry with Chebyshev Polynomials,\u201d Journal of Statistical Planning and Inference 14, 2008 (https://web.archive.org/web/20080221202153/https://www.math.hmc.edu/~benjamin/papers/CombTrig.pdf, pg. 4)"]}, {"name": "add_data_dir()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_data_dir", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Recursively add files under data_path to data_files list.", "Recursively add files under data_path to the list of data_files to be installed (and distributed). The data_path can be either a relative path-name, or an absolute path-name, or a 2-tuple where the first argument shows where in the install directory the data directory should be installed to.", "Argument can be either", "Rules for installation paths:", "For example suppose the source directory contains fun/foo.dat and fun/bar/car.dat:", "Will install data-files to the locations:"]}, {"name": "add_data_files()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_data_files", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Add data files to configuration data_files.", "Argument(s) can be either", "The form of each element of the files sequence is very flexible allowing many combinations of where to get the files from the package and where they should ultimately be installed on the system. The most basic usage is for an element of the files argument sequence to be a simple filename. This will cause that file from the local path to be installed to the installation path of the self.name package (package path). The file argument can also be a relative path in which case the entire relative path will be installed into the package directory. Finally, the file can be an absolute path name in which case the file will be found at the absolute path name but installed to the package path.", "This basic behavior can be augmented by passing a 2-tuple in as the file argument. The first element of the tuple should specify the relative path (under the package install directory) where the remaining sequence of files should be installed to (it has nothing to do with the file-names in the source distribution). The second element of the tuple is the sequence of files that should be installed. The files in this sequence can be filenames, relative paths, or absolute paths. For absolute paths the file will be installed in the top-level package installation directory (regardless of the first argument). Filenames and relative path names will be installed in the package install directory under the path name given as the first element of the tuple.", "Rules for installation paths:", "An additional feature is that the path to a data-file can actually be a function that takes no arguments and returns the actual path(s) to the data-files. This is useful when the data files are generated while building the package.", "Add files to the list of data_files to be included with the package.", "will install these data files to:", "where <package install directory> is the package (or sub-package) directory such as \u2018/usr/lib/python2.4/site-packages/mypackage\u2019 (\u2018C: Python2.4 Lib site-packages mypackage\u2019) or \u2018/usr/lib/python2.4/site- packages/mypackage/mysubpackage\u2019 (\u2018C: Python2.4 Lib site-packages mypackage mysubpackage\u2019)."]}, {"name": "add_extension()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_extension", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Add extension to configuration.", "Create and add an Extension instance to the ext_modules list. This method also takes the following optional keyword arguments that are passed on to the Extension constructor.", "name of the extension", "list of the sources. The list of sources may contain functions (called source generators) which must take an extension instance and a build directory as inputs and return a source file or list of source files or None. If None is returned then no sources are generated. If the Extension instance has no sources after processing all source generators, then no extension module is built.", "The depends list contains paths to files or directories that the sources of the extension module depend on. If any path in the depends list is newer than the extension module, then the module will be rebuilt.", "dict or list of dict of keywords to be appended to keywords.", "The self.paths(\u2026) method is applied to all lists that may contain paths."]}, {"name": "add_headers()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_headers", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Add installable headers to configuration.", "Add the given sequence of files to the beginning of the headers list. By default, headers will be installed under <python- include>/<self.name.replace(\u2018.\u2019,\u2019/\u2019)>/ directory. If an item of files is a tuple, then its first argument specifies the actual installation location relative to the <python-include> path.", "Argument(s) can be either:"]}, {"name": "add_include_dirs()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_include_dirs", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Add paths to configuration include directories.", "Add the given sequence of paths to the beginning of the include_dirs list. This list will be visible to all extension modules of the current package."]}, {"name": "add_installed_library()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_installed_library", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Similar to add_library, but the specified library is installed.", "Most C libraries used with distutils are only used to build python extensions, but libraries built through this method will be installed so that they can be reused by third-party packages.", "Name of the installed library.", "List of the library\u2019s source files. See add_library for details.", "Path to install the library, relative to the current sub-package.", "The following keys are allowed:", "See also", "The best way to encode the options required to link against the specified C libraries is to use a \u201clibname.ini\u201d file, and use get_info to retrieve the required options (see add_npy_pkg_config for more information)."]}, {"name": "add_library()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_library", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Add library to configuration.", "Name of the extension.", "List of the sources. The list of sources may contain functions (called source generators) which must take an extension instance and a build directory as inputs and return a source file or list of source files or None. If None is returned then no sources are generated. If the Extension instance has no sources after processing all source generators, then no extension module is built.", "The following keys are allowed:"]}, {"name": "add_npy_pkg_config()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_npy_pkg_config", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Generate and install a npy-pkg config file from a template.", "The config file generated from template is installed in the given install directory, using subst_dict for variable substitution.", "The path of the template, relatively to the current package path.", "Where to install the npy-pkg config file, relatively to the current package path.", "If given, any string of the form @key@ will be replaced by subst_dict[key] in the template file when installed. The install prefix is always available through the variable @prefix@, since the install prefix is not easy to get reliably from setup.py.", "See also", "This works for both standard installs and in-place builds, i.e. the @prefix@ refer to the source directory for in-place builds.", "Assuming the foo.ini.in file has the following content:", "The generated file will have the following content:", "and will be installed as foo.ini in the \u2018lib\u2019 subpath.", "When cross-compiling with numpy distutils, it might be necessary to use modified npy-pkg-config files. Using the default/generated files will link with the host libraries (i.e. libnpymath.a). For cross-compilation you of-course need to link with target libraries, while using the host Python installation.", "You can copy out the numpy/core/lib/npy-pkg-config directory, add a pkgdir value to the .ini files and set NPY_PKG_CONFIG_PATH environment variable to point to the directory with the modified npy-pkg-config files.", "Example npymath.ini modified for cross-compilation:"]}, {"name": "add_scripts()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_scripts", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Add scripts to configuration.", "Add the sequence of files to the beginning of the scripts list. Scripts will be installed under the <prefix>/bin/ directory."]}, {"name": "add_subpackage()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_subpackage", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Add a sub-package to the current Configuration instance.", "This is useful in a setup.py script for adding sub-packages to a package.", "name of the subpackage", "if given, the subpackage path such as the subpackage is in subpackage_path / subpackage_name. If None,the subpackage is assumed to be located in the local path / subpackage_name."]}, {"name": "Additional Git Resources", "path": "dev/gitwash/git_resources", "type": "Development", "text": ["There are many ways of working with git; here are some posts on the rules of thumb that other projects have come up with:", "You can get these on your own machine with (e.g) git help push or (same thing) git push --help, but, for convenience, here are the online manual pages for some common commands:"]}, {"name": "Advanced debugging tools", "path": "dev/development_advanced_debugging", "type": "Development", "text": ["If you reached here, you want to dive into, or use, more advanced tooling. This is usually not necessary for first time contributors and most day-to-day development. These are used more rarely, for example close to a new NumPy release, or when a large or particular complex change was made.", "Since not all of these tools are used on a regular bases and only available on some systems, please expect differences, issues, or quirks; we will be happy to help if you get stuck and appreciate any improvements or suggestions to these workflows.", "Most development will not require more than a typical debugging toolchain as shown in Debugging. But for example memory leaks can be particularly subtle or difficult to narrow down.", "We do not expect any of these tools to be run by most contributors. However, you can ensure that we can track down such issues more easily easier:", "This will help us catch any oversights before your change is released and means you do not have to worry about making reference counting errors, which can be intimidating.", "Debug builds of Python are easily available for example on debian systems, and can be used on all platforms. Running a test or terminal is usually as easy as:", "and were already mentioned in Debugging.", "A Python debug build will help:", "Python debug builds allows to check correct reference counting. This works using the additional commands:", "Running the test suite only with a debug python build will not find many errors on its own. An additional advantage of a debug build of Python is that it allows detecting memory leaks.", "A tool to make this easier is pytest-leaks, which can be installed using pip. Unfortunately, pytest itself may leak memory, but good results can usually (currently) be achieved by removing:", "from numpy/conftest.py (This may change with new pytest-leaks versions or pytest updates).", "This allows to run the test suite, or part of it, conveniently:", "where -R2:3 is the pytest-leaks command (see its documentation), the -s causes output to print and may be necessary (in some versions captured output was detected as a leak).", "Note that some tests are known (or even designed) to leak references, we try to mark them, but expect some false positives.", "Valgrind is a powerful tool to find certain memory access problems and should be run on complicated C code. Basic use of valgrind usually requires no more than:", "where PYTHONMALLOC=malloc is necessary to avoid false positives from python itself. Depending on the system and valgrind version, you may see more false positives. valgrind supports \u201csuppressions\u201d to ignore some of these, and Python does have a suppression file (and even a compile time option) which may help if you find it necessary.", "Valgrind helps:", "Find many memory leaks. Note that for most leaks the python debug build approach (and pytest-leaks) is much more sensitive. The reason is that valgrind can only detect if memory is definitely lost. If:", "Has incorrect reference counting for dtype, this is a bug, but valgrind cannot see it because np.dtype(np.int64) always returns the same object. However, not all dtypes are singletons, so this might leak memory for different input. In rare cases NumPy uses malloc and not the Python memory allocators which are invisible to the Python debug build. malloc should normally be avoided, but there are some exceptions (e.g. the PyArray_Dims structure is public API and cannot use the Python allocators.)", "Even though using valgrind for memory leak detection is slow and less sensitive it can be a convenient: you can run most programs with valgrind without modification.", "Things to be aware of:", "A big advantage of valgrind is that it has no requirements aside from valgrind itself (although you probably want to use debug builds for better tracebacks).", "You can run the test suite with valgrind which may be sufficient when you are only interested in a few tests:", "Note the --continue-on-collection-errors, which is currently necessary due to missing longdouble support causing failures (this will usually not be necessary if you do not run the full test suite).", "If you wish to detect memory leaks you will also require --show-leak-kinds=definite and possibly more valgrind options. Just as for pytest-leaks certain tests are known to leak cause errors in valgrind and may or may not be marked as such.", "We have developed pytest-valgrind which:", "Please refer to its README for more information (it includes an example command for NumPy)."]}, {"name": "Advanced F2PY use cases", "path": "f2py/advanced", "type": "Advanced F2PY use cases", "text": ["User-defined Python C/API functions can be defined inside signature files using usercode and pymethoddef statements (they must be used inside the python module block). For example, the following signature file spam.pyf", "wraps the C library function system():", "In Python this can then be used as:", "The following example illustrates how to add user-defined variables to a F2PY generated extension module by modifying the dictionary of a F2PY generated module. Consider the following signature file (compiled with f2py -c var.pyf):", "Notice that the second usercode statement must be defined inside an interface block and the module dictionary is available through the variable d (see varmodule.c generated by f2py var.pyf for additional details).", "Usage in Python:", "Currently, F2PY can handle only <type spec>(kind=<kindselector>) declarations where <kindselector> is a numeric integer (e.g. 1, 2, 4,\u2026), but not a function call KIND(..) or any other expression. F2PY needs to know what would be the corresponding C type and a general solution for that would be too complicated to implement.", "However, F2PY provides a hook to overcome this difficulty, namely, users can define their own <Fortran type> to <C type> maps. For example, if Fortran 90 code contains:", "then create a mapping file containing a Python dictionary:", "for instance.", "Use the --f2cmap command-line option to pass the file name to F2PY. By default, F2PY assumes file name is .f2py_f2cmap in the current working directory.", "More generally, the f2cmap file must contain a dictionary with items:", "that defines mapping between Fortran type:", "and the corresponding <C type>. The <C type> can be one of the following:", "For more information, see the F2Py source code numpy/f2py/capi_maps.py."]}, {"name": "Array creation", "path": "user/basics.creation", "type": "User Guide", "text": ["See also", "Array creation routines", "There are 6 general mechanisms for creating arrays:", "You can use these methods to create ndarrays or Structured arrays. This document will cover general methods for ndarray creation.", "NumPy arrays can be defined using Python sequences such as lists and tuples. Lists and tuples are defined using [...] and (...), respectively. Lists and tuples can define ndarray creation:", "When you use numpy.array to define a new array, you should consider the dtype of the elements in the array, which can be specified explicitly. This feature gives you more control over the underlying data structures and how the elements are handled in C/C++ functions. If you are not careful with dtype assignments, you can get unwanted overflow, as such", "An 8-bit signed integer represents integers from -128 to 127. Assigning the int8 array to integers outside of this range results in overflow. This feature can often be misunderstood. If you perform calculations with mismatching dtypes, you can get unwanted results, for example:", "Notice when you perform operations with two arrays of the same dtype: uint32, the resulting array is the same type. When you perform operations with different dtype, NumPy will assign a new type that satisfies all of the array elements involved in the computation, here uint32 and int32 can both be represented in as int64.", "The default NumPy behavior is to create arrays in either 64-bit signed integers or double precision floating point numbers, int64 and float, respectively. If you expect your arrays to be a certain type, then you need to specify the dtype while you create the array.", "NumPy has over 40 built-in functions for creating arrays as laid out in the Array creation routines. These functions can be split into roughly three categories, based on the dimension of the array they create:", "The 1D array creation functions e.g. numpy.linspace and numpy.arange generally need at least two inputs, start and stop.", "numpy.arange creates arrays with regularly incrementing values. Check the documentation for complete information and examples. A few examples are shown:", "Note: best practice for numpy.arange is to use integer start, end, and step values. There are some subtleties regarding dtype. In the second example, the dtype is defined. In the third example, the array is dtype=float to accommodate the step size of 0.1. Due to roundoff error, the stop value is sometimes included.", "numpy.linspace will create arrays with a specified number of elements, and spaced equally between the specified beginning and end values. For example:", "The advantage of this creation function is that you guarantee the number of elements and the starting and end point. The previous arange(start, stop, step) will not include the value stop.", "The 2D array creation functions e.g. numpy.eye, numpy.diag, and numpy.vander define properties of special matrices represented as 2D arrays.", "np.eye(n, m) defines a 2D identity matrix. The elements where i=j (row index and column index are equal) are 1 and the rest are 0, as such:", "numpy.diag can define either a square 2D array with given values along the diagonal or if given a 2D array returns a 1D array that is only the diagonal elements. The two array creation functions can be helpful while doing linear algebra, as such:", "vander(x, n) defines a Vandermonde matrix as a 2D NumPy array. Each column of the Vandermonde matrix is a decreasing power of the input 1D array or list or tuple, x where the highest polynomial order is n-1. This array creation routine is helpful in generating linear least squares models, as such:", "The ndarray creation functions e.g. numpy.ones, numpy.zeros, and random define arrays based upon the desired shape. The ndarray creation functions can create arrays with any dimension by specifying how many dimensions and length along that dimension in a tuple or list.", "numpy.zeros will create an array filled with 0 values with the specified shape. The default dtype is float64:", "numpy.ones will create an array filled with 1 values. It is identical to zeros in all other respects as such:", "The random method of the result of default_rng will create an array filled with random values between 0 and 1. It is included with the numpy.random library. Below, two arrays are created with shapes (2,3) and (2,3,2), respectively. The seed is set to 42 so you can reproduce these pseudorandom numbers:", "numpy.indices will create a set of arrays (stacked as a one-higher dimensioned array), one per dimension with each representing variation in that dimension:", "This is particularly useful for evaluating functions of multiple dimensions on a regular grid.", "Once you have created arrays, you can replicate, join, or mutate those existing arrays to create new arrays. When you assign an array or its elements to a new variable, you have to explicitly numpy.copy the array, otherwise the variable is a view into the original array. Consider the following example:", "In this example, you did not create a new array. You created a variable, b that viewed the first 2 elements of a. When you added 1 to b you would get the same result by adding 1 to a[:2]. If you want to create a new array, use the numpy.copy array creation routine as such:", "For more information and examples look at Copies and Views.", "There are a number of routines to join existing arrays e.g. numpy.vstack, numpy.hstack, and numpy.block. Here is an example of joining four 2-by-2 arrays into a 4-by-4 array using block:", "Other routines use similar syntax to join ndarrays. Check the routine\u2019s documentation for further examples and syntax.", "This is the most common case of large array creation. The details depend greatly on the format of data on disk. This section gives general pointers on how to handle various formats. For more detailed examples of IO look at How to Read and Write files.", "Various fields have standard formats for array data. The following lists the ones with known Python libraries to read them and return NumPy arrays (there may be others for which it is possible to read and convert to NumPy arrays so check the last section as well)", "Examples of formats that cannot be read directly but for which it is not hard to convert are those formats supported by libraries like PIL (able to read and write many image formats such as jpg, png, etc).", "Delimited files such as comma separated value (csv) and tab separated value (tsv) files are used for programs like Excel and LabView. Python functions can read and parse these files line-by-line. NumPy has two standard routines for importing a file with delimited data numpy.loadtxt and numpy.genfromtxt. These functions have more involved use cases in Reading and writing files. A simple example given a simple.csv:", "Importing simple.csv is accomplished using loadtxt:", "More generic ASCII files can be read using scipy.io and Pandas.", "There are a variety of approaches one can use. If the file has a relatively simple format then one can write a simple I/O library and use the NumPy fromfile() function and .tofile() method to read and write NumPy arrays directly (mind your byteorder though!) If a good C or C++ library exists that read the data, one can wrap that library with a variety of techniques though that certainly is much more work and requires significantly more advanced knowledge to interface with C or C++.", "NumPy is the fundamental library for array containers in the Python Scientific Computing stack. Many Python libraries, including SciPy, Pandas, and OpenCV, use NumPy ndarrays as the common format for data exchange, These libraries can create, operate on, and work with NumPy arrays."]}, {"name": "Array creation routines", "path": "reference/routines.array-creation", "type": "Array creation routines", "text": ["See also", "Array creation", "empty(shape[, dtype, order, like])", "Return a new array of given shape and type, without initializing entries.", "empty_like(prototype[, dtype, order, subok, ...])", "Return a new array with the same shape and type as a given array.", "eye(N[, M, k, dtype, order, like])", "Return a 2-D array with ones on the diagonal and zeros elsewhere.", "identity(n[, dtype, like])", "Return the identity array.", "ones(shape[, dtype, order, like])", "Return a new array of given shape and type, filled with ones.", "ones_like(a[, dtype, order, subok, shape])", "Return an array of ones with the same shape and type as a given array.", "zeros(shape[, dtype, order, like])", "Return a new array of given shape and type, filled with zeros.", "zeros_like(a[, dtype, order, subok, shape])", "Return an array of zeros with the same shape and type as a given array.", "full(shape, fill_value[, dtype, order, like])", "Return a new array of given shape and type, filled with fill_value.", "full_like(a, fill_value[, dtype, order, ...])", "Return a full array with the same shape and type as a given array.", "array(object[, dtype, copy, order, subok, ...])", "Create an array.", "asarray(a[, dtype, order, like])", "Convert the input to an array.", "asanyarray(a[, dtype, order, like])", "Convert the input to an ndarray, but pass ndarray subclasses through.", "ascontiguousarray(a[, dtype, like])", "Return a contiguous array (ndim >= 1) in memory (C order).", "asmatrix(data[, dtype])", "Interpret the input as a matrix.", "copy(a[, order, subok])", "Return an array copy of the given object.", "frombuffer(buffer[, dtype, count, offset, like])", "Interpret a buffer as a 1-dimensional array.", "fromfile(file[, dtype, count, sep, offset, like])", "Construct an array from data in a text or binary file.", "fromfunction(function, shape, *[, dtype, like])", "Construct an array by executing a function over each coordinate.", "fromiter(iter, dtype[, count, like])", "Create a new 1-dimensional array from an iterable object.", "fromstring(string[, dtype, count, like])", "A new 1-D array initialized from text data in a string.", "loadtxt(fname[, dtype, comments, delimiter, ...])", "Load data from a text file.", "Note", "numpy.rec is the preferred alias for numpy.core.records.", "core.records.array(obj[, dtype, shape, ...])", "Construct a record array from a wide-variety of objects.", "core.records.fromarrays(arrayList[, dtype, ...])", "Create a record array from a (flat) list of arrays", "core.records.fromrecords(recList[, dtype, ...])", "Create a recarray from a list of records in text form.", "core.records.fromstring(datastring[, dtype, ...])", "Create a record array from binary data", "core.records.fromfile(fd[, dtype, shape, ...])", "Create an array from binary file data", "Note", "numpy.char is the preferred alias for numpy.core.defchararray.", "core.defchararray.array(obj[, itemsize, ...])", "Create a chararray.", "core.defchararray.asarray(obj[, itemsize, ...])", "Convert the input to a chararray, copying the data only if necessary.", "arange([start,] stop[, step,][, dtype, like])", "Return evenly spaced values within a given interval.", "linspace(start, stop[, num, endpoint, ...])", "Return evenly spaced numbers over a specified interval.", "logspace(start, stop[, num, endpoint, base, ...])", "Return numbers spaced evenly on a log scale.", "geomspace(start, stop[, num, endpoint, ...])", "Return numbers spaced evenly on a log scale (a geometric progression).", "meshgrid(*xi[, copy, sparse, indexing])", "Return coordinate matrices from coordinate vectors.", "mgrid", "nd_grid instance which returns a dense multi-dimensional \"meshgrid\".", "ogrid", "nd_grid instance which returns an open multi-dimensional \"meshgrid\".", "diag(v[, k])", "Extract a diagonal or construct a diagonal array.", "diagflat(v[, k])", "Create a two-dimensional array with the flattened input as a diagonal.", "tri(N[, M, k, dtype, like])", "An array with ones at and below the given diagonal and zeros elsewhere.", "tril(m[, k])", "Lower triangle of an array.", "triu(m[, k])", "Upper triangle of an array.", "vander(x[, N, increasing])", "Generate a Vandermonde matrix.", "mat(data[, dtype])", "Interpret the input as a matrix.", "bmat(obj[, ldict, gdict])", "Build a matrix object from a string, nested sequence, or array."]}, {"name": "Array manipulation routines", "path": "reference/routines.array-manipulation", "type": "Array manipulation routines", "text": ["copyto(dst, src[, casting, where])", "Copies values from one array to another, broadcasting as necessary.", "shape(a)", "Return the shape of an array.", "reshape(a, newshape[, order])", "Gives a new shape to an array without changing its data.", "ravel(a[, order])", "Return a contiguous flattened array.", "ndarray.flat", "A 1-D iterator over the array.", "ndarray.flatten([order])", "Return a copy of the array collapsed into one dimension.", "moveaxis(a, source, destination)", "Move axes of an array to new positions.", "rollaxis(a, axis[, start])", "Roll the specified axis backwards, until it lies in a given position.", "swapaxes(a, axis1, axis2)", "Interchange two axes of an array.", "ndarray.T", "The transposed array.", "transpose(a[, axes])", "Reverse or permute the axes of an array; returns the modified array.", "atleast_1d(*arys)", "Convert inputs to arrays with at least one dimension.", "atleast_2d(*arys)", "View inputs as arrays with at least two dimensions.", "atleast_3d(*arys)", "View inputs as arrays with at least three dimensions.", "broadcast", "Produce an object that mimics broadcasting.", "broadcast_to(array, shape[, subok])", "Broadcast an array to a new shape.", "broadcast_arrays(*args[, subok])", "Broadcast any number of arrays against each other.", "expand_dims(a, axis)", "Expand the shape of an array.", "squeeze(a[, axis])", "Remove axes of length one from a.", "asarray(a[, dtype, order, like])", "Convert the input to an array.", "asanyarray(a[, dtype, order, like])", "Convert the input to an ndarray, but pass ndarray subclasses through.", "asmatrix(data[, dtype])", "Interpret the input as a matrix.", "asfarray(a[, dtype])", "Return an array converted to a float type.", "asfortranarray(a[, dtype, like])", "Return an array (ndim >= 1) laid out in Fortran order in memory.", "ascontiguousarray(a[, dtype, like])", "Return a contiguous array (ndim >= 1) in memory (C order).", "asarray_chkfinite(a[, dtype, order])", "Convert the input to an array, checking for NaNs or Infs.", "asscalar(a)", "Convert an array of size 1 to its scalar equivalent.", "require(a[, dtype, requirements, like])", "Return an ndarray of the provided type that satisfies requirements.", "concatenate([axis, out, dtype, casting])", "Join a sequence of arrays along an existing axis.", "stack(arrays[, axis, out])", "Join a sequence of arrays along a new axis.", "block(arrays)", "Assemble an nd-array from nested lists of blocks.", "vstack(tup)", "Stack arrays in sequence vertically (row wise).", "hstack(tup)", "Stack arrays in sequence horizontally (column wise).", "dstack(tup)", "Stack arrays in sequence depth wise (along third axis).", "column_stack(tup)", "Stack 1-D arrays as columns into a 2-D array.", "row_stack(tup)", "Stack arrays in sequence vertically (row wise).", "split(ary, indices_or_sections[, axis])", "Split an array into multiple sub-arrays as views into ary.", "array_split(ary, indices_or_sections[, axis])", "Split an array into multiple sub-arrays.", "dsplit(ary, indices_or_sections)", "Split array into multiple sub-arrays along the 3rd axis (depth).", "hsplit(ary, indices_or_sections)", "Split an array into multiple sub-arrays horizontally (column-wise).", "vsplit(ary, indices_or_sections)", "Split an array into multiple sub-arrays vertically (row-wise).", "tile(A, reps)", "Construct an array by repeating A the number of times given by reps.", "repeat(a, repeats[, axis])", "Repeat elements of an array.", "delete(arr, obj[, axis])", "Return a new array with sub-arrays along an axis deleted.", "insert(arr, obj, values[, axis])", "Insert values along the given axis before the given indices.", "append(arr, values[, axis])", "Append values to the end of an array.", "resize(a, new_shape)", "Return a new array with the specified shape.", "trim_zeros(filt[, trim])", "Trim the leading and/or trailing zeros from a 1-D array or sequence.", "unique(ar[, return_index, return_inverse, ...])", "Find the unique elements of an array.", "flip(m[, axis])", "Reverse the order of elements in an array along the given axis.", "fliplr(m)", "Reverse the order of elements along axis 1 (left/right).", "flipud(m)", "Reverse the order of elements along axis 0 (up/down).", "reshape(a, newshape[, order])", "Gives a new shape to an array without changing its data.", "roll(a, shift[, axis])", "Roll array elements along a given axis.", "rot90(m[, k, axes])", "Rotate an array by 90 degrees in the plane specified by axes."]}, {"name": "Array objects", "path": "reference/arrays", "type": "Array objects", "text": ["NumPy provides an N-dimensional array type, the ndarray, which describes a collection of \u201citems\u201d of the same type. The items can be indexed using for example N integers.", "All ndarrays are homogeneous: every item takes up the same size block of memory, and all blocks are interpreted in exactly the same way. How each item in the array is to be interpreted is specified by a separate data-type object, one of which is associated with every array. In addition to basic types (integers, floats, etc.), the data type objects can also represent data structures.", "An item extracted from an array, e.g., by indexing, is represented by a Python object whose type is one of the array scalar types built in NumPy. The array scalars allow easy manipulation of also more complicated arrangements of data.", "Figure Conceptual diagram showing the relationship between the three fundamental objects used to describe the data in an array: 1) the ndarray itself, 2) the data-type object that describes the layout of a single fixed-size element of the array, 3) the array-scalar Python object that is returned when a single element of the array is accessed."]}, {"name": "Binary operations", "path": "reference/routines.bitwise", "type": "Binary operations", "text": ["bitwise_and(x1, x2, /[, out, where, ...])", "Compute the bit-wise AND of two arrays element-wise.", "bitwise_or(x1, x2, /[, out, where, casting, ...])", "Compute the bit-wise OR of two arrays element-wise.", "bitwise_xor(x1, x2, /[, out, where, ...])", "Compute the bit-wise XOR of two arrays element-wise.", "invert(x, /[, out, where, casting, order, ...])", "Compute bit-wise inversion, or bit-wise NOT, element-wise.", "left_shift(x1, x2, /[, out, where, casting, ...])", "Shift the bits of an integer to the left.", "right_shift(x1, x2, /[, out, where, ...])", "Shift the bits of an integer to the right.", "packbits(a, /[, axis, bitorder])", "Packs the elements of a binary-valued array into bits in a uint8 array.", "unpackbits(a, /[, axis, count, bitorder])", "Unpacks elements of a uint8 array into a binary-valued output array.", "binary_repr(num[, width])", "Return the binary representation of the input number as a string."]}, {"name": "Bit Generators", "path": "reference/random/bit_generators/index", "type": "Bit Generators", "text": ["The random values produced by Generator originate in a BitGenerator. The BitGenerators do not directly provide random numbers and only contains methods used for seeding, getting or setting the state, jumping or advancing the state, and for accessing low-level wrappers for consumption by code that can efficiently access the functions provided, e.g., numba.", "The included BitGenerators are:", "BitGenerator([seed])", "Base Class for generic BitGenerators, which provide a stream of random bits based on different algorithms."]}, {"name": "broadcast.index", "path": "reference/generated/numpy.broadcast.index", "type": "Standard array subclasses", "text": ["attribute", "current index in broadcasted result"]}, {"name": "broadcast.iters", "path": "reference/generated/numpy.broadcast.iters", "type": "Standard array subclasses", "text": ["attribute", "tuple of iterators along self\u2019s \u201ccomponents.\u201d", "Returns a tuple of numpy.flatiter objects, one for each \u201ccomponent\u201d of self.", "See also"]}, {"name": "broadcast.nd", "path": "reference/generated/numpy.broadcast.nd", "type": "Standard array subclasses", "text": ["attribute", "Number of dimensions of broadcasted result. For code intended for NumPy 1.12.0 and later the more consistent ndim is preferred."]}, {"name": "broadcast.ndim", "path": "reference/generated/numpy.broadcast.ndim", "type": "Standard array subclasses", "text": ["attribute", "Number of dimensions of broadcasted result. Alias for nd.", "New in version 1.12.0."]}, {"name": "broadcast.numiter", "path": "reference/generated/numpy.broadcast.numiter", "type": "Standard array subclasses", "text": ["attribute", "Number of iterators possessed by the broadcasted result."]}, {"name": "broadcast.reset()", "path": "reference/generated/numpy.broadcast.reset", "type": "numpy.broadcast.reset", "text": ["method", "Reset the broadcasted result\u2019s iterator(s)."]}, {"name": "broadcast.size", "path": "reference/generated/numpy.broadcast.size", "type": "Standard array subclasses", "text": ["attribute", "Total size of broadcasted result."]}, {"name": "build_src", "path": "f2py/buildtools/distutils", "type": "Using via \n        \n         numpy.distutils", "text": ["numpy.distutils is part of NumPy, and extends the standard Python distutils module to deal with Fortran sources and F2PY signature files, e.g. compile Fortran sources, call F2PY to construct extension modules, etc.", "Example", "Consider the following setup_file.py for the fib and scalar examples from Three ways to wrap - getting started section:", "Running", "will build two extension modules scalar and fib2 to the build directory.", "numpy.distutils extends distutils with the following features:", "Extension class argument sources may contain Fortran source files. In addition, the list sources may contain at most one F2PY signature file, and in this case, the name of an Extension module must match with the <modulename> used in signature file. It is assumed that an F2PY signature file contains exactly one python\nmodule block.", "If sources do not contain a signature file, then F2PY is used to scan Fortran source files to construct wrappers to the Fortran codes.", "Additional options to the F2PY executable can be given using the Extension class argument f2py_options.", "The following new distutils commands are defined:", "to construct Fortran wrapper extension modules, among many other things.", "to change Fortran compiler options.", "Additionally, the build_ext and build_clib commands are also enhanced to support Fortran sources.", "Run", "to see available options for these commands.", "When building Python packages containing Fortran sources, one can choose different Fortran compilers by using the build_ext command option --fcompiler=<Vendor>. Here <Vendor> can be one of the following names (on linux systems):", "See numpy_distutils/fcompiler.py for an up-to-date list of supported compilers for different platforms, or run"]}, {"name": "Building from source", "path": "user/building", "type": "User Guide", "text": ["There are two options for building NumPy- building with Gitpod or locally from source. Your choice depends on your operating system and familiarity with the command line.", "Gitpod is an open-source platform that automatically creates the correct development environment right in your browser, reducing the need to install local development environments and deal with incompatible dependencies.", "If you are a Windows user, unfamiliar with using the command line or building NumPy for the first time, it is often faster to build with Gitpod. Here are the in-depth instructions for building NumPy with building NumPy with Gitpod.", "Building locally on your machine gives you more granular control. If you are a MacOS or Linux user familiar with using the command line, you can continue with building NumPy locally by following the instructions below.", "Building NumPy requires the following software installed:", "Python 3.6.x or newer", "Please note that the Python development headers also need to be installed, e.g., on Debian/Ubuntu one needs to install both python3 and python3-dev. On Windows and macOS this is normally not an issue.", "Compilers", "Much of NumPy is written in C. You will need a C compiler that complies with the C99 standard.", "While a FORTRAN 77 compiler is not necessary for building NumPy, it is needed to run the numpy.f2py tests. These tests are skipped if the compiler is not auto-detected.", "Note that NumPy is developed mainly using GNU compilers and tested on MSVC and Clang compilers. Compilers from other vendors such as Intel, Absoft, Sun, NAG, Compaq, Vast, Portland, Lahey, HP, IBM are only supported in the form of community feedback, and may not work out of the box. GCC 4.x (and later) compilers are recommended. On ARM64 (aarch64) GCC 8.x (and later) are recommended.", "Linear Algebra libraries", "NumPy does not require any external linear algebra libraries to be installed. However, if these are available, NumPy\u2019s setup script can detect them and use them for building. A number of different LAPACK library setups can be used, including optimized LAPACK libraries such as OpenBLAS or MKL. The choice and location of these libraries as well as include paths and other such build options can be specified in a site.cfg file located in the NumPy root repository or a .numpy-site.cfg file in your home directory. See the site.cfg.example example file included in the NumPy repository or sdist for documentation, and below for specifying search priority from environmental variables.", "Cython", "For building NumPy, you\u2019ll need a recent version of Cython.", "To install NumPy, run:", "To perform an in-place build that can be run from the source folder run:", "Note: for build instructions to do development work on NumPy itself, see Setting up and using your development environment.", "Make sure to test your builds. To ensure everything stays in shape, see if all tests pass:", "For detailed info on testing, see Testing builds.", "It\u2019s possible to do a parallel build with:", "This will compile numpy on 4 CPUs and install it into the specified prefix. to perform a parallel in-place build, run:", "The number of build jobs can also be specified via the environment variable NPY_NUM_BUILD_JOBS.", "Compilers are auto-detected; building with a particular compiler can be done with --fcompiler. E.g. to select gfortran:", "For more information see:", "One relatively simple and reliable way to check for the compiler used to build a library is to use ldd on the library. If libg2c.so is a dependency, this means that g77 has been used (note: g77 is no longer supported for building NumPy). If libgfortran.so is a dependency, gfortran has been used. If both are dependencies, this means both have been used, which is almost always a very bad idea.", "NumPy searches for optimized linear algebra libraries such as BLAS and LAPACK. There are specific orders for searching these libraries, as described below and in the site.cfg.example file.", "Note that both BLAS and CBLAS interfaces are needed for a properly optimized build of NumPy.", "The default order for the libraries are:", "The detection of BLAS libraries may be bypassed by defining the environment variable NPY_BLAS_LIBS , which should contain the exact linker flags you want to use (interface is assumed to be Fortran 77). Also define NPY_CBLAS_LIBS (even empty if CBLAS is contained in your BLAS library) to trigger use of CBLAS and avoid slow fallback code for matrix calculations.", "If you wish to build against OpenBLAS but you also have BLIS available one may predefine the order of searching via the environment variable NPY_BLAS_ORDER which is a comma-separated list of the above names which is used to determine what to search for, for instance:", "will prefer to use ATLAS, then BLIS, then OpenBLAS and as a last resort MKL. If neither of these exists the build will fail (names are compared lower case).", "Alternatively one may use ! or ^ to negate all items:", "will allow using anything but NetLIB BLAS and ATLAS libraries, the order of the above list is retained.", "One cannot mix negation and positives, nor have multiple negations, such cases will raise an error.", "The default order for the libraries are:", "The detection of LAPACK libraries may be bypassed by defining the environment variable NPY_LAPACK_LIBS, which should contain the exact linker flags you want to use (language is assumed to be Fortran 77).", "If you wish to build against OpenBLAS but you also have MKL available one may predefine the order of searching via the environment variable NPY_LAPACK_ORDER which is a comma-separated list of the above names, for instance:", "will prefer to use ATLAS, then OpenBLAS and as a last resort MKL. If neither of these exists the build will fail (names are compared lower case).", "Alternatively one may use ! or ^ to negate all items:", "will allow using anything but the NetLIB LAPACK library, the order of the above list is retained.", "One cannot mix negation and positives, nor have multiple negations, such cases will raise an error.", "Deprecated since version 1.20: The native libraries on macOS, provided by Accelerate, are not fit for use in NumPy since they have bugs that cause wrong output under easily reproducible conditions. If the vendor fixes those bugs, the library could be reinstated, but until then users compiling for themselves should use another linear algebra library or use the built-in (but slower) default, see the next section.", "Usage of ATLAS and other accelerated libraries in NumPy can be disabled via:", "or:", "You can tell Numpy to use 64-bit BLAS/LAPACK libraries by setting the environment variable:", "when building Numpy. The following 64-bit BLAS/LAPACK libraries are supported:", "The order in which they are preferred is determined by NPY_BLAS_ILP64_ORDER and NPY_LAPACK_ILP64_ORDER environment variables. The default value is openblas64_,openblas_ilp64.", "Note", "Using non-symbol-suffixed 64-bit BLAS/LAPACK in a program that also uses 32-bit BLAS/LAPACK can cause crashes under certain conditions (e.g. with embedded Python interpreters on Linux).", "The 64-bit OpenBLAS with 64_ symbol suffix is obtained by compiling OpenBLAS with settings:", "The symbol suffix avoids the symbol name clashes between 32-bit and 64-bit BLAS/LAPACK libraries.", "Additional compiler flags can be supplied by setting the OPT, FOPT (for Fortran), and CC environment variables. When providing options that should improve the performance of the code ensure that you also set -DNDEBUG so that debugging code is not executed."]}, {"name": "Building the NumPy API and reference docs", "path": "dev/howto_build_docs", "type": "Development", "text": ["If you only want to get the documentation, note that pre-built versions can be found at", "https://numpy.org/doc/", "in several different formats.", "Before proceeding further it should be noted that the documentation is built with the make tool, which is not natively available on Windows. MacOS or Linux users can jump to Prerequisites. It is recommended for Windows users to set up their development environment on Gitpod or Windows Subsystem for Linux (WSL). WSL is a good option for a persistent local set-up.", "Gitpod is an open-source platform that automatically creates the correct development environment right in your browser, reducing the need to install local development environments and deal with incompatible dependencies.", "If you have good internet connectivity and want a temporary set-up, it is often faster to build with Gitpod. Here are the in-depth instructions for building NumPy with Gitpod.", "Building the NumPy documentation and API reference requires the following:", "Since large parts of the main documentation are obtained from NumPy via import numpy and examining the docstrings, you will need to first build and install it so that the correct version is imported. NumPy has to be re-built and re-installed every time you fetch the latest version of the repository, before generating the documentation. This ensures that the NumPy version and the git repository version are in sync.", "Note that you can e.g. install NumPy to a temporary location and set the PYTHONPATH environment variable appropriately. Alternatively, if using Python virtual environments (via e.g. conda, virtualenv or the venv module), installing NumPy into a new virtual environment is recommended.", "All of the necessary dependencies for building the NumPy docs except for Doxygen can be installed with:", "We currently use Sphinx along with Doxygen for generating the API and reference documentation for NumPy. In addition, building the documentation requires the Sphinx extension plot_directive, which is shipped with Matplotlib. We also use numpydoc to render docstrings in the generated API documentation. SciPy is installed since some parts of the documentation require SciPy functions.", "For installing Doxygen, please check the official download and installation pages, or if you are using Linux then you can install it through your distribution package manager.", "Note", "Try to install a newer version of Doxygen > 1.8.10 otherwise you may get some warnings during the build.", "If you obtained NumPy via git, also get the git submodules that contain additional parts required for building the documentation:", "Now you are ready to generate the docs, so write:", "If all goes well, this will generate a build/html subdirectory in the /doc directory, containing the built documentation. If you get a message about installed numpy != current repo git version, you must either override the check by setting GITVER or re-install NumPy.", "If you have built NumPy into a virtual environment and get an error that says numpy not found, cannot build documentation without..., you need to override the makefile PYTHON variable at the command line, so instead of writing make\u00a0 html write:", "To build the PDF documentation, do instead:", "You will need to have LaTeX installed for this, inclusive of support for Greek letters. For example, on Ubuntu xenial texlive-lang-greek and cm-super are needed. Also, latexmk is needed on non-Windows systems.", "Instead of the above, you can also do:", "which will rebuild NumPy, install it to a temporary location, and build the documentation in all formats. This will most likely again only work on Unix platforms.", "The documentation for NumPy distributed at https://numpy.org/doc in html and pdf format is also built with make dist. See HOWTO RELEASE for details on how to update https://numpy.org/doc."]}, {"name": "busdaycalendar.holidays", "path": "reference/generated/numpy.busdaycalendar.holidays", "type": "Datetime support functions", "text": ["attribute", "A copy of the holiday array indicating additional invalid days."]}, {"name": "busdaycalendar.weekmask", "path": "reference/generated/numpy.busdaycalendar.weekmask", "type": "Datetime support functions", "text": ["attribute", "A copy of the seven-element boolean mask indicating valid days."]}, {"name": "Byte-swapping", "path": "user/basics.byteswapping", "type": "User Guide", "text": ["The ndarray is an object that provide a python array interface to data in memory.", "It often happens that the memory that you want to view with an array is not of the same byte ordering as the computer on which you are running Python.", "For example, I might be working on a computer with a little-endian CPU - such as an Intel Pentium, but I have loaded some data from a file written by a computer that is big-endian. Let\u2019s say I have loaded 4 bytes from a file written by a Sun (big-endian) computer. I know that these 4 bytes represent two 16-bit integers. On a big-endian machine, a two-byte integer is stored with the Most Significant Byte (MSB) first, and then the Least Significant Byte (LSB). Thus the bytes are, in memory order:", "Let\u2019s say the two integers were in fact 1 and 770. Because 770 = 256 * 3 + 2, the 4 bytes in memory would contain respectively: 0, 1, 3, 2. The bytes I have loaded from the file would have these contents:", "We might want to use an ndarray to access these integers. In that case, we can create an array around this memory, and tell numpy that there are two integers, and that they are 16 bit and big-endian:", "Note the array dtype above of >i2. The > means \u2018big-endian\u2019 (< is little-endian) and i2 means \u2018signed 2-byte integer\u2019. For example, if our data represented a single unsigned 4-byte little-endian integer, the dtype string would be <u4.", "In fact, why don\u2019t we try that?", "Returning to our big_end_arr - in this case our underlying data is big-endian (data endianness) and we\u2019ve set the dtype to match (the dtype is also big-endian). However, sometimes you need to flip these around.", "Warning", "Scalars currently do not include byte order information, so extracting a scalar from an array will return an integer in native byte order. Hence:", "As you can imagine from the introduction, there are two ways you can affect the relationship between the byte ordering of the array and the underlying memory it is looking at:", "The common situations in which you need to change byte ordering are:", "We make something where they don\u2019t match:", "The obvious fix for this situation is to change the dtype so it gives the correct endianness:", "Note the array has not changed in memory:", "You might want to do this if you need the data in memory to be a certain ordering. For example you might be writing the memory out to a file that needs a certain byte ordering.", "Now the array has changed in memory:", "You may have a correctly specified array dtype, but you need the array to have the opposite byte order in memory, and you want the dtype to match so the array values make sense. In this case you just do both of the previous operations:", "An easier way of casting the data to a specific dtype and byte ordering can be achieved with the ndarray astype method:"]}, {"name": "C API Deprecations", "path": "reference/c-api/deprecations", "type": "C API Deprecations", "text": ["The API exposed by NumPy for third-party extensions has grown over years of releases, and has allowed programmers to directly access NumPy functionality from C. This API can be best described as \u201corganic\u201d. It has emerged from multiple competing desires and from multiple points of view over the years, strongly influenced by the desire to make it easy for users to move to NumPy from Numeric and Numarray. The core API originated with Numeric in 1995 and there are patterns such as the heavy use of macros written to mimic Python\u2019s C-API as well as account for compiler technology of the late 90\u2019s. There is also only a small group of volunteers who have had very little time to spend on improving this API.", "There is an ongoing effort to improve the API. It is important in this effort to ensure that code that compiles for NumPy 1.X continues to compile for NumPy 1.X. At the same time, certain API\u2019s will be marked as deprecated so that future-looking code can avoid these API\u2019s and follow better practices.", "Another important role played by deprecation markings in the C API is to move towards hiding internal details of the NumPy implementation. For those needing direct, easy, access to the data of ndarrays, this will not remove this ability. Rather, there are many potential performance optimizations which require changing the implementation details, and NumPy developers have been unable to try them because of the high value of preserving ABI compatibility. By deprecating this direct access, we will in the future be able to improve NumPy\u2019s performance in ways we cannot presently.", "In C, there is no equivalent to the deprecation warnings that Python supports. One way to do deprecations is to flag them in the documentation and release notes, then remove or change the deprecated features in a future major version (NumPy 2.0 and beyond). Minor versions of NumPy should not have major C-API changes, however, that prevent code that worked on a previous minor release. For example, we will do our best to ensure that code that compiled and worked on NumPy 1.4 should continue to work on NumPy 1.7 (but perhaps with compiler warnings).", "To use the NPY_NO_DEPRECATED_API mechanism, you need to #define it to the target API version of NumPy before #including any NumPy headers. If you want to confirm that your code is clean against 1.7, use:", "On compilers which support a #warning mechanism, NumPy issues a compiler warning if you do not define the symbol NPY_NO_DEPRECATED_API. This way, the fact that there are deprecations will be flagged for third-party developers who may not have read the release notes closely."]}, {"name": "char **NpyIter_GetDataPtrArray()", "path": "reference/c-api/iterator#c.NpyIter_GetDataPtrArray", "type": "Array Iterator API", "text": ["This gives back a pointer to the nop data pointers. If NPY_ITER_EXTERNAL_LOOP was not specified, each data pointer points to the current data item of the iterator. If no inner iteration was specified, it points to the first data item of the inner loop.", "This pointer may be cached before the iteration loop, calling iternext will not change it. This function may be safely called without holding the Python GIL."]}, {"name": "char **NpyIter_GetInitialDataPtrArray()", "path": "reference/c-api/iterator#c.NpyIter_GetInitialDataPtrArray", "type": "Array Iterator API", "text": ["Gets the array of data pointers directly into the arrays (never into the buffers), corresponding to iteration index 0.", "These pointers are different from the pointers accepted by NpyIter_ResetBasePointers, because the direction along some axes may have been reversed.", "This function may be safely called without holding the Python GIL."]}, {"name": "char *core_signature", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_signature", "type": "Python Types and C-Structures", "text": ["Core signature string"]}, {"name": "char *data", "path": "reference/c-api/types-and-structures#c.NPY_AO.data", "type": "Python Types and C-Structures", "text": ["Accessible via PyArray_DATA, this data member is a pointer to the first element of the array. This pointer can (and normally should) be recast to the data type of the array."]}, {"name": "char *dataptr", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.dataptr", "type": "Python Types and C-Structures", "text": ["This member points to an element in the ndarray indicated by the index."]}, {"name": "char *doc", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.doc", "type": "Python Types and C-Structures", "text": ["Documentation for the ufunc. Should not contain the function signature as this is generated dynamically when __doc__ is retrieved."]}, {"name": "char *name", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.name", "type": "Python Types and C-Structures", "text": ["A string name for the ufunc. This is used dynamically to build the __doc__ attribute of ufuncs."]}, {"name": "char *PyArray_BYTES()", "path": "reference/c-api/array#c.PyArray_BYTES", "type": "Array API", "text": ["These two macros are similar and obtain the pointer to the data-buffer for the array. The first macro can (and should be) assigned to a particular pointer where the second is for generic processing. If you have not guaranteed a contiguous and/or aligned array then be sure you understand how to access the data in the array to avoid memory and/or alignment problems."]}, {"name": "char *PyArray_One()", "path": "reference/c-api/array#c.PyArray_One", "type": "Array API", "text": ["A pointer to newly created memory of size arr ->itemsize that holds the representation of 1 for that type. The returned pointer, ret, must be freed using PyDataMem_FREE (ret) when it is not needed anymore."]}, {"name": "char *PyArray_Zero()", "path": "reference/c-api/array#c.PyArray_Zero", "type": "Array API", "text": ["A pointer to newly created memory of size arr ->itemsize that holds the representation of 0 for that type. The returned pointer, ret, must be freed using PyDataMem_FREE (ret) when it is not needed anymore."]}, {"name": "char *PyDataMem_RENEW()", "path": "reference/c-api/array#c.PyDataMem_RENEW", "type": "Array API", "text": ["Macros to allocate, free, and reallocate memory. These macros are used internally to create arrays."]}, {"name": "char *types", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.types", "type": "Python Types and C-Structures", "text": ["An array of \\(nargs \\times ntypes\\) 8-bit type_numbers which contains the type signature for the function for each of the supported (builtin) data types. For each of the ntypes functions, the corresponding set of type numbers in this array shows how the args argument should be interpreted in the 1-d vector loop. These type numbers do not have to be the same type and mixed-type ufuncs are supported."]}, {"name": "char byteorder", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.byteorder", "type": "Python Types and C-Structures", "text": ["A character indicating the byte-order: \u2018>\u2019 (big-endian), \u2018<\u2019 (little- endian), \u2018=\u2019 (native), \u2018|\u2019 (irrelevant, ignore). All builtin data- types have byteorder \u2018=\u2019."]}, {"name": "char flags", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.flags", "type": "Python Types and C-Structures", "text": ["A data-type bit-flag that determines if the data-type exhibits object- array like behavior. Each bit in this member is a flag which are named as:"]}, {"name": "char kind", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.kind", "type": "Python Types and C-Structures", "text": ["A character code indicating the kind of array (using the array interface typestring notation). A \u2018b\u2019 represents Boolean, a \u2018i\u2019 represents signed integer, a \u2018u\u2019 represents unsigned integer, \u2018f\u2019 represents floating point, \u2018c\u2019 represents complex floating point, \u2018S\u2019 represents 8-bit zero-terminated bytes, \u2018U\u2019 represents 32-bit/character unicode string, and \u2018V\u2019 represents arbitrary."]}, {"name": "char type", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.type", "type": "Python Types and C-Structures", "text": ["A traditional character code indicating the data type."]}, {"name": "char typekind", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.typekind", "type": "Python Types and C-Structures", "text": ["A character indicating what kind of array is present according to the typestring convention with \u2018t\u2019 -> bitfield, \u2018b\u2019 -> Boolean, \u2018i\u2019 -> signed integer, \u2018u\u2019 -> unsigned integer, \u2018f\u2019 -> floating point, \u2018c\u2019 -> complex floating point, \u2018O\u2019 -> object, \u2018S\u2019 -> (byte-)string, \u2018U\u2019 -> unicode, \u2018V\u2019 -> void."]}, {"name": "char.add()", "path": "reference/generated/numpy.char.add", "type": "numpy.char.add", "text": ["Return element-wise string concatenation for two arrays of str or unicode.", "Arrays x1 and x2 must have the same shape.", "Input array.", "Input array.", "Output array of string_ or unicode_, depending on input types of the same shape as x1 and x2."]}, {"name": "char.array()", "path": "reference/generated/numpy.char.array", "type": "numpy.char.array", "text": ["Create a chararray.", "Note", "This class is provided for numarray backward-compatibility. New code (not concerned with numarray compatibility) should use arrays of type string_ or unicode_ and use the free functions in numpy.char for fast vectorized string operations instead.", "Versus a regular NumPy array of type str or unicode, this class adds the following functionality:", "itemsize is the number of characters per scalar in the resulting array. If itemsize is None, and obj is an object array or a Python list, the itemsize will be automatically determined. If itemsize is provided and obj is of type str or unicode, then the obj string will be chunked into itemsize pieces.", "If true (default), then the object is copied. Otherwise, a copy will only be made if __array__ returns a copy, if obj is a nested sequence, or if a copy is needed to satisfy any of the other requirements (itemsize, unicode, order, etc.).", "When true, the resulting chararray can contain Unicode characters, when false only 8-bit characters. If unicode is None and obj is one of the following:", "then the unicode setting of the output array will be automatically determined.", "Specify the order of the array. If order is \u2018C\u2019 (default), then the array will be in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019, then the returned array will be in Fortran-contiguous order (first-index varies the fastest). If order is \u2018A\u2019, then the returned array may be in any order (either C-, Fortran-contiguous, or even discontiguous)."]}, {"name": "char.asarray()", "path": "reference/generated/numpy.char.asarray", "type": "numpy.char.asarray", "text": ["Convert the input to a chararray, copying the data only if necessary.", "Versus a regular NumPy array of type str or unicode, this class adds the following functionality:", "itemsize is the number of characters per scalar in the resulting array. If itemsize is None, and obj is an object array or a Python list, the itemsize will be automatically determined. If itemsize is provided and obj is of type str or unicode, then the obj string will be chunked into itemsize pieces.", "When true, the resulting chararray can contain Unicode characters, when false only 8-bit characters. If unicode is None and obj is one of the following:", "then the unicode setting of the output array will be automatically determined.", "Specify the order of the array. If order is \u2018C\u2019 (default), then the array will be in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019, then the returned array will be in Fortran-contiguous order (first-index varies the fastest)."]}, {"name": "char.capitalize()", "path": "reference/generated/numpy.char.capitalize", "type": "numpy.char.capitalize", "text": ["Return a copy of a with only the first character of each element capitalized.", "Calls str.capitalize element-wise.", "For 8-bit strings, this method is locale-dependent.", "Input array of strings to capitalize.", "Output array of str or unicode, depending on input types", "See also"]}, {"name": "char.center()", "path": "reference/generated/numpy.char.center", "type": "numpy.char.center", "text": ["Return a copy of a with its elements centered in a string of length width.", "Calls str.center element-wise.", "The length of the resulting strings", "The padding character to use (default is space).", "Output array of str or unicode, depending on input types", "See also"]}, {"name": "char.chararray.argsort()", "path": "reference/generated/numpy.char.chararray.argsort", "type": "numpy.char.chararray.argsort", "text": ["method", "Returns the indices that would sort this array.", "Refer to numpy.argsort for full documentation.", "See also", "equivalent function"]}, {"name": "char.chararray.astype()", "path": "reference/generated/numpy.char.chararray.astype", "type": "numpy.char.chararray.astype", "text": ["method", "Copy of the array, cast to a specified type.", "Typecode or data-type to which the array is cast.", "Controls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means Fortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous, \u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements appear in memory as possible. Default is \u2018K\u2019.", "Controls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for backwards compatibility.", "If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.", "By default, astype always returns a newly allocated array. If this is set to false, and the dtype, order, and subok requirements are satisfied, the input array is returned instead of a copy.", "Unless copy is False and the other conditions for returning the input array are satisfied (see description for copy input parameter), arr_t is a new array of the same shape as the input array, with dtype, order given by dtype, order.", "When casting from complex to float or int. To avoid this, one should use a.real.astype(t).", "Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is allowed, but casting from multiple fields is not.", "Changed in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019 casting mode requires that the string dtype length is long enough to store the max integer/float value converted."]}, {"name": "char.chararray.base", "path": "reference/generated/numpy.char.chararray.base", "type": "String operations", "text": ["attribute", "Base object if memory is from some other object.", "The base of an array that owns its memory is None:", "Slicing creates a view, whose memory is shared with x:"]}, {"name": "char.chararray.copy()", "path": "reference/generated/numpy.char.chararray.copy", "type": "numpy.char.chararray.copy", "text": ["method", "Return a copy of the array.", "Controls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of a as closely as possible. (Note that this function and numpy.copy are very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)", "See also", "Similar function with different default behavior", "This function is the preferred method for creating an array copy. The function numpy.copy is similar, but it defaults to using order \u2018K\u2019, and will not pass sub-classes through by default."]}, {"name": "char.chararray.count()", "path": "reference/generated/numpy.char.chararray.count", "type": "numpy.char.chararray.count", "text": ["method", "Returns an array with the number of non-overlapping occurrences of substring sub in the range [start, end].", "See also"]}, {"name": "char.chararray.ctypes", "path": "reference/generated/numpy.char.chararray.ctypes", "type": "String operations", "text": ["attribute", "An object to simplify the interaction of the array with the ctypes module.", "This attribute creates an object that makes it easier to use arrays when calling shared libraries with the ctypes module. The returned object has, among others, data, shape, and strides attributes (see Notes below) which themselves return ctypes objects that can be used as arguments to a shared library.", "Possessing attributes data, shape, strides, etc.", "See also", "Below are the public attributes of this object which were documented in \u201cGuide to NumPy\u201d (we have omitted undocumented public attributes, as well as documented private attributes):", "A pointer to the memory area of the array as a Python integer. This memory area may contain data that is not aligned, or not in correct byte-order. The memory area may not even be writeable. The array flags and data-type of this array should be respected when passing this attribute to arbitrary C-code to avoid trouble that can include Python crashing. User Beware! The value of this attribute is exactly the same as self._array_interface_['data'][0].", "Note that unlike data_as, a reference will not be kept to the array: code like ctypes.c_void_p((a + b).ctypes.data) will result in a pointer to a deallocated array, and should be spelt (a + b).ctypes.data_as(ctypes.c_void_p)", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the C-integer corresponding to dtype('p') on this platform (see c_intp). This base-type could be ctypes.c_int, ctypes.c_long, or ctypes.c_longlong depending on the platform. The ctypes array contains the shape of the underlying array.", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the same as for the shape attribute. This ctypes array contains the strides information from the underlying array. This strides information is important for showing how many bytes must be jumped to get to the next element in the array.", "Return the data pointer cast to a particular c-types object. For example, calling self._as_parameter_ is equivalent to self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a pointer to a ctypes array of floating-point data: self.data_as(ctypes.POINTER(ctypes.c_double)).", "The returned pointer will keep a reference to the array.", "Return the shape tuple as an array of some other c-types type. For example: self.shape_as(ctypes.c_short).", "Return the strides tuple as an array of some other c-types type. For example: self.strides_as(ctypes.c_longlong).", "If the ctypes module is not available, then the ctypes attribute of array objects still returns something useful, but ctypes objects are not returned and errors may be raised instead. In particular, the object will still have the as_parameter attribute which will return an integer equal to the data attribute."]}, {"name": "char.chararray.data", "path": "reference/generated/numpy.char.chararray.data", "type": "String operations", "text": ["attribute", "Python buffer object pointing to the start of the array\u2019s data."]}, {"name": "char.chararray.decode()", "path": "reference/generated/numpy.char.chararray.decode", "type": "numpy.char.chararray.decode", "text": ["method", "Calls str.decode element-wise.", "See also"]}, {"name": "char.chararray.dtype", "path": "reference/generated/numpy.char.chararray.dtype", "type": "String operations", "text": ["attribute", "Data-type of the array\u2019s elements.", "See also"]}, {"name": "char.chararray.dump()", "path": "reference/generated/numpy.char.chararray.dump", "type": "numpy.char.chararray.dump", "text": ["method", "Dump a pickle of the array to the specified file. The array can be read back with pickle.load or numpy.load.", "A string naming the dump file.", "Changed in version 1.17.0: pathlib.Path objects are now accepted."]}, {"name": "char.chararray.dumps()", "path": "reference/generated/numpy.char.chararray.dumps", "type": "numpy.char.chararray.dumps", "text": ["method", "Returns the pickle of the array as a string. pickle.loads will convert the string back to an array."]}, {"name": "char.chararray.encode()", "path": "reference/generated/numpy.char.chararray.encode", "type": "numpy.char.chararray.encode", "text": ["method", "Calls str.encode element-wise.", "See also"]}, {"name": "char.chararray.endswith()", "path": "reference/generated/numpy.char.chararray.endswith", "type": "numpy.char.chararray.endswith", "text": ["method", "Returns a boolean array which is True where the string element in self ends with suffix, otherwise False.", "See also"]}, {"name": "char.chararray.expandtabs()", "path": "reference/generated/numpy.char.chararray.expandtabs", "type": "numpy.char.chararray.expandtabs", "text": ["method", "Return a copy of each string element where all tab characters are replaced by one or more spaces.", "See also"]}, {"name": "char.chararray.fill()", "path": "reference/generated/numpy.char.chararray.fill", "type": "numpy.char.chararray.fill", "text": ["method", "Fill the array with a scalar value.", "All elements of a will be assigned this value."]}, {"name": "char.chararray.find()", "path": "reference/generated/numpy.char.chararray.find", "type": "numpy.char.chararray.find", "text": ["method", "For each element, return the lowest index in the string where substring sub is found.", "See also"]}, {"name": "char.chararray.flags", "path": "reference/generated/numpy.char.chararray.flags", "type": "String operations", "text": ["attribute", "Information about the memory layout of the array.", "The flags object can be accessed dictionary-like (as in a.flags['WRITEABLE']), or by using lowercased attribute names (as in a.flags.writeable). Short flag names are only supported in dictionary access.", "Only the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by the user, via direct assignment to the attribute or dictionary entry, or by calling ndarray.setflags.", "The array flags cannot be set arbitrarily:", "Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.", "Even for contiguous arrays a stride for a given dimension arr.strides[dim] may be arbitrary if arr.shape[dim] == 1 or the array has no elements. It does not generally hold that self.strides[-1] == self.itemsize for C-style contiguous arrays or self.strides[0] == self.itemsize for Fortran-style contiguous arrays is true.", "The data is in a single, C-style contiguous segment.", "The data is in a single, Fortran-style contiguous segment.", "The array owns the memory it uses or borrows it from another object.", "The data area can be written to. Setting this to False locks the data, making it read-only. A view (slice, etc.) inherits WRITEABLE from its base array at creation time, but a view of a writeable array may be subsequently locked while the base array remains writeable. (The opposite is not true, in that a view of a locked array may not be made writeable. However, currently, locking a base object does not lock any views that already reference it, so under that circumstance it is possible to alter the contents of a locked array via a previously created writeable view onto it.) Attempting to change a non-writeable array raises a RuntimeError exception.", "The data and all elements are aligned appropriately for the hardware.", "This array is a copy of some other array. The C-API function PyArray_ResolveWritebackIfCopy must be called before deallocating to the base array will be updated with the contents of this array.", "(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array. When this array is deallocated, the base array will be updated with the contents of this array.", "F_CONTIGUOUS and not C_CONTIGUOUS.", "F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).", "ALIGNED and WRITEABLE.", "BEHAVED and C_CONTIGUOUS.", "BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS."]}, {"name": "char.chararray.flat", "path": "reference/generated/numpy.char.chararray.flat", "type": "String operations", "text": ["attribute", "A 1-D iterator over the array.", "This is a numpy.flatiter instance, which acts similarly to, but is not a subclass of, Python\u2019s built-in iterator object.", "See also", "Return a copy of the array collapsed into one dimension.", "An assignment example:"]}, {"name": "char.chararray.flatten()", "path": "reference/generated/numpy.char.chararray.flatten", "type": "numpy.char.chararray.flatten", "text": ["method", "Return a copy of the array collapsed into one dimension.", "\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in column-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major order if a is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019 means to flatten a in the order the elements occur in memory. The default is \u2018C\u2019.", "A copy of the input array, flattened to one dimension.", "See also", "Return a flattened array.", "A 1-D flat iterator over the array."]}, {"name": "char.chararray.getfield()", "path": "reference/generated/numpy.char.chararray.getfield", "type": "numpy.char.chararray.getfield", "text": ["method", "Returns a field of the given array as a certain type.", "A field is a view of the array data with a given data-type. The values in the view are determined by the given type and the offset into the current array in bytes. The offset needs to be such that the view dtype fits in the array dtype; for example an array of dtype complex128 has 16-byte elements. If taking a view with a 32-bit integer (4 bytes), the offset needs to be between 0 and 12 bytes.", "The data type of the view. The dtype size of the view can not be larger than that of the array itself.", "Number of bytes to skip before beginning the element view.", "By choosing an offset of 8 bytes we can select the complex part of the array for our view:"]}, {"name": "char.chararray.imag", "path": "reference/generated/numpy.char.chararray.imag", "type": "String operations", "text": ["attribute", "The imaginary part of the array."]}, {"name": "char.chararray.index()", "path": "reference/generated/numpy.char.chararray.index", "type": "numpy.char.chararray.index", "text": ["method", "Like find, but raises ValueError when the substring is not found.", "See also"]}, {"name": "char.chararray.isalnum()", "path": "reference/generated/numpy.char.chararray.isalnum", "type": "numpy.char.chararray.isalnum", "text": ["method", "Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.", "See also"]}, {"name": "char.chararray.isalpha()", "path": "reference/generated/numpy.char.chararray.isalpha", "type": "numpy.char.chararray.isalpha", "text": ["method", "Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise.", "See also"]}, {"name": "char.chararray.isdecimal()", "path": "reference/generated/numpy.char.chararray.isdecimal", "type": "numpy.char.chararray.isdecimal", "text": ["method", "For each element in self, return True if there are only decimal characters in the element.", "See also"]}, {"name": "char.chararray.isdigit()", "path": "reference/generated/numpy.char.chararray.isdigit", "type": "numpy.char.chararray.isdigit", "text": ["method", "Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.", "See also"]}, {"name": "char.chararray.islower()", "path": "reference/generated/numpy.char.chararray.islower", "type": "numpy.char.chararray.islower", "text": ["method", "Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise.", "See also"]}, {"name": "char.chararray.isnumeric()", "path": "reference/generated/numpy.char.chararray.isnumeric", "type": "numpy.char.chararray.isnumeric", "text": ["method", "For each element in self, return True if there are only numeric characters in the element.", "See also"]}, {"name": "char.chararray.isspace()", "path": "reference/generated/numpy.char.chararray.isspace", "type": "numpy.char.chararray.isspace", "text": ["method", "Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise.", "See also"]}, {"name": "char.chararray.istitle()", "path": "reference/generated/numpy.char.chararray.istitle", "type": "numpy.char.chararray.istitle", "text": ["method", "Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise.", "See also"]}, {"name": "char.chararray.isupper()", "path": "reference/generated/numpy.char.chararray.isupper", "type": "numpy.char.chararray.isupper", "text": ["method", "Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise.", "See also"]}, {"name": "char.chararray.item()", "path": "reference/generated/numpy.char.chararray.item", "type": "numpy.char.chararray.item", "text": ["method", "Copy an element of an array to a standard Python scalar and return it.", "A copy of the specified element of the array as a suitable Python scalar", "When the data type of a is longdouble or clongdouble, item() returns a scalar array object because there is no available Python scalar that would not lose information. Void arrays return a buffer object for item(), unless fields are defined, in which case a tuple is returned.", "item is very similar to a[args], except, instead of an array scalar, a standard Python scalar is returned. This can be useful for speeding up access to elements of the array and doing arithmetic on elements of the array using Python\u2019s optimized math."]}, {"name": "char.chararray.itemsize", "path": "reference/generated/numpy.char.chararray.itemsize", "type": "String operations", "text": ["attribute", "Length of one array element in bytes."]}, {"name": "char.chararray.join()", "path": "reference/generated/numpy.char.chararray.join", "type": "numpy.char.chararray.join", "text": ["method", "Return a string which is the concatenation of the strings in the sequence seq.", "See also"]}, {"name": "char.chararray.ljust()", "path": "reference/generated/numpy.char.chararray.ljust", "type": "numpy.char.chararray.ljust", "text": ["method", "Return an array with the elements of self left-justified in a string of length width.", "See also"]}, {"name": "char.chararray.lower()", "path": "reference/generated/numpy.char.chararray.lower", "type": "numpy.char.chararray.lower", "text": ["method", "Return an array with the elements of self converted to lowercase.", "See also"]}, {"name": "char.chararray.lstrip()", "path": "reference/generated/numpy.char.chararray.lstrip", "type": "numpy.char.chararray.lstrip", "text": ["method", "For each element in self, return a copy with the leading characters removed.", "See also"]}, {"name": "char.chararray.nbytes", "path": "reference/generated/numpy.char.chararray.nbytes", "type": "String operations", "text": ["attribute", "Total bytes consumed by the elements of the array.", "Does not include memory consumed by non-element attributes of the array object."]}, {"name": "char.chararray.ndim", "path": "reference/generated/numpy.char.chararray.ndim", "type": "String operations", "text": ["attribute", "Number of array dimensions."]}, {"name": "char.chararray.nonzero()", "path": "reference/generated/numpy.char.chararray.nonzero", "type": "numpy.char.chararray.nonzero", "text": ["method", "Return the indices of the elements that are non-zero.", "Refer to numpy.nonzero for full documentation.", "See also", "equivalent function"]}, {"name": "char.chararray.put()", "path": "reference/generated/numpy.char.chararray.put", "type": "numpy.char.chararray.put", "text": ["method", "Set a.flat[n] = values[n] for all n in indices.", "Refer to numpy.put for full documentation.", "See also", "equivalent function"]}, {"name": "char.chararray.ravel()", "path": "reference/generated/numpy.char.chararray.ravel", "type": "numpy.char.chararray.ravel", "text": ["method", "Return a flattened array.", "Refer to numpy.ravel for full documentation.", "See also", "equivalent function", "a flat iterator on the array."]}, {"name": "char.chararray.real", "path": "reference/generated/numpy.char.chararray.real", "type": "String operations", "text": ["attribute", "The real part of the array.", "See also", "equivalent function"]}, {"name": "char.chararray.repeat()", "path": "reference/generated/numpy.char.chararray.repeat", "type": "numpy.char.chararray.repeat", "text": ["method", "Repeat elements of an array.", "Refer to numpy.repeat for full documentation.", "See also", "equivalent function"]}, {"name": "char.chararray.replace()", "path": "reference/generated/numpy.char.chararray.replace", "type": "numpy.char.chararray.replace", "text": ["method", "For each element in self, return a copy of the string with all occurrences of substring old replaced by new.", "See also"]}, {"name": "char.chararray.reshape()", "path": "reference/generated/numpy.char.chararray.reshape", "type": "numpy.char.chararray.reshape", "text": ["method", "Returns an array containing the same data with a new shape.", "Refer to numpy.reshape for full documentation.", "See also", "equivalent function", "Unlike the free function numpy.reshape, this method on ndarray allows the elements of the shape parameter to be passed in as separate arguments. For example, a.reshape(10, 11) is equivalent to a.reshape((10, 11))."]}, {"name": "char.chararray.resize()", "path": "reference/generated/numpy.char.chararray.resize", "type": "numpy.char.chararray.resize", "text": ["method", "Change shape and size of array in-place.", "Shape of resized array.", "If False, reference count will not be checked. Default is True.", "If a does not own its own data or references or views to it exist, and the data memory must be changed. PyPy only: will always raise if the data memory must be changed, since there is no reliable way to determine if references or views to it exist.", "If the order keyword argument is specified. This behaviour is a bug in NumPy.", "See also", "Return a new array with the specified shape.", "This reallocates space for the data area if necessary.", "Only contiguous arrays (data elements consecutive in memory) can be resized.", "The purpose of the reference count check is to make sure you do not use this array as a buffer for another Python object and then reallocate the memory. However, reference counts can increase in other ways so if you are sure that you have not shared the memory for this array with another Python object, then you may safely set refcheck to False.", "Shrinking an array: array is flattened (in the order that the data are stored in memory), resized, and reshaped:", "Enlarging an array: as above, but missing entries are filled with zeros:", "Referencing an array prevents resizing\u2026", "Unless refcheck is False:"]}, {"name": "char.chararray.rfind()", "path": "reference/generated/numpy.char.chararray.rfind", "type": "numpy.char.chararray.rfind", "text": ["method", "For each element in self, return the highest index in the string where substring sub is found, such that sub is contained within [start, end].", "See also"]}, {"name": "char.chararray.rindex()", "path": "reference/generated/numpy.char.chararray.rindex", "type": "numpy.char.chararray.rindex", "text": ["method", "Like rfind, but raises ValueError when the substring sub is not found.", "See also"]}, {"name": "char.chararray.rjust()", "path": "reference/generated/numpy.char.chararray.rjust", "type": "numpy.char.chararray.rjust", "text": ["method", "Return an array with the elements of self right-justified in a string of length width.", "See also"]}, {"name": "char.chararray.rsplit()", "path": "reference/generated/numpy.char.chararray.rsplit", "type": "numpy.char.chararray.rsplit", "text": ["method", "For each element in self, return a list of the words in the string, using sep as the delimiter string.", "See also"]}, {"name": "char.chararray.rstrip()", "path": "reference/generated/numpy.char.chararray.rstrip", "type": "numpy.char.chararray.rstrip", "text": ["method", "For each element in self, return a copy with the trailing characters removed.", "See also"]}, {"name": "char.chararray.searchsorted()", "path": "reference/generated/numpy.char.chararray.searchsorted", "type": "numpy.char.chararray.searchsorted", "text": ["method", "Find indices where elements of v should be inserted in a to maintain order.", "For full documentation, see numpy.searchsorted", "See also", "equivalent function"]}, {"name": "char.chararray.setfield()", "path": "reference/generated/numpy.char.chararray.setfield", "type": "numpy.char.chararray.setfield", "text": ["method", "Put a value into a specified place in a field defined by a data-type.", "Place val into a\u2019s field defined by dtype and beginning offset bytes into the field.", "Value to be placed in field.", "Data-type of the field in which to place val.", "The number of bytes into the field at which to place val.", "See also"]}, {"name": "char.chararray.setflags()", "path": "reference/generated/numpy.char.chararray.setflags", "type": "numpy.char.chararray.setflags", "text": ["method", "Set array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY), respectively.", "These Boolean-valued flags affect how numpy interprets the memory area used by a (see Notes below). The ALIGNED flag can only be set to True if the data is actually aligned according to the type. The WRITEBACKIFCOPY and (deprecated) UPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be set to True if the array owns its own memory, or the ultimate owner of the memory exposes a writeable buffer interface, or is a string. (The exception for string is made so that unpickling can be done without copying memory.)", "Describes whether or not a can be written to.", "Describes whether or not a is aligned properly for its type.", "Describes whether or not a is a copy of another \u201cbase\u201d array.", "Array flags provide information about how the memory area used for the array is to be interpreted. There are 7 Boolean flags in use, only four of which can be changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.", "WRITEABLE (W) the data area can be written to;", "ALIGNED (A) the data and strides are aligned appropriately for the hardware (as determined by the compiler);", "UPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;", "WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by .base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the base array will be updated with the contents of this array.", "All flags can be accessed using the single (upper case) letter as well as the full name."]}, {"name": "char.chararray.shape", "path": "reference/generated/numpy.char.chararray.shape", "type": "String operations", "text": ["attribute", "Tuple of array dimensions.", "The shape property is usually used to get the current shape of an array, but may also be used to reshape the array in-place by assigning a tuple of array dimensions to it. As with numpy.reshape, one of the new shape dimensions can be -1, in which case its value is inferred from the size of the array and the remaining dimensions. Reshaping an array in-place will fail if a copy is required.", "See also", "similar function", "similar method"]}, {"name": "char.chararray.size", "path": "reference/generated/numpy.char.chararray.size", "type": "String operations", "text": ["attribute", "Number of elements in the array.", "Equal to np.prod(a.shape), i.e., the product of the array\u2019s dimensions.", "a.size returns a standard arbitrary precision Python integer. This may not be the case with other methods of obtaining the same value (like the suggested np.prod(a.shape), which returns an instance of np.int_), and may be relevant if the value is used further in calculations that may overflow a fixed size integer type."]}, {"name": "char.chararray.sort()", "path": "reference/generated/numpy.char.chararray.sort", "type": "numpy.char.chararray.sort", "text": ["method", "Sort an array in-place. Refer to numpy.sort for full documentation.", "Axis along which to sort. Default is -1, which means sort along the last axis.", "Sorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and \u2018mergesort\u2019 use timsort under the covers and, in general, the actual implementation will vary with datatype. The \u2018mergesort\u2019 option is retained for backwards compatibility.", "Changed in version 1.15.0: The \u2018stable\u2019 option was added.", "When a is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.", "See also", "Return a sorted copy of an array.", "Indirect sort.", "Indirect stable sort on multiple keys.", "Find elements in sorted array.", "Partial sort.", "See numpy.sort for notes on the different sorting algorithms.", "Use the order keyword to specify a field to use when sorting a structured array:"]}, {"name": "char.chararray.split()", "path": "reference/generated/numpy.char.chararray.split", "type": "numpy.char.chararray.split", "text": ["method", "For each element in self, return a list of the words in the string, using sep as the delimiter string.", "See also"]}, {"name": "char.chararray.splitlines()", "path": "reference/generated/numpy.char.chararray.splitlines", "type": "numpy.char.chararray.splitlines", "text": ["method", "For each element in self, return a list of the lines in the element, breaking at line boundaries.", "See also"]}, {"name": "char.chararray.squeeze()", "path": "reference/generated/numpy.char.chararray.squeeze", "type": "numpy.char.chararray.squeeze", "text": ["method", "Remove axes of length one from a.", "Refer to numpy.squeeze for full documentation.", "See also", "equivalent function"]}, {"name": "char.chararray.startswith()", "path": "reference/generated/numpy.char.chararray.startswith", "type": "numpy.char.chararray.startswith", "text": ["method", "Returns a boolean array which is True where the string element in self starts with prefix, otherwise False.", "See also"]}, {"name": "char.chararray.strides", "path": "reference/generated/numpy.char.chararray.strides", "type": "String operations", "text": ["attribute", "Tuple of bytes to step in each dimension when traversing an array.", "The byte offset of element (i[0], i[1], ..., i[n]) in an array a is:", "A more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file in the NumPy reference guide.", "See also", "Imagine an array of 32-bit integers (each 4 bytes):", "This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array x will be (20, 4)."]}, {"name": "char.chararray.strip()", "path": "reference/generated/numpy.char.chararray.strip", "type": "numpy.char.chararray.strip", "text": ["method", "For each element in self, return a copy with the leading and trailing characters removed.", "See also"]}, {"name": "char.chararray.swapaxes()", "path": "reference/generated/numpy.char.chararray.swapaxes", "type": "numpy.char.chararray.swapaxes", "text": ["method", "Return a view of the array with axis1 and axis2 interchanged.", "Refer to numpy.swapaxes for full documentation.", "See also", "equivalent function"]}, {"name": "char.chararray.swapcase()", "path": "reference/generated/numpy.char.chararray.swapcase", "type": "numpy.char.chararray.swapcase", "text": ["method", "For each element in self, return a copy of the string with uppercase characters converted to lowercase and vice versa.", "See also"]}, {"name": "char.chararray.T", "path": "reference/generated/numpy.char.chararray.t", "type": "String operations", "text": ["attribute", "The transposed array.", "Same as self.transpose().", "See also"]}, {"name": "char.chararray.take()", "path": "reference/generated/numpy.char.chararray.take", "type": "numpy.char.chararray.take", "text": ["method", "Return an array formed from the elements of a at the given indices.", "Refer to numpy.take for full documentation.", "See also", "equivalent function"]}, {"name": "char.chararray.title()", "path": "reference/generated/numpy.char.chararray.title", "type": "numpy.char.chararray.title", "text": ["method", "For each element in self, return a titlecased version of the string: words start with uppercase characters, all remaining cased characters are lowercase.", "See also"]}, {"name": "char.chararray.tobytes()", "path": "reference/generated/numpy.char.chararray.tobytes", "type": "String operations", "text": ["method", "Construct Python bytes containing the raw data bytes in the array.", "Constructs Python bytes showing a copy of the raw contents of data memory. The bytes object is produced in C-order by default. This behavior is controlled by the order parameter.", "New in version 1.9.0.", "Controls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. Default is \u2018C\u2019.", "Python bytes exhibiting a copy of a\u2019s raw data."]}, {"name": "char.chararray.tofile()", "path": "reference/generated/numpy.char.chararray.tofile", "type": "numpy.char.chararray.tofile", "text": ["method", "Write array to a file as text or binary (default).", "Data is always written in \u2018C\u2019 order, independent of the order of a. The data produced by this method can be recovered using the function fromfile().", "An open file object, or a string containing a filename.", "Changed in version 1.17.0: pathlib.Path objects are now accepted.", "Separator between array items for text output. If \u201c\u201d (empty), a binary file is written, equivalent to file.write(a.tobytes()).", "Format string for text file output. Each entry in the array is formatted to text by first converting it to the closest Python type, and then using \u201cformat\u201d % item.", "This is a convenience function for quick storage of array data. Information on endianness and precision is lost, so this method is not a good choice for files intended to archive data or transport data between machines with different endianness. Some of these problems can be overcome by outputting the data as text files, at the expense of speed and file size.", "When fid is a file object, array contents are directly written to the file, bypassing the file object\u2019s write method. As a result, tofile cannot be used with files objects supporting compression (e.g., GzipFile) or file-like objects that do not support fileno() (e.g., BytesIO)."]}, {"name": "char.chararray.tolist()", "path": "reference/generated/numpy.char.chararray.tolist", "type": "numpy.char.chararray.tolist", "text": ["method", "Return the array as an a.ndim-levels deep nested list of Python scalars.", "Return a copy of the array data as a (nested) Python list. Data items are converted to the nearest compatible builtin Python type, via the item function.", "If a.ndim is 0, then since the depth of the nested list is 0, it will not be a list at all, but a simple Python scalar.", "The possibly nested list of array elements.", "The array may be recreated via a = np.array(a.tolist()), although this may sometimes lose precision.", "For a 1D array, a.tolist() is almost the same as list(a), except that tolist changes numpy scalars to Python scalars:", "Additionally, for a 2D array, tolist applies recursively:", "The base case for this recursion is a 0D array:"]}, {"name": "char.chararray.tostring()", "path": "reference/generated/numpy.char.chararray.tostring", "type": "numpy.char.chararray.tostring", "text": ["method", "A compatibility alias for tobytes, with exactly the same behavior.", "Despite its name, it returns bytes not strs.", "Deprecated since version 1.19.0."]}, {"name": "char.chararray.translate()", "path": "reference/generated/numpy.char.chararray.translate", "type": "numpy.char.chararray.translate", "text": ["method", "For each element in self, return a copy of the string where all characters occurring in the optional argument deletechars are removed, and the remaining characters have been mapped through the given translation table.", "See also"]}, {"name": "char.chararray.transpose()", "path": "reference/generated/numpy.char.chararray.transpose", "type": "numpy.char.chararray.transpose", "text": ["method", "Returns a view of the array with axes transposed.", "For a 1-D array this has no effect, as a transposed vector is simply the same vector. To convert a 1-D array into a 2D column vector, an additional dimension must be added. np.atleast2d(a).T achieves this, as does a[:, np.newaxis]. For a 2-D array, this is a standard matrix transpose. For an n-D array, if axes are given, their order indicates how the axes are permuted (see Examples). If axes are not provided and a.shape = (i[0], i[1], ... i[n-2], i[n-1]), then a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0]).", "View of a, with axes suitably permuted.", "See also", "Equivalent function", "Array property returning the array transposed.", "Give a new shape to an array without changing its data."]}, {"name": "char.chararray.upper()", "path": "reference/generated/numpy.char.chararray.upper", "type": "numpy.char.chararray.upper", "text": ["method", "Return an array with the elements of self converted to uppercase.", "See also"]}, {"name": "char.chararray.view()", "path": "reference/generated/numpy.char.chararray.view", "type": "numpy.char.chararray.view", "text": ["method", "New view of array with the same data.", "Note", "Passing None for dtype is different from omitting the parameter, since the former invokes dtype(None) which is an alias for dtype('float_').", "Data-type descriptor of the returned view, e.g., float32 or int16. Omitting it results in the view having the same data-type as a. This argument can also be specified as an ndarray sub-class, which then specifies the type of the returned object (this is equivalent to setting the type parameter).", "Type of the returned view, e.g., ndarray or matrix. Again, omission of the parameter results in type preservation.", "a.view() is used two different ways:", "a.view(some_dtype) or a.view(dtype=some_dtype) constructs a view of the array\u2019s memory with a different data-type. This can cause a reinterpretation of the bytes of memory.", "a.view(ndarray_subclass) or a.view(type=ndarray_subclass) just returns an instance of ndarray_subclass that looks at the same array (same shape, dtype, etc.) This does not cause a reinterpretation of the memory.", "For a.view(some_dtype), if some_dtype has a different number of bytes per entry than the previous dtype (for example, converting a regular array to a structured array), then the behavior of the view cannot be predicted just from the superficial appearance of a (shown by print(a)). It also depends on exactly how a is stored in memory. Therefore if a is C-ordered versus fortran-ordered, versus defined as a slice or transpose, etc., the view may give different results.", "Viewing array data using a different type and dtype:", "Creating a view on a structured array so it can be used in calculations", "Making changes to the view changes the underlying array", "Using a view to convert an array to a recarray:", "Views share data:", "Views that change the dtype size (bytes per entry) should normally be avoided on arrays defined by slices, transposes, fortran-ordering, etc.:"]}, {"name": "char.chararray.zfill()", "path": "reference/generated/numpy.char.chararray.zfill", "type": "numpy.char.chararray.zfill", "text": ["method", "Return the numeric string left-filled with zeros in a string of length width.", "See also"]}, {"name": "char.compare_chararrays()", "path": "reference/generated/numpy.char.compare_chararrays", "type": "numpy.char.compare_chararrays", "text": ["Performs element-wise comparison of two string arrays using the comparison operator specified by cmp_op.", "Arrays to be compared.", "Type of comparison.", "If True, the spaces at the end of Strings are removed before the comparison.", "The output array of type Boolean with the same shape as a and b.", "If cmp_op is not valid.", "If at least one of a or b is a non-string array"]}, {"name": "char.count()", "path": "reference/generated/numpy.char.count", "type": "numpy.char.count", "text": ["Returns an array with the number of non-overlapping occurrences of substring sub in the range [start, end].", "Calls str.count element-wise.", "The substring to search for.", "Optional arguments start and end are interpreted as slice notation to specify the range in which to count.", "Output array of ints.", "See also"]}, {"name": "char.decode()", "path": "reference/generated/numpy.char.decode", "type": "numpy.char.decode", "text": ["Calls str.decode element-wise.", "The set of available codecs comes from the Python standard library, and may be extended at runtime. For more information, see the codecs module.", "The name of an encoding", "Specifies how to handle encoding errors", "See also", "The type of the result will depend on the encoding specified."]}, {"name": "char.encode()", "path": "reference/generated/numpy.char.encode", "type": "numpy.char.encode", "text": ["Calls str.encode element-wise.", "The set of available codecs comes from the Python standard library, and may be extended at runtime. For more information, see the codecs module.", "The name of an encoding", "Specifies how to handle encoding errors", "See also", "The type of the result will depend on the encoding specified."]}, {"name": "char.endswith()", "path": "reference/generated/numpy.char.endswith", "type": "numpy.char.endswith", "text": ["Returns a boolean array which is True where the string element in a ends with suffix, otherwise False.", "Calls str.endswith element-wise.", "With optional start, test beginning at that position. With optional end, stop comparing at that position.", "Outputs an array of bools.", "See also"]}, {"name": "char.equal()", "path": "reference/generated/numpy.char.equal", "type": "numpy.char.equal", "text": ["Return (x1 == x2) element-wise.", "Unlike numpy.equal, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.", "Input arrays of the same shape.", "Output array of bools.", "See also"]}, {"name": "char.expandtabs()", "path": "reference/generated/numpy.char.expandtabs", "type": "numpy.char.expandtabs", "text": ["Return a copy of each string element where all tab characters are replaced by one or more spaces.", "Calls str.expandtabs element-wise.", "Return a copy of each string element where all tab characters are replaced by one or more spaces, depending on the current column and the given tabsize. The column number is reset to zero after each newline occurring in the string. This doesn\u2019t understand other non-printing characters or escape sequences.", "Input array", "Replace tabs with tabsize number of spaces. If not given defaults to 8 spaces.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.find()", "path": "reference/generated/numpy.char.find", "type": "numpy.char.find", "text": ["For each element, return the lowest index in the string where substring sub is found.", "Calls str.find element-wise.", "For each element, return the lowest index in the string where substring sub is found, such that sub is contained in the range [start, end].", "Optional arguments start and end are interpreted as in slice notation.", "Output array of ints. Returns -1 if sub is not found.", "See also"]}, {"name": "char.greater()", "path": "reference/generated/numpy.char.greater", "type": "numpy.char.greater", "text": ["Return (x1 > x2) element-wise.", "Unlike numpy.greater, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.", "Input arrays of the same shape.", "Output array of bools.", "See also"]}, {"name": "char.greater_equal()", "path": "reference/generated/numpy.char.greater_equal", "type": "numpy.char.greater_equal", "text": ["Return (x1 >= x2) element-wise.", "Unlike numpy.greater_equal, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.", "Input arrays of the same shape.", "Output array of bools.", "See also"]}, {"name": "char.index()", "path": "reference/generated/numpy.char.index", "type": "numpy.char.index", "text": ["Like find, but raises ValueError when the substring is not found.", "Calls str.index element-wise.", "Output array of ints. Returns -1 if sub is not found.", "See also"]}, {"name": "char.isalnum()", "path": "reference/generated/numpy.char.isalnum", "type": "numpy.char.isalnum", "text": ["Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.", "Calls str.isalnum element-wise.", "For 8-bit strings, this method is locale-dependent.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.isalpha()", "path": "reference/generated/numpy.char.isalpha", "type": "numpy.char.isalpha", "text": ["Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise.", "Calls str.isalpha element-wise.", "For 8-bit strings, this method is locale-dependent.", "Output array of bools", "See also"]}, {"name": "char.isdecimal()", "path": "reference/generated/numpy.char.isdecimal", "type": "numpy.char.isdecimal", "text": ["For each element, return True if there are only decimal characters in the element.", "Calls unicode.isdecimal element-wise.", "Decimal characters include digit characters, and all characters that can be used to form decimal-radix numbers, e.g. U+0660, ARABIC-INDIC DIGIT ZERO.", "Input array.", "Array of booleans identical in shape to a.", "See also"]}, {"name": "char.isdigit()", "path": "reference/generated/numpy.char.isdigit", "type": "numpy.char.isdigit", "text": ["Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.", "Calls str.isdigit element-wise.", "For 8-bit strings, this method is locale-dependent.", "Output array of bools", "See also"]}, {"name": "char.islower()", "path": "reference/generated/numpy.char.islower", "type": "numpy.char.islower", "text": ["Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise.", "Calls str.islower element-wise.", "For 8-bit strings, this method is locale-dependent.", "Output array of bools", "See also"]}, {"name": "char.isnumeric()", "path": "reference/generated/numpy.char.isnumeric", "type": "numpy.char.isnumeric", "text": ["For each element, return True if there are only numeric characters in the element.", "Calls unicode.isnumeric element-wise.", "Numeric characters include digit characters, and all characters that have the Unicode numeric value property, e.g. U+2155,\nVULGAR FRACTION ONE FIFTH.", "Input array.", "Array of booleans of same shape as a.", "See also"]}, {"name": "char.isspace()", "path": "reference/generated/numpy.char.isspace", "type": "numpy.char.isspace", "text": ["Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise.", "Calls str.isspace element-wise.", "For 8-bit strings, this method is locale-dependent.", "Output array of bools", "See also"]}, {"name": "char.istitle()", "path": "reference/generated/numpy.char.istitle", "type": "numpy.char.istitle", "text": ["Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise.", "Call str.istitle element-wise.", "For 8-bit strings, this method is locale-dependent.", "Output array of bools", "See also"]}, {"name": "char.isupper()", "path": "reference/generated/numpy.char.isupper", "type": "numpy.char.isupper", "text": ["Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise.", "Call str.isupper element-wise.", "For 8-bit strings, this method is locale-dependent.", "Output array of bools", "See also"]}, {"name": "char.join()", "path": "reference/generated/numpy.char.join", "type": "numpy.char.join", "text": ["Return a string which is the concatenation of the strings in the sequence seq.", "Calls str.join element-wise.", "Output array of str or unicode, depending on input types", "See also"]}, {"name": "char.less()", "path": "reference/generated/numpy.char.less", "type": "numpy.char.less", "text": ["Return (x1 < x2) element-wise.", "Unlike numpy.greater, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.", "Input arrays of the same shape.", "Output array of bools.", "See also"]}, {"name": "char.less_equal()", "path": "reference/generated/numpy.char.less_equal", "type": "numpy.char.less_equal", "text": ["Return (x1 <= x2) element-wise.", "Unlike numpy.less_equal, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.", "Input arrays of the same shape.", "Output array of bools.", "See also"]}, {"name": "char.ljust()", "path": "reference/generated/numpy.char.ljust", "type": "numpy.char.ljust", "text": ["Return an array with the elements of a left-justified in a string of length width.", "Calls str.ljust element-wise.", "The length of the resulting strings", "The character to use for padding", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.lower()", "path": "reference/generated/numpy.char.lower", "type": "numpy.char.lower", "text": ["Return an array with the elements converted to lowercase.", "Call str.lower element-wise.", "For 8-bit strings, this method is locale-dependent.", "Input array.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.lstrip()", "path": "reference/generated/numpy.char.lstrip", "type": "numpy.char.lstrip", "text": ["For each element in a, return a copy with the leading characters removed.", "Calls str.lstrip element-wise.", "Input array.", "The chars argument is a string specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The chars argument is not a prefix; rather, all combinations of its values are stripped.", "Output array of str or unicode, depending on input type", "See also", "The \u2018a\u2019 variable is unstripped from c[1] because whitespace leading."]}, {"name": "char.mod()", "path": "reference/generated/numpy.char.mod", "type": "numpy.char.mod", "text": ["Return (a % i), that is pre-Python 2.6 string formatting (interpolation), element-wise for a pair of array_likes of str or unicode.", "These values will be element-wise interpolated into the string.", "Output array of str or unicode, depending on input types", "See also"]}, {"name": "char.multiply()", "path": "reference/generated/numpy.char.multiply", "type": "numpy.char.multiply", "text": ["Return (a * i), that is string multiple concatenation, element-wise.", "Values in i of less than 0 are treated as 0 (which yields an empty string).", "Output array of str or unicode, depending on input types"]}, {"name": "char.not_equal()", "path": "reference/generated/numpy.char.not_equal", "type": "numpy.char.not_equal", "text": ["Return (x1 != x2) element-wise.", "Unlike numpy.not_equal, this comparison is performed by first stripping whitespace characters from the end of the string. This behavior is provided for backward-compatibility with numarray.", "Input arrays of the same shape.", "Output array of bools.", "See also"]}, {"name": "char.partition()", "path": "reference/generated/numpy.char.partition", "type": "numpy.char.partition", "text": ["Partition each element in a around sep.", "Calls str.partition element-wise.", "For each element in a, split the element as the first occurrence of sep, and return 3 strings containing the part before the separator, the separator itself, and the part after the separator. If the separator is not found, return 3 strings containing the string itself, followed by two empty strings.", "Input array", "Separator to split each string element in a.", "Output array of str or unicode, depending on input type. The output array will have an extra dimension with 3 elements per input element.", "See also"]}, {"name": "char.replace()", "path": "reference/generated/numpy.char.replace", "type": "numpy.char.replace", "text": ["For each element in a, return a copy of the string with all occurrences of substring old replaced by new.", "Calls str.replace element-wise.", "If the optional argument count is given, only the first count occurrences are replaced.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.rfind()", "path": "reference/generated/numpy.char.rfind", "type": "numpy.char.rfind", "text": ["For each element in a, return the highest index in the string where substring sub is found, such that sub is contained within [start, end].", "Calls str.rfind element-wise.", "Optional arguments start and end are interpreted as in slice notation.", "Output array of ints. Return -1 on failure.", "See also"]}, {"name": "char.rindex()", "path": "reference/generated/numpy.char.rindex", "type": "numpy.char.rindex", "text": ["Like rfind, but raises ValueError when the substring sub is not found.", "Calls str.rindex element-wise.", "Output array of ints.", "See also"]}, {"name": "char.rjust()", "path": "reference/generated/numpy.char.rjust", "type": "numpy.char.rjust", "text": ["Return an array with the elements of a right-justified in a string of length width.", "Calls str.rjust element-wise.", "The length of the resulting strings", "The character to use for padding", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.rpartition()", "path": "reference/generated/numpy.char.rpartition", "type": "numpy.char.rpartition", "text": ["Partition (split) each element around the right-most separator.", "Calls str.rpartition element-wise.", "For each element in a, split the element as the last occurrence of sep, and return 3 strings containing the part before the separator, the separator itself, and the part after the separator. If the separator is not found, return 3 strings containing the string itself, followed by two empty strings.", "Input array", "Right-most separator to split each element in array.", "Output array of string or unicode, depending on input type. The output array will have an extra dimension with 3 elements per input element.", "See also"]}, {"name": "char.rsplit()", "path": "reference/generated/numpy.char.rsplit", "type": "numpy.char.rsplit", "text": ["For each element in a, return a list of the words in the string, using sep as the delimiter string.", "Calls str.rsplit element-wise.", "Except for splitting from the right, rsplit behaves like split.", "If sep is not specified or None, any whitespace string is a separator.", "If maxsplit is given, at most maxsplit splits are done, the rightmost ones.", "Array of list objects", "See also"]}, {"name": "char.rstrip()", "path": "reference/generated/numpy.char.rstrip", "type": "numpy.char.rstrip", "text": ["For each element in a, return a copy with the trailing characters removed.", "Calls str.rstrip element-wise.", "The chars argument is a string specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The chars argument is not a suffix; rather, all combinations of its values are stripped.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.split()", "path": "reference/generated/numpy.char.split", "type": "numpy.char.split", "text": ["For each element in a, return a list of the words in the string, using sep as the delimiter string.", "Calls str.split element-wise.", "If sep is not specified or None, any whitespace string is a separator.", "If maxsplit is given, at most maxsplit splits are done.", "Array of list objects", "See also"]}, {"name": "char.splitlines()", "path": "reference/generated/numpy.char.splitlines", "type": "numpy.char.splitlines", "text": ["For each element in a, return a list of the lines in the element, breaking at line boundaries.", "Calls str.splitlines element-wise.", "Line breaks are not included in the resulting list unless keepends is given and true.", "Array of list objects", "See also"]}, {"name": "char.startswith()", "path": "reference/generated/numpy.char.startswith", "type": "numpy.char.startswith", "text": ["Returns a boolean array which is True where the string element in a starts with prefix, otherwise False.", "Calls str.startswith element-wise.", "With optional start, test beginning at that position. With optional end, stop comparing at that position.", "Array of booleans", "See also"]}, {"name": "char.str_len()", "path": "reference/generated/numpy.char.str_len", "type": "numpy.char.str_len", "text": ["Return len(a) element-wise.", "Output array of integers", "See also"]}, {"name": "char.strip()", "path": "reference/generated/numpy.char.strip", "type": "numpy.char.strip", "text": ["For each element in a, return a copy with the leading and trailing characters removed.", "Calls str.strip element-wise.", "The chars argument is a string specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.swapcase()", "path": "reference/generated/numpy.char.swapcase", "type": "numpy.char.swapcase", "text": ["Return element-wise a copy of the string with uppercase characters converted to lowercase and vice versa.", "Calls str.swapcase element-wise.", "For 8-bit strings, this method is locale-dependent.", "Input array.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.title()", "path": "reference/generated/numpy.char.title", "type": "numpy.char.title", "text": ["Return element-wise title cased version of string or unicode.", "Title case words start with uppercase characters, all remaining cased characters are lowercase.", "Calls str.title element-wise.", "For 8-bit strings, this method is locale-dependent.", "Input array.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.translate()", "path": "reference/generated/numpy.char.translate", "type": "numpy.char.translate", "text": ["For each element in a, return a copy of the string where all characters occurring in the optional argument deletechars are removed, and the remaining characters have been mapped through the given translation table.", "Calls str.translate element-wise.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.upper()", "path": "reference/generated/numpy.char.upper", "type": "numpy.char.upper", "text": ["Return an array with the elements converted to uppercase.", "Calls str.upper element-wise.", "For 8-bit strings, this method is locale-dependent.", "Input array.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "char.zfill()", "path": "reference/generated/numpy.char.zfill", "type": "numpy.char.zfill", "text": ["Return the numeric string left-filled with zeros", "Calls str.zfill element-wise.", "Input array.", "Width of string to left-fill elements in a.", "Output array of str or unicode, depending on input type", "See also"]}, {"name": "chararray.argsort()", "path": "reference/generated/numpy.chararray.argsort", "type": "numpy.chararray.argsort", "text": ["method", "Returns the indices that would sort this array.", "Refer to numpy.argsort for full documentation.", "See also", "equivalent function"]}, {"name": "chararray.astype()", "path": "reference/generated/numpy.chararray.astype", "type": "numpy.chararray.astype", "text": ["method", "Copy of the array, cast to a specified type.", "Typecode or data-type to which the array is cast.", "Controls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means Fortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous, \u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements appear in memory as possible. Default is \u2018K\u2019.", "Controls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for backwards compatibility.", "If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.", "By default, astype always returns a newly allocated array. If this is set to false, and the dtype, order, and subok requirements are satisfied, the input array is returned instead of a copy.", "Unless copy is False and the other conditions for returning the input array are satisfied (see description for copy input parameter), arr_t is a new array of the same shape as the input array, with dtype, order given by dtype, order.", "When casting from complex to float or int. To avoid this, one should use a.real.astype(t).", "Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is allowed, but casting from multiple fields is not.", "Changed in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019 casting mode requires that the string dtype length is long enough to store the max integer/float value converted."]}, {"name": "chararray.base", "path": "reference/generated/numpy.chararray.base", "type": "String operations", "text": ["attribute", "Base object if memory is from some other object.", "The base of an array that owns its memory is None:", "Slicing creates a view, whose memory is shared with x:"]}, {"name": "chararray.copy()", "path": "reference/generated/numpy.chararray.copy", "type": "numpy.chararray.copy", "text": ["method", "Return a copy of the array.", "Controls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of a as closely as possible. (Note that this function and numpy.copy are very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)", "See also", "Similar function with different default behavior", "This function is the preferred method for creating an array copy. The function numpy.copy is similar, but it defaults to using order \u2018K\u2019, and will not pass sub-classes through by default."]}, {"name": "chararray.count()", "path": "reference/generated/numpy.chararray.count", "type": "numpy.chararray.count", "text": ["method", "Returns an array with the number of non-overlapping occurrences of substring sub in the range [start, end].", "See also"]}, {"name": "chararray.ctypes", "path": "reference/generated/numpy.chararray.ctypes", "type": "String operations", "text": ["attribute", "An object to simplify the interaction of the array with the ctypes module.", "This attribute creates an object that makes it easier to use arrays when calling shared libraries with the ctypes module. The returned object has, among others, data, shape, and strides attributes (see Notes below) which themselves return ctypes objects that can be used as arguments to a shared library.", "Possessing attributes data, shape, strides, etc.", "See also", "Below are the public attributes of this object which were documented in \u201cGuide to NumPy\u201d (we have omitted undocumented public attributes, as well as documented private attributes):", "A pointer to the memory area of the array as a Python integer. This memory area may contain data that is not aligned, or not in correct byte-order. The memory area may not even be writeable. The array flags and data-type of this array should be respected when passing this attribute to arbitrary C-code to avoid trouble that can include Python crashing. User Beware! The value of this attribute is exactly the same as self._array_interface_['data'][0].", "Note that unlike data_as, a reference will not be kept to the array: code like ctypes.c_void_p((a + b).ctypes.data) will result in a pointer to a deallocated array, and should be spelt (a + b).ctypes.data_as(ctypes.c_void_p)", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the C-integer corresponding to dtype('p') on this platform (see c_intp). This base-type could be ctypes.c_int, ctypes.c_long, or ctypes.c_longlong depending on the platform. The ctypes array contains the shape of the underlying array.", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the same as for the shape attribute. This ctypes array contains the strides information from the underlying array. This strides information is important for showing how many bytes must be jumped to get to the next element in the array.", "Return the data pointer cast to a particular c-types object. For example, calling self._as_parameter_ is equivalent to self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a pointer to a ctypes array of floating-point data: self.data_as(ctypes.POINTER(ctypes.c_double)).", "The returned pointer will keep a reference to the array.", "Return the shape tuple as an array of some other c-types type. For example: self.shape_as(ctypes.c_short).", "Return the strides tuple as an array of some other c-types type. For example: self.strides_as(ctypes.c_longlong).", "If the ctypes module is not available, then the ctypes attribute of array objects still returns something useful, but ctypes objects are not returned and errors may be raised instead. In particular, the object will still have the as_parameter attribute which will return an integer equal to the data attribute."]}, {"name": "chararray.data", "path": "reference/generated/numpy.chararray.data", "type": "String operations", "text": ["attribute", "Python buffer object pointing to the start of the array\u2019s data."]}, {"name": "chararray.decode()", "path": "reference/generated/numpy.chararray.decode", "type": "numpy.chararray.decode", "text": ["method", "Calls str.decode element-wise.", "See also"]}, {"name": "chararray.dump()", "path": "reference/generated/numpy.chararray.dump", "type": "numpy.chararray.dump", "text": ["method", "Dump a pickle of the array to the specified file. The array can be read back with pickle.load or numpy.load.", "A string naming the dump file.", "Changed in version 1.17.0: pathlib.Path objects are now accepted."]}, {"name": "chararray.dumps()", "path": "reference/generated/numpy.chararray.dumps", "type": "numpy.chararray.dumps", "text": ["method", "Returns the pickle of the array as a string. pickle.loads will convert the string back to an array."]}, {"name": "chararray.encode()", "path": "reference/generated/numpy.chararray.encode", "type": "numpy.chararray.encode", "text": ["method", "Calls str.encode element-wise.", "See also"]}, {"name": "chararray.endswith()", "path": "reference/generated/numpy.chararray.endswith", "type": "numpy.chararray.endswith", "text": ["method", "Returns a boolean array which is True where the string element in self ends with suffix, otherwise False.", "See also"]}, {"name": "chararray.expandtabs()", "path": "reference/generated/numpy.chararray.expandtabs", "type": "numpy.chararray.expandtabs", "text": ["method", "Return a copy of each string element where all tab characters are replaced by one or more spaces.", "See also"]}, {"name": "chararray.fill()", "path": "reference/generated/numpy.chararray.fill", "type": "numpy.chararray.fill", "text": ["method", "Fill the array with a scalar value.", "All elements of a will be assigned this value."]}, {"name": "chararray.find()", "path": "reference/generated/numpy.chararray.find", "type": "numpy.chararray.find", "text": ["method", "For each element, return the lowest index in the string where substring sub is found.", "See also"]}, {"name": "chararray.flags", "path": "reference/generated/numpy.chararray.flags", "type": "String operations", "text": ["attribute", "Information about the memory layout of the array.", "The flags object can be accessed dictionary-like (as in a.flags['WRITEABLE']), or by using lowercased attribute names (as in a.flags.writeable). Short flag names are only supported in dictionary access.", "Only the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by the user, via direct assignment to the attribute or dictionary entry, or by calling ndarray.setflags.", "The array flags cannot be set arbitrarily:", "Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.", "Even for contiguous arrays a stride for a given dimension arr.strides[dim] may be arbitrary if arr.shape[dim] == 1 or the array has no elements. It does not generally hold that self.strides[-1] == self.itemsize for C-style contiguous arrays or self.strides[0] == self.itemsize for Fortran-style contiguous arrays is true.", "The data is in a single, C-style contiguous segment.", "The data is in a single, Fortran-style contiguous segment.", "The array owns the memory it uses or borrows it from another object.", "The data area can be written to. Setting this to False locks the data, making it read-only. A view (slice, etc.) inherits WRITEABLE from its base array at creation time, but a view of a writeable array may be subsequently locked while the base array remains writeable. (The opposite is not true, in that a view of a locked array may not be made writeable. However, currently, locking a base object does not lock any views that already reference it, so under that circumstance it is possible to alter the contents of a locked array via a previously created writeable view onto it.) Attempting to change a non-writeable array raises a RuntimeError exception.", "The data and all elements are aligned appropriately for the hardware.", "This array is a copy of some other array. The C-API function PyArray_ResolveWritebackIfCopy must be called before deallocating to the base array will be updated with the contents of this array.", "(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array. When this array is deallocated, the base array will be updated with the contents of this array.", "F_CONTIGUOUS and not C_CONTIGUOUS.", "F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).", "ALIGNED and WRITEABLE.", "BEHAVED and C_CONTIGUOUS.", "BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS."]}, {"name": "chararray.flat", "path": "reference/generated/numpy.chararray.flat", "type": "String operations", "text": ["attribute", "A 1-D iterator over the array.", "This is a numpy.flatiter instance, which acts similarly to, but is not a subclass of, Python\u2019s built-in iterator object.", "See also", "Return a copy of the array collapsed into one dimension.", "An assignment example:"]}, {"name": "chararray.flatten()", "path": "reference/generated/numpy.chararray.flatten", "type": "numpy.chararray.flatten", "text": ["method", "Return a copy of the array collapsed into one dimension.", "\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in column-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major order if a is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019 means to flatten a in the order the elements occur in memory. The default is \u2018C\u2019.", "A copy of the input array, flattened to one dimension.", "See also", "Return a flattened array.", "A 1-D flat iterator over the array."]}, {"name": "chararray.getfield()", "path": "reference/generated/numpy.chararray.getfield", "type": "numpy.chararray.getfield", "text": ["method", "Returns a field of the given array as a certain type.", "A field is a view of the array data with a given data-type. The values in the view are determined by the given type and the offset into the current array in bytes. The offset needs to be such that the view dtype fits in the array dtype; for example an array of dtype complex128 has 16-byte elements. If taking a view with a 32-bit integer (4 bytes), the offset needs to be between 0 and 12 bytes.", "The data type of the view. The dtype size of the view can not be larger than that of the array itself.", "Number of bytes to skip before beginning the element view.", "By choosing an offset of 8 bytes we can select the complex part of the array for our view:"]}, {"name": "chararray.index()", "path": "reference/generated/numpy.chararray.index", "type": "numpy.chararray.index", "text": ["method", "Like find, but raises ValueError when the substring is not found.", "See also"]}, {"name": "chararray.isalnum()", "path": "reference/generated/numpy.chararray.isalnum", "type": "numpy.chararray.isalnum", "text": ["method", "Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise.", "See also"]}, {"name": "chararray.isalpha()", "path": "reference/generated/numpy.chararray.isalpha", "type": "numpy.chararray.isalpha", "text": ["method", "Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise.", "See also"]}, {"name": "chararray.isdecimal()", "path": "reference/generated/numpy.chararray.isdecimal", "type": "numpy.chararray.isdecimal", "text": ["method", "For each element in self, return True if there are only decimal characters in the element.", "See also"]}, {"name": "chararray.isdigit()", "path": "reference/generated/numpy.chararray.isdigit", "type": "numpy.chararray.isdigit", "text": ["method", "Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise.", "See also"]}, {"name": "chararray.islower()", "path": "reference/generated/numpy.chararray.islower", "type": "numpy.chararray.islower", "text": ["method", "Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise.", "See also"]}, {"name": "chararray.isnumeric()", "path": "reference/generated/numpy.chararray.isnumeric", "type": "numpy.chararray.isnumeric", "text": ["method", "For each element in self, return True if there are only numeric characters in the element.", "See also"]}, {"name": "chararray.isspace()", "path": "reference/generated/numpy.chararray.isspace", "type": "numpy.chararray.isspace", "text": ["method", "Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise.", "See also"]}, {"name": "chararray.istitle()", "path": "reference/generated/numpy.chararray.istitle", "type": "numpy.chararray.istitle", "text": ["method", "Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise.", "See also"]}, {"name": "chararray.isupper()", "path": "reference/generated/numpy.chararray.isupper", "type": "numpy.chararray.isupper", "text": ["method", "Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise.", "See also"]}, {"name": "chararray.item()", "path": "reference/generated/numpy.chararray.item", "type": "numpy.chararray.item", "text": ["method", "Copy an element of an array to a standard Python scalar and return it.", "A copy of the specified element of the array as a suitable Python scalar", "When the data type of a is longdouble or clongdouble, item() returns a scalar array object because there is no available Python scalar that would not lose information. Void arrays return a buffer object for item(), unless fields are defined, in which case a tuple is returned.", "item is very similar to a[args], except, instead of an array scalar, a standard Python scalar is returned. This can be useful for speeding up access to elements of the array and doing arithmetic on elements of the array using Python\u2019s optimized math."]}, {"name": "chararray.itemsize", "path": "reference/generated/numpy.chararray.itemsize", "type": "String operations", "text": ["attribute", "Length of one array element in bytes."]}, {"name": "chararray.join()", "path": "reference/generated/numpy.chararray.join", "type": "numpy.chararray.join", "text": ["method", "Return a string which is the concatenation of the strings in the sequence seq.", "See also"]}, {"name": "chararray.ljust()", "path": "reference/generated/numpy.chararray.ljust", "type": "numpy.chararray.ljust", "text": ["method", "Return an array with the elements of self left-justified in a string of length width.", "See also"]}, {"name": "chararray.lower()", "path": "reference/generated/numpy.chararray.lower", "type": "numpy.chararray.lower", "text": ["method", "Return an array with the elements of self converted to lowercase.", "See also"]}, {"name": "chararray.lstrip()", "path": "reference/generated/numpy.chararray.lstrip", "type": "numpy.chararray.lstrip", "text": ["method", "For each element in self, return a copy with the leading characters removed.", "See also"]}, {"name": "chararray.nbytes", "path": "reference/generated/numpy.chararray.nbytes", "type": "String operations", "text": ["attribute", "Total bytes consumed by the elements of the array.", "Does not include memory consumed by non-element attributes of the array object."]}, {"name": "chararray.ndim", "path": "reference/generated/numpy.chararray.ndim", "type": "String operations", "text": ["attribute", "Number of array dimensions."]}, {"name": "chararray.nonzero()", "path": "reference/generated/numpy.chararray.nonzero", "type": "numpy.chararray.nonzero", "text": ["method", "Return the indices of the elements that are non-zero.", "Refer to numpy.nonzero for full documentation.", "See also", "equivalent function"]}, {"name": "chararray.put()", "path": "reference/generated/numpy.chararray.put", "type": "numpy.chararray.put", "text": ["method", "Set a.flat[n] = values[n] for all n in indices.", "Refer to numpy.put for full documentation.", "See also", "equivalent function"]}, {"name": "chararray.ravel()", "path": "reference/generated/numpy.chararray.ravel", "type": "numpy.chararray.ravel", "text": ["method", "Return a flattened array.", "Refer to numpy.ravel for full documentation.", "See also", "equivalent function", "a flat iterator on the array."]}, {"name": "chararray.repeat()", "path": "reference/generated/numpy.chararray.repeat", "type": "numpy.chararray.repeat", "text": ["method", "Repeat elements of an array.", "Refer to numpy.repeat for full documentation.", "See also", "equivalent function"]}, {"name": "chararray.replace()", "path": "reference/generated/numpy.chararray.replace", "type": "numpy.chararray.replace", "text": ["method", "For each element in self, return a copy of the string with all occurrences of substring old replaced by new.", "See also"]}, {"name": "chararray.reshape()", "path": "reference/generated/numpy.chararray.reshape", "type": "numpy.chararray.reshape", "text": ["method", "Returns an array containing the same data with a new shape.", "Refer to numpy.reshape for full documentation.", "See also", "equivalent function", "Unlike the free function numpy.reshape, this method on ndarray allows the elements of the shape parameter to be passed in as separate arguments. For example, a.reshape(10, 11) is equivalent to a.reshape((10, 11))."]}, {"name": "chararray.resize()", "path": "reference/generated/numpy.chararray.resize", "type": "numpy.chararray.resize", "text": ["method", "Change shape and size of array in-place.", "Shape of resized array.", "If False, reference count will not be checked. Default is True.", "If a does not own its own data or references or views to it exist, and the data memory must be changed. PyPy only: will always raise if the data memory must be changed, since there is no reliable way to determine if references or views to it exist.", "If the order keyword argument is specified. This behaviour is a bug in NumPy.", "See also", "Return a new array with the specified shape.", "This reallocates space for the data area if necessary.", "Only contiguous arrays (data elements consecutive in memory) can be resized.", "The purpose of the reference count check is to make sure you do not use this array as a buffer for another Python object and then reallocate the memory. However, reference counts can increase in other ways so if you are sure that you have not shared the memory for this array with another Python object, then you may safely set refcheck to False.", "Shrinking an array: array is flattened (in the order that the data are stored in memory), resized, and reshaped:", "Enlarging an array: as above, but missing entries are filled with zeros:", "Referencing an array prevents resizing\u2026", "Unless refcheck is False:"]}, {"name": "chararray.rfind()", "path": "reference/generated/numpy.chararray.rfind", "type": "numpy.chararray.rfind", "text": ["method", "For each element in self, return the highest index in the string where substring sub is found, such that sub is contained within [start, end].", "See also"]}, {"name": "chararray.rindex()", "path": "reference/generated/numpy.chararray.rindex", "type": "numpy.chararray.rindex", "text": ["method", "Like rfind, but raises ValueError when the substring sub is not found.", "See also"]}, {"name": "chararray.rjust()", "path": "reference/generated/numpy.chararray.rjust", "type": "numpy.chararray.rjust", "text": ["method", "Return an array with the elements of self right-justified in a string of length width.", "See also"]}, {"name": "chararray.rsplit()", "path": "reference/generated/numpy.chararray.rsplit", "type": "numpy.chararray.rsplit", "text": ["method", "For each element in self, return a list of the words in the string, using sep as the delimiter string.", "See also"]}, {"name": "chararray.rstrip()", "path": "reference/generated/numpy.chararray.rstrip", "type": "numpy.chararray.rstrip", "text": ["method", "For each element in self, return a copy with the trailing characters removed.", "See also"]}, {"name": "chararray.searchsorted()", "path": "reference/generated/numpy.chararray.searchsorted", "type": "numpy.chararray.searchsorted", "text": ["method", "Find indices where elements of v should be inserted in a to maintain order.", "For full documentation, see numpy.searchsorted", "See also", "equivalent function"]}, {"name": "chararray.setfield()", "path": "reference/generated/numpy.chararray.setfield", "type": "numpy.chararray.setfield", "text": ["method", "Put a value into a specified place in a field defined by a data-type.", "Place val into a\u2019s field defined by dtype and beginning offset bytes into the field.", "Value to be placed in field.", "Data-type of the field in which to place val.", "The number of bytes into the field at which to place val.", "See also"]}, {"name": "chararray.setflags()", "path": "reference/generated/numpy.chararray.setflags", "type": "numpy.chararray.setflags", "text": ["method", "Set array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY), respectively.", "These Boolean-valued flags affect how numpy interprets the memory area used by a (see Notes below). The ALIGNED flag can only be set to True if the data is actually aligned according to the type. The WRITEBACKIFCOPY and (deprecated) UPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be set to True if the array owns its own memory, or the ultimate owner of the memory exposes a writeable buffer interface, or is a string. (The exception for string is made so that unpickling can be done without copying memory.)", "Describes whether or not a can be written to.", "Describes whether or not a is aligned properly for its type.", "Describes whether or not a is a copy of another \u201cbase\u201d array.", "Array flags provide information about how the memory area used for the array is to be interpreted. There are 7 Boolean flags in use, only four of which can be changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.", "WRITEABLE (W) the data area can be written to;", "ALIGNED (A) the data and strides are aligned appropriately for the hardware (as determined by the compiler);", "UPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;", "WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by .base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the base array will be updated with the contents of this array.", "All flags can be accessed using the single (upper case) letter as well as the full name."]}, {"name": "chararray.size", "path": "reference/generated/numpy.chararray.size", "type": "String operations", "text": ["attribute", "Number of elements in the array.", "Equal to np.prod(a.shape), i.e., the product of the array\u2019s dimensions.", "a.size returns a standard arbitrary precision Python integer. This may not be the case with other methods of obtaining the same value (like the suggested np.prod(a.shape), which returns an instance of np.int_), and may be relevant if the value is used further in calculations that may overflow a fixed size integer type."]}, {"name": "chararray.sort()", "path": "reference/generated/numpy.chararray.sort", "type": "numpy.chararray.sort", "text": ["method", "Sort an array in-place. Refer to numpy.sort for full documentation.", "Axis along which to sort. Default is -1, which means sort along the last axis.", "Sorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and \u2018mergesort\u2019 use timsort under the covers and, in general, the actual implementation will vary with datatype. The \u2018mergesort\u2019 option is retained for backwards compatibility.", "Changed in version 1.15.0: The \u2018stable\u2019 option was added.", "When a is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties.", "See also", "Return a sorted copy of an array.", "Indirect sort.", "Indirect stable sort on multiple keys.", "Find elements in sorted array.", "Partial sort.", "See numpy.sort for notes on the different sorting algorithms.", "Use the order keyword to specify a field to use when sorting a structured array:"]}, {"name": "chararray.split()", "path": "reference/generated/numpy.chararray.split", "type": "numpy.chararray.split", "text": ["method", "For each element in self, return a list of the words in the string, using sep as the delimiter string.", "See also"]}, {"name": "chararray.splitlines()", "path": "reference/generated/numpy.chararray.splitlines", "type": "numpy.chararray.splitlines", "text": ["method", "For each element in self, return a list of the lines in the element, breaking at line boundaries.", "See also"]}, {"name": "chararray.squeeze()", "path": "reference/generated/numpy.chararray.squeeze", "type": "numpy.chararray.squeeze", "text": ["method", "Remove axes of length one from a.", "Refer to numpy.squeeze for full documentation.", "See also", "equivalent function"]}, {"name": "chararray.startswith()", "path": "reference/generated/numpy.chararray.startswith", "type": "numpy.chararray.startswith", "text": ["method", "Returns a boolean array which is True where the string element in self starts with prefix, otherwise False.", "See also"]}, {"name": "chararray.strides", "path": "reference/generated/numpy.chararray.strides", "type": "String operations", "text": ["attribute", "Tuple of bytes to step in each dimension when traversing an array.", "The byte offset of element (i[0], i[1], ..., i[n]) in an array a is:", "A more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file in the NumPy reference guide.", "See also", "Imagine an array of 32-bit integers (each 4 bytes):", "This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array x will be (20, 4)."]}, {"name": "chararray.strip()", "path": "reference/generated/numpy.chararray.strip", "type": "numpy.chararray.strip", "text": ["method", "For each element in self, return a copy with the leading and trailing characters removed.", "See also"]}, {"name": "chararray.swapaxes()", "path": "reference/generated/numpy.chararray.swapaxes", "type": "numpy.chararray.swapaxes", "text": ["method", "Return a view of the array with axis1 and axis2 interchanged.", "Refer to numpy.swapaxes for full documentation.", "See also", "equivalent function"]}, {"name": "chararray.swapcase()", "path": "reference/generated/numpy.chararray.swapcase", "type": "numpy.chararray.swapcase", "text": ["method", "For each element in self, return a copy of the string with uppercase characters converted to lowercase and vice versa.", "See also"]}, {"name": "chararray.T", "path": "reference/generated/numpy.chararray.t", "type": "String operations", "text": ["attribute", "The transposed array.", "Same as self.transpose().", "See also"]}, {"name": "chararray.take()", "path": "reference/generated/numpy.chararray.take", "type": "numpy.chararray.take", "text": ["method", "Return an array formed from the elements of a at the given indices.", "Refer to numpy.take for full documentation.", "See also", "equivalent function"]}, {"name": "chararray.title()", "path": "reference/generated/numpy.chararray.title", "type": "numpy.chararray.title", "text": ["method", "For each element in self, return a titlecased version of the string: words start with uppercase characters, all remaining cased characters are lowercase.", "See also"]}, {"name": "chararray.tobytes()", "path": "reference/generated/numpy.chararray.tobytes", "type": "String operations", "text": ["method", "Construct Python bytes containing the raw data bytes in the array.", "Constructs Python bytes showing a copy of the raw contents of data memory. The bytes object is produced in C-order by default. This behavior is controlled by the order parameter.", "New in version 1.9.0.", "Controls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. Default is \u2018C\u2019.", "Python bytes exhibiting a copy of a\u2019s raw data."]}, {"name": "chararray.tofile()", "path": "reference/generated/numpy.chararray.tofile", "type": "numpy.chararray.tofile", "text": ["method", "Write array to a file as text or binary (default).", "Data is always written in \u2018C\u2019 order, independent of the order of a. The data produced by this method can be recovered using the function fromfile().", "An open file object, or a string containing a filename.", "Changed in version 1.17.0: pathlib.Path objects are now accepted.", "Separator between array items for text output. If \u201c\u201d (empty), a binary file is written, equivalent to file.write(a.tobytes()).", "Format string for text file output. Each entry in the array is formatted to text by first converting it to the closest Python type, and then using \u201cformat\u201d % item.", "This is a convenience function for quick storage of array data. Information on endianness and precision is lost, so this method is not a good choice for files intended to archive data or transport data between machines with different endianness. Some of these problems can be overcome by outputting the data as text files, at the expense of speed and file size.", "When fid is a file object, array contents are directly written to the file, bypassing the file object\u2019s write method. As a result, tofile cannot be used with files objects supporting compression (e.g., GzipFile) or file-like objects that do not support fileno() (e.g., BytesIO)."]}, {"name": "chararray.tolist()", "path": "reference/generated/numpy.chararray.tolist", "type": "numpy.chararray.tolist", "text": ["method", "Return the array as an a.ndim-levels deep nested list of Python scalars.", "Return a copy of the array data as a (nested) Python list. Data items are converted to the nearest compatible builtin Python type, via the item function.", "If a.ndim is 0, then since the depth of the nested list is 0, it will not be a list at all, but a simple Python scalar.", "The possibly nested list of array elements.", "The array may be recreated via a = np.array(a.tolist()), although this may sometimes lose precision.", "For a 1D array, a.tolist() is almost the same as list(a), except that tolist changes numpy scalars to Python scalars:", "Additionally, for a 2D array, tolist applies recursively:", "The base case for this recursion is a 0D array:"]}, {"name": "chararray.tostring()", "path": "reference/generated/numpy.chararray.tostring", "type": "numpy.chararray.tostring", "text": ["method", "A compatibility alias for tobytes, with exactly the same behavior.", "Despite its name, it returns bytes not strs.", "Deprecated since version 1.19.0."]}, {"name": "chararray.translate()", "path": "reference/generated/numpy.chararray.translate", "type": "numpy.chararray.translate", "text": ["method", "For each element in self, return a copy of the string where all characters occurring in the optional argument deletechars are removed, and the remaining characters have been mapped through the given translation table.", "See also"]}, {"name": "chararray.transpose()", "path": "reference/generated/numpy.chararray.transpose", "type": "numpy.chararray.transpose", "text": ["method", "Returns a view of the array with axes transposed.", "For a 1-D array this has no effect, as a transposed vector is simply the same vector. To convert a 1-D array into a 2D column vector, an additional dimension must be added. np.atleast2d(a).T achieves this, as does a[:, np.newaxis]. For a 2-D array, this is a standard matrix transpose. For an n-D array, if axes are given, their order indicates how the axes are permuted (see Examples). If axes are not provided and a.shape = (i[0], i[1], ... i[n-2], i[n-1]), then a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0]).", "View of a, with axes suitably permuted.", "See also", "Equivalent function", "Array property returning the array transposed.", "Give a new shape to an array without changing its data."]}, {"name": "chararray.upper()", "path": "reference/generated/numpy.chararray.upper", "type": "numpy.chararray.upper", "text": ["method", "Return an array with the elements of self converted to uppercase.", "See also"]}, {"name": "chararray.view()", "path": "reference/generated/numpy.chararray.view", "type": "numpy.chararray.view", "text": ["method", "New view of array with the same data.", "Note", "Passing None for dtype is different from omitting the parameter, since the former invokes dtype(None) which is an alias for dtype('float_').", "Data-type descriptor of the returned view, e.g., float32 or int16. Omitting it results in the view having the same data-type as a. This argument can also be specified as an ndarray sub-class, which then specifies the type of the returned object (this is equivalent to setting the type parameter).", "Type of the returned view, e.g., ndarray or matrix. Again, omission of the parameter results in type preservation.", "a.view() is used two different ways:", "a.view(some_dtype) or a.view(dtype=some_dtype) constructs a view of the array\u2019s memory with a different data-type. This can cause a reinterpretation of the bytes of memory.", "a.view(ndarray_subclass) or a.view(type=ndarray_subclass) just returns an instance of ndarray_subclass that looks at the same array (same shape, dtype, etc.) This does not cause a reinterpretation of the memory.", "For a.view(some_dtype), if some_dtype has a different number of bytes per entry than the previous dtype (for example, converting a regular array to a structured array), then the behavior of the view cannot be predicted just from the superficial appearance of a (shown by print(a)). It also depends on exactly how a is stored in memory. Therefore if a is C-ordered versus fortran-ordered, versus defined as a slice or transpose, etc., the view may give different results.", "Viewing array data using a different type and dtype:", "Creating a view on a structured array so it can be used in calculations", "Making changes to the view changes the underlying array", "Using a view to convert an array to a recarray:", "Views share data:", "Views that change the dtype size (bytes per entry) should normally be avoided on arrays defined by slices, transposes, fortran-ordering, etc.:"]}, {"name": "chararray.zfill()", "path": "reference/generated/numpy.chararray.zfill", "type": "numpy.chararray.zfill", "text": ["method", "Return the numeric string left-filled with zeros in a string of length width.", "See also"]}, {"name": "class.__array__()", "path": "reference/arrays.classes#numpy.class.__array__", "type": "Standard array subclasses", "text": ["If a class (ndarray subclass or not) having the __array__ method is used as the output object of an ufunc, results will not be written to the object returned by __array__. This practice will return TypeError."]}, {"name": "class.__array_finalize__()", "path": "reference/arrays.classes#numpy.class.__array_finalize__", "type": "Standard array subclasses", "text": ["This method is called whenever the system internally allocates a new array from obj, where obj is a subclass (subtype) of the ndarray. It can be used to change attributes of self after construction (so as to ensure a 2-d matrix for example), or to update meta-information from the \u201cparent.\u201d Subclasses inherit a default implementation of this method that does nothing."]}, {"name": "class.__array_function__()", "path": "reference/arrays.classes#numpy.class.__array_function__", "type": "Standard array subclasses", "text": ["New in version 1.16.", "Note", "As a convenience for __array_function__ implementors, types provides all argument types with an '__array_function__' attribute. This allows implementors to quickly identify cases where they should defer to __array_function__ implementations on other arguments. Implementations should not rely on the iteration order of types.", "Most implementations of __array_function__ will start with two checks:", "If these conditions hold, __array_function__ should return the result from calling its implementation for func(*args, **kwargs). Otherwise, it should return the sentinel value NotImplemented, indicating that the function is not implemented by these types.", "There are no general requirements on the return value from __array_function__, although most sensible implementations should probably return array(s) with the same type as one of the function\u2019s arguments.", "It may also be convenient to define a custom decorators (implements below) for registering __array_function__ implementations.", "Note that it is not required for __array_function__ implementations to include all of the corresponding NumPy function\u2019s optional arguments (e.g., broadcast_to above omits the irrelevant subok argument). Optional arguments are only passed in to __array_function__ if they were explicitly used in the NumPy function call.", "Just like the case for builtin special methods like __add__, properly written __array_function__ methods should always return NotImplemented when an unknown type is encountered. Otherwise, it will be impossible to correctly override NumPy functions from another object if the operation also includes one of your objects.", "For the most part, the rules for dispatch with __array_function__ match those for __array_ufunc__. In particular:", "If no __array_function__ methods exists, NumPy will default to calling its own implementation, intended for use on NumPy arrays. This case arises, for example, when all array-like arguments are Python numbers or lists. (NumPy arrays do have a __array_function__ method, given below, but it always returns NotImplemented if any argument other than a NumPy array subclass implements __array_function__.)", "One deviation from the current behavior of __array_ufunc__ is that NumPy will only call __array_function__ on the first argument of each unique type. This matches Python\u2019s rule for calling reflected methods, and this ensures that checking overloads has acceptable performance even when there are a large number of overloaded arguments."]}, {"name": "class.__array_prepare__()", "path": "reference/arrays.classes#numpy.class.__array_prepare__", "type": "Standard array subclasses", "text": ["At the beginning of every ufunc, this method is called on the input object with the highest array priority, or the output object if one was specified. The output array is passed in and whatever is returned is passed to the ufunc. Subclasses inherit a default implementation of this method which simply returns the output array unmodified. Subclasses may opt to use this method to transform the output array into an instance of the subclass and update metadata before returning the array to the ufunc for computation.", "Note", "For ufuncs, it is hoped to eventually deprecate this method in favour of __array_ufunc__."]}, {"name": "class.__array_priority__", "path": "reference/arrays.classes#numpy.class.__array_priority__", "type": "Standard array subclasses", "text": ["The value of this attribute is used to determine what type of object to return in situations where there is more than one possibility for the Python type of the returned object. Subclasses inherit a default value of 0.0 for this attribute.", "Note", "For ufuncs, it is hoped to eventually deprecate this method in favour of __array_ufunc__."]}, {"name": "class.__array_ufunc__()", "path": "reference/arrays.classes", "type": "Standard array subclasses", "text": ["Note", "Subclassing a numpy.ndarray is possible but if your goal is to create an array with modified behavior, as do dask arrays for distributed computation and cupy arrays for GPU-based computation, subclassing is discouraged. Instead, using numpy\u2019s dispatch mechanism is recommended.", "The ndarray can be inherited from (in Python or in C) if desired. Therefore, it can form a foundation for many useful classes. Often whether to sub-class the array object or to simply use the core array component as an internal part of a new class is a difficult decision, and can be simply a matter of choice. NumPy has several tools for simplifying how your new object interacts with other array objects, and so the choice may not be significant in the end. One way to simplify the question is by asking yourself if the object you are interested in can be replaced as a single array or does it really require two or more arrays at its core.", "Note that asarray always returns the base-class ndarray. If you are confident that your use of the array object can handle any subclass of an ndarray, then asanyarray can be used to allow subclasses to propagate more cleanly through your subroutine. In principal a subclass could redefine any aspect of the array and therefore, under strict guidelines, asanyarray would rarely be useful. However, most subclasses of the array object will not redefine certain aspects of the array object such as the buffer interface, or the attributes of the array. One important example, however, of why your subroutine may not be able to handle an arbitrary subclass of an array is that matrices redefine the \u201c*\u201d operator to be matrix-multiplication, rather than element-by-element multiplication.", "See also", "Subclassing ndarray", "NumPy provides several hooks that classes can customize:", "New in version 1.13.", "Any class, ndarray subclass or not, can define this method or set it to None in order to override the behavior of NumPy\u2019s ufuncs. This works quite similarly to Python\u2019s __mul__ and other binary operation routines.", "The method should return either the result of the operation, or NotImplemented if the operation requested is not implemented.", "If one of the input or output arguments has a __array_ufunc__ method, it is executed instead of the ufunc. If more than one of the arguments implements __array_ufunc__, they are tried in the order: subclasses before superclasses, inputs before outputs, otherwise left to right. The first routine returning something other than NotImplemented determines the result. If all of the __array_ufunc__ operations return NotImplemented, a TypeError is raised.", "Note", "We intend to re-implement numpy functions as (generalized) Ufunc, in which case it will become possible for them to be overridden by the __array_ufunc__ method. A prime candidate is matmul, which currently is not a Ufunc, but could be relatively easily be rewritten as a (set of) generalized Ufuncs. The same may happen with functions such as median, amin, and argsort.", "Like with some other special methods in python, such as __hash__ and __iter__, it is possible to indicate that your class does not support ufuncs by setting __array_ufunc__ = None. Ufuncs always raise TypeError when called on an object that sets __array_ufunc__ = None.", "The presence of __array_ufunc__ also influences how ndarray handles binary operations like arr + obj and arr\n< obj when arr is an ndarray and obj is an instance of a custom class. There are two possibilities. If obj.__array_ufunc__ is present and not None, then ndarray.__add__ and friends will delegate to the ufunc machinery, meaning that arr + obj becomes np.add(arr, obj), and then add invokes obj.__array_ufunc__. This is useful if you want to define an object that acts like an array.", "Alternatively, if obj.__array_ufunc__ is set to None, then as a special case, special methods like ndarray.__add__ will notice this and unconditionally raise TypeError. This is useful if you want to create objects that interact with arrays via binary operations, but are not themselves arrays. For example, a units handling system might have an object m representing the \u201cmeters\u201d unit, and want to support the syntax arr * m to represent that the array has units of \u201cmeters\u201d, but not want to otherwise interact with arrays via ufuncs or otherwise. This can be done by setting __array_ufunc__ = None and defining __mul__ and __rmul__ methods. (Note that this means that writing an __array_ufunc__ that always returns NotImplemented is not quite the same as setting __array_ufunc__ = None: in the former case, arr + obj will raise TypeError, while in the latter case it is possible to define a __radd__ method to prevent this.)", "The above does not hold for in-place operators, for which ndarray never returns NotImplemented. Hence, arr += obj would always lead to a TypeError. This is because for arrays in-place operations cannot generically be replaced by a simple reverse operation. (For instance, by default, arr += obj would be translated to arr =\narr + obj, i.e., arr would be replaced, contrary to what is expected for in-place array operations.)", "Note", "If you define __array_ufunc__:", "Note", "If a class defines the __array_ufunc__ method, this disables the __array_wrap__, __array_prepare__, __array_priority__ mechanism described below for ufuncs (which may eventually be deprecated).", "New in version 1.16.", "Note", "As a convenience for __array_function__ implementors, types provides all argument types with an '__array_function__' attribute. This allows implementors to quickly identify cases where they should defer to __array_function__ implementations on other arguments. Implementations should not rely on the iteration order of types.", "Most implementations of __array_function__ will start with two checks:", "If these conditions hold, __array_function__ should return the result from calling its implementation for func(*args, **kwargs). Otherwise, it should return the sentinel value NotImplemented, indicating that the function is not implemented by these types.", "There are no general requirements on the return value from __array_function__, although most sensible implementations should probably return array(s) with the same type as one of the function\u2019s arguments.", "It may also be convenient to define a custom decorators (implements below) for registering __array_function__ implementations.", "Note that it is not required for __array_function__ implementations to include all of the corresponding NumPy function\u2019s optional arguments (e.g., broadcast_to above omits the irrelevant subok argument). Optional arguments are only passed in to __array_function__ if they were explicitly used in the NumPy function call.", "Just like the case for builtin special methods like __add__, properly written __array_function__ methods should always return NotImplemented when an unknown type is encountered. Otherwise, it will be impossible to correctly override NumPy functions from another object if the operation also includes one of your objects.", "For the most part, the rules for dispatch with __array_function__ match those for __array_ufunc__. In particular:", "If no __array_function__ methods exists, NumPy will default to calling its own implementation, intended for use on NumPy arrays. This case arises, for example, when all array-like arguments are Python numbers or lists. (NumPy arrays do have a __array_function__ method, given below, but it always returns NotImplemented if any argument other than a NumPy array subclass implements __array_function__.)", "One deviation from the current behavior of __array_ufunc__ is that NumPy will only call __array_function__ on the first argument of each unique type. This matches Python\u2019s rule for calling reflected methods, and this ensures that checking overloads has acceptable performance even when there are a large number of overloaded arguments.", "This method is called whenever the system internally allocates a new array from obj, where obj is a subclass (subtype) of the ndarray. It can be used to change attributes of self after construction (so as to ensure a 2-d matrix for example), or to update meta-information from the \u201cparent.\u201d Subclasses inherit a default implementation of this method that does nothing.", "At the beginning of every ufunc, this method is called on the input object with the highest array priority, or the output object if one was specified. The output array is passed in and whatever is returned is passed to the ufunc. Subclasses inherit a default implementation of this method which simply returns the output array unmodified. Subclasses may opt to use this method to transform the output array into an instance of the subclass and update metadata before returning the array to the ufunc for computation.", "Note", "For ufuncs, it is hoped to eventually deprecate this method in favour of __array_ufunc__.", "At the end of every ufunc, this method is called on the input object with the highest array priority, or the output object if one was specified. The ufunc-computed array is passed in and whatever is returned is passed to the user. Subclasses inherit a default implementation of this method, which transforms the array into a new instance of the object\u2019s class. Subclasses may opt to use this method to transform the output array into an instance of the subclass and update metadata before returning the array to the user.", "Note", "For ufuncs, it is hoped to eventually deprecate this method in favour of __array_ufunc__.", "The value of this attribute is used to determine what type of object to return in situations where there is more than one possibility for the Python type of the returned object. Subclasses inherit a default value of 0.0 for this attribute.", "Note", "For ufuncs, it is hoped to eventually deprecate this method in favour of __array_ufunc__.", "If a class (ndarray subclass or not) having the __array__ method is used as the output object of an ufunc, results will not be written to the object returned by __array__. This practice will return TypeError.", "Note", "It is strongly advised not to use the matrix subclass. As described below, it makes writing functions that deal consistently with matrices and regular arrays very difficult. Currently, they are mainly used for interacting with scipy.sparse. We hope to provide an alternative for this use, however, and eventually remove the matrix subclass.", "matrix objects inherit from the ndarray and therefore, they have the same attributes and methods of ndarrays. There are six important differences of matrix objects, however, that may lead to unexpected results when you use matrices but expect them to act like arrays:", "Matrices have special attributes which make calculations easier. These are", "matrix.T", "Returns the transpose of the matrix.", "matrix.H", "Returns the (complex) conjugate transpose of self.", "matrix.I", "Returns the (multiplicative) inverse of invertible self.", "matrix.A", "Return self as an ndarray object.", "Warning", "Matrix objects over-ride multiplication, \u2018*\u2019, and power, \u2018**\u2019, to be matrix-multiplication and matrix power, respectively. If your subroutine can accept sub-classes and you do not convert to base- class arrays, then you must use the ufuncs multiply and power to be sure that you are performing the correct operation for all inputs.", "The matrix class is a Python subclass of the ndarray and can be used as a reference for how to construct your own subclass of the ndarray. Matrices can be created from other matrices, strings, and anything else that can be converted to an ndarray . The name \u201cmat \u201cis an alias for \u201cmatrix \u201cin NumPy.", "matrix(data[, dtype, copy])", "Note", "It is no longer recommended to use this class, even for linear", "asmatrix(data[, dtype])", "Interpret the input as a matrix.", "bmat(obj[, ldict, gdict])", "Build a matrix object from a string, nested sequence, or array.", "Example 1: Matrix creation from a string", "Example 2: Matrix creation from nested sequence", "Example 3: Matrix creation from an array", "Memory-mapped files are useful for reading and/or modifying small segments of a large file with regular layout, without reading the entire file into memory. A simple subclass of the ndarray uses a memory-mapped file for the data buffer of the array. For small files, the over-head of reading the entire file into memory is typically not significant, however for large files using memory mapping can save considerable resources.", "Memory-mapped-file arrays have one additional method (besides those they inherit from the ndarray): .flush() which must be called manually by the user to ensure that any changes to the array actually get written to disk.", "memmap(filename[, dtype, mode, offset, ...])", "Create a memory-map to an array stored in a binary file on disk.", "memmap.flush()", "Write any changes in the array to the file on disk.", "Example:", "See also", "Creating character arrays (numpy.char)", "Note", "The chararray class exists for backwards compatibility with Numarray, it is not recommended for new development. Starting from numpy 1.4, if one needs arrays of strings, it is recommended to use arrays of dtype object_, bytes_ or str_, and use the free functions in the numpy.char module for fast vectorized string operations.", "These are enhanced arrays of either str_ type or bytes_ type. These arrays inherit from the ndarray, but specially-define the operations +, *, and % on a (broadcasting) element-by-element basis. These operations are not available on the standard ndarray of character type. In addition, the chararray has all of the standard str (and bytes) methods, executing them on an element-by-element basis. Perhaps the easiest way to create a chararray is to use self.view(chararray) where self is an ndarray of str or unicode data-type. However, a chararray can also be created using the numpy.chararray constructor, or via the numpy.char.array function:", "chararray(shape[, itemsize, unicode, ...])", "Provides a convenient view on arrays of string and unicode values.", "core.defchararray.array(obj[, itemsize, ...])", "Create a chararray.", "Another difference with the standard ndarray of str data-type is that the chararray inherits the feature introduced by Numarray that white-space at the end of any element in the array will be ignored on item retrieval and comparison operations.", "See also", "Creating record arrays (numpy.rec), Data type routines, Data type objects (dtype).", "NumPy provides the recarray class which allows accessing the fields of a structured array as attributes, and a corresponding scalar data type object record.", "recarray(shape[, dtype, buf, offset, ...])", "Construct an ndarray that allows field access using attributes.", "record", "A data-type scalar that allows field access as attribute lookup.", "See also", "Masked arrays", "For backward compatibility and as a standard \u201ccontainer \u201cclass, the UserArray from Numeric has been brought over to NumPy and named numpy.lib.user_array.container The container class is a Python class whose self.array attribute is an ndarray. Multiple inheritance is probably easier with numpy.lib.user_array.container than with the ndarray itself and so it is included by default. It is not documented here beyond mentioning its existence because you are encouraged to use the ndarray class directly if you can.", "numpy.lib.user_array.container(data[, ...])", "Standard container-class for easy multiple-inheritance.", "Iterators are a powerful concept for array processing. Essentially, iterators implement a generalized for-loop. If myiter is an iterator object, then the Python code:", "calls val = next(myiter) repeatedly until StopIteration is raised by the iterator. There are several ways to iterate over an array that may be useful: default iteration, flat iteration, and \\(N\\)-dimensional enumeration.", "The default iterator of an ndarray object is the default Python iterator of a sequence type. Thus, when the array object itself is used as an iterator. The default behavior is equivalent to:", "This default iterator selects a sub-array of dimension \\(N-1\\) from the array. This can be a useful construct for defining recursive algorithms. To loop over the entire array requires \\(N\\) for-loops.", "ndarray.flat", "A 1-D iterator over the array.", "As mentioned previously, the flat attribute of ndarray objects returns an iterator that will cycle over the entire array in C-style contiguous order.", "Here, I\u2019ve used the built-in enumerate iterator to return the iterator index as well as the value.", "ndenumerate(arr)", "Multidimensional index iterator.", "Sometimes it may be useful to get the N-dimensional index while iterating. The ndenumerate iterator can achieve this.", "broadcast", "Produce an object that mimics broadcasting.", "The general concept of broadcasting is also available from Python using the broadcast iterator. This object takes \\(N\\) objects as inputs and returns an iterator that returns tuples providing each of the input sequence elements in the broadcasted result."]}, {"name": "class.__array_wrap__()", "path": "reference/arrays.classes#numpy.class.__array_wrap__", "type": "Standard array subclasses", "text": ["At the end of every ufunc, this method is called on the input object with the highest array priority, or the output object if one was specified. The ufunc-computed array is passed in and whatever is returned is passed to the user. Subclasses inherit a default implementation of this method, which transforms the array into a new instance of the object\u2019s class. Subclasses may opt to use this method to transform the output array into an instance of the subclass and update metadata before returning the array to the user.", "Note", "For ufuncs, it is hoped to eventually deprecate this method in favour of __array_ufunc__."]}, {"name": "config.add_library()", "path": "reference/distutils_guide", "type": "NumPy Distutils - Users Guide", "text": ["Currently SciPy project consists of two packages:", "NumPy \u2014 it provides packages like:", "The aim of this document is to describe how to add new tools to SciPy.", "SciPy consists of Python packages, called SciPy packages, that are available to Python users via the scipy namespace. Each SciPy package may contain other SciPy packages. And so on. Therefore, the SciPy directory tree is a tree of packages with arbitrary depth and width. Any SciPy package may depend on NumPy packages but the dependence on other SciPy packages should be kept minimal or zero.", "A SciPy package contains, in addition to its sources, the following files and directories:", "Their contents are described below.", "In order to add a Python package to SciPy, its build script (setup.py) must meet certain requirements. The most important requirement is that the package define a configuration(parent_package='',top_path=None) function which returns a dictionary suitable for passing to numpy.distutils.core.setup(..). To simplify the construction of this dictionary, numpy.distutils.misc_util provides the Configuration class, described below.", "Below is an example of a minimal setup.py file for a pure SciPy package:", "The arguments of the configuration function specify the name of parent SciPy package (parent_package) and the directory location of the main setup.py script (top_path). These arguments, along with the name of the current package, should be passed to the Configuration constructor.", "The Configuration constructor has a fourth optional argument, package_path, that can be used when package files are located in a different location than the directory of the setup.py file.", "Remaining Configuration arguments are all keyword arguments that will be used to initialize attributes of Configuration instance. Usually, these keywords are the same as the ones that setup(..) function would expect, for example, packages, ext_modules, data_files, include_dirs, libraries, headers, scripts, package_dir, etc. However, the direct specification of these keywords is not recommended as the content of these keyword arguments will not be processed or checked for the consistency of SciPy building system.", "Finally, Configuration has .todict() method that returns all the configuration data as a dictionary suitable for passing on to the setup(..) function.", "In addition to attributes that can be specified via keyword arguments to Configuration constructor, Configuration instance (let us denote as config) has the following attributes that can be useful in writing setup scripts:", "config.add_data_files(*files) \u2014 prepend files to data_files list. If files item is a tuple then its first element defines the suffix of where data files are copied relative to package installation directory and the second element specifies the path to data files. By default data files are copied under package installation directory. For example,", "will install data files to the following locations", "Path to data files can be a function taking no arguments and returning path(s) to data files \u2013 this is a useful when data files are generated while building the package. (XXX: explain the step when this function are called exactly)", "config.add_data_dir(data_path) \u2014 add directory data_path recursively to data_files. The whole directory tree starting at data_path will be copied under package installation directory. If data_path is a tuple then its first element defines the suffix of where data files are copied relative to package installation directory and the second element specifies the path to data directory. By default, data directory are copied under package installation directory under the basename of data_path. For example,", "will install data files to the following locations", "config.add_extension(name,sources,**kw) \u2014 create and add an Extension instance to ext_modules list. The first argument name defines the name of the extension module that will be installed under config.name package. The second argument is a list of sources. add_extension method takes also keyword arguments that are passed on to the Extension constructor. The list of allowed keywords is the following: include_dirs, define_macros, undef_macros, library_dirs, libraries, runtime_library_dirs, extra_objects, extra_compile_args, extra_link_args, export_symbols, swig_opts, depends, language, f2py_options, module_dirs, extra_info, extra_f77_compile_args, extra_f90_compile_args.", "Note that config.paths method is applied to all lists that may contain paths. extra_info is a dictionary or a list of dictionaries that content will be appended to keyword arguments. The list depends contains paths to files or directories that the sources of the extension module depend on. If any path in the depends list is newer than the extension module, then the module will be rebuilt.", "The list of sources may contain functions (\u2018source generators\u2019) with a pattern def <funcname>(ext, build_dir): return\n<source(s) or None>. If funcname returns None, no sources are generated. And if the Extension instance has no sources after processing all source generators, no extension module will be built. This is the recommended way to conditionally define extension modules. Source generator functions are called by the build_src sub-command of numpy.distutils.", "For example, here is a typical source generator function:", "The first argument contains the Extension instance that can be useful to access its attributes like depends, sources, etc. lists and modify them during the building process. The second argument gives a path to a build directory that must be used when creating files to a disk.", "NumPy distutils supports automatic conversion of source files named <somefile>.src. This facility can be used to maintain very similar code blocks requiring only simple changes between blocks. During the build phase of setup, if a template file named <somefile>.src is encountered, a new file named <somefile> is constructed from the template and placed in the build directory to be used instead. Two forms of template conversion are supported. The first form occurs for files named <file>.ext.src where ext is a recognized Fortran extension (f, f90, f95, f77, for, ftn, pyf). The second form is used for all other cases.", "This template converter will replicate all function and subroutine blocks in the file with names that contain \u2018<\u2026>\u2019 according to the rules in \u2018<\u2026>\u2019. The number of comma-separated words in \u2018<\u2026>\u2019 determines the number of times the block is repeated. What these words are indicates what that repeat rule, \u2018<\u2026>\u2019, should be replaced with in each block. All of the repeat rules in a block must contain the same number of comma-separated words indicating the number of times that block should be repeated. If the word in the repeat rule needs a comma, leftarrow, or rightarrow, then prepend it with a backslash \u2018 '. If a word in the repeat rule matches \u2018 \\<index>\u2019 then it will be replaced with the <index>-th word in the same repeat specification. There are two forms for the repeat rule: named and short.", "A named repeat rule is useful when the same set of repeats must be used several times in a block. It is specified using <rule1=item1, item2, item3,\u2026, itemN>, where N is the number of times the block should be repeated. On each repeat of the block, the entire expression, \u2018<\u2026>\u2019 will be replaced first with item1, and then with item2, and so forth until N repeats are accomplished. Once a named repeat specification has been introduced, the same repeat rule may be used in the current block by referring only to the name (i.e. <rule1>).", "A short repeat rule looks like <item1, item2, item3, \u2026, itemN>. The rule specifies that the entire expression, \u2018<\u2026>\u2019 should be replaced first with item1, and then with item2, and so forth until N repeats are accomplished.", "The following predefined named repeat rules are available:", "Non-Fortran files use a separate syntax for defining template blocks that should be repeated using a variable expansion similar to the named repeat rules of the Fortran-specific repeats.", "NumPy Distutils preprocesses C source files (extension: .c.src) written in a custom templating language to generate C code. The @ symbol is used to wrap macro-style variables to empower a string substitution mechanism that might describe (for instance) a set of data types.", "The template language blocks are delimited by /**begin repeat and /**end repeat**/ lines, which may also be nested using consecutively numbered delimiting lines such as /**begin repeat1 and /**end repeat1**/:", "The above rules may be clearer in the following template source example:", "The preprocessing of generically-typed C source files (whether in NumPy proper or in any third party package using NumPy Distutils) is performed by conv_template.py. The type-specific C files generated (extension: .c) by these modules during the build process are ready to be compiled. This form of generic typing is also supported for C header files (preprocessed to produce .h files).", "The header of a typical SciPy __init__.py is:", "It is possible to specify config_fc options in setup.py scripts. For example, using", "sources=[\u2026], config_fc={\u2018noopt\u2019:(__file__,1)})", "will compile the library sources without optimization flags.", "It\u2019s recommended to specify only those config_fc options in such a way that are compiler independent.", "Some old Fortran codes need special compiler options in order to work correctly. In order to specify compiler options per source file, numpy.distutils Fortran compiler looks for the following pattern:", "in the first 20 lines of the source and use the f77flags for specified type of the fcompiler (the first character C is optional).", "TODO: This feature can be easily extended for Fortran 90 codes as well. Let us know if you would need such a feature."]}, {"name": "const Tp *data()", "path": "dev/howto-docs#_CPPv4N9DoxyLimbo4dataEv", "type": "Development", "text": ["Returns the raw data for the limbo. "]}, {"name": "Contributing to NumPy", "path": "dev/index", "type": "Development", "text": ["Not a coder? Not a problem! NumPy is multi-faceted, and we can use a lot of help. These are all activities we\u2019d like to get help with (they\u2019re all important, so we list them in alphabetical order):", "The rest of this document discusses working on the NumPy code base and documentation. We\u2019re in the process of updating our descriptions of other activities and roles. If you are interested in these other activities, please contact us! You can do this via the numpy-discussion mailing list, or on GitHub (open an issue or comment on a relevant issue). These are our preferred communication channels (open source is open by nature!), however if you prefer to discuss in private first, please reach out to our community coordinators at numpy-team@googlegroups.com or numpy-team.slack.com (send an email to numpy-team@googlegroups.com for an invite the first time).", "Here\u2019s the short summary, complete TOC links are below:", "If you are a first-time contributor:", "Clone the project to your local computer:", "Change the directory:", "Add the upstream repository:", "Now, git remote -v will show two remote repositories named:", "Develop your contribution:", "Pull the latest changes from upstream:", "Create a branch for the feature you want to work on. Since the branch name will appear in the merge message, use a sensible name such as \u2018linspace-speedups\u2019:", "To submit your contribution:", "Push your changes back to your fork on GitHub:", "Review process:", "Document changes", "Beyond changes to a functions docstring and possible description in the general documentation, if your change introduces any user-facing modifications they may need to be mentioned in the release notes. To add your change to the release notes, you need to create a short file with a summary and place it in doc/release/upcoming_changes. The file doc/release/upcoming_changes/README.rst details the format and filename conventions.", "If your change introduces a deprecation, make sure to discuss this first on GitHub or the mailing list first. If agreement on the deprecation is reached, follow NEP 23 deprecation policy to add the deprecation.", "Cross referencing issues", "If the PR relates to any issues, you can add the text xref gh-xxxx where xxxx is the number of the issue to github comments. Likewise, if the PR solves an issue, replace the xref with closes, fixes or any of the other flavors github accepts.", "In the source code, be sure to preface any issue or PR reference with gh-xxxx.", "For a more detailed discussion, read on and follow the links at the bottom of this page.", "If GitHub indicates that the branch of your Pull Request can no longer be merged automatically, you have to incorporate changes that have been made since you started into your branch. Our recommended way to do this is to rebase on main.", "Use the following import conventions:", "Pull requests (PRs) that modify code should either have new tests, or modify existing tests to fail before the PR and pass afterwards. You should run the tests before pushing a PR.", "Running NumPy\u2019s test suite locally requires some additional packages, such as pytest and hypothesis. The additional testing dependencies are listed in test_requirements.txt in the top-level directory, and can conveniently be installed with:", "Tests for a module should ideally cover all code in that module, i.e., statement coverage should be at 100%.", "To measure the test coverage, install pytest-cov and then run:", "This will create a report in build/coverage, which can be viewed with:", "To build docs, run make from the doc directory. make help lists all targets. For example, to build the HTML documentation, you can run:", "To get the appropriate dependencies and other requirements, see Building the NumPy API and reference docs.", "The rest of the story", "NumPy-specific workflow is in numpy-development-workflow."]}, {"name": "Convenience Classes", "path": "reference/routines.polynomials.package", "type": "Convenience classes", "text": ["The following lists the various constants and methods common to all of the classes representing the various kinds of polynomials. In the following, the term Poly represents any one of the convenience classes (e.g. Polynomial, Chebyshev, Hermite, etc.) while the lowercase p represents an instance of a polynomial class.", "Methods for creating polynomial instances.", "Methods for converting a polynomial instance of one kind to another."]}, {"name": "Copies and views", "path": "user/basics.copies", "type": "User Guide", "text": ["When operating on NumPy arrays, it is possible to access the internal data buffer directly using a view without copying data around. This ensures good performance but can also cause unwanted problems if the user is not aware of how this works. Hence, it is important to know the difference between these two terms and to know which operations return copies and which return views.", "The NumPy array is a data structure consisting of two parts: the contiguous data buffer with the actual data elements and the metadata that contains information about the data buffer. The metadata includes data type, strides, and other important information that helps manipulate the ndarray easily. See the Internal organization of NumPy arrays section for a detailed look.", "It is possible to access the array differently by just changing certain metadata like stride and dtype without changing the data buffer. This creates a new way of looking at the data and these new arrays are called views. The data buffer remains the same, so any changes made to a view reflects in the original copy. A view can be forced through the ndarray.view method.", "When a new array is created by duplicating the data buffer as well as the metadata, it is called a copy. Changes made to the copy do not reflect on the original array. Making a copy is slower and memory-consuming but sometimes necessary. A copy can be forced by using ndarray.copy.", "See also", "Indexing on ndarrays", "Views are created when elements can be addressed with offsets and strides in the original array. Hence, basic indexing always creates views. For example:", "Here, y gets changed when x is changed because it is a view.", "Advanced indexing, on the other hand, always creates copies. For example:", "Here, y is a copy, as signified by the base attribute. We can also confirm this by assigning new values to x[[1, 2]] which in turn will not affect y at all:", "It must be noted here that during the assignment of x[[1, 2]] no view or copy is created as the assignment happens in-place.", "The numpy.reshape function creates a view where possible or a copy otherwise. In most cases, the strides can be modified to reshape the array with a view. However, in some cases where the array becomes non-contiguous (perhaps after a ndarray.transpose operation), the reshaping cannot be done by modifying strides and requires a copy. In these cases, we can raise an error by assigning the new shape to the shape attribute of the array. For example:", "Taking the example of another operation, ravel returns a contiguous flattened view of the array wherever possible. On the other hand, ndarray.flatten always returns a flattened copy of the array. However, to guarantee a view in most cases, x.reshape(-1) may be preferable.", "The base attribute of the ndarray makes it easy to tell if an array is a view or a copy. The base attribute of a view returns the original array while it returns None for a copy.", "Note that the base attribute should not be used to determine if an ndarray object is new; only if it is a view or a copy of another ndarray."]}, {"name": "core.defchararray.array()", "path": "reference/generated/numpy.core.defchararray.array", "type": "numpy.core.defchararray.array", "text": ["Create a chararray.", "Note", "This class is provided for numarray backward-compatibility. New code (not concerned with numarray compatibility) should use arrays of type string_ or unicode_ and use the free functions in numpy.char for fast vectorized string operations instead.", "Versus a regular NumPy array of type str or unicode, this class adds the following functionality:", "itemsize is the number of characters per scalar in the resulting array. If itemsize is None, and obj is an object array or a Python list, the itemsize will be automatically determined. If itemsize is provided and obj is of type str or unicode, then the obj string will be chunked into itemsize pieces.", "If true (default), then the object is copied. Otherwise, a copy will only be made if __array__ returns a copy, if obj is a nested sequence, or if a copy is needed to satisfy any of the other requirements (itemsize, unicode, order, etc.).", "When true, the resulting chararray can contain Unicode characters, when false only 8-bit characters. If unicode is None and obj is one of the following:", "then the unicode setting of the output array will be automatically determined.", "Specify the order of the array. If order is \u2018C\u2019 (default), then the array will be in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019, then the returned array will be in Fortran-contiguous order (first-index varies the fastest). If order is \u2018A\u2019, then the returned array may be in any order (either C-, Fortran-contiguous, or even discontiguous)."]}, {"name": "core.defchararray.asarray()", "path": "reference/generated/numpy.core.defchararray.asarray", "type": "numpy.core.defchararray.asarray", "text": ["Convert the input to a chararray, copying the data only if necessary.", "Versus a regular NumPy array of type str or unicode, this class adds the following functionality:", "itemsize is the number of characters per scalar in the resulting array. If itemsize is None, and obj is an object array or a Python list, the itemsize will be automatically determined. If itemsize is provided and obj is of type str or unicode, then the obj string will be chunked into itemsize pieces.", "When true, the resulting chararray can contain Unicode characters, when false only 8-bit characters. If unicode is None and obj is one of the following:", "then the unicode setting of the output array will be automatically determined.", "Specify the order of the array. If order is \u2018C\u2019 (default), then the array will be in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019, then the returned array will be in Fortran-contiguous order (first-index varies the fastest)."]}, {"name": "core.records.array()", "path": "reference/generated/numpy.core.records.array", "type": "numpy.core.records.array", "text": ["Construct a record array from a wide-variety of objects.", "A general-purpose record array constructor that dispatches to the appropriate recarray creation function based on the inputs (see Notes).", "Input object. See Notes for details on how various input types are treated.", "Valid dtype for array.", "Shape of each array.", "Position in the file or buffer to start reading from.", "Buffer (buf) is interpreted according to these strides (strides define how many bytes each array element, row, column, etc. occupy in memory).", "If dtype is None, these arguments are passed to numpy.format_parser to construct a dtype. See that function for detailed documentation.", "Whether to copy the input object (True), or to use a reference instead. This option only applies when the input is an ndarray or recarray. Defaults to True.", "Record array created from the specified object.", "If obj is None, then call the recarray constructor. If obj is a string, then call the fromstring constructor. If obj is a list or a tuple, then if the first object is an ndarray, call fromarrays, otherwise call fromrecords. If obj is a recarray, then make a copy of the data in the recarray (if copy=True) and use the new formats, names, and titles. If obj is a file, then call fromfile. Finally, if obj is an ndarray, then return obj.view(recarray), making a copy of the data if copy=True."]}, {"name": "core.records.fromarrays()", "path": "reference/generated/numpy.core.records.fromarrays", "type": "numpy.core.records.fromarrays", "text": ["Create a record array from a (flat) list of arrays", "List of array-like objects (such as lists, tuples, and ndarrays).", "valid dtype for all arrays", "Shape of the resulting array. If not provided, inferred from arrayList[0].", "If dtype is None, these arguments are passed to numpy.format_parser to construct a dtype. See that function for detailed documentation.", "Record array consisting of given arrayList columns."]}, {"name": "core.records.fromfile()", "path": "reference/generated/numpy.core.records.fromfile", "type": "numpy.core.records.fromfile", "text": ["Create an array from binary file data", "If file is a string or a path-like object then that file is opened, else it is assumed to be a file object. The file object must support random access (i.e. it must have tell and seek methods).", "valid dtype for all arrays", "shape of each array.", "Position in the file to start reading from.", "If dtype is None, these arguments are passed to numpy.format_parser to construct a dtype. See that function for detailed documentation", "record array consisting of data enclosed in file."]}, {"name": "core.records.fromrecords()", "path": "reference/generated/numpy.core.records.fromrecords", "type": "numpy.core.records.fromrecords", "text": ["Create a recarray from a list of records in text form.", "data in the same field may be heterogeneous - they will be promoted to the highest data type.", "valid dtype for all arrays", "shape of each array.", "If dtype is None, these arguments are passed to numpy.format_parser to construct a dtype. See that function for detailed documentation.", "If both formats and dtype are None, then this will auto-detect formats. Use list of tuples rather than list of lists for faster processing.", "record array consisting of given recList rows."]}, {"name": "core.records.fromstring()", "path": "reference/generated/numpy.core.records.fromstring", "type": "numpy.core.records.fromstring", "text": ["Create a record array from binary data", "Note that despite the name of this function it does not accept str instances.", "Buffer of binary data", "Valid dtype for all arrays", "Shape of each array.", "Position in the buffer to start reading from.", "If dtype is None, these arguments are passed to numpy.format_parser to construct a dtype. See that function for detailed documentation.", "Record array view into the data in datastring. This will be readonly if datastring is readonly.", "See also"]}, {"name": "CT", "path": "reference/routines.fft", "type": "Discrete Fourier Transform ( \n      \n       numpy.fft\n      \n      )", "text": ["The SciPy module scipy.fft is a more comprehensive superset of numpy.fft, which includes only a basic set of routines.", "fft(a[, n, axis, norm])", "Compute the one-dimensional discrete Fourier Transform.", "ifft(a[, n, axis, norm])", "Compute the one-dimensional inverse discrete Fourier Transform.", "fft2(a[, s, axes, norm])", "Compute the 2-dimensional discrete Fourier Transform.", "ifft2(a[, s, axes, norm])", "Compute the 2-dimensional inverse discrete Fourier Transform.", "fftn(a[, s, axes, norm])", "Compute the N-dimensional discrete Fourier Transform.", "ifftn(a[, s, axes, norm])", "Compute the N-dimensional inverse discrete Fourier Transform.", "rfft(a[, n, axis, norm])", "Compute the one-dimensional discrete Fourier Transform for real input.", "irfft(a[, n, axis, norm])", "Computes the inverse of rfft.", "rfft2(a[, s, axes, norm])", "Compute the 2-dimensional FFT of a real array.", "irfft2(a[, s, axes, norm])", "Computes the inverse of rfft2.", "rfftn(a[, s, axes, norm])", "Compute the N-dimensional discrete Fourier Transform for real input.", "irfftn(a[, s, axes, norm])", "Computes the inverse of rfftn.", "hfft(a[, n, axis, norm])", "Compute the FFT of a signal that has Hermitian symmetry, i.e., a real spectrum.", "ihfft(a[, n, axis, norm])", "Compute the inverse FFT of a signal that has Hermitian symmetry.", "fftfreq(n[, d])", "Return the Discrete Fourier Transform sample frequencies.", "rfftfreq(n[, d])", "Return the Discrete Fourier Transform sample frequencies (for usage with rfft, irfft).", "fftshift(x[, axes])", "Shift the zero-frequency component to the center of the spectrum.", "ifftshift(x[, axes])", "The inverse of fftshift.", "Fourier analysis is fundamentally a method for expressing a function as a sum of periodic components, and for recovering the function from those components. When both the function and its Fourier transform are replaced with discretized counterparts, it is called the discrete Fourier transform (DFT). The DFT has become a mainstay of numerical computing in part because of a very fast algorithm for computing it, called the Fast Fourier Transform (FFT), which was known to Gauss (1805) and was brought to light in its current form by Cooley and Tukey [CT]. Press et al. [NR] provide an accessible introduction to Fourier analysis and its applications.", "Because the discrete Fourier transform separates its input into components that contribute at discrete frequencies, it has a great number of applications in digital signal processing, e.g., for filtering, and in this context the discretized input to the transform is customarily referred to as a signal, which exists in the time domain. The output is called a spectrum or transform and exists in the frequency domain.", "There are many ways to define the DFT, varying in the sign of the exponent, normalization, etc. In this implementation, the DFT is defined as", "The DFT is in general defined for complex inputs and outputs, and a single-frequency component at linear frequency \\(f\\) is represented by a complex exponential \\(a_m = \\exp\\{2\\pi i\\,f m\\Delta t\\}\\), where \\(\\Delta t\\) is the sampling interval.", "The values in the result follow so-called \u201cstandard\u201d order: If A =\nfft(a, n), then A[0] contains the zero-frequency term (the sum of the signal), which is always purely real for real inputs. Then A[1:n/2] contains the positive-frequency terms, and A[n/2+1:] contains the negative-frequency terms, in order of decreasingly negative frequency. For an even number of input points, A[n/2] represents both positive and negative Nyquist frequency, and is also purely real for real input. For an odd number of input points, A[(n-1)/2] contains the largest positive frequency, while A[(n+1)/2] contains the largest negative frequency. The routine np.fft.fftfreq(n) returns an array giving the frequencies of corresponding elements in the output. The routine np.fft.fftshift(A) shifts transforms and their frequencies to put the zero-frequency components in the middle, and np.fft.ifftshift(A) undoes that shift.", "When the input a is a time-domain signal and A = fft(a), np.abs(A) is its amplitude spectrum and np.abs(A)**2 is its power spectrum. The phase spectrum is obtained by np.angle(A).", "The inverse DFT is defined as", "It differs from the forward transform by the sign of the exponential argument and the default normalization by \\(1/n\\).", "numpy.fft promotes float32 and complex64 arrays to float64 and complex128 arrays respectively. For an FFT implementation that does not promote input arrays, see scipy.fftpack.", "The argument norm indicates which direction of the pair of direct/inverse transforms is scaled and with what normalization factor. The default normalization (\"backward\") has the direct (forward) transforms unscaled and the inverse (backward) transforms scaled by \\(1/n\\). It is possible to obtain unitary transforms by setting the keyword argument norm to \"ortho\" so that both direct and inverse transforms are scaled by \\(1/\\sqrt{n}\\). Finally, setting the keyword argument norm to \"forward\" has the direct transforms scaled by \\(1/n\\) and the inverse transforms unscaled (i.e. exactly opposite to the default \"backward\"). None is an alias of the default option \"backward\" for backward compatibility.", "When the input is purely real, its transform is Hermitian, i.e., the component at frequency \\(f_k\\) is the complex conjugate of the component at frequency \\(-f_k\\), which means that for real inputs there is no information in the negative frequency components that is not already available from the positive frequency components. The family of rfft functions is designed to operate on real inputs, and exploits this symmetry by computing only the positive frequency components, up to and including the Nyquist frequency. Thus, n input points produce n/2+1 complex output points. The inverses of this family assumes the same symmetry of its input, and for an output of n points uses n/2+1 input points.", "Correspondingly, when the spectrum is purely real, the signal is Hermitian. The hfft family of functions exploits this symmetry by using n/2+1 complex points in the input (time) domain for n real points in the frequency domain.", "In higher dimensions, FFTs are used, e.g., for image analysis and filtering. The computational efficiency of the FFT means that it can also be a faster way to compute large convolutions, using the property that a convolution in the time domain is equivalent to a point-by-point multiplication in the frequency domain.", "In two dimensions, the DFT is defined as", "which extends in the obvious way to higher dimensions, and the inverses in higher dimensions also extend in the same way.", "Cooley, James W., and John W. Tukey, 1965, \u201cAn algorithm for the machine calculation of complex Fourier series,\u201d Math. Comput. 19: 297-301.", "Press, W., Teukolsky, S., Vetterline, W.T., and Flannery, B.P., 2007, Numerical Recipes: The Art of Scientific Computing, ch. 12-13. Cambridge Univ. Press, Cambridge, UK.", "For examples, see the various functions."]}, {"name": "Data type routines", "path": "reference/routines.dtype", "type": "Data type routines", "text": ["can_cast(from_, to[, casting])", "Returns True if cast between data types can occur according to the casting rule.", "promote_types(type1, type2)", "Returns the data type with the smallest size and smallest scalar kind to which both type1 and type2 may be safely cast.", "min_scalar_type(a, /)", "For scalar a, returns the data type with the smallest size and smallest scalar kind which can hold its value.", "result_type(*arrays_and_dtypes)", "Returns the type that results from applying the NumPy type promotion rules to the arguments.", "common_type(*arrays)", "Return a scalar type which is common to the input arrays.", "obj2sctype(rep[, default])", "Return the scalar dtype or NumPy equivalent of Python type of an object.", "dtype(dtype[, align, copy])", "Create a data type object.", "format_parser(formats, names, titles[, ...])", "Class to convert formats, names, titles description to a dtype.", "finfo(dtype)", "Machine limits for floating point types.", "iinfo(type)", "Machine limits for integer types.", "MachAr([float_conv, int_conv, ...])", "Diagnosing machine parameters.", "issctype(rep)", "Determines whether the given object represents a scalar data-type.", "issubdtype(arg1, arg2)", "Returns True if first argument is a typecode lower/equal in type hierarchy.", "issubsctype(arg1, arg2)", "Determine if the first argument is a subclass of the second argument.", "issubclass_(arg1, arg2)", "Determine if a class is a subclass of a second class.", "find_common_type(array_types, scalar_types)", "Determine common type following standard coercion rules.", "typename(char)", "Return a description for the given data type code.", "sctype2char(sctype)", "Return the string representation of a scalar dtype.", "mintypecode(typechars[, typeset, default])", "Return the character for the minimum-size type to which given types can be safely cast.", "maximum_sctype(t)", "Return the scalar type of highest precision of the same kind as the input."]}, {"name": "Data types", "path": "user/basics.types", "type": "User Guide", "text": ["See also", "Data type objects", "NumPy supports a much greater variety of numerical types than Python does. This section shows which are available, and how to modify an array\u2019s data-type.", "The primitive types supported are tied closely to those in C:", "Numpy type", "C type", "Description", "numpy.bool_", "bool", "Boolean (True or False) stored as a byte", "numpy.byte", "signed char", "Platform-defined", "numpy.ubyte", "unsigned char", "Platform-defined", "numpy.short", "short", "Platform-defined", "numpy.ushort", "unsigned short", "Platform-defined", "numpy.intc", "int", "Platform-defined", "numpy.uintc", "unsigned int", "Platform-defined", "numpy.int_", "long", "Platform-defined", "numpy.uint", "unsigned long", "Platform-defined", "numpy.longlong", "long long", "Platform-defined", "numpy.ulonglong", "unsigned long long", "Platform-defined", "numpy.half / numpy.float16", "Half precision float: sign bit, 5 bits exponent, 10 bits mantissa", "numpy.single", "float", "Platform-defined single precision float: typically sign bit, 8 bits exponent, 23 bits mantissa", "numpy.double", "double", "Platform-defined double precision float: typically sign bit, 11 bits exponent, 52 bits mantissa.", "numpy.longdouble", "long double", "Platform-defined extended-precision float", "numpy.csingle", "float complex", "Complex number, represented by two single-precision floats (real and imaginary components)", "numpy.cdouble", "double complex", "Complex number, represented by two double-precision floats (real and imaginary components).", "numpy.clongdouble", "long double complex", "Complex number, represented by two extended-precision floats (real and imaginary components).", "Since many of these have platform-dependent definitions, a set of fixed-size aliases are provided (See Sized aliases).", "NumPy numerical types are instances of dtype (data-type) objects, each having unique characteristics. Once you have imported NumPy using", "the dtypes are available as np.bool_, np.float32, etc.", "Advanced types, not listed above, are explored in section Structured arrays.", "There are 5 basic numerical types representing booleans (bool), integers (int), unsigned integers (uint) floating point (float) and complex. Those with numbers in their name indicate the bitsize of the type (i.e. how many bits are needed to represent a single value in memory). Some types, such as int and intp, have differing bitsizes, dependent on the platforms (e.g. 32-bit vs. 64-bit machines). This should be taken into account when interfacing with low-level code (such as C or Fortran) where the raw memory is addressed.", "Data-types can be used as functions to convert python numbers to array scalars (see the array scalar section for an explanation), python sequences of numbers to arrays of that type, or as arguments to the dtype keyword that many numpy functions or methods accept. Some examples:", "Array types can also be referred to by character codes, mostly to retain backward compatibility with older packages such as Numeric. Some documentation may still refer to these, for example:", "We recommend using dtype objects instead.", "To convert the type of an array, use the .astype() method (preferred) or the type itself as a function. For example:", "Note that, above, we use the Python float object as a dtype. NumPy knows that int refers to np.int_, bool means np.bool_, that float is np.float_ and complex is np.complex_. The other data-types do not have Python equivalents.", "To determine the type of an array, look at the dtype attribute:", "dtype objects also contain information about the type, such as its bit-width and its byte-order. The data type can also be used indirectly to query properties of the type, such as whether it is an integer:", "NumPy generally returns elements of arrays as array scalars (a scalar with an associated dtype). Array scalars differ from Python scalars, but for the most part they can be used interchangeably (the primary exception is for versions of Python older than v2.x, where integer array scalars cannot act as indices for lists and tuples). There are some exceptions, such as when code requires very specific attributes of a scalar or when it checks specifically whether a value is a Python scalar. Generally, problems are easily fixed by explicitly converting array scalars to Python scalars, using the corresponding Python type function (e.g., int, float, complex, str, unicode).", "The primary advantage of using array scalars is that they preserve the array type (Python may not have a matching scalar type available, e.g. int16). Therefore, the use of array scalars ensures identical behaviour between arrays and scalars, irrespective of whether the value is inside an array or not. NumPy scalars also have many of the same methods arrays do.", "The fixed size of NumPy numeric types may cause overflow errors when a value requires more memory than available in the data type. For example, numpy.power evaluates 100 ** 8 correctly for 64-bit integers, but gives 1874919424 (incorrect) for a 32-bit integer.", "The behaviour of NumPy and Python integer types differs significantly for integer overflows and may confuse users expecting NumPy integers to behave similar to Python\u2019s int. Unlike NumPy, the size of Python\u2019s int is flexible. This means Python integers may expand to accommodate any integer and will not overflow.", "NumPy provides numpy.iinfo and numpy.finfo to verify the minimum or maximum values of NumPy integer and floating point values respectively", "If 64-bit integers are still too small the result may be cast to a floating point number. Floating point numbers offer a larger, but inexact, range of possible values.", "Python\u2019s floating-point numbers are usually 64-bit floating-point numbers, nearly equivalent to np.float64. In some unusual situations it may be useful to use floating-point numbers with more precision. Whether this is possible in numpy depends on the hardware and on the development environment: specifically, x86 machines provide hardware floating-point with 80-bit precision, and while most C compilers provide this as their long double type, MSVC (standard for Windows builds) makes long double identical to double (64 bits). NumPy makes the compiler\u2019s long double available as np.longdouble (and np.clongdouble for the complex numbers). You can find out what your numpy provides with np.finfo(np.longdouble).", "NumPy does not provide a dtype with more precision than C\u2019s long double\\; in particular, the 128-bit IEEE quad precision data type (FORTRAN\u2019s REAL*16\\) is not available.", "For efficient memory alignment, np.longdouble is usually stored padded with zero bits, either to 96 or 128 bits. Which is more efficient depends on hardware and development environment; typically on 32-bit systems they are padded to 96 bits, while on 64-bit systems they are typically padded to 128 bits. np.longdouble is padded to the system default; np.float96 and np.float128 are provided for users who want specific padding. In spite of the names, np.float96 and np.float128 provide only as much precision as np.longdouble, that is, 80 bits on most x86 machines and 64 bits in standard Windows builds.", "Be warned that even if np.longdouble offers more precision than python float, it is easy to lose that extra precision, since python often forces values to pass through float. For example, the % formatting operator requires its arguments to be converted to standard python types, and it is therefore impossible to preserve extended precision even if many decimal places are requested. It can be useful to test your code with the value 1 + np.finfo(np.longdouble).eps."]}, {"name": "DataSource.abspath()", "path": "reference/generated/numpy.datasource.abspath", "type": "numpy.DataSource.abspath", "text": ["method", "Return absolute path of file in the DataSource directory.", "If path is an URL, then abspath will return either the location the file exists locally or the location it would exist when opened using the open method.", "Can be a local file or a remote URL.", "Complete path, including the DataSource destination directory.", "The functionality is based on os.path.abspath."]}, {"name": "DataSource.exists()", "path": "reference/generated/numpy.datasource.exists", "type": "numpy.DataSource.exists", "text": ["method", "Test if path exists.", "Test if path exists as (and in this order):", "Can be a local file or a remote URL.", "True if path exists.", "When path is an URL, exists will return True if it\u2019s either stored locally in the DataSource directory, or is a valid remote URL. DataSource does not discriminate between the two, the file is accessible if it exists in either location."]}, {"name": "DataSource.open()", "path": "reference/generated/numpy.datasource.open", "type": "numpy.DataSource.open", "text": ["method", "Open and return file-like object.", "If path is an URL, it will be downloaded, stored in the DataSource directory and opened from there.", "Local file path or URL to open.", "Mode to open path. Mode \u2018r\u2019 for reading, \u2018w\u2019 for writing, \u2018a\u2019 to append. Available modes depend on the type of object specified by path. Default is \u2018r\u2019.", "Open text file with given encoding. The default encoding will be what io.open uses.", "Newline to use when reading text file.", "File object."]}, {"name": "Datetime Support Functions", "path": "reference/routines.datetime", "type": "Datetime Support Functions", "text": ["datetime_as_string(arr[, unit, timezone, ...])", "Convert an array of datetimes into an array of strings.", "datetime_data(dtype, /)", "Get information about the step size of a date or time type.", "busdaycalendar([weekmask, holidays])", "A business day calendar object that efficiently stores information defining valid days for the busday family of functions.", "is_busday(dates[, weekmask, holidays, ...])", "Calculates which of the given dates are valid days, and which are not.", "busday_offset(dates, offsets[, roll, ...])", "First adjusts the date to fall on a valid day according to the roll rule, then applies offsets to the given dates counted in valid days.", "busday_count(begindates, enddates[, ...])", "Counts the number of valid days between begindates and enddates, not including the day of enddates."]}, {"name": "Datetimes and Timedeltas", "path": "reference/arrays.datetime", "type": "Datetimes and Timedeltas", "text": ["New in version 1.7.0.", "Starting in NumPy 1.7, there are core array data types which natively support datetime functionality. The data type is called \u201cdatetime64\u201d, so named because \u201cdatetime\u201d is already taken by the datetime library included in Python.", "The most basic way to create datetimes is from strings in ISO 8601 date or datetime format. It is also possible to create datetimes from an integer by offset relative to the Unix epoch (00:00:00 UTC on 1 January 1970). The unit for internal storage is automatically selected from the form of the string, and can be either a date unit or a time unit. The date units are years (\u2018Y\u2019), months (\u2018M\u2019), weeks (\u2018W\u2019), and days (\u2018D\u2019), while the time units are hours (\u2018h\u2019), minutes (\u2018m\u2019), seconds (\u2018s\u2019), milliseconds (\u2018ms\u2019), and some additional SI-prefix seconds-based units. The datetime64 data type also accepts the string \u201cNAT\u201d, in any combination of lowercase/uppercase letters, for a \u201cNot A Time\u201d value.", "A simple ISO date:", "From an integer and a date unit, 1 year since the UNIX epoch:", "Using months for the unit:", "Specifying just the month, but forcing a \u2018days\u2019 unit:", "From a date and time:", "NAT (not a time):", "When creating an array of datetimes from a string, it is still possible to automatically select the unit from the inputs, by using the datetime type with generic units.", "An array of datetimes can be constructed from integers representing POSIX timestamps with the given unit.", "The datetime type works with many common NumPy functions, for example arange can be used to generate ranges of dates.", "All the dates for one month:", "The datetime object represents a single moment in time. If two datetimes have different units, they may still be representing the same moment of time, and converting from a bigger unit like months to a smaller unit like days is considered a \u2018safe\u2019 cast because the moment of time is still being represented exactly.", "Deprecated since version 1.11.0: NumPy does not store timezone information. For backwards compatibility, datetime64 still parses timezone offsets, which it handles by converting to UTC. This behaviour is deprecated and will raise an error in the future.", "NumPy allows the subtraction of two Datetime values, an operation which produces a number with a time unit. Because NumPy doesn\u2019t have a physical quantities system in its core, the timedelta64 data type was created to complement datetime64. The arguments for timedelta64 are a number, to represent the number of units, and a date/time unit, such as (D)ay, (M)onth, (Y)ear, (h)ours, (m)inutes, or (s)econds. The timedelta64 data type also accepts the string \u201cNAT\u201d in place of the number for a \u201cNot A Time\u201d value.", "Datetimes and Timedeltas work together to provide ways for simple datetime calculations.", "There are two Timedelta units (\u2018Y\u2019, years and \u2018M\u2019, months) which are treated specially, because how much time they represent changes depending on when they are used. While a timedelta day unit is equivalent to 24 hours, there is no way to convert a month unit into days, because different months have different numbers of days.", "The Datetime and Timedelta data types support a large number of time units, as well as generic units which can be coerced into any of the other units based on input data.", "Datetimes are always stored based on POSIX time (though having a TAI mode which allows for accounting of leap-seconds is proposed), with an epoch of 1970-01-01T00:00Z. This means the supported dates are always a symmetric interval around the epoch, called \u201ctime span\u201d in the table below.", "The length of the span is the range of a 64-bit integer times the length of the date or unit. For example, the time span for \u2018W\u2019 (week) is exactly 7 times longer than the time span for \u2018D\u2019 (day), and the time span for \u2018D\u2019 (day) is exactly 24 times longer than the time span for \u2018h\u2019 (hour).", "Here are the date units:", "Code", "Meaning", "Time span (relative)", "Time span (absolute)", "Y", "year", "+/- 9.2e18 years", "[9.2e18 BC, 9.2e18 AD]", "M", "month", "+/- 7.6e17 years", "[7.6e17 BC, 7.6e17 AD]", "W", "week", "+/- 1.7e17 years", "[1.7e17 BC, 1.7e17 AD]", "D", "day", "+/- 2.5e16 years", "[2.5e16 BC, 2.5e16 AD]", "And here are the time units:", "Code", "Meaning", "Time span (relative)", "Time span (absolute)", "h", "hour", "+/- 1.0e15 years", "[1.0e15 BC, 1.0e15 AD]", "m", "minute", "+/- 1.7e13 years", "[1.7e13 BC, 1.7e13 AD]", "s", "second", "+/- 2.9e11 years", "[2.9e11 BC, 2.9e11 AD]", "ms", "millisecond", "+/- 2.9e8 years", "[ 2.9e8 BC, 2.9e8 AD]", "us / \u03bcs", "microsecond", "+/- 2.9e5 years", "[290301 BC, 294241 AD]", "ns", "nanosecond", "+/- 292 years", "[ 1678 AD, 2262 AD]", "ps", "picosecond", "+/- 106 days", "[ 1969 AD, 1970 AD]", "fs", "femtosecond", "+/- 2.6 hours", "[ 1969 AD, 1970 AD]", "as", "attosecond", "+/- 9.2 seconds", "[ 1969 AD, 1970 AD]", "To allow the datetime to be used in contexts where only certain days of the week are valid, NumPy includes a set of \u201cbusday\u201d (business day) functions.", "The default for busday functions is that the only valid days are Monday through Friday (the usual business days). The implementation is based on a \u201cweekmask\u201d containing 7 Boolean flags to indicate valid days; custom weekmasks are possible that specify other sets of valid days.", "The \u201cbusday\u201d functions can additionally check a list of \u201choliday\u201d dates, specific dates that are not valid days.", "The function busday_offset allows you to apply offsets specified in business days to datetimes with a unit of \u2018D\u2019 (day).", "When an input date falls on the weekend or a holiday, busday_offset first applies a rule to roll the date to a valid business day, then applies the offset. The default rule is \u2018raise\u2019, which simply raises an exception. The rules most typically used are \u2018forward\u2019 and \u2018backward\u2019.", "In some cases, an appropriate use of the roll and the offset is necessary to get a desired answer.", "The first business day on or after a date:", "The first business day strictly after a date:", "The function is also useful for computing some kinds of days like holidays. In Canada and the U.S., Mother\u2019s day is on the second Sunday in May, which can be computed with a custom weekmask.", "When performance is important for manipulating many business dates with one particular choice of weekmask and holidays, there is an object busdaycalendar which stores the data necessary in an optimized form.", "To test a datetime64 value to see if it is a valid day, use is_busday.", "To find how many valid days there are in a specified range of datetime64 dates, use busday_count:", "If you have an array of datetime64 day values, and you want a count of how many of them are valid dates, you can do this:", "Here are several examples of custom weekmask values. These examples specify the \u201cbusday\u201d default of Monday through Friday being valid days.", "Some examples:"]}, {"name": "deletechars", "path": "user/basics.io.genfromtxt", "type": "User Guide", "text": ["NumPy provides several functions to create arrays from tabular data. We focus here on the genfromtxt function.", "In a nutshell, genfromtxt runs two main loops. The first loop converts each line of the file in a sequence of strings. The second loop converts each string to the appropriate data type. This mechanism is slower than a single loop, but gives more flexibility. In particular, genfromtxt is able to take missing data into account, when other faster and simpler functions like loadtxt cannot.", "Note", "When giving examples, we will use the following conventions:", "The only mandatory argument of genfromtxt is the source of the data. It can be a string, a list of strings, a generator or an open file-like object with a read method, for example, a file or io.StringIO object. If a single string is provided, it is assumed to be the name of a local or remote file. If a list of strings or a generator returning strings is provided, each string is treated as one line in a file. When the URL of a remote file is passed, the file is automatically downloaded to the current directory and opened.", "Recognized file types are text files and archives. Currently, the function recognizes gzip and bz2 (bzip2) archives. The type of the archive is determined from the extension of the file: if the filename ends with '.gz', a gzip archive is expected; if it ends with 'bz2', a bzip2 archive is assumed.", "Once the file is defined and open for reading, genfromtxt splits each non-empty line into a sequence of strings. Empty or commented lines are just skipped. The delimiter keyword is used to define how the splitting should take place.", "Quite often, a single character marks the separation between columns. For example, comma-separated files (CSV) use a comma (,) or a semicolon (;) as delimiter:", "Another common separator is \"\\t\", the tabulation character. However, we are not limited to a single character, any string will do. By default, genfromtxt assumes delimiter=None, meaning that the line is split along white spaces (including tabs) and that consecutive white spaces are considered as a single white space.", "Alternatively, we may be dealing with a fixed-width file, where columns are defined as a given number of characters. In that case, we need to set delimiter to a single integer (if all the columns have the same size) or to a sequence of integers (if columns can have different sizes):", "By default, when a line is decomposed into a series of strings, the individual entries are not stripped of leading nor trailing white spaces. This behavior can be overwritten by setting the optional argument autostrip to a value of True:", "The optional argument comments is used to define a character string that marks the beginning of a comment. By default, genfromtxt assumes comments='#'. The comment marker may occur anywhere on the line. Any character present after the comment marker(s) is simply ignored:", "New in version 1.7.0: When comments is set to None, no lines are treated as comments.", "Note", "There is one notable exception to this behavior: if the optional argument names=True, the first commented line will be examined for names.", "The presence of a header in the file can hinder data processing. In that case, we need to use the skip_header optional argument. The values of this argument must be an integer which corresponds to the number of lines to skip at the beginning of the file, before any other action is performed. Similarly, we can skip the last n lines of the file by using the skip_footer attribute and giving it a value of n:", "By default, skip_header=0 and skip_footer=0, meaning that no lines are skipped.", "In some cases, we are not interested in all the columns of the data but only a few of them. We can select which columns to import with the usecols argument. This argument accepts a single integer or a sequence of integers corresponding to the indices of the columns to import. Remember that by convention, the first column has an index of 0. Negative integers behave the same as regular Python negative indexes.", "For example, if we want to import only the first and the last columns, we can use usecols=(0, -1):", "If the columns have names, we can also select which columns to import by giving their name to the usecols argument, either as a sequence of strings or a comma-separated string:", "The main way to control how the sequences of strings we have read from the file are converted to other types is to set the dtype argument. Acceptable values for this argument are:", "In all the cases but the first one, the output will be a 1D array with a structured dtype. This dtype has as many fields as items in the sequence. The field names are defined with the names keyword.", "When dtype=None, the type of each column is determined iteratively from its data. We start by checking whether a string can be converted to a boolean (that is, if the string matches true or false in lower cases); then whether it can be converted to an integer, then to a float, then to a complex and eventually to a string. This behavior may be changed by modifying the default mapper of the StringConverter class.", "The option dtype=None is provided for convenience. However, it is significantly slower than setting the dtype explicitly.", "A natural approach when dealing with tabular data is to allocate a name to each column. A first possibility is to use an explicit structured dtype, as mentioned previously:", "Another simpler possibility is to use the names keyword with a sequence of strings or a comma-separated string:", "In the example above, we used the fact that by default, dtype=float. By giving a sequence of names, we are forcing the output to a structured dtype.", "We may sometimes need to define the column names from the data itself. In that case, we must use the names keyword with a value of True. The names will then be read from the first line (after the skip_header ones), even if the line is commented out:", "The default value of names is None. If we give any other value to the keyword, the new names will overwrite the field names we may have defined with the dtype:", "If names=None but a structured dtype is expected, names are defined with the standard NumPy default of \"f%i\", yielding names like f0, f1 and so forth:", "In the same way, if we don\u2019t give enough names to match the length of the dtype, the missing names will be defined with this default template:", "We can overwrite this default with the defaultfmt argument, that takes any format string:", "Note", "We need to keep in mind that defaultfmt is used only if some names are expected but not defined.", "NumPy arrays with a structured dtype can also be viewed as recarray, where a field can be accessed as if it were an attribute. For that reason, we may need to make sure that the field name doesn\u2019t contain any space or invalid character, or that it does not correspond to the name of a standard attribute (like size or shape), which would confuse the interpreter. genfromtxt accepts three optional arguments that provide a finer control on the names:", "Gives a string combining all the characters that must be deleted from the name. By default, invalid characters are ~!@#$%^&*()-=+~\\|]}[{';:\n/?.>,<.", "Gives a list of the names to exclude, such as return, file, print\u2026 If one of the input name is part of this list, an underscore character ('_') will be appended to it.", "Whether the names should be case-sensitive (case_sensitive=True), converted to upper case (case_sensitive=False or case_sensitive='upper') or to lower case (case_sensitive='lower').", "Usually, defining a dtype is sufficient to define how the sequence of strings must be converted. However, some additional control may sometimes be required. For example, we may want to make sure that a date in a format YYYY/MM/DD is converted to a datetime object, or that a string like xx% is properly converted to a float between 0 and 1. In such cases, we should define conversion functions with the converters arguments.", "The value of this argument is typically a dictionary with column indices or column names as keys and a conversion functions as values. These conversion functions can either be actual functions or lambda functions. In any case, they should accept only a string as input and output only a single element of the wanted type.", "In the following example, the second column is converted from as string representing a percentage to a float between 0 and 1:", "We need to keep in mind that by default, dtype=float. A float is therefore expected for the second column. However, the strings ' 2.3%' and ' 78.9%' cannot be converted to float and we end up having np.nan instead. Let\u2019s now use a converter:", "The same results can be obtained by using the name of the second column (\"p\") as key instead of its index (1):", "Converters can also be used to provide a default for missing entries. In the following example, the converter convert transforms a stripped string into the corresponding float or into -999 if the string is empty. We need to explicitly strip the string from white spaces as it is not done by default:", "Some entries may be missing in the dataset we are trying to import. In a previous example, we used a converter to transform an empty string into a float. However, user-defined converters may rapidly become cumbersome to manage.", "The genfromtxt function provides two other complementary mechanisms: the missing_values argument is used to recognize missing data and a second argument, filling_values, is used to process these missing data.", "By default, any empty string is marked as missing. We can also consider more complex strings, such as \"N/A\" or \"???\" to represent missing or invalid data. The missing_values argument accepts three kinds of values:", "This string will be used as the marker for missing data for all the columns", "In that case, each item is associated to a column, in order.", "Values of the dictionary are strings or sequence of strings. The corresponding keys can be column indices (integers) or column names (strings). In addition, the special key None can be used to define a default applicable to all columns.", "We know how to recognize missing data, but we still need to provide a value for these missing entries. By default, this value is determined from the expected dtype according to this table:", "Expected type", "Default", "bool", "False", "int", "-1", "float", "np.nan", "complex", "np.nan+0j", "string", "'???'", "We can get a finer control on the conversion of missing values with the filling_values optional argument. Like missing_values, this argument accepts different kind of values:", "This will be the default for all columns", "Each entry will be the default for the corresponding column", "Each key can be a column index or a column name, and the corresponding value should be a single object. We can use the special key None to define a default for all columns.", "In the following example, we suppose that the missing values are flagged with \"N/A\" in the first column and by \"???\" in the third column. We wish to transform these missing values to 0 if they occur in the first and second column, and to -999 if they occur in the last column:", "We may also want to keep track of the occurrence of missing data by constructing a boolean mask, with True entries where data was missing and False otherwise. To do that, we just have to set the optional argument usemask to True (the default is False). The output array will then be a MaskedArray.", "In addition to genfromtxt, the numpy.lib.npyio module provides several convenience functions derived from genfromtxt. These functions work the same way as the original, but they have different default values.", "Returns a standard numpy.recarray (if usemask=False) or a MaskedRecords array (if usemaske=True). The default dtype is dtype=None, meaning that the types of each column will be automatically determined.", "Like recfromtxt, but with a default delimiter=\",\"."]}, {"name": "Development workflow", "path": "dev/development_workflow", "type": "Development", "text": ["You already have your own forked copy of the NumPy repository, by following Create a NumPy fork, Make the local copy, you have configured git by following Git configuration, and have linked the upstream repository as explained in Linking your repository to the upstream repo.", "What is described below is a recommended workflow with Git.", "In short:", "When finished:", "This way of working helps to keep work well organized and the history as clear as possible.", "See also", "There are many online tutorials to help you learn git. For discussions of specific git workflows, see these discussions on linux git workflow, and ipython git workflow.", "First, fetch new commits from the upstream repository:", "Then, create a new branch based on the main branch of the upstream repository:", "Optional: Check which files have changed with git status (see git status). You\u2019ll see a listing like this one:", "To commit the staged files into the local copy of your repo, do git\ncommit. At this point, a text editor will open up to allow you to write a commit message. Read the commit message section to be sure that you are writing a properly formatted and sufficiently detailed commit message. After saving your message and closing the editor, your commit will be saved. For trivial commits, a short commit message can be passed in through the command line using the -m flag. For example, git commit -am \"ENH: Some message\".", "In some cases, you will see this form of the commit command: git commit\n-a. The extra -a flag automatically commits all modified files and removes all deleted files. This can save you some typing of numerous git\nadd commands; however, it can add unwanted changes to a commit if you\u2019re not careful. For more information, see why the -a flag? - and the helpful use-case description in the tangled working copy problem.", "Push the changes to your forked repo on github:", "For more information, see git push.", "Note", "Assuming you have followed the instructions in these pages, git will create a default link to your github repo called origin. In git >= 1.7 you can ensure that the link to origin is permanently set by using the --set-upstream option:", "From now on git will know that my-new-feature is related to the my-new-feature branch in your own github repo. Subsequent push calls are then simplified to the following:", "You have to use --set-upstream for each new branch that you create.", "It may be the case that while you were working on your edits, new commits have been added to upstream that affect your work. In this case, follow the Rebasing on main section of this document to apply those changes to your branch.", "Commit messages should be clear and follow a few basic rules. Example:", "Describing the motivation for a change, the nature of a bug for bug fixes or some details on what an enhancement does are also good to include in a commit message. Messages should be understandable without looking at the code changes. A commit message like MAINT: fixed another one is an example of what not to do; the reader has to go look for context elsewhere.", "Standard acronyms to start the commit message with are:", "If you plan a new feature or API change, it\u2019s wisest to first email the NumPy mailing list asking for comment. If you haven\u2019t heard back in a week, it\u2019s OK to ping the list again.", "When you feel your work is finished, you can create a pull request (PR). Github has a nice help page that outlines the process for filing pull requests.", "If your changes involve modifications to the API or addition/modification of a function, add a release note to the doc/release/upcoming_changes/ directory, following the instructions and format in the doc/release/upcoming_changes/README.rst file.", "We review pull requests as soon as we can, typically within a week. If you get no review comments within two weeks, feel free to ask for feedback by adding a comment on your PR (this will notify maintainers).", "If your PR is large or complicated, asking for input on the numpy-discussion mailing list may also be useful.", "This updates your feature branch with changes from the upstream NumPy github repo. If you do not absolutely need to do this, try to avoid doing it, except perhaps when you are finished. The first step will be to update the remote repository with new commits from upstream:", "Next, you need to update the feature branch:", "If you have made changes to files that have changed also upstream, this may generate merge conflicts that you need to resolve. See below for help in this case.", "Finally, remove the backup branch upon a successful rebase:", "Note", "Rebasing on main is preferred over merging upstream back to your branch. Using git merge and git pull is discouraged when working on feature branches.", "Sometimes, you mess up merges or rebases. Luckily, in Git it is relatively straightforward to recover from such mistakes.", "If you mess up during a rebase:", "If you notice you messed up after the rebase:", "If you forgot to make a backup branch:", "If you didn\u2019t actually mess up but there are merge conflicts, you need to resolve those. This can be one of the trickier things to get right. For a good description of how to do this, see this article on merging conflicts.", "Note", "Do this only for your own feature branches.", "There\u2019s an embarrassing typo in a commit you made? Or perhaps you made several false starts you would like the posterity not to see.", "This can be done via interactive rebasing.", "Suppose that the commit history looks like this:", "and 6ad92e5 is the last commit in the main branch. Suppose we want to make the following changes:", "We do as follows:", "This will open an editor with the following text in it:", "To achieve what we want, we will make the following changes to it:", "This means that (i) we want to edit the commit message for 13d7934, and (ii) collapse the last three commits into one. Now we save and quit the editor.", "Git will then immediately bring up an editor for editing the commit message. After revising it, we get the output:", "and the history looks now like this:", "If it went wrong, recovery is again possible as explained above.", "See also: https://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-branch-locally-and-remotely", "If you want to work on some stuff with other people, where you are all committing into the same repository, or even the same branch, then just share it via github.", "First fork NumPy into your account, as from Create a NumPy fork.", "Then, go to your forked repository github page, say https://github.com/your-user-name/numpy", "Click on the \u2018Admin\u2019 button, and add anyone else to the repo as a collaborator:", "Now all those people can do:", "Remember that links starting with git@ use the ssh protocol and are read-write; links starting with git:// are read-only.", "Your collaborators can then commit directly into that repo with the usual:", "To see a graphical representation of the repository branches and commits:", "To see a linear list of commits for this branch:", "You can also look at the network graph visualizer for your github repo.", "Backporting is the process of copying new feature/fixes committed in numpy/main back to stable release branches. To do this you make a branch off the branch you are backporting to, cherry pick the commits you want from numpy/main, and then submit a pull request for the branch containing the backport.", "First, you need to make the branch you will work on. This needs to be based on the older version of NumPy (not main):", "Now you need to apply the changes from main to this branch using git cherry-pick:", "Push the new branch to your Github repository:", "Requires commit rights to the main NumPy repo.", "When you have a set of \u201cready\u201d changes in a feature branch ready for NumPy\u2019s main or maintenance branches, you can push them to upstream as follows:", "First, merge or rebase on the target branch.", "Only a few, unrelated commits then prefer rebasing:", "See Rebasing on main.", "If all of the commits are related, create a merge commit:", "Check that what you are going to push looks sensible:", "Push to upstream:", "Note", "It\u2019s usually a good idea to use the -n flag to git push to check first that you\u2019re about to push the changes you want to the place you want."]}, {"name": "distutils.ccompiler.CCompiler_compile()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_compile", "type": "numpy.distutils.ccompiler.CCompiler_compile", "text": ["Compile one or more source files.", "Please refer to the Python distutils API reference for more details.", "A list of filenames", "Path to the output directory.", "A list of macro definitions.", "The directories to add to the default include file search path for this compilation only.", "Whether or not to output debug symbols in or alongside the object file(s).", "Extra pre- and post-arguments.", "A list of file names that all targets depend on.", "A list of object file names, one per source file sources.", "If compilation fails."]}, {"name": "distutils.ccompiler.CCompiler_customize()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_customize", "type": "numpy.distutils.ccompiler.CCompiler_customize", "text": ["Do any platform-specific customization of a compiler instance.", "This method calls distutils.sysconfig.customize_compiler for platform-specific customization, as well as optionally remove a flag to suppress spurious warnings in case C++ code is being compiled.", "This parameter is not used for anything.", "Whether or not C++ has to be compiled. If so (True), the \"-Wstrict-prototypes\" option is removed to prevent spurious warnings. Default is False.", "All the default options used by distutils can be extracted with:"]}, {"name": "distutils.ccompiler.CCompiler_customize_cmd()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_customize_cmd", "type": "numpy.distutils.ccompiler.CCompiler_customize_cmd", "text": ["Customize compiler using distutils command.", "An instance inheriting from distutils.cmd.Command.", "List of CCompiler commands (without 'set_') that should not be altered. Strings that are checked for are: ('include_dirs', 'define', 'undef', 'libraries', 'library_dirs',\n'rpath', 'link_objects')."]}, {"name": "distutils.ccompiler.CCompiler_cxx_compiler()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_cxx_compiler", "type": "numpy.distutils.ccompiler.CCompiler_cxx_compiler", "text": ["Return the C++ compiler.", "The C++ compiler, as a CCompiler instance."]}, {"name": "distutils.ccompiler.CCompiler_find_executables()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_find_executables", "type": "numpy.distutils.ccompiler.CCompiler_find_executables", "text": ["Does nothing here, but is called by the get_version method and can be overridden by subclasses. In particular it is redefined in the FCompiler class where more documentation can be found."]}, {"name": "distutils.ccompiler.CCompiler_get_version()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_get_version", "type": "numpy.distutils.ccompiler.CCompiler_get_version", "text": ["Return compiler version, or None if compiler is not available.", "If True, force a new determination of the version, even if the compiler already has a version attribute. Default is False.", "The list of status values returned by the version look-up process for which a version string is returned. If the status value is not in ok_status, None is returned. Default is [0].", "Version string, in the format of distutils.version.LooseVersion."]}, {"name": "distutils.ccompiler.CCompiler_object_filenames()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_object_filenames", "type": "numpy.distutils.ccompiler.CCompiler_object_filenames", "text": ["Return the name of the object files for the given source files.", "The list of paths to source files. Paths can be either relative or absolute, this is handled transparently.", "Whether to strip the directory from the returned paths. If True, the file name prepended by output_dir is returned. Default is False.", "If given, this path is prepended to the returned paths to the object files.", "The list of paths to the object files corresponding to the source files in source_filenames."]}, {"name": "distutils.ccompiler.CCompiler_show_customization()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_show_customization", "type": "numpy.distutils.ccompiler.CCompiler_show_customization", "text": ["Print the compiler customizations to stdout.", "Printing is only done if the distutils log threshold is < 2."]}, {"name": "distutils.ccompiler.CCompiler_spawn()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_spawn", "type": "numpy.distutils.ccompiler.CCompiler_spawn", "text": ["Execute a command in a sub-process.", "The command to execute.", "The text to add to the log file kept by numpy.distutils. If not given, display is equal to cmd.", "If the command failed, i.e. the exit status was not 0."]}, {"name": "distutils.ccompiler.gen_lib_options()", "path": "reference/generated/numpy.distutils.ccompiler.gen_lib_options", "type": "numpy.distutils.ccompiler.gen_lib_options", "text": []}, {"name": "distutils.ccompiler.new_compiler()", "path": "reference/generated/numpy.distutils.ccompiler.new_compiler", "type": "numpy.distutils.ccompiler.new_compiler", "text": []}, {"name": "distutils.ccompiler.replace_method()", "path": "reference/generated/numpy.distutils.ccompiler.replace_method", "type": "numpy.distutils.ccompiler.replace_method", "text": []}, {"name": "distutils.ccompiler.simple_version_match()", "path": "reference/generated/numpy.distutils.ccompiler.simple_version_match", "type": "numpy.distutils.ccompiler.simple_version_match", "text": ["Simple matching of version numbers, for use in CCompiler and FCompiler.", "A regular expression matching version numbers. Default is r'[-.\\d]+'.", "A regular expression matching patterns to skip. Default is '', in which case nothing is skipped.", "A regular expression matching the start of where to start looking for version numbers. Default is '', in which case searching is started at the beginning of the version string given to matcher.", "A function that is appropriate to use as the .version_match attribute of a CCompiler class. matcher takes a single parameter, a version string."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cache_flush()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cache_flush", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cache_flush", "text": ["method", "Force update the cache."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cc_normalize_flags", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags", "text": ["method", "Remove the conflicts that caused due gathering implied features flags.", "flags should be sorted from the lowest to the highest interest."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.conf_features", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.conf_features", "type": "NumPy.distutils.ccompiler_opt.ccompileropt.conf_features", "text": ["attribute"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.conf_features_partial()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.conf_features_partial", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.conf_features_partial", "text": ["method", "Return a dictionary of supported CPU features by the platform, and accumulate the rest of undefined options in conf_features, the returned dict has same rules and notes in class attribute conf_features, also its override any options that been set in \u2018conf_features\u2019."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_flags()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_baseline_flags", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_flags", "text": ["method", "Returns a list of final CPU baseline compiler flags"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_baseline_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names", "text": ["method", "return a list of final CPU baseline feature names"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_dispatch_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_dispatch_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_dispatch_names", "text": ["method", "return a list of final CPU dispatch feature names"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_compile()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_compile", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_compile", "text": ["method", "Wrap CCompiler.compile()"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_info()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_info", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_info", "text": ["method", "Return a tuple containing info about (platform, compiler, extra_args), required by the abstract class \u2018_CCompiler\u2019 for discovering the platform environment. This is also used as a cache factor in order to detect any changes happening from outside."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_test()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_test", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_test", "text": ["method", "Return True if \u2018CCompiler.compile()\u2019 able to compile a source file with certain flags."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_ahead()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_ahead", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_ahead", "text": ["method", "Return list of features in \u2018names\u2019 after remove any implied features and keep the origins.", "sequence of CPU feature names in uppercase."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_c_preprocessor()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_c_preprocessor", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_c_preprocessor", "text": ["method", "Generate C preprocessor definitions and include headers of a CPU feature.", "CPU feature name in uppercase.", "if > 0, align the generated strings to the right depend on number of tabs."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_detect()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_detect", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_detect", "text": ["method", "Return a list of CPU features that required to be detected sorted from the lowest to highest interest."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_get_til()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_get_til", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_get_til", "text": ["method", "same as feature_implies_c() but stop collecting implied features when feature\u2019s option that provided through parameter \u2018keyisfalse\u2019 is False, also sorting the returned features."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_implies()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_implies", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_implies", "text": ["method", "Return a set of CPU features that implied by \u2018names\u2019", "CPU feature name(s) in uppercase.", "if False(default) then the returned set will not contain any features from \u2018names\u2019. This case happens only when two features imply each other."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_implies_c()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_implies_c", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_implies_c", "text": ["method", "same as feature_implies() but combining \u2018names\u2019"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_is_exist()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_is_exist", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_is_exist", "text": ["method", "Returns True if a certain feature is exist and covered within _Config.conf_features.", "feature name in uppercase."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_names", "text": ["method", "Returns a set of CPU feature names that supported by platform and the C compiler.", "Specify certain CPU features to test it against the C compiler. if None(default), it will test all current supported features. Note: feature names must be in upper-case.", "If None(default), default compiler flags for every CPU feature will be used during the test.", "A list of C macro definitions."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_sorted()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_sorted", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_sorted", "text": ["method", "Sort a list of CPU features ordered by the lowest interest.", "sequence of supported feature names in uppercase.", "If true, the sorted features is reversed. (highest interest)"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_untied()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_untied", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_untied", "text": ["method", "same as \u2018feature_ahead()\u2019 but if both features implied each other and keep the highest interest.", "sequence of CPU feature names in uppercase."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.generate_dispatch_header()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.generate_dispatch_header", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.generate_dispatch_header", "text": ["method", "Generate the dispatch header which contains the #definitions and headers for platform-specific instruction-sets for the enabled CPU baseline and dispatch-able features.", "Its highly recommended to take a look at the generated header also the generated source files via try_dispatch() in order to get the full picture."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.is_cached()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.is_cached", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.is_cached", "text": ["method", "Returns True if the class loaded from the cache file"]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.parse_targets()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.parse_targets", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.parse_targets", "text": ["method", "Fetch and parse configuration statements that required for defining the targeted CPU features, statements should be declared in the top of source in between C comment and start with a special mark @targets.", "Configuration statements are sort of keywords representing CPU features names, group of statements and policies, combined together to determine the required optimization.", "the path of C source file."]}, {"name": "distutils.ccompiler_opt.CCompilerOpt.try_dispatch()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.try_dispatch", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.try_dispatch", "text": ["method", "Compile one or more dispatch-able sources and generates object files, also generates abstract C config headers and macros that used later for the final runtime dispatching process.", "The mechanism behind it is to takes each source file that specified in \u2018sources\u2019 and branching it into several files depend on special configuration statements that must be declared in the top of each source which contains targeted CPU features, then it compiles every branched source with the proper compiler flags.", "Must be a list of dispatch-able sources file paths, and configuration statements must be declared inside each file.", "Path of parent directory for the generated headers and wrapped sources. If None(default) the files will generated in-place.", "Distutils CCompiler instance to be used for compilation. If None (default), the provided instance during the initialization will be used instead.", "Arguments to pass on to the CCompiler.compile()", "Raises by CCompiler.compile() on compiling failure.", "Some errors during checking the sanity of configuration statements.", "See also", "Parsing the configuration statements of dispatch-able sources."]}, {"name": "distutils.ccompiler_opt.new_ccompiler_opt()", "path": "reference/generated/numpy.distutils.ccompiler_opt.new_ccompiler_opt", "type": "numpy.distutils.ccompiler_opt.new_ccompiler_opt", "text": ["Create a new instance of \u2018CCompilerOpt\u2019 and generate the dispatch header which contains the #definitions and headers of platform-specific instruction-sets for the enabled CPU baseline and dispatch-able features.", "path of the dispatch header"]}, {"name": "distutils.cpuinfo.cpu", "path": "reference/generated/numpy.distutils.cpuinfo.cpu", "type": "numpy.distutils.cpuinfo.cpu", "text": []}, {"name": "distutils.exec_command.exec_command()", "path": "reference/generated/numpy.distutils.exec_command.exec_command", "type": "numpy.distutils.exec_command.exec_command", "text": ["Return (status,output) of executed command.", "Deprecated since version 1.17: Use subprocess.Popen instead", "A concatenated string of executable and arguments.", "Before running command cd execute_in and after cd -.", "If True, execute sh -c command. Default None (True)", "If True use tee. Default None (True)", "Both stdout and stderr messages.", "On NT, DOS systems the returned status is correct for external commands. Wild cards will not work for non-posix systems or when use_shell=0."]}, {"name": "distutils.exec_command.filepath_from_subprocess_output()", "path": "reference/generated/numpy.distutils.exec_command.filepath_from_subprocess_output", "type": "numpy.distutils.exec_command.filepath_from_subprocess_output", "text": ["Convert bytes in the encoding used by a subprocess into a filesystem-appropriate str.", "Inherited from exec_command, and possibly incorrect."]}, {"name": "distutils.exec_command.find_executable()", "path": "reference/generated/numpy.distutils.exec_command.find_executable", "type": "numpy.distutils.exec_command.find_executable", "text": ["Return full path of a executable or None.", "Symbolic links are not followed."]}, {"name": "distutils.exec_command.forward_bytes_to_stdout()", "path": "reference/generated/numpy.distutils.exec_command.forward_bytes_to_stdout", "type": "numpy.distutils.exec_command.forward_bytes_to_stdout", "text": ["Forward bytes from a subprocess call to the console, without attempting to decode them.", "The assumption is that the subprocess call already returned bytes in a suitable encoding."]}, {"name": "distutils.exec_command.get_pythonexe()", "path": "reference/generated/numpy.distutils.exec_command.get_pythonexe", "type": "numpy.distutils.exec_command.get_pythonexe", "text": []}, {"name": "distutils.exec_command.temp_file_name()", "path": "reference/generated/numpy.distutils.exec_command.temp_file_name", "type": "numpy.distutils.exec_command.temp_file_name", "text": []}, {"name": "distutils.log.set_verbosity()", "path": "reference/generated/numpy.distutils.log.set_verbosity", "type": "numpy.distutils.log.set_verbosity", "text": []}, {"name": "distutils.system_info.get_info()", "path": "reference/generated/numpy.distutils.system_info.get_info", "type": "numpy.distutils.system_info.get_info", "text": ["0 - do nothing 1 - display warning message 2 - raise error"]}, {"name": "distutils.system_info.get_standard_file()", "path": "reference/generated/numpy.distutils.system_info.get_standard_file", "type": "numpy.distutils.system_info.get_standard_file", "text": ["Returns a list of files named \u2018fname\u2019 from 1) System-wide directory (directory-location of this module) 2) Users HOME directory (os.environ[\u2018HOME\u2019]) 3) Local directory"]}, {"name": "double npy_half_to_double()", "path": "reference/c-api/coremath#c.npy_half_to_double", "type": "NumPy core libraries", "text": ["Converts a half-precision float to a double-precision float."]}, {"name": "double npy_spacing()", "path": "reference/c-api/coremath#c.npy_spacing", "type": "NumPy core libraries", "text": ["This is a function equivalent to Fortran intrinsic. Return distance between x and next representable floating point value from x, e.g. spacing(1) == eps. spacing of nan and +/- inf return nan. Single and extended precisions are available with suffix f and l.", "New in version 1.4.0."]}, {"name": "double PyArray_GetPriority()", "path": "reference/c-api/array#c.PyArray_GetPriority", "type": "Array API", "text": ["Return the __array_priority__ attribute (converted to a double) of obj or def if no attribute of that name exists. Fast returns that avoid the attribute lookup are provided for objects of type PyArray_Type."]}, {"name": "double random_beta()", "path": "reference/random/c-api#c.random_beta", "type": "C API for random", "text": []}, {"name": "double random_chisquare()", "path": "reference/random/c-api#c.random_chisquare", "type": "C API for random", "text": []}, {"name": "double random_exponential()", "path": "reference/random/c-api#c.random_exponential", "type": "C API for random", "text": []}, {"name": "double random_f()", "path": "reference/random/c-api#c.random_f", "type": "C API for random", "text": []}, {"name": "double random_gamma()", "path": "reference/random/c-api#c.random_gamma", "type": "C API for random", "text": []}, {"name": "double random_gumbel()", "path": "reference/random/c-api#c.random_gumbel", "type": "C API for random", "text": []}, {"name": "double random_laplace()", "path": "reference/random/c-api#c.random_laplace", "type": "C API for random", "text": []}, {"name": "double random_logistic()", "path": "reference/random/c-api#c.random_logistic", "type": "C API for random", "text": []}, {"name": "double random_lognormal()", "path": "reference/random/c-api#c.random_lognormal", "type": "C API for random", "text": []}, {"name": "double random_noncentral_chisquare()", "path": "reference/random/c-api#c.random_noncentral_chisquare", "type": "C API for random", "text": []}, {"name": "double random_noncentral_f()", "path": "reference/random/c-api#c.random_noncentral_f", "type": "C API for random", "text": []}, {"name": "double random_normal()", "path": "reference/random/c-api#c.random_normal", "type": "C API for random", "text": []}, {"name": "double random_pareto()", "path": "reference/random/c-api#c.random_pareto", "type": "C API for random", "text": []}, {"name": "double random_power()", "path": "reference/random/c-api#c.random_power", "type": "C API for random", "text": []}, {"name": "double random_rayleigh()", "path": "reference/random/c-api#c.random_rayleigh", "type": "C API for random", "text": []}, {"name": "double random_standard_cauchy()", "path": "reference/random/c-api#c.random_standard_cauchy", "type": "C API for random", "text": []}, {"name": "double random_standard_exponential()", "path": "reference/random/c-api#c.random_standard_exponential", "type": "C API for random", "text": []}, {"name": "double random_standard_gamma()", "path": "reference/random/c-api#c.random_standard_gamma", "type": "C API for random", "text": []}, {"name": "double random_standard_normal()", "path": "reference/random/c-api#c.random_standard_normal", "type": "C API for random", "text": []}, {"name": "double random_standard_t()", "path": "reference/random/c-api#c.random_standard_t", "type": "C API for random", "text": []}, {"name": "double random_standard_uniform()", "path": "reference/random/c-api#c.random_standard_uniform", "type": "C API for random", "text": []}, {"name": "double random_triangular()", "path": "reference/random/c-api#c.random_triangular", "type": "C API for random", "text": []}, {"name": "double random_uniform()", "path": "reference/random/c-api#c.random_uniform", "type": "C API for random", "text": []}, {"name": "double random_vonmises()", "path": "reference/random/c-api#c.random_vonmises", "type": "C API for random", "text": []}, {"name": "double random_wald()", "path": "reference/random/c-api#c.random_wald", "type": "C API for random", "text": []}, {"name": "double random_weibull()", "path": "reference/random/c-api#c.random_weibull", "type": "C API for random", "text": []}, {"name": "DoxyLimbo()", "path": "dev/howto-docs#_CPPv4N9DoxyLimbo9DoxyLimboERK9DoxyLimboI2Tp1NE", "type": "Development", "text": ["Set Default behavior for copy the limbo. "]}, {"name": "dtype object", "path": "reference/arrays.dtypes", "type": "Data type objects ( \n      \n       dtype\n      \n      )", "text": ["A data type object (an instance of numpy.dtype class) describes how the bytes in the fixed-size block of memory corresponding to an array item should be interpreted. It describes the following aspects of the data:", "If the data type is structured data type, an aggregate of other data types, (e.g., describing an array item consisting of an integer and a float),", "To describe the type of scalar data, there are several built-in scalar types in NumPy for various precision of integers, floating-point numbers, etc. An item extracted from an array, e.g., by indexing, will be a Python object whose type is the scalar type associated with the data type of the array.", "Note that the scalar types are not dtype objects, even though they can be used in place of one whenever a data type specification is needed in NumPy.", "Structured data types are formed by creating a data type whose field contain other data types. Each field has a name by which it can be accessed. The parent data type should be of sufficient size to contain all its fields; the parent is nearly always based on the void type which allows an arbitrary item size. Structured data types may also contain nested structured sub-array data types in their fields.", "Finally, a data type can describe items that are themselves arrays of items of another data type. These sub-arrays must, however, be of a fixed size.", "If an array is created using a data-type describing a sub-array, the dimensions of the sub-array are appended to the shape of the array when the array is created. Sub-arrays in a field of a structured type behave differently, see Field access.", "Sub-arrays always have a C-contiguous memory layout.", "A simple data type containing a 32-bit big-endian integer: (see Specifying and constructing data types for details on construction)", "The corresponding array scalar type is int32.", "A structured data type containing a 16-character string (in field \u2018name\u2019) and a sub-array of two 64-bit floating-point number (in field \u2018grades\u2019):", "Items of an array of this data type are wrapped in an array scalar type that also has two fields:", "Whenever a data-type is required in a NumPy function or method, either a dtype object or something that can be converted to one can be supplied. Such conversions are done by the dtype constructor:", "dtype(dtype[, align, copy])", "Create a data type object.", "What can be converted to a data-type object is described below:", "Used as-is.", "The default data type: float_.", "The 24 built-in array scalar type objects all convert to an associated data-type object. This is true for their sub-classes as well.", "Note that not all data-type information can be supplied with a type-object: for example, flexible data-types have a default itemsize of 0, and require an explicitly given size to be useful.", "The generic hierarchical type objects convert to corresponding type objects according to the associations:", "number, inexact, floating", "float", "complexfloating", "cfloat", "integer, signedinteger", "int_", "unsignedinteger", "uint", "character", "string", "generic, flexible", "void", "Deprecated since version 1.19: This conversion of generic scalar types is deprecated. This is because it can be unexpected in a context such as arr.astype(dtype=np.floating), which casts an array of float32 to an array of float64, even though float32 is a subdtype of np.floating.", "Several python types are equivalent to a corresponding array scalar when used to generate a dtype object:", "int", "int_", "bool", "bool_", "float", "float_", "complex", "cfloat", "bytes", "bytes_", "str", "str_", "buffer", "void", "(all others)", "object_", "Note that str refers to either null terminated bytes or unicode strings depending on the Python version. In code targeting both Python 2 and 3 np.unicode_ should be used as a dtype for strings. See Note on string types.", "Note", "All other types map to object_ for convenience. Code should expect that such types may map to a specific (new) dtype in the future.", "Any type object with a dtype attribute: The attribute will be accessed and used directly. The attribute must return something that is convertible into a dtype object.", "Several kinds of strings can be converted. Recognized strings can be prepended with '>' (big-endian), '<' (little-endian), or '=' (hardware-native, the default), to specify the byte order.", "Each built-in data-type has a character code (the updated Numeric typecodes), that uniquely identifies it.", "The first character specifies the kind of data and the remaining characters specify the number of bytes per item, except for Unicode, where it is interpreted as the number of characters. The item size must correspond to an existing type, or an error will be raised. The supported kinds are", "'?'", "boolean", "'b'", "(signed) byte", "'B'", "unsigned byte", "'i'", "(signed) integer", "'u'", "unsigned integer", "'f'", "floating-point", "'c'", "complex-floating point", "'m'", "timedelta", "'M'", "datetime", "'O'", "(Python) objects", "'S', 'a'", "zero-terminated bytes (not recommended)", "'U'", "Unicode string", "'V'", "raw data (void)", "Note on string types", "For backward compatibility with Python 2 the S and a typestrings remain zero-terminated bytes and numpy.string_ continues to alias numpy.bytes_. To use actual strings in Python 3 use U or numpy.str_. For signed bytes that do not need zero-termination b or i1 can be used.", "A short-hand notation for specifying the format of a structured data type is a comma-separated string of basic formats.", "A basic format in this context is an optional shape specifier followed by an array-protocol type string. Parenthesis are required on the shape if it has more than one dimension. NumPy allows a modification on the format in that any string that can uniquely identify the type can be used to specify the data-type in a field. The generated data-type fields are named 'f0', 'f1', \u2026, 'f<N-1>' where N (>1) is the number of comma-separated basic formats in the string. If the optional shape specifier is provided, then the data-type for the corresponding field describes a sub-array.", "Any string in numpy.sctypeDict.keys():", "The first argument must be an object that is converted to a zero-sized flexible data-type object, the second argument is an integer providing the desired itemsize.", "The first argument is any object that can be converted into a fixed-size data-type object. The second argument is the desired shape of this type. If the shape parameter is 1, then the data-type object used to be equivalent to fixed dtype. This behaviour is deprecated since NumPy 1.17 and will raise an error in the future. If shape is a tuple, then the new dtype defines a sub-array of the given shape.", "obj should be a list of fields where each field is described by a tuple of length 2 or 3. (Equivalent to the descr item in the __array_interface__ attribute.)", "The first element, field_name, is the field name (if this is '' then a standard field name, 'f#', is assigned). The field name may also be a 2-tuple of strings where the first string is either a \u201ctitle\u201d (which may be any string or unicode string) or meta-data for the field which can be any object, and the second string is the \u201cname\u201d which must be a valid Python identifier.", "The second element, field_dtype, can be anything that can be interpreted as a data-type.", "The optional third element field_shape contains the shape if this field represents an array of the data-type in the second element. Note that a 3-tuple with a third argument equal to 1 is equivalent to a 2-tuple.", "This style does not accept align in the dtype constructor as it is assumed that all of the memory is accounted for by the array interface description.", "Data-type with fields big (big-endian 32-bit integer) and little (little-endian 32-bit integer):", "Data-type with fields R, G, B, A, each being an unsigned 8-bit integer:", "This style has two required and three optional keys. The names and formats keys are required. Their respective values are equal-length lists with the field names and the field formats. The field names must be strings and the field formats can be any object accepted by dtype constructor.", "When the optional keys offsets and titles are provided, their values must each be lists of the same length as the names and formats lists. The offsets value is a list of byte offsets (limited to ctypes.c_int) for each field, while the titles value is a list of titles for each field (None can be used if no title is desired for that field). The titles can be any object, but when a str object will add another entry to the fields dictionary keyed by the title and referencing the same field tuple which will contain the title as an additional tuple member.", "The itemsize key allows the total size of the dtype to be set, and must be an integer large enough so all the fields are within the dtype. If the dtype being constructed is aligned, the itemsize must also be divisible by the struct alignment. Total dtype itemsize is limited to ctypes.c_int.", "Data type with fields r, g, b, a, each being an 8-bit unsigned integer:", "Data type with fields r and b (with the given titles), both being 8-bit unsigned integers, the first at byte position 0 from the start of the field and the second at position 2:", "This usage is discouraged, because it is ambiguous with the other dict-based construction method. If you have a field called \u2018names\u2019 and a field called \u2018formats\u2019 there will be a conflict.", "This style allows passing in the fields attribute of a data-type object.", "obj should contain string or unicode keys that refer to (data-type, offset) or (data-type, offset, title) tuples.", "Data type containing field col1 (10-character string at byte position 0), col2 (32-bit float at byte position 10), and col3 (integers at byte position 14):", "In NumPy 1.7 and later, this form allows base_dtype to be interpreted as a structured dtype. Arrays created with this dtype will have underlying dtype base_dtype but will have fields and flags taken from new_dtype. This is useful for creating custom structured dtypes, as done in record arrays.", "This form also makes it possible to specify struct dtypes with overlapping fields, functioning like the \u2018union\u2019 type in C. This usage is discouraged, however, and the union mechanism is preferred.", "Both arguments must be convertible to data-type objects with the same total size.", "32-bit integer, whose first two bytes are interpreted as an integer via field real, and the following two bytes via field imag.", "32-bit integer, which is interpreted as consisting of a sub-array of shape (4,) containing 8-bit integers:", "32-bit integer, containing fields r, g, b, a that interpret the 4 bytes in the integer as four unsigned integers:", "NumPy data type descriptions are instances of the dtype class.", "The type of the data is described by the following dtype attributes:", "dtype.type", "dtype.kind", "A character code (one of 'biufcmMOSUV') identifying the general kind of data.", "dtype.char", "A unique character code for each of the 21 different built-in types.", "dtype.num", "A unique number for each of the 21 different built-in types.", "dtype.str", "The array-protocol typestring of this data-type object.", "Size of the data is in turn described by:", "dtype.name", "A bit-width name for this data-type.", "dtype.itemsize", "The element size of this data-type object.", "Endianness of this data:", "dtype.byteorder", "A character indicating the byte-order of this data-type object.", "Information about sub-data-types in a structured data type:", "dtype.fields", "Dictionary of named fields defined for this data type, or None.", "dtype.names", "Ordered list of field names, or None if there are no fields.", "For data types that describe sub-arrays:", "dtype.subdtype", "Tuple (item_dtype, shape) if this dtype describes a sub-array, and None otherwise.", "dtype.shape", "Shape tuple of the sub-array if this data type describes a sub-array, and () otherwise.", "Attributes providing additional information:", "dtype.hasobject", "Boolean indicating whether this dtype contains any reference-counted objects in any fields or sub-dtypes.", "dtype.flags", "Bit-flags describing how this data type is to be interpreted.", "dtype.isbuiltin", "Integer indicating how this dtype relates to the built-in dtypes.", "dtype.isnative", "Boolean indicating whether the byte order of this dtype is native to the platform.", "dtype.descr", "__array_interface__ description of the data-type.", "dtype.alignment", "The required alignment (bytes) of this data-type according to the compiler.", "dtype.base", "Returns dtype for the base element of the subarrays, regardless of their dimension or shape.", "Metadata attached by the user:", "dtype.metadata", "Either None or a readonly dictionary of metadata (mappingproxy).", "Data types have the following method for changing the byte order:", "dtype.newbyteorder([new_order])", "Return a new dtype with a different byte order.", "The following methods implement the pickle protocol:", "dtype.__reduce__", "Helper for pickle.", "dtype.__setstate__", "Utility method for typing:", "dtype.__class_getitem__(item, /)", "Return a parametrized wrapper around the dtype type.", "Comparison operations:", "dtype.__ge__(value, /)", "Return self>=value.", "dtype.__gt__(value, /)", "Return self>value.", "dtype.__le__(value, /)", "Return self<=value.", "dtype.__lt__(value, /)", "Return self<value."]}, {"name": "dtype.__class_getitem__()", "path": "reference/generated/numpy.dtype.__class_getitem__", "type": "numpy.dtype.__class_getitem__", "text": ["method", "Return a parametrized wrapper around the dtype type.", "New in version 1.22.", "A parametrized dtype type.", "See also", "Type hinting generics in standard collections.", "This method is only available for python 3.9 and later."]}, {"name": "dtype.__ge__()", "path": "reference/generated/numpy.dtype.__ge__", "type": "numpy.dtype.__ge__", "text": ["method", "Return self>=value."]}, {"name": "dtype.__gt__()", "path": "reference/generated/numpy.dtype.__gt__", "type": "numpy.dtype.__gt__", "text": ["method", "Return self>value."]}, {"name": "dtype.__le__()", "path": "reference/generated/numpy.dtype.__le__", "type": "numpy.dtype.__le__", "text": ["method", "Return self<=value."]}, {"name": "dtype.__lt__()", "path": "reference/generated/numpy.dtype.__lt__", "type": "numpy.dtype.__lt__", "text": ["method", "Return self<value."]}, {"name": "dtype.__reduce__()", "path": "reference/generated/numpy.dtype.__reduce__", "type": "numpy.dtype.__reduce__", "text": ["method", "Helper for pickle."]}, {"name": "dtype.__setstate__()", "path": "reference/generated/numpy.dtype.__setstate__", "type": "numpy.dtype.__setstate__", "text": ["method"]}, {"name": "dtype.alignment", "path": "reference/generated/numpy.dtype.alignment", "type": "numpy.dtype.alignment", "text": ["attribute", "The required alignment (bytes) of this data-type according to the compiler.", "More information is available in the C-API section of the manual."]}, {"name": "dtype.base", "path": "reference/generated/numpy.dtype.base", "type": "numpy.dtype.base", "text": ["attribute", "Returns dtype for the base element of the subarrays, regardless of their dimension or shape.", "See also"]}, {"name": "dtype.byteorder", "path": "reference/generated/numpy.dtype.byteorder", "type": "numpy.dtype.byteorder", "text": ["attribute", "A character indicating the byte-order of this data-type object.", "One of:", "\u2018=\u2019", "native", "\u2018<\u2019", "little-endian", "\u2018>\u2019", "big-endian", "\u2018|\u2019", "not applicable", "All built-in data-type objects have byteorder either \u2018=\u2019 or \u2018|\u2019."]}, {"name": "dtype.char", "path": "reference/generated/numpy.dtype.char", "type": "numpy.dtype.char", "text": ["attribute", "A unique character code for each of the 21 different built-in types."]}, {"name": "dtype.descr", "path": "reference/generated/numpy.dtype.descr", "type": "numpy.dtype.descr", "text": ["attribute", "__array_interface__ description of the data-type.", "The format is that required by the \u2018descr\u2019 key in the __array_interface__ attribute.", "Warning: This attribute exists specifically for __array_interface__, and passing it directly to np.dtype will not accurately reconstruct some dtypes (e.g., scalar and subarray dtypes)."]}, {"name": "dtype.fields", "path": "reference/generated/numpy.dtype.fields", "type": "numpy.dtype.fields", "text": ["attribute", "Dictionary of named fields defined for this data type, or None.", "The dictionary is indexed by keys that are the names of the fields. Each entry in the dictionary is a tuple fully describing the field:", "Offset is limited to C int, which is signed and usually 32 bits. If present, the optional title can be any object (if it is a string or unicode then it will also be a key in the fields dictionary, otherwise it\u2019s meta-data). Notice also that the first two elements of the tuple can be passed directly as arguments to the ndarray.getfield and ndarray.setfield methods.", "See also"]}, {"name": "dtype.flags", "path": "reference/generated/numpy.dtype.flags", "type": "numpy.dtype.flags", "text": ["attribute", "Bit-flags describing how this data type is to be interpreted.", "Bit-masks are in numpy.core.multiarray as the constants ITEM_HASOBJECT, LIST_PICKLE, ITEM_IS_POINTER, NEEDS_INIT, NEEDS_PYAPI, USE_GETITEM, USE_SETITEM. A full explanation of these flags is in C-API documentation; they are largely useful for user-defined data-types.", "The following example demonstrates that operations on this particular dtype requires Python C-API."]}, {"name": "dtype.hasobject", "path": "reference/generated/numpy.dtype.hasobject", "type": "numpy.dtype.hasobject", "text": ["attribute", "Boolean indicating whether this dtype contains any reference-counted objects in any fields or sub-dtypes.", "Recall that what is actually in the ndarray memory representing the Python object is the memory address of that object (a pointer). Special handling may be required, and this attribute is useful for distinguishing data types that may contain arbitrary Python objects and data-types that won\u2019t."]}, {"name": "dtype.isalignedstruct", "path": "reference/generated/numpy.dtype.isalignedstruct", "type": "Data type objects", "text": ["attribute", "Boolean indicating whether the dtype is a struct which maintains field alignment. This flag is sticky, so when combining multiple structs together, it is preserved and produces new dtypes which are also aligned."]}, {"name": "dtype.isbuiltin", "path": "reference/generated/numpy.dtype.isbuiltin", "type": "numpy.dtype.isbuiltin", "text": ["attribute", "Integer indicating how this dtype relates to the built-in dtypes.", "Read-only.", "0", "if this is a structured array type, with fields", "1", "if this is a dtype compiled into numpy (such as ints, floats etc)", "2", "if the dtype is for a user-defined numpy type A user-defined type uses the numpy C-API machinery to extend numpy to handle a new array type. See User-defined data-types in the NumPy manual."]}, {"name": "dtype.isnative", "path": "reference/generated/numpy.dtype.isnative", "type": "numpy.dtype.isnative", "text": ["attribute", "Boolean indicating whether the byte order of this dtype is native to the platform."]}, {"name": "dtype.itemsize", "path": "reference/generated/numpy.dtype.itemsize", "type": "numpy.dtype.itemsize", "text": ["attribute", "The element size of this data-type object.", "For 18 of the 21 types this number is fixed by the data-type. For the flexible data-types, this number can be anything."]}, {"name": "dtype.kind", "path": "reference/generated/numpy.dtype.kind", "type": "numpy.dtype.kind", "text": ["attribute", "A character code (one of \u2018biufcmMOSUV\u2019) identifying the general kind of data.", "b", "boolean", "i", "signed integer", "u", "unsigned integer", "f", "floating-point", "c", "complex floating-point", "m", "timedelta", "M", "datetime", "O", "object", "S", "(byte-)string", "U", "Unicode", "V", "void"]}, {"name": "dtype.metadata", "path": "reference/generated/numpy.dtype.metadata", "type": "numpy.dtype.metadata", "text": ["attribute", "Either None or a readonly dictionary of metadata (mappingproxy).", "The metadata field can be set using any dictionary at data-type creation. NumPy currently has no uniform approach to propagating metadata; although some array operations preserve it, there is no guarantee that others will.", "Warning", "Although used in certain projects, this feature was long undocumented and is not well supported. Some aspects of metadata propagation are expected to change in the future.", "Adding arrays with identical datatypes currently preserves the metadata:", "But if the arrays have different dtype metadata, the metadata may be dropped:"]}, {"name": "dtype.name", "path": "reference/generated/numpy.dtype.name", "type": "numpy.dtype.name", "text": ["attribute", "A bit-width name for this data-type.", "Un-sized flexible data-type objects do not have this attribute."]}, {"name": "dtype.names", "path": "reference/generated/numpy.dtype.names", "type": "numpy.dtype.names", "text": ["attribute", "Ordered list of field names, or None if there are no fields.", "The names are ordered according to increasing byte offset. This can be used, for example, to walk through all of the named fields in offset order."]}, {"name": "dtype.ndim", "path": "reference/generated/numpy.dtype.ndim", "type": "Data type objects", "text": ["attribute", "Number of dimensions of the sub-array if this data type describes a sub-array, and 0 otherwise.", "New in version 1.13.0."]}, {"name": "dtype.newbyteorder()", "path": "reference/generated/numpy.dtype.newbyteorder", "type": "numpy.dtype.newbyteorder", "text": ["method", "Return a new dtype with a different byte order.", "Changes are also made in all fields and sub-arrays of the data type.", "Byte order to force; a value from the byte order specifications below. The default value (\u2018S\u2019) results in swapping the current byte order. new_order codes can be any of:", "New dtype object with the given change to the byte order.", "Changes are also made in all fields and sub-arrays of the data type."]}, {"name": "dtype.num", "path": "reference/generated/numpy.dtype.num", "type": "numpy.dtype.num", "text": ["attribute", "A unique number for each of the 21 different built-in types.", "These are roughly ordered from least-to-most precision."]}, {"name": "dtype.shape", "path": "reference/generated/numpy.dtype.shape", "type": "numpy.dtype.shape", "text": ["attribute", "Shape tuple of the sub-array if this data type describes a sub-array, and () otherwise."]}, {"name": "dtype.str", "path": "reference/generated/numpy.dtype.str", "type": "numpy.dtype.str", "text": ["attribute", "The array-protocol typestring of this data-type object."]}, {"name": "dtype.subdtype", "path": "reference/generated/numpy.dtype.subdtype", "type": "numpy.dtype.subdtype", "text": ["attribute", "Tuple (item_dtype, shape) if this dtype describes a sub-array, and None otherwise.", "The shape is the fixed shape of the sub-array described by this data type, and item_dtype the data type of the array.", "If a field whose dtype object has this attribute is retrieved, then the extra dimensions implied by shape are tacked on to the end of the retrieved array.", "See also"]}, {"name": "dtype.type", "path": "reference/generated/numpy.dtype.type", "type": "numpy.dtype.type", "text": ["attribute"]}, {"name": "Elementary Function", "path": "reference/c-api/generalized-ufuncs", "type": "Generalized Universal Function API", "text": ["There is a general need for looping over not only functions on scalars but also over functions on vectors (or arrays). This concept is realized in NumPy by generalizing the universal functions (ufuncs). In regular ufuncs, the elementary function is limited to element-by-element operations, whereas the generalized version (gufuncs) supports \u201csub-array\u201d by \u201csub-array\u201d operations. The Perl vector library PDL provides a similar functionality and its terms are re-used in the following.", "Each generalized ufunc has information associated with it that states what the \u201ccore\u201d dimensionality of the inputs is, as well as the corresponding dimensionality of the outputs (the element-wise ufuncs have zero core dimensions). The list of the core dimensions for all arguments is called the \u201csignature\u201d of a ufunc. For example, the ufunc numpy.add has signature (),()->() defining two scalar inputs and one scalar output.", "Another example is the function inner1d(a, b) with a signature of (i),(i)->(). This applies the inner product along the last axis of each input, but keeps the remaining indices intact. For example, where a is of shape (3, 5, N) and b is of shape (5, N), this will return an output of shape (3,5). The underlying elementary function is called 3 * 5 times. In the signature, we specify one core dimension (i) for each input and zero core dimensions () for the output, since it takes two 1-d arrays and returns a scalar. By using the same name i, we specify that the two corresponding dimensions should be of the same size.", "The dimensions beyond the core dimensions are called \u201cloop\u201d dimensions. In the above example, this corresponds to (3, 5).", "The signature determines how the dimensions of each input/output array are split into core and loop dimensions:", "Typically, the size of all core dimensions in an output will be determined by the size of a core dimension with the same label in an input array. This is not a requirement, and it is possible to define a signature where a label comes up for the first time in an output, although some precautions must be taken when calling such a function. An example would be the function euclidean_pdist(a), with signature (n,d)->(p), that given an array of n d-dimensional vectors, computes all unique pairwise Euclidean distances among them. The output dimension p must therefore be equal to n * (n - 1) / 2, but it is the caller\u2019s responsibility to pass in an output array of the right size. If the size of a core dimension of an output cannot be determined from a passed in input or output array, an error will be raised.", "Note: Prior to NumPy 1.10.0, less strict checks were in place: missing core dimensions were created by prepending 1\u2019s to the shape as necessary, core dimensions with the same label were broadcast together, and undetermined dimensions were created with size 1.", "Each ufunc consists of an elementary function that performs the most basic operation on the smallest portion of array arguments (e.g. adding two numbers is the most basic operation in adding two arrays). The ufunc applies the elementary function multiple times on different parts of the arrays. The input/output of elementary functions can be vectors; e.g., the elementary function of inner1d takes two vectors as input.", "A signature is a string describing the input/output dimensions of the elementary function of a ufunc. See section below for more details.", "The dimensionality of each input/output of an elementary function is defined by its core dimensions (zero core dimensions correspond to a scalar input/output). The core dimensions are mapped to the last dimensions of the input/output arrays.", "A dimension name represents a core dimension in the signature. Different dimensions may share a name, indicating that they are of the same size.", "A dimension index is an integer representing a dimension name. It enumerates the dimension names according to the order of the first occurrence of each name in the signature.", "The signature defines \u201ccore\u201d dimensionality of input and output variables, and thereby also defines the contraction of the dimensions. The signature is represented by a string of the following format:", "The formal syntax of signatures is as follows:", "Notes:", "Here are some examples of signatures:", "name", "signature", "common usage", "add", "(),()->()", "binary ufunc", "sum1d", "(i)->()", "reduction", "inner1d", "(i),(i)->()", "vector-vector multiplication", "matmat", "(m,n),(n,p)->(m,p)", "matrix multiplication", "vecmat", "(n),(n,p)->(p)", "vector-matrix multiplication", "matvec", "(m,n),(n)->(m)", "matrix-vector multiplication", "matmul", "(m?,n),(n,p?)->(m?,p?)", "combination of the four above", "outer_inner", "(i,t),(j,t)->(i,j)", "inner over the last dimension, outer over the second to last, and loop/broadcast over the rest.", "cross1d", "(3),(3)->(3)", "cross product where the last dimension is frozen and must be 3", "The last is an instance of freezing a core dimension and can be used to improve ufunc performance", "The current interface remains unchanged, and PyUFunc_FromFuncAndData can still be used to implement (specialized) ufuncs, consisting of scalar elementary functions.", "One can use PyUFunc_FromFuncAndDataAndSignature to declare a more general ufunc. The argument list is the same as PyUFunc_FromFuncAndData, with an additional argument specifying the signature as C string.", "Furthermore, the callback function is of the same type as before, void (*foo)(char **args, intp *dimensions, intp *steps, void *func). When invoked, args is a list of length nargs containing the data of all input/output arguments. For a scalar elementary function, steps is also of length nargs, denoting the strides used for the arguments. dimensions is a pointer to a single integer defining the size of the axis to be looped over.", "For a non-trivial signature, dimensions will also contain the sizes of the core dimensions as well, starting at the second entry. Only one size is provided for each unique dimension name and the sizes are given according to the first occurrence of a dimension name in the signature.", "The first nargs elements of steps remain the same as for scalar ufuncs. The following elements contain the strides of all core dimensions for all arguments in order.", "For example, consider a ufunc with signature (i,j),(i)->(). In this case, args will contain three pointers to the data of the input/output arrays a, b, c. Furthermore, dimensions will be [N, I, J] to define the size of N of the loop and the sizes I and J for the core dimensions i and j. Finally, steps will be [a_N, b_N, c_N, a_i, a_j, b_i], containing all necessary strides."]}, {"name": "enum NPY_CASTING", "path": "reference/c-api/array#c.NPY_CASTING", "type": "Array API", "text": ["New in version 1.6.", "An enumeration type indicating how permissive data conversions should be. This is used by the iterator added in NumPy 1.6, and is intended to be used more broadly in a future version.", "Only allow identical types.", "Allow identical and casts involving byte swapping.", "Only allow casts which will not cause values to be rounded, truncated, or otherwise changed.", "Allow any safe casts, and casts between types of the same kind. For example, float64 -> float32 is permitted with this rule.", "Allow any cast, no matter what kind of data loss may occur."]}, {"name": "enum NPY_CLIPMODE", "path": "reference/c-api/array#c.NPY_CLIPMODE", "type": "Array API", "text": ["A variable type indicating the kind of clipping that should be applied in certain functions.", "The default for most operations, raises an exception if an index is out of bounds.", "Clips an index to the valid range if it is out of bounds.", "Wraps an index to the valid range if it is out of bounds."]}, {"name": "enum NPY_ORDER", "path": "reference/c-api/array#c.NPY_ORDER", "type": "Array API", "text": ["An enumeration type indicating the element order that an array should be interpreted in. When a brand new array is created, generally only NPY_CORDER and NPY_FORTRANORDER are used, whereas when one or more inputs are provided, the order can be based on them.", "Fortran order if all the inputs are Fortran, C otherwise.", "C order.", "Fortran order.", "An order as close to the order of the inputs as possible, even if the input is in neither C nor Fortran order."]}, {"name": "enum NPY_SCALARKIND", "path": "reference/c-api/array#c.NPY_SCALARKIND", "type": "Array API", "text": ["A special variable type indicating the number of \u201ckinds\u201d of scalars distinguished in determining scalar-coercion rules. This variable can take on the values:", "Defined to be the number of scalar kinds (not including NPY_NOSCALAR)."]}, {"name": "enum NPY_SEARCHSIDE", "path": "reference/c-api/array#c.NPY_SEARCHSIDE", "type": "Array API", "text": ["A variable type indicating whether the index returned should be that of the first suitable location (if NPY_SEARCHLEFT) or of the last (if NPY_SEARCHRIGHT)."]}, {"name": "enum NPY_SELECTKIND", "path": "reference/c-api/array#c.NPY_SELECTKIND", "type": "Array API", "text": ["A variable type indicating the selection algorithm being used."]}, {"name": "enumerator NPY_BOOL", "path": "reference/c-api/dtype#c.NPY_BOOL", "type": "Data Type API", "text": ["The enumeration value for the boolean type, stored as one byte. It may only be set to the values 0 and 1."]}, {"name": "enumerator NPY_BOOL_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_BOOL_SCALAR", "type": "Array API", "text": []}, {"name": "enumerator NPY_BYTE", "path": "reference/c-api/dtype#c.NPY_BYTE", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_CDOUBLE", "path": "reference/c-api/dtype#c.NPY_CDOUBLE", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_CFLOAT", "path": "reference/c-api/dtype#c.NPY_CFLOAT", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_CLIP", "path": "reference/c-api/array#c.NPY_CLIPMODE.NPY_CLIP", "type": "Array API", "text": ["Clips an index to the valid range if it is out of bounds."]}, {"name": "enumerator NPY_CLONGDOUBLE", "path": "reference/c-api/dtype#c.NPY_CLONGDOUBLE", "type": "Data Type API", "text": ["The enumeration value for a platform-specific complex floating point type which is made up of two NPY_LONGDOUBLE values."]}, {"name": "enumerator NPY_COMPLEX128", "path": "reference/c-api/dtype#c.NPY_COMPLEX128", "type": "Data Type API", "text": ["The enumeration value for a 128-bit/16-byte complex type made up of two NPY_DOUBLE values."]}, {"name": "enumerator NPY_COMPLEX64", "path": "reference/c-api/dtype#c.NPY_COMPLEX64", "type": "Data Type API", "text": ["The enumeration value for a 64-bit/8-byte complex type made up of two NPY_FLOAT values."]}, {"name": "enumerator NPY_COMPLEX_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_COMPLEX_SCALAR", "type": "Array API", "text": []}, {"name": "enumerator NPY_CORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_CORDER", "type": "Array API", "text": ["C order."]}, {"name": "enumerator NPY_DATETIME", "path": "reference/c-api/dtype#c.NPY_DATETIME", "type": "Data Type API", "text": ["The enumeration value for a data type which holds dates or datetimes with a precision based on selectable date or time units."]}, {"name": "enumerator NPY_DEFAULT_TYPE", "path": "reference/c-api/dtype#c.NPY_DEFAULT_TYPE", "type": "Data Type API", "text": ["The default type to use when no dtype is explicitly specified, for example when calling np.zero(shape). This is equivalent to NPY_DOUBLE."]}, {"name": "enumerator NPY_DOUBLE", "path": "reference/c-api/dtype#c.NPY_DOUBLE", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_EQUIV_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_EQUIV_CASTING", "type": "Array API", "text": ["Allow identical and casts involving byte swapping."]}, {"name": "enumerator NPY_FLOAT", "path": "reference/c-api/dtype#c.NPY_FLOAT", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_FLOAT16", "path": "reference/c-api/dtype#c.NPY_FLOAT16", "type": "Data Type API", "text": ["The enumeration value for a 16-bit/2-byte IEEE 754-2008 compatible floating point type."]}, {"name": "enumerator NPY_FLOAT32", "path": "reference/c-api/dtype#c.NPY_FLOAT32", "type": "Data Type API", "text": ["The enumeration value for a 32-bit/4-byte IEEE 754 compatible floating point type."]}, {"name": "enumerator NPY_FLOAT64", "path": "reference/c-api/dtype#c.NPY_FLOAT64", "type": "Data Type API", "text": ["The enumeration value for a 64-bit/8-byte IEEE 754 compatible floating point type."]}, {"name": "enumerator NPY_FLOAT_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_FLOAT_SCALAR", "type": "Array API", "text": []}, {"name": "enumerator NPY_FORTRANORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_FORTRANORDER", "type": "Array API", "text": ["Fortran order."]}, {"name": "enumerator NPY_HALF", "path": "reference/c-api/dtype#c.NPY_HALF", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_HEAPSORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_HEAPSORT", "type": "Array API", "text": []}, {"name": "enumerator NPY_INT", "path": "reference/c-api/dtype#c.NPY_INT", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_INT16", "path": "reference/c-api/dtype#c.NPY_INT16", "type": "Data Type API", "text": ["The enumeration value for a 16-bit/2-byte signed integer."]}, {"name": "enumerator NPY_INT32", "path": "reference/c-api/dtype#c.NPY_INT32", "type": "Data Type API", "text": ["The enumeration value for a 32-bit/4-byte signed integer."]}, {"name": "enumerator NPY_INT64", "path": "reference/c-api/dtype#c.NPY_INT64", "type": "Data Type API", "text": ["The enumeration value for a 64-bit/8-byte signed integer."]}, {"name": "enumerator NPY_INT8", "path": "reference/c-api/dtype#c.NPY_INT8", "type": "Data Type API", "text": ["The enumeration value for an 8-bit/1-byte signed integer."]}, {"name": "enumerator NPY_INTNEG_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_INTNEG_SCALAR", "type": "Array API", "text": []}, {"name": "enumerator NPY_INTP", "path": "reference/c-api/dtype#c.NPY_INTP", "type": "Data Type API", "text": ["The enumeration value for a signed integer type which is the same size as a (void *) pointer. This is the type used by all arrays of indices."]}, {"name": "enumerator NPY_INTPOS_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_INTPOS_SCALAR", "type": "Array API", "text": []}, {"name": "enumerator NPY_KEEPORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_KEEPORDER", "type": "Array API", "text": ["An order as close to the order of the inputs as possible, even if the input is in neither C nor Fortran order."]}, {"name": "enumerator NPY_LONG", "path": "reference/c-api/dtype#c.NPY_LONG", "type": "Data Type API", "text": ["Equivalent to either NPY_INT or NPY_LONGLONG, depending on the platform."]}, {"name": "enumerator NPY_LONGDOUBLE", "path": "reference/c-api/dtype#c.NPY_LONGDOUBLE", "type": "Data Type API", "text": ["The enumeration value for a platform-specific floating point type which is at least as large as NPY_DOUBLE, but larger on many platforms."]}, {"name": "enumerator NPY_LONGLONG", "path": "reference/c-api/dtype#c.NPY_LONGLONG", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_MASK", "path": "reference/c-api/dtype#c.NPY_MASK", "type": "Data Type API", "text": ["The enumeration value of the type used for masks, such as with the NPY_ITER_ARRAYMASK iterator flag. This is equivalent to NPY_UINT8."]}, {"name": "enumerator NPY_MERGESORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_MERGESORT", "type": "Array API", "text": []}, {"name": "enumerator NPY_NSCALARKINDS", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_NSCALARKINDS", "type": "Array API", "text": ["Defined to be the number of scalar kinds (not including NPY_NOSCALAR)."]}, {"name": "enumerator NPY_NSORTS", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_NSORTS", "type": "Array API", "text": ["Defined to be the number of sorts. It is fixed at three by the need for backwards compatibility, and consequently NPY_MERGESORT and NPY_STABLESORT are aliased to each other and may refer to one of several stable sorting algorithms depending on the data type."]}, {"name": "enumerator NPY_OBJECT", "path": "reference/c-api/dtype#c.NPY_OBJECT", "type": "Data Type API", "text": ["The enumeration value for references to arbitrary Python objects."]}, {"name": "enumerator NPY_OBJECT_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_OBJECT_SCALAR", "type": "Array API", "text": []}, {"name": "enumerator NPY_SAFE_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_SAFE_CASTING", "type": "Array API", "text": ["Only allow casts which will not cause values to be rounded, truncated, or otherwise changed."]}, {"name": "enumerator NPY_SAME_KIND_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_SAME_KIND_CASTING", "type": "Array API", "text": ["Allow any safe casts, and casts between types of the same kind. For example, float64 -> float32 is permitted with this rule."]}, {"name": "enumerator NPY_SEARCHRIGHT", "path": "reference/c-api/array#c.NPY_SEARCHSIDE.NPY_SEARCHRIGHT", "type": "Array API", "text": []}, {"name": "enumerator NPY_SHORT", "path": "reference/c-api/dtype#c.NPY_SHORT", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_STABLESORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_STABLESORT", "type": "Array API", "text": ["Used as an alias of NPY_MERGESORT and vica versa."]}, {"name": "enumerator NPY_STRING", "path": "reference/c-api/dtype#c.NPY_STRING", "type": "Data Type API", "text": ["The enumeration value for ASCII strings of a selectable size. The strings have a fixed maximum size within a given array."]}, {"name": "enumerator NPY_TIMEDELTA", "path": "reference/c-api/dtype#c.NPY_TIMEDELTA", "type": "Data Type API", "text": ["The enumeration value for a data type which holds lengths of times in integers of selectable date or time units."]}, {"name": "enumerator NPY_TYPES", "path": "reference/c-api/dtype", "type": "Data Type API", "text": ["The standard array can have 24 different data types (and has some support for adding your own types). These data types all have an enumerated type, an enumerated type-character, and a corresponding array scalar Python type object (placed in a hierarchy). There are also standard C typedefs to make it easier to manipulate elements of the given data type. For the numeric types, there are also bit-width equivalent C typedefs and named typenumbers that make it easier to select the precision desired.", "Warning", "The names for the types in c code follows c naming conventions more closely. The Python names for these types follow Python conventions. Thus, NPY_FLOAT picks up a 32-bit float in C, but numpy.float_ in Python corresponds to a 64-bit double. The bit-width names can be used in both Python and C for clarity.", "There is a list of enumerated types defined providing the basic 24 data types plus some useful generic names. Whenever the code requires a type number, one of these enumerated types is requested. The types are all called NPY_{NAME}:", "The enumeration value for the boolean type, stored as one byte. It may only be set to the values 0 and 1.", "The enumeration value for an 8-bit/1-byte signed integer.", "The enumeration value for a 16-bit/2-byte signed integer.", "The enumeration value for a 32-bit/4-byte signed integer.", "Equivalent to either NPY_INT or NPY_LONGLONG, depending on the platform.", "The enumeration value for a 64-bit/8-byte signed integer.", "The enumeration value for an 8-bit/1-byte unsigned integer.", "The enumeration value for a 16-bit/2-byte unsigned integer.", "The enumeration value for a 32-bit/4-byte unsigned integer.", "Equivalent to either NPY_UINT or NPY_ULONGLONG, depending on the platform.", "The enumeration value for a 64-bit/8-byte unsigned integer.", "The enumeration value for a 16-bit/2-byte IEEE 754-2008 compatible floating point type.", "The enumeration value for a 32-bit/4-byte IEEE 754 compatible floating point type.", "The enumeration value for a 64-bit/8-byte IEEE 754 compatible floating point type.", "The enumeration value for a platform-specific floating point type which is at least as large as NPY_DOUBLE, but larger on many platforms.", "The enumeration value for a 64-bit/8-byte complex type made up of two NPY_FLOAT values.", "The enumeration value for a 128-bit/16-byte complex type made up of two NPY_DOUBLE values.", "The enumeration value for a platform-specific complex floating point type which is made up of two NPY_LONGDOUBLE values.", "The enumeration value for a data type which holds dates or datetimes with a precision based on selectable date or time units.", "The enumeration value for a data type which holds lengths of times in integers of selectable date or time units.", "The enumeration value for ASCII strings of a selectable size. The strings have a fixed maximum size within a given array.", "The enumeration value for UCS4 strings of a selectable size. The strings have a fixed maximum size within a given array.", "The enumeration value for references to arbitrary Python objects.", "Primarily used to hold struct dtypes, but can contain arbitrary binary data.", "Some useful aliases of the above types are", "The enumeration value for a signed integer type which is the same size as a (void *) pointer. This is the type used by all arrays of indices.", "The enumeration value for an unsigned integer type which is the same size as a (void *) pointer.", "The enumeration value of the type used for masks, such as with the NPY_ITER_ARRAYMASK iterator flag. This is equivalent to NPY_UINT8.", "The default type to use when no dtype is explicitly specified, for example when calling np.zero(shape). This is equivalent to NPY_DOUBLE.", "Other useful related constants are", "The total number of built-in NumPy types. The enumeration covers the range from 0 to NPY_NTYPES-1.", "A signal value guaranteed not to be a valid type enumeration number.", "The start of type numbers used for Custom Data types.", "The various character codes indicating certain types are also part of an enumerated list. References to type characters (should they be needed at all) should always use these enumerations. The form of them is NPY_{NAME}LTR where {NAME} can be", "BOOL, BYTE, UBYTE, SHORT, USHORT, INT, UINT, LONG, ULONG, LONGLONG, ULONGLONG, HALF, FLOAT, DOUBLE, LONGDOUBLE, CFLOAT, CDOUBLE, CLONGDOUBLE, DATETIME, TIMEDELTA, OBJECT, STRING, VOID", "INTP, UINTP", "GENBOOL, SIGNED, UNSIGNED, FLOATING, COMPLEX", "The latter group of {NAME}s corresponds to letters used in the array interface typestring specification.", "These are defined for {bits} = 8, 16, 32, 64, 128, and 256 and provide the maximum (minimum) value of the corresponding (unsigned) integer type. Note: the actual integer type may not be available on all platforms (i.e. 128-bit and 256-bit integers are rare).", "This is defined for {type} = BYTE, SHORT, INT, LONG, LONGLONG, INTP", "This is defined for all defined for {type} = BYTE, UBYTE, SHORT, USHORT, INT, UINT, LONG, ULONG, LONGLONG, ULONGLONG, INTP, UINTP", "All NPY_SIZEOF_{CTYPE} constants have corresponding NPY_BITSOF_{CTYPE} constants defined. The NPY_BITSOF_{CTYPE} constants provide the number of bits in the data type. Specifically, the available {CTYPE}s are", "BOOL, CHAR, SHORT, INT, LONG, LONGLONG, FLOAT, DOUBLE, LONGDOUBLE", "All of the numeric data types (integer, floating point, and complex) have constants that are defined to be a specific enumerated type number. Exactly which enumerated type a bit-width type refers to is platform dependent. In particular, the constants available are PyArray_{NAME}{BITS} where {NAME} is INT, UINT, FLOAT, COMPLEX and {BITS} can be 8, 16, 32, 64, 80, 96, 128, 160, 192, 256, and 512. Obviously not all bit-widths are available on all platforms for all the kinds of numeric types. Commonly 8-, 16-, 32-, 64-bit integers; 32-, 64-bit floats; and 64-, 128-bit complex types are available.", "The constants NPY_INTP and NPY_UINTP refer to an enumerated integer type that is large enough to hold a pointer on the platform. Index arrays should always be converted to NPY_INTP , because the dimension of the array is of type npy_intp.", "There are standard variable types for each of the numeric data types and the bool data type. Some of these are already available in the C-specification. You can create variables in extension code with these types.", "unsigned char; The constants NPY_FALSE and NPY_TRUE are also defined.", "Unsigned versions of the integers can be defined by pre-pending a \u2018u\u2019 to the front of the integer name.", "char", "unsigned char", "short", "unsigned short", "int", "unsigned int", "16-bit integer", "16-bit unsigned integer", "32-bit integer", "32-bit unsigned integer", "64-bit integer", "64-bit unsigned integer", "long int", "unsigned long int", "long long int", "unsigned long long int", "Py_intptr_t (an integer that is the size of a pointer on the platform).", "unsigned Py_intptr_t (an integer that is the size of a pointer on the platform).", "16-bit float", "32-bit float", "32-bit complex float", "64-bit double", "64-bit complex double", "long double", "long complex double", "complex types are structures with .real and .imag members (in that order).", "There are also typedefs for signed integers, unsigned integers, floating point, and complex floating point types of specific bit- widths. The available type names are", "npy_int{bits}, npy_uint{bits}, npy_float{bits}, and npy_complex{bits}", "where {bits} is the number of bits in the type and can be 8, 16, 32, 64, 128, and 256 for integer types; 16, 32 , 64, 80, 96, 128, and 256 for floating-point types; and 32, 64, 128, 160, 192, and 512 for complex-valued types. Which bit-widths are available is platform dependent. The bolded bit-widths are usually available on all platforms.", "For help in printing, the following strings are defined as the correct format specifier in printf and related commands."]}, {"name": "enumerator NPY_UBYTE", "path": "reference/c-api/dtype#c.NPY_UBYTE", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_UINT", "path": "reference/c-api/dtype#c.NPY_UINT", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_UINT16", "path": "reference/c-api/dtype#c.NPY_UINT16", "type": "Data Type API", "text": ["The enumeration value for a 16-bit/2-byte unsigned integer."]}, {"name": "enumerator NPY_UINT32", "path": "reference/c-api/dtype#c.NPY_UINT32", "type": "Data Type API", "text": ["The enumeration value for a 32-bit/4-byte unsigned integer."]}, {"name": "enumerator NPY_UINT64", "path": "reference/c-api/dtype#c.NPY_UINT64", "type": "Data Type API", "text": ["The enumeration value for a 64-bit/8-byte unsigned integer."]}, {"name": "enumerator NPY_UINT8", "path": "reference/c-api/dtype#c.NPY_UINT8", "type": "Data Type API", "text": ["The enumeration value for an 8-bit/1-byte unsigned integer."]}, {"name": "enumerator NPY_UINTP", "path": "reference/c-api/dtype#c.NPY_UINTP", "type": "Data Type API", "text": ["The enumeration value for an unsigned integer type which is the same size as a (void *) pointer."]}, {"name": "enumerator NPY_ULONG", "path": "reference/c-api/dtype#c.NPY_ULONG", "type": "Data Type API", "text": ["Equivalent to either NPY_UINT or NPY_ULONGLONG, depending on the platform."]}, {"name": "enumerator NPY_ULONGLONG", "path": "reference/c-api/dtype#c.NPY_ULONGLONG", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_UNICODE", "path": "reference/c-api/dtype#c.NPY_UNICODE", "type": "Data Type API", "text": ["The enumeration value for UCS4 strings of a selectable size. The strings have a fixed maximum size within a given array."]}, {"name": "enumerator NPY_UNSAFE_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_UNSAFE_CASTING", "type": "Array API", "text": ["Allow any cast, no matter what kind of data loss may occur."]}, {"name": "enumerator NPY_USHORT", "path": "reference/c-api/dtype#c.NPY_USHORT", "type": "Data Type API", "text": []}, {"name": "enumerator NPY_VOID", "path": "reference/c-api/dtype#c.NPY_VOID", "type": "Data Type API", "text": ["Primarily used to hold struct dtypes, but can contain arbitrary binary data."]}, {"name": "enumerator NPY_WRAP", "path": "reference/c-api/array#c.NPY_CLIPMODE.NPY_WRAP", "type": "Array API", "text": ["Wraps an index to the valid range if it is out of bounds."]}, {"name": "errstate.__call__()", "path": "reference/generated/numpy.errstate.__call__", "type": "numpy.errstate.__call__", "text": ["method", "Call self as a function."]}, {"name": "exec_command", "path": "reference/generated/numpy.distutils.exec_command", "type": "numpy.distutils.exec_command", "text": ["exec_command", "Implements exec_command function that is (almost) equivalent to commands.getstatusoutput function but on NT, DOS systems the returned status is actually correct (though, the returned status values may be different by a factor). In addition, exec_command takes keyword arguments for (re-)defining environment variables.", "Provides functions:", "in the modified environment.", "variable PATH. Equivalent to posix which command.", "Author: Pearu Peterson <pearu@cens.ioc.ee> Created: 11 January 2003", "Requires: Python 2.x", "Successfully tested on:", "os.name", "sys.platform", "comments", "posix", "linux2", "Debian (sid) Linux, Python 2.1.3+, 2.2.3+, 2.3.3 PyCrust 0.9.3, Idle 1.0.2", "posix", "linux2", "Red Hat 9 Linux, Python 2.1.3, 2.2.2, 2.3.2", "posix", "sunos5", "SunOS 5.9, Python 2.2, 2.3.2", "posix", "darwin", "Darwin 7.2.0, Python 2.3", "nt", "win32", "Windows Me Python 2.3(EE), Idle 1.0, PyCrust 0.7.2 Python 2.1.1 Idle 0.8", "nt", "win32", "Windows 98, Python 2.1.1. Idle 0.8", "nt", "win32", "Cygwin 98-4.10, Python 2.1.1(MSC) - echo tests fail i.e. redefining environment variables may not work. FIXED: don\u2019t use cygwin echo! Comment: also cmd /c echo will not work but redefining environment variables do work.", "posix", "cygwin", "Cygwin 98-4.10, Python 2.3.3(cygming special)", "nt", "win32", "Windows XP, Python 2.3.3", "Known bugs:", "exec_command(command[, execute_in, ...])", "Return (status,output) of executed command.", "filepath_from_subprocess_output(output)", "Convert bytes in the encoding used by a subprocess into a filesystem-appropriate str.", "find_executable(exe[, path, _cache])", "Return full path of a executable or None.", "forward_bytes_to_stdout(val)", "Forward bytes from a subprocess call to the console, without attempting to decode them.", "get_pythonexe()", "temp_file_name()"]}, {"name": "Extending", "path": "reference/random/extending", "type": "Examples of using Numba, Cython, CFFI", "text": ["The BitGenerators have been designed to be extendable using standard tools for high-performance Python \u2013 numba and Cython. The Generator object can also be used with user-provided BitGenerators as long as these export a small set of required functions.", "Numba can be used with either CTypes or CFFI. The current iteration of the BitGenerators all export a small set of functions through both interfaces.", "This example shows how numba can be used to produce gaussian samples using a pure Python implementation which is then compiled. The random numbers are provided by ctypes.next_double.", "Both CTypes and CFFI allow the more complicated distributions to be used directly in Numba after compiling the file distributions.c into a DLL or so. An example showing the use of a more complicated distribution is in the examples section below.", "Cython can be used to unpack the PyCapsule provided by a BitGenerator. This example uses PCG64 and the example from above. The usual caveats for writing high-performance code using Cython \u2013 removing bounds checks and wrap around, providing array alignment information \u2013 still apply.", "The BitGenerator can also be directly accessed using the members of the bitgen_t struct.", "Cython can be used to directly access the functions in numpy/random/c_distributions.pxd. This requires linking with the npyrandom library located in numpy/random/lib.", "See Extending numpy.random via Cython for the complete listings of these examples and a minimal setup.py to build the c-extension modules.", "CFFI can be used to directly access the functions in include/numpy/random/distributions.h. Some \u201cmassaging\u201d of the header file is required:", "Once the header is parsed by ffi.cdef, the functions can be accessed directly from the _generator shared object, using the BitGenerator.cffi interface.", "Generator can be used with user-provided BitGenerators. The simplest way to write a new BitGenerator is to examine the pyx file of one of the existing BitGenerators. The key structure that must be provided is the capsule which contains a PyCapsule to a struct pointer of type bitgen_t,", "which provides 5 pointers. The first is an opaque pointer to the data structure used by the BitGenerators. The next three are function pointers which return the next 64- and 32-bit unsigned integers, the next random double and the next raw value. This final function is used for testing and so can be set to the next 64-bit unsigned integer function if not needed. Functions inside Generator use this structure as in"]}, {"name": "Extending numpy.random via Cython", "path": "reference/random/examples/cython/index", "type": "Cython", "text": []}, {"name": "Extending via CFFI", "path": "reference/random/examples/cffi", "type": "CFFI", "text": []}, {"name": "Extending via Numba", "path": "reference/random/examples/numba", "type": "Numba", "text": []}, {"name": "Extending via Numba and CFFI", "path": "reference/random/examples/numba_cffi", "type": "CFFI + Numba", "text": []}, {"name": "extending.pyx", "path": "reference/random/examples/cython/extending.pyx", "type": "Cython", "text": []}, {"name": "extending_distributions.pyx", "path": "reference/random/examples/cython/extending_distributions.pyx", "type": "Cython", "text": []}, {"name": "F2PY user guide and reference manual", "path": "f2py/index", "type": "F2PY user guide and reference manual", "text": ["The purpose of the F2PY \u2013Fortran to Python interface generator\u2013 utility is to provide a connection between Python and Fortran languages. F2PY is a part of NumPy (numpy.f2py) and also available as a standalone command line tool f2py when numpy is installed that facilitates creating/building Python C/API extension modules that make it possible", "from Python."]}, {"name": "fft.fft()", "path": "reference/generated/numpy.fft.fft", "type": "numpy.fft.fft", "text": ["Compute the one-dimensional discrete Fourier Transform.", "This function computes the one-dimensional n-point discrete Fourier Transform (DFT) with the efficient Fast Fourier Transform (FFT) algorithm [CT].", "Input array, can be complex.", "Length of the transformed axis of the output. If n is smaller than the length of the input, the input is cropped. If it is larger, the input is padded with zeros. If n is not given, the length of the input along the axis specified by axis is used.", "Axis over which to compute the FFT. If not given, the last axis is used.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axis indicated by axis, or the last one if axis is not specified.", "If axis is not a valid axis of a.", "See also", "for definition of the DFT and conventions used.", "The inverse of fft.", "The two-dimensional FFT.", "The n-dimensional FFT.", "The n-dimensional FFT of real input.", "Frequency bins for given FFT parameters.", "FFT (Fast Fourier Transform) refers to a way the discrete Fourier Transform (DFT) can be calculated efficiently, by using symmetries in the calculated terms. The symmetry is highest when n is a power of 2, and the transform is therefore most efficient for these sizes.", "The DFT is defined, with the conventions used in this implementation, in the documentation for the numpy.fft module.", "Cooley, James W., and John W. Tukey, 1965, \u201cAn algorithm for the machine calculation of complex Fourier series,\u201d Math. Comput. 19: 297-301.", "In this example, real input has an FFT which is Hermitian, i.e., symmetric in the real part and anti-symmetric in the imaginary part, as described in the numpy.fft documentation:"]}, {"name": "fft.fft2()", "path": "reference/generated/numpy.fft.fft2", "type": "numpy.fft.fft2", "text": ["Compute the 2-dimensional discrete Fourier Transform.", "This function computes the n-dimensional discrete Fourier Transform over any axes in an M-dimensional array by means of the Fast Fourier Transform (FFT). By default, the transform is computed over the last two axes of the input array, i.e., a 2-dimensional FFT.", "Input array, can be complex", "Shape (length of each transformed axis) of the output (s[0] refers to axis 0, s[1] to axis 1, etc.). This corresponds to n for fft(x, n). Along each axis, if the given shape is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. if s is not given, the shape of the input along the axes specified by axes is used.", "Axes over which to compute the FFT. If not given, the last two axes are used. A repeated index in axes means the transform over that axis is performed multiple times. A one-element sequence means that a one-dimensional FFT is performed.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axes indicated by axes, or the last two axes if axes is not given.", "If s and axes have different length, or axes not given and len(s) != 2.", "If an element of axes is larger than than the number of axes of a.", "See also", "Overall view of discrete Fourier transforms, with definitions and conventions used.", "The inverse two-dimensional FFT.", "The one-dimensional FFT.", "The n-dimensional FFT.", "Shifts zero-frequency terms to the center of the array. For two-dimensional input, swaps first and third quadrants, and second and fourth quadrants.", "fft2 is just fftn with a different default for axes.", "The output, analogously to fft, contains the term for zero frequency in the low-order corner of the transformed axes, the positive frequency terms in the first half of these axes, the term for the Nyquist frequency in the middle of the axes and the negative frequency terms in the second half of the axes, in order of decreasingly negative frequency.", "See fftn for details and a plotting example, and numpy.fft for definitions and conventions used."]}, {"name": "fft.fftfreq()", "path": "reference/generated/numpy.fft.fftfreq", "type": "numpy.fft.fftfreq", "text": ["Return the Discrete Fourier Transform sample frequencies.", "The returned float array f contains the frequency bin centers in cycles per unit of the sample spacing (with zero at the start). For instance, if the sample spacing is in seconds, then the frequency unit is cycles/second.", "Given a window length n and a sample spacing d:", "Window length.", "Sample spacing (inverse of the sampling rate). Defaults to 1.", "Array of length n containing the sample frequencies."]}, {"name": "fft.fftn()", "path": "reference/generated/numpy.fft.fftn", "type": "numpy.fft.fftn", "text": ["Compute the N-dimensional discrete Fourier Transform.", "This function computes the N-dimensional discrete Fourier Transform over any number of axes in an M-dimensional array by means of the Fast Fourier Transform (FFT).", "Input array, can be complex.", "Shape (length of each transformed axis) of the output (s[0] refers to axis 0, s[1] to axis 1, etc.). This corresponds to n for fft(x, n). Along any axis, if the given shape is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. if s is not given, the shape of the input along the axes specified by axes is used.", "Axes over which to compute the FFT. If not given, the last len(s) axes are used, or all axes if s is also not specified. Repeated indices in axes means that the transform over that axis is performed multiple times.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axes indicated by axes, or by a combination of s and a, as explained in the parameters section above.", "If s and axes have different length.", "If an element of axes is larger than than the number of axes of a.", "See also", "Overall view of discrete Fourier transforms, with definitions and conventions used.", "The inverse of fftn, the inverse n-dimensional FFT.", "The one-dimensional FFT, with definitions and conventions used.", "The n-dimensional FFT of real input.", "The two-dimensional FFT.", "Shifts zero-frequency terms to centre of array", "The output, analogously to fft, contains the term for zero frequency in the low-order corner of all axes, the positive frequency terms in the first half of all axes, the term for the Nyquist frequency in the middle of all axes and the negative frequency terms in the second half of all axes, in order of decreasingly negative frequency.", "See numpy.fft for details, definitions and conventions used."]}, {"name": "fft.fftshift()", "path": "reference/generated/numpy.fft.fftshift", "type": "numpy.fft.fftshift", "text": ["Shift the zero-frequency component to the center of the spectrum.", "This function swaps half-spaces for all axes listed (defaults to all). Note that y[0] is the Nyquist component only if len(x) is even.", "Input array.", "Axes over which to shift. Default is None, which shifts all axes.", "The shifted array.", "See also", "The inverse of fftshift.", "Shift the zero-frequency component only along the second axis:"]}, {"name": "fft.hfft()", "path": "reference/generated/numpy.fft.hfft", "type": "numpy.fft.hfft", "text": ["Compute the FFT of a signal that has Hermitian symmetry, i.e., a real spectrum.", "The input array.", "Length of the transformed axis of the output. For n output points, n//2 + 1 input points are necessary. If the input is longer than this, it is cropped. If it is shorter than this, it is padded with zeros. If n is not given, it is taken to be 2*(m-1) where m is the length of the input along the axis specified by axis.", "Axis over which to compute the FFT. If not given, the last axis is used.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axis indicated by axis, or the last one if axis is not specified. The length of the transformed axis is n, or, if n is not given, 2*m - 2 where m is the length of the transformed axis of the input. To get an odd number of output points, n must be specified, for instance as 2*m - 1 in the typical case,", "If axis is not a valid axis of a.", "See also", "Compute the one-dimensional FFT for real input.", "The inverse of hfft.", "hfft/ihfft are a pair analogous to rfft/irfft, but for the opposite case: here the signal has Hermitian symmetry in the time domain and is real in the frequency domain. So here it\u2019s hfft for which you must supply the length of the result if it is to be odd.", "The correct interpretation of the hermitian input depends on the length of the original data, as given by n. This is because each input shape could correspond to either an odd or even length signal. By default, hfft assumes an even output length which puts the last entry at the Nyquist frequency; aliasing with its symmetric counterpart. By Hermitian symmetry, the value is thus treated as purely real. To avoid losing information, the shape of the full signal must be given."]}, {"name": "fft.ifft()", "path": "reference/generated/numpy.fft.ifft", "type": "numpy.fft.ifft", "text": ["Compute the one-dimensional inverse discrete Fourier Transform.", "This function computes the inverse of the one-dimensional n-point discrete Fourier transform computed by fft. In other words, ifft(fft(a)) == a to within numerical accuracy. For a general description of the algorithm and definitions, see numpy.fft.", "The input should be ordered in the same way as is returned by fft, i.e.,", "For an even number of input points, A[n//2] represents the sum of the values at the positive and negative Nyquist frequencies, as the two are aliased together. See numpy.fft for details.", "Input array, can be complex.", "Length of the transformed axis of the output. If n is smaller than the length of the input, the input is cropped. If it is larger, the input is padded with zeros. If n is not given, the length of the input along the axis specified by axis is used. See notes about padding issues.", "Axis over which to compute the inverse DFT. If not given, the last axis is used.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axis indicated by axis, or the last one if axis is not specified.", "If axis is not a valid axis of a.", "See also", "An introduction, with definitions and general explanations.", "The one-dimensional (forward) FFT, of which ifft is the inverse", "The two-dimensional inverse FFT.", "The n-dimensional inverse FFT.", "If the input parameter n is larger than the size of the input, the input is padded by appending zeros at the end. Even though this is the common approach, it might lead to surprising results. If a different padding is desired, it must be performed before calling ifft.", "Create and plot a band-limited signal with random phases:"]}, {"name": "fft.ifft2()", "path": "reference/generated/numpy.fft.ifft2", "type": "numpy.fft.ifft2", "text": ["Compute the 2-dimensional inverse discrete Fourier Transform.", "This function computes the inverse of the 2-dimensional discrete Fourier Transform over any number of axes in an M-dimensional array by means of the Fast Fourier Transform (FFT). In other words, ifft2(fft2(a)) == a to within numerical accuracy. By default, the inverse transform is computed over the last two axes of the input array.", "The input, analogously to ifft, should be ordered in the same way as is returned by fft2, i.e. it should have the term for zero frequency in the low-order corner of the two axes, the positive frequency terms in the first half of these axes, the term for the Nyquist frequency in the middle of the axes and the negative frequency terms in the second half of both axes, in order of decreasingly negative frequency.", "Input array, can be complex.", "Shape (length of each axis) of the output (s[0] refers to axis 0, s[1] to axis 1, etc.). This corresponds to n for ifft(x, n). Along each axis, if the given shape is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. if s is not given, the shape of the input along the axes specified by axes is used. See notes for issue on ifft zero padding.", "Axes over which to compute the FFT. If not given, the last two axes are used. A repeated index in axes means the transform over that axis is performed multiple times. A one-element sequence means that a one-dimensional FFT is performed.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axes indicated by axes, or the last two axes if axes is not given.", "If s and axes have different length, or axes not given and len(s) != 2.", "If an element of axes is larger than than the number of axes of a.", "See also", "Overall view of discrete Fourier transforms, with definitions and conventions used.", "The forward 2-dimensional FFT, of which ifft2 is the inverse.", "The inverse of the n-dimensional FFT.", "The one-dimensional FFT.", "The one-dimensional inverse FFT.", "ifft2 is just ifftn with a different default for axes.", "See ifftn for details and a plotting example, and numpy.fft for definition and conventions used.", "Zero-padding, analogously with ifft, is performed by appending zeros to the input along the specified dimension. Although this is the common approach, it might lead to surprising results. If another form of zero padding is desired, it must be performed before ifft2 is called."]}, {"name": "fft.ifftn()", "path": "reference/generated/numpy.fft.ifftn", "type": "numpy.fft.ifftn", "text": ["Compute the N-dimensional inverse discrete Fourier Transform.", "This function computes the inverse of the N-dimensional discrete Fourier Transform over any number of axes in an M-dimensional array by means of the Fast Fourier Transform (FFT). In other words, ifftn(fftn(a)) == a to within numerical accuracy. For a description of the definitions and conventions used, see numpy.fft.", "The input, analogously to ifft, should be ordered in the same way as is returned by fftn, i.e. it should have the term for zero frequency in all axes in the low-order corner, the positive frequency terms in the first half of all axes, the term for the Nyquist frequency in the middle of all axes and the negative frequency terms in the second half of all axes, in order of decreasingly negative frequency.", "Input array, can be complex.", "Shape (length of each transformed axis) of the output (s[0] refers to axis 0, s[1] to axis 1, etc.). This corresponds to n for ifft(x, n). Along any axis, if the given shape is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. if s is not given, the shape of the input along the axes specified by axes is used. See notes for issue on ifft zero padding.", "Axes over which to compute the IFFT. If not given, the last len(s) axes are used, or all axes if s is also not specified. Repeated indices in axes means that the inverse transform over that axis is performed multiple times.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axes indicated by axes, or by a combination of s or a, as explained in the parameters section above.", "If s and axes have different length.", "If an element of axes is larger than than the number of axes of a.", "See also", "Overall view of discrete Fourier transforms, with definitions and conventions used.", "The forward n-dimensional FFT, of which ifftn is the inverse.", "The one-dimensional inverse FFT.", "The two-dimensional inverse FFT.", "Undoes fftshift, shifts zero-frequency terms to beginning of array.", "See numpy.fft for definitions and conventions used.", "Zero-padding, analogously with ifft, is performed by appending zeros to the input along the specified dimension. Although this is the common approach, it might lead to surprising results. If another form of zero padding is desired, it must be performed before ifftn is called.", "Create and plot an image with band-limited frequency content:"]}, {"name": "fft.ifftshift()", "path": "reference/generated/numpy.fft.ifftshift", "type": "numpy.fft.ifftshift", "text": ["The inverse of fftshift. Although identical for even-length x, the functions differ by one sample for odd-length x.", "Input array.", "Axes over which to calculate. Defaults to None, which shifts all axes.", "The shifted array.", "See also", "Shift zero-frequency component to the center of the spectrum."]}, {"name": "fft.ihfft()", "path": "reference/generated/numpy.fft.ihfft", "type": "numpy.fft.ihfft", "text": ["Compute the inverse FFT of a signal that has Hermitian symmetry.", "Input array.", "Length of the inverse FFT, the number of points along transformation axis in the input to use. If n is smaller than the length of the input, the input is cropped. If it is larger, the input is padded with zeros. If n is not given, the length of the input along the axis specified by axis is used.", "Axis over which to compute the inverse FFT. If not given, the last axis is used.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axis indicated by axis, or the last one if axis is not specified. The length of the transformed axis is n//2 + 1.", "See also", "hfft/ihfft are a pair analogous to rfft/irfft, but for the opposite case: here the signal has Hermitian symmetry in the time domain and is real in the frequency domain. So here it\u2019s hfft for which you must supply the length of the result if it is to be odd:"]}, {"name": "fft.irfft()", "path": "reference/generated/numpy.fft.irfft", "type": "numpy.fft.irfft", "text": ["Computes the inverse of rfft.", "This function computes the inverse of the one-dimensional n-point discrete Fourier Transform of real input computed by rfft. In other words, irfft(rfft(a), len(a)) == a to within numerical accuracy. (See Notes below for why len(a) is necessary here.)", "The input is expected to be in the form returned by rfft, i.e. the real zero-frequency term followed by the complex positive frequency terms in order of increasing frequency. Since the discrete Fourier Transform of real input is Hermitian-symmetric, the negative frequency terms are taken to be the complex conjugates of the corresponding positive frequency terms.", "The input array.", "Length of the transformed axis of the output. For n output points, n//2+1 input points are necessary. If the input is longer than this, it is cropped. If it is shorter than this, it is padded with zeros. If n is not given, it is taken to be 2*(m-1) where m is the length of the input along the axis specified by axis.", "Axis over which to compute the inverse FFT. If not given, the last axis is used.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axis indicated by axis, or the last one if axis is not specified. The length of the transformed axis is n, or, if n is not given, 2*(m-1) where m is the length of the transformed axis of the input. To get an odd number of output points, n must be specified.", "If axis is not a valid axis of a.", "See also", "For definition of the DFT and conventions used.", "The one-dimensional FFT of real input, of which irfft is inverse.", "The one-dimensional FFT.", "The inverse of the two-dimensional FFT of real input.", "The inverse of the n-dimensional FFT of real input.", "Returns the real valued n-point inverse discrete Fourier transform of a, where a contains the non-negative frequency terms of a Hermitian-symmetric sequence. n is the length of the result, not the input.", "If you specify an n such that a must be zero-padded or truncated, the extra/removed values will be added/removed at high frequencies. One can thus resample a series to m points via Fourier interpolation by: a_resamp = irfft(rfft(a), m).", "The correct interpretation of the hermitian input depends on the length of the original data, as given by n. This is because each input shape could correspond to either an odd or even length signal. By default, irfft assumes an even output length which puts the last entry at the Nyquist frequency; aliasing with its symmetric counterpart. By Hermitian symmetry, the value is thus treated as purely real. To avoid losing information, the correct length of the real input must be given.", "Notice how the last term in the input to the ordinary ifft is the complex conjugate of the second term, and the output has zero imaginary part everywhere. When calling irfft, the negative frequencies are not specified, and the output array is purely real."]}, {"name": "fft.irfft2()", "path": "reference/generated/numpy.fft.irfft2", "type": "numpy.fft.irfft2", "text": ["Computes the inverse of rfft2.", "The input array", "Shape of the real output to the inverse FFT.", "The axes over which to compute the inverse fft. Default is the last two axes.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The result of the inverse real 2-D FFT.", "See also", "The forward two-dimensional FFT of real input, of which irfft2 is the inverse.", "The one-dimensional FFT for real input.", "The inverse of the one-dimensional FFT of real input.", "Compute the inverse of the N-dimensional FFT of real input.", "This is really irfftn with different defaults. For more details see irfftn."]}, {"name": "fft.irfftn()", "path": "reference/generated/numpy.fft.irfftn", "type": "numpy.fft.irfftn", "text": ["Computes the inverse of rfftn.", "This function computes the inverse of the N-dimensional discrete Fourier Transform for real input over any number of axes in an M-dimensional array by means of the Fast Fourier Transform (FFT). In other words, irfftn(rfftn(a), a.shape) == a to within numerical accuracy. (The a.shape is necessary like len(a) is for irfft, and for the same reason.)", "The input should be ordered in the same way as is returned by rfftn, i.e. as for irfft for the final transformation axis, and as for ifftn along all the other axes.", "Input array.", "Shape (length of each transformed axis) of the output (s[0] refers to axis 0, s[1] to axis 1, etc.). s is also the number of input points used along this axis, except for the last axis, where s[-1]//2+1 points of the input are used. Along any axis, if the shape indicated by s is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. If s is not given, the shape of the input along the axes specified by axes is used. Except for the last axis which is taken to be 2*(m-1) where m is the length of the input along that axis.", "Axes over which to compute the inverse FFT. If not given, the last len(s) axes are used, or all axes if s is also not specified. Repeated indices in axes means that the inverse transform over that axis is performed multiple times.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axes indicated by axes, or by a combination of s or a, as explained in the parameters section above. The length of each transformed axis is as given by the corresponding element of s, or the length of the input in every axis except for the last one if s is not given. In the final transformed axis the length of the output when s is not given is 2*(m-1) where m is the length of the final transformed axis of the input. To get an odd number of output points in the final axis, s must be specified.", "If s and axes have different length.", "If an element of axes is larger than than the number of axes of a.", "See also", "The forward n-dimensional FFT of real input, of which ifftn is the inverse.", "The one-dimensional FFT, with definitions and conventions used.", "The inverse of the one-dimensional FFT of real input.", "The inverse of the two-dimensional FFT of real input.", "See fft for definitions and conventions used.", "See rfft for definitions and conventions used for real input.", "The correct interpretation of the hermitian input depends on the shape of the original data, as given by s. This is because each input shape could correspond to either an odd or even length signal. By default, irfftn assumes an even output length which puts the last entry at the Nyquist frequency; aliasing with its symmetric counterpart. When performing the final complex to real transform, the last value is thus treated as purely real. To avoid losing information, the correct shape of the real input must be given."]}, {"name": "fft.rfft()", "path": "reference/generated/numpy.fft.rfft", "type": "numpy.fft.rfft", "text": ["Compute the one-dimensional discrete Fourier Transform for real input.", "This function computes the one-dimensional n-point discrete Fourier Transform (DFT) of a real-valued array by means of an efficient algorithm called the Fast Fourier Transform (FFT).", "Input array", "Number of points along transformation axis in the input to use. If n is smaller than the length of the input, the input is cropped. If it is larger, the input is padded with zeros. If n is not given, the length of the input along the axis specified by axis is used.", "Axis over which to compute the FFT. If not given, the last axis is used.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axis indicated by axis, or the last one if axis is not specified. If n is even, the length of the transformed axis is (n/2)+1. If n is odd, the length is (n+1)/2.", "If axis is not a valid axis of a.", "See also", "For definition of the DFT and conventions used.", "The inverse of rfft.", "The one-dimensional FFT of general (complex) input.", "The n-dimensional FFT.", "The n-dimensional FFT of real input.", "When the DFT is computed for purely real input, the output is Hermitian-symmetric, i.e. the negative frequency terms are just the complex conjugates of the corresponding positive-frequency terms, and the negative-frequency terms are therefore redundant. This function does not compute the negative frequency terms, and the length of the transformed axis of the output is therefore n//2 + 1.", "When A = rfft(a) and fs is the sampling frequency, A[0] contains the zero-frequency term 0*fs, which is real due to Hermitian symmetry.", "If n is even, A[-1] contains the term representing both positive and negative Nyquist frequency (+fs/2 and -fs/2), and must also be purely real. If n is odd, there is no term at fs/2; A[-1] contains the largest positive frequency (fs/2*(n-1)/n), and is complex in the general case.", "If the input a contains an imaginary part, it is silently discarded.", "Notice how the final element of the fft output is the complex conjugate of the second element, for real input. For rfft, this symmetry is exploited to compute only the non-negative frequency terms."]}, {"name": "fft.rfft2()", "path": "reference/generated/numpy.fft.rfft2", "type": "numpy.fft.rfft2", "text": ["Compute the 2-dimensional FFT of a real array.", "Input array, taken to be real.", "Shape of the FFT.", "Axes over which to compute the FFT.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The result of the real 2-D FFT.", "See also", "Compute the N-dimensional discrete Fourier Transform for real input.", "This is really just rfftn with different default behavior. For more details see rfftn."]}, {"name": "fft.rfftfreq()", "path": "reference/generated/numpy.fft.rfftfreq", "type": "numpy.fft.rfftfreq", "text": ["Return the Discrete Fourier Transform sample frequencies (for usage with rfft, irfft).", "The returned float array f contains the frequency bin centers in cycles per unit of the sample spacing (with zero at the start). For instance, if the sample spacing is in seconds, then the frequency unit is cycles/second.", "Given a window length n and a sample spacing d:", "Unlike fftfreq (but like scipy.fftpack.rfftfreq) the Nyquist frequency component is considered to be positive.", "Window length.", "Sample spacing (inverse of the sampling rate). Defaults to 1.", "Array of length n//2 + 1 containing the sample frequencies."]}, {"name": "fft.rfftn()", "path": "reference/generated/numpy.fft.rfftn", "type": "numpy.fft.rfftn", "text": ["Compute the N-dimensional discrete Fourier Transform for real input.", "This function computes the N-dimensional discrete Fourier Transform over any number of axes in an M-dimensional real array by means of the Fast Fourier Transform (FFT). By default, all axes are transformed, with the real transform performed over the last axis, while the remaining transforms are complex.", "Input array, taken to be real.", "Shape (length along each transformed axis) to use from the input. (s[0] refers to axis 0, s[1] to axis 1, etc.). The final element of s corresponds to n for rfft(x, n), while for the remaining axes, it corresponds to n for fft(x, n). Along any axis, if the given shape is smaller than that of the input, the input is cropped. If it is larger, the input is padded with zeros. if s is not given, the shape of the input along the axes specified by axes is used.", "Axes over which to compute the FFT. If not given, the last len(s) axes are used, or all axes if s is also not specified.", "New in version 1.10.0.", "Normalization mode (see numpy.fft). Default is \u201cbackward\u201d. Indicates which direction of the forward/backward pair of transforms is scaled and with what normalization factor.", "New in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.", "The truncated or zero-padded input, transformed along the axes indicated by axes, or by a combination of s and a, as explained in the parameters section above. The length of the last axis transformed will be s[-1]//2+1, while the remaining transformed axes will have lengths according to s, or unchanged from the input.", "If s and axes have different length.", "If an element of axes is larger than than the number of axes of a.", "See also", "The inverse of rfftn, i.e. the inverse of the n-dimensional FFT of real input.", "The one-dimensional FFT, with definitions and conventions used.", "The one-dimensional FFT of real input.", "The n-dimensional FFT.", "The two-dimensional FFT of real input.", "The transform for real input is performed over the last transformation axis, as by rfft, then the transform over the remaining axes is performed as by fftn. The order of the output is as for rfft for the final transformation axis, and as for fftn for the remaining transformation axes.", "See fft for details, definitions and conventions used."]}, {"name": "final class numpy.typing.NBitBase", "path": "reference/typing#numpy.typing.NBitBase", "type": "Typing ( \n    \n     numpy.typing\n    \n    )", "text": ["A type representing numpy.number precision during static type checking.", "Used exclusively for the purpose static type checking, NBitBase represents the base of a hierarchical set of subclasses. Each subsequent subclass is herein used for representing a lower level of precision, e.g. 64Bit > 32Bit > 16Bit.", "New in version 1.20.", "Below is a typical usage example: NBitBase is herein used for annotating a function that takes a float and integer of arbitrary precision as arguments and returns a new float of whichever precision is largest (e.g. np.float16 + np.int64 -> np.float64)."]}, {"name": "flatiter.base", "path": "reference/generated/numpy.flatiter.base", "type": "Indexing routines", "text": ["attribute", "A reference to the array that is iterated over."]}, {"name": "flatiter.coords", "path": "reference/generated/numpy.flatiter.coords", "type": "Indexing routines", "text": ["attribute", "An N-dimensional tuple of current coordinates."]}, {"name": "flatiter.copy()", "path": "reference/generated/numpy.flatiter.copy", "type": "numpy.flatiter.copy", "text": ["method", "Get a copy of the iterator as a 1-D array."]}, {"name": "flatiter.index", "path": "reference/generated/numpy.flatiter.index", "type": "Indexing routines", "text": ["attribute", "Current flat index into the array."]}, {"name": "float npy_half_to_float()", "path": "reference/c-api/coremath#c.npy_half_to_float", "type": "NumPy core libraries", "text": ["Converts a half-precision float to a single-precision float."]}, {"name": "float random_gamma_f()", "path": "reference/random/c-api#c.random_gamma_f", "type": "C API for random", "text": []}, {"name": "float random_standard_exponential_f()", "path": "reference/random/c-api#c.random_standard_exponential_f", "type": "C API for random", "text": []}, {"name": "float random_standard_gamma_f()", "path": "reference/random/c-api#c.random_standard_gamma_f", "type": "C API for random", "text": []}, {"name": "float random_standard_normal_f()", "path": "reference/random/c-api#c.random_standard_normal_f", "type": "C API for random", "text": []}, {"name": "float random_standard_uniform_f()", "path": "reference/random/c-api#c.random_standard_uniform_f", "type": "C API for random", "text": []}, {"name": "Floating point error handling", "path": "reference/routines.err", "type": "Floating point error handling", "text": ["seterr([all, divide, over, under, invalid])", "Set how floating-point errors are handled.", "geterr()", "Get the current way of handling floating-point errors.", "seterrcall(func)", "Set the floating-point error callback function or log object.", "geterrcall()", "Return the current callback function used on floating-point errors.", "errstate(**kwargs)", "Context manager for floating-point error handling.", "seterrobj(errobj, /)", "Set the object that defines floating-point error handling.", "geterrobj()", "Return the current object that defines floating-point error handling."]}, {"name": "For downstream package authors", "path": "user/depending_on_numpy", "type": "User Guide", "text": ["This document aims to explain some best practices for authoring a package that depends on NumPy.", "NumPy uses a standard, PEP 440 compliant, versioning scheme: major.minor.bugfix. A major release is highly unusual (NumPy is still at version 1.xx) and if it happens it will likely indicate an ABI break. Minor versions are released regularly, typically every 6 months. Minor versions contain new features, deprecations, and removals of previously deprecated code. Bugfix releases are made even more frequently; they do not contain any new features or deprecations.", "It is important to know that NumPy, like Python itself and most other well known scientific Python projects, does not use semantic versioning. Instead, backwards incompatible API changes require deprecation warnings for at least two releases. For more details, see NEP 23 \u2014 Backwards compatibility and deprecation policy.", "NumPy has both a Python API and a C API. The C API can be used directly or via Cython, f2py, or other such tools. If your package uses the C API, then ABI (application binary interface) stability of NumPy is important. NumPy\u2019s ABI is forward but not backward compatible. This means: binaries compiled against a given version of NumPy will still run correctly with newer NumPy versions, but not with older versions.", "For large, actively maintained packages that depend on NumPy, we recommend testing against the development version of NumPy in CI. To make this easy, nightly builds are provided as wheels at https://anaconda.org/scipy-wheels-nightly/. This helps detect regressions in NumPy that need fixing before the next NumPy release. Furthermore, we recommend to raise errors on warnings in CI for this job, either all warnings or otherwise at least DeprecationWarning and FutureWarning. This gives you an early warning about changes in NumPy to adapt your code.", "If a package either uses the NumPy C API directly or it uses some other tool that depends on it like Cython or Pythran, NumPy is a build-time dependency of the package. Because the NumPy ABI is only forward compatible, you must build your own binaries (wheels or other package formats) against the lowest NumPy version that you support (or an even older version).", "Picking the correct NumPy version to build against for each Python version and platform can get complicated. There are a couple of ways to do this. Build-time dependencies are specified in pyproject.toml (see PEP 517), which is the file used to build wheels by PEP 517 compliant tools (e.g., when using pip wheel).", "You can specify everything manually in pyproject.toml, or you can instead rely on the oldest-supported-numpy metapackage. oldest-supported-numpy will specify the correct NumPy version at build time for wheels, taking into account Python version, Python implementation (CPython or PyPy), operating system and hardware platform. It will specify the oldest NumPy version that supports that combination of characteristics. Note: for platforms for which NumPy provides wheels on PyPI, it will be the first version with wheels (even if some older NumPy version happens to build).", "For conda-forge it\u2019s a little less complicated: there\u2019s dedicated handling for NumPy in build-time and runtime dependencies, so typically this is enough (see here for docs):", "Note", "pip has --no-use-pep517 and --no-build-isolation flags that may ignore pyproject.toml or treat it differently - if users use those flags, they are responsible for installing the correct build dependencies themselves.", "conda will always use -no-build-isolation; dependencies for conda builds are given in the conda recipe (meta.yaml), the ones in pyproject.toml have no effect.", "Please do not use setup_requires (it is deprecated and may invoke easy_install).", "Because for NumPy you have to care about ABI compatibility, you specify the version with == to the lowest supported version. For your other build dependencies you can probably be looser, however it\u2019s still important to set lower and upper bounds for each dependency. It\u2019s fine to specify either a range or a specific version for a dependency like wheel or setuptools. It\u2019s recommended to set the upper bound of the range to the latest already released version of wheel and setuptools - this prevents future releases from breaking your packages on PyPI.", "NumPy itself and many core scientific Python packages have agreed on a schedule for dropping support for old Python and NumPy versions: NEP 29 \u2014 Recommend Python and NumPy version support as a community policy standard. We recommend all packages depending on NumPy to follow the recommendations in NEP 29.", "For run-time dependencies, you specify the range of versions in install_requires in setup.py (assuming you use numpy.distutils or setuptools to build). Getting the upper bound right for NumPy is slightly tricky. If we don\u2019t set any bound, a too-new version will be pulled in a few years down the line, and NumPy may have deprecated and removed some API that your package depended on by then. On the other hand if you set the upper bound to the newest already-released version, then as soon as a new NumPy version is released there will be no matching version of your package that works with it.", "What to do here depends on your release frequency. Given that NumPy releases come in a 6-monthly cadence and that features that get deprecated in NumPy should stay around for another two releases, a good upper bound is <1.(xx+3).0 - where xx is the minor version of the latest already-released NumPy. This is safe to do if you release at least once a year. If your own releases are much less frequent, you may set the upper bound a little further into the future - this is a trade-off between a future NumPy version _maybe_ removing something you rely on, and the upper bound being exceeded which _may_ lead to your package being hard to install in combination with other packages relying on the latest NumPy.", "Note", "SciPy has more documentation on how it builds wheels and deals with its build-time and runtime dependencies here.", "NumPy and SciPy wheel build CI may also be useful as a reference, it can be found here for NumPy and here for SciPy."]}, {"name": "Fortran 77 programs", "path": "f2py/buildtools/index", "type": "F2PY and Build Systems", "text": ["In this section we will cover the various popular build systems and their usage with f2py.", "Note", "As of November 2021", "The default build system for F2PY has traditionally been the through the enhanced numpy.distutils module. This module is based on distutils which will be removed in Python 3.12.0 in October 2023; setuptools does not have support for Fortran or F2PY and it is unclear if it will be supported in the future. Alternative methods are thus increasingly more important.", "Building an extension module which includes Python and Fortran consists of:", "One or more generated files from f2py", "fortranobject.{c,h}", "NumPy headers", "Broadly speaking there are three cases which arise when considering the outputs of f2py:", "Generates", "When no COMMON blocks are present only a C wrapper file is generated. Wrappers are also generated to rewrite assumed shape arrays as automatic arrays.", "Generates:", "The secondary wrapper is used to handle code which is subdivided into modules. It rewrites assumed shape arrays as automatic arrays.", "Generates:", "Signature files .pyf do not signal their language standard via the file extension, they may generate the F90 and F77 specific wrappers depending on their contents; which shifts the burden of checking for generated files onto the build system.", "Note", "The signature file output situation is being reconsidered in issue 20385 .", "In theory keeping the above requirements in hand, any build system can be adapted to generate f2py extension modules. Here we will cover a subset of the more popular systems.", "Note", "make has no place in a modern multi-language setup, and so is not discussed further."]}, {"name": "Functional programming", "path": "reference/routines.functional", "type": "Functional programming", "text": ["apply_along_axis(func1d, axis, arr, *args, ...)", "Apply a function to 1-D slices along the given axis.", "apply_over_axes(func, a, axes)", "Apply a function repeatedly over multiple axes.", "vectorize(pyfunc[, otypes, doc, excluded, ...])", "Generalized function class.", "frompyfunc(func, /, nin, nout, *[, identity])", "Takes an arbitrary Python function and returns a NumPy ufunc.", "piecewise(x, condlist, funclist, *args, **kw)", "Evaluate a piecewise-defined function."]}, {"name": "generic.__array__()", "path": "reference/generated/numpy.generic.__array__", "type": "numpy.generic.__array__", "text": ["method", "sc.__array__(dtype) return 0-dim array from scalar with specified dtype"]}, {"name": "generic.__array_interface__", "path": "reference/generated/numpy.generic.__array_interface__", "type": "numpy.generic.__array_interface__", "text": ["attribute", "Array protocol: Python side"]}, {"name": "generic.__array_priority__", "path": "reference/generated/numpy.generic.__array_priority__", "type": "numpy.generic.__array_priority__", "text": ["attribute", "Array priority."]}, {"name": "generic.__array_struct__", "path": "reference/generated/numpy.generic.__array_struct__", "type": "numpy.generic.__array_struct__", "text": ["attribute", "Array protocol: struct"]}, {"name": "generic.__array_wrap__()", "path": "reference/generated/numpy.generic.__array_wrap__", "type": "numpy.generic.__array_wrap__", "text": ["method", "sc.__array_wrap__(obj) return scalar from array"]}, {"name": "generic.__reduce__()", "path": "reference/generated/numpy.generic.__reduce__", "type": "numpy.generic.__reduce__", "text": ["method", "Helper for pickle."]}, {"name": "generic.__setstate__()", "path": "reference/generated/numpy.generic.__setstate__", "type": "numpy.generic.__setstate__", "text": ["method"]}, {"name": "generic.base", "path": "reference/generated/numpy.generic.base", "type": "numpy.generic.base", "text": ["attribute", "Scalar attribute identical to the corresponding array attribute.", "Please see ndarray.base."]}, {"name": "generic.byteswap()", "path": "reference/generated/numpy.generic.byteswap", "type": "numpy.generic.byteswap", "text": ["method", "Scalar method identical to the corresponding array attribute.", "Please see ndarray.byteswap."]}, {"name": "generic.data", "path": "reference/generated/numpy.generic.data", "type": "numpy.generic.data", "text": ["attribute", "Pointer to start of data."]}, {"name": "generic.dtype", "path": "reference/generated/numpy.generic.dtype", "type": "numpy.generic.dtype", "text": ["attribute", "Get array data-descriptor."]}, {"name": "generic.flags", "path": "reference/generated/numpy.generic.flags", "type": "numpy.generic.flags", "text": ["attribute", "The integer value of flags."]}, {"name": "generic.flat", "path": "reference/generated/numpy.generic.flat", "type": "numpy.generic.flat", "text": ["attribute", "A 1-D view of the scalar."]}, {"name": "generic.imag", "path": "reference/generated/numpy.generic.imag", "type": "numpy.generic.imag", "text": ["attribute", "The imaginary part of the scalar."]}, {"name": "generic.itemsize", "path": "reference/generated/numpy.generic.itemsize", "type": "numpy.generic.itemsize", "text": ["attribute", "The length of one element in bytes."]}, {"name": "generic.ndim", "path": "reference/generated/numpy.generic.ndim", "type": "numpy.generic.ndim", "text": ["attribute", "The number of array dimensions."]}, {"name": "generic.real", "path": "reference/generated/numpy.generic.real", "type": "numpy.generic.real", "text": ["attribute", "The real part of the scalar."]}, {"name": "generic.setflags()", "path": "reference/generated/numpy.generic.setflags", "type": "numpy.generic.setflags", "text": ["method", "Scalar method identical to the corresponding array attribute.", "Please see ndarray.setflags."]}, {"name": "generic.shape", "path": "reference/generated/numpy.generic.shape", "type": "numpy.generic.shape", "text": ["attribute", "Tuple of array dimensions."]}, {"name": "generic.size", "path": "reference/generated/numpy.generic.size", "type": "numpy.generic.size", "text": ["attribute", "The number of elements in the gentype."]}, {"name": "generic.squeeze()", "path": "reference/generated/numpy.generic.squeeze", "type": "numpy.generic.squeeze", "text": ["method", "Scalar method identical to the corresponding array attribute.", "Please see ndarray.squeeze."]}, {"name": "generic.strides", "path": "reference/generated/numpy.generic.strides", "type": "numpy.generic.strides", "text": ["attribute", "Tuple of bytes steps in each dimension."]}, {"name": "generic.T", "path": "reference/generated/numpy.generic.t", "type": "numpy.generic.T", "text": ["attribute", "Scalar attribute identical to the corresponding array attribute.", "Please see ndarray.T."]}, {"name": "Get the local copy of the code", "path": "dev/gitwash/following_latest", "type": "Development", "text": ["From the command line:", "You now have a copy of the code tree in the new numpy directory. If this doesn\u2019t work you can try the alternative read-only url:"]}, {"name": "get_build_temp_dir()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_build_temp_dir", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Return a path to a temporary directory where temporary files should be placed."]}, {"name": "get_config_cmd()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_config_cmd", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Returns the numpy.distutils config command instance."]}, {"name": "get_distribution()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_distribution", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Return the distutils distribution object for self."]}, {"name": "get_info()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_info", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Get resources information.", "Return information (from system_info.get_info) for all of the names in the argument list in a single dictionary."]}, {"name": "get_subpackage()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_subpackage", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Return list of subpackage configurations.", "Name of the subpackage to get the configuration. \u2018*\u2019 in subpackage_name is handled as a wildcard.", "If None, then the path is assumed to be the local path plus the subpackage_name. If a setup.py file is not found in the subpackage_path, then a default configuration is used.", "Parent name."]}, {"name": "get_version()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_version", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Try to get version string of a package.", "Return a version string of the current package or None if the version information could not be detected.", "This method scans files named __version__.py, <packagename>_version.py, version.py, and __svn_version__.py for string variables version, __version__, and <packagename>_version, until a version number is found."]}, {"name": "Git configuration", "path": "dev/gitwash/configure_git", "type": "Development", "text": ["Your personal git configurations are saved in the .gitconfig file in your home directory. Here is an example .gitconfig file:", "You can edit this file directly or you can use the git config --global command:", "To set up on another computer, you can copy your ~/.gitconfig file, or run the commands above.", "It is good practice to tell git who you are, for labeling any changes you make to the code. The simplest way to do this is from the command line:", "This will write the settings into your git configuration file, which should now contain a user section with your name and email:", "Of course you\u2019ll need to replace Your Name and you@yourdomain.example.com with your actual name and email address.", "You might well benefit from some aliases to common commands.", "For example, you might well want to be able to shorten git checkout to git co. Or you may want to alias git diff --color-words (which gives a nicely formatted output of the diff) to git wdiff", "The following git config --global commands:", "will create an alias section in your .gitconfig file with contents like this:", "You may also want to make sure that your editor of choice is used", "To enforce summaries when doing merges (~/.gitconfig file again):", "Or from the command line:"]}, {"name": "Git for development", "path": "dev/gitwash/index", "type": "Development", "text": ["These pages describe a general git and github workflow.", "This is not a comprehensive git reference. It\u2019s tailored to the github hosting service. You may well find better or quicker ways of getting stuff done with git, but these should get you started.", "For general resources for learning git see Additional Git Resources.", "Have a look at the github install help pages available from github help", "Contents:"]}, {"name": "Global State", "path": "reference/global_state", "type": "Global State", "text": ["NumPy has a few import-time, compile-time, or runtime options which change the global behaviour. Most of these are related to performance or for debugging purposes and will not be interesting to the vast majority of users.", "NumPy itself is normally intentionally limited to a single thread during function calls, however it does support multiple Python threads running at the same time. Note that for performant linear algebra NumPy uses a BLAS backend such as OpenBLAS or MKL, which may use multiple threads that may be controlled by environment variables such as OMP_NUM_THREADS depending on what is used. One way to control the number of threads is the package threadpoolctl", "When working with very large arrays on modern Linux kernels, you can experience a significant speedup when transparent hugepage is used. The current system policy for transparent hugepages can be seen by:", "When set to madvise NumPy will typically use hugepages for a performance boost. This behaviour can be modified by setting the environment variable:", "or setting it to 1 to always enable it. When not set, the default is to use madvise on Kernels 4.6 and newer. These kernels presumably experience a large speedup with hugepage support. This flag is checked at import time.", "The array function protocol which allows array-like objects to hook into the NumPy API is currently enabled by default. This option exists since NumPy 1.16 and is enabled by default since NumPy 1.17. It can be disabled using:", "See also numpy.class.__array_function__ for more information. This flag is checked at import time.", "The compile-time environment variables:", "control how NumPy reports contiguity for arrays. The default that it is enabled and the debug mode is disabled. This setting should always be enabled. Setting the debug option can be interesting for testing code written in C which iterates through arrays that may or may not be contiguous in memory. Most users will have no reason to change these; for details see the memory layout documentation.", "Some users might pass ownership of the data pointer to the ndarray by setting the OWNDATA flag. If they do this without setting (manually) a memory allocation policy, the default will be to call free. If NUMPY_WARN_IF_NO_MEM_POLICY is set to \"1\", a RuntimeWarning will be emitted. A better alternative is to use a PyCapsule with a deallocator and set the ndarray.base."]}, {"name": "have_f77c()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.have_f77c", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Check for availability of Fortran 77 compiler.", "Use it inside source generating function to ensure that setup distribution instance has been initialized.", "True if a Fortran 77 compiler is available (because a simple Fortran 77 code was able to be compiled successfully)."]}, {"name": "have_f90c()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.have_f90c", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Check for availability of Fortran 90 compiler.", "Use it inside source generating function to ensure that setup distribution instance has been initialized.", "True if a Fortran 90 compiler is available (because a simple Fortran 90 code was able to be compiled successfully)"]}, {"name": "Hermite Series, \u201cPhysicists\u201d (numpy.polynomial.hermite)", "path": "reference/routines.polynomials.hermite", "type": "Hermite Series, \u201cPhysicists\u201d ( \n        \n         numpy.polynomial.hermite\n        \n        )", "text": ["This module provides a number of objects (mostly functions) useful for dealing with Hermite series, including a Hermite class that encapsulates the usual arithmetic operations. (General information on how this module represents and works with such polynomials is in the docstring for its \u201cparent\u201d sub-package, numpy.polynomial).", "Hermite(coef[, domain, window])", "An Hermite series class.", "hermdomain", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermzero", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermone", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermx", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermadd(c1, c2)", "Add one Hermite series to another.", "hermsub(c1, c2)", "Subtract one Hermite series from another.", "hermmulx(c)", "Multiply a Hermite series by x.", "hermmul(c1, c2)", "Multiply one Hermite series by another.", "hermdiv(c1, c2)", "Divide one Hermite series by another.", "hermpow(c, pow[, maxpower])", "Raise a Hermite series to a power.", "hermval(x, c[, tensor])", "Evaluate an Hermite series at points x.", "hermval2d(x, y, c)", "Evaluate a 2-D Hermite series at points (x, y).", "hermval3d(x, y, z, c)", "Evaluate a 3-D Hermite series at points (x, y, z).", "hermgrid2d(x, y, c)", "Evaluate a 2-D Hermite series on the Cartesian product of x and y.", "hermgrid3d(x, y, z, c)", "Evaluate a 3-D Hermite series on the Cartesian product of x, y, and z.", "hermder(c[, m, scl, axis])", "Differentiate a Hermite series.", "hermint(c[, m, k, lbnd, scl, axis])", "Integrate a Hermite series.", "hermfromroots(roots)", "Generate a Hermite series with given roots.", "hermroots(c)", "Compute the roots of a Hermite series.", "hermvander(x, deg)", "Pseudo-Vandermonde matrix of given degree.", "hermvander2d(x, y, deg)", "Pseudo-Vandermonde matrix of given degrees.", "hermvander3d(x, y, z, deg)", "Pseudo-Vandermonde matrix of given degrees.", "hermgauss(deg)", "Gauss-Hermite quadrature.", "hermweight(x)", "Weight function of the Hermite polynomials.", "hermcompanion(c)", "Return the scaled companion matrix of c.", "hermfit(x, y, deg[, rcond, full, w])", "Least squares fit of Hermite series to data.", "hermtrim(c[, tol])", "Remove \"small\" \"trailing\" coefficients from a polynomial.", "hermline(off, scl)", "Hermite series whose graph is a straight line.", "herm2poly(c)", "Convert a Hermite series to a polynomial.", "poly2herm(pol)", "Convert a polynomial to a Hermite series.", "numpy.polynomial"]}, {"name": "HermiteE Series, \u201cProbabilists\u201d (numpy.polynomial.hermite_e)", "path": "reference/routines.polynomials.hermite_e", "type": "HermiteE Series, \u201cProbabilists\u201d ( \n        \n         numpy.polynomial.hermite_e\n        \n        )", "text": ["This module provides a number of objects (mostly functions) useful for dealing with Hermite_e series, including a HermiteE class that encapsulates the usual arithmetic operations. (General information on how this module represents and works with such polynomials is in the docstring for its \u201cparent\u201d sub-package, numpy.polynomial).", "HermiteE(coef[, domain, window])", "An HermiteE series class.", "hermedomain", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermezero", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermeone", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermex", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "hermeadd(c1, c2)", "Add one Hermite series to another.", "hermesub(c1, c2)", "Subtract one Hermite series from another.", "hermemulx(c)", "Multiply a Hermite series by x.", "hermemul(c1, c2)", "Multiply one Hermite series by another.", "hermediv(c1, c2)", "Divide one Hermite series by another.", "hermepow(c, pow[, maxpower])", "Raise a Hermite series to a power.", "hermeval(x, c[, tensor])", "Evaluate an HermiteE series at points x.", "hermeval2d(x, y, c)", "Evaluate a 2-D HermiteE series at points (x, y).", "hermeval3d(x, y, z, c)", "Evaluate a 3-D Hermite_e series at points (x, y, z).", "hermegrid2d(x, y, c)", "Evaluate a 2-D HermiteE series on the Cartesian product of x and y.", "hermegrid3d(x, y, z, c)", "Evaluate a 3-D HermiteE series on the Cartesian product of x, y, and z.", "hermeder(c[, m, scl, axis])", "Differentiate a Hermite_e series.", "hermeint(c[, m, k, lbnd, scl, axis])", "Integrate a Hermite_e series.", "hermefromroots(roots)", "Generate a HermiteE series with given roots.", "hermeroots(c)", "Compute the roots of a HermiteE series.", "hermevander(x, deg)", "Pseudo-Vandermonde matrix of given degree.", "hermevander2d(x, y, deg)", "Pseudo-Vandermonde matrix of given degrees.", "hermevander3d(x, y, z, deg)", "Pseudo-Vandermonde matrix of given degrees.", "hermegauss(deg)", "Gauss-HermiteE quadrature.", "hermeweight(x)", "Weight function of the Hermite_e polynomials.", "hermecompanion(c)", "Return the scaled companion matrix of c.", "hermefit(x, y, deg[, rcond, full, w])", "Least squares fit of Hermite series to data.", "hermetrim(c[, tol])", "Remove \"small\" \"trailing\" coefficients from a polynomial.", "hermeline(off, scl)", "Hermite series whose graph is a straight line.", "herme2poly(c)", "Convert a Hermite series to a polynomial.", "poly2herme(pol)", "Convert a polynomial to a Hermite series.", "numpy.polynomial"]}, {"name": "How to write a NumPy how-to", "path": "user/how-to-how-to", "type": "User Guide", "text": ["How-tos get straight to the point \u2013 they", "\u201cI need to refuel my car.\u201d", "Add helpful details for newcomers (\u201cHayseed Road\u201d, even though it\u2019s the only turnoff at three km/mi). But not irrelevant ones:", "If there\u2019s related background (tutorial, explanation, reference, alternative approach), bring it to the user\u2019s attention with a link (\u201cDirections from Route 7,\u201d \u201cWhy so few filling stations?\u201d).", "If the information is already documented and succinct enough for a how-to, just link to it, possibly after an introduction (\u201cThree km/mi, take a right\u201d).", "\u201cI want to see the sights.\u201d", "The See the sights how-to should link to a set of narrower how-tos:", "and these might in turn link to still narrower how-tos \u2013 so the town center page might link to", "By organizing how-tos this way, you not only display the options for people who need to narrow their question, you also have provided answers for users who start with narrower questions (\u201cI want to see historic buildings,\u201d \u201cWhich way to city hall?\u201d).", "If a how-to has many steps:", "People use the terms \u201chow-to\u201d and \u201ctutorial\u201d interchangeably, but we draw a distinction, following Daniele Procida\u2019s taxonomy of documentation.", "Documentation needs to meet users where they are. How-tos offer get-it-done information; the user wants steps to copy and doesn\u2019t necessarily want to understand NumPy. Tutorials are warm-fuzzy information; the user wants a feel for some aspect of NumPy (and again, may or may not care about deeper knowledge).", "We distinguish both tutorials and how-tos from Explanations, which are deep dives intended to give understanding rather than immediate assistance, and References, which give complete, authoritative data on some concrete part of NumPy (like its API) but aren\u2019t obligated to paint a broader picture.", "For more on tutorials, see Learn to write a NumPy tutorial", "Yes \u2013 until the sections with question-mark headings; they explain rather than giving directions. In a how-to, those would be links."]}, {"name": "I/O with NumPy", "path": "user/basics.io", "type": "User Guide", "text": []}, {"name": "include statements", "path": "f2py/signature-file", "type": "Signature file", "text": ["The syntax specification for signature files (.pyf files) is modeled on the Fortran 90/95 language specification. Almost all Fortran 90/95 standard constructs are understood, both in free and fixed format (recall that Fortran 77 is a subset of Fortran 90/95). F2PY introduces some extensions to the Fortran 90/95 language specification that help in the design of the Fortran to Python interface, making it more \u201cPythonic\u201d.", "Signature files may contain arbitrary Fortran code so that any Fortran 90/95 codes can be treated as signature files. F2PY silently ignores Fortran constructs that are irrelevant for creating the interface. However, this also means that syntax errors are not caught by F2PY and will only be caught when the library is built.", "In general, the contents of the signature files are case-sensitive. When scanning Fortran codes to generate a signature file, F2PY lowers all cases automatically except in multi-line blocks or when the --no-lower option is used.", "The syntax of signature files is presented below.", "A signature file may contain one (recommended) or more python\nmodule blocks. The python module block describes the contents of a Python/C extension module <modulename>module.c that F2PY generates.", "Warning", "Exception: if <modulename> contains a substring __user__, then the corresponding python module block describes the signatures of call-back functions (see Call-back arguments).", "A python module block has the following structure:", "Here brackets [] indicate an optional section, dots ... indicate one or more of a previous section. So, []... is to be read as zero or more of a previous section.", "The signature of a Fortran routine has the following structure:", "From a Fortran routine signature F2PY generates a Python/C extension function that has the following signature:", "The signature of a Fortran block data has the following structure:", "The definition of the <argument/variable type declaration> part is", "where", "and", "If an argument has no <argument type declaration>, its type is determined by applying implicit rules to its name.", "The definition of the <use statement> part is", "where", "The definition of the <common block statement> part is", "where", "The <other statement> part refers to any other Fortran language constructs that are not described above. F2PY ignores most of them except the following:", "If a file <filename> does not exist, the include statement is ignored. Otherwise, the file <filename> is included to a signature file. include statements can be used in any part of a signature file, also outside the Fortran/C routine signature blocks.", "where", "Implicit rules are used to determine the type specification of a variable (from the first-letter of its name) if the variable is not defined using <variable type declaration>. Default implicit rules are given by:", "F2PY generates wrappers for all entry names using the signature of the routine block.", "Note", "The entry statement can be used to describe the signature of an arbitrary subroutine or function allowing F2PY to generate a number of wrappers from only one routine block signature. There are few restrictions while doing this: fortranname cannot be used, callstatement and callprotoargument can be used only if they are valid for all entry routines, etc.", "In addition, F2PY introduces the following statements:", "Uses a Py_BEGIN_ALLOW_THREADS .. Py_END_ALLOW_THREADS block around the call to Fortran/C function.", "Replaces the F2PY generated call statement to Fortran/C function with <C-expr|multi-line block>. The wrapped Fortran/C function is available as (*f2py_func).", "To raise an exception, set f2py_success = 0 in <C-expr|multi-line\nblock>.", "When the callstatement statement is used then F2PY may not generate proper prototypes for Fortran/C functions (because <C-expr> may contain any function calls and F2PY has no way to determine what should be the proper prototype).", "With this statement you can explicitly specify the arguments of the corresponding prototype:", "F2PY allows for the use of an arbitrary <routine name> for a given Fortran/C function. Then this statement is used for the <actual\nFortran/C routine name>.", "If fortranname statement is used without <actual Fortran/C routine name> then a dummy wrapper is generated.", "When this is used inside a python module block, the given C code will be inserted to generated C/API source just before wrapper function definitions.", "Here you can define arbitrary C functions to be used for the initialization of optional arguments.", "For example, if usercode is used twice inside python module block then the second multi-line block is inserted after the definition of the external routines.", "When used inside <routine signature>, then the given C code will be inserted into the corresponding wrapper function just after the declaration of variables but before any C statements. So, the usercode follow-up can contain both declarations and C statements.", "When used inside the first interface block, then the given C code will be inserted at the end of the initialization function of the extension module. This is how the extension modules dictionary can be modified and has many use-cases; for example, to define additional variables.", "This is a multi-line block which will be inserted into the definition of a module methods PyMethodDef-array. It must be a comma-separated list of C arrays (see Extending and Embedding Python documentation for details). pymethoddef statement can be used only inside python\nmodule block.", "The following attributes are used by F2PY:", "The corresponding argument is moved to the end of <optional\narguments> list. A default value for an optional argument can be specified via <init_expr>, see the entitydecl definition.", "Note", "The corresponding argument with this attribute considered mandatory. This is the default. required should only be specified if there is a need to disable the automatic optional setting when <init_expr> is used.", "If a Python None object is used as a required argument, the argument is treated as optional. That is, in the case of array argument, the memory is allocated. If <init_expr> is given, then the corresponding initialization is carried out.", "The corresponding variable is considered as an array with dimensions given in <arrayspec>.", "This specifies the \u201cintention\u201d of the corresponding argument. <intentspec> is a comma separated list of the following keys:", "The corresponding argument is considered to be input-only. This means that the value of the argument is passed to a Fortran/C function and that the function is expected to not change the value of this argument.", "The corresponding argument is marked for input/output or as an in situ output argument. intent(inout) arguments can be only \u201ccontiguous\u201d NumPy arrays with proper type and size. Here \u201ccontiguous\u201d can be either in the Fortran or C sense. The latter coincides with the default contiguous concept used in NumPy and is effective only if intent(c) is used. F2PY assumes Fortran contiguous arguments by default.", "Note", "Using intent(inout) is generally not recommended, use intent(in,out) instead.", "See also the intent(inplace) attribute.", "The corresponding argument is considered to be an input/output or in situ output argument. intent(inplace) arguments must be NumPy arrays of a proper size. If the type of an array is not \u201cproper\u201d or the array is non-contiguous then the array will be modified in-place to fix the type and make it contiguous.", "Note", "Using intent(inplace) is generally not recommended either.", "For example, when slices have been taken from an intent(inplace) argument then after in-place changes, the data pointers for the slices may point to an unallocated memory area.", "The corresponding argument is considered to be a return variable. It is appended to the <returned variables> list. Using intent(out) sets intent(hide) automatically, unless intent(in) or intent(inout) are specified as well.", "By default, returned multidimensional arrays are Fortran-contiguous. If intent(c) attribute is used, then the returned multidimensional arrays are C-contiguous.", "The corresponding argument is removed from the list of required or optional arguments. Typically intent(hide) is used with intent(out) or when <init_expr> completely determines the value of the argument like in the following example:", "The corresponding argument is treated as a C scalar or C array argument. For the case of a scalar argument, its value is passed to a C function as a C scalar argument (recall that Fortran scalar arguments are actually C pointer arguments). For array arguments, the wrapper function is assumed to treat multidimensional arrays as C-contiguous arrays.", "There is no need to use intent(c) for one-dimensional arrays, irrespective of whether the wrapped function is in Fortran or C. This is because the concepts of Fortran- and C contiguity overlap in one-dimensional cases.", "If intent(c) is used as a statement but without an entity declaration list, then F2PY adds the intent(c) attribute to all arguments.", "Also, when wrapping C functions, one must use intent(c) attribute for <routine name> in order to disable Fortran specific F_FUNC(..,..) macros.", "The corresponding argument is treated as junk memory. No Fortran nor C contiguity checks are carried out. Using intent(cache) makes sense only for array arguments, also in conjunction with intent(hide) or optional attributes.", "Ensures that the original contents of intent(in) argument is preserved. Typically used with the intent(in,out) attribute. F2PY creates an optional argument overwrite_<argument name> with the default value 0.", "This indicates that the original contents of the intent(in) argument may be altered by the Fortran/C function. F2PY creates an optional argument overwrite_<argument name> with the default value 1.", "Replaces the returned name with <new name> in the __doc__ string of the wrapper function.", "Constructs an external function suitable for calling Python functions from Fortran. intent(callback) must be specified before the corresponding external statement. If the \u2018argument\u2019 is not in the argument list then it will be added to Python wrapper but only by initializing an external function.", "Note", "Use intent(callback) in situations where the Fortran/C code assumes that the user implemented a function with a given prototype and linked it to an executable. Don\u2019t use intent(callback) if the function appears in the argument list of a Fortran routine.", "With intent(hide) or optional attributes specified and using a wrapper function without specifying the callback argument in the argument list; then the call-back function is assumed to be found in the namespace of the F2PY generated extension module where it can be set as a module attribute by a user.", "Defines an auxiliary C variable in the F2PY generated wrapper function. Useful to save parameter values so that they can be accessed in initialization expressions for other variables.", "Note", "intent(aux) silently implies intent(c).", "The following rules apply:", "If none of intent(in | inout | out | hide) are specified, intent(in) is assumed.", "If intent(copy) or intent(overwrite) is used, then an additional optional argument is introduced with a name overwrite_<argument name> and a default value 0 or 1, respectively.", "Performs a consistency check on the arguments by evaluating <C-booleanexpr>; if <C-booleanexpr> returns 0, an exception is raised.", "Note", "If check(..) is not used then F2PY automatically generates a few standard checks (e.g. in a case of an array argument, it checks for the proper shape and size). Use check() to disable checks generated by F2PY.", "This declares that the corresponding argument depends on the values of variables in the <names> list. For example, <init_expr> may use the values of other arguments. Using information given by depend(..) attributes, F2PY ensures that arguments are initialized in a proper order. If the depend(..) attribute is not used then F2PY determines dependence relations automatically. Use depend() to disable the dependence relations generated by F2PY.", "When you edit dependence relations that were initially generated by F2PY, be careful not to break the dependence relations of other relevant variables. Another thing to watch out for is cyclic dependencies. F2PY is able to detect cyclic dependencies when constructing wrappers and it complains if any are found.", "The corresponding variable is a Fortran 90 allocatable array defined as Fortran 90 module data.", "The corresponding argument is a function provided by user. The signature of this call-back function can be defined", "For example, F2PY generates from:", "the following call-back signatures:", "The corresponding user-provided Python function are then:", "See also the intent(callback) attribute.", "This indicates that the corresponding variable is a parameter and it must have a fixed value. F2PY replaces all parameter occurrences by their corresponding values.", "The F2PY directives allow using F2PY signature file constructs in Fortran 77/90 source codes. With this feature one can (almost) completely skip the intermediate signature file generation and apply F2PY directly to Fortran source codes.", "F2PY directives have the following form:", "where allowed comment characters for fixed and free format Fortran codes are cC*!# and !, respectively. Everything that follows <comment char>f2py is ignored by a compiler but read by F2PY as a normal non-comment Fortran line:", "Note", "When F2PY finds a line with F2PY directive, the directive is first replaced by 5 spaces and then the line is reread.", "For fixed format Fortran codes, <comment char> must be at the first column of a file, of course. For free format Fortran codes, the F2PY directives can appear anywhere in a file.", "C expressions are used in the following parts of signature files:", "A C expression may contain:", "the following CPP macros:", "For initializing an array <array name>, F2PY generates a loop over all indices and dimensions that executes the following pseudo-statement:", "where _i[<i>] refers to the <i>-th index value and that runs from 0 to shape(<array name>,<i>)-1.", "For example, a function myrange(n) generated from the following signature", "is equivalent to numpy.arange(n,dtype=float).", "Warning", "F2PY may lower cases also in C expressions when scanning Fortran codes (see --[no]-lower option).", "A multi-line block starts with ''' (triple single-quotes) and ends with ''' in some strictly subsequent line. Multi-line blocks can be used only within .pyf files. The contents of a multi-line block can be arbitrary (except that it cannot contain ''') and no transformations (e.g. lowering cases) are applied to it.", "Currently, multi-line blocks can be used in the following constructs:"]}, {"name": "Indexing on ndarrays", "path": "user/basics.indexing", "type": "User Guide", "text": ["See also", "Indexing routines", "ndarrays can be indexed using the standard Python x[obj] syntax, where x is the array and obj the selection. There are different kinds of indexing available depending on obj: basic indexing, advanced indexing and field access.", "Most of the following examples show the use of indexing when referencing data in an array. The examples work just as well when assigning to an array. See Assigning values to indexed arrays for specific examples and explanations on how assignments work.", "Note that in Python, x[(exp1, exp2, ..., expN)] is equivalent to x[exp1, exp2, ..., expN]; the latter is just syntactic sugar for the former.", "Single element indexing works exactly like that for other standard Python sequences. It is 0-based, and accepts negative indices for indexing from the end of the array.", "It is not necessary to separate each dimension\u2019s index into its own set of square brackets.", "Note that if one indexes a multidimensional array with fewer indices than dimensions, one gets a subdimensional array. For example:", "That is, each index specified selects the array corresponding to the rest of the dimensions selected. In the above example, choosing 0 means that the remaining dimension of length 5 is being left unspecified, and that what is returned is an array of that dimensionality and size. It must be noted that the returned array is a view, i.e., it is not a copy of the original, but points to the same values in memory as does the original array. In this case, the 1-D array at the first position (0) is returned. So using a single index on the returned array, results in a single element being returned. That is:", "So note that x[0, 2] == x[0][2] though the second case is more inefficient as a new temporary array is created after the first index that is subsequently indexed by 2.", "Note", "NumPy uses C-order indexing. That means that the last index usually represents the most rapidly changing memory location, unlike Fortran or IDL, where the first index represents the most rapidly changing location in memory. This difference represents a great potential for confusion.", "Basic slicing extends Python\u2019s basic concept of slicing to N dimensions. Basic slicing occurs when obj is a slice object (constructed by start:stop:step notation inside of brackets), an integer, or a tuple of slice objects and integers. Ellipsis and newaxis objects can be interspersed with these as well.", "Deprecated since version 1.15.0: In order to remain backward compatible with a common usage in Numeric, basic slicing is also initiated if the selection object is any non-ndarray and non-tuple sequence (such as a list) containing slice objects, the Ellipsis object, or the newaxis object, but not for integer arrays or other embedded sequences.", "The simplest case of indexing with N integers returns an array scalar representing the corresponding item. As in Python, all indices are zero-based: for the i-th index \\(n_i\\), the valid range is \\(0 \\le n_i < d_i\\) where \\(d_i\\) is the i-th element of the shape of the array. Negative indices are interpreted as counting from the end of the array (i.e., if \\(n_i < 0\\), it means \\(n_i + d_i\\)).", "All arrays generated by basic slicing are always views of the original array.", "Note", "NumPy slicing creates a view instead of a copy as in the case of built-in Python sequences such as string, tuple and list. Care must be taken when extracting a small portion from a large array which becomes useless after the extraction, because the small portion extracted contains a reference to the large original array whose memory will not be released until all arrays derived from it are garbage-collected. In such cases an explicit copy() is recommended.", "The standard rules of sequence slicing apply to basic slicing on a per-dimension basis (including using a step index). Some useful concepts to remember include:", "The basic slice syntax is i:j:k where i is the starting index, j is the stopping index, and k is the step (\\(k\\neq0\\)). This selects the m elements (in the corresponding dimension) with index values i, i + k, \u2026, i + (m - 1) k where \\(m = q + (r\\neq0)\\) and q and r are the quotient and remainder obtained by dividing j - i by k: j - i = q k + r, so that i + (m - 1) k < j. For example:", "Negative i and j are interpreted as n + i and n + j where n is the number of elements in the corresponding dimension. Negative k makes stepping go towards smaller indices. From the above example:", "Assume n is the number of elements in the dimension being sliced. Then, if i is not given it defaults to 0 for k > 0 and n - 1 for k < 0 . If j is not given it defaults to n for k > 0 and -n-1 for k < 0 . If k is not given it defaults to 1. Note that :: is the same as : and means select all indices along this axis. From the above example:", "If the number of objects in the selection tuple is less than N, then : is assumed for any subsequent dimensions. For example:", "Basic slicing with more than one non-: entry in the slicing tuple, acts like repeated application of slicing using a single non-: entry, where the non-: entries are successively taken (with all other non-: entries replaced by :). Thus, x[ind1, ..., ind2,:] acts like x[ind1][..., ind2, :] under basic slicing.", "Warning", "The above is not true for advanced indexing.", "There are some tools to facilitate the easy matching of array shapes with expressions and in assignments.", "Ellipsis expands to the number of : objects needed for the selection tuple to index all dimensions. In most cases, this means that the length of the expanded selection tuple is x.ndim. There may only be a single ellipsis present. From the above example:", "This is equivalent to:", "Each newaxis object in the selection tuple serves to expand the dimensions of the resulting selection by one unit-length dimension. The added dimension is the position of the newaxis object in the selection tuple. newaxis is an alias for None, and None can be used in place of this with the same result. From the above example:", "This can be handy to combine two arrays in a way that otherwise would require explicit reshaping operations. For example:", "Advanced indexing is triggered when the selection object, obj, is a non-tuple sequence object, an ndarray (of data type integer or bool), or a tuple with at least one sequence object or ndarray (of data type integer or bool). There are two types of advanced indexing: integer and Boolean.", "Advanced indexing always returns a copy of the data (contrast with basic slicing that returns a view).", "Warning", "The definition of advanced indexing means that x[(1, 2, 3),] is fundamentally different than x[(1, 2, 3)]. The latter is equivalent to x[1, 2, 3] which will trigger basic selection while the former will trigger advanced indexing. Be sure to understand why this occurs.", "Also recognize that x[[1, 2, 3]] will trigger advanced indexing, whereas due to the deprecated Numeric compatibility mentioned above, x[[1, 2, slice(None)]] will trigger basic slicing.", "Integer array indexing allows selection of arbitrary items in the array based on their N-dimensional index. Each integer array represents a number of indices into that dimension.", "Negative values are permitted in the index arrays and work as they do with single indices or slices:", "If the index values are out of bounds then an IndexError is thrown:", "When the index consists of as many integer arrays as dimensions of the array being indexed, the indexing is straightforward, but different from slicing.", "Advanced indices always are broadcast and iterated as one:", "Note that the resulting shape is identical to the (broadcast) indexing array shapes ind_1, ..., ind_N. If the indices cannot be broadcast to the same shape, an exception IndexError: shape mismatch: indexing arrays could\nnot be broadcast together with shapes... is raised.", "Indexing with multidimensional index arrays tend to be more unusual uses, but they are permitted, and they are useful for some problems. We\u2019ll start with the simplest multidimensional case:", "In this case, if the index arrays have a matching shape, and there is an index array for each dimension of the array being indexed, the resultant array has the same shape as the index arrays, and the values correspond to the index set for each position in the index arrays. In this example, the first index value is 0 for both index arrays, and thus the first value of the resultant array is y[0, 0]. The next value is y[2, 1], and the last is y[4, 2].", "If the index arrays do not have the same shape, there is an attempt to broadcast them to the same shape. If they cannot be broadcast to the same shape, an exception is raised:", "The broadcasting mechanism permits index arrays to be combined with scalars for other indices. The effect is that the scalar value is used for all the corresponding values of the index arrays:", "Jumping to the next level of complexity, it is possible to only partially index an array with index arrays. It takes a bit of thought to understand what happens in such cases. For example if we just use one index array with y:", "It results in the construction of a new array where each value of the index array selects one row from the array being indexed and the resultant array has the resulting shape (number of index elements, size of row).", "In general, the shape of the resultant array will be the concatenation of the shape of the index array (or the shape that all the index arrays were broadcast to) with the shape of any unused dimensions (those not indexed) in the array being indexed.", "From each row, a specific element should be selected. The row index is just [0, 1, 2] and the column index specifies the element to choose for the corresponding row, here [0, 1, 0]. Using both together the task can be solved using advanced indexing:", "To achieve a behaviour similar to the basic slicing above, broadcasting can be used. The function ix_ can help with this broadcasting. This is best understood with an example.", "From a 4x3 array the corner elements should be selected using advanced indexing. Thus all elements for which the column is one of [0, 2] and the row is one of [0, 3] need to be selected. To use advanced indexing one needs to select all elements explicitly. Using the method explained previously one could write:", "However, since the indexing arrays above just repeat themselves, broadcasting can be used (compare operations such as rows[:, np.newaxis] + columns) to simplify this:", "This broadcasting can also be achieved using the function ix_:", "Note that without the np.ix_ call, only the diagonal elements would be selected:", "This difference is the most important thing to remember about indexing with multiple advanced indices.", "A real-life example of where advanced indexing may be useful is for a color lookup table where we want to map the values of an image into RGB triples for display. The lookup table could have a shape (nlookup, 3). Indexing such an array with an image with shape (ny, nx) with dtype=np.uint8 (or any integer type so long as values are with the bounds of the lookup table) will result in an array of shape (ny, nx, 3) where a triple of RGB values is associated with each pixel location.", "This advanced indexing occurs when obj is an array object of Boolean type, such as may be returned from comparison operators. A single boolean index array is practically identical to x[obj.nonzero()] where, as described above, obj.nonzero() returns a tuple (of length obj.ndim) of integer index arrays showing the True elements of obj. However, it is faster when obj.shape == x.shape.", "If obj.ndim == x.ndim, x[obj] returns a 1-dimensional array filled with the elements of x corresponding to the True values of obj. The search order will be row-major, C-style. If obj has True values at entries that are outside of the bounds of x, then an index error will be raised. If obj is smaller than x it is identical to filling it with False.", "A common use case for this is filtering for desired element values. For example, one may wish to select all entries from an array which are not NaN:", "Or wish to add a constant to all negative elements:", "In general if an index includes a Boolean array, the result will be identical to inserting obj.nonzero() into the same position and using the integer array indexing mechanism described above. x[ind_1, boolean_array, ind_2] is equivalent to x[(ind_1,) + boolean_array.nonzero() + (ind_2,)].", "If there is only one Boolean array and no integer indexing array present, this is straightforward. Care must only be taken to make sure that the boolean index has exactly as many dimensions as it is supposed to work with.", "In general, when the boolean array has fewer dimensions than the array being indexed, this is equivalent to x[b, ...], which means x is indexed by b followed by as many : as are needed to fill out the rank of x. Thus the shape of the result is one dimension containing the number of True elements of the boolean array, followed by the remaining dimensions of the array being indexed:", "Here the 4th and 5th rows are selected from the indexed array and combined to make a 2-D array.", "From an array, select all rows which sum up to less or equal two:", "Combining multiple Boolean indexing arrays or a Boolean with an integer indexing array can best be understood with the obj.nonzero() analogy. The function ix_ also supports boolean arrays and will work without any surprises.", "Use boolean indexing to select all rows adding up to an even number. At the same time columns 0 and 2 should be selected with an advanced integer index. Using the ix_ function this can be done with:", "Without the np.ix_ call, only the diagonal elements would be selected.", "Or without np.ix_ (compare the integer array examples):", "Use a 2-D boolean array of shape (2, 3) with four True elements to select rows from a 3-D array of shape (2, 3, 5) results in a 2-D result of shape (4, 5):", "When there is at least one slice (:), ellipsis (...) or newaxis in the index (or the array has more dimensions than there are advanced indices), then the behaviour can be more complicated. It is like concatenating the indexing result for each advanced index element.", "In the simplest case, there is only a single advanced index combined with a slice. For example:", "In effect, the slice and index array operation are independent. The slice operation extracts columns with index 1 and 2, (i.e. the 2nd and 3rd columns), followed by the index array operation which extracts rows with index 0, 2 and 4 (i.e the first, third and fifth rows). This is equivalent to:", "A single advanced index can, for example, replace a slice and the result array will be the same. However, it is a copy and may have a different memory layout. A slice is preferable when it is possible. For example:", "The easiest way to understand a combination of multiple advanced indices may be to think in terms of the resulting shape. There are two parts to the indexing operation, the subspace defined by the basic indexing (excluding integers) and the subspace from the advanced indexing part. Two cases of index combination need to be distinguished:", "In the first case, the dimensions resulting from the advanced indexing operation come first in the result array, and the subspace dimensions after that. In the second case, the dimensions from the advanced indexing operations are inserted into the result array at the same spot as they were in the initial array (the latter logic is what makes simple advanced indexing behave just like slicing).", "Suppose x.shape is (10, 20, 30) and ind is a (2, 3, 4)-shaped indexing intp array, then result = x[..., ind, :] has shape (10, 2, 3, 4, 30) because the (20,)-shaped subspace has been replaced with a (2, 3, 4)-shaped broadcasted indexing subspace. If we let i, j, k loop over the (2, 3, 4)-shaped subspace then result[..., i, j, k, :] = x[..., ind[i, j, k], :]. This example produces the same result as x.take(ind, axis=-2).", "Let x.shape be (10, 20, 30, 40, 50) and suppose ind_1 and ind_2 can be broadcast to the shape (2, 3, 4). Then x[:, ind_1, ind_2] has shape (10, 2, 3, 4, 40, 50) because the (20, 30)-shaped subspace from X has been replaced with the (2, 3, 4) subspace from the indices. However, x[:, ind_1, :, ind_2] has shape (2, 3, 4, 10, 30, 50) because there is no unambiguous place to drop in the indexing subspace, thus it is tacked-on to the beginning. It is always possible to use .transpose() to move the subspace anywhere desired. Note that this example cannot be replicated using take.", "Slicing can be combined with broadcasted boolean indices:", "See also", "Structured arrays", "If the ndarray object is a structured array the fields of the array can be accessed by indexing the array with strings, dictionary-like.", "Indexing x['field-name'] returns a new view to the array, which is of the same shape as x (except when the field is a sub-array) but of data type x.dtype['field-name'] and contains only the part of the data in the specified field. Also, record array scalars can be \u201cindexed\u201d this way.", "Indexing into a structured array can also be done with a list of field names, e.g. x[['field-name1', 'field-name2']]. As of NumPy 1.16, this returns a view containing only those fields. In older versions of NumPy, it returned a copy. See the user guide section on Structured arrays for more information on multifield indexing.", "If the accessed field is a sub-array, the dimensions of the sub-array are appended to the shape of the result. For example:", "x.flat returns an iterator that will iterate over the entire array (in C-contiguous style with the last index varying the fastest). This iterator object can also be indexed using basic slicing or advanced indexing as long as the selection object is not a tuple. This should be clear from the fact that x.flat is a 1-dimensional view. It can be used for integer indexing with 1-dimensional C-style-flat indices. The shape of any returned array is therefore the shape of the integer indexing object.", "As mentioned, one can select a subset of an array to assign to using a single index, slices, and index and mask arrays. The value being assigned to the indexed array must be shape consistent (the same shape or broadcastable to the shape the index produces). For example, it is permitted to assign a constant to a slice:", "or an array of the right size:", "Note that assignments may result in changes if assigning higher types to lower types (like floats to ints) or even exceptions (assigning complex to floats or ints):", "Unlike some of the references (such as array and mask indices) assignments are always made to the original data in the array (indeed, nothing else would make sense!). Note though, that some actions may not work as one may naively expect. This particular example is often surprising to people:", "Where people expect that the 1st location will be incremented by 3. In fact, it will only be incremented by 1. The reason is that a new array is extracted from the original (as a temporary) containing the values at 1, 1, 3, 1, then the value 1 is added to the temporary, and then the temporary is assigned back to the original array. Thus the value of the array at x[1] + 1 is assigned to x[1] three times, rather than being incremented 3 times.", "The indexing syntax is very powerful but limiting when dealing with a variable number of indices. For example, if you want to write a function that can handle arguments with various numbers of dimensions without having to write special case code for each number of possible dimensions, how can that be done? If one supplies to the index a tuple, the tuple will be interpreted as a list of indices. For example:", "So one can use code to construct tuples of any number of indices and then use these within an index.", "Slices can be specified within programs by using the slice() function in Python. For example:", "Likewise, ellipsis can be specified by code by using the Ellipsis object:", "For this reason, it is possible to use the output from the np.nonzero() function directly as an index since it always returns a tuple of index arrays.", "Because the special treatment of tuples, they are not automatically converted to an array as a list would be. As an example:", "These are some detailed notes, which are not of importance for day to day indexing (in no particular order):"]}, {"name": "Indexing routines", "path": "reference/arrays.indexing", "type": "Indexing routines", "text": ["See also", "Indexing on ndarrays", "c_", "Translates slice objects to concatenation along the second axis.", "r_", "Translates slice objects to concatenation along the first axis.", "s_", "A nicer way to build up index tuples for arrays.", "nonzero(a)", "Return the indices of the elements that are non-zero.", "where(condition, [x, y], /)", "Return elements chosen from x or y depending on condition.", "indices(dimensions[, dtype, sparse])", "Return an array representing the indices of a grid.", "ix_(*args)", "Construct an open mesh from multiple sequences.", "ogrid", "nd_grid instance which returns an open multi-dimensional \"meshgrid\".", "ravel_multi_index(multi_index, dims[, mode, ...])", "Converts a tuple of index arrays into an array of flat indices, applying boundary modes to the multi-index.", "unravel_index(indices, shape[, order])", "Converts a flat index or array of flat indices into a tuple of coordinate arrays.", "diag_indices(n[, ndim])", "Return the indices to access the main diagonal of an array.", "diag_indices_from(arr)", "Return the indices to access the main diagonal of an n-dimensional array.", "mask_indices(n, mask_func[, k])", "Return the indices to access (n, n) arrays, given a masking function.", "tril_indices(n[, k, m])", "Return the indices for the lower-triangle of an (n, m) array.", "tril_indices_from(arr[, k])", "Return the indices for the lower-triangle of arr.", "triu_indices(n[, k, m])", "Return the indices for the upper-triangle of an (n, m) array.", "triu_indices_from(arr[, k])", "Return the indices for the upper-triangle of arr.", "take(a, indices[, axis, out, mode])", "Take elements from an array along an axis.", "take_along_axis(arr, indices, axis)", "Take values from the input array by matching 1d index and data slices.", "choose(a, choices[, out, mode])", "Construct an array from an index array and a list of arrays to choose from.", "compress(condition, a[, axis, out])", "Return selected slices of an array along given axis.", "diag(v[, k])", "Extract a diagonal or construct a diagonal array.", "diagonal(a[, offset, axis1, axis2])", "Return specified diagonals.", "select(condlist, choicelist[, default])", "Return an array drawn from elements in choicelist, depending on conditions.", "lib.stride_tricks.sliding_window_view(x, ...)", "Create a sliding window view into the array with the given window shape.", "lib.stride_tricks.as_strided(x[, shape, ...])", "Create a view into the array with the given shape and strides.", "place(arr, mask, vals)", "Change elements of an array based on conditional and input values.", "put(a, ind, v[, mode])", "Replaces specified elements of an array with given values.", "put_along_axis(arr, indices, values, axis)", "Put values into the destination array by matching 1d index and data slices.", "putmask(a, mask, values)", "Changes elements of an array based on conditional and input values.", "fill_diagonal(a, val[, wrap])", "Fill the main diagonal of the given array of any dimensionality.", "nditer(op[, flags, op_flags, op_dtypes, ...])", "Efficient multi-dimensional iterator object to iterate over arrays.", "ndenumerate(arr)", "Multidimensional index iterator.", "ndindex(*shape)", "An N-dimensional iterator object to index arrays.", "nested_iters(op, axes[, flags, op_flags, ...])", "Create nditers for use in nested loops", "flatiter()", "Flat iterator object to iterate over arrays.", "lib.Arrayterator(var[, buf_size])", "Buffered iterator for big arrays."]}, {"name": "Input and output", "path": "reference/routines.io", "type": "Input and output", "text": ["load(file[, mmap_mode, allow_pickle, ...])", "Load arrays or pickled objects from .npy, .npz or pickled files.", "save(file, arr[, allow_pickle, fix_imports])", "Save an array to a binary file in NumPy .npy format.", "savez(file, *args, **kwds)", "Save several arrays into a single file in uncompressed .npz format.", "savez_compressed(file, *args, **kwds)", "Save several arrays into a single file in compressed .npz format.", "The format of these binary file types is documented in numpy.lib.format", "loadtxt(fname[, dtype, comments, delimiter, ...])", "Load data from a text file.", "savetxt(fname, X[, fmt, delimiter, newline, ...])", "Save an array to a text file.", "genfromtxt(fname[, dtype, comments, ...])", "Load data from a text file, with missing values handled as specified.", "fromregex(file, regexp, dtype[, encoding])", "Construct an array from a text file, using regular expression parsing.", "fromstring(string[, dtype, count, like])", "A new 1-D array initialized from text data in a string.", "ndarray.tofile(fid[, sep, format])", "Write array to a file as text or binary (default).", "ndarray.tolist()", "Return the array as an a.ndim-levels deep nested list of Python scalars.", "fromfile(file[, dtype, count, sep, offset, like])", "Construct an array from data in a text or binary file.", "ndarray.tofile(fid[, sep, format])", "Write array to a file as text or binary (default).", "array2string(a[, max_line_width, precision, ...])", "Return a string representation of an array.", "array_repr(arr[, max_line_width, precision, ...])", "Return the string representation of an array.", "array_str(a[, max_line_width, precision, ...])", "Return a string representation of the data in an array.", "format_float_positional(x[, precision, ...])", "Format a floating-point scalar as a decimal string in positional notation.", "format_float_scientific(x[, precision, ...])", "Format a floating-point scalar as a decimal string in scientific notation.", "memmap(filename[, dtype, mode, offset, ...])", "Create a memory-map to an array stored in a binary file on disk.", "lib.format.open_memmap(filename[, mode, ...])", "Open a .npy file as a memory-mapped array.", "set_printoptions([precision, threshold, ...])", "Set printing options.", "get_printoptions()", "Return the current print options.", "set_string_function(f[, repr])", "Set a Python function to be used when pretty printing arrays.", "printoptions(*args, **kwargs)", "Context manager for setting print options.", "binary_repr(num[, width])", "Return the binary representation of the input number as a string.", "base_repr(number[, base, padding])", "Return a string representation of a number in the given base system.", "DataSource([destpath])", "A generic data source file (file, http, ftp, ...).", "lib.format", "Binary serialization"]}, {"name": "Install git", "path": "dev/gitwash/git_intro", "type": "Development", "text": ["Developing with git can be done entirely without github. Git is a distributed version control system. In order to use git on your machine you must install it."]}, {"name": "int **cancastscalarkindto", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.cancastscalarkindto", "type": "Python Types and C-Structures", "text": ["Either NULL or an array of NPY_NSCALARKINDS pointers. These pointers should each be either NULL or a pointer to an array of integers (terminated by NPY_NOTYPE) indicating data-types that a scalar of this data-type of the specified kind can be cast to safely (this usually means without losing precision)."]}, {"name": "int *cancastto", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.cancastto", "type": "Python Types and C-Structures", "text": ["Either NULL or an array of integers (terminated by NPY_NOTYPE ) indicated data-types that this data-type can be cast to safely (this usually means without losing precision)."]}, {"name": "int *core_dim_ixs", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_dim_ixs", "type": "Python Types and C-Structures", "text": ["Dimension indices in a flattened form; indices of argument k are stored in core_dim_ixs[core_offsets[k] : core_offsets[k] +\ncore_numdims[k]]"]}, {"name": "int *core_num_dims", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_num_dims", "type": "Python Types and C-Structures", "text": ["Number of core dimensions of each argument"]}, {"name": "int *core_offsets", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_offsets", "type": "Python Types and C-Structures", "text": ["Position of 1st core dimension of each argument in core_dim_ixs, equivalent to cumsum(core_num_dims)"]}, {"name": "int alignment", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.alignment", "type": "Python Types and C-Structures", "text": ["A number providing alignment information for this data type. Specifically, it shows how far from the start of a 2-element structure (whose first element is a char ), the compiler places an item of this type: offsetof(struct {char c; type v;},\nv)"]}, {"name": "int argmax()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argmax", "type": "Python Types and C-Structures", "text": ["A pointer to a function that retrieves the index of the largest of n elements in arr beginning at the element pointed to by data. This function requires that the memory segment be contiguous and behaved. The return value is always 0. The index of the largest element is returned in max_ind."]}, {"name": "int argmin()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argmin", "type": "Python Types and C-Structures", "text": ["A pointer to a function that retrieves the index of the smallest of n elements in arr beginning at the element pointed to by data. This function requires that the memory segment be contiguous and behaved. The return value is always 0. The index of the smallest element is returned in min_ind."]}, {"name": "int argsort()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argsort", "type": "Python Types and C-Structures", "text": ["An array of function pointers to sorting algorithms for this data type. The same sorting algorithms as for sort are available. The indices producing the sort are returned in result (which must be initialized with indices 0 to length-1 inclusive)."]}, {"name": "int compare()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.compare", "type": "Python Types and C-Structures", "text": ["A pointer to a function that compares two elements of the array, arr, pointed to by d1 and d2. This function requires behaved (aligned and not swapped) arrays. The return value is 1 if * d1 > * d2, 0 if * d1 == * d2, and -1 if * d1 < * d2. The array object arr is used to retrieve itemsize and field information for flexible arrays."]}, {"name": "int core_enabled", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_enabled", "type": "Python Types and C-Structures", "text": ["0 for scalar ufuncs; 1 for generalized ufuncs"]}, {"name": "int core_num_dim_ix", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_num_dim_ix", "type": "Python Types and C-Structures", "text": ["Number of distinct core dimension names in the signature"]}, {"name": "int doxy_javadoc_example()", "path": "dev/howto-docs", "type": "Development", "text": ["This guide will help you decide what to contribute and how to submit it to the official NumPy documentation.", "The NumPy community has set a firm goal of improving its documentation. We hold regular documentation meetings on Zoom (dates are announced on the numpy-discussion mailing list), and everyone is welcome. Reach out if you have questions or need someone to guide you through your first steps \u2013 we\u2019re happy to help. Minutes are taken on hackmd.io and stored in the NumPy Archive repository.", "The NumPy Documentation has the details covered. API reference documentation is generated directly from docstrings in the code when the documentation is built. Although we have mostly complete reference documentation for each function and class exposed to users, there is a lack of usage examples for some of them.", "What we lack are docs with broader scope \u2013 tutorials, how-tos, and explanations. Reporting defects is another way to contribute. We discuss both.", "We\u2019re eager to hear about and fix doc defects. But to attack the biggest problems we end up having to defer or overlook some bug reports. Here are the best defects to go after.", "Top priority goes to technical inaccuracies \u2013 a docstring missing a parameter, a faulty description of a function/parameter/method, and so on. Other \u201cstructural\u201d defects like broken links also get priority. All these fixes are easy to confirm and put in place. You can submit a pull request (PR) with the fix, if you know how to do that; otherwise please open an issue.", "Typos and misspellings fall on a lower rung; we welcome hearing about them but may not be able to fix them promptly. These too can be handled as pull requests or issues.", "Obvious wording mistakes (like leaving out a \u201cnot\u201d) fall into the typo category, but other rewordings \u2013 even for grammar \u2013 require a judgment call, which raises the bar. Test the waters by first presenting the fix as an issue.", "Some functions/objects like numpy.ndarray.transpose, numpy.array etc. defined in C-extension modules have their docstrings defined separately in _add_newdocs.py", "Your frustrations using our documents are our best guide to what needs fixing.", "If you write a missing doc you join the front line of open source, but it\u2019s a meaningful contribution just to let us know what\u2019s missing. If you want to compose a doc, run your thoughts by the mailing list for further ideas and feedback. If you want to alert us to a gap, open an issue. See this issue for an example.", "If you\u2019re looking for subjects, our formal roadmap for documentation is a NumPy Enhancement Proposal (NEP), NEP 44 - Restructuring the NumPy Documentation. It identifies areas where our docs need help and lists several additions we\u2019d like to see, including Jupyter notebooks.", "There are formulas for writing useful documents, and four formulas cover nearly everything. There are four formulas because there are four categories of document \u2013 tutorial, how-to guide, explanation, and reference. The insight that docs divide up this way belongs to Daniele Procida and his Di\u00e1taxis Framework. When you begin a document or propose one, have in mind which of these types it will be.", "In addition to the documentation that is part of the NumPy source tree, you can submit content in Jupyter Notebook format to the NumPy Tutorials page. This set of tutorials and educational materials is meant to provide high-quality resources by the NumPy project, both for self-learning and for teaching classes with. These resources are developed in a separate GitHub repository, numpy-tutorials, where you can check out existing notebooks, open issues to suggest new topics or submit your own tutorials as pull requests.", "Don\u2019t worry if English is not your first language, or if you can only come up with a rough draft. Open source is a community effort. Do your best \u2013 we\u2019ll help fix issues.", "Images and real-life data make text more engaging and powerful, but be sure what you use is appropriately licensed and available. Here again, even a rough idea for artwork can be polished by others.", "For now, the only data formats accepted by NumPy are those also used by other Python scientific libraries like pandas, SciPy, or Matplotlib. We\u2019re developing a package to accept more formats; contact us for details.", "NumPy documentation is kept in the source code tree. To get your document into the docbase you must download the tree, build it, and submit a pull request. If GitHub and pull requests are new to you, check our Contributor Guide.", "Our markup language is reStructuredText (rST), which is more elaborate than Markdown. Sphinx, the tool many Python projects use to build and link project documentation, converts the rST into HTML and other formats. For more on rST, see the Quick reStructuredText Guide or the reStructuredText Primer", "If you run across outside material that would be a useful addition to the NumPy docs, let us know by opening an issue.", "You don\u2019t have to contribute here to contribute to NumPy. You\u2019ve contributed if you write a tutorial on your blog, create a YouTube video, or answer questions on Stack Overflow and other sites.", "NumPy style governs cases where:", "Our current rules:", "When using Sphinx in combination with the NumPy conventions, you should use the numpydoc extension so that your docstrings will be handled correctly. For example, Sphinx will extract the Parameters section from your docstring and convert it into a field list. Using numpydoc will also avoid the reStructuredText errors produced by plain Sphinx when it encounters NumPy docstring conventions like section headers (e.g. -------------) that sphinx does not expect to find in docstrings.", "It is available from:", "Note that for documentation within NumPy, it is not necessary to do import numpy as np at the beginning of an example.", "Please use the numpydoc formatting standard as shown in their example.", "NumPy uses Doxygen to parse specially-formatted C/C++ comment blocks. This generates XML files, which are converted by Breathe into RST, which is used by Sphinx.", "It takes three steps to complete the documentation process:", "Although there is still no commenting style set to follow, the Javadoc is more preferable than the others due to the similarities with the current existing non-indexed comment blocks.", "Note", "Please see \u201cDocumenting the code\u201d.", "This is what Javadoc style looks like:", "And here is how it is rendered:", "This a simple brief. ", "And the details goes here. Multi lines are welcome.", "leave a comment for the returned value. ", "For line comment, you can use a triple forward slash. For example:", "And here is how it is rendered:", "Template to represent limbo numbers. ", "Specializations for integer types that are part of nowhere. It doesn\u2019t support with any real types.", "Type of the integer. Required to be an integer type. ", "Number of elements. ", "Default constructor. Initialize nothing. ", "Set Default behavior for copy the limbo. ", "Returns the raw data for the limbo. ", "Example for inline comment. ", "Note", "For more tags/commands, please take a look at https://www.doxygen.nl/manual/commands.html", "@brief", "Starts a paragraph that serves as a brief description. By default the first sentence of the documentation block is automatically treated as a brief description, since option JAVADOC_AUTOBRIEF is enabled within doxygen configurations.", "@details", "Just like @brief starts a brief description, @details starts the detailed description. You can also start a new paragraph (blank line) then the @details command is not needed.", "@param", "Starts a parameter description for a function parameter with name <parameter-name>, followed by a description of the parameter. The existence of the parameter is checked and a warning is given if the documentation of this (or any other) parameter is missing or not present in the function declaration or definition.", "@return", "Starts a return value description for a function. Multiple adjacent @return commands will be joined into a single paragraph. The @return description ends when a blank line or some other sectioning command is encountered.", "@code/@endcode", "Starts/Ends a block of code. A code block is treated differently from ordinary text. It is interpreted as source code.", "@rst/@endrst", "Starts/Ends a block of reST markup.", "Take a look at the following example:", "And here is how it is rendered:", "A comment block contains reST markup. ", "Some code example:", "Note", "Thanks to Breathe, we were able to bring it to Doxygen", "Not all headers files are collected automatically. You have to add the desired C/C++ header paths within the sub-config files of Doxygen.", "Sub-config files have the unique name .doxyfile, which you can usually find near directories that contain documented headers. You need to create a new config file if there\u2019s not one located in a path close(2-depth) to the headers you want to add.", "Sub-config files can accept any of Doxygen configuration options, but do not override or re-initialize any configuration option, rather only use the concatenation operator \u201c+=\u201d. For example:", "Note", "@CUR_DIR is a template constant returns the current dir path of the sub-config file.", "Breathe provides a wide range of custom directives to allow converting the documents generated by Doxygen into reST files.", "Note", "For more information, please check out \u201cDirectives & Config Variables\u201d", "doxygenfunction", "This directive generates the appropriate output for a single function. The function name is required to be unique in the project.", "Checkout the example to see it in action.", "doxygenclass", "This directive generates the appropriate output for a single class. It takes the standard project, path, outline and no-link options and additionally the members, protected-members, private-members, undoc-members, membergroups and members-only options:", "Checkout the doxygenclass documentation <https://breathe.readthedocs.io/en/latest/class.html#class-example>_ for more details and to see it in action.", "doxygennamespace", "This directive generates the appropriate output for the contents of a namespace. It takes the standard project, path, outline and no-link options and additionally the content-only, members, protected-members, private-members and undoc-members options. To reference a nested namespace, the full namespaced path must be provided, e.g. foo::bar for the bar namespace inside the foo namespace.", "Checkout the doxygennamespace documentation for more details and to see it in action.", "doxygengroup", "This directive generates the appropriate output for the contents of a doxygen group. A doxygen group can be declared with specific doxygen markup in the source comments as covered in the doxygen grouping documentation.", "It takes the standard project, path, outline and no-link options and additionally the content-only, members, protected-members, private-members and undoc-members options.", "Checkout the doxygengroup documentation for more details and to see it in action."]}, {"name": "int elsize", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.elsize", "type": "Python Types and C-Structures", "text": ["For data types that are always the same size (such as long), this holds the size of the data type. For flexible data types where different arrays can have a different elementsize, this should be 0."]}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.PyArray_Chunk.flags", "type": "Python Types and C-Structures", "text": ["Any data flags (e.g. NPY_ARRAY_WRITEABLE ) that should be used to interpret the memory."]}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.NPY_AO.flags", "type": "Python Types and C-Structures", "text": ["Pointed to by the macro PyArray_FLAGS, this data member represents the flags indicating how the memory pointed to by data is to be interpreted. Possible flags are NPY_ARRAY_C_CONTIGUOUS, NPY_ARRAY_F_CONTIGUOUS, NPY_ARRAY_OWNDATA, NPY_ARRAY_ALIGNED, NPY_ARRAY_WRITEABLE, NPY_ARRAY_WRITEBACKIFCOPY, and NPY_ARRAY_UPDATEIFCOPY."]}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.flags", "type": "Python Types and C-Structures", "text": ["Any of the bits NPY_ARRAY_C_CONTIGUOUS (1), NPY_ARRAY_F_CONTIGUOUS (2), NPY_ARRAY_ALIGNED (0x100), NPY_ARRAY_NOTSWAPPED (0x200), or NPY_ARRAY_WRITEABLE (0x400) to indicate something about the data. The NPY_ARRAY_ALIGNED, NPY_ARRAY_C_CONTIGUOUS, and NPY_ARRAY_F_CONTIGUOUS flags can actually be determined from the other parameters. The flag NPY_ARR_HAS_DESCR (0x800) can also be set to indicate to objects consuming the version 3 array interface that the descr member of the structure is present (it will be ignored by objects consuming version 2 of the array interface)."]}, {"name": "int fromstr()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fromstr", "type": "Python Types and C-Structures", "text": ["A pointer to a function that converts the string pointed to by str to one element of the corresponding type and places it in the memory location pointed to by ip. After the conversion is completed, *endptr points to the rest of the string. The last argument arr is the array into which ip points (needed for variable-size data- types). Returns 0 on success or -1 on failure. Requires a behaved array. This function should be called without holding the Python GIL, and has to grab it for error reporting."]}, {"name": "int identity", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.identity", "type": "Python Types and C-Structures", "text": ["Either PyUFunc_One, PyUFunc_Zero, PyUFunc_MinusOne, PyUFunc_None, PyUFunc_ReorderableNone, or PyUFunc_IdentityValue to indicate the identity for this operation. It is only used for a reduce-like call on an empty array."]}, {"name": "int itemsize", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.itemsize", "type": "Python Types and C-Structures", "text": ["The number of bytes each item in the array requires."]}, {"name": "int len", "path": "reference/c-api/types-and-structures#c.PyArray_Dims.len", "type": "Python Types and C-Structures", "text": ["The length of the list of integers. It is assumed safe to access ptr [0] to ptr [len-1]."]}, {"name": "int nargs", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.nargs", "type": "Python Types and C-Structures", "text": ["The total number of arguments (nin + nout). This must be less than NPY_MAXARGS."]}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.NPY_AO.nd", "type": "Python Types and C-Structures", "text": ["An integer providing the number of dimensions for this array. When nd is 0, the array is sometimes called a rank-0 array. Such arrays have undefined dimensions and strides and cannot be accessed. Macro PyArray_NDIM defined in ndarraytypes.h points to this data member. NPY_MAXDIMS is the largest number of dimensions for any array."]}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject.nd", "type": "Python Types and C-Structures", "text": ["The number of dimensions in the broadcasted result."]}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.nd", "type": "Python Types and C-Structures", "text": ["the number of dimensions in the array."]}, {"name": "int nout", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.nout", "type": "Python Types and C-Structures", "text": ["The number of output arguments."]}, {"name": "int npy_clear_floatstatus()", "path": "reference/c-api/coremath#c.npy_clear_floatstatus", "type": "NumPy core libraries", "text": ["Clears the floating point status. Returns the previous status mask.", "Note that npy_clear_floatstatus_barrier is preferable as it prevents aggressive compiler optimizations reordering the call relative to the code setting the status, which could lead to incorrect results.", "New in version 1.9.0."]}, {"name": "int npy_clear_floatstatus_barrier()", "path": "reference/c-api/coremath#c.npy_clear_floatstatus_barrier", "type": "NumPy core libraries", "text": ["Clears the floating point status. A pointer to a local variable is passed in to prevent aggressive compiler optimizations from reordering this function call. Returns the previous status mask.", "New in version 1.15.0."]}, {"name": "int npy_get_floatstatus()", "path": "reference/c-api/coremath#c.npy_get_floatstatus", "type": "NumPy core libraries", "text": ["Get floating point status. Returns a bitmask with following possible flags:", "Note that npy_get_floatstatus_barrier is preferable as it prevents aggressive compiler optimizations reordering the call relative to the code setting the status, which could lead to incorrect results.", "New in version 1.9.0."]}, {"name": "int npy_get_floatstatus_barrier()", "path": "reference/c-api/coremath#c.npy_get_floatstatus_barrier", "type": "NumPy core libraries", "text": ["Get floating point status. A pointer to a local variable is passed in to prevent aggressive compiler optimizations from reordering this function call relative to the code setting the status, which could lead to incorrect results.", "Returns a bitmask with following possible flags:", "New in version 1.15.0."]}, {"name": "int npy_half_eq()", "path": "reference/c-api/coremath#c.npy_half_eq", "type": "NumPy core libraries", "text": ["Compares two half-precision floats (h1 == h2)."]}, {"name": "int npy_half_eq_nonan()", "path": "reference/c-api/coremath#c.npy_half_eq_nonan", "type": "NumPy core libraries", "text": ["Compares two half-precision floats that are known to not be NaN (h1 == h2). If a value is NaN, the result is undefined."]}, {"name": "int npy_half_ge()", "path": "reference/c-api/coremath#c.npy_half_ge", "type": "NumPy core libraries", "text": ["Compares two half-precision floats (h1 >= h2)."]}, {"name": "int npy_half_gt()", "path": "reference/c-api/coremath#c.npy_half_gt", "type": "NumPy core libraries", "text": ["Compares two half-precision floats (h1 > h2)."]}, {"name": "int npy_half_isfinite()", "path": "reference/c-api/coremath#c.npy_half_isfinite", "type": "NumPy core libraries", "text": ["Tests whether the half-precision float is finite (not NaN or Inf)."]}, {"name": "int npy_half_isinf()", "path": "reference/c-api/coremath#c.npy_half_isinf", "type": "NumPy core libraries", "text": ["Tests whether the half-precision float is plus or minus Inf."]}, {"name": "int npy_half_isnan()", "path": "reference/c-api/coremath#c.npy_half_isnan", "type": "NumPy core libraries", "text": ["Tests whether the half-precision float is a NaN."]}, {"name": "int npy_half_iszero()", "path": "reference/c-api/coremath#c.npy_half_iszero", "type": "NumPy core libraries", "text": ["Tests whether the half-precision float has a value equal to zero. This may be slightly faster than calling npy_half_eq(h, NPY_ZERO)."]}, {"name": "int npy_half_le()", "path": "reference/c-api/coremath#c.npy_half_le", "type": "NumPy core libraries", "text": ["Compares two half-precision floats (h1 <= h2)."]}, {"name": "int npy_half_le_nonan()", "path": "reference/c-api/coremath#c.npy_half_le_nonan", "type": "NumPy core libraries", "text": ["Compares two half-precision floats that are known to not be NaN (h1 <= h2). If a value is NaN, the result is undefined."]}, {"name": "int npy_half_lt()", "path": "reference/c-api/coremath#c.npy_half_lt", "type": "NumPy core libraries", "text": ["Compares two half-precision floats (h1 < h2)."]}, {"name": "int npy_half_lt_nonan()", "path": "reference/c-api/coremath#c.npy_half_lt_nonan", "type": "NumPy core libraries", "text": ["Compares two half-precision floats that are known to not be NaN (h1 < h2). If a value is NaN, the result is undefined."]}, {"name": "int npy_half_ne()", "path": "reference/c-api/coremath#c.npy_half_ne", "type": "NumPy core libraries", "text": ["Compares two half-precision floats (h1 != h2)."]}, {"name": "int npy_half_signbit()", "path": "reference/c-api/coremath#c.npy_half_signbit", "type": "NumPy core libraries", "text": ["Returns 1 is h is negative, 0 otherwise."]}, {"name": "int NpyIter_CreateCompatibleStrides()", "path": "reference/c-api/iterator#c.NpyIter_CreateCompatibleStrides", "type": "Array Iterator API", "text": ["Builds a set of strides which are the same as the strides of an output array created using the NPY_ITER_ALLOCATE flag, where NULL was passed for op_axes. This is for data packed contiguously, but not necessarily in C or Fortran order. This should be used together with NpyIter_GetShape and NpyIter_GetNDim with the flag NPY_ITER_MULTI_INDEX passed into the constructor.", "A use case for this function is to match the shape and layout of the iterator and tack on one or more dimensions. For example, in order to generate a vector per input value for a numerical gradient, you pass in ndim*itemsize for itemsize, then add another dimension to the end with size ndim and stride itemsize. To do the Hessian matrix, you do the same thing but add two dimensions, or take advantage of the symmetry and pack it into 1 dimension with a particular encoding.", "This function may only be called if the iterator is tracking a multi-index and if NPY_ITER_DONT_NEGATE_STRIDES was used to prevent an axis from being iterated in reverse order.", "If an array is created with this method, simply adding \u2018itemsize\u2019 for each iteration will traverse the new array matching the iterator.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_Deallocate()", "path": "reference/c-api/iterator#c.NpyIter_Deallocate", "type": "Array Iterator API", "text": ["Deallocates the iterator object and resolves any needed writebacks.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_EnableExternalLoop()", "path": "reference/c-api/iterator#c.NpyIter_EnableExternalLoop", "type": "Array Iterator API", "text": ["If NpyIter_RemoveMultiIndex was called, you may want to enable the flag NPY_ITER_EXTERNAL_LOOP. This flag is not permitted together with NPY_ITER_MULTI_INDEX, so this function is provided to enable the feature after NpyIter_RemoveMultiIndex is called. This function also resets the iterator to its initial state.", "WARNING: This function changes the internal logic of the iterator. Any cached functions or pointers from the iterator must be retrieved again!", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_GetNDim()", "path": "reference/c-api/iterator#c.NpyIter_GetNDim", "type": "Array Iterator API", "text": ["Returns the number of dimensions being iterated. If a multi-index was not requested in the iterator constructor, this value may be smaller than the number of dimensions in the original objects."]}, {"name": "int NpyIter_GetNOp()", "path": "reference/c-api/iterator#c.NpyIter_GetNOp", "type": "Array Iterator API", "text": ["Returns the number of operands in the iterator."]}, {"name": "int NpyIter_GetShape()", "path": "reference/c-api/iterator#c.NpyIter_GetShape", "type": "Array Iterator API", "text": ["Returns the broadcast shape of the iterator in outshape. This can only be called on an iterator which is tracking a multi-index.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_GotoIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoIndex", "type": "Array Iterator API", "text": ["Adjusts the iterator to point to the index specified. If the iterator was constructed with the flag NPY_ITER_C_INDEX, index is the C-order index, and if the iterator was constructed with the flag NPY_ITER_F_INDEX, index is the Fortran-order index. Returns an error if there is no index being tracked, the index is out of bounds, or inner loop iteration is disabled.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_GotoIterIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoIterIndex", "type": "Array Iterator API", "text": ["Adjusts the iterator to point to the iterindex specified. The IterIndex is an index matching the iteration order of the iterator. Returns an error if the iterindex is out of bounds, buffering is enabled, or inner loop iteration is disabled.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_GotoMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoMultiIndex", "type": "Array Iterator API", "text": ["Adjusts the iterator to point to the ndim indices pointed to by multi_index. Returns an error if a multi-index is not being tracked, the indices are out of bounds, or inner loop iteration is disabled.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_RemoveAxis()", "path": "reference/c-api/iterator#c.NpyIter_RemoveAxis", "type": "Array Iterator API", "text": ["Removes an axis from iteration. This requires that NPY_ITER_MULTI_INDEX was set for iterator creation, and does not work if buffering is enabled or an index is being tracked. This function also resets the iterator to its initial state.", "This is useful for setting up an accumulation loop, for example. The iterator can first be created with all the dimensions, including the accumulation axis, so that the output gets created correctly. Then, the accumulation axis can be removed, and the calculation done in a nested fashion.", "WARNING: This function may change the internal memory layout of the iterator. Any cached functions or pointers from the iterator must be retrieved again! The iterator range will be reset as well.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_RemoveMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_RemoveMultiIndex", "type": "Array Iterator API", "text": ["If the iterator is tracking a multi-index, this strips support for them, and does further iterator optimizations that are possible if multi-indices are not needed. This function also resets the iterator to its initial state.", "WARNING: This function may change the internal memory layout of the iterator. Any cached functions or pointers from the iterator must be retrieved again!", "After calling this function, NpyIter_HasMultiIndex(iter) will return false.", "Returns NPY_SUCCEED or NPY_FAIL."]}, {"name": "int NpyIter_Reset()", "path": "reference/c-api/iterator#c.NpyIter_Reset", "type": "Array Iterator API", "text": ["Resets the iterator back to its initial state, at the beginning of the iteration range.", "Returns NPY_SUCCEED or NPY_FAIL. If errmsg is non-NULL, no Python exception is set when NPY_FAIL is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL."]}, {"name": "int NpyIter_ResetBasePointers()", "path": "reference/c-api/iterator#c.NpyIter_ResetBasePointers", "type": "Array Iterator API", "text": ["Resets the iterator back to its initial state, but using the values in baseptrs for the data instead of the pointers from the arrays being iterated. This functions is intended to be used, together with the op_axes parameter, by nested iteration code with two or more iterators.", "Returns NPY_SUCCEED or NPY_FAIL. If errmsg is non-NULL, no Python exception is set when NPY_FAIL is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL.", "TODO: Move the following into a special section on nested iterators.", "Creating iterators for nested iteration requires some care. All the iterator operands must match exactly, or the calls to NpyIter_ResetBasePointers will be invalid. This means that automatic copies and output allocation should not be used haphazardly. It is possible to still use the automatic data conversion and casting features of the iterator by creating one of the iterators with all the conversion parameters enabled, then grabbing the allocated operands with the NpyIter_GetOperandArray function and passing them into the constructors for the rest of the iterators.", "WARNING: When creating iterators for nested iteration, the code must not use a dimension more than once in the different iterators. If this is done, nested iteration will produce out-of-bounds pointers during iteration.", "WARNING: When creating iterators for nested iteration, buffering can only be applied to the innermost iterator. If a buffered iterator is used as the source for baseptrs, it will point into a small buffer instead of the array and the inner iteration will be invalid.", "The pattern for using nested iterators is as follows."]}, {"name": "int NpyIter_ResetToIterIndexRange()", "path": "reference/c-api/iterator#c.NpyIter_ResetToIterIndexRange", "type": "Array Iterator API", "text": ["Resets the iterator and restricts it to the iterindex range [istart, iend). See NpyIter_Copy for an explanation of how to use this for multi-threaded iteration. This requires that the flag NPY_ITER_RANGED was passed to the iterator constructor.", "If you want to reset both the iterindex range and the base pointers at the same time, you can do the following to avoid extra buffer copying (be sure to add the return code error checks when you copy this code).", "Returns NPY_SUCCEED or NPY_FAIL. If errmsg is non-NULL, no Python exception is set when NPY_FAIL is returned. Instead, *errmsg is set to an error message. When errmsg is non-NULL, the function may be safely called without holding the Python GIL."]}, {"name": "int ntypes", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.ntypes", "type": "Python Types and C-Structures", "text": ["The number of supported data types for the ufunc. This number specifies how many different 1-d loops (of the builtin data types) are available."]}, {"name": "int PyArray_AxisConverter()", "path": "reference/c-api/array#c.PyArray_AxisConverter", "type": "Array API", "text": ["Convert a Python object, obj, representing an axis argument to the proper value for passing to the functions that take an integer axis. Specifically, if obj is None, axis is set to NPY_MAXDIMS which is interpreted correctly by the C-API functions that take axis arguments."]}, {"name": "int PyArray_BoolConverter()", "path": "reference/c-api/array#c.PyArray_BoolConverter", "type": "Array API", "text": ["Convert any Python object, obj, to NPY_TRUE or NPY_FALSE, and place the result in value."]}, {"name": "int PyArray_Broadcast()", "path": "reference/c-api/array#c.PyArray_Broadcast", "type": "Array API", "text": ["This function encapsulates the broadcasting rules. The mit container should already contain iterators for all the arrays that need to be broadcast. On return, these iterators will be adjusted so that iteration over each simultaneously will accomplish the broadcasting. A negative number is returned if an error occurs."]}, {"name": "int PyArray_BufferConverter()", "path": "reference/c-api/array#c.PyArray_BufferConverter", "type": "Array API", "text": ["Convert any Python object, obj, with a (single-segment) buffer interface to a variable with members that detail the object\u2019s use of its chunk of memory. The buf variable is a pointer to a structure with base, ptr, len, and flags members. The PyArray_Chunk structure is binary compatible with the Python\u2019s buffer object (through its len member on 32-bit platforms and its ptr member on 64-bit platforms or in Python 2.5). On return, the base member is set to obj (or its base if obj is already a buffer object pointing to another object). If you need to hold on to the memory be sure to INCREF the base member. The chunk of memory is pointed to by buf ->ptr member and has length buf ->len. The flags member of buf is NPY_ARRAY_ALIGNED with the NPY_ARRAY_WRITEABLE flag set if obj has a writeable buffer interface."]}, {"name": "int PyArray_ByteorderConverter()", "path": "reference/c-api/array#c.PyArray_ByteorderConverter", "type": "Array API", "text": ["Convert Python strings into the corresponding byte-order character: \u2018>\u2019, \u2018<\u2019, \u2018s\u2019, \u2018=\u2019, or \u2018|\u2019."]}, {"name": "int PyArray_CanCastArrayTo()", "path": "reference/c-api/array#c.PyArray_CanCastArrayTo", "type": "Array API", "text": ["New in version 1.6.", "Returns non-zero if arr can be cast to totype according to the casting rule given in casting. If arr is an array scalar, its value is taken into account, and non-zero is also returned when the value will not overflow or be truncated to an integer when converting to a smaller type.", "This is almost the same as the result of PyArray_CanCastTypeTo(PyArray_MinScalarType(arr), totype, casting), but it also handles a special case arising because the set of uint values is not a subset of the int values for types with the same number of bits."]}, {"name": "int PyArray_CanCastSafely()", "path": "reference/c-api/array#c.PyArray_CanCastSafely", "type": "Array API", "text": ["Returns non-zero if an array of data type fromtype can be cast to an array of data type totype without losing information. An exception is that 64-bit integers are allowed to be cast to 64-bit floating point values even though this can lose precision on large integers so as not to proliferate the use of long doubles without explicit requests. Flexible array types are not checked according to their lengths with this function."]}, {"name": "int PyArray_CanCastTo()", "path": "reference/c-api/array#c.PyArray_CanCastTo", "type": "Array API", "text": ["PyArray_CanCastTypeTo supersedes this function in NumPy 1.6 and later.", "Equivalent to PyArray_CanCastTypeTo(fromtype, totype, NPY_SAFE_CASTING)."]}, {"name": "int PyArray_CanCastTypeTo()", "path": "reference/c-api/array#c.PyArray_CanCastTypeTo", "type": "Array API", "text": ["New in version 1.6.", "Returns non-zero if an array of data type fromtype (which can include flexible types) can be cast safely to an array of data type totype (which can include flexible types) according to the casting rule casting. For simple types with NPY_SAFE_CASTING, this is basically a wrapper around PyArray_CanCastSafely, but for flexible types such as strings or unicode, it produces results taking into account their sizes. Integer and float types can only be cast to a string or unicode type using NPY_SAFE_CASTING if the string or unicode type is big enough to hold the max value of the integer/float type being cast from."]}, {"name": "int PyArray_CanCoerceScalar()", "path": "reference/c-api/array#c.PyArray_CanCoerceScalar", "type": "Array API", "text": ["See the function PyArray_ResultType for details of NumPy type promotion, updated in NumPy 1.6.0.", "Implements the rules for scalar coercion. Scalars are only silently coerced from thistype to neededtype if this function returns nonzero. If scalar is NPY_NOSCALAR, then this function is equivalent to PyArray_CanCastSafely. The rule is that scalars of the same KIND can be coerced into arrays of the same KIND. This rule means that high-precision scalars will never cause low-precision arrays of the same KIND to be upcast."]}, {"name": "int PyArray_CastingConverter()", "path": "reference/c-api/array#c.PyArray_CastingConverter", "type": "Array API", "text": ["Convert the Python strings \u2018no\u2019, \u2018equiv\u2019, \u2018safe\u2019, \u2018same_kind\u2019, and \u2018unsafe\u2019 into the NPY_CASTING enumeration NPY_NO_CASTING, NPY_EQUIV_CASTING, NPY_SAFE_CASTING, NPY_SAME_KIND_CASTING, and NPY_UNSAFE_CASTING."]}, {"name": "int PyArray_CastTo()", "path": "reference/c-api/array#c.PyArray_CastTo", "type": "Array API", "text": ["As of 1.6, this function simply calls PyArray_CopyInto, which handles the casting.", "Cast the elements of the array in into the array out. The output array should be writeable, have an integer-multiple of the number of elements in the input array (more than one copy can be placed in out), and have a data type that is one of the builtin types. Returns 0 on success and -1 if an error occurs."]}, {"name": "int PyArray_CheckAnyScalar()", "path": "reference/c-api/array#c.PyArray_CheckAnyScalar", "type": "Array API", "text": ["Evaluates true if op is a Python scalar object (see PyArray_IsPythonScalar), an array scalar (an instance of a sub-type of PyGenericArr_Type) or an instance of a sub-type of PyArray_Type whose dimensionality is 0."]}, {"name": "int PyArray_CheckExact()", "path": "reference/c-api/array#c.PyArray_CheckExact", "type": "Array API", "text": ["Evaluates true if op is a Python object with type PyArray_Type."]}, {"name": "int PyArray_CheckScalar()", "path": "reference/c-api/array#c.PyArray_CheckScalar", "type": "Array API", "text": ["Evaluates true if op is either an array scalar (an instance of a sub-type of PyGenericArr_Type ), or an instance of (a sub-class of) PyArray_Type whose dimensionality is 0."]}, {"name": "int PyArray_ClipmodeConverter()", "path": "reference/c-api/array#c.PyArray_ClipmodeConverter", "type": "Array API", "text": ["Convert the Python strings \u2018clip\u2019, \u2018wrap\u2019, and \u2018raise\u2019 into the NPY_CLIPMODE enumeration NPY_CLIP, NPY_WRAP, and NPY_RAISE."]}, {"name": "int PyArray_CompareLists()", "path": "reference/c-api/array#c.PyArray_CompareLists", "type": "Array API", "text": ["Given two n -length arrays of integers, l1, and l2, return 1 if the lists are identical; otherwise, return 0."]}, {"name": "int PyArray_ConvertClipmodeSequence()", "path": "reference/c-api/array#c.PyArray_ConvertClipmodeSequence", "type": "Array API", "text": ["Converts either a sequence of clipmodes or a single clipmode into a C array of NPY_CLIPMODE values. The number of clipmodes n must be known before calling this function. This function is provided to help functions allow a different clipmode for each dimension."]}, {"name": "int PyArray_CopyInto()", "path": "reference/c-api/array#c.PyArray_CopyInto", "type": "Array API", "text": ["Copy from the source array, src, into the destination array, dest, performing a data-type conversion if necessary. If an error occurs return -1 (otherwise 0). The shape of src must be broadcastable to the shape of dest. The data areas of dest and src must not overlap."]}, {"name": "int PyArray_CopyObject()", "path": "reference/c-api/array#c.PyArray_CopyObject", "type": "Array API", "text": ["Assign an object src to a NumPy array dest according to array-coercion rules. This is basically identical to PyArray_FromAny, but assigns directly to the output array. Returns 0 on success and -1 on failures."]}, {"name": "int Pyarray_DescrAlignConverter()", "path": "reference/c-api/array#c.Pyarray_DescrAlignConverter", "type": "Array API", "text": ["Like PyArray_DescrConverter except it aligns C-struct-like objects on word-boundaries as the compiler would."]}, {"name": "int Pyarray_DescrAlignConverter2()", "path": "reference/c-api/array#c.Pyarray_DescrAlignConverter2", "type": "Array API", "text": ["Like PyArray_DescrConverter2 except it aligns C-struct-like objects on word-boundaries as the compiler would."]}, {"name": "int PyArray_DescrConverter()", "path": "reference/c-api/array#c.PyArray_DescrConverter", "type": "Array API", "text": ["Convert any compatible Python object, obj, to a data-type object in dtype. A large number of Python objects can be converted to data-type objects. See Data type objects (dtype) for a complete description. This version of the converter converts None objects to a NPY_DEFAULT_TYPE data-type object. This function can be used with the \u201cO&\u201d character code in PyArg_ParseTuple processing."]}, {"name": "int PyArray_DescrConverter2()", "path": "reference/c-api/array#c.PyArray_DescrConverter2", "type": "Array API", "text": ["Convert any compatible Python object, obj, to a data-type object in dtype. This version of the converter converts None objects so that the returned data-type is NULL. This function can also be used with the \u201cO&\u201d character in PyArg_ParseTuple processing."]}, {"name": "int PyArray_Dump()", "path": "reference/c-api/array#c.PyArray_Dump", "type": "Array API", "text": ["Pickle the object in self to the given file (either a string or a Python file object). If file is a Python string it is considered to be the name of a file which is then opened in binary mode. The given protocol is used (if protocol is negative, or the highest available is used). This is a simple wrapper around cPickle.dump(self, file, protocol)."]}, {"name": "int PyArray_EquivByteorders()", "path": "reference/c-api/array#c.PyArray_EquivByteorders", "type": "Array API", "text": ["True if byteorder characters b1 and b2 ( NPY_LITTLE, NPY_BIG, NPY_NATIVE, NPY_IGNORE ) are either equal or equivalent as to their specification of a native byte order. Thus, on a little-endian machine NPY_LITTLE and NPY_NATIVE are equivalent where they are not equivalent on a big-endian machine."]}, {"name": "int PyArray_FillWithScalar()", "path": "reference/c-api/array#c.PyArray_FillWithScalar", "type": "Array API", "text": ["Fill the array, arr, with the given scalar object, obj. The object is first converted to the data type of arr, and then copied into every location. A -1 is returned if an error occurs, otherwise 0 is returned."]}, {"name": "int PyArray_FinalizeFunc()", "path": "reference/c-api/array#c.PyArray_FinalizeFunc", "type": "Array API", "text": ["The function pointed to by the CObject __array_finalize__. The first argument is the newly created sub-type. The second argument (if not NULL) is the \u201cparent\u201d array (if the array was created using slicing or some other operation where a clearly-distinguishable parent is present). This routine can do anything it wants to. It should return a -1 on error and 0 otherwise."]}, {"name": "int PyArray_FLAGS()", "path": "reference/c-api/array#c.PyArray_FLAGS", "type": "Array API", "text": ["Returns an integer representing the array-flags."]}, {"name": "int PyArray_Free()", "path": "reference/c-api/array#c.PyArray_Free", "type": "Array API", "text": ["Must be called with the same objects and memory locations returned from PyArray_AsCArray (\u2026). This function cleans up memory that otherwise would get leaked."]}, {"name": "int PyArray_GetArrayParamsFromObject()", "path": "reference/c-api/array#c.PyArray_GetArrayParamsFromObject", "type": "Array API", "text": ["Deprecated since version NumPy: 1.19", "Unless NumPy is made aware of an issue with this, this function is scheduled for rapid removal without replacement.", "Changed in version NumPy: 1.19", "context is never used. Its use results in an error.", "New in version 1.6."]}, {"name": "int PyArray_GetEndianness()", "path": "reference/c-api/config#c.PyArray_GetEndianness", "type": "System configuration", "text": ["New in version 1.3.0.", "Returns the endianness of the current platform. One of NPY_CPU_BIG, NPY_CPU_LITTLE, or NPY_CPU_UNKNOWN_ENDIAN."]}, {"name": "int PyArray_HasArrayInterface()", "path": "reference/c-api/array#c.PyArray_HasArrayInterface", "type": "Array API", "text": ["If op implements any part of the array interface, then out will contain a new reference to the newly created ndarray using the interface or out will contain NULL if an error during conversion occurs. Otherwise, out will contain a borrowed reference to Py_NotImplemented and no error condition is set."]}, {"name": "int PyArray_HasArrayInterfaceType()", "path": "reference/c-api/array#c.PyArray_HasArrayInterfaceType", "type": "Array API", "text": ["If op implements any part of the array interface, then out will contain a new reference to the newly created ndarray using the interface or out will contain NULL if an error during conversion occurs. Otherwise, out will contain a borrowed reference to Py_NotImplemented and no error condition is set. This version allows setting of the dtype in the part of the array interface that looks for the __array__ attribute. context is unused."]}, {"name": "int PyArray_HASFIELDS()", "path": "reference/c-api/array#c.PyArray_HASFIELDS", "type": "Array API", "text": ["Type has fields associated with it."]}, {"name": "int PyArray_IntpConverter()", "path": "reference/c-api/array#c.PyArray_IntpConverter", "type": "Array API", "text": ["Convert any Python sequence, obj, smaller than NPY_MAXDIMS to a C-array of npy_intp. The Python object could also be a single number. The seq variable is a pointer to a structure with members ptr and len. On successful return, seq ->ptr contains a pointer to memory that must be freed, by calling PyDimMem_FREE, to avoid a memory leak. The restriction on memory size allows this converter to be conveniently used for sequences intended to be interpreted as array shapes."]}, {"name": "int PyArray_IntpFromSequence()", "path": "reference/c-api/array#c.PyArray_IntpFromSequence", "type": "Array API", "text": ["Convert any Python sequence (or single Python number) passed in as seq to (up to) maxvals pointer-sized integers and place them in the vals array. The sequence can be smaller then maxvals as the number of converted objects is returned."]}, {"name": "int PyArray_IS_C_CONTIGUOUS()", "path": "reference/c-api/array#c.PyArray_IS_C_CONTIGUOUS", "type": "Array API", "text": ["Evaluates true if arr is C-style contiguous."]}, {"name": "int PyArray_IS_F_CONTIGUOUS()", "path": "reference/c-api/array#c.PyArray_IS_F_CONTIGUOUS", "type": "Array API", "text": ["Evaluates true if arr is Fortran-style contiguous."]}, {"name": "int PyArray_ISALIGNED()", "path": "reference/c-api/array#c.PyArray_ISALIGNED", "type": "Array API", "text": ["Evaluates true if the data area of arr is properly aligned on the machine."]}, {"name": "int PyArray_IsAnyScalar()", "path": "reference/c-api/array#c.PyArray_IsAnyScalar", "type": "Array API", "text": ["Evaluates true if op is either a Python scalar object (see PyArray_IsPythonScalar) or an array scalar (an instance of a sub- type of PyGenericArr_Type )."]}, {"name": "int PyArray_ISBEHAVED()", "path": "reference/c-api/array#c.PyArray_ISBEHAVED", "type": "Array API", "text": ["Evaluates true if the data area of arr is aligned and writeable and in machine byte-order according to its descriptor."]}, {"name": "int PyArray_ISBEHAVED_RO()", "path": "reference/c-api/array#c.PyArray_ISBEHAVED_RO", "type": "Array API", "text": ["Evaluates true if the data area of arr is aligned and in machine byte-order."]}, {"name": "int PyArray_ISBOOL()", "path": "reference/c-api/array#c.PyArray_ISBOOL", "type": "Array API", "text": ["Type represents Boolean data type."]}, {"name": "int PyArray_ISBYTESWAPPED()", "path": "reference/c-api/array#c.PyArray_ISBYTESWAPPED", "type": "Array API", "text": ["Evaluates true if the data area of the ndarray m is not in machine byte-order according to the array\u2019s data-type descriptor."]}, {"name": "int PyArray_ISCARRAY()", "path": "reference/c-api/array#c.PyArray_ISCARRAY", "type": "Array API", "text": ["Evaluates true if the data area of arr is C-style contiguous, and PyArray_ISBEHAVED (arr) is true."]}, {"name": "int PyArray_ISCARRAY_RO()", "path": "reference/c-api/array#c.PyArray_ISCARRAY_RO", "type": "Array API", "text": ["Evaluates true if the data area of arr is C-style contiguous, aligned, and in machine byte-order."]}, {"name": "int PyArray_ISCOMPLEX()", "path": "reference/c-api/array#c.PyArray_ISCOMPLEX", "type": "Array API", "text": ["Type represents any complex floating point number."]}, {"name": "int PyArray_ISEXTENDED()", "path": "reference/c-api/array#c.PyArray_ISEXTENDED", "type": "Array API", "text": ["Type is either flexible or user-defined."]}, {"name": "int PyArray_ISFARRAY()", "path": "reference/c-api/array#c.PyArray_ISFARRAY", "type": "Array API", "text": ["Evaluates true if the data area of arr is Fortran-style contiguous and PyArray_ISBEHAVED (arr) is true."]}, {"name": "int PyArray_ISFARRAY_RO()", "path": "reference/c-api/array#c.PyArray_ISFARRAY_RO", "type": "Array API", "text": ["Evaluates true if the data area of arr is Fortran-style contiguous, aligned, and in machine byte-order ."]}, {"name": "int PyArray_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyArray_ISFLEXIBLE", "type": "Array API", "text": ["Type represents one of the flexible array types ( NPY_STRING, NPY_UNICODE, or NPY_VOID )."]}, {"name": "int PyArray_ISFLOAT()", "path": "reference/c-api/array#c.PyArray_ISFLOAT", "type": "Array API", "text": ["Type represents any floating point number."]}, {"name": "int PyArray_ISFORTRAN()", "path": "reference/c-api/array#c.PyArray_ISFORTRAN", "type": "Array API", "text": ["Evaluates true if arr is Fortran-style contiguous and not C-style contiguous. PyArray_IS_F_CONTIGUOUS is the correct way to test for Fortran-style contiguity."]}, {"name": "int PyArray_ISINTEGER()", "path": "reference/c-api/array#c.PyArray_ISINTEGER", "type": "Array API", "text": ["Type represents any integer."]}, {"name": "int PyArray_ISNOTSWAPPED()", "path": "reference/c-api/array#c.PyArray_ISNOTSWAPPED", "type": "Array API", "text": ["Evaluates true if the data area of the ndarray m is in machine byte-order according to the array\u2019s data-type descriptor."]}, {"name": "int PyArray_ISNUMBER()", "path": "reference/c-api/array#c.PyArray_ISNUMBER", "type": "Array API", "text": ["Type represents any integer, floating point, or complex floating point number."]}, {"name": "int PyArray_ISOBJECT()", "path": "reference/c-api/array#c.PyArray_ISOBJECT", "type": "Array API", "text": ["Type represents object data type."]}, {"name": "int PyArray_ISONESEGMENT()", "path": "reference/c-api/array#c.PyArray_ISONESEGMENT", "type": "Array API", "text": ["Evaluates true if the data area of arr consists of a single (C-style or Fortran-style) contiguous segment."]}, {"name": "int PyArray_ISPYTHON()", "path": "reference/c-api/array#c.PyArray_ISPYTHON", "type": "Array API", "text": ["Type represents an enumerated type corresponding to one of the standard Python scalar (bool, int, float, or complex)."]}, {"name": "int PyArray_IsPythonNumber()", "path": "reference/c-api/array#c.PyArray_IsPythonNumber", "type": "Array API", "text": ["Evaluates true if op is an instance of a builtin numeric type (int, float, complex, long, bool)"]}, {"name": "int PyArray_IsPythonScalar()", "path": "reference/c-api/array#c.PyArray_IsPythonScalar", "type": "Array API", "text": ["Evaluates true if op is a builtin Python scalar object (int, float, complex, bytes, str, long, bool)."]}, {"name": "int PyArray_ISSIGNED()", "path": "reference/c-api/array#c.PyArray_ISSIGNED", "type": "Array API", "text": ["Type represents a signed integer."]}, {"name": "int PyArray_ISSTRING()", "path": "reference/c-api/array#c.PyArray_ISSTRING", "type": "Array API", "text": ["Type represents a string data type."]}, {"name": "int PyArray_ISUNSIGNED()", "path": "reference/c-api/array#c.PyArray_ISUNSIGNED", "type": "Array API", "text": ["Type represents an unsigned integer."]}, {"name": "int PyArray_ISUSERDEF()", "path": "reference/c-api/array#c.PyArray_ISUSERDEF", "type": "Array API", "text": ["Type represents a user-defined type."]}, {"name": "int PyArray_ISWRITEABLE()", "path": "reference/c-api/array#c.PyArray_ISWRITEABLE", "type": "Array API", "text": ["Evaluates true if the data area of arr can be written to"]}, {"name": "int PyArray_IsZeroDim()", "path": "reference/c-api/array#c.PyArray_IsZeroDim", "type": "Array API", "text": ["Evaluates true if op is an instance of (a subclass of) PyArray_Type and has 0 dimensions."]}, {"name": "int PyArray_ITER_NOTDONE()", "path": "reference/c-api/array#c.PyArray_ITER_NOTDONE", "type": "Array API", "text": ["Evaluates TRUE as long as the iterator has not looped through all of the elements, otherwise it evaluates FALSE."]}, {"name": "int PyArray_MoveInto()", "path": "reference/c-api/array#c.PyArray_MoveInto", "type": "Array API", "text": ["Move data from the source array, src, into the destination array, dest, performing a data-type conversion if necessary. If an error occurs return -1 (otherwise 0). The shape of src must be broadcastable to the shape of dest. The data areas of dest and src may overlap."]}, {"name": "int PyArray_MultiIter_NOTDONE()", "path": "reference/c-api/array#c.PyArray_MultiIter_NOTDONE", "type": "Array API", "text": ["Evaluates TRUE as long as the multi-iterator has not looped through all of the elements (of the broadcasted result), otherwise it evaluates FALSE."]}, {"name": "int PyArray_MultiplyIntList()", "path": "reference/c-api/array#c.PyArray_MultiplyIntList", "type": "Array API", "text": ["Both of these routines multiply an n -length array, seq, of integers and return the result. No overflow checking is performed."]}, {"name": "int PyArray_NDIM()", "path": "reference/c-api/array", "type": "Array API", "text": ["These macros access the PyArrayObject structure members and are defined in ndarraytypes.h. The input argument, arr, can be any PyObject* that is directly interpretable as a PyArrayObject* (any instance of the PyArray_Type and its sub-types).", "The number of dimensions in the array.", "Returns an integer representing the array-flags.", "Return the (builtin) typenumber for the elements of this array.", "Convert obj and place it in the ndarray, arr, at the place pointed to by itemptr. Return -1 if an error occurs or 0 on success.", "New in version 1.7.", "Enables the specified array flags. This function does no validation, and assumes that you know what you\u2019re doing.", "New in version 1.7.", "Clears the specified array flags. This function does no validation, and assumes that you know what you\u2019re doing.", "These two macros are similar and obtain the pointer to the data-buffer for the array. The first macro can (and should be) assigned to a particular pointer where the second is for generic processing. If you have not guaranteed a contiguous and/or aligned array then be sure you understand how to access the data in the array to avoid memory and/or alignment problems.", "Returns a pointer to the dimensions/shape of the array. The number of elements matches the number of dimensions of the array. Can return NULL for 0-dimensional arrays.", "New in version 1.7.", "A synonym for PyArray_DIMS, named to be consistent with the shape usage within Python.", "Returns a pointer to the strides of the array. The number of elements matches the number of dimensions of the array.", "Return the shape in the n \\(^{\\textrm{th}}\\) dimension.", "Return the stride in the n \\(^{\\textrm{th}}\\) dimension.", "Return the itemsize for the elements of this array.", "Note that, in the old API that was deprecated in version 1.7, this function had the return type int.", "Returns the total size (in number of elements) of the array.", "Returns 0 if obj is not a sub-class of ndarray. Otherwise, returns the total number of elements in the array. Safer version of PyArray_SIZE (obj).", "Returns the total number of bytes consumed by the array.", "This returns the base object of the array. In most cases, this means the object which owns the memory the array is pointing at.", "If you are constructing an array using the C API, and specifying your own memory, you should use the function PyArray_SetBaseObject to set the base to an object which owns the memory.", "If the (deprecated) NPY_ARRAY_UPDATEIFCOPY or the NPY_ARRAY_WRITEBACKIFCOPY flags are set, it has a different meaning, namely base is the array into which the current array will be copied upon copy resolution. This overloading of the base property for two functions is likely to change in a future version of NumPy.", "Returns a borrowed reference to the dtype property of the array.", "New in version 1.7.", "A synonym for PyArray_DESCR, named to be consistent with the \u2018dtype\u2019 usage within Python.", "Get a Python object of a builtin type from the ndarray, arr, at the location pointed to by itemptr. Return NULL on failure.", "numpy.ndarray.item is identical to PyArray_GETITEM.", "The function pointed to by the CObject __array_finalize__. The first argument is the newly created sub-type. The second argument (if not NULL) is the \u201cparent\u201d array (if the array was created using slicing or some other operation where a clearly-distinguishable parent is present). This routine can do anything it wants to. It should return a -1 on error and 0 otherwise.", "These functions and macros provide easy access to elements of the ndarray from C. These work for all arrays. You may need to take care when accessing the data in the array, however, if it is not in machine byte-order, misaligned, or not writeable. In other words, be sure to respect the state of the flags unless you know what you are doing, or have previously guaranteed an array that is writeable, aligned, and in machine byte-order using PyArray_FromAny. If you wish to handle all types of arrays, the copyswap function for each type is useful for handling misbehaved arrays. Some platforms (e.g. Solaris) do not like misaligned data and will crash if you de-reference a misaligned pointer. Other platforms (e.g. x86 Linux) will just work more slowly with misaligned data.", "Return a pointer to the data of the ndarray, aobj, at the N-dimensional index given by the c-array, ind, (which must be at least aobj ->nd in size). You may want to typecast the returned pointer to the data type of the ndarray.", "Quick, inline access to the element at the given coordinates in the ndarray, obj, which must have respectively 1, 2, 3, or 4 dimensions (this is not checked). The corresponding i, j, k, and l coordinates can be any integer but will be interpreted as npy_intp. You may want to typecast the returned pointer to the data type of the ndarray.", "This function steals a reference to descr. The easiest way to get one is using PyArray_DescrFromType.", "This is the main array creation function. Most new arrays are created with this flexible function.", "The returned object is an object of Python-type subtype, which must be a subtype of PyArray_Type. The array has nd dimensions, described by dims. The data-type descriptor of the new array is descr.", "If subtype is of an array subclass instead of the base &PyArray_Type, then obj is the object to pass to the __array_finalize__ method of the subclass.", "If data is NULL, then new unitinialized memory will be allocated and flags can be non-zero to indicate a Fortran-style contiguous array. Use PyArray_FILLWBYTE to initialize the memory.", "If data is not NULL, then it is assumed to point to the memory to be used for the array and the flags argument is used as the new flags for the array (except the state of NPY_ARRAY_OWNDATA, NPY_ARRAY_WRITEBACKIFCOPY and NPY_ARRAY_UPDATEIFCOPY flags of the new array will be reset).", "In addition, if data is non-NULL, then strides can also be provided. If strides is NULL, then the array strides are computed as C-style contiguous (default) or Fortran-style contiguous (flags is nonzero for data = NULL or flags & NPY_ARRAY_F_CONTIGUOUS is nonzero non-NULL data). Any provided dims and strides are copied into newly allocated dimension and strides arrays for the new array object.", "PyArray_CheckStrides can help verify non- NULL stride information.", "If data is provided, it must stay alive for the life of the array. One way to manage this is through PyArray_SetBaseObject", "New in version 1.6.", "This function steals a reference to descr if it is not NULL. This array creation routine allows for the convenient creation of a new array matching an existing array\u2019s shapes and memory layout, possibly changing the layout and/or data type.", "When order is NPY_ANYORDER, the result order is NPY_FORTRANORDER if prototype is a fortran array, NPY_CORDER otherwise. When order is NPY_KEEPORDER, the result order matches that of prototype, even when the axes of prototype aren\u2019t in C or Fortran order.", "If descr is NULL, the data type of prototype is used.", "If subok is 1, the newly created array will use the sub-type of prototype to create the new array, otherwise it will create a base-class array.", "This is similar to PyArray_NewFromDescr (\u2026) except you specify the data-type descriptor with type_num and itemsize, where type_num corresponds to a builtin (or user-defined) type. If the type always has the same number of bytes, then itemsize is ignored. Otherwise, itemsize specifies the particular size of this array.", "Warning", "If data is passed to PyArray_NewFromDescr or PyArray_New, this memory must not be deallocated until the new array is deleted. If this data came from another Python object, this can be accomplished using Py_INCREF on that object and setting the base member of the new array to point to that object. If strides are passed in they must be consistent with the dimensions, the itemsize, and the data of the array.", "Create a new uninitialized array of type, typenum, whose size in each of nd dimensions is given by the integer array, dims.The memory for the array is uninitialized (unless typenum is NPY_OBJECT in which case each element in the array is set to NULL). The typenum argument allows specification of any of the builtin data-types such as NPY_FLOAT or NPY_LONG. The memory for the array can be set to zero if desired using PyArray_FILLWBYTE (return_object, 0).This function cannot be used to create a flexible-type array (no itemsize given).", "Create an array wrapper around data pointed to by the given pointer. The array flags will have a default that the data area is well-behaved and C-style contiguous. The shape of the array is given by the dims c-array of length nd. The data-type of the array is indicated by typenum. If data comes from another reference-counted Python object, the reference count on this object should be increased after the pointer is passed in, and the base member of the returned ndarray should point to the Python object that owns the data. This will ensure that the provided memory is not freed while the returned array is in existence.", "This function steals a reference to descr.", "Create a new array with the provided data-type descriptor, descr, of the shape determined by nd and dims.", "Fill the array pointed to by obj \u2014which must be a (subclass of) ndarray\u2014with the contents of val (evaluated as a byte). This macro calls memset, so obj must be contiguous.", "Construct a new nd -dimensional array with shape given by dims and data type given by dtype. If fortran is non-zero, then a Fortran-order array is created, otherwise a C-order array is created. Fill the memory with zeros (or the 0 object if dtype corresponds to NPY_OBJECT ).", "Macro form of PyArray_Zeros which takes a type-number instead of a data-type object.", "Construct a new nd -dimensional array with shape given by dims and data type given by dtype. If fortran is non-zero, then a Fortran-order array is created, otherwise a C-order array is created. The array is uninitialized unless the data type corresponds to NPY_OBJECT in which case the array is filled with Py_None.", "Macro form of PyArray_Empty which takes a type-number, typenum, instead of a data-type object.", "Construct a new 1-dimensional array of data-type, typenum, that ranges from start to stop (exclusive) in increments of step . Equivalent to arange (start, stop, step, dtype).", "Construct a new 1-dimensional array of data-type determined by descr, that ranges from start to stop (exclusive) in increments of step. Equivalent to arange( start, stop, step, typenum ).", "New in version 1.7.", "This function steals a reference to obj and sets it as the base property of arr.", "If you construct an array by passing in your own memory buffer as a parameter, you need to set the array\u2019s base property to ensure the lifetime of the memory buffer is appropriate.", "The return value is 0 on success, -1 on failure.", "If the object provided is an array, this function traverses the chain of base pointers so that each array points to the owner of the memory directly. Once the base is set, it may not be changed to another value.", "This is the main function used to obtain an array from any nested sequence, or object that exposes the array interface, op. The parameters allow specification of the required dtype, the minimum (min_depth) and maximum (max_depth) number of dimensions acceptable, and other requirements for the array. This function steals a reference to the dtype argument, which needs to be a PyArray_Descr structure indicating the desired data-type (including required byteorder). The dtype argument may be NULL, indicating that any data-type (and byteorder) is acceptable. Unless NPY_ARRAY_FORCECAST is present in flags, this call will generate an error if the data type cannot be safely obtained from the object. If you want to use NULL for the dtype and ensure the array is notswapped then use PyArray_CheckFromAny. A value of 0 for either of the depth parameters causes the parameter to be ignored. Any of the following array flags can be added (e.g. using |) to get the requirements argument. If your code can handle general (e.g. strided, byte-swapped, or unaligned arrays) then requirements may be 0. Also, if op is not already an array (or does not expose the array interface), then a new array will be created (and filled from op using the sequence protocol). The new array will have NPY_ARRAY_DEFAULT as its flags member. The context argument is unused.", "Make sure the returned array is C-style contiguous", "Make sure the returned array is Fortran-style contiguous.", "Make sure the returned array is aligned on proper boundaries for its data type. An aligned array has the data pointer and every strides factor as a multiple of the alignment factor for the data-type- descriptor.", "Make sure the returned array can be written to.", "Make sure a copy is made of op. If this flag is not present, data is not copied if it can be avoided.", "Make sure the result is a base-class ndarray. By default, if op is an instance of a subclass of ndarray, an instance of that same subclass is returned. If this flag is set, an ndarray object will be returned instead.", "Force a cast to the output type even if it cannot be done safely. Without this flag, a data cast will occur only if it can be done safely, otherwise an error is raised.", "If op is already an array, but does not satisfy the requirements, then a copy is made (which will satisfy the requirements). If this flag is present and a copy (of an object that is already an array) must be made, then the corresponding NPY_ARRAY_WRITEBACKIFCOPY flag is set in the returned copy and op is made to be read-only. You must be sure to call PyArray_ResolveWritebackIfCopy to copy the contents back into op and the op array will be made writeable again. If op is not writeable to begin with, or if it is not already an array, then an error is raised.", "Deprecated. Use NPY_ARRAY_WRITEBACKIFCOPY, which is similar. This flag \u201cautomatically\u201d copies the data back when the returned array is deallocated, which is not supported in all python implementations.", "NPY_ARRAY_ALIGNED | NPY_ARRAY_WRITEABLE", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_BEHAVED", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_ALIGNED", "NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_BEHAVED", "NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_ALIGNED", "NPY_ARRAY_CARRAY", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_ALIGNED", "NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_ALIGNED", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_ALIGNED | NPY_ARRAY_WRITEABLE", "NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED | NPY_ARRAY_WRITEBACKIFCOPY | NPY_ARRAY_UPDATEIFCOPY", "NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED | NPY_ARRAY_WRITEBACKIFCOPY | NPY_ARRAY_UPDATEIFCOPY", "Deprecated since version NumPy: 1.19", "Unless NumPy is made aware of an issue with this, this function is scheduled for rapid removal without replacement.", "Changed in version NumPy: 1.19", "context is never used. Its use results in an error.", "New in version 1.6.", "Nearly identical to PyArray_FromAny (\u2026) except requirements can contain NPY_ARRAY_NOTSWAPPED (over-riding the specification in dtype) and NPY_ARRAY_ELEMENTSTRIDES which indicates that the array should be aligned in the sense that the strides are multiples of the element size.", "In versions 1.6 and earlier of NumPy, the following flags did not have the _ARRAY_ macro namespace in them. That form of the constant names is deprecated in 1.7.", "Make sure the returned array has a data-type descriptor that is in machine byte-order, over-riding any specification in the dtype argument. Normally, the byte-order requirement is determined by the dtype argument. If this flag is set and the dtype argument does not indicate a machine byte-order descriptor (or is NULL and the object is already an array with a data-type descriptor that is not in machine byte- order), then a new data-type descriptor is created and used with its byte-order field set to native.", "NPY_ARRAY_ALIGNED | NPY_ARRAY_WRITEABLE | NPY_ARRAY_NOTSWAPPED", "Make sure the returned array has strides that are multiples of the element size.", "Special case of PyArray_FromAny for when op is already an array but it needs to be of a specific newtype (including byte-order) or has certain requirements.", "Returns an ndarray object from a Python object that exposes the __array_struct__ attribute and follows the array interface protocol. If the object does not contain this attribute then a borrowed reference to Py_NotImplemented is returned.", "Returns an ndarray object from a Python object that exposes the __array_interface__ attribute following the array interface protocol. If the object does not contain this attribute then a borrowed reference to Py_NotImplemented is returned.", "Return an ndarray object from a Python object that exposes the __array__ method. The __array__ method can take 0, or 1 argument ([dtype]). context is unused.", "This function returns a (C-style) contiguous and behaved function array from any nested sequence or array interface exporting object, op, of (non-flexible) type given by the enumerated typenum, of minimum depth min_depth, and of maximum depth max_depth. Equivalent to a call to PyArray_FromAny with requirements set to NPY_ARRAY_DEFAULT and the type_num member of the type argument set to typenum.", "This function returns a well-behaved C-style contiguous array from any nested sequence or array-interface exporting object. The minimum number of dimensions the array can have is given by min_depth while the maximum is max_depth. This is equivalent to call PyArray_FromAny with requirements NPY_ARRAY_DEFAULT and NPY_ARRAY_ENSUREARRAY.", "Return an aligned and in native-byteorder array from any nested sequence or array-interface exporting object, op, of a type given by the enumerated typenum. The minimum number of dimensions the array can have is given by min_depth while the maximum is max_depth. This is equivalent to a call to PyArray_FromAny with requirements set to BEHAVED.", "This function steals a reference to op and makes sure that op is a base-class ndarray. It special cases array scalars, but otherwise calls PyArray_FromAny ( op, NULL, 0, 0, NPY_ARRAY_ENSUREARRAY, NULL).", "Construct a one-dimensional ndarray of a single type from a binary or (ASCII) text string of length slen. The data-type of the array to-be-created is given by dtype. If num is -1, then copy the entire string and return an appropriately sized array, otherwise, num is the number of items to copy from the string. If sep is NULL (or \u201c\u201d), then interpret the string as bytes of binary data, otherwise convert the sub-strings separated by sep to items of data-type dtype. Some data-types may not be readable in text mode and an error will be raised if that occurs. All errors return NULL.", "Construct a one-dimensional ndarray of a single type from a binary or text file. The open file pointer is fp, the data-type of the array to be created is given by dtype. This must match the data in the file. If num is -1, then read until the end of the file and return an appropriately sized array, otherwise, num is the number of items to read. If sep is NULL (or \u201c\u201d), then read from the file in binary mode, otherwise read from the file in text mode with sep providing the item separator. Some array types cannot be read in text mode in which case an error is raised.", "Construct a one-dimensional ndarray of a single type from an object, buf, that exports the (single-segment) buffer protocol (or has an attribute __buffer__ that returns an object that exports the buffer protocol). A writeable buffer will be tried first followed by a read- only buffer. The NPY_ARRAY_WRITEABLE flag of the returned array will reflect which one was successful. The data is assumed to start at offset bytes from the start of the memory location for the object. The type of the data in the buffer will be interpreted depending on the data- type descriptor, dtype. If count is negative then it will be determined from the size of the buffer and the requested itemsize, otherwise, count represents how many elements should be converted from the buffer.", "Copy from the source array, src, into the destination array, dest, performing a data-type conversion if necessary. If an error occurs return -1 (otherwise 0). The shape of src must be broadcastable to the shape of dest. The data areas of dest and src must not overlap.", "Assign an object src to a NumPy array dest according to array-coercion rules. This is basically identical to PyArray_FromAny, but assigns directly to the output array. Returns 0 on success and -1 on failures.", "Move data from the source array, src, into the destination array, dest, performing a data-type conversion if necessary. If an error occurs return -1 (otherwise 0). The shape of src must be broadcastable to the shape of dest. The data areas of dest and src may overlap.", "If op is already (C-style) contiguous and well-behaved then just return a reference, otherwise return a (contiguous and well-behaved) copy of the array. The parameter op must be a (sub-class of an) ndarray and no checking for that is done.", "Convert obj to an ndarray. The argument can be any nested sequence or object that exports the array interface. This is a macro form of PyArray_FromAny using NULL, 0, 0, 0 for the other arguments. Your code must be able to handle any data-type descriptor and any combination of data-flags to use this macro.", "Similar to PyArray_FROM_O except it can take an argument of requirements indicating properties the resulting array must have. Available requirements that can be enforced are NPY_ARRAY_C_CONTIGUOUS, NPY_ARRAY_F_CONTIGUOUS, NPY_ARRAY_ALIGNED, NPY_ARRAY_WRITEABLE, NPY_ARRAY_NOTSWAPPED, NPY_ARRAY_ENSURECOPY, NPY_ARRAY_WRITEBACKIFCOPY, NPY_ARRAY_UPDATEIFCOPY, NPY_ARRAY_FORCECAST, and NPY_ARRAY_ENSUREARRAY. Standard combinations of flags can also be used:", "Similar to PyArray_FROM_O except it can take an argument of typenum specifying the type-number the returned array.", "Combination of PyArray_FROM_OF and PyArray_FROM_OT allowing both a typenum and a flags argument to be provided.", "Similar to PyArray_FromAny except the data-type is specified using a typenumber. PyArray_DescrFromType (typenum) is passed directly to PyArray_FromAny. This macro also adds NPY_ARRAY_DEFAULT to requirements if NPY_ARRAY_ENSURECOPY is passed in as requirements.", "Encapsulate the functionality of functions and methods that take the axis= keyword and work properly with None as the axis argument. The input array is obj, while *axis is a converted integer (so that >=MAXDIMS is the None value), and requirements gives the needed properties of obj. The output is a converted version of the input so that requirements are met and if needed a flattening has occurred. On output negative values of *axis are converted and the new value is checked to ensure consistency with the shape of obj.", "Evaluates true if op is a Python object whose type is a sub-type of PyArray_Type.", "Evaluates true if op is a Python object with type PyArray_Type.", "If op implements any part of the array interface, then out will contain a new reference to the newly created ndarray using the interface or out will contain NULL if an error during conversion occurs. Otherwise, out will contain a borrowed reference to Py_NotImplemented and no error condition is set.", "If op implements any part of the array interface, then out will contain a new reference to the newly created ndarray using the interface or out will contain NULL if an error during conversion occurs. Otherwise, out will contain a borrowed reference to Py_NotImplemented and no error condition is set. This version allows setting of the dtype in the part of the array interface that looks for the __array__ attribute. context is unused.", "Evaluates true if op is an instance of (a subclass of) PyArray_Type and has 0 dimensions.", "Evaluates true if op is an instance of Py{cls}ArrType_Type.", "Evaluates true if op is either an array scalar (an instance of a sub-type of PyGenericArr_Type ), or an instance of (a sub-class of) PyArray_Type whose dimensionality is 0.", "Evaluates true if op is an instance of a builtin numeric type (int, float, complex, long, bool)", "Evaluates true if op is a builtin Python scalar object (int, float, complex, bytes, str, long, bool).", "Evaluates true if op is either a Python scalar object (see PyArray_IsPythonScalar) or an array scalar (an instance of a sub- type of PyGenericArr_Type ).", "Evaluates true if op is a Python scalar object (see PyArray_IsPythonScalar), an array scalar (an instance of a sub-type of PyGenericArr_Type) or an instance of a sub-type of PyArray_Type whose dimensionality is 0.", "For the typenum macros, the argument is an integer representing an enumerated array data type. For the array type checking macros the argument must be a PyObject* that can be directly interpreted as a PyArrayObject*.", "Type represents an unsigned integer.", "Type represents a signed integer.", "Type represents any integer.", "Type represents any floating point number.", "Type represents any complex floating point number.", "Type represents any integer, floating point, or complex floating point number.", "Type represents a string data type.", "Type represents an enumerated type corresponding to one of the standard Python scalar (bool, int, float, or complex).", "Type represents one of the flexible array types ( NPY_STRING, NPY_UNICODE, or NPY_VOID ).", "Type has no size information attached, and can be resized. Should only be called on flexible dtypes. Types that are attached to an array will always be sized, hence the array form of this macro not existing.", "Changed in version 1.18.", "For structured datatypes with no fields this function now returns False.", "Type represents a user-defined type.", "Type is either flexible or user-defined.", "Type represents object data type.", "Type represents Boolean data type.", "Type has fields associated with it.", "Evaluates true if the data area of the ndarray m is in machine byte-order according to the array\u2019s data-type descriptor.", "Evaluates true if the data area of the ndarray m is not in machine byte-order according to the array\u2019s data-type descriptor.", "Return NPY_TRUE if type1 and type2 actually represent equivalent types for this platform (the fortran member of each type is ignored). For example, on 32-bit platforms, NPY_LONG and NPY_INT are equivalent. Otherwise return NPY_FALSE.", "Return NPY_TRUE if a1 and a2 are arrays with equivalent types for this platform.", "Special case of PyArray_EquivTypes (\u2026) that does not accept flexible data types but may be easier to call.", "True if byteorder characters b1 and b2 ( NPY_LITTLE, NPY_BIG, NPY_NATIVE, NPY_IGNORE ) are either equal or equivalent as to their specification of a native byte order. Thus, on a little-endian machine NPY_LITTLE and NPY_NATIVE are equivalent where they are not equivalent on a big-endian machine.", "Mainly for backwards compatibility to the Numeric C-API and for simple casts to non-flexible types. Return a new array object with the elements of arr cast to the data-type typenum which must be one of the enumerated types and not a flexible type.", "Return a new array of the type specified, casting the elements of arr as appropriate. The fortran argument specifies the ordering of the output array.", "As of 1.6, this function simply calls PyArray_CopyInto, which handles the casting.", "Cast the elements of the array in into the array out. The output array should be writeable, have an integer-multiple of the number of elements in the input array (more than one copy can be placed in out), and have a data type that is one of the builtin types. Returns 0 on success and -1 if an error occurs.", "Return the low-level casting function to cast from the given descriptor to the builtin type number. If no casting function exists return NULL and set an error. Using this function instead of direct access to from ->f->cast will allow support of any user-defined casting functions added to a descriptors casting dictionary.", "Returns non-zero if an array of data type fromtype can be cast to an array of data type totype without losing information. An exception is that 64-bit integers are allowed to be cast to 64-bit floating point values even though this can lose precision on large integers so as not to proliferate the use of long doubles without explicit requests. Flexible array types are not checked according to their lengths with this function.", "PyArray_CanCastTypeTo supersedes this function in NumPy 1.6 and later.", "Equivalent to PyArray_CanCastTypeTo(fromtype, totype, NPY_SAFE_CASTING).", "New in version 1.6.", "Returns non-zero if an array of data type fromtype (which can include flexible types) can be cast safely to an array of data type totype (which can include flexible types) according to the casting rule casting. For simple types with NPY_SAFE_CASTING, this is basically a wrapper around PyArray_CanCastSafely, but for flexible types such as strings or unicode, it produces results taking into account their sizes. Integer and float types can only be cast to a string or unicode type using NPY_SAFE_CASTING if the string or unicode type is big enough to hold the max value of the integer/float type being cast from.", "New in version 1.6.", "Returns non-zero if arr can be cast to totype according to the casting rule given in casting. If arr is an array scalar, its value is taken into account, and non-zero is also returned when the value will not overflow or be truncated to an integer when converting to a smaller type.", "This is almost the same as the result of PyArray_CanCastTypeTo(PyArray_MinScalarType(arr), totype, casting), but it also handles a special case arising because the set of uint values is not a subset of the int values for types with the same number of bits.", "New in version 1.6.", "If arr is an array, returns its data type descriptor, but if arr is an array scalar (has 0 dimensions), it finds the data type of smallest size to which the value may be converted without overflow or truncation to an integer.", "This function will not demote complex to float or anything to boolean, but will demote a signed integer to an unsigned integer when the scalar value is positive.", "New in version 1.6.", "Finds the data type of smallest size and kind to which type1 and type2 may be safely converted. This function is symmetric and associative. A string or unicode result will be the proper size for storing the max value of the input types converted to a string or unicode.", "New in version 1.6.", "This applies type promotion to all the inputs, using the NumPy rules for combining scalars and arrays, to determine the output type of a set of operands. This is the same result type that ufuncs produce. The specific algorithm used is as follows.", "Categories are determined by first checking which of boolean, integer (int/uint), or floating point (float/complex) the maximum kind of all the arrays and the scalars are.", "If there are only scalars or the maximum category of the scalars is higher than the maximum category of the arrays, the data types are combined with PyArray_PromoteTypes to produce the return value.", "Otherwise, PyArray_MinScalarType is called on each array, and the resulting data types are all combined with PyArray_PromoteTypes to produce the return value.", "The set of int values is not a subset of the uint values for types with the same number of bits, something not reflected in PyArray_MinScalarType, but handled as a special case in PyArray_ResultType.", "This function is superseded by PyArray_MinScalarType and/or PyArray_ResultType.", "This function is useful for determining a common type that two or more arrays can be converted to. It only works for non-flexible array types as no itemsize information is passed. The mintype argument represents the minimum type acceptable, and op represents the object that will be converted to an array. The return value is the enumerated typenumber that represents the data-type that op should have.", "This function is superseded by PyArray_ResultType.", "This function works similarly to PyArray_ObjectType (\u2026) except it handles flexible arrays. The mintype argument can have an itemsize member and the outtype argument will have an itemsize member at least as big but perhaps bigger depending on the object op.", "The functionality this provides is largely superseded by iterator NpyIter introduced in 1.6, with flag NPY_ITER_COMMON_DTYPE or with the same dtype parameter for all operands.", "Convert a sequence of Python objects contained in op to an array of ndarrays each having the same data type. The type is selected in the same way as PyArray_ResultType. The length of the sequence is returned in n, and an n -length array of PyArrayObject pointers is the return value (or NULL if an error occurs). The returned array must be freed by the caller of this routine (using PyDataMem_FREE ) and all the array objects in it DECREF \u2018d or a memory-leak will occur. The example template-code below shows a typically usage:", "Changed in version 1.18.0: A mix of scalars and zero-dimensional arrays now produces a type capable of holding the scalar value. Previously priority was given to the dtype of the arrays.", "A pointer to newly created memory of size arr ->itemsize that holds the representation of 0 for that type. The returned pointer, ret, must be freed using PyDataMem_FREE (ret) when it is not needed anymore.", "A pointer to newly created memory of size arr ->itemsize that holds the representation of 1 for that type. The returned pointer, ret, must be freed using PyDataMem_FREE (ret) when it is not needed anymore.", "Returns NPY_TRUE if typenum represents a valid type-number (builtin or user-defined or character code). Otherwise, this function returns NPY_FALSE.", "Initialize all function pointers and members to NULL.", "Register a data-type as a new user-defined data type for arrays. The type must have most of its entries filled in. This is not always checked and errors can produce segfaults. In particular, the typeobj member of the dtype structure must be filled with a Python type that has a fixed-size element-size that corresponds to the elsize member of dtype. Also the f member must have the required functions: nonzero, copyswap, copyswapn, getitem, setitem, and cast (some of the cast functions may be NULL if no support is desired). To avoid confusion, you should choose a unique character typecode but this is not enforced and not relied on internally.", "A user-defined type number is returned that uniquely identifies the type. A pointer to the new structure can then be obtained from PyArray_DescrFromType using the returned type number. A -1 is returned if an error occurs. If this dtype has already been registered (checked only by the address of the pointer), then return the previously-assigned type-number.", "Register a low-level casting function, castfunc, to convert from the data-type, descr, to the given data-type number, totype. Any old casting function is over-written. A 0 is returned on success or a -1 on failure.", "Register the data-type number, totype, as castable from data-type object, descr, of the given scalar kind. Use scalar = NPY_NOSCALAR to register that an array of data-type descr can be cast safely to a data-type whose type_number is totype. The return value is 0 on success or -1 on failure.", "Given a string return the type-number for the data-type with that string as the type-object name. Returns NPY_NOTYPE without setting an error if no type can be found. Only works for user-defined data-types.", "Used for an array, op, that contains any Python objects. It increments the reference count of every object in the array according to the data-type of op. A -1 is returned if an error occurs, otherwise 0 is returned.", "A function to INCREF all the objects at the location ptr according to the data-type dtype. If ptr is the start of a structured type with an object at any offset, then this will (recursively) increment the reference count of all object-like items in the structured type.", "Used for an array, op, that contains any Python objects. It decrements the reference count of every object in the array according to the data-type of op. Normal return value is 0. A -1 is returned if an error occurs.", "A function to XDECREF all the object-like items at the location ptr as recorded in the data-type, dtype. This works recursively so that if dtype itself has fields with data-types that contain object-like items, all the object-like fields will be XDECREF 'd.", "Fill a newly created array with a single value obj at all locations in the structure with object data-types. No checking is performed but arr must be of data-type NPY_OBJECT and be single-segment and uninitialized (no previous objects in position). Use PyArray_XDECREF (arr) if you need to decrement all the items in the object array prior to calling this function.", "Precondition: arr is a copy of base (though possibly with different strides, ordering, etc.) Set the UPDATEIFCOPY flag and arr->base so that when arr is destructed, it will copy any changes back to base. DEPRECATED, use PyArray_SetWritebackIfCopyBase.", "Returns 0 for success, -1 for failure.", "Precondition: arr is a copy of base (though possibly with different strides, ordering, etc.) Sets the NPY_ARRAY_WRITEBACKIFCOPY flag and arr->base, and set base to READONLY. Call PyArray_ResolveWritebackIfCopy before calling Py_DECREF in order copy any changes back to base and reset the READONLY flag.", "Returns 0 for success, -1 for failure.", "The flags attribute of the PyArrayObject structure contains important information about the memory used by the array (pointed to by the data member) This flag information must be kept accurate or strange results and even segfaults may result.", "There are 6 (binary) flags that describe the memory area used by the data buffer. These constants are defined in arrayobject.h and determine the bit-position of the flag. Python exposes a nice attribute- based interface as well as a dictionary-like interface for getting (and, if appropriate, setting) these flags.", "Memory areas of all kinds can be pointed to by an ndarray, necessitating these flags. If you get an arbitrary PyArrayObject in C-code, you need to be aware of the flags that are set. If you need to guarantee a certain kind of array (like NPY_ARRAY_C_CONTIGUOUS and NPY_ARRAY_BEHAVED), then pass these requirements into the PyArray_FromAny function.", "An ndarray can have a data segment that is not a simple contiguous chunk of well-behaved memory you can manipulate. It may not be aligned with word boundaries (very important on some platforms). It might have its data in a different byte-order than the machine recognizes. It might not be writeable. It might be in Fortran-contiguous order. The array flags are used to indicate what can be said about data associated with an array.", "In versions 1.6 and earlier of NumPy, the following flags did not have the _ARRAY_ macro namespace in them. That form of the constant names is deprecated in 1.7.", "The data area is in C-style contiguous order (last index varies the fastest).", "The data area is in Fortran-style contiguous order (first index varies the fastest).", "Note", "Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.", "Even for contiguous arrays a stride for a given dimension arr.strides[dim] may be arbitrary if arr.shape[dim] == 1 or the array has no elements. It does not generally hold that self.strides[-1] == self.itemsize for C-style contiguous arrays or self.strides[0] == self.itemsize for Fortran-style contiguous arrays is true. The correct way to access the itemsize of an array from the C API is PyArray_ITEMSIZE(arr).", "See also", "Internal memory layout of an ndarray", "The data area is owned by this array. Should never be set manually, instead create a PyObject wrapping the data and set the array\u2019s base to that object. For an example, see the test in test_mem_policy.", "The data area and all array elements are aligned appropriately.", "The data area can be written to.", "Notice that the above 3 flags are defined so that a new, well- behaved array has these flags defined as true.", "The data area represents a (well-behaved) copy whose information should be transferred back to the original when PyArray_ResolveWritebackIfCopy is called.", "This is a special flag that is set if this array represents a copy made because a user required certain flags in PyArray_FromAny and a copy had to be made of some other array (and the user asked for this flag to be set in such a situation). The base attribute then points to the \u201cmisbehaved\u201d array (which is set read_only). :c:func`PyArray_ResolveWritebackIfCopy` will copy its contents back to the \u201cmisbehaved\u201d array (casting if necessary) and will reset the \u201cmisbehaved\u201d array to NPY_ARRAY_WRITEABLE. If the \u201cmisbehaved\u201d array was not NPY_ARRAY_WRITEABLE to begin with then PyArray_FromAny would have returned an error because NPY_ARRAY_WRITEBACKIFCOPY would not have been possible.", "A deprecated version of NPY_ARRAY_WRITEBACKIFCOPY which depends upon dealloc to trigger the writeback. For backwards compatibility, PyArray_ResolveWritebackIfCopy is called at dealloc but relying on that behavior is deprecated and not supported in PyPy.", "PyArray_UpdateFlags (obj, flags) will update the obj->flags for flags which can be any of NPY_ARRAY_C_CONTIGUOUS, NPY_ARRAY_F_CONTIGUOUS, NPY_ARRAY_ALIGNED, or NPY_ARRAY_WRITEABLE.", "NPY_ARRAY_ALIGNED | NPY_ARRAY_WRITEABLE", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_BEHAVED", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_ALIGNED", "NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_BEHAVED", "NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_ALIGNED", "NPY_ARRAY_CARRAY", "NPY_ARRAY_C_CONTIGUOUS | NPY_ARRAY_F_CONTIGUOUS | NPY_ARRAY_ALIGNED", "These constants are used in PyArray_FromAny (and its macro forms) to specify desired properties of the new array.", "Cast to the desired type, even if it can\u2019t be done without losing information.", "Make sure the resulting array is a copy of the original.", "Make sure the resulting object is an actual ndarray, and not a sub-class.", "For all of these macros arr must be an instance of a (subclass of) PyArray_Type.", "The first parameter, arr, must be an ndarray or subclass. The parameter, flags, should be an integer consisting of bitwise combinations of the possible flags an array can have: NPY_ARRAY_C_CONTIGUOUS, NPY_ARRAY_F_CONTIGUOUS, NPY_ARRAY_OWNDATA, NPY_ARRAY_ALIGNED, NPY_ARRAY_WRITEABLE, NPY_ARRAY_WRITEBACKIFCOPY, NPY_ARRAY_UPDATEIFCOPY.", "Evaluates true if arr is C-style contiguous.", "Evaluates true if arr is Fortran-style contiguous.", "Evaluates true if arr is Fortran-style contiguous and not C-style contiguous. PyArray_IS_F_CONTIGUOUS is the correct way to test for Fortran-style contiguity.", "Evaluates true if the data area of arr can be written to", "Evaluates true if the data area of arr is properly aligned on the machine.", "Evaluates true if the data area of arr is aligned and writeable and in machine byte-order according to its descriptor.", "Evaluates true if the data area of arr is aligned and in machine byte-order.", "Evaluates true if the data area of arr is C-style contiguous, and PyArray_ISBEHAVED (arr) is true.", "Evaluates true if the data area of arr is Fortran-style contiguous and PyArray_ISBEHAVED (arr) is true.", "Evaluates true if the data area of arr is C-style contiguous, aligned, and in machine byte-order.", "Evaluates true if the data area of arr is Fortran-style contiguous, aligned, and in machine byte-order .", "Evaluates true if the data area of arr consists of a single (C-style or Fortran-style) contiguous segment.", "The NPY_ARRAY_C_CONTIGUOUS, NPY_ARRAY_ALIGNED, and NPY_ARRAY_F_CONTIGUOUS array flags can be \u201ccalculated\u201d from the array object itself. This routine updates one or more of these flags of arr as specified in flagmask by performing the required calculation.", "Warning", "It is important to keep the flags updated (using PyArray_UpdateFlags can help) whenever a manipulation with an array is performed that might cause them to change. Later calculations in NumPy that rely on the state of these flags do not repeat the calculation to update them.", "Equivalent to ndarray.getfield (self, dtype, offset). This function steals a reference to PyArray_Descr and returns a new array of the given dtype using the data in the current array at a specified offset in bytes. The offset plus the itemsize of the new array type must be less than self\n->descr->elsize or an error is raised. The same shape and strides as the original array are used. Therefore, this function has the effect of returning a field from a structured array. But, it can also be used to select specific bytes or groups of bytes from any array type.", "Equivalent to ndarray.setfield (self, val, dtype, offset ). Set the field starting at offset in bytes and of the given dtype to val. The offset plus dtype ->elsize must be less than self ->descr->elsize or an error is raised. Otherwise, the val argument is converted to an array and copied into the field pointed to. If necessary, the elements of val are repeated to fill the destination array, But, the number of elements in the destination must be an integer multiple of the number of elements in val.", "Equivalent to ndarray.byteswap (self, inplace). Return an array whose data area is byteswapped. If inplace is non-zero, then do the byteswap inplace and return a reference to self. Otherwise, create a byteswapped copy and leave self unchanged.", "Equivalent to ndarray.copy (self, fortran). Make a copy of the old array. The returned array is always aligned and writeable with data interpreted the same as the old array. If order is NPY_CORDER, then a C-style contiguous array is returned. If order is NPY_FORTRANORDER, then a Fortran-style contiguous array is returned. If order is NPY_ANYORDER, then the array returned is Fortran-style contiguous only if the old one is; otherwise, it is C-style contiguous.", "Equivalent to ndarray.tolist (self). Return a nested Python list from self.", "Equivalent to ndarray.tobytes (self, order). Return the bytes of this array in a Python string.", "Write the contents of self to the file pointer fp in C-style contiguous fashion. Write the data as binary bytes if sep is the string \u201c\u201dor NULL. Otherwise, write the contents of self as text using the sep string as the item separator. Each item will be printed to the file. If the format string is not NULL or \u201c\u201d, then it is a Python print statement format string showing how the items are to be written.", "Pickle the object in self to the given file (either a string or a Python file object). If file is a Python string it is considered to be the name of a file which is then opened in binary mode. The given protocol is used (if protocol is negative, or the highest available is used). This is a simple wrapper around cPickle.dump(self, file, protocol).", "Pickle the object in self to a Python string and return it. Use the Pickle protocol provided (or the highest available if protocol is negative).", "Fill the array, arr, with the given scalar object, obj. The object is first converted to the data type of arr, and then copied into every location. A -1 is returned if an error occurs, otherwise 0 is returned.", "Equivalent to ndarray.view (self, dtype). Return a new view of the array self as possibly a different data-type, dtype, and different array subclass ptype.", "If dtype is NULL, then the returned array will have the same data type as self. The new data-type must be consistent with the size of self. Either the itemsizes must be identical, or self must be single-segment and the total number of bytes must be the same. In the latter case the dimensions of the returned array will be altered in the last (or first for Fortran-style contiguous arrays) dimension. The data area of the returned array and self is exactly the same.", "Result will be a new array (pointing to the same memory location as self if possible), but having a shape given by newshape. If the new shape is not compatible with the strides of self, then a copy of the array with the new specified shape will be returned.", "Equivalent to ndarray.reshape (self, shape) where shape is a sequence. Converts shape to a PyArray_Dims structure and calls PyArray_Newshape internally. For back-ward compatibility \u2013 Not recommended", "Equivalent to ndarray.squeeze (self). Return a new view of self with all of the dimensions of length 1 removed from the shape.", "Warning", "matrix objects are always 2-dimensional. Therefore, PyArray_Squeeze has no effect on arrays of matrix sub-class.", "Equivalent to ndarray.swapaxes (self, a1, a2). The returned array is a new view of the data in self with the given axes, a1 and a2, swapped.", "Equivalent to ndarray.resize (self, newshape, refcheck = refcheck, order= fortran ). This function only works on single-segment arrays. It changes the shape of self inplace and will reallocate the memory for self if newshape has a different total number of elements then the old shape. If reallocation is necessary, then self must own its data, have self - >base==NULL, have self - >weakrefs==NULL, and (unless refcheck is 0) not be referenced by any other array. The fortran argument can be NPY_ANYORDER, NPY_CORDER, or NPY_FORTRANORDER. It currently has no effect. Eventually it could be used to determine how the resize operation should view the data when constructing a differently-dimensioned array. Returns None on success and NULL on error.", "Equivalent to ndarray.transpose (self, permute). Permute the axes of the ndarray object self according to the data structure permute and return the result. If permute is NULL, then the resulting array has its axes reversed. For example if self has shape \\(10\\times20\\times30\\), and permute .ptr is (0,2,1) the shape of the result is \\(10\\times30\\times20.\\) If permute is NULL, the shape of the result is \\(30\\times20\\times10.\\)", "Equivalent to ndarray.flatten (self, order). Return a 1-d copy of the array. If order is NPY_FORTRANORDER the elements are scanned out in Fortran order (first-dimension varies the fastest). If order is NPY_CORDER, the elements of self are scanned in C-order (last dimension varies the fastest). If order NPY_ANYORDER, then the result of PyArray_ISFORTRAN (self) is used to determine which order to flatten.", "Equivalent to self.ravel(order). Same basic functionality as PyArray_Flatten (self, order) except if order is 0 and self is C-style contiguous, the shape is altered but no copy is performed.", "Equivalent to ndarray.take (self, indices, axis, ret, clipmode) except axis =None in Python is obtained by setting axis = NPY_MAXDIMS in C. Extract the items from self indicated by the integer-valued indices along the given axis. The clipmode argument can be NPY_RAISE, NPY_WRAP, or NPY_CLIP to indicate what to do with out-of-bound indices. The ret argument can specify an output array rather than having one created internally.", "Equivalent to self.put(values, indices, clipmode ). Put values into self at the corresponding (flattened) indices. If values is too small it will be repeated as necessary.", "Place the values in self wherever corresponding positions (using a flattened context) in mask are true. The mask and self arrays must have the same total number of elements. If values is too small, it will be repeated as necessary.", "Equivalent to ndarray.repeat (self, op, axis). Copy the elements of self, op times along the given axis. Either op is a scalar integer or a sequence of length self ->dimensions[ axis ] indicating how many times to repeat each item along the axis.", "Equivalent to ndarray.choose (self, op, ret, clipmode). Create a new array by selecting elements from the sequence of arrays in op based on the integer values in self. The arrays must all be broadcastable to the same shape and the entries in self should be between 0 and len(op). The output is placed in ret unless it is NULL in which case a new output is created. The clipmode argument determines behavior for when entries in self are not between 0 and len(op).", "raise a ValueError;", "wrap values < 0 by adding len(op) and values >=len(op) by subtracting len(op) until they are in range;", "all values are clipped to the region [0, len(op) ).", "Equivalent to ndarray.sort (self, axis, kind). Return an array with the items of self sorted along axis. The array is sorted using the algorithm denoted by kind, which is an integer/enum pointing to the type of sorting algorithms used.", "Equivalent to ndarray.argsort (self, axis). Return an array of indices such that selection of these indices along the given axis would return a sorted version of self. If self ->descr is a data-type with fields defined, then self->descr->names is used to determine the sort order. A comparison where the first field is equal will use the second field and so on. To alter the sort order of a structured array, create a new data-type with a different order of names and construct a view of the array with that new data-type.", "Given a sequence of arrays (sort_keys) of the same shape, return an array of indices (similar to PyArray_ArgSort (\u2026)) that would sort the arrays lexicographically. A lexicographic sort specifies that when two keys are found to be equal, the order is based on comparison of subsequent keys. A merge sort (which leaves equal entries unmoved) is required to be defined for the types. The sort is accomplished by sorting the indices first using the first sort_key and then using the second sort_key and so forth. This is equivalent to the lexsort(sort_keys, axis) Python command. Because of the way the merge-sort works, be sure to understand the order the sort_keys must be in (reversed from the order you would use when comparing two elements).", "If these arrays are all collected in a structured array, then PyArray_Sort (\u2026) can also be used to sort the array directly.", "Equivalent to ndarray.searchsorted (self, values, side, perm). Assuming self is a 1-d array in ascending order, then the output is an array of indices the same shape as values such that, if the elements in values were inserted before the indices, the order of self would be preserved. No checking is done on whether or not self is in ascending order.", "The side argument indicates whether the index returned should be that of the first suitable location (if NPY_SEARCHLEFT) or of the last (if NPY_SEARCHRIGHT).", "The sorter argument, if not NULL, must be a 1D array of integer indices the same length as self, that sorts it into ascending order. This is typically the result of a call to PyArray_ArgSort (\u2026) Binary search is used to find the required insertion points.", "Equivalent to ndarray.partition (self, ktharray, axis, kind). Partitions the array so that the values of the element indexed by ktharray are in the positions they would be if the array is fully sorted and places all elements smaller than the kth before and all elements equal or greater after the kth element. The ordering of all elements within the partitions is undefined. If self->descr is a data-type with fields defined, then self->descr->names is used to determine the sort order. A comparison where the first field is equal will use the second field and so on. To alter the sort order of a structured array, create a new data-type with a different order of names and construct a view of the array with that new data-type. Returns zero on success and -1 on failure.", "Equivalent to ndarray.argpartition (self, ktharray, axis, kind). Return an array of indices such that selection of these indices along the given axis would return a partitioned version of self.", "Equivalent to ndarray.diagonal (self, offset, axis1, axis2 ). Return the offset diagonals of the 2-d arrays defined by axis1 and axis2.", "New in version 1.6.", "Counts the number of non-zero elements in the array object self.", "Equivalent to ndarray.nonzero (self). Returns a tuple of index arrays that select elements of self that are nonzero. If (nd= PyArray_NDIM ( self ))==1, then a single index array is returned. The index arrays have data type NPY_INTP. If a tuple is returned (nd \\(\\neq\\) 1), then its length is nd.", "Equivalent to ndarray.compress (self, condition, axis ). Return the elements along axis corresponding to elements of condition that are true.", "Tip", "Pass in NPY_MAXDIMS for axis in order to achieve the same effect that is obtained by passing in axis=None in Python (treating the array as a 1-d array).", "Note", "The out argument specifies where to place the result. If out is NULL, then the output array is created, otherwise the output is placed in out which must be the correct size and type. A new reference to the output array is always returned even when out is not NULL. The caller of the routine has the responsibility to Py_DECREF out if not NULL or a memory-leak will occur.", "Equivalent to ndarray.argmax (self, axis). Return the index of the largest element of self along axis.", "Equivalent to ndarray.argmin (self, axis). Return the index of the smallest element of self along axis.", "Equivalent to ndarray.max (self, axis). Returns the largest element of self along the given axis. When the result is a single element, returns a numpy scalar instead of an ndarray.", "Equivalent to ndarray.min (self, axis). Return the smallest element of self along the given axis. When the result is a single element, returns a numpy scalar instead of an ndarray.", "Equivalent to ndarray.ptp (self, axis). Return the difference between the largest element of self along axis and the smallest element of self along axis. When the result is a single element, returns a numpy scalar instead of an ndarray.", "Note", "The rtype argument specifies the data-type the reduction should take place over. This is important if the data-type of the array is not \u201clarge\u201d enough to handle the output. By default, all integer data-types are made at least as large as NPY_LONG for the \u201cadd\u201d and \u201cmultiply\u201d ufuncs (which form the basis for mean, sum, cumsum, prod, and cumprod functions).", "Equivalent to ndarray.mean (self, axis, rtype). Returns the mean of the elements along the given axis, using the enumerated type rtype as the data type to sum in. Default sum behavior is obtained using NPY_NOTYPE for rtype.", "Equivalent to ndarray.trace (self, offset, axis1, axis2, rtype). Return the sum (using rtype as the data type of summation) over the offset diagonal elements of the 2-d arrays defined by axis1 and axis2 variables. A positive offset chooses diagonals above the main diagonal. A negative offset selects diagonals below the main diagonal.", "Equivalent to ndarray.clip (self, min, max). Clip an array, self, so that values larger than max are fixed to max and values less than min are fixed to min.", "Equivalent to ndarray.conjugate (self). Return the complex conjugate of self. If self is not of complex data type, then return self with a reference.", "Equivalent to ndarray.round (self, decimals, out). Returns the array with elements rounded to the nearest decimal place. The decimal place is defined as the \\(10^{-\\textrm{decimals}}\\) digit so that negative decimals cause rounding to the nearest 10\u2019s, 100\u2019s, etc. If out is NULL, then the output array is created, otherwise the output is placed in out which must be the correct size and type.", "Equivalent to ndarray.std (self, axis, rtype). Return the standard deviation using data along axis converted to data type rtype.", "Equivalent to ndarray.sum (self, axis, rtype). Return 1-d vector sums of elements in self along axis. Perform the sum after converting data to data type rtype.", "Equivalent to ndarray.cumsum (self, axis, rtype). Return cumulative 1-d sums of elements in self along axis. Perform the sum after converting data to data type rtype.", "Equivalent to ndarray.prod (self, axis, rtype). Return 1-d products of elements in self along axis. Perform the product after converting data to data type rtype.", "Equivalent to ndarray.cumprod (self, axis, rtype). Return 1-d cumulative products of elements in self along axis. Perform the product after converting data to data type rtype.", "Equivalent to ndarray.all (self, axis). Return an array with True elements for every 1-d sub-array of self defined by axis in which all the elements are True.", "Equivalent to ndarray.any (self, axis). Return an array with True elements for every 1-d sub-array of self defined by axis in which any of the elements are True.", "Sometimes it is useful to access a multidimensional array as a C-style multi-dimensional array so that algorithms can be implemented using C\u2019s a[i][j][k] syntax. This routine returns a pointer, ptr, that simulates this kind of C-style array, for 1-, 2-, and 3-d ndarrays.", "Note", "The simulation of a C-style array is not complete for 2-d and 3-d arrays. For example, the simulated arrays of pointers cannot be passed to subroutines expecting specific, statically-defined 2-d and 3-d arrays. To pass to functions requiring those kind of inputs, you must statically define the required array and copy data.", "Must be called with the same objects and memory locations returned from PyArray_AsCArray (\u2026). This function cleans up memory that otherwise would get leaked.", "Join the sequence of objects in obj together along axis into a single array. If the dimensions or types are not compatible an error is raised.", "Compute a product-sum over the last dimensions of obj1 and obj2. Neither array is conjugated.", "Compute a product-sum over the last dimension of obj1 and the second-to-last dimension of obj2. For 2-d arrays this is a matrix-product. Neither array is conjugated.", "New in version 1.6.", "Same as PyArray_MatrixProduct, but store the result in out. The output array must have the correct shape, type, and be C-contiguous, or an exception is raised.", "New in version 1.6.", "Applies the Einstein summation convention to the array operands provided, returning a new array or placing the result in out. The string in subscripts is a comma separated list of index letters. The number of operands is in nop, and op_in is an array containing those operands. The data type of the output can be forced with dtype, the output order can be forced with order (NPY_KEEPORDER is recommended), and when dtype is specified, casting indicates how permissive the data conversion should be.", "See the einsum function for more details.", "A specialized copy and transpose function that works only for 2-d arrays. The returned array is a transposed copy of op.", "Compute the 1-d correlation of the 1-d arrays op1 and op2 . The correlation is computed at each output point by multiplying op1 by a shifted version of op2 and summing the result. As a result of the shift, needed values outside of the defined range of op1 and op2 are interpreted as zero. The mode determines how many shifts to return: 0 - return only shifts that did not need to assume zero- values; 1 - return an object that is the same size as op1, 2 - return all possible shifts (any overlap at all is accepted).", "This does not compute the usual correlation: if op2 is larger than op1, the arguments are swapped, and the conjugate is never taken for complex arrays. See PyArray_Correlate2 for the usual signal processing correlation.", "Updated version of PyArray_Correlate, which uses the usual definition of correlation for 1d arrays. The correlation is computed at each output point by multiplying op1 by a shifted version of op2 and summing the result. As a result of the shift, needed values outside of the defined range of op1 and op2 are interpreted as zero. The mode determines how many shifts to return: 0 - return only shifts that did not need to assume zero- values; 1 - return an object that is the same size as op1, 2 - return all possible shifts (any overlap at all is accepted).", "Compute z as follows:", "If both x and y are NULL, then return PyArray_Nonzero (condition). Otherwise, both x and y must be given and the object returned is shaped like condition and has elements of x and y where condition is respectively True or False.", "Determine if newstrides is a strides array consistent with the memory of an nd -dimensional array with shape dims and element-size, elsize. The newstrides array is checked to see if jumping by the provided number of bytes in each direction will ever mean jumping more than numbytes which is the assumed size of the available memory segment. If numbytes is 0, then an equivalent numbytes is computed assuming nd, dims, and elsize refer to a single-segment array. Return NPY_TRUE if newstrides is acceptable, otherwise return NPY_FALSE.", "Both of these routines multiply an n -length array, seq, of integers and return the result. No overflow checking is performed.", "Given two n -length arrays of integers, l1, and l2, return 1 if the lists are identical; otherwise, return 0.", "New in version 1.7.0.", "When working with more complex dtypes which are composed of other dtypes, such as the struct dtype, creating inner loops that manipulate the dtypes requires carrying along additional data. NumPy supports this idea through a struct NpyAuxData, mandating a few conventions so that it is possible to do this.", "Defining an NpyAuxData is similar to defining a class in C++, but the object semantics have to be tracked manually since the API is in C. Here\u2019s an example for a function which doubles up an element using an element copier function as a primitive.", "The function pointer type for NpyAuxData free functions.", "The function pointer type for NpyAuxData clone functions. These functions should never set the Python exception on error, because they may be called from a multi-threaded context.", "A macro which calls the auxdata\u2019s free function appropriately, does nothing if auxdata is NULL.", "A macro which calls the auxdata\u2019s clone function appropriately, returning a deep copy of the auxiliary data.", "As of NumPy 1.6.0, these array iterators are superseded by the new array iterator, NpyIter.", "An array iterator is a simple way to access the elements of an N-dimensional array quickly and efficiently. Section 2 provides more description and examples of this useful approach to looping over an array.", "Return an array iterator object from the array, arr. This is equivalent to arr. flat. The array iterator object makes it easy to loop over an N-dimensional non-contiguous array in C-style contiguous fashion.", "Return an array iterator that will iterate over all axes but the one provided in *axis. The returned iterator cannot be used with PyArray_ITER_GOTO1D. This iterator could be used to write something similar to what ufuncs do wherein the loop over the largest axis is done by a separate sub-routine. If *axis is negative then *axis will be set to the axis having the smallest stride and that axis will be used.", "Return an array iterator that is broadcast to iterate as an array of the shape provided by dimensions and nd.", "Evaluates true if op is an array iterator (or instance of a subclass of the array iterator type).", "Reset an iterator to the beginning of the array.", "Incremement the index and the dataptr members of the iterator to point to the next element of the array. If the array is not (C-style) contiguous, also increment the N-dimensional coordinates array.", "A pointer to the current element of the array.", "Set the iterator index, dataptr, and coordinates members to the location in the array indicated by the N-dimensional c-array, destination, which must have size at least iterator ->nd_m1+1.", "Set the iterator index and dataptr to the location in the array indicated by the integer index which points to an element in the C-styled flattened array.", "Evaluates TRUE as long as the iterator has not looped through all of the elements, otherwise it evaluates FALSE.", "A simplified interface to broadcasting. This function takes the number of arrays to broadcast and then num extra ( PyObject * ) arguments. These arguments are converted to arrays and iterators are created. PyArray_Broadcast is then called on the resulting multi-iterator object. The resulting, broadcasted mult-iterator object is then returned. A broadcasted operation can then be performed using a single loop and using PyArray_MultiIter_NEXT (..)", "Reset all the iterators to the beginning in a multi-iterator object, multi.", "Advance each iterator in a multi-iterator object, multi, to its next (broadcasted) element.", "Return the data-pointer of the i \\(^{\\textrm{th}}\\) iterator in a multi-iterator object.", "Advance the pointer of only the i \\(^{\\textrm{th}}\\) iterator.", "Advance each iterator in a multi-iterator object, multi, to the given \\(N\\) -dimensional destination where \\(N\\) is the number of dimensions in the broadcasted array.", "Advance each iterator in a multi-iterator object, multi, to the corresponding location of the index into the flattened broadcasted array.", "Evaluates TRUE as long as the multi-iterator has not looped through all of the elements (of the broadcasted result), otherwise it evaluates FALSE.", "This function encapsulates the broadcasting rules. The mit container should already contain iterators for all the arrays that need to be broadcast. On return, these iterators will be adjusted so that iteration over each simultaneously will accomplish the broadcasting. A negative number is returned if an error occurs.", "This function takes a multi-iterator object that has been previously \u201cbroadcasted,\u201d finds the dimension with the smallest \u201csum of strides\u201d in the broadcasted result and adapts all the iterators so as not to iterate over that dimension (by effectively making them of length-1 in that dimension). The corresponding dimension is returned unless mit ->nd is 0, then -1 is returned. This function is useful for constructing ufunc-like routines that broadcast their inputs correctly and then call a strided 1-d version of the routine as the inner-loop. This 1-d version is usually optimized for speed and for this reason the loop should be performed over the axis that won\u2019t require large stride jumps.", "New in version 1.4.0.", "Neighborhood iterators are subclasses of the iterator object, and can be used to iter over a neighborhood of a point. For example, you may want to iterate over every voxel of a 3d image, and for every such voxel, iterate over an hypercube. Neighborhood iterator automatically handle boundaries, thus making this kind of code much easier to write than manual boundaries handling, at the cost of a slight overhead.", "This function creates a new neighborhood iterator from an existing iterator. The neighborhood will be computed relatively to the position currently pointed by iter, the bounds define the shape of the neighborhood iterator, and the mode argument the boundaries handling mode.", "The bounds argument is expected to be a (2 * iter->ao->nd) arrays, such as the range bound[2*i]->bounds[2*i+1] defines the range where to walk for dimension i (both bounds are included in the walked coordinates). The bounds should be ordered for each dimension (bounds[2*i] <= bounds[2*i+1]).", "The mode should be one of:", "Zero padding. Outside bounds values will be 0.", "One padding, Outside bounds values will be 1.", "Constant padding. Outside bounds values will be the same as the first item in fill_value.", "Mirror padding. Outside bounds values will be as if the array items were mirrored. For example, for the array [1, 2, 3, 4], x[-2] will be 2, x[-2] will be 1, x[4] will be 4, x[5] will be 1, etc\u2026", "Circular padding. Outside bounds values will be as if the array was repeated. For example, for the array [1, 2, 3, 4], x[-2] will be 3, x[-2] will be 4, x[4] will be 1, x[5] will be 2, etc\u2026", "If the mode is constant filling (NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING), fill_value should point to an array object which holds the filling value (the first item will be the filling value if the array contains more than one item). For other cases, fill_value may be NULL.", "Reset the iterator position to the first point of the neighborhood. This should be called whenever the iter argument given at PyArray_NeighborhoodIterObject is changed (see example)", "After this call, iter->dataptr points to the next point of the neighborhood. Calling this function after every point of the neighborhood has been visited is undefined.", "Array mapping is the machinery behind advanced indexing.", "Use advanced indexing to iterate an array.", "Swap the axes to or from their inserted form. MapIter always puts the advanced (array) indices first in the iteration. But if they are consecutive, it will insert/transpose them back before returning. This is stored as mit->consec != 0 (the place where they are inserted). For assignments, the opposite happens: the values to be assigned are transposed (getmap=1 instead of getmap=0). getmap=0 and getmap=1 undo the other operation.", "This function needs to update the state of the map iterator and point mit->dataptr to the memory-location of the next object.", "Note that this function never handles an extra operand but provides compatibility for an old (exposed) API.", "Similar to PyArray_MapIterArray but with an additional copy_if_overlap argument. If copy_if_overlap != 0, checks if a has memory overlap with any of the arrays in index and with extra_op, and make copies as appropriate to avoid problems if the input is modified during the iteration. iter->array may contain a copied array (UPDATEIFCOPY/WRITEBACKIFCOPY set).", "This function steals a reference to arr.", "This function checks to see if arr is a 0-dimensional array and, if so, returns the appropriate array scalar. It should be used whenever 0-dimensional arrays could be returned to Python.", "Return an array scalar object of the given dtype by copying from memory pointed to by data. base is expected to be the array object that is the owner of the data. base is required if dtype is a void scalar, or if the NPY_USE_GETITEM flag is set and it is known that the getitem method uses the arr argument without checking if it is NULL. Otherwise base may be NULL.", "If the data is not in native byte order (as indicated by dtype->byteorder) then this function will byteswap the data, because array scalars are always in correct machine-byte order.", "Return an array scalar object of the type and itemsize indicated by the array object arr copied from the memory pointed to by data and swapping if the data in arr is not in machine byte-order.", "Return a 0-dimensional array of type determined by outcode from scalar which should be an array-scalar object. If outcode is NULL, then the type is determined from scalar.", "Return in ctypeptr a pointer to the actual value in an array scalar. There is no error checking so scalar must be an array-scalar object, and ctypeptr must have enough space to hold the correct type. For flexible-sized types, a pointer to the data is copied into the memory of ctypeptr, for all other types, the actual data is copied into the address pointed to by ctypeptr.", "Return the data (cast to the data type indicated by outcode) from the array-scalar, scalar, into the memory pointed to by ctypeptr (which must be large enough to handle the incoming memory).", "Returns a scalar type-object from a type-number, type . Equivalent to PyArray_DescrFromType (type)->typeobj except for reference counting and error-checking. Returns a new reference to the typeobject on success or NULL on failure.", "See the function PyArray_MinScalarType for an alternative mechanism introduced in NumPy 1.6.0.", "Return the kind of scalar represented by typenum and the array in *arr (if arr is not NULL ). The array is assumed to be rank-0 and only used if typenum represents a signed integer. If arr is not NULL and the first element is negative then NPY_INTNEG_SCALAR is returned, otherwise NPY_INTPOS_SCALAR is returned. The possible return values are the enumerated values in NPY_SCALARKIND.", "See the function PyArray_ResultType for details of NumPy type promotion, updated in NumPy 1.6.0.", "Implements the rules for scalar coercion. Scalars are only silently coerced from thistype to neededtype if this function returns nonzero. If scalar is NPY_NOSCALAR, then this function is equivalent to PyArray_CanCastSafely. The rule is that scalars of the same KIND can be coerced into arrays of the same KIND. This rule means that high-precision scalars will never cause low-precision arrays of the same KIND to be upcast.", "Warning", "Data-type objects must be reference counted so be aware of the action on the data-type reference of different C-API calls. The standard rule is that when a data-type object is returned it is a new reference. Functions that take PyArray_Descr* objects and return arrays steal references to the data-type their inputs unless otherwise noted. Therefore, you must own a reference to any data-type object used as input to such a function.", "Evaluates as true if obj is a data-type object ( PyArray_Descr* ).", "Return a new data-type object copied from obj (the fields reference is just updated so that the new object points to the same fields dictionary if any).", "Create a new data-type object from the built-in (or user-registered) data-type indicated by typenum. All builtin types should not have any of their fields changed. This creates a new copy of the PyArray_Descr structure so that you can fill it in as appropriate. This function is especially needed for flexible data-types which need to have a new elsize member in order to be meaningful in array construction.", "Create a new data-type object with the byteorder set according to newendian. All referenced data-type objects (in subdescr and fields members of the data-type object) are also changed (recursively).", "The value of newendian is one of these macros:", "If a byteorder of NPY_IGNORE is encountered it is left alone. If newendian is NPY_SWAP, then all byte-orders are swapped. Other valid newendian values are NPY_NATIVE, NPY_LITTLE, and NPY_BIG which all cause the returned data-typed descriptor (and all it\u2019s referenced data-type descriptors) to have the corresponding byte- order.", "Determine an appropriate data-type object from the object op (which should be a \u201cnested\u201d sequence object) and the minimum data-type descriptor mintype (which can be NULL ). Similar in behavior to array(op).dtype. Don\u2019t confuse this function with PyArray_DescrConverter. This function essentially looks at all the objects in the (nested) sequence and determines the data-type from the elements it finds.", "Return a data-type object from an array-scalar object. No checking is done to be sure that scalar is an array scalar. If no suitable data-type can be determined, then a data-type of NPY_OBJECT is returned by default.", "Returns a data-type object corresponding to typenum. The typenum can be one of the enumerated types, a character code for one of the enumerated types, or a user-defined type. If you want to use a flexible size array, then you need to flexible typenum and set the results elsize parameter to the desired size. The typenum is one of the NPY_TYPES.", "Convert any compatible Python object, obj, to a data-type object in dtype. A large number of Python objects can be converted to data-type objects. See Data type objects (dtype) for a complete description. This version of the converter converts None objects to a NPY_DEFAULT_TYPE data-type object. This function can be used with the \u201cO&\u201d character code in PyArg_ParseTuple processing.", "Convert any compatible Python object, obj, to a data-type object in dtype. This version of the converter converts None objects so that the returned data-type is NULL. This function can also be used with the \u201cO&\u201d character in PyArg_ParseTuple processing.", "Like PyArray_DescrConverter except it aligns C-struct-like objects on word-boundaries as the compiler would.", "Like PyArray_DescrConverter2 except it aligns C-struct-like objects on word-boundaries as the compiler would.", "Take the fields dictionary, dict, such as the one attached to a data-type object and construct an ordered-list of field names such as is stored in the names field of the PyArray_Descr object.", "All of these functions can be used in PyArg_ParseTuple (\u2026) with the \u201cO&\u201d format specifier to automatically convert any Python object to the required C-object. All of these functions return NPY_SUCCEED if successful and NPY_FAIL if not. The first argument to all of these function is a Python object. The second argument is the address of the C-type to convert the Python object to.", "Warning", "Be sure to understand what steps you should take to manage the memory when using these conversion functions. These functions can require freeing memory, and/or altering the reference counts of specific objects based on your use.", "Convert any Python object to a PyArrayObject. If PyArray_Check (obj) is TRUE then its reference count is incremented and a reference placed in address. If obj is not an array, then convert it to an array using PyArray_FromAny . No matter what is returned, you must DECREF the object returned by this routine in address when you are done with it.", "This is a default converter for output arrays given to functions. If obj is Py_None or NULL, then *address will be NULL but the call will succeed. If PyArray_Check ( obj) is TRUE then it is returned in *address without incrementing its reference count.", "Convert any Python sequence, obj, smaller than NPY_MAXDIMS to a C-array of npy_intp. The Python object could also be a single number. The seq variable is a pointer to a structure with members ptr and len. On successful return, seq ->ptr contains a pointer to memory that must be freed, by calling PyDimMem_FREE, to avoid a memory leak. The restriction on memory size allows this converter to be conveniently used for sequences intended to be interpreted as array shapes.", "Convert any Python object, obj, with a (single-segment) buffer interface to a variable with members that detail the object\u2019s use of its chunk of memory. The buf variable is a pointer to a structure with base, ptr, len, and flags members. The PyArray_Chunk structure is binary compatible with the Python\u2019s buffer object (through its len member on 32-bit platforms and its ptr member on 64-bit platforms or in Python 2.5). On return, the base member is set to obj (or its base if obj is already a buffer object pointing to another object). If you need to hold on to the memory be sure to INCREF the base member. The chunk of memory is pointed to by buf ->ptr member and has length buf ->len. The flags member of buf is NPY_ARRAY_ALIGNED with the NPY_ARRAY_WRITEABLE flag set if obj has a writeable buffer interface.", "Convert a Python object, obj, representing an axis argument to the proper value for passing to the functions that take an integer axis. Specifically, if obj is None, axis is set to NPY_MAXDIMS which is interpreted correctly by the C-API functions that take axis arguments.", "Convert any Python object, obj, to NPY_TRUE or NPY_FALSE, and place the result in value.", "Convert Python strings into the corresponding byte-order character: \u2018>\u2019, \u2018<\u2019, \u2018s\u2019, \u2018=\u2019, or \u2018|\u2019.", "Convert Python strings into one of NPY_QUICKSORT (starts with \u2018q\u2019 or \u2018Q\u2019), NPY_HEAPSORT (starts with \u2018h\u2019 or \u2018H\u2019), NPY_MERGESORT (starts with \u2018m\u2019 or \u2018M\u2019) or NPY_STABLESORT (starts with \u2018t\u2019 or \u2018T\u2019). NPY_MERGESORT and NPY_STABLESORT are aliased to each other for backwards compatibility and may refer to one of several stable sorting algorithms depending on the data type.", "Convert Python strings into one of NPY_SEARCHLEFT (starts with \u2018l\u2019 or \u2018L\u2019), or NPY_SEARCHRIGHT (starts with \u2018r\u2019 or \u2018R\u2019).", "Convert the Python strings \u2018C\u2019, \u2018F\u2019, \u2018A\u2019, and \u2018K\u2019 into the NPY_ORDER enumeration NPY_CORDER, NPY_FORTRANORDER, NPY_ANYORDER, and NPY_KEEPORDER.", "Convert the Python strings \u2018no\u2019, \u2018equiv\u2019, \u2018safe\u2019, \u2018same_kind\u2019, and \u2018unsafe\u2019 into the NPY_CASTING enumeration NPY_NO_CASTING, NPY_EQUIV_CASTING, NPY_SAFE_CASTING, NPY_SAME_KIND_CASTING, and NPY_UNSAFE_CASTING.", "Convert the Python strings \u2018clip\u2019, \u2018wrap\u2019, and \u2018raise\u2019 into the NPY_CLIPMODE enumeration NPY_CLIP, NPY_WRAP, and NPY_RAISE.", "Converts either a sequence of clipmodes or a single clipmode into a C array of NPY_CLIPMODE values. The number of clipmodes n must be known before calling this function. This function is provided to help functions allow a different clipmode for each dimension.", "Convert all kinds of Python objects (including arrays and array scalars) to a standard integer. On error, -1 is returned and an exception set. You may find useful the macro:", "Convert all kinds of Python objects (including arrays and array scalars) to a (platform-pointer-sized) integer. On error, -1 is returned and an exception set.", "Convert any Python sequence (or single Python number) passed in as seq to (up to) maxvals pointer-sized integers and place them in the vals array. The sequence can be smaller then maxvals as the number of converted objects is returned.", "Convert typestring characters (with itemsize) to basic enumerated data types. The typestring character corresponding to signed and unsigned integers, floating point numbers, and complex-floating point numbers are recognized and converted. Other values of gentype are returned. This function can be used to convert, for example, the string \u2018f4\u2019 to NPY_FLOAT32.", "In order to make use of the C-API from another extension module, the import_array function must be called. If the extension module is self-contained in a single .c file, then that is all that needs to be done. If, however, the extension module involves multiple files where the C-API is needed then some additional steps must be taken.", "This function must be called in the initialization section of a module that will make use of the C-API. It imports the module where the function-pointer table is stored and points the correct variable to it.", "Using these #defines you can use the C-API in multiple files for a single extension module. In each file you must define PY_ARRAY_UNIQUE_SYMBOL to some name that will hold the C-API (e.g. myextension_ARRAY_API). This must be done before including the numpy/arrayobject.h file. In the module initialization routine you call import_array. In addition, in the files that do not have the module initialization sub_routine define NO_IMPORT_ARRAY prior to including numpy/arrayobject.h.", "Suppose I have two files coolmodule.c and coolhelper.c which need to be compiled and linked into a single extension module. Suppose coolmodule.c contains the required initcool module initialization function (with the import_array() function called). Then, coolmodule.c would have at the top:", "On the other hand, coolhelper.c would contain at the top:", "You can also put the common two last lines into an extension-local header file as long as you make sure that NO_IMPORT_ARRAY is #defined before #including that file.", "Internally, these #defines work as follows:", "Because python extensions are not used in the same way as usual libraries on most platforms, some errors cannot be automatically detected at build time or even runtime. For example, if you build an extension using a function available only for numpy >= 1.3.0, and you import the extension later with numpy 1.2, you will not get an import error (but almost certainly a segmentation fault when calling the function). That\u2019s why several functions are provided to check for numpy versions. The macros NPY_VERSION and NPY_FEATURE_VERSION corresponds to the numpy version used to build the extension, whereas the versions returned by the functions PyArray_GetNDArrayCVersion and PyArray_GetNDArrayCFeatureVersion corresponds to the runtime numpy\u2019s version.", "The rules for ABI and API compatibilities can be summarized as follows:", "ABI incompatibility is automatically detected in every numpy\u2019s version. API incompatibility detection was added in numpy 1.4.0. If you want to supported many different numpy versions with one extension binary, you have to build your extension with the lowest NPY_FEATURE_VERSION as possible.", "The current version of the ndarray object (check to see if this variable is defined to guarantee the numpy/arrayobject.h header is being used).", "The current version of the C-API.", "This just returns the value NPY_VERSION. NPY_VERSION changes whenever a backward incompatible change at the ABI level. Because it is in the C-API, however, comparing the output of this function from the value defined in the current header gives a way to test if the C-API has changed thus requiring a re-compilation of extension modules that use the C-API. This is automatically checked in the function import_array.", "New in version 1.4.0.", "This just returns the value NPY_FEATURE_VERSION. NPY_FEATURE_VERSION changes whenever the API changes (e.g. a function is added). A changed value does not always require a recompile.", "NumPy stores an internal table of Python callable objects that are used to implement arithmetic operations for arrays as well as certain array calculation methods. This function allows the user to replace any or all of these Python objects with their own versions. The keys of the dictionary, dict, are the named functions to replace and the paired value is the Python callable object to use. Care should be taken that the function used to replace an internal array operation does not itself call back to that internal array operation (unless you have designed the function to handle that), or an unchecked infinite recursion can result (possibly causing program crash). The key names that represent operations that can be replaced are:", "add, subtract, multiply, divide, remainder, power, square, reciprocal, ones_like, sqrt, negative, positive, absolute, invert, left_shift, right_shift, bitwise_and, bitwise_xor, bitwise_or, less, less_equal, equal, not_equal, greater, greater_equal, floor_divide, true_divide, logical_or, logical_and, floor, ceil, maximum, minimum, rint.", "These functions are included here because they are used at least once in the array object\u2019s methods. The function returns -1 (without setting a Python Error) if one of the objects being assigned is not callable.", "Deprecated since version 1.16.", "Return a Python dictionary containing the callable Python objects stored in the internal arithmetic operation table. The keys of this dictionary are given in the explanation for PyArray_SetNumericOps.", "Deprecated since version 1.16.", "This function allows you to alter the tp_str and tp_repr methods of the array object to any Python function. Thus you can alter what happens for all arrays when str(arr) or repr(arr) is called from Python. The function to be called is passed in as op. If repr is non-zero, then this function will be called in response to repr(arr), otherwise the function will be called in response to str(arr). No check on whether or not op is callable is performed. The callable passed in to op should expect an array argument and should return a string to be printed.", "Macros to allocate, free, and reallocate memory. These macros are used internally to create arrays.", "Macros to allocate, free, and reallocate dimension and strides memory.", "These macros use different memory allocators, depending on the constant NPY_USE_PYMEM. The system malloc is used when NPY_USE_PYMEM is 0, if NPY_USE_PYMEM is 1, then the Python memory allocator is used.", "If obj.flags has NPY_ARRAY_WRITEBACKIFCOPY or (deprecated) NPY_ARRAY_UPDATEIFCOPY, this function clears the flags, DECREF s obj->base and makes it writeable, and sets obj->base to NULL. It then copies obj->data to obj->base->data, and returns the error state of the copy operation. This is the opposite of PyArray_SetWritebackIfCopyBase. Usually this is called once you are finished with obj, just before Py_DECREF(obj). It may be called multiple times, or with NULL input. See also PyArray_DiscardWritebackIfCopy.", "Returns 0 if nothing was done, -1 on error, and 1 if action was taken.", "These macros are only meaningful if NPY_ALLOW_THREADS evaluates True during compilation of the extension module. Otherwise, these macros are equivalent to whitespace. Python uses a single Global Interpreter Lock (GIL) for each Python process so that only a single thread may execute at a time (even on multi-cpu machines). When calling out to a compiled function that may take time to compute (and does not have side-effects for other threads like updated global variables), the GIL should be released so that other Python threads can run while the time-consuming calculations are performed. This can be accomplished using two groups of macros. Typically, if one macro in a group is used in a code block, all of them must be used in the same code block. Currently, NPY_ALLOW_THREADS is defined to the python-defined WITH_THREADS constant unless the environment variable NPY_NOSMP is set in which case NPY_ALLOW_THREADS is defined to be 0.", "This group is used to call code that may take some time but does not use any Python C-API calls. Thus, the GIL should be released during its calculation.", "Equivalent to Py_BEGIN_ALLOW_THREADS except it uses NPY_ALLOW_THREADS to determine if the macro if replaced with white-space or not.", "Equivalent to Py_END_ALLOW_THREADS except it uses NPY_ALLOW_THREADS to determine if the macro if replaced with white-space or not.", "Place in the variable declaration area. This macro sets up the variable needed for storing the Python state.", "Place right before code that does not need the Python interpreter (no Python C-API calls). This macro saves the Python state and releases the GIL.", "Place right after code that does not need the Python interpreter. This macro acquires the GIL and restores the Python state from the saved variable.", "Useful to release the GIL only if dtype does not contain arbitrary Python objects which may need the Python interpreter during execution of the loop.", "Useful to regain the GIL in situations where it was released using the BEGIN form of this macro.", "Useful to release the GIL only if loop_size exceeds a minimum threshold, currently set to 500. Should be matched with a NPY_END_THREADS to regain the GIL.", "This group is used to re-acquire the Python GIL after it has been released. For example, suppose the GIL has been released (using the previous calls), and then some path in the code (perhaps in a different subroutine) requires use of the Python C-API, then these macros are useful to acquire the GIL. These macros accomplish essentially a reverse of the previous three (acquire the LOCK saving what state it had) and then re-release it with the saved state.", "Place in the variable declaration area to set up the necessary variable.", "Place before code that needs to call the Python C-API (when it is known that the GIL has already been released).", "Place after code that needs to call the Python C-API (to re-release the GIL).", "Tip", "Never use semicolons after the threading support macros.", "Default priority for arrays.", "Default subtype priority.", "Default scalar priority (very small)", "Return the __array_priority__ attribute (converted to a double) of obj or def if no attribute of that name exists. Fast returns that avoid the attribute lookup are provided for objects of type PyArray_Type.", "Default size of the user-settable internal buffers.", "Smallest size of user-settable internal buffers.", "Largest size allowed for the user-settable buffers.", "The number of floating-point types", "The maximum number of dimensions allowed in arrays.", "The maximum number of array arguments that can be used in functions.", "Defined as 0 for use with Bool.", "Defined as 1 for use with Bool.", "The return value of failed converter functions which are called using the \u201cO&\u201d syntax in PyArg_ParseTuple-like functions.", "The return value of successful converter functions which are called using the \u201cO&\u201d syntax in PyArg_ParseTuple-like functions.", "Evaluates as True if arrays a1 and a2 have the same shape.", "Returns the maximum of a and b. If (a) or (b) are expressions they are evaluated twice.", "Returns the minimum of a and b. If (a) or (b) are expressions they are evaluated twice.", "Implements the complex comparisons between two complex numbers (structures with a real and imag member) using NumPy\u2019s definition of the ordering which is lexicographic: comparing the real parts first and then the complex parts if the real parts are equal.", "Returns the reference count of any Python object.", "If obj.flags has NPY_ARRAY_WRITEBACKIFCOPY or (deprecated) NPY_ARRAY_UPDATEIFCOPY, this function clears the flags, DECREF s obj->base and makes it writeable, and sets obj->base to NULL. In contrast to PyArray_DiscardWritebackIfCopy it makes no attempt to copy the data from obj->base This undoes PyArray_SetWritebackIfCopyBase. Usually this is called after an error when you are finished with obj, just before Py_DECREF(obj). It may be called multiple times, or with NULL input.", "Deprecated in 1.14, use PyArray_DiscardWritebackIfCopy followed by Py_XDECREF", "DECREF\u2019s an array object which may have the (deprecated) NPY_ARRAY_UPDATEIFCOPY or NPY_ARRAY_WRITEBACKIFCOPY flag set without causing the contents to be copied back into the original array. Resets the NPY_ARRAY_WRITEABLE flag on the base object. This is useful for recovering from an error condition when writeback semantics are used, but will lead to wrong results.", "A special variable-type which can take on different values to indicate the sorting algorithm being used.", "Used as an alias of NPY_MERGESORT and vica versa.", "Defined to be the number of sorts. It is fixed at three by the need for backwards compatibility, and consequently NPY_MERGESORT and NPY_STABLESORT are aliased to each other and may refer to one of several stable sorting algorithms depending on the data type.", "A special variable type indicating the number of \u201ckinds\u201d of scalars distinguished in determining scalar-coercion rules. This variable can take on the values:", "Defined to be the number of scalar kinds (not including NPY_NOSCALAR).", "An enumeration type indicating the element order that an array should be interpreted in. When a brand new array is created, generally only NPY_CORDER and NPY_FORTRANORDER are used, whereas when one or more inputs are provided, the order can be based on them.", "Fortran order if all the inputs are Fortran, C otherwise.", "C order.", "Fortran order.", "An order as close to the order of the inputs as possible, even if the input is in neither C nor Fortran order.", "A variable type indicating the kind of clipping that should be applied in certain functions.", "The default for most operations, raises an exception if an index is out of bounds.", "Clips an index to the valid range if it is out of bounds.", "Wraps an index to the valid range if it is out of bounds.", "A variable type indicating whether the index returned should be that of the first suitable location (if NPY_SEARCHLEFT) or of the last (if NPY_SEARCHRIGHT).", "A variable type indicating the selection algorithm being used.", "New in version 1.6.", "An enumeration type indicating how permissive data conversions should be. This is used by the iterator added in NumPy 1.6, and is intended to be used more broadly in a future version.", "Only allow identical types.", "Allow identical and casts involving byte swapping.", "Only allow casts which will not cause values to be rounded, truncated, or otherwise changed.", "Allow any safe casts, and casts between types of the same kind. For example, float64 -> float32 is permitted with this rule.", "Allow any cast, no matter what kind of data loss may occur."]}, {"name": "int PyArray_ObjectType()", "path": "reference/c-api/array#c.PyArray_ObjectType", "type": "Array API", "text": ["This function is superseded by PyArray_MinScalarType and/or PyArray_ResultType.", "This function is useful for determining a common type that two or more arrays can be converted to. It only works for non-flexible array types as no itemsize information is passed. The mintype argument represents the minimum type acceptable, and op represents the object that will be converted to an array. The return value is the enumerated typenumber that represents the data-type that op should have."]}, {"name": "int PyArray_OrderConverter()", "path": "reference/c-api/array#c.PyArray_OrderConverter", "type": "Array API", "text": ["Convert the Python strings \u2018C\u2019, \u2018F\u2019, \u2018A\u2019, and \u2018K\u2019 into the NPY_ORDER enumeration NPY_CORDER, NPY_FORTRANORDER, NPY_ANYORDER, and NPY_KEEPORDER."]}, {"name": "int PyArray_OutputConverter()", "path": "reference/c-api/array#c.PyArray_OutputConverter", "type": "Array API", "text": ["This is a default converter for output arrays given to functions. If obj is Py_None or NULL, then *address will be NULL but the call will succeed. If PyArray_Check ( obj) is TRUE then it is returned in *address without incrementing its reference count."]}, {"name": "int PyArray_Partition()", "path": "reference/c-api/array#c.PyArray_Partition", "type": "Array API", "text": ["Equivalent to ndarray.partition (self, ktharray, axis, kind). Partitions the array so that the values of the element indexed by ktharray are in the positions they would be if the array is fully sorted and places all elements smaller than the kth before and all elements equal or greater after the kth element. The ordering of all elements within the partitions is undefined. If self->descr is a data-type with fields defined, then self->descr->names is used to determine the sort order. A comparison where the first field is equal will use the second field and so on. To alter the sort order of a structured array, create a new data-type with a different order of names and construct a view of the array with that new data-type. Returns zero on success and -1 on failure."]}, {"name": "int PyArray_RegisterCanCast()", "path": "reference/c-api/array#c.PyArray_RegisterCanCast", "type": "Array API", "text": ["Register the data-type number, totype, as castable from data-type object, descr, of the given scalar kind. Use scalar = NPY_NOSCALAR to register that an array of data-type descr can be cast safely to a data-type whose type_number is totype. The return value is 0 on success or -1 on failure."]}, {"name": "int PyArray_RegisterCastFunc()", "path": "reference/c-api/array#c.PyArray_RegisterCastFunc", "type": "Array API", "text": ["Register a low-level casting function, castfunc, to convert from the data-type, descr, to the given data-type number, totype. Any old casting function is over-written. A 0 is returned on success or a -1 on failure."]}, {"name": "int PyArray_RegisterDataType()", "path": "reference/c-api/array#c.PyArray_RegisterDataType", "type": "Array API", "text": ["Register a data-type as a new user-defined data type for arrays. The type must have most of its entries filled in. This is not always checked and errors can produce segfaults. In particular, the typeobj member of the dtype structure must be filled with a Python type that has a fixed-size element-size that corresponds to the elsize member of dtype. Also the f member must have the required functions: nonzero, copyswap, copyswapn, getitem, setitem, and cast (some of the cast functions may be NULL if no support is desired). To avoid confusion, you should choose a unique character typecode but this is not enforced and not relied on internally.", "A user-defined type number is returned that uniquely identifies the type. A pointer to the new structure can then be obtained from PyArray_DescrFromType using the returned type number. A -1 is returned if an error occurs. If this dtype has already been registered (checked only by the address of the pointer), then return the previously-assigned type-number."]}, {"name": "int PyArray_RemoveSmallest()", "path": "reference/c-api/array#c.PyArray_RemoveSmallest", "type": "Array API", "text": ["This function takes a multi-iterator object that has been previously \u201cbroadcasted,\u201d finds the dimension with the smallest \u201csum of strides\u201d in the broadcasted result and adapts all the iterators so as not to iterate over that dimension (by effectively making them of length-1 in that dimension). The corresponding dimension is returned unless mit ->nd is 0, then -1 is returned. This function is useful for constructing ufunc-like routines that broadcast their inputs correctly and then call a strided 1-d version of the routine as the inner-loop. This 1-d version is usually optimized for speed and for this reason the loop should be performed over the axis that won\u2019t require large stride jumps."]}, {"name": "int PyArray_ResolveWritebackIfCopy()", "path": "reference/c-api/array#c.PyArray_ResolveWritebackIfCopy", "type": "Array API", "text": ["If obj.flags has NPY_ARRAY_WRITEBACKIFCOPY or (deprecated) NPY_ARRAY_UPDATEIFCOPY, this function clears the flags, DECREF s obj->base and makes it writeable, and sets obj->base to NULL. It then copies obj->data to obj->base->data, and returns the error state of the copy operation. This is the opposite of PyArray_SetWritebackIfCopyBase. Usually this is called once you are finished with obj, just before Py_DECREF(obj). It may be called multiple times, or with NULL input. See also PyArray_DiscardWritebackIfCopy.", "Returns 0 if nothing was done, -1 on error, and 1 if action was taken."]}, {"name": "int PyArray_SearchsideConverter()", "path": "reference/c-api/array#c.PyArray_SearchsideConverter", "type": "Array API", "text": ["Convert Python strings into one of NPY_SEARCHLEFT (starts with \u2018l\u2019 or \u2018L\u2019), or NPY_SEARCHRIGHT (starts with \u2018r\u2019 or \u2018R\u2019)."]}, {"name": "int PyArray_SetBaseObject()", "path": "reference/c-api/array#c.PyArray_SetBaseObject", "type": "Array API", "text": ["New in version 1.7.", "This function steals a reference to obj and sets it as the base property of arr.", "If you construct an array by passing in your own memory buffer as a parameter, you need to set the array\u2019s base property to ensure the lifetime of the memory buffer is appropriate.", "The return value is 0 on success, -1 on failure.", "If the object provided is an array, this function traverses the chain of base pointers so that each array points to the owner of the memory directly. Once the base is set, it may not be changed to another value."]}, {"name": "int PyArray_SetField()", "path": "reference/c-api/array#c.PyArray_SetField", "type": "Array API", "text": ["Equivalent to ndarray.setfield (self, val, dtype, offset ). Set the field starting at offset in bytes and of the given dtype to val. The offset plus dtype ->elsize must be less than self ->descr->elsize or an error is raised. Otherwise, the val argument is converted to an array and copied into the field pointed to. If necessary, the elements of val are repeated to fill the destination array, But, the number of elements in the destination must be an integer multiple of the number of elements in val."]}, {"name": "int PyArray_SETITEM()", "path": "reference/c-api/array#c.PyArray_SETITEM", "type": "Array API", "text": ["Convert obj and place it in the ndarray, arr, at the place pointed to by itemptr. Return -1 if an error occurs or 0 on success."]}, {"name": "int PyArray_SetUpdateIfCopyBase()", "path": "reference/c-api/array#c.PyArray_SetUpdateIfCopyBase", "type": "Array API", "text": ["Precondition: arr is a copy of base (though possibly with different strides, ordering, etc.) Set the UPDATEIFCOPY flag and arr->base so that when arr is destructed, it will copy any changes back to base. DEPRECATED, use PyArray_SetWritebackIfCopyBase.", "Returns 0 for success, -1 for failure."]}, {"name": "int PyArray_SetWritebackIfCopyBase()", "path": "reference/c-api/array#c.PyArray_SetWritebackIfCopyBase", "type": "Array API", "text": ["Precondition: arr is a copy of base (though possibly with different strides, ordering, etc.) Sets the NPY_ARRAY_WRITEBACKIFCOPY flag and arr->base, and set base to READONLY. Call PyArray_ResolveWritebackIfCopy before calling Py_DECREF in order copy any changes back to base and reset the READONLY flag.", "Returns 0 for success, -1 for failure."]}, {"name": "int PyArray_SortkindConverter()", "path": "reference/c-api/array#c.PyArray_SortkindConverter", "type": "Array API", "text": ["Convert Python strings into one of NPY_QUICKSORT (starts with \u2018q\u2019 or \u2018Q\u2019), NPY_HEAPSORT (starts with \u2018h\u2019 or \u2018H\u2019), NPY_MERGESORT (starts with \u2018m\u2019 or \u2018M\u2019) or NPY_STABLESORT (starts with \u2018t\u2019 or \u2018T\u2019). NPY_MERGESORT and NPY_STABLESORT are aliased to each other for backwards compatibility and may refer to one of several stable sorting algorithms depending on the data type."]}, {"name": "int PyArray_TYPE()", "path": "reference/c-api/array#c.PyArray_TYPE", "type": "Array API", "text": ["Return the (builtin) typenumber for the elements of this array."]}, {"name": "int PyArray_TypeNumFromName()", "path": "reference/c-api/array#c.PyArray_TypeNumFromName", "type": "Array API", "text": ["Given a string return the type-number for the data-type with that string as the type-object name. Returns NPY_NOTYPE without setting an error if no type can be found. Only works for user-defined data-types."]}, {"name": "int PyArray_TypestrConvert()", "path": "reference/c-api/array#c.PyArray_TypestrConvert", "type": "Array API", "text": ["Convert typestring characters (with itemsize) to basic enumerated data types. The typestring character corresponding to signed and unsigned integers, floating point numbers, and complex-floating point numbers are recognized and converted. Other values of gentype are returned. This function can be used to convert, for example, the string \u2018f4\u2019 to NPY_FLOAT32."]}, {"name": "int PyArray_ValidType()", "path": "reference/c-api/array#c.PyArray_ValidType", "type": "Array API", "text": ["Returns NPY_TRUE if typenum represents a valid type-number (builtin or user-defined or character code). Otherwise, this function returns NPY_FALSE."]}, {"name": "int PyArray_XDECREF()", "path": "reference/c-api/array#c.PyArray_XDECREF", "type": "Array API", "text": ["Used for an array, op, that contains any Python objects. It decrements the reference count of every object in the array according to the data-type of op. Normal return value is 0. A -1 is returned if an error occurs."]}, {"name": "int PyArrayIter_Check()", "path": "reference/c-api/array#c.PyArrayIter_Check", "type": "Array API", "text": ["Evaluates true if op is an array iterator (or instance of a subclass of the array iterator type)."]}, {"name": "int PyArrayNeighborhoodIter_Next()", "path": "reference/c-api/array#c.PyArrayNeighborhoodIter_Next", "type": "Array API", "text": ["After this call, iter->dataptr points to the next point of the neighborhood. Calling this function after every point of the neighborhood has been visited is undefined."]}, {"name": "int PyArrayNeighborhoodIter_Reset()", "path": "reference/c-api/array#c.PyArrayNeighborhoodIter_Reset", "type": "Array API", "text": ["Reset the iterator position to the first point of the neighborhood. This should be called whenever the iter argument given at PyArray_NeighborhoodIterObject is changed (see example)"]}, {"name": "int PyDataType_FLAGCHK()", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.PyDataType_FLAGCHK", "type": "Python Types and C-Structures", "text": ["Return true if all the given flags are set for the data-type object."]}, {"name": "int PyDataType_HASFIELDS()", "path": "reference/c-api/array#c.PyDataType_HASFIELDS", "type": "Array API", "text": []}, {"name": "int PyDataType_ISBOOL()", "path": "reference/c-api/array#c.PyDataType_ISBOOL", "type": "Array API", "text": []}, {"name": "int PyDataType_ISCOMPLEX()", "path": "reference/c-api/array#c.PyDataType_ISCOMPLEX", "type": "Array API", "text": []}, {"name": "int PyDataType_ISEXTENDED()", "path": "reference/c-api/array#c.PyDataType_ISEXTENDED", "type": "Array API", "text": []}, {"name": "int PyDataType_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyDataType_ISFLEXIBLE", "type": "Array API", "text": []}, {"name": "int PyDataType_ISFLOAT()", "path": "reference/c-api/array#c.PyDataType_ISFLOAT", "type": "Array API", "text": []}, {"name": "int PyDataType_ISINTEGER()", "path": "reference/c-api/array#c.PyDataType_ISINTEGER", "type": "Array API", "text": []}, {"name": "int PyDataType_ISNUMBER()", "path": "reference/c-api/array#c.PyDataType_ISNUMBER", "type": "Array API", "text": []}, {"name": "int PyDataType_ISOBJECT()", "path": "reference/c-api/array#c.PyDataType_ISOBJECT", "type": "Array API", "text": []}, {"name": "int PyDataType_ISPYTHON()", "path": "reference/c-api/array#c.PyDataType_ISPYTHON", "type": "Array API", "text": []}, {"name": "int PyDataType_ISSIGNED()", "path": "reference/c-api/array#c.PyDataType_ISSIGNED", "type": "Array API", "text": []}, {"name": "int PyDataType_ISSTRING()", "path": "reference/c-api/array#c.PyDataType_ISSTRING", "type": "Array API", "text": []}, {"name": "int PyDataType_ISUNSIGNED()", "path": "reference/c-api/array#c.PyDataType_ISUNSIGNED", "type": "Array API", "text": []}, {"name": "int PyDataType_ISUNSIZED()", "path": "reference/c-api/array#c.PyDataType_ISUNSIZED", "type": "Array API", "text": ["Type has no size information attached, and can be resized. Should only be called on flexible dtypes. Types that are attached to an array will always be sized, hence the array form of this macro not existing.", "Changed in version 1.18.", "For structured datatypes with no fields this function now returns False."]}, {"name": "int PyDataType_ISUSERDEF()", "path": "reference/c-api/array#c.PyDataType_ISUSERDEF", "type": "Array API", "text": []}, {"name": "int PyDataType_REFCHK()", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.PyDataType_REFCHK", "type": "Python Types and C-Structures", "text": ["Equivalent to PyDataType_FLAGCHK (dtype, NPY_ITEM_REFCOUNT)."]}, {"name": "int PyModule_AddIntConstant()", "path": "user/c-info.how-to-extend#c.PyModule_AddIntConstant", "type": "User Guide", "text": []}, {"name": "int PyModule_AddObject()", "path": "user/c-info.how-to-extend", "type": "User Guide", "text": ["While the ndarray object is designed to allow rapid computation in Python, it is also designed to be general-purpose and satisfy a wide- variety of computational needs. As a result, if absolute speed is essential, there is no replacement for a well-crafted, compiled loop specific to your application and hardware. This is one of the reasons that numpy includes f2py so that an easy-to-use mechanisms for linking (simple) C/C++ and (arbitrary) Fortran code directly into Python are available. You are encouraged to use and improve this mechanism. The purpose of this section is not to document this tool but to document the more basic steps to writing an extension module that this tool depends on.", "When an extension module is written, compiled, and installed to somewhere in the Python path (sys.path), the code can then be imported into Python as if it were a standard python file. It will contain objects and methods that have been defined and compiled in C code. The basic steps for doing this in Python are well-documented and you can find more information in the documentation for Python itself available online at www.python.org .", "In addition to the Python C-API, there is a full and rich C-API for NumPy allowing sophisticated manipulations on a C-level. However, for most applications, only a few API calls will typically be used. For example, if you need to just extract a pointer to memory along with some shape information to pass to another calculation routine, then you will use very different calls than if you are trying to create a new array-like type or add a new data type for ndarrays. This chapter documents the API calls and macros that are most commonly used.", "There is exactly one function that must be defined in your C-code in order for Python to use it as an extension module. The function must be called init{name} where {name} is the name of the module from Python. This function must be declared so that it is visible to code outside of the routine. Besides adding the methods and constants you desire, this subroutine must also contain calls like import_array() and/or import_ufunc() depending on which C-API is needed. Forgetting to place these commands will show itself as an ugly segmentation fault (crash) as soon as any C-API subroutine is actually called. It is actually possible to have multiple init{name} functions in a single file in which case multiple modules will be defined by that file. However, there are some tricks to get that to work correctly and it is not covered here.", "A minimal init{name} method looks like:", "The mymethods must be an array (usually statically declared) of PyMethodDef structures which contain method names, actual C-functions, a variable indicating whether the method uses keyword arguments or not, and docstrings. These are explained in the next section. If you want to add constants to the module, then you store the returned value from Py_InitModule which is a module object. The most general way to add items to the module is to get the module dictionary using PyModule_GetDict(module). With the module dictionary, you can add whatever you like to the module manually. An easier way to add objects to the module is to use one of three additional Python C-API calls that do not require a separate extraction of the module dictionary. These are documented in the Python documentation, but repeated here for convenience:", "All three of these functions require the module object (the return value of Py_InitModule). The name is a string that labels the value in the module. Depending on which function is called, the value argument is either a general object (PyModule_AddObject steals a reference to it), an integer constant, or a string constant.", "The second argument passed in to the Py_InitModule function is a structure that makes it easy to to define functions in the module. In the example given above, the mymethods structure would have been defined earlier in the file (usually right before the init{name} subroutine) to:", "Each entry in the mymethods array is a PyMethodDef structure containing 1) the Python name, 2) the C-function that implements the function, 3) flags indicating whether or not keywords are accepted for this function, and 4) The docstring for the function. Any number of functions may be defined for a single module by adding more entries to this table. The last entry must be all NULL as shown to act as a sentinel. Python looks for this entry to know that all of the functions for the module have been defined.", "The last thing that must be done to finish the extension module is to actually write the code that performs the desired functions. There are two kinds of functions: those that don\u2019t accept keyword arguments, and those that do.", "Functions that don\u2019t accept keyword arguments should be written as:", "The dummy argument is not used in this context and can be safely ignored. The args argument contains all of the arguments passed in to the function as a tuple. You can do anything you want at this point, but usually the easiest way to manage the input arguments is to call PyArg_ParseTuple (args, format_string, addresses_to_C_variables\u2026) or PyArg_UnpackTuple (tuple, \u201cname\u201d, min, max, \u2026). A good description of how to use the first function is contained in the Python C-API reference manual under section 5.5 (Parsing arguments and building values). You should pay particular attention to the \u201cO&\u201d format which uses converter functions to go between the Python object and the C object. All of the other format functions can be (mostly) thought of as special cases of this general rule. There are several converter functions defined in the NumPy C-API that may be of use. In particular, the PyArray_DescrConverter function is very useful to support arbitrary data-type specification. This function transforms any valid data-type Python object into a PyArray_Descr* object. Remember to pass in the address of the C-variables that should be filled in.", "There are lots of examples of how to use PyArg_ParseTuple throughout the NumPy source code. The standard usage is like this:", "It is important to keep in mind that you get a borrowed reference to the object when using the \u201cO\u201d format string. However, the converter functions usually require some form of memory handling. In this example, if the conversion is successful, dtype will hold a new reference to a PyArray_Descr* object, while input will hold a borrowed reference. Therefore, if this conversion were mixed with another conversion (say to an integer) and the data-type conversion was successful but the integer conversion failed, then you would need to release the reference count to the data-type object before returning. A typical way to do this is to set dtype to NULL before calling PyArg_ParseTuple and then use Py_XDECREF on dtype before returning.", "After the input arguments are processed, the code that actually does the work is written (likely calling other functions as needed). The final step of the C-function is to return something. If an error is encountered then NULL should be returned (making sure an error has actually been set). If nothing should be returned then increment Py_None and return it. If a single object should be returned then it is returned (ensuring that you own a reference to it first). If multiple objects should be returned then you need to return a tuple. The Py_BuildValue (format_string, c_variables\u2026) function makes it easy to build tuples of Python objects from C variables. Pay special attention to the difference between \u2018N\u2019 and \u2018O\u2019 in the format string or you can easily create memory leaks. The \u2018O\u2019 format string increments the reference count of the PyObject* C-variable it corresponds to, while the \u2018N\u2019 format string steals a reference to the corresponding PyObject* C-variable. You should use \u2018N\u2019 if you have already created a reference for the object and just want to give that reference to the tuple. You should use \u2018O\u2019 if you only have a borrowed reference to an object and need to create one to provide for the tuple.", "These functions are very similar to functions without keyword arguments. The only difference is that the function signature is:", "The kwds argument holds a Python dictionary whose keys are the names of the keyword arguments and whose values are the corresponding keyword-argument values. This dictionary can be processed however you see fit. The easiest way to handle it, however, is to replace the PyArg_ParseTuple (args, format_string, addresses\u2026) function with a call to PyArg_ParseTupleAndKeywords (args, kwds, format_string, char *kwlist[], addresses\u2026). The kwlist parameter to this function is a NULL -terminated array of strings providing the expected keyword arguments. There should be one string for each entry in the format_string. Using this function will raise a TypeError if invalid keyword arguments are passed in.", "For more help on this function please see section 1.8 (Keyword Parameters for Extension Functions) of the Extending and Embedding tutorial in the Python documentation.", "The biggest difficulty when writing extension modules is reference counting. It is an important reason for the popularity of f2py, weave, Cython, ctypes, etc\u2026. If you mis-handle reference counts you can get problems from memory-leaks to segmentation faults. The only strategy I know of to handle reference counts correctly is blood, sweat, and tears. First, you force it into your head that every Python variable has a reference count. Then, you understand exactly what each function does to the reference count of your objects, so that you can properly use DECREF and INCREF when you need them. Reference counting can really test the amount of patience and diligence you have towards your programming craft. Despite the grim depiction, most cases of reference counting are quite straightforward with the most common difficulty being not using DECREF on objects before exiting early from a routine due to some error. In second place, is the common error of not owning the reference on an object that is passed to a function or macro that is going to steal the reference ( e.g. PyTuple_SET_ITEM, and most functions that take PyArray_Descr objects).", "Typically you get a new reference to a variable when it is created or is the return value of some function (there are some prominent exceptions, however \u2014 such as getting an item out of a tuple or a dictionary). When you own the reference, you are responsible to make sure that Py_DECREF (var) is called when the variable is no longer necessary (and no other function has \u201cstolen\u201d its reference). Also, if you are passing a Python object to a function that will \u201csteal\u201d the reference, then you need to make sure you own it (or use Py_INCREF to get your own reference). You will also encounter the notion of borrowing a reference. A function that borrows a reference does not alter the reference count of the object and does not expect to \u201chold on \u201cto the reference. It\u2019s just going to use the object temporarily. When you use PyArg_ParseTuple or PyArg_UnpackTuple you receive a borrowed reference to the objects in the tuple and should not alter their reference count inside your function. With practice, you can learn to get reference counting right, but it can be frustrating at first.", "One common source of reference-count errors is the Py_BuildValue function. Pay careful attention to the difference between the \u2018N\u2019 format character and the \u2018O\u2019 format character. If you create a new object in your subroutine (such as an output array), and you are passing it back in a tuple of return values, then you should most- likely use the \u2018N\u2019 format character in Py_BuildValue. The \u2018O\u2019 character will increase the reference count by one. This will leave the caller with two reference counts for a brand-new array. When the variable is deleted and the reference count decremented by one, there will still be that extra reference count, and the array will never be deallocated. You will have a reference-counting induced memory leak. Using the \u2018N\u2019 character will avoid this situation as it will return to the caller an object (inside the tuple) with a single reference count.", "Most extension modules for NumPy will need to access the memory for an ndarray object (or one of it\u2019s sub-classes). The easiest way to do this doesn\u2019t require you to know much about the internals of NumPy. The method is to", "Ensure you are dealing with a well-behaved array (aligned, in machine byte-order and single-segment) of the correct type and number of dimensions.", "Each of these sub-topics is covered in the following sub-sections.", "The main routine for obtaining an array from any Python object that can be converted to an array is PyArray_FromAny. This function is very flexible with many input arguments. Several macros make it easier to use the basic function. PyArray_FROM_OTF is arguably the most useful of these macros for the most common uses. It allows you to convert an arbitrary Python object to an array of a specific builtin data-type ( e.g. float), while specifying a particular set of requirements ( e.g. contiguous, aligned, and writeable). The syntax is", "Return an ndarray from any Python object, obj, that can be converted to an array. The number of dimensions in the returned array is determined by the object. The desired data-type of the returned array is provided in typenum which should be one of the enumerated types. The requirements for the returned array can be any combination of standard array flags. Each of these arguments is explained in more detail below. You receive a new reference to the array on success. On failure, NULL is returned and an exception is set.", "The object can be any Python object convertible to an ndarray. If the object is already (a subclass of) the ndarray that satisfies the requirements then a new reference is returned. Otherwise, a new array is constructed. The contents of obj are copied to the new array unless the array interface is used so that data does not have to be copied. Objects that can be converted to an array include: 1) any nested sequence object, 2) any object exposing the array interface, 3) any object with an __array__ method (which should return an ndarray), and 4) any scalar object (becomes a zero-dimensional array). Sub-classes of the ndarray that otherwise fit the requirements will be passed through. If you want to ensure a base-class ndarray, then use NPY_ARRAY_ENSUREARRAY in the requirements flag. A copy is made only if necessary. If you want to guarantee a copy, then pass in NPY_ARRAY_ENSURECOPY to the requirements flag.", "One of the enumerated types or NPY_NOTYPE if the data-type should be determined from the object itself. The C-based names can be used:", "NPY_BOOL, NPY_BYTE, NPY_UBYTE, NPY_SHORT, NPY_USHORT, NPY_INT, NPY_UINT, NPY_LONG, NPY_ULONG, NPY_LONGLONG, NPY_ULONGLONG, NPY_DOUBLE, NPY_LONGDOUBLE, NPY_CFLOAT, NPY_CDOUBLE, NPY_CLONGDOUBLE, NPY_OBJECT.", "Alternatively, the bit-width names can be used as supported on the platform. For example:", "NPY_INT8, NPY_INT16, NPY_INT32, NPY_INT64, NPY_UINT8, NPY_UINT16, NPY_UINT32, NPY_UINT64, NPY_FLOAT32, NPY_FLOAT64, NPY_COMPLEX64, NPY_COMPLEX128.", "The object will be converted to the desired type only if it can be done without losing precision. Otherwise NULL will be returned and an error raised. Use NPY_ARRAY_FORCECAST in the requirements flag to override this behavior.", "The memory model for an ndarray admits arbitrary strides in each dimension to advance to the next element of the array. Often, however, you need to interface with code that expects a C-contiguous or a Fortran-contiguous memory layout. In addition, an ndarray can be misaligned (the address of an element is not at an integral multiple of the size of the element) which can cause your program to crash (or at least work more slowly) if you try and dereference a pointer into the array data. Both of these problems can be solved by converting the Python object into an array that is more \u201cwell-behaved\u201d for your specific usage.", "The requirements flag allows specification of what kind of array is acceptable. If the object passed in does not satisfy this requirements then a copy is made so that the returned object will satisfy the requirements. these ndarray can use a very generic pointer to memory. This flag allows specification of the desired properties of the returned array object. All of the flags are explained in the detailed API chapter. The flags most commonly needed are NPY_ARRAY_IN_ARRAY, NPY_OUT_ARRAY, and NPY_ARRAY_INOUT_ARRAY:", "This flag is useful for arrays that must be in C-contiguous order and aligned. These kinds of arrays are usually input arrays for some algorithm.", "This flag is useful to specify an array that is in C-contiguous order, is aligned, and can be written to as well. Such an array is usually returned as output (although normally such output arrays are created from scratch).", "This flag is useful to specify an array that will be used for both input and output. PyArray_ResolveWritebackIfCopy must be called before Py_DECREF at the end of the interface routine to write back the temporary data into the original array passed in. Use of the NPY_ARRAY_WRITEBACKIFCOPY or NPY_ARRAY_UPDATEIFCOPY flags requires that the input object is already an array (because other objects cannot be automatically updated in this fashion). If an error occurs use PyArray_DiscardWritebackIfCopy (obj) on an array with these flags set. This will set the underlying base array writable without causing the contents to be copied back into the original array.", "Other useful flags that can be OR\u2019d as additional requirements are:", "Cast to the desired type, even if it can\u2019t be done without losing information.", "Make sure the resulting array is a copy of the original.", "Make sure the resulting object is an actual ndarray and not a sub- class.", "Note", "Whether or not an array is byte-swapped is determined by the data-type of the array. Native byte-order arrays are always requested by PyArray_FROM_OTF and so there is no need for a NPY_ARRAY_NOTSWAPPED flag in the requirements argument. There is also no way to get a byte-swapped array from this routine.", "Quite often, new arrays must be created from within extension-module code. Perhaps an output array is needed and you don\u2019t want the caller to have to supply it. Perhaps only a temporary array is needed to hold an intermediate calculation. Whatever the need there are simple ways to get an ndarray object of whatever data-type is needed. The most general function for doing this is PyArray_NewFromDescr. All array creation functions go through this heavily re-used code. Because of its flexibility, it can be somewhat confusing to use. As a result, simpler forms exist that are easier to use. These forms are part of the PyArray_SimpleNew family of functions, which simplify the interface by providing default values for common use cases.", "If obj is an ndarray (PyArrayObject*), then the data-area of the ndarray is pointed to by the void* pointer PyArray_DATA (obj) or the char* pointer PyArray_BYTES (obj). Remember that (in general) this data-area may not be aligned according to the data-type, it may represent byte-swapped data, and/or it may not be writeable. If the data area is aligned and in native byte-order, then how to get at a specific element of the array is determined only by the array of npy_intp variables, PyArray_STRIDES (obj). In particular, this c-array of integers shows how many bytes must be added to the current element pointer to get to the next element in each dimension. For arrays less than 4-dimensions there are PyArray_GETPTR{k} (obj, \u2026) macros where {k} is the integer 1, 2, 3, or 4 that make using the array strides easier. The arguments \u2026. represent {k} non- negative integer indices into the array. For example, suppose E is a 3-dimensional ndarray. A (void*) pointer to the element E[i,j,k] is obtained as PyArray_GETPTR3 (E, i, j, k).", "As explained previously, C-style contiguous arrays and Fortran-style contiguous arrays have particular striding patterns. Two array flags (NPY_ARRAY_C_CONTIGUOUS and NPY_ARRAY_F_CONTIGUOUS) indicate whether or not the striding pattern of a particular array matches the C-style contiguous or Fortran-style contiguous or neither. Whether or not the striding pattern matches a standard C or Fortran one can be tested Using PyArray_IS_C_CONTIGUOUS (obj) and PyArray_ISFORTRAN (obj) respectively. Most third-party libraries expect contiguous arrays. But, often it is not difficult to support general-purpose striding. I encourage you to use the striding information in your own code whenever possible, and reserve single-segment requirements for wrapping third-party code. Using the striding information provided with the ndarray rather than requiring a contiguous striding reduces copying that otherwise must be made.", "The following example shows how you might write a wrapper that accepts two input arguments (that will be converted to an array) and an output argument (that must be an array). The function returns None and updates the output array. Note the updated use of WRITEBACKIFCOPY semantics for NumPy v1.14 and above"]}, {"name": "int PyModule_AddStringConstant()", "path": "user/c-info.how-to-extend#c.PyModule_AddStringConstant", "type": "User Guide", "text": ["All three of these functions require the module object (the return value of Py_InitModule). The name is a string that labels the value in the module. Depending on which function is called, the value argument is either a general object (PyModule_AddObject steals a reference to it), an integer constant, or a string constant."]}, {"name": "int PyTypeNum_ISBOOL()", "path": "reference/c-api/array#c.PyTypeNum_ISBOOL", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISCOMPLEX()", "path": "reference/c-api/array#c.PyTypeNum_ISCOMPLEX", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISEXTENDED()", "path": "reference/c-api/array#c.PyTypeNum_ISEXTENDED", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyTypeNum_ISFLEXIBLE", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISFLOAT()", "path": "reference/c-api/array#c.PyTypeNum_ISFLOAT", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISINTEGER()", "path": "reference/c-api/array#c.PyTypeNum_ISINTEGER", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISNUMBER()", "path": "reference/c-api/array#c.PyTypeNum_ISNUMBER", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISOBJECT()", "path": "reference/c-api/array#c.PyTypeNum_ISOBJECT", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISPYTHON()", "path": "reference/c-api/array#c.PyTypeNum_ISPYTHON", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISSIGNED()", "path": "reference/c-api/array#c.PyTypeNum_ISSIGNED", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISSTRING()", "path": "reference/c-api/array#c.PyTypeNum_ISSTRING", "type": "Array API", "text": []}, {"name": "int PyTypeNum_ISUSERDEF()", "path": "reference/c-api/array#c.PyTypeNum_ISUSERDEF", "type": "Array API", "text": []}, {"name": "int PyUFunc_checkfperr()", "path": "reference/c-api/ufunc#c.PyUFunc_checkfperr", "type": "UFunc API", "text": ["A simple interface to the IEEE error-flag checking support. The errmask argument is a mask of UFUNC_MASK_{ERR} bitmasks indicating which errors to check for (and how to check for them). The errobj must be a Python tuple with two elements: a string containing the name which will be used in any communication of error and either a callable Python object (call-back function) or Py_None. The callable object will only be used if UFUNC_ERR_CALL is set as the desired error checking method. This routine manages the GIL and is safe to call even after releasing the GIL. If an error in the IEEE-compatible hardware is determined a -1 is returned, otherwise a 0 is returned."]}, {"name": "int PyUFunc_RegisterLoopForDescr()", "path": "reference/c-api/ufunc#c.PyUFunc_RegisterLoopForDescr", "type": "UFunc API", "text": ["This function behaves like PyUFunc_RegisterLoopForType above, except that it allows the user to register a 1-d loop using PyArray_Descr objects instead of dtype type num values. This allows a 1-d loop to be registered for structured array data-dtypes and custom data-types instead of scalar data-types."]}, {"name": "int PyUFunc_RegisterLoopForType()", "path": "reference/c-api/ufunc#c.PyUFunc_RegisterLoopForType", "type": "UFunc API", "text": ["This function allows the user to register a 1-d loop with an already- created ufunc to be used whenever the ufunc is called with any of its input arguments as the user-defined data-type. This is needed in order to make ufuncs work with built-in data-types. The data-type must have been previously registered with the numpy system. The loop is passed in as function. This loop can take arbitrary data which should be passed in as data. The data-types the loop requires are passed in as arg_types which must be a pointer to memory at least as large as ufunc->nargs."]}, {"name": "int PyUFunc_ReplaceLoopBySignature()", "path": "reference/c-api/ufunc#c.PyUFunc_ReplaceLoopBySignature", "type": "UFunc API", "text": ["Replace a 1-d loop matching the given signature in the already-created ufunc with the new 1-d loop newfunc. Return the old 1-d loop function in oldfunc. Return 0 on success and -1 on failure. This function works only with built-in types (use PyUFunc_RegisterLoopForType for user-defined types). A signature is an array of data-type numbers indicating the inputs followed by the outputs assumed by the 1-d loop."]}, {"name": "int random_multivariate_hypergeometric_count()", "path": "reference/random/c-api#c.random_multivariate_hypergeometric_count", "type": "C API for random", "text": []}, {"name": "int reserved1", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.reserved1", "type": "Python Types and C-Structures", "text": ["Unused."]}, {"name": "int scanfunc()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.scanfunc", "type": "Python Types and C-Structures", "text": ["A pointer to a function that scans (scanf style) one element of the corresponding type from the file descriptor fd into the array memory pointed to by ip. The array is assumed to be behaved. The last argument arr is the array to be scanned into. Returns number of receiving arguments successfully assigned (which may be zero in case a matching failure occurred before the first receiving argument was assigned), or EOF if input failure occurs before the first receiving argument was assigned. This function should be called without holding the Python GIL, and has to grab it for error reporting."]}, {"name": "int setitem()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.setitem", "type": "Python Types and C-Structures", "text": ["A pointer to a function that sets the Python object item into the array, arr, at the position pointed to by data . This function deals with \u201cmisbehaved\u201d arrays. If successful, a zero is returned, otherwise, a negative one is returned (and a Python error set)."]}, {"name": "int sort()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.sort", "type": "Python Types and C-Structures", "text": ["An array of function pointers to a particular sorting algorithms. A particular sorting algorithm is obtained using a key (so far NPY_QUICKSORT, NPY_HEAPSORT, and NPY_MERGESORT are defined). These sorts are done in-place assuming contiguous and aligned data."]}, {"name": "Internal organization of NumPy arrays", "path": "dev/internals", "type": "Development", "text": ["It helps to understand a bit about how NumPy arrays are handled under the covers to help understand NumPy better. This section will not go into great detail. Those wishing to understand the full details are requested to refer to Travis Oliphant\u2019s book Guide to NumPy.", "NumPy arrays consist of two major components: the raw array data (from now on, referred to as the data buffer), and the information about the raw array data. The data buffer is typically what people think of as arrays in C or Fortran, a contiguous (and fixed) block of memory containing fixed-sized data items. NumPy also contains a significant set of data that describes how to interpret the data in the data buffer. This extra information contains (among other things):", "This arrangement allows for the very flexible use of arrays. One thing that it allows is simple changes to the metadata to change the interpretation of the array buffer. Changing the byteorder of the array is a simple change involving no rearrangement of the data. The shape of the array can be changed very easily without changing anything in the data buffer or any data copying at all.", "Among other things that are made possible is one can create a new array metadata object that uses the same data buffer to create a new view of that data buffer that has a different interpretation of the buffer (e.g., different shape, offset, byte order, strides, etc) but shares the same data bytes. Many operations in NumPy do just this such as slicing. Other operations, such as transpose, don\u2019t move data elements around in the array, but rather change the information about the shape and strides so that the indexing of the array changes, but the data in the doesn\u2019t move.", "Typically these new versions of the array metadata but the same data buffer are new views into the data buffer. There is a different ndarray object, but it uses the same data buffer. This is why it is necessary to force copies through the use of the copy method if one really wants to make a new and independent copy of the data buffer.", "New views into arrays mean the object reference counts for the data buffer increase. Simply doing away with the original array object will not remove the data buffer if other views of it still exist.", "See also", "Indexing on ndarrays", "What is the right way to index multi-dimensional arrays? Before you jump to conclusions about the one and true way to index multi-dimensional arrays, it pays to understand why this is a confusing issue. This section will try to explain in detail how NumPy indexing works and why we adopt the convention we do for images, and when it may be appropriate to adopt other conventions.", "The first thing to understand is that there are two conflicting conventions for indexing 2-dimensional arrays. Matrix notation uses the first index to indicate which row is being selected and the second index to indicate which column is selected. This is opposite the geometrically oriented-convention for images where people generally think the first index represents x position (i.e., column) and the second represents y position (i.e., row). This alone is the source of much confusion; matrix-oriented users and image-oriented users expect two different things with regard to indexing.", "The second issue to understand is how indices correspond to the order in which the array is stored in memory. In Fortran, the first index is the most rapidly varying index when moving through the elements of a two-dimensional array as it is stored in memory. If you adopt the matrix convention for indexing, then this means the matrix is stored one column at a time (since the first index moves to the next row as it changes). Thus Fortran is considered a Column-major language. C has just the opposite convention. In C, the last index changes most rapidly as one moves through the array as stored in memory. Thus C is a Row-major language. The matrix is stored by rows. Note that in both cases it presumes that the matrix convention for indexing is being used, i.e., for both Fortran and C, the first index is the row. Note this convention implies that the indexing convention is invariant and that the data order changes to keep that so.", "But that\u2019s not the only way to look at it. Suppose one has large two-dimensional arrays (images or matrices) stored in data files. Suppose the data are stored by rows rather than by columns. If we are to preserve our index convention (whether matrix or image) that means that depending on the language we use, we may be forced to reorder the data if it is read into memory to preserve our indexing convention. For example, if we read row-ordered data into memory without reordering, it will match the matrix indexing convention for C, but not for Fortran. Conversely, it will match the image indexing convention for Fortran, but not for C. For C, if one is using data stored in row order, and one wants to preserve the image index convention, the data must be reordered when reading into memory.", "In the end, what you do for Fortran or C depends on which is more important, not reordering data or preserving the indexing convention. For large images, reordering data is potentially expensive, and often the indexing convention is inverted to avoid that.", "The situation with NumPy makes this issue yet more complicated. The internal machinery of NumPy arrays is flexible enough to accept any ordering of indices. One can simply reorder indices by manipulating the internal stride information for arrays without reordering the data at all. NumPy will know how to map the new index order to the data without moving the data.", "So if this is true, why not choose the index order that matches what you most expect? In particular, why not define row-ordered images to use the image convention? (This is sometimes referred to as the Fortran convention vs the C convention, thus the \u2018C\u2019 and \u2018FORTRAN\u2019 order options for array ordering in NumPy.) The drawback of doing this is potential performance penalties. It\u2019s common to access the data sequentially, either implicitly in array operations or explicitly by looping over rows of an image. When that is done, then the data will be accessed in non-optimal order. As the first index is incremented, what is actually happening is that elements spaced far apart in memory are being sequentially accessed, with usually poor memory access speeds. For example, for a two-dimensional image im defined so that im[0, 10] represents the value at x = 0, y = 10. To be consistent with usual Python behavior then im[0] would represent a column at x = 0. Yet that data would be spread over the whole array since the data are stored in row order. Despite the flexibility of NumPy\u2019s indexing, it can\u2019t really paper over the fact basic operations are rendered inefficient because of data order or that getting contiguous subarrays is still awkward (e.g., im[:, 0] for the first row, vs im[0]). Thus one can\u2019t use an idiom such as for row in im; for col in im does work, but doesn\u2019t yield contiguous column data.", "As it turns out, NumPy is smart enough when dealing with ufuncs to determine which index is the most rapidly varying one in memory and uses that for the innermost loop. Thus for ufuncs, there is no large intrinsic advantage to either approach in most cases. On the other hand, use of ndarray.flat with a FORTRAN ordered array will lead to non-optimal memory access as adjacent elements in the flattened array (iterator, actually) are not contiguous in memory.", "Indeed, the fact is that Python indexing on lists and other sequences naturally leads to an outside-to-inside ordering (the first index gets the largest grouping, the next largest, and the last gets the smallest element). Since image data are normally stored in rows, this corresponds to the position within rows being the last item indexed.", "If you do want to use Fortran ordering realize that there are two approaches to consider: 1) accept that the first index is just not the most rapidly changing in memory and have all your I/O routines reorder your data when going from memory to disk or visa versa, or use NumPy\u2019s mechanism for mapping the first index to the most rapidly varying data. We recommend the former if possible. The disadvantage of the latter is that many of NumPy\u2019s functions will yield arrays without Fortran ordering unless you are careful to use the order keyword. Doing this would be highly inconvenient.", "Otherwise, we recommend simply learning to reverse the usual order of indices when accessing elements of an array. Granted, it goes against the grain, but it is more in line with Python semantics and the natural order of the data."]}, {"name": "Is the intended behavior clear under all conditions? Some things to watch:", "path": "dev/reviewer_guidelines", "type": "Development", "text": ["Reviewing open pull requests (PRs) helps move the project forward. We encourage people outside the project to get involved as well; it\u2019s a great way to get familiar with the codebase.", "Reviews can come from outside the NumPy team \u2013 we welcome contributions from domain experts (for instance, linalg or fft) or maintainers of other projects. You do not need to be a NumPy maintainer (a NumPy team member with permission to merge a PR) to review.", "If we do not know you yet, consider introducing yourself in the mailing list or Slack before you start reviewing pull requests.", "When reviewing pull requests, please use workflow tracking features on GitHub as appropriate:", "It may be helpful to have a copy of the pull request code checked out on your own machine so that you can play with it locally. You can use the GitHub CLI to do this by clicking the Open with button in the upper right-hand corner of the PR page.", "Assuming you have your development environment set up, you can now build the code and test it.", "It may be helpful to store some of these in GitHub\u2019s saved replies for reviewing:"]}, {"name": "is_array()", "path": "reference/swig.interface-file", "type": "numpy.i: a SWIG Interface File for NumPy", "text": ["The Simple Wrapper and Interface Generator (or SWIG) is a powerful tool for generating wrapper code for interfacing to a wide variety of scripting languages. SWIG can parse header files, and using only the code prototypes, create an interface to the target language. But SWIG is not omnipotent. For example, it cannot know from the prototype:", "what exactly seq is. Is it a single value to be altered in-place? Is it an array, and if so what is its length? Is it input-only? Output-only? Input-output? SWIG cannot determine these details, and does not attempt to do so.", "If we designed rms, we probably made it a routine that takes an input-only array of length n of double values called seq and returns the root mean square. The default behavior of SWIG, however, will be to create a wrapper function that compiles, but is nearly impossible to use from the scripting language in the way the C routine was intended.", "For Python, the preferred way of handling contiguous (or technically, strided) blocks of homogeneous data is with NumPy, which provides full object-oriented access to multidimensial arrays of data. Therefore, the most logical Python interface for the rms function would be (including doc string):", "where seq would be a NumPy array of double values, and its length n would be extracted from seq internally before being passed to the C routine. Even better, since NumPy supports construction of arrays from arbitrary Python sequences, seq itself could be a nearly arbitrary sequence (so long as each element can be converted to a double) and the wrapper code would internally convert it to a NumPy array before extracting its data and length.", "SWIG allows these types of conversions to be defined via a mechanism called typemaps. This document provides information on how to use numpy.i, a SWIG interface file that defines a series of typemaps intended to make the type of array-related conversions described above relatively simple to implement. For example, suppose that the rms function prototype defined above was in a header file named rms.h. To obtain the Python interface discussed above, your SWIG interface file would need the following:", "Typemaps are keyed off a list of one or more function arguments, either by type or by type and name. We will refer to such lists as signatures. One of the many typemaps defined by numpy.i is used above and has the signature (double* IN_ARRAY1, int DIM1). The argument names are intended to suggest that the double* argument is an input array of one dimension and that the int represents the size of that dimension. This is precisely the pattern in the rms prototype.", "Most likely, no actual prototypes to be wrapped will have the argument names IN_ARRAY1 and DIM1. We use the SWIG %apply directive to apply the typemap for one-dimensional input arrays of type double to the actual prototype used by rms. Using numpy.i effectively, therefore, requires knowing what typemaps are available and what they do.", "A SWIG interface file that includes the SWIG directives given above will produce wrapper code that looks something like:", "The typemaps from numpy.i are responsible for the following lines of code: 12\u201320, 25 and 30. Line 10 parses the input to the rms function. From the format string \"O:rms\", we can see that the argument list is expected to be a single Python object (specified by the O before the colon) and whose pointer is stored in obj0. A number of functions, supplied by numpy.i, are called to make and check the (possible) conversion from a generic Python object to a NumPy array. These functions are explained in the section Helper Functions, but hopefully their names are self-explanatory. At line 12 we use obj0 to construct a NumPy array. At line 17, we check the validity of the result: that it is non-null and that it has a single dimension of arbitrary length. Once these states are verified, we extract the data buffer and length in lines 19 and 20 so that we can call the underlying C function at line 22. Line 25 performs memory management for the case where we have created a new array that is no longer needed.", "This code has a significant amount of error handling. Note the SWIG_fail is a macro for goto fail, referring to the label at line 28. If the user provides the wrong number of arguments, this will be caught at line 10. If construction of the NumPy array fails or produces an array with the wrong number of dimensions, these errors are caught at line 17. And finally, if an error is detected, memory is still managed correctly at line 30.", "Note that if the C function signature was in a different order:", "that SWIG would not match the typemap signature given above with the argument list for rms. Fortunately, numpy.i has a set of typemaps with the data pointer given last:", "This simply has the effect of switching the definitions of arg1 and arg2 in lines 3 and 4 of the generated code above, and their assignments in lines 19 and 20.", "The numpy.i file is currently located in the tools/swig sub-directory under the numpy installation directory. Typically, you will want to copy it to the directory where you are developing your wrappers.", "A simple module that only uses a single SWIG interface file should include the following:", "Within a compiled Python module, import_array() should only get called once. This could be in a C/C++ file that you have written and is linked to the module. If this is the case, then none of your interface files should #define SWIG_FILE_WITH_INIT or call import_array(). Or, this initialization call could be in a wrapper file generated by SWIG from an interface file that has the %init block as above. If this is the case, and you have more than one SWIG interface file, then only one interface file should #define SWIG_FILE_WITH_INIT and call import_array().", "The typemap directives provided by numpy.i for arrays of different data types, say double and int, and dimensions of different types, say int or long, are identical to one another except for the C and NumPy type specifications. The typemaps are therefore implemented (typically behind the scenes) via a macro:", "that can be invoked for appropriate (DATA_TYPE, DATA_TYPECODE,\nDIM_TYPE) triplets. For example:", "The numpy.i interface file uses the %numpy_typemaps macro to implement typemaps for the following C data types and int dimension types:", "In the following descriptions, we reference a generic DATA_TYPE, which could be any of the C data types listed above, and DIM_TYPE which should be one of the many types of integers.", "The typemap signatures are largely differentiated on the name given to the buffer pointer. Names with FARRAY are for Fortran-ordered arrays, and names with ARRAY are for C-ordered (or 1D arrays).", "Input arrays are defined as arrays of data that are passed into a routine but are not altered in-place or returned to the user. The Python input array is therefore allowed to be almost any Python sequence (such as a list) that can be converted to the requested type of array. The input array signatures are", "1D:", "2D:", "3D:", "4D:", "The first signature listed, ( DATA_TYPE IN_ARRAY[ANY] ) is for one-dimensional arrays with hard-coded dimensions. Likewise, ( DATA_TYPE IN_ARRAY2[ANY][ANY] ) is for two-dimensional arrays with hard-coded dimensions, and similarly for three-dimensional.", "In-place arrays are defined as arrays that are modified in-place. The input values may or may not be used, but the values at the time the function returns are significant. The provided Python argument must therefore be a NumPy array of the required type. The in-place signatures are", "1D:", "2D:", "3D:", "4D:", "These typemaps now check to make sure that the INPLACE_ARRAY arguments use native byte ordering. If not, an exception is raised.", "There is also a \u201cflat\u201d in-place array for situations in which you would like to modify or process each element, regardless of the number of dimensions. One example is a \u201cquantization\u201d function that quantizes each element of an array in-place, be it 1D, 2D or whatever. This form checks for continuity but allows either C or Fortran ordering.", "ND:", "Argout arrays are arrays that appear in the input arguments in C, but are in fact output arrays. This pattern occurs often when there is more than one output variable and the single return argument is therefore not sufficient. In Python, the conventional way to return multiple arguments is to pack them into a sequence (tuple, list, etc.) and return the sequence. This is what the argout typemaps do. If a wrapped function that uses these argout typemaps has more than one return argument, they are packed into a tuple or list, depending on the version of Python. The Python user does not pass these arrays in, they simply get returned. For the case where a dimension is specified, the python user must provide that dimension as an argument. The argout signatures are", "1D:", "2D:", "3D:", "4D:", "These are typically used in situations where in C/C++, you would allocate a(n) array(s) on the heap, and call the function to fill the array(s) values. In Python, the arrays are allocated for you and returned as new array objects.", "Note that we support DATA_TYPE* argout typemaps in 1D, but not 2D or 3D. This is because of a quirk with the SWIG typemap syntax and cannot be avoided. Note that for these types of 1D typemaps, the Python function will take a single argument representing DIM1.", "Argoutview arrays are for when your C code provides you with a view of its internal data and does not require any memory to be allocated by the user. This can be dangerous. There is almost no way to guarantee that the internal data from the C code will remain in existence for the entire lifetime of the NumPy array that encapsulates it. If the user destroys the object that provides the view of the data before destroying the NumPy array, then using that array may result in bad memory references or segmentation faults. Nevertheless, there are situations, working with large data sets, where you simply have no other choice.", "The C code to be wrapped for argoutview arrays are characterized by pointers: pointers to the dimensions and double pointers to the data, so that these values can be passed back to the user. The argoutview typemap signatures are therefore", "1D:", "2D:", "3D:", "4D:", "Note that arrays with hard-coded dimensions are not supported. These cannot follow the double pointer signatures of these typemaps.", "A recent addition to numpy.i are typemaps that permit argout arrays with views into memory that is managed. See the discussion here.", "1D:", "2D:", "3D:", "4D:", "The numpy.i interface file does not support typemaps for output arrays, for several reasons. First, C/C++ return arguments are limited to a single value. This prevents obtaining dimension information in a general way. Second, arrays with hard-coded lengths are not permitted as return arguments. In other words:", "is not legal C/C++ syntax. Therefore, we cannot provide typemaps of the form:", "If you run into a situation where a function or method is returning a pointer to an array, your best bet is to write your own version of the function to be wrapped, either with %extend for the case of class methods or %ignore and %rename for the case of functions.", "Note that C++ type bool is not supported in the list in the Available Typemaps section. NumPy bools are a single byte, while the C++ bool is four bytes (at least on my system). Therefore:", "will result in typemaps that will produce code that reference improper data lengths. You can implement the following macro expansion:", "to fix the data length problem, and Input Arrays will work fine, but In-Place Arrays might fail type-checking.", "Typemap conversions for complex floating-point types is also not supported automatically. This is because Python and NumPy are written in C, which does not have native complex types. Both Python and NumPy implement their own (essentially equivalent) struct definitions for complex variables:", "We could have implemented:", "which would have provided automatic type conversions for arrays of type Py_complex, npy_cfloat and npy_cdouble. However, it seemed unlikely that there would be any independent (non-Python, non-NumPy) application code that people would be using SWIG to generate a Python interface to, that also used these definitions for complex types. More likely, these application codes will define their own complex types, or in the case of C++, use std::complex. Assuming these data structures are compatible with Python and NumPy complex types, %numpy_typemap expansions as above (with the user\u2019s complex type substituted for the first argument) should work.", "SWIG has sophisticated type checking for numerical types. For example, if your C/C++ routine expects an integer as input, the code generated by SWIG will check for both Python integers and Python long integers, and raise an overflow error if the provided Python integer is too big to cast down to a C integer. With the introduction of NumPy scalar arrays into your Python code, you might conceivably extract an integer from a NumPy array and attempt to pass this to a SWIG-wrapped C/C++ function that expects an int, but the SWIG type checking will not recognize the NumPy array scalar as an integer. (Often, this does in fact work \u2013 it depends on whether NumPy recognizes the integer type you are using as inheriting from the Python integer type on the platform you are using. Sometimes, this means that code that works on a 32-bit machine will fail on a 64-bit machine.)", "If you get a Python error that looks like the following:", "and the argument you are passing is an integer extracted from a NumPy array, then you have stumbled upon this problem. The solution is to modify the SWIG type conversion system to accept NumPy array scalars in addition to the standard integer types. Fortunately, this capability has been provided for you. Simply copy the file:", "to the working build directory for you project, and this problem will be fixed. It is suggested that you do this anyway, as it only increases the capabilities of your Python interface.", "The SWIG type checking and conversion system is a complicated combination of C macros, SWIG macros, SWIG typemaps and SWIG fragments. Fragments are a way to conditionally insert code into your wrapper file if it is needed, and not insert it if not needed. If multiple typemaps require the same fragment, the fragment only gets inserted into your wrapper code once.", "There is a fragment for converting a Python integer to a C long. There is a different fragment that converts a Python integer to a C int, that calls the routine defined in the long fragment. We can make the changes we want here by changing the definition for the long fragment. SWIG determines the active definition for a fragment using a \u201cfirst come, first served\u201d system. That is, we need to define the fragment for long conversions prior to SWIG doing it internally. SWIG allows us to do this by putting our fragment definitions in the file pyfragments.swg. If we were to put the new fragment definitions in numpy.i, they would be ignored.", "The numpy.i file contains several macros and routines that it uses internally to build its typemaps. However, these functions may be useful elsewhere in your interface file. These macros and routines are implemented as fragments, which are described briefly in the previous section. If you try to use one or more of the following macros or functions, but your compiler complains that it does not recognize the symbol, then you need to force these fragments to appear in your code using:", "in your SWIG interface file.", "Evaluates as true if a is non-NULL and can be cast to a PyArrayObject*.", "Evaluates to the integer data type code of a, assuming a can be cast to a PyArrayObject*.", "Evaluates to the integer number of dimensions of a, assuming a can be cast to a PyArrayObject*.", "Evaluates to an array of type npy_intp and length array_numdims(a), giving the lengths of all of the dimensions of a, assuming a can be cast to a PyArrayObject*.", "Evaluates to the i-th dimension size of a, assuming a can be cast to a PyArrayObject*.", "Evaluates to an array of type npy_intp and length array_numdims(a), giving the stridess of all of the dimensions of a, assuming a can be cast to a PyArrayObject*. A stride is the distance in bytes between an element and its immediate neighbor along the same axis.", "Evaluates to the i-th stride of a, assuming a can be cast to a PyArrayObject*.", "Evaluates to a pointer of type void* that points to the data buffer of a, assuming a can be cast to a PyArrayObject*.", "Returns a borrowed reference to the dtype property (PyArray_Descr*) of a, assuming a can be cast to a PyArrayObject*.", "Returns an integer representing the flags of a, assuming a can be cast to a PyArrayObject*.", "Sets the flag represented by f of a, assuming a can be cast to a PyArrayObject*.", "Evaluates as true if a is a contiguous array. Equivalent to (PyArray_ISCONTIGUOUS(a)).", "Evaluates as true if the data buffer of a uses native byte order. Equivalent to (PyArray_ISNOTSWAPPED(a)).", "Evaluates as true if a is FORTRAN ordered.", "pytype_string()", "Return type: const char*", "Arguments:", "Return a string describing the type of py_obj.", "typecode_string()", "Return type: const char*", "Arguments:", "Return a string describing the type corresponding to the NumPy typecode.", "type_match()", "Return type: int", "Arguments:", "Make sure that actual_type is compatible with desired_type. For example, this allows character and byte types, or int and long types, to match. This is now equivalent to PyArray_EquivTypenums().", "obj_to_array_no_conversion()", "Return type: PyArrayObject*", "Arguments:", "Cast input to a PyArrayObject* if legal, and ensure that it is of type typecode. If input cannot be cast, or the typecode is wrong, set a Python error and return NULL.", "obj_to_array_allow_conversion()", "Return type: PyArrayObject*", "Arguments:", "Convert input to a NumPy array with the given typecode. On success, return a valid PyArrayObject* with the correct type. On failure, the Python error string will be set and the routine returns NULL.", "make_contiguous()", "Return type: PyArrayObject*", "Arguments:", "Check to see if ary is contiguous. If so, return the input pointer and flag it as not a new object. If it is not contiguous, create a new PyArrayObject* using the original data, flag it as a new object and return the pointer.", "make_fortran()", "Return type: PyArrayObject*", "Arguments", "Check to see if ary is Fortran contiguous. If so, return the input pointer and flag it as not a new object. If it is not Fortran contiguous, create a new PyArrayObject* using the original data, flag it as a new object and return the pointer.", "obj_to_array_contiguous_allow_conversion()", "Return type: PyArrayObject*", "Arguments:", "Convert input to a contiguous PyArrayObject* of the specified type. If the input object is not a contiguous PyArrayObject*, a new one will be created and the new object flag will be set.", "obj_to_array_fortran_allow_conversion()", "Return type: PyArrayObject*", "Arguments:", "Convert input to a Fortran contiguous PyArrayObject* of the specified type. If the input object is not a Fortran contiguous PyArrayObject*, a new one will be created and the new object flag will be set.", "require_contiguous()", "Return type: int", "Arguments:", "Test whether ary is contiguous. If so, return 1. Otherwise, set a Python error and return 0.", "require_native()", "Return type: int", "Arguments:", "Require that ary is not byte-swapped. If the array is not byte-swapped, return 1. Otherwise, set a Python error and return 0.", "require_dimensions()", "Return type: int", "Arguments:", "Require ary to have a specified number of dimensions. If the array has the specified number of dimensions, return 1. Otherwise, set a Python error and return 0.", "require_dimensions_n()", "Return type: int", "Arguments:", "Require ary to have one of a list of specified number of dimensions. If the array has one of the specified number of dimensions, return 1. Otherwise, set the Python error string and return 0.", "require_size()", "Return type: int", "Arguments:", "Require ary to have a specified shape. If the array has the specified shape, return 1. Otherwise, set the Python error string and return 0.", "require_fortran()", "Return type: int", "Arguments:", "Require the given PyArrayObject to to be Fortran ordered. If the PyArrayObject is already Fortran ordered, do nothing. Else, set the Fortran ordering flag and recompute the strides.", "There are many C or C++ array/NumPy array situations not covered by a simple %include \"numpy.i\" and subsequent %apply directives.", "Consider a reasonable prototype for a dot product function:", "The Python interface that we want is:", "The problem here is that there is one dimension argument and two array arguments, and our typemaps are set up for dimensions that apply to a single array (in fact, SWIG does not provide a mechanism for associating len with vec2 that takes two Python input arguments). The recommended solution is the following:", "If the header file that contains the prototype for double dot() also contains other prototypes that you want to wrap, so that you need to %include this header file, then you will also need a %ignore\ndot; directive, placed after the %rename and before the %include directives. Or, if the function in question is a class method, you will want to use %extend rather than %inline in addition to %ignore.", "A note on error handling: Note that my_dot returns a double but that it can also raise a Python error. The resulting wrapper function will return a Python float representation of 0.0 when the vector lengths do not match. Since this is not NULL, the Python interpreter will not know to check for an error. For this reason, we add the %exception directive above for my_dot to get the behavior we want (note that $action is a macro that gets expanded to a valid call to my_dot). In general, you will probably want to write a SWIG macro to perform this task.", "There are other wrapping situations in which numpy.i may be helpful when you encounter them.", "In some situations, it is possible that you could use the %numpy_typemaps macro to implement typemaps for your own types. See the Other Common Types: bool or Other Common Types: complex sections for examples. Another situation is if your dimensions are of a type other than int (say long for example):", "When you use the %apply directive, as is usually necessary to use numpy.i, it will remain in effect until you tell SWIG that it shouldn\u2019t be. If the arguments to the functions or methods that you are wrapping have common names, such as length or vector, these typemaps may get applied in situations you do not expect or want. Therefore, it is always a good idea to add a %clear directive after you are done with a specific typemap:", "In general, you should target these typemap signatures specifically where you want them, and then clear them after you are done.", "Out of the box, numpy.i provides typemaps that support conversion between NumPy arrays and C arrays:", "That support 74 different argument signatures for each data type, including:", "The numpy.i interface file also provides additional tools for wrapper developers, including:"]}, {"name": "Iterating Over Arrays", "path": "reference/arrays.nditer", "type": "Iterating Over Arrays", "text": ["Note", "Arrays support the iterator protocol and can be iterated over like Python lists. See the Indexing, Slicing and Iterating section in the Quickstart guide for basic usage and examples. The remainder of this document presents the nditer object and covers more advanced usage.", "The iterator object nditer, introduced in NumPy 1.6, provides many flexible ways to visit all the elements of one or more arrays in a systematic fashion. This page introduces some basic ways to use the object for computations on arrays in Python, then concludes with how one can accelerate the inner loop in Cython. Since the Python exposure of nditer is a relatively straightforward mapping of the C array iterator API, these ideas will also provide help working with array iteration from C or C++.", "The most basic task that can be done with the nditer is to visit every element of an array. Each element is provided one by one using the standard Python iterator interface.", "An important thing to be aware of for this iteration is that the order is chosen to match the memory layout of the array instead of using a standard C or Fortran ordering. This is done for access efficiency, reflecting the idea that by default one simply wants to visit each element without concern for a particular ordering. We can see this by iterating over the transpose of our previous array, compared to taking a copy of that transpose in C order.", "The elements of both a and a.T get traversed in the same order, namely the order they are stored in memory, whereas the elements of a.T.copy(order=\u2019C\u2019) get visited in a different order because they have been put into a different memory layout.", "There are times when it is important to visit the elements of an array in a specific order, irrespective of the layout of the elements in memory. The nditer object provides an order parameter to control this aspect of iteration. The default, having the behavior described above, is order=\u2019K\u2019 to keep the existing order. This can be overridden with order=\u2019C\u2019 for C order and order=\u2019F\u2019 for Fortran order.", "By default, the nditer treats the input operand as a read-only object. To be able to modify the array elements, you must specify either read-write or write-only mode using the \u2018readwrite\u2019 or \u2018writeonly\u2019 per-operand flags.", "The nditer will then yield writeable buffer arrays which you may modify. However, because the nditer must copy this buffer data back to the original array once iteration is finished, you must signal when the iteration is ended, by one of two methods. You may either:", "The nditer can no longer be iterated once either close is called or its context is exited.", "If you are writing code that needs to support older versions of numpy, note that prior to 1.15, nditer was not a context manager and did not have a close method. Instead it relied on the destructor to initiate the writeback of the buffer.", "In all the examples so far, the elements of a are provided by the iterator one at a time, because all the looping logic is internal to the iterator. While this is simple and convenient, it is not very efficient. A better approach is to move the one-dimensional innermost loop into your code, external to the iterator. This way, NumPy\u2019s vectorized operations can be used on larger chunks of the elements being visited.", "The nditer will try to provide chunks that are as large as possible to the inner loop. By forcing \u2018C\u2019 and \u2018F\u2019 order, we get different external loop sizes. This mode is enabled by specifying an iterator flag.", "Observe that with the default of keeping native memory order, the iterator is able to provide a single one-dimensional chunk, whereas when forcing Fortran order, it has to provide three chunks of two elements each.", "During iteration, you may want to use the index of the current element in a computation. For example, you may want to visit the elements of an array in memory order, but use a C-order, Fortran-order, or multidimensional index to look up values in a different array.", "The index is tracked by the iterator object itself, and accessible through the index or multi_index properties, depending on what was requested. The examples below show printouts demonstrating the progression of the index:", "Tracking an index or multi-index is incompatible with using an external loop, because it requires a different index value per element. If you try to combine these flags, the nditer object will raise an exception.", "To make its properties more readily accessible during iteration, nditer has an alternative syntax for iterating, which works explicitly with the iterator object itself. With this looping construct, the current value is accessible by indexing into the iterator. Other properties, such as tracked indices remain as before. The examples below produce identical results to the ones in the previous section.", "When forcing an iteration order, we observed that the external loop option may provide the elements in smaller chunks because the elements can\u2019t be visited in the appropriate order with a constant stride. When writing C code, this is generally fine, however in pure Python code this can cause a significant reduction in performance.", "By enabling buffering mode, the chunks provided by the iterator to the inner loop can be made larger, significantly reducing the overhead of the Python interpreter. In the example forcing Fortran iteration order, the inner loop gets to see all the elements in one go when buffering is enabled.", "There are times when it is necessary to treat an array as a different data type than it is stored as. For instance, one may want to do all computations on 64-bit floats, even if the arrays being manipulated are 32-bit floats. Except when writing low-level C code, it\u2019s generally better to let the iterator handle the copying or buffering instead of casting the data type yourself in the inner loop.", "There are two mechanisms which allow this to be done, temporary copies and buffering mode. With temporary copies, a copy of the entire array is made with the new data type, then iteration is done in the copy. Write access is permitted through a mode which updates the original array after all the iteration is complete. The major drawback of temporary copies is that the temporary copy may consume a large amount of memory, particularly if the iteration data type has a larger itemsize than the original one.", "Buffering mode mitigates the memory usage issue and is more cache-friendly than making temporary copies. Except for special cases, where the whole array is needed at once outside the iterator, buffering is recommended over temporary copying. Within NumPy, buffering is used by the ufuncs and other functions to support flexible inputs with minimal memory overhead.", "In our examples, we will treat the input array with a complex data type, so that we can take square roots of negative numbers. Without enabling copies or buffering mode, the iterator will raise an exception if the data type doesn\u2019t match precisely.", "In copying mode, \u2018copy\u2019 is specified as a per-operand flag. This is done to provide control in a per-operand fashion. Buffering mode is specified as an iterator flag.", "The iterator uses NumPy\u2019s casting rules to determine whether a specific conversion is permitted. By default, it enforces \u2018safe\u2019 casting. This means, for example, that it will raise an exception if you try to treat a 64-bit float array as a 32-bit float array. In many cases, the rule \u2018same_kind\u2019 is the most reasonable rule to use, since it will allow conversion from 64 to 32-bit float, but not from float to int or from complex to float.", "One thing to watch out for is conversions back to the original data type when using a read-write or write-only operand. A common case is to implement the inner loop in terms of 64-bit floats, and use \u2018same_kind\u2019 casting to allow the other floating-point types to be processed as well. While in read-only mode, an integer array could be provided, read-write mode will raise an exception because conversion back to the array would violate the casting rule.", "NumPy has a set of rules for dealing with arrays that have differing shapes which are applied whenever functions take multiple operands which combine element-wise. This is called broadcasting. The nditer object can apply these rules for you when you need to write such a function.", "As an example, we print out the result of broadcasting a one and a two dimensional array together.", "When a broadcasting error occurs, the iterator raises an exception which includes the input shapes to help diagnose the problem.", "A common case in NumPy functions is to have outputs allocated based on the broadcasting of the input, and additionally have an optional parameter called \u2018out\u2019 where the result will be placed when it is provided. The nditer object provides a convenient idiom that makes it very easy to support this mechanism.", "We\u2019ll show how this works by creating a function square which squares its input. Let\u2019s start with a minimal function definition excluding \u2018out\u2019 parameter support.", "By default, the nditer uses the flags \u2018allocate\u2019 and \u2018writeonly\u2019 for operands that are passed in as None. This means we were able to provide just the two operands to the iterator, and it handled the rest.", "When adding the \u2018out\u2019 parameter, we have to explicitly provide those flags, because if someone passes in an array as \u2018out\u2019, the iterator will default to \u2018readonly\u2019, and our inner loop would fail. The reason \u2018readonly\u2019 is the default for input arrays is to prevent confusion about unintentionally triggering a reduction operation. If the default were \u2018readwrite\u2019, any broadcasting operation would also trigger a reduction, a topic which is covered later in this document.", "While we\u2019re at it, let\u2019s also introduce the \u2018no_broadcast\u2019 flag, which will prevent the output from being broadcast. This is important, because we only want one input value for each output. Aggregating more than one input value is a reduction operation which requires special handling. It would already raise an error because reductions must be explicitly enabled in an iterator flag, but the error message that results from disabling broadcasting is much more understandable for end-users. To see how to generalize the square function to a reduction, look at the sum of squares function in the section about Cython.", "For completeness, we\u2019ll also add the \u2018external_loop\u2019 and \u2018buffered\u2019 flags, as these are what you will typically want for performance reasons.", "Any binary operation can be extended to an array operation in an outer product fashion like in outer, and the nditer object provides a way to accomplish this by explicitly mapping the axes of the operands. It is also possible to do this with newaxis indexing, but we will show you how to directly use the nditer op_axes parameter to accomplish this with no intermediate views.", "We\u2019ll do a simple outer product, placing the dimensions of the first operand before the dimensions of the second operand. The op_axes parameter needs one list of axes for each operand, and provides a mapping from the iterator\u2019s axes to the axes of the operand.", "Suppose the first operand is one dimensional and the second operand is two dimensional. The iterator will have three dimensions, so op_axes will have two 3-element lists. The first list picks out the one axis of the first operand, and is -1 for the rest of the iterator axes, with a final result of [0, -1, -1]. The second list picks out the two axes of the second operand, but shouldn\u2019t overlap with the axes picked out in the first operand. Its list is [-1, 0, 1]. The output operand maps onto the iterator axes in the standard manner, so we can provide None instead of constructing another list.", "The operation in the inner loop is a straightforward multiplication. Everything to do with the outer product is handled by the iterator setup.", "Note that once the iterator is closed we can not access operands and must use a reference created inside the context manager.", "Whenever a writeable operand has fewer elements than the full iteration space, that operand is undergoing a reduction. The nditer object requires that any reduction operand be flagged as read-write, and only allows reductions when \u2018reduce_ok\u2019 is provided as an iterator flag.", "For a simple example, consider taking the sum of all elements in an array.", "Things are a little bit more tricky when combining reduction and allocated operands. Before iteration is started, any reduction operand must be initialized to its starting values. Here\u2019s how we can do this, taking sums along the last axis of a.", "To do buffered reduction requires yet another adjustment during the setup. Normally the iterator construction involves copying the first buffer of data from the readable arrays into the buffer. Any reduction operand is readable, so it may be read into a buffer. Unfortunately, initialization of the operand after this buffering operation is complete will not be reflected in the buffer that the iteration starts with, and garbage results will be produced.", "The iterator flag \u201cdelay_bufalloc\u201d is there to allow iterator-allocated reduction operands to exist together with buffering. When this flag is set, the iterator will leave its buffers uninitialized until it receives a reset, after which it will be ready for regular iteration. Here\u2019s how the previous example looks if we also enable buffering.", "Those who want really good performance out of their low level operations should strongly consider directly using the iteration API provided in C, but for those who are not comfortable with C or C++, Cython is a good middle ground with reasonable performance tradeoffs. For the nditer object, this means letting the iterator take care of broadcasting, dtype conversion, and buffering, while giving the inner loop to Cython.", "For our example, we\u2019ll create a sum of squares function. To start, let\u2019s implement this function in straightforward Python. We want to support an \u2018axis\u2019 parameter similar to the numpy sum function, so we will need to construct a list for the op_axes parameter. Here\u2019s how this looks.", "To Cython-ize this function, we replace the inner loop (y[\u2026] += x*x) with Cython code that\u2019s specialized for the float64 dtype. With the \u2018external_loop\u2019 flag enabled, the arrays provided to the inner loop will always be one-dimensional, so very little checking needs to be done.", "Here\u2019s the listing of sum_squares.pyx:", "On this machine, building the .pyx file into a module looked like the following, but you may have to find some Cython tutorials to tell you the specifics for your system configuration.:", "Running this from the Python interpreter produces the same answers as our native Python/NumPy code did.", "Doing a little timing in IPython shows that the reduced overhead and memory allocation of the Cython inner loop is providing a very nice speedup over both the straightforward Python code and an expression using NumPy\u2019s built-in sum function.:"]}, {"name": "Laguerre Series (numpy.polynomial.laguerre)", "path": "reference/routines.polynomials.laguerre", "type": "Laguerre Series ( \n        \n         numpy.polynomial.laguerre\n        \n        )", "text": ["This module provides a number of objects (mostly functions) useful for dealing with Laguerre series, including a Laguerre class that encapsulates the usual arithmetic operations. (General information on how this module represents and works with such polynomials is in the docstring for its \u201cparent\u201d sub-package, numpy.polynomial).", "Laguerre(coef[, domain, window])", "A Laguerre series class.", "lagdomain", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "lagzero", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "lagone", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "lagx", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "lagadd(c1, c2)", "Add one Laguerre series to another.", "lagsub(c1, c2)", "Subtract one Laguerre series from another.", "lagmulx(c)", "Multiply a Laguerre series by x.", "lagmul(c1, c2)", "Multiply one Laguerre series by another.", "lagdiv(c1, c2)", "Divide one Laguerre series by another.", "lagpow(c, pow[, maxpower])", "Raise a Laguerre series to a power.", "lagval(x, c[, tensor])", "Evaluate a Laguerre series at points x.", "lagval2d(x, y, c)", "Evaluate a 2-D Laguerre series at points (x, y).", "lagval3d(x, y, z, c)", "Evaluate a 3-D Laguerre series at points (x, y, z).", "laggrid2d(x, y, c)", "Evaluate a 2-D Laguerre series on the Cartesian product of x and y.", "laggrid3d(x, y, z, c)", "Evaluate a 3-D Laguerre series on the Cartesian product of x, y, and z.", "lagder(c[, m, scl, axis])", "Differentiate a Laguerre series.", "lagint(c[, m, k, lbnd, scl, axis])", "Integrate a Laguerre series.", "lagfromroots(roots)", "Generate a Laguerre series with given roots.", "lagroots(c)", "Compute the roots of a Laguerre series.", "lagvander(x, deg)", "Pseudo-Vandermonde matrix of given degree.", "lagvander2d(x, y, deg)", "Pseudo-Vandermonde matrix of given degrees.", "lagvander3d(x, y, z, deg)", "Pseudo-Vandermonde matrix of given degrees.", "laggauss(deg)", "Gauss-Laguerre quadrature.", "lagweight(x)", "Weight function of the Laguerre polynomials.", "lagcompanion(c)", "Return the companion matrix of c.", "lagfit(x, y, deg[, rcond, full, w])", "Least squares fit of Laguerre series to data.", "lagtrim(c[, tol])", "Remove \"small\" \"trailing\" coefficients from a polynomial.", "lagline(off, scl)", "Laguerre series whose graph is a straight line.", "lag2poly(c)", "Convert a Laguerre series to a polynomial.", "poly2lag(pol)", "Convert a polynomial to a Laguerre series.", "numpy.polynomial"]}, {"name": "Legendre Series (numpy.polynomial.legendre)", "path": "reference/routines.polynomials.legendre", "type": "Legendre Series ( \n        \n         numpy.polynomial.legendre\n        \n        )", "text": ["This module provides a number of objects (mostly functions) useful for dealing with Legendre series, including a Legendre class that encapsulates the usual arithmetic operations. (General information on how this module represents and works with such polynomials is in the docstring for its \u201cparent\u201d sub-package, numpy.polynomial).", "Legendre(coef[, domain, window])", "A Legendre series class.", "legdomain", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "legzero", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "legone", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "legx", "An array object represents a multidimensional, homogeneous array of fixed-size items.", "legadd(c1, c2)", "Add one Legendre series to another.", "legsub(c1, c2)", "Subtract one Legendre series from another.", "legmulx(c)", "Multiply a Legendre series by x.", "legmul(c1, c2)", "Multiply one Legendre series by another.", "legdiv(c1, c2)", "Divide one Legendre series by another.", "legpow(c, pow[, maxpower])", "Raise a Legendre series to a power.", "legval(x, c[, tensor])", "Evaluate a Legendre series at points x.", "legval2d(x, y, c)", "Evaluate a 2-D Legendre series at points (x, y).", "legval3d(x, y, z, c)", "Evaluate a 3-D Legendre series at points (x, y, z).", "leggrid2d(x, y, c)", "Evaluate a 2-D Legendre series on the Cartesian product of x and y.", "leggrid3d(x, y, z, c)", "Evaluate a 3-D Legendre series on the Cartesian product of x, y, and z.", "legder(c[, m, scl, axis])", "Differentiate a Legendre series.", "legint(c[, m, k, lbnd, scl, axis])", "Integrate a Legendre series.", "legfromroots(roots)", "Generate a Legendre series with given roots.", "legroots(c)", "Compute the roots of a Legendre series.", "legvander(x, deg)", "Pseudo-Vandermonde matrix of given degree.", "legvander2d(x, y, deg)", "Pseudo-Vandermonde matrix of given degrees.", "legvander3d(x, y, z, deg)", "Pseudo-Vandermonde matrix of given degrees.", "leggauss(deg)", "Gauss-Legendre quadrature.", "legweight(x)", "Weight function of the Legendre polynomials.", "legcompanion(c)", "Return the scaled companion matrix of c.", "legfit(x, y, deg[, rcond, full, w])", "Least squares fit of Legendre series to data.", "legtrim(c[, tol])", "Remove \"small\" \"trailing\" coefficients from a polynomial.", "legline(off, scl)", "Legendre series whose graph is a straight line.", "leg2poly(c)", "Convert a Legendre series to a polynomial.", "poly2leg(pol)", "Convert a polynomial to a Legendre series.", "numpy.polynomial"]}, {"name": "lib.format.descr_to_dtype()", "path": "reference/generated/numpy.lib.format.descr_to_dtype", "type": "numpy.lib.format.descr_to_dtype", "text": ["Returns a dtype based off the given description.", "This is essentially the reverse of dtype_to_descr(). It will remove the valueless padding fields created by, i.e. simple fields like dtype(\u2018float32\u2019), and then convert the description to its corresponding dtype.", "The object retrieved by dtype.descr. Can be passed to numpy.dtype() in order to replicate the input dtype.", "The dtype constructed by the description."]}, {"name": "lib.format.dtype_to_descr()", "path": "reference/generated/numpy.lib.format.dtype_to_descr", "type": "numpy.lib.format.dtype_to_descr", "text": ["Get a serializable descriptor from the dtype.", "The .descr attribute of a dtype object cannot be round-tripped through the dtype() constructor. Simple types, like dtype(\u2018float32\u2019), have a descr which looks like a record array with one field with \u2018\u2019 as a name. The dtype() constructor interprets this as a request to give a default name. Instead, we construct descriptor that can be passed to dtype().", "The dtype of the array that will be written to disk.", "An object that can be passed to numpy.dtype() in order to replicate the input dtype."]}, {"name": "lib.format.header_data_from_array_1_0()", "path": "reference/generated/numpy.lib.format.header_data_from_array_1_0", "type": "numpy.lib.format.header_data_from_array_1_0", "text": ["Get the dictionary of header metadata from a numpy.ndarray.", "This has the appropriate entries for writing its string representation to the header of the file."]}, {"name": "lib.format.magic()", "path": "reference/generated/numpy.lib.format.magic", "type": "numpy.lib.format.magic", "text": ["Return the magic string for the given file format version."]}, {"name": "lib.format.open_memmap()", "path": "reference/generated/numpy.lib.format.open_memmap", "type": "numpy.lib.format.open_memmap", "text": ["Open a .npy file as a memory-mapped array.", "This may be used to read an existing file or create a new one.", "The name of the file on disk. This may not be a file-like object.", "The mode in which to open the file; the default is \u2018r+\u2019. In addition to the standard file modes, \u2018c\u2019 is also accepted to mean \u201ccopy on write.\u201d See memmap for the available mode strings.", "The data type of the array if we are creating a new file in \u201cwrite\u201d mode, if not, dtype is ignored. The default value is None, which results in a data-type of float64.", "The shape of the array if we are creating a new file in \u201cwrite\u201d mode, in which case this parameter is required. Otherwise, this parameter is ignored and is thus optional.", "Whether the array should be Fortran-contiguous (True) or C-contiguous (False, the default) if we are creating a new file in \u201cwrite\u201d mode.", "If the mode is a \u201cwrite\u201d mode, then this is the version of the file format used to create the file. None means use the oldest supported version that is able to store the data. Default: None", "The memory-mapped array.", "If the data or the mode is invalid.", "If the file is not found or cannot be opened correctly.", "See also"]}, {"name": "lib.format.read_array()", "path": "reference/generated/numpy.lib.format.read_array", "type": "numpy.lib.format.read_array", "text": ["Read an array from an NPY file.", "If this is not a real file object, then this may take extra memory and time.", "Whether to allow writing pickled data. Default: False", "Changed in version 1.16.3: Made default False in response to CVE-2019-6446.", "Additional keyword arguments to pass to pickle.load. These are only useful when loading object arrays saved on Python 2 when using Python 3.", "The array from the data on disk.", "If the data is invalid, or allow_pickle=False and the file contains an object array."]}, {"name": "lib.format.read_array_header_1_0()", "path": "reference/generated/numpy.lib.format.read_array_header_1_0", "type": "numpy.lib.format.read_array_header_1_0", "text": ["Read an array header from a filelike object using the 1.0 file format version.", "This will leave the file object located just after the header.", "A file object or something with a read() method like a file.", "The shape of the array.", "The array data will be written out directly if it is either C-contiguous or Fortran-contiguous. Otherwise, it will be made contiguous before writing it out.", "The dtype of the file\u2019s data.", "If the data is invalid."]}, {"name": "lib.format.read_array_header_2_0()", "path": "reference/generated/numpy.lib.format.read_array_header_2_0", "type": "numpy.lib.format.read_array_header_2_0", "text": ["Read an array header from a filelike object using the 2.0 file format version.", "This will leave the file object located just after the header.", "New in version 1.9.0.", "A file object or something with a read() method like a file.", "The shape of the array.", "The array data will be written out directly if it is either C-contiguous or Fortran-contiguous. Otherwise, it will be made contiguous before writing it out.", "The dtype of the file\u2019s data.", "If the data is invalid."]}, {"name": "lib.format.read_magic()", "path": "reference/generated/numpy.lib.format.read_magic", "type": "numpy.lib.format.read_magic", "text": ["Read the magic string to get the version of the file format."]}, {"name": "lib.format.write_array()", "path": "reference/generated/numpy.lib.format.write_array", "type": "numpy.lib.format.write_array", "text": ["Write an array to an NPY file, including a header.", "If the array is neither C-contiguous nor Fortran-contiguous AND the file_like object is not a real file object, this function will have to copy data in memory.", "An open, writable file object, or similar object with a .write() method.", "The array to write to disk.", "The version number of the format. None means use the oldest supported version that is able to store the data. Default: None", "Whether to allow writing pickled data. Default: True", "Additional keyword arguments to pass to pickle.dump, excluding \u2018protocol\u2019. These are only useful when pickling objects in object arrays on Python 3 to Python 2 compatible format.", "If the array cannot be persisted. This includes the case of allow_pickle=False and array being an object array.", "If the array contains Python objects as part of its dtype, the process of pickling them may raise various errors if the objects are not picklable."]}, {"name": "lib.format.write_array_header_1_0()", "path": "reference/generated/numpy.lib.format.write_array_header_1_0", "type": "numpy.lib.format.write_array_header_1_0", "text": ["Write the header for an array using the 1.0 format.", "This has the appropriate entries for writing its string representation to the header of the file."]}, {"name": "lib.format.write_array_header_2_0()", "path": "reference/generated/numpy.lib.format.write_array_header_2_0", "type": "numpy.lib.format.write_array_header_2_0", "text": ["The 2.0 format allows storing very large structured arrays.", "New in version 1.9.0.", "This has the appropriate entries for writing its string representation to the header of the file."]}, {"name": "lib.scimath.arccos()", "path": "reference/generated/numpy.lib.scimath.arccos", "type": "numpy.lib.scimath.arccos", "text": ["Compute the inverse cosine of x.", "Return the \u201cprincipal value\u201d (for a description of this, see numpy.arccos) of the inverse cosine of x. For real x such that abs(x) <= 1, this is a real number in the closed interval \\([0, \\pi]\\). Otherwise, the complex principle value is returned.", "The value(s) whose arccos is (are) required.", "The inverse cosine(s) of the x value(s). If x was a scalar, so is out, otherwise an array object is returned.", "See also", "For an arccos() that returns NAN when real x is not in the interval [-1,1], use numpy.arccos."]}, {"name": "lib.scimath.arcsin()", "path": "reference/generated/numpy.lib.scimath.arcsin", "type": "numpy.lib.scimath.arcsin", "text": ["Compute the inverse sine of x.", "Return the \u201cprincipal value\u201d (for a description of this, see numpy.arcsin) of the inverse sine of x. For real x such that abs(x) <= 1, this is a real number in the closed interval \\([-\\pi/2, \\pi/2]\\). Otherwise, the complex principle value is returned.", "The value(s) whose arcsin is (are) required.", "The inverse sine(s) of the x value(s). If x was a scalar, so is out, otherwise an array object is returned.", "See also", "For an arcsin() that returns NAN when real x is not in the interval [-1,1], use numpy.arcsin."]}, {"name": "lib.scimath.arctanh()", "path": "reference/generated/numpy.lib.scimath.arctanh", "type": "numpy.lib.scimath.arctanh", "text": ["Compute the inverse hyperbolic tangent of x.", "Return the \u201cprincipal value\u201d (for a description of this, see numpy.arctanh) of arctanh(x). For real x such that abs(x) < 1, this is a real number. If abs(x) > 1, or if x is complex, the result is complex. Finally, x = 1 returns``inf`` and x=-1 returns -inf.", "The value(s) whose arctanh is (are) required.", "The inverse hyperbolic tangent(s) of the x value(s). If x was a scalar so is out, otherwise an array is returned.", "See also", "For an arctanh() that returns NAN when real x is not in the interval (-1,1), use numpy.arctanh (this latter, however, does return +/-inf for x = +/-1)."]}, {"name": "lib.scimath.log()", "path": "reference/generated/numpy.lib.scimath.log", "type": "numpy.lib.scimath.log", "text": ["Compute the natural logarithm of x.", "Return the \u201cprincipal value\u201d (for a description of this, see numpy.log) of \\(log_e(x)\\). For real x > 0, this is a real number (log(0) returns -inf and log(np.inf) returns inf). Otherwise, the complex principle value is returned.", "The value(s) whose log is (are) required.", "The log of the x value(s). If x was a scalar, so is out, otherwise an array is returned.", "See also", "For a log() that returns NAN when real x < 0, use numpy.log (note, however, that otherwise numpy.log and this log are identical, i.e., both return -inf for x = 0, inf for x = inf, and, notably, the complex principle value if x.imag != 0).", "Negative arguments are handled \u201ccorrectly\u201d (recall that exp(log(x)) == x does not hold for real x < 0):"]}, {"name": "lib.scimath.log10()", "path": "reference/generated/numpy.lib.scimath.log10", "type": "numpy.lib.scimath.log10", "text": ["Compute the logarithm base 10 of x.", "Return the \u201cprincipal value\u201d (for a description of this, see numpy.log10) of \\(log_{10}(x)\\). For real x > 0, this is a real number (log10(0) returns -inf and log10(np.inf) returns inf). Otherwise, the complex principle value is returned.", "The value(s) whose log base 10 is (are) required.", "The log base 10 of the x value(s). If x was a scalar, so is out, otherwise an array object is returned.", "See also", "For a log10() that returns NAN when real x < 0, use numpy.log10 (note, however, that otherwise numpy.log10 and this log10 are identical, i.e., both return -inf for x = 0, inf for x = inf, and, notably, the complex principle value if x.imag != 0).", "(We set the printing precision so the example can be auto-tested)"]}, {"name": "lib.scimath.log2()", "path": "reference/generated/numpy.lib.scimath.log2", "type": "numpy.lib.scimath.log2", "text": ["Compute the logarithm base 2 of x.", "Return the \u201cprincipal value\u201d (for a description of this, see numpy.log2) of \\(log_2(x)\\). For real x > 0, this is a real number (log2(0) returns -inf and log2(np.inf) returns inf). Otherwise, the complex principle value is returned.", "The value(s) whose log base 2 is (are) required.", "The log base 2 of the x value(s). If x was a scalar, so is out, otherwise an array is returned.", "See also", "For a log2() that returns NAN when real x < 0, use numpy.log2 (note, however, that otherwise numpy.log2 and this log2 are identical, i.e., both return -inf for x = 0, inf for x = inf, and, notably, the complex principle value if x.imag != 0).", "We set the printing precision so the example can be auto-tested:"]}, {"name": "lib.scimath.logn()", "path": "reference/generated/numpy.lib.scimath.logn", "type": "numpy.lib.scimath.logn", "text": ["Take log base n of x.", "If x contains negative inputs, the answer is computed and returned in the complex domain.", "The integer base(s) in which the log is taken.", "The value(s) whose log base n is (are) required.", "The log base n of the x value(s). If x was a scalar, so is out, otherwise an array is returned."]}, {"name": "lib.scimath.power()", "path": "reference/generated/numpy.lib.scimath.power", "type": "numpy.lib.scimath.power", "text": ["Return x to the power p, (x**p).", "If x contains negative values, the output is converted to the complex domain.", "The input value(s).", "The power(s) to which x is raised. If x contains multiple values, p has to either be a scalar, or contain the same number of values as x. In the latter case, the result is x[0]**p[0], x[1]**p[1], ....", "The result of x**p. If x and p are scalars, so is out, otherwise an array is returned.", "See also"]}, {"name": "lib.scimath.sqrt()", "path": "reference/generated/numpy.lib.scimath.sqrt", "type": "numpy.lib.scimath.sqrt", "text": ["Compute the square root of x.", "For negative input elements, a complex value is returned (unlike numpy.sqrt which returns NaN).", "The input value(s).", "The square root of x. If x was a scalar, so is out, otherwise an array is returned.", "See also", "For real, non-negative inputs this works just like numpy.sqrt:", "But it automatically handles negative inputs:"]}, {"name": "lib.stride_tricks.as_strided()", "path": "reference/generated/numpy.lib.stride_tricks.as_strided", "type": "numpy.lib.stride_tricks.as_strided", "text": ["Create a view into the array with the given shape and strides.", "Warning", "This function has to be used with extreme care, see notes.", "Array to create a new.", "The shape of the new array. Defaults to x.shape.", "The strides of the new array. Defaults to x.strides.", "New in version 1.10.", "If True, subclasses are preserved.", "New in version 1.12.", "If set to False, the returned array will always be readonly. Otherwise it will be writable if the original array was. It is advisable to set this to False if possible (see Notes).", "See also", "broadcast an array to a given shape.", "reshape an array.", "userfriendly and safe function for the creation of sliding window views.", "as_strided creates a view into the array given the exact strides and shape. This means it manipulates the internal data structure of ndarray and, if done incorrectly, the array elements can point to invalid memory and can corrupt results or crash your program. It is advisable to always use the original x.strides when calculating new strides to avoid reliance on a contiguous memory layout.", "Furthermore, arrays created with this function often contain self overlapping memory, so that two elements are identical. Vectorized write operations on such arrays will typically be unpredictable. They may even give different results for small, large, or transposed arrays. Since writing to these arrays has to be tested and done with great care, you may want to use writeable=False to avoid accidental write operations.", "For these reasons it is advisable to avoid as_strided when possible."]}, {"name": "lib.stride_tricks.sliding_window_view()", "path": "reference/generated/numpy.lib.stride_tricks.sliding_window_view", "type": "numpy.lib.stride_tricks.sliding_window_view", "text": ["Create a sliding window view into the array with the given window shape.", "Also known as rolling or moving window, the window slides across all dimensions of the array and extracts subsets of the array at all window positions.", "New in version 1.20.0.", "Array to create the sliding window view from.", "Size of window over each axis that takes part in the sliding window. If axis is not present, must have same length as the number of input array dimensions. Single integers i are treated as if they were the tuple (i,).", "Axis or axes along which the sliding window is applied. By default, the sliding window is applied to all axes and window_shape[i] will refer to axis i of x. If axis is given as a tuple of int, window_shape[i] will refer to the axis axis[i] of x. Single integers i are treated as if they were the tuple (i,).", "If True, sub-classes will be passed-through, otherwise the returned array will be forced to be a base-class array (default).", "When true, allow writing to the returned view. The default is false, as this should be used with caution: the returned view contains the same memory location multiple times, so writing to one location will cause others to change.", "Sliding window view of the array. The sliding window dimensions are inserted at the end, and the original dimensions are trimmed as required by the size of the sliding window. That is, view.shape = x_shape_trimmed + window_shape, where x_shape_trimmed is x.shape with every entry reduced by one less than the corresponding window size.", "See also", "A lower-level and less safe routine for creating arbitrary views from custom shape and strides.", "broadcast an array to a given shape.", "For many applications using a sliding window view can be convenient, but potentially very slow. Often specialized solutions exist, for example:", "As a rough estimate, a sliding window approach with an input size of N and a window size of W will scale as O(N*W) where frequently a special algorithm can achieve O(N). That means that the sliding window variant for a window size of 100 can be a 100 times slower than a more specialized version.", "Nevertheless, for small window sizes, when no custom algorithm exists, or as a prototyping and developing tool, this function can be a good solution.", "This also works in more dimensions, e.g.", "The axis can be specified explicitly:", "The same axis can be used several times. In that case, every use reduces the corresponding original dimension:", "Combining with stepped slicing (::step), this can be used to take sliding views which skip elements:", "or views which move by multiple elements", "A common application of sliding_window_view is the calculation of running statistics. The simplest example is the moving average:", "Note that a sliding window approach is often not optimal (see Notes)."]}, {"name": "linalg.cholesky()", "path": "reference/generated/numpy.linalg.cholesky", "type": "numpy.linalg.cholesky", "text": ["Cholesky decomposition.", "Return the Cholesky decomposition, L * L.H, of the square matrix a, where L is lower-triangular and .H is the conjugate transpose operator (which is the ordinary transpose if a is real-valued). a must be Hermitian (symmetric if real-valued) and positive-definite. No checking is performed to verify whether a is Hermitian or not. In addition, only the lower-triangular and diagonal elements of a are used. Only L is actually returned.", "Hermitian (symmetric if all elements are real), positive-definite input matrix.", "Upper or lower-triangular Cholesky factor of a. Returns a matrix object if a is a matrix object.", "If the decomposition fails, for example, if a is not positive-definite.", "See also", "Similar function in SciPy.", "Cholesky decompose a banded Hermitian positive-definite matrix.", "Cholesky decomposition of a matrix, to use in scipy.linalg.cho_solve.", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "The Cholesky decomposition is often used as a fast way of solving", "(when A is both Hermitian/symmetric and positive-definite).", "First, we solve for \\(\\mathbf{y}\\) in", "and then for \\(\\mathbf{x}\\) in"]}, {"name": "linalg.cond()", "path": "reference/generated/numpy.linalg.cond", "type": "numpy.linalg.cond", "text": ["Compute the condition number of a matrix.", "This function is capable of returning the condition number using one of seven different norms, depending on the value of p (see Parameters below).", "The matrix whose condition number is sought.", "Order of the norm used in the condition number computation:", "p", "norm for matrices", "None", "2-norm, computed directly using the SVD", "\u2018fro\u2019", "Frobenius norm", "inf", "max(sum(abs(x), axis=1))", "-inf", "min(sum(abs(x), axis=1))", "1", "max(sum(abs(x), axis=0))", "-1", "min(sum(abs(x), axis=0))", "2", "2-norm (largest sing. value)", "-2", "smallest singular value", "inf means the numpy.inf object, and the Frobenius norm is the root-of-sum-of-squares norm.", "The condition number of the matrix. May be infinite.", "See also", "The condition number of x is defined as the norm of x times the norm of the inverse of x [1]; the norm can be the usual L2-norm (root-of-sum-of-squares) or one of a number of other matrix norms.", "G. Strang, Linear Algebra and Its Applications, Orlando, FL, Academic Press, Inc., 1980, pg. 285."]}, {"name": "linalg.det()", "path": "reference/generated/numpy.linalg.det", "type": "numpy.linalg.det", "text": ["Compute the determinant of an array.", "Input array to compute determinants for.", "Determinant of a.", "See also", "Another way to represent the determinant, more suitable for large matrices where underflow/overflow may occur.", "Similar function in SciPy.", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "The determinant is computed via LU factorization using the LAPACK routine z/dgetrf.", "The determinant of a 2-D array [[a, b], [c, d]] is ad - bc:", "Computing determinants for a stack of matrices:"]}, {"name": "linalg.eig()", "path": "reference/generated/numpy.linalg.eig", "type": "numpy.linalg.eig", "text": ["Compute the eigenvalues and right eigenvectors of a square array.", "Matrices for which the eigenvalues and right eigenvectors will be computed", "The eigenvalues, each repeated according to its multiplicity. The eigenvalues are not necessarily ordered. The resulting array will be of complex type, unless the imaginary part is zero in which case it will be cast to a real type. When a is real the resulting eigenvalues will be real (0 imaginary part) or occur in conjugate pairs", "The normalized (unit \u201clength\u201d) eigenvectors, such that the column v[:,i] is the eigenvector corresponding to the eigenvalue w[i].", "If the eigenvalue computation does not converge.", "See also", "eigenvalues of a non-symmetric array.", "eigenvalues and eigenvectors of a real symmetric or complex Hermitian (conjugate symmetric) array.", "eigenvalues of a real symmetric or complex Hermitian (conjugate symmetric) array.", "Similar function in SciPy that also solves the generalized eigenvalue problem.", "Best choice for unitary and other non-Hermitian normal matrices.", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "This is implemented using the _geev LAPACK routines which compute the eigenvalues and eigenvectors of general square arrays.", "The number w is an eigenvalue of a if there exists a vector v such that a @ v = w * v. Thus, the arrays a, w, and v satisfy the equations a @ v[:,i] = w[i] * v[:,i] for \\(i \\in \\{0,...,M-1\\}\\).", "The array v of eigenvectors may not be of maximum rank, that is, some of the columns may be linearly dependent, although round-off error may obscure that fact. If the eigenvalues are all different, then theoretically the eigenvectors are linearly independent and a can be diagonalized by a similarity transformation using v, i.e, inv(v) @ a @ v is diagonal.", "For non-Hermitian normal matrices the SciPy function scipy.linalg.schur is preferred because the matrix v is guaranteed to be unitary, which is not the case when using eig. The Schur factorization produces an upper triangular matrix rather than a diagonal matrix, but for normal matrices only the diagonal of the upper triangular matrix is needed, the rest is roundoff error.", "Finally, it is emphasized that v consists of the right (as in right-hand side) eigenvectors of a. A vector y satisfying y.T @ a = z * y.T for some number z is called a left eigenvector of a, and, in general, the left and right eigenvectors of a matrix are not necessarily the (perhaps conjugate) transposes of each other.", "G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, Various pp.", "(Almost) trivial example with real e-values and e-vectors.", "Real matrix possessing complex e-values and e-vectors; note that the e-values are complex conjugates of each other.", "Complex-valued matrix with real e-values (but complex-valued e-vectors); note that a.conj().T == a, i.e., a is Hermitian.", "Be careful about round-off error!"]}, {"name": "linalg.eigh()", "path": "reference/generated/numpy.linalg.eigh", "type": "numpy.linalg.eigh", "text": ["Return the eigenvalues and eigenvectors of a complex Hermitian (conjugate symmetric) or a real symmetric matrix.", "Returns two objects, a 1-D array containing the eigenvalues of a, and a 2-D square array or matrix (depending on the input type) of the corresponding eigenvectors (in columns).", "Hermitian or real symmetric matrices whose eigenvalues and eigenvectors are to be computed.", "Specifies whether the calculation is done with the lower triangular part of a (\u2018L\u2019, default) or the upper triangular part (\u2018U\u2019). Irrespective of this value only the real parts of the diagonal will be considered in the computation to preserve the notion of a Hermitian matrix. It therefore follows that the imaginary part of the diagonal will always be treated as zero.", "The eigenvalues in ascending order, each repeated according to its multiplicity.", "The column v[:, i] is the normalized eigenvector corresponding to the eigenvalue w[i]. Will return a matrix object if a is a matrix object.", "If the eigenvalue computation does not converge.", "See also", "eigenvalues of real symmetric or complex Hermitian (conjugate symmetric) arrays.", "eigenvalues and right eigenvectors for non-symmetric arrays.", "eigenvalues of non-symmetric arrays.", "Similar function in SciPy (but also solves the generalized eigenvalue problem).", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "The eigenvalues/eigenvectors are computed using LAPACK routines _syevd, _heevd.", "The eigenvalues of real symmetric or complex Hermitian matrices are always real. [1] The array v of (column) eigenvectors is unitary and a, w, and v satisfy the equations dot(a, v[:, i]) = w[i] * v[:, i].", "G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222."]}, {"name": "linalg.eigvals()", "path": "reference/generated/numpy.linalg.eigvals", "type": "numpy.linalg.eigvals", "text": ["Compute the eigenvalues of a general matrix.", "Main difference between eigvals and eig: the eigenvectors aren\u2019t returned.", "A complex- or real-valued matrix whose eigenvalues will be computed.", "The eigenvalues, each repeated according to its multiplicity. They are not necessarily ordered, nor are they necessarily real for real matrices.", "If the eigenvalue computation does not converge.", "See also", "eigenvalues and right eigenvectors of general arrays", "eigenvalues of real symmetric or complex Hermitian (conjugate symmetric) arrays.", "eigenvalues and eigenvectors of real symmetric or complex Hermitian (conjugate symmetric) arrays.", "Similar function in SciPy.", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "This is implemented using the _geev LAPACK routines which compute the eigenvalues and eigenvectors of general square arrays.", "Illustration, using the fact that the eigenvalues of a diagonal matrix are its diagonal elements, that multiplying a matrix on the left by an orthogonal matrix, Q, and on the right by Q.T (the transpose of Q), preserves the eigenvalues of the \u201cmiddle\u201d matrix. In other words, if Q is orthogonal, then Q * A * Q.T has the same eigenvalues as A:", "Now multiply a diagonal matrix by Q on one side and by Q.T on the other:"]}, {"name": "linalg.eigvalsh()", "path": "reference/generated/numpy.linalg.eigvalsh", "type": "numpy.linalg.eigvalsh", "text": ["Compute the eigenvalues of a complex Hermitian or real symmetric matrix.", "Main difference from eigh: the eigenvectors are not computed.", "A complex- or real-valued matrix whose eigenvalues are to be computed.", "Specifies whether the calculation is done with the lower triangular part of a (\u2018L\u2019, default) or the upper triangular part (\u2018U\u2019). Irrespective of this value only the real parts of the diagonal will be considered in the computation to preserve the notion of a Hermitian matrix. It therefore follows that the imaginary part of the diagonal will always be treated as zero.", "The eigenvalues in ascending order, each repeated according to its multiplicity.", "If the eigenvalue computation does not converge.", "See also", "eigenvalues and eigenvectors of real symmetric or complex Hermitian (conjugate symmetric) arrays.", "eigenvalues of general real or complex arrays.", "eigenvalues and right eigenvectors of general real or complex arrays.", "Similar function in SciPy.", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "The eigenvalues are computed using LAPACK routines _syevd, _heevd."]}, {"name": "linalg.inv()", "path": "reference/generated/numpy.linalg.inv", "type": "numpy.linalg.inv", "text": ["Compute the (multiplicative) inverse of a matrix.", "Given a square matrix a, return the matrix ainv satisfying dot(a, ainv) = dot(ainv, a) = eye(a.shape[0]).", "Matrix to be inverted.", "(Multiplicative) inverse of the matrix a.", "If a is not square or inversion fails.", "See also", "Similar function in SciPy.", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "If a is a matrix object, then the return value is a matrix as well:", "Inverses of several matrices can be computed at once:"]}, {"name": "linalg.LinAlgError", "path": "reference/generated/numpy.linalg.linalgerror", "type": "numpy.linalg.LinAlgError", "text": ["Generic Python-exception-derived object raised by linalg functions.", "General purpose exception class, derived from Python\u2019s exception.Exception class, programmatically raised in linalg functions when a Linear Algebra-related condition would prevent further correct execution of the function."]}, {"name": "linalg.lstsq()", "path": "reference/generated/numpy.linalg.lstsq", "type": "numpy.linalg.lstsq", "text": ["Return the least-squares solution to a linear matrix equation.", "Computes the vector x that approximately solves the equation a @ x = b. The equation may be under-, well-, or over-determined (i.e., the number of linearly independent rows of a can be less than, equal to, or greater than its number of linearly independent columns). If a is square and of full rank, then x (but for round-off error) is the \u201cexact\u201d solution of the equation. Else, x minimizes the Euclidean 2-norm \\(||b - ax||\\). If there are multiple minimizing solutions, the one with the smallest 2-norm \\(||x||\\) is returned.", "\u201cCoefficient\u201d matrix.", "Ordinate or \u201cdependent variable\u201d values. If b is two-dimensional, the least-squares solution is calculated for each of the K columns of b.", "Cut-off ratio for small singular values of a. For the purposes of rank determination, singular values are treated as zero if they are smaller than rcond times the largest singular value of a.", "Changed in version 1.14.0: If not set, a FutureWarning is given. The previous default of -1 will use the machine precision as rcond parameter, the new default will use the machine precision times max(M, N). To silence the warning and use the new default, use rcond=None, to keep using the old behavior, use rcond=-1.", "Least-squares solution. If b is two-dimensional, the solutions are in the K columns of x.", "Sums of squared residuals: Squared Euclidean 2-norm for each column in b - a @ x. If the rank of a is < N or M <= N, this is an empty array. If b is 1-dimensional, this is a (1,) shape array. Otherwise the shape is (K,).", "Rank of matrix a.", "Singular values of a.", "If computation does not converge.", "See also", "Similar function in SciPy.", "If b is a matrix, then all array results are returned as matrices.", "Fit a line, y = mx + c, through some noisy data-points:", "By examining the coefficients, we see that the line should have a gradient of roughly 1 and cut the y-axis at, more or less, -1.", "We can rewrite the line equation as y = Ap, where A = [[x 1]] and p = [[m], [c]]. Now use lstsq to solve for p:", "Plot the data along with the fitted line:"]}, {"name": "linalg.matrix_power()", "path": "reference/generated/numpy.linalg.matrix_power", "type": "numpy.linalg.matrix_power", "text": ["Raise a square matrix to the (integer) power n.", "For positive integers n, the power is computed by repeated matrix squarings and matrix multiplications. If n == 0, the identity matrix of the same shape as M is returned. If n < 0, the inverse is computed and then raised to the abs(n).", "Note", "Stacks of object matrices are not currently supported.", "Matrix to be \u201cpowered\u201d.", "The exponent can be any integer or long integer, positive, negative, or zero.", "The return value is the same shape and type as M; if the exponent is positive or zero then the type of the elements is the same as those of M. If the exponent is negative the elements are floating-point.", "For matrices that are not square or that (for negative powers) cannot be inverted numerically.", "Somewhat more sophisticated example"]}, {"name": "linalg.matrix_rank()", "path": "reference/generated/numpy.linalg.matrix_rank", "type": "numpy.linalg.matrix_rank", "text": ["Return matrix rank of array using SVD method", "Rank of the array is the number of singular values of the array that are greater than tol.", "Changed in version 1.14: Can now operate on stacks of matrices", "Input vector or stack of matrices.", "Threshold below which SVD values are considered zero. If tol is None, and S is an array with singular values for M, and eps is the epsilon value for datatype of S, then tol is set to S.max() * max(M, N) * eps.", "Changed in version 1.14: Broadcasted against the stack of matrices", "If True, A is assumed to be Hermitian (symmetric if real-valued), enabling a more efficient method for finding singular values. Defaults to False.", "New in version 1.14.", "Rank of A.", "The default threshold to detect rank deficiency is a test on the magnitude of the singular values of A. By default, we identify singular values less than S.max() * max(M, N) * eps as indicating rank deficiency (with the symbols defined above). This is the algorithm MATLAB uses [1]. It also appears in Numerical recipes in the discussion of SVD solutions for linear least squares [2].", "This default threshold is designed to detect rank deficiency accounting for the numerical errors of the SVD computation. Imagine that there is a column in A that is an exact (in floating point) linear combination of other columns in A. Computing the SVD on A will not produce a singular value exactly equal to 0 in general: any difference of the smallest SVD value from 0 will be caused by numerical imprecision in the calculation of the SVD. Our threshold for small SVD values takes this numerical imprecision into account, and the default threshold will detect such numerical rank deficiency. The threshold may declare a matrix A rank deficient even if the linear combination of some columns of A is not exactly equal to another column of A but only numerically very close to another column of A.", "We chose our default threshold because it is in wide use. Other thresholds are possible. For example, elsewhere in the 2007 edition of Numerical recipes there is an alternative threshold of S.max() *\nnp.finfo(A.dtype).eps / 2. * np.sqrt(m + n + 1.). The authors describe this threshold as being based on \u201cexpected roundoff error\u201d (p 71).", "The thresholds above deal with floating point roundoff error in the calculation of the SVD. However, you may have more information about the sources of error in A that would make you consider other tolerance values to detect effective rank deficiency. The most useful measure of the tolerance depends on the operations you intend to use on your matrix. For example, if your data come from uncertain measurements with uncertainties greater than floating point epsilon, choosing a tolerance near that uncertainty may be preferable. The tolerance may be absolute if the uncertainties are absolute rather than relative.", "MATLAB reference documentation, \u201cRank\u201d https://www.mathworks.com/help/techdoc/ref/rank.html", "W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery, \u201cNumerical Recipes (3rd edition)\u201d, Cambridge University Press, 2007, page 795."]}, {"name": "linalg.multi_dot()", "path": "reference/generated/numpy.linalg.multi_dot", "type": "numpy.linalg.multi_dot", "text": ["Compute the dot product of two or more arrays in a single function call, while automatically selecting the fastest evaluation order.", "multi_dot chains numpy.dot and uses optimal parenthesization of the matrices [1] [2]. Depending on the shapes of the matrices, this can speed up the multiplication a lot.", "If the first argument is 1-D it is treated as a row vector. If the last argument is 1-D it is treated as a column vector. The other arguments must be 2-D.", "Think of multi_dot as:", "If the first argument is 1-D it is treated as row vector. If the last argument is 1-D it is treated as column vector. The other arguments must be 2-D.", "Output argument. This must have the exact kind that would be returned if it was not used. In particular, it must have the right type, must be C-contiguous, and its dtype must be the dtype that would be returned for dot(a, b). This is a performance feature. Therefore, if these conditions are not met, an exception is raised, instead of attempting to be flexible.", "New in version 1.19.0.", "Returns the dot product of the supplied arrays.", "See also", "dot multiplication with two arguments.", "The cost for a matrix multiplication can be calculated with the following function:", "Assume we have three matrices \\(A_{10x100}, B_{100x5}, C_{5x50}\\).", "The costs for the two different parenthesizations are as follows:", "Cormen, \u201cIntroduction to Algorithms\u201d, Chapter 15.2, p. 370-378", "https://en.wikipedia.org/wiki/Matrix_chain_multiplication", "multi_dot allows you to write:", "instead of:"]}, {"name": "linalg.norm()", "path": "reference/generated/numpy.linalg.norm", "type": "numpy.linalg.norm", "text": ["Matrix or vector norm.", "This function is able to return one of eight different matrix norms, or one of an infinite number of vector norms (described below), depending on the value of the ord parameter.", "Input array. If axis is None, x must be 1-D or 2-D, unless ord is None. If both axis and ord are None, the 2-norm of x.ravel will be returned.", "Order of the norm (see table under Notes). inf means numpy\u2019s inf object. The default is None.", "If axis is an integer, it specifies the axis of x along which to compute the vector norms. If axis is a 2-tuple, it specifies the axes that hold 2-D matrices, and the matrix norms of these matrices are computed. If axis is None then either a vector norm (when x is 1-D) or a matrix norm (when x is 2-D) is returned. The default is None.", "New in version 1.8.0.", "If this is set to True, the axes which are normed over are left in the result as dimensions with size one. With this option the result will broadcast correctly against the original x.", "New in version 1.10.0.", "Norm of the matrix or vector(s).", "See also", "Similar function in SciPy.", "For values of ord < 1, the result is, strictly speaking, not a mathematical \u2018norm\u2019, but it may still be useful for various numerical purposes.", "The following norms can be calculated:", "ord", "norm for matrices", "norm for vectors", "None", "Frobenius norm", "2-norm", "\u2018fro\u2019", "Frobenius norm", "\u2013", "\u2018nuc\u2019", "nuclear norm", "\u2013", "inf", "max(sum(abs(x), axis=1))", "max(abs(x))", "-inf", "min(sum(abs(x), axis=1))", "min(abs(x))", "0", "\u2013", "sum(x != 0)", "1", "max(sum(abs(x), axis=0))", "as below", "-1", "min(sum(abs(x), axis=0))", "as below", "2", "2-norm (largest sing. value)", "as below", "-2", "smallest singular value", "as below", "other", "\u2013", "sum(abs(x)**ord)**(1./ord)", "The Frobenius norm is given by [1]:", "\\(||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}\\)", "The nuclear norm is the sum of the singular values.", "Both the Frobenius and nuclear norm orders are only defined for matrices and raise a ValueError when x.ndim != 2.", "G. H. Golub and C. F. Van Loan, Matrix Computations, Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15", "Using the axis argument to compute vector norms:", "Using the axis argument to compute matrix norms:"]}, {"name": "linalg.pinv()", "path": "reference/generated/numpy.linalg.pinv", "type": "numpy.linalg.pinv", "text": ["Compute the (Moore-Penrose) pseudo-inverse of a matrix.", "Calculate the generalized inverse of a matrix using its singular-value decomposition (SVD) and including all large singular values.", "Changed in version 1.14: Can now operate on stacks of matrices", "Matrix or stack of matrices to be pseudo-inverted.", "Cutoff for small singular values. Singular values less than or equal to rcond * largest_singular_value are set to zero. Broadcasts against the stack of matrices.", "If True, a is assumed to be Hermitian (symmetric if real-valued), enabling a more efficient method for finding singular values. Defaults to False.", "New in version 1.17.0.", "The pseudo-inverse of a. If a is a matrix instance, then so is B.", "If the SVD computation does not converge.", "See also", "Similar function in SciPy.", "Similar function in SciPy (SVD-based).", "Compute the (Moore-Penrose) pseudo-inverse of a Hermitian matrix.", "The pseudo-inverse of a matrix A, denoted \\(A^+\\), is defined as: \u201cthe matrix that \u2018solves\u2019 [the least-squares problem] \\(Ax = b\\),\u201d i.e., if \\(\\bar{x}\\) is said solution, then \\(A^+\\) is that matrix such that \\(\\bar{x} = A^+b\\).", "It can be shown that if \\(Q_1 \\Sigma Q_2^T = A\\) is the singular value decomposition of A, then \\(A^+ = Q_2 \\Sigma^+ Q_1^T\\), where \\(Q_{1,2}\\) are orthogonal matrices, \\(\\Sigma\\) is a diagonal matrix consisting of A\u2019s so-called singular values, (followed, typically, by zeros), and then \\(\\Sigma^+\\) is simply the diagonal matrix consisting of the reciprocals of A\u2019s singular values (again, followed by zeros). [1]", "G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pp. 139-142.", "The following example checks that a * a+ * a == a and a+ * a * a+ == a+:"]}, {"name": "linalg.qr()", "path": "reference/generated/numpy.linalg.qr", "type": "numpy.linalg.qr", "text": ["Compute the qr factorization of a matrix.", "Factor the matrix a as qr, where q is orthonormal and r is upper-triangular.", "An array-like object with the dimensionality of at least 2.", "If K = min(M, N), then", "(\u2026, M, K), (\u2026, K, N) (default)", "The options \u2018reduced\u2019, \u2018complete, and \u2018raw\u2019 are new in numpy 1.8, see the notes for more information. The default is \u2018reduced\u2019, and to maintain backward compatibility with earlier versions of numpy both it and the old default \u2018full\u2019 can be omitted. Note that array h returned in \u2018raw\u2019 mode is transposed for calling Fortran. The \u2018economic\u2019 mode is deprecated. The modes \u2018full\u2019 and \u2018economic\u2019 may be passed using only the first letter for backwards compatibility, but all others must be spelled out. See the Notes for more explanation.", "A matrix with orthonormal columns. When mode = \u2018complete\u2019 the result is an orthogonal/unitary matrix depending on whether or not a is real/complex. The determinant may be either +/- 1 in that case. In case the number of dimensions in the input array is greater than 2 then a stack of the matrices with above properties is returned.", "The upper-triangular matrix or a stack of upper-triangular matrices if the number of dimensions in the input array is greater than 2.", "The array h contains the Householder reflectors that generate q along with r. The tau array contains scaling factors for the reflectors. In the deprecated \u2018economic\u2019 mode only h is returned.", "If factoring fails.", "See also", "Similar function in SciPy.", "Compute RQ decomposition of a matrix.", "This is an interface to the LAPACK routines dgeqrf, zgeqrf, dorgqr, and zungqr.", "For more information on the qr factorization, see for example: https://en.wikipedia.org/wiki/QR_factorization", "Subclasses of ndarray are preserved except for the \u2018raw\u2019 mode. So if a is of type matrix, all the return values will be matrices too.", "New \u2018reduced\u2019, \u2018complete\u2019, and \u2018raw\u2019 options for mode were added in NumPy 1.8.0 and the old option \u2018full\u2019 was made an alias of \u2018reduced\u2019. In addition the options \u2018full\u2019 and \u2018economic\u2019 were deprecated. Because \u2018full\u2019 was the previous default and \u2018reduced\u2019 is the new default, backward compatibility can be maintained by letting mode default. The \u2018raw\u2019 option was added so that LAPACK routines that can multiply arrays by q using the Householder reflectors can be used. Note that in this case the returned arrays are of type np.double or np.cdouble and the h array is transposed to be FORTRAN compatible. No routines using the \u2018raw\u2019 return are currently exposed by numpy, but some are available in lapack_lite and just await the necessary work.", "Example illustrating a common use of qr: solving of least squares problems", "What are the least-squares-best m and y0 in y = y0 + mx for the following data: {(0,1), (1,0), (1,2), (2,1)}. (Graph the points and you\u2019ll see that it should be y0 = 0, m = 1.) The answer is provided by solving the over-determined matrix equation Ax = b, where:", "If A = qr such that q is orthonormal (which is always possible via Gram-Schmidt), then x = inv(r) * (q.T) * b. (In numpy practice, however, we simply use lstsq.)"]}, {"name": "linalg.slogdet()", "path": "reference/generated/numpy.linalg.slogdet", "type": "numpy.linalg.slogdet", "text": ["Compute the sign and (natural) logarithm of the determinant of an array.", "If an array has a very small or very large determinant, then a call to det may overflow or underflow. This routine is more robust against such issues, because it computes the logarithm of the determinant rather than the determinant itself.", "Input array, has to be a square 2-D array.", "A number representing the sign of the determinant. For a real matrix, this is 1, 0, or -1. For a complex matrix, this is a complex number with absolute value 1 (i.e., it is on the unit circle), or else 0.", "The natural log of the absolute value of the determinant.", "See also", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "New in version 1.6.0.", "The determinant is computed via LU factorization using the LAPACK routine z/dgetrf.", "The determinant of a 2-D array [[a, b], [c, d]] is ad - bc:", "Computing log-determinants for a stack of matrices:", "This routine succeeds where ordinary det does not:"]}, {"name": "linalg.solve()", "path": "reference/generated/numpy.linalg.solve", "type": "numpy.linalg.solve", "text": ["Solve a linear matrix equation, or system of linear scalar equations.", "Computes the \u201cexact\u201d solution, x, of the well-determined, i.e., full rank, linear matrix equation ax = b.", "Coefficient matrix.", "Ordinate or \u201cdependent variable\u201d values.", "Solution to the system a x = b. Returned shape is identical to b.", "If a is singular or not square.", "See also", "Similar function in SciPy.", "New in version 1.8.0.", "Broadcasting rules apply, see the numpy.linalg documentation for details.", "The solutions are computed using LAPACK routine _gesv.", "a must be square and of full-rank, i.e., all rows (or, equivalently, columns) must be linearly independent; if either is not true, use lstsq for the least-squares best \u201csolution\u201d of the system/equation.", "G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 22.", "Solve the system of equations x0 + 2 * x1 = 1 and 3 * x0 + 5 * x1 = 2:", "Check that the solution is correct:"]}, {"name": "linalg.svd()", "path": "reference/generated/numpy.linalg.svd", "type": "numpy.linalg.svd", "text": ["Singular Value Decomposition.", "When a is a 2D array, it is factorized as u @ np.diag(s) @ vh\n= (u * s) @ vh, where u and vh are 2D unitary arrays and s is a 1D array of a\u2019s singular values. When a is higher-dimensional, SVD is applied in stacked mode as explained below.", "A real or complex array with a.ndim >= 2.", "If True (default), u and vh have the shapes (..., M, M) and (..., N, N), respectively. Otherwise, the shapes are (..., M, K) and (..., K, N), respectively, where K = min(M, N).", "Whether or not to compute u and vh in addition to s. True by default.", "If True, a is assumed to be Hermitian (symmetric if real-valued), enabling a more efficient method for finding singular values. Defaults to False.", "New in version 1.17.0.", "Unitary array(s). The first a.ndim - 2 dimensions have the same size as those of the input a. The size of the last two dimensions depends on the value of full_matrices. Only returned when compute_uv is True.", "Vector(s) with the singular values, within each vector sorted in descending order. The first a.ndim - 2 dimensions have the same size as those of the input a.", "Unitary array(s). The first a.ndim - 2 dimensions have the same size as those of the input a. The size of the last two dimensions depends on the value of full_matrices. Only returned when compute_uv is True.", "If SVD computation does not converge.", "See also", "Similar function in SciPy.", "Compute singular values of a matrix.", "Changed in version 1.8.0: Broadcasting rules apply, see the numpy.linalg documentation for details.", "The decomposition is performed using LAPACK routine _gesdd.", "SVD is usually described for the factorization of a 2D matrix \\(A\\). The higher-dimensional case will be discussed below. In the 2D case, SVD is written as \\(A = U S V^H\\), where \\(A = a\\), \\(U= u\\), \\(S= \\mathtt{np.diag}(s)\\) and \\(V^H = vh\\). The 1D array s contains the singular values of a and u and vh are unitary. The rows of vh are the eigenvectors of \\(A^H A\\) and the columns of u are the eigenvectors of \\(A A^H\\). In both cases the corresponding (possibly non-zero) eigenvalues are given by s**2.", "If a has more than two dimensions, then broadcasting rules apply, as explained in Linear algebra on several matrices at once. This means that SVD is working in \u201cstacked\u201d mode: it iterates over all indices of the first a.ndim - 2 dimensions and for each combination SVD is applied to the last two indices. The matrix a can be reconstructed from the decomposition with either (u * s[..., None, :]) @ vh or u @ (s[..., None] * vh). (The @ operator can be replaced by the function np.matmul for python versions below 3.5.)", "If a is a matrix object (as opposed to an ndarray), then so are all the return values.", "Reconstruction based on full SVD, 2D case:", "Reconstruction based on reduced SVD, 2D case:", "Reconstruction based on full SVD, 4D case:", "Reconstruction based on reduced SVD, 4D case:"]}, {"name": "linalg.tensorinv()", "path": "reference/generated/numpy.linalg.tensorinv", "type": "numpy.linalg.tensorinv", "text": ["Compute the \u2018inverse\u2019 of an N-dimensional array.", "The result is an inverse for a relative to the tensordot operation tensordot(a, b, ind), i. e., up to floating-point accuracy, tensordot(tensorinv(a), a, ind) is the \u201cidentity\u201d tensor for the tensordot operation.", "Tensor to \u2018invert\u2019. Its shape must be \u2018square\u2019, i. e., prod(a.shape[:ind]) == prod(a.shape[ind:]).", "Number of first indices that are involved in the inverse sum. Must be a positive integer, default is 2.", "a\u2019s tensordot inverse, shape a.shape[ind:] + a.shape[:ind].", "If a is singular or not \u2018square\u2019 (in the above sense).", "See also"]}, {"name": "linalg.tensorsolve()", "path": "reference/generated/numpy.linalg.tensorsolve", "type": "numpy.linalg.tensorsolve", "text": ["Solve the tensor equation a x = b for x.", "It is assumed that all indices of x are summed over in the product, together with the rightmost indices of a, as is done in, for example, tensordot(a, x, axes=b.ndim).", "Coefficient tensor, of shape b.shape + Q. Q, a tuple, equals the shape of that sub-tensor of a consisting of the appropriate number of its rightmost indices, and must be such that prod(Q) == prod(b.shape) (in which sense a is said to be \u2018square\u2019).", "Right-hand tensor, which can be of any shape.", "Axes in a to reorder to the right, before inversion. If None (default), no reordering is done.", "If a is singular or not \u2018square\u2019 (in the above sense).", "See also"]}, {"name": "Linear algebra (numpy.linalg)", "path": "reference/routines.linalg", "type": "Linear algebra ( \n      \n       numpy.linalg\n      \n      )", "text": ["The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient low level implementations of standard linear algebra algorithms. Those libraries may be provided by NumPy itself using C versions of a subset of their reference implementations but, when possible, highly optimized libraries that take advantage of specialized processor functionality are preferred. Examples of such libraries are OpenBLAS, MKL (TM), and ATLAS. Because those libraries are multithreaded and processor dependent, environmental variables and external packages such as threadpoolctl may be needed to control the number of threads or specify the processor architecture.", "The SciPy library also contains a linalg submodule, and there is overlap in the functionality provided by the SciPy and NumPy submodules. SciPy contains functions not found in numpy.linalg, such as functions related to LU decomposition and the Schur decomposition, multiple ways of calculating the pseudoinverse, and matrix transcendentals such as the matrix logarithm. Some functions that exist in both have augmented functionality in scipy.linalg. For example, scipy.linalg.eig can take a second matrix argument for solving generalized eigenvalue problems. Some functions in NumPy, however, have more flexible broadcasting options. For example, numpy.linalg.solve can handle \u201cstacked\u201d arrays, while scipy.linalg.solve accepts only a single square array as its first argument.", "Note", "The term matrix as it is used on this page indicates a 2d numpy.array object, and not a numpy.matrix object. The latter is no longer recommended, even for linear algebra. See the matrix object documentation for more information.", "Introduced in NumPy 1.10.0, the @ operator is preferable to other methods when computing the matrix product between 2d arrays. The numpy.matmul function implements the @ operator.", "dot(a, b[, out])", "Dot product of two arrays.", "linalg.multi_dot(arrays, *[, out])", "Compute the dot product of two or more arrays in a single function call, while automatically selecting the fastest evaluation order.", "vdot(a, b, /)", "Return the dot product of two vectors.", "inner(a, b, /)", "Inner product of two arrays.", "outer(a, b[, out])", "Compute the outer product of two vectors.", "matmul(x1, x2, /[, out, casting, order, ...])", "Matrix product of two arrays.", "tensordot(a, b[, axes])", "Compute tensor dot product along specified axes.", "einsum(subscripts, *operands[, out, dtype, ...])", "Evaluates the Einstein summation convention on the operands.", "einsum_path(subscripts, *operands[, optimize])", "Evaluates the lowest cost contraction order for an einsum expression by considering the creation of intermediate arrays.", "linalg.matrix_power(a, n)", "Raise a square matrix to the (integer) power n.", "kron(a, b)", "Kronecker product of two arrays.", "linalg.cholesky(a)", "Cholesky decomposition.", "linalg.qr(a[, mode])", "Compute the qr factorization of a matrix.", "linalg.svd(a[, full_matrices, compute_uv, ...])", "Singular Value Decomposition.", "linalg.eig(a)", "Compute the eigenvalues and right eigenvectors of a square array.", "linalg.eigh(a[, UPLO])", "Return the eigenvalues and eigenvectors of a complex Hermitian (conjugate symmetric) or a real symmetric matrix.", "linalg.eigvals(a)", "Compute the eigenvalues of a general matrix.", "linalg.eigvalsh(a[, UPLO])", "Compute the eigenvalues of a complex Hermitian or real symmetric matrix.", "linalg.norm(x[, ord, axis, keepdims])", "Matrix or vector norm.", "linalg.cond(x[, p])", "Compute the condition number of a matrix.", "linalg.det(a)", "Compute the determinant of an array.", "linalg.matrix_rank(A[, tol, hermitian])", "Return matrix rank of array using SVD method", "linalg.slogdet(a)", "Compute the sign and (natural) logarithm of the determinant of an array.", "trace(a[, offset, axis1, axis2, dtype, out])", "Return the sum along diagonals of the array.", "linalg.solve(a, b)", "Solve a linear matrix equation, or system of linear scalar equations.", "linalg.tensorsolve(a, b[, axes])", "Solve the tensor equation a x = b for x.", "linalg.lstsq(a, b[, rcond])", "Return the least-squares solution to a linear matrix equation.", "linalg.inv(a)", "Compute the (multiplicative) inverse of a matrix.", "linalg.pinv(a[, rcond, hermitian])", "Compute the (Moore-Penrose) pseudo-inverse of a matrix.", "linalg.tensorinv(a[, ind])", "Compute the 'inverse' of an N-dimensional array.", "linalg.LinAlgError", "Generic Python-exception-derived object raised by linalg functions.", "New in version 1.8.0.", "Several of the linear algebra routines listed above are able to compute results for several matrices at once, if they are stacked into the same array.", "This is indicated in the documentation via input parameter specifications such as a : (..., M, M) array_like. This means that if for instance given an input array a.shape == (N, M, M), it is interpreted as a \u201cstack\u201d of N matrices, each of size M-by-M. Similar specification applies to return values, for instance the determinant has det : (...) and will in this case return an array of shape det(a).shape == (N,). This generalizes to linear algebra operations on higher-dimensional arrays: the last 1 or 2 dimensions of a multidimensional array are interpreted as vectors or matrices, as appropriate for each operation."]}, {"name": "Logic functions", "path": "reference/routines.logic", "type": "Logic functions", "text": ["all(a[, axis, out, keepdims, where])", "Test whether all array elements along a given axis evaluate to True.", "any(a[, axis, out, keepdims, where])", "Test whether any array element along a given axis evaluates to True.", "isfinite(x, /[, out, where, casting, order, ...])", "Test element-wise for finiteness (not infinity and not Not a Number).", "isinf(x, /[, out, where, casting, order, ...])", "Test element-wise for positive or negative infinity.", "isnan(x, /[, out, where, casting, order, ...])", "Test element-wise for NaN and return result as a boolean array.", "isnat(x, /[, out, where, casting, order, ...])", "Test element-wise for NaT (not a time) and return result as a boolean array.", "isneginf(x[, out])", "Test element-wise for negative infinity, return result as bool array.", "isposinf(x[, out])", "Test element-wise for positive infinity, return result as bool array.", "iscomplex(x)", "Returns a bool array, where True if input element is complex.", "iscomplexobj(x)", "Check for a complex type or an array of complex numbers.", "isfortran(a)", "Check if the array is Fortran contiguous but not C contiguous.", "isreal(x)", "Returns a bool array, where True if input element is real.", "isrealobj(x)", "Return True if x is a not complex type or an array of complex numbers.", "isscalar(element)", "Returns True if the type of element is a scalar type.", "logical_and(x1, x2, /[, out, where, ...])", "Compute the truth value of x1 AND x2 element-wise.", "logical_or(x1, x2, /[, out, where, casting, ...])", "Compute the truth value of x1 OR x2 element-wise.", "logical_not(x, /[, out, where, casting, ...])", "Compute the truth value of NOT x element-wise.", "logical_xor(x1, x2, /[, out, where, ...])", "Compute the truth value of x1 XOR x2, element-wise.", "allclose(a, b[, rtol, atol, equal_nan])", "Returns True if two arrays are element-wise equal within a tolerance.", "isclose(a, b[, rtol, atol, equal_nan])", "Returns a boolean array where two arrays are element-wise equal within a tolerance.", "array_equal(a1, a2[, equal_nan])", "True if two arrays have the same shape and elements, False otherwise.", "array_equiv(a1, a2)", "Returns True if input arrays are shape consistent and all elements equal.", "greater(x1, x2, /[, out, where, casting, ...])", "Return the truth value of (x1 > x2) element-wise.", "greater_equal(x1, x2, /[, out, where, ...])", "Return the truth value of (x1 >= x2) element-wise.", "less(x1, x2, /[, out, where, casting, ...])", "Return the truth value of (x1 < x2) element-wise.", "less_equal(x1, x2, /[, out, where, casting, ...])", "Return the truth value of (x1 <= x2) element-wise.", "equal(x1, x2, /[, out, where, casting, ...])", "Return (x1 == x2) element-wise.", "not_equal(x1, x2, /[, out, where, casting, ...])", "Return (x1 != x2) element-wise."]}, {"name": "ma.all()", "path": "reference/generated/numpy.ma.all", "type": "numpy.ma.all", "text": ["Returns True if all elements evaluate to True.", "The output array is masked where all the values along the given axis are masked: if the output would have been a scalar and that all the values are masked, then the output is masked.", "Refer to numpy.all for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function"]}, {"name": "ma.allclose()", "path": "reference/generated/numpy.ma.allclose", "type": "numpy.ma.allclose", "text": ["Returns True if two arrays are element-wise equal within a tolerance.", "This function is equivalent to allclose except that masked values are treated as equal (default) or unequal, depending on the masked_equal argument.", "Input arrays to compare.", "Whether masked values in a and b are considered equal (True) or not (False). They are considered equal by default.", "Relative tolerance. The relative difference is equal to rtol * b. Default is 1e-5.", "Absolute tolerance. The absolute difference is equal to atol. Default is 1e-8.", "Returns True if the two arrays are equal within the given tolerance, False otherwise. If either array contains NaN, then False is returned.", "See also", "the non-masked allclose.", "If the following equation is element-wise True, then allclose returns True:", "Return True if all elements of a and b are equal subject to given tolerances.", "Masked values are not compared directly."]}, {"name": "ma.allequal()", "path": "reference/generated/numpy.ma.allequal", "type": "numpy.ma.allequal", "text": ["Return True if all entries of a and b are equal, using fill_value as a truth value where either or both are masked.", "Input arrays to compare.", "Whether masked values in a or b are considered equal (True) or not (False).", "Returns True if the two arrays are equal within the given tolerance, False otherwise. If either array contains NaN, then False is returned.", "See also"]}, {"name": "ma.anom()", "path": "reference/generated/numpy.ma.anom", "type": "numpy.ma.anom", "text": ["Compute the anomalies (deviations from the arithmetic mean) along the given axis.", "Returns an array of anomalies, with the same shape as the input and where the arithmetic mean is computed along the given axis.", "Axis over which the anomalies are taken. The default is to use the mean of the flattened array as reference.", "the default is float32; for arrays of float types it is the same as the array type.", "See also", "Compute the mean of the array."]}, {"name": "ma.anomalies()", "path": "reference/generated/numpy.ma.anomalies", "type": "numpy.ma.anomalies", "text": ["Compute the anomalies (deviations from the arithmetic mean) along the given axis.", "Returns an array of anomalies, with the same shape as the input and where the arithmetic mean is computed along the given axis.", "Axis over which the anomalies are taken. The default is to use the mean of the flattened array as reference.", "the default is float32; for arrays of float types it is the same as the array type.", "See also", "Compute the mean of the array."]}, {"name": "ma.any()", "path": "reference/generated/numpy.ma.any", "type": "numpy.ma.any", "text": ["Returns True if any of the elements of a evaluate to True.", "Masked values are considered as False during computation.", "Refer to numpy.any for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function"]}, {"name": "ma.append()", "path": "reference/generated/numpy.ma.append", "type": "numpy.ma.append", "text": ["Append values to the end of an array.", "New in version 1.9.0.", "Values are appended to a copy of this array.", "These values are appended to a copy of a. It must be of the correct shape (the same shape as a, excluding axis). If axis is not specified, b can be any shape and will be flattened before use.", "The axis along which v are appended. If axis is not given, both a and b are flattened before use.", "A copy of a with b appended to axis. Note that append does not occur in-place: a new array is allocated and filled. If axis is None, the result is a flattened array.", "See also", "Equivalent function in the top-level NumPy module."]}, {"name": "ma.apply_along_axis()", "path": "reference/generated/numpy.ma.apply_along_axis", "type": "numpy.ma.apply_along_axis", "text": ["Apply a function to 1-D slices along the given axis.", "Execute func1d(a, *args, **kwargs) where func1d operates on 1-D arrays and a is a 1-D slice of arr along axis.", "This is equivalent to (but faster than) the following use of ndindex and s_, which sets each of ii, jj, and kk to a tuple of indices:", "Equivalently, eliminating the inner loop, this can be expressed as:", "This function should accept 1-D arrays. It is applied to 1-D slices of arr along the specified axis.", "Axis along which arr is sliced.", "Input array.", "Additional arguments to func1d.", "Additional named arguments to func1d.", "New in version 1.9.0.", "The output array. The shape of out is identical to the shape of arr, except along the axis dimension. This axis is removed, and replaced with new dimensions equal to the shape of the return value of func1d. So if func1d returns a scalar out will have one fewer dimensions than arr.", "See also", "Apply a function repeatedly over multiple axes.", "For a function that returns a 1D array, the number of dimensions in outarr is the same as arr.", "For a function that returns a higher dimensional array, those dimensions are inserted in place of the axis dimension."]}, {"name": "ma.apply_over_axes()", "path": "reference/generated/numpy.ma.apply_over_axes", "type": "numpy.ma.apply_over_axes", "text": ["Apply a function repeatedly over multiple axes.", "func is called as res = func(a, axis), where axis is the first element of axes. The result res of the function call must have either the same dimensions as a or one less dimension. If res has one less dimension than a, a dimension is inserted before axis. The call to func is then repeated for each axis in axes, with res as the first argument.", "This function must take two arguments, func(a, axis).", "Input array.", "Axes over which func is applied; the elements must be integers.", "The output array. The number of dimensions is the same as a, but the shape can be different. This depends on whether func changes the shape of its output with respect to its input.", "See also", "Apply a function to 1-D slices of an array along the given axis.", "Tuple axis arguments to ufuncs are equivalent:"]}, {"name": "ma.arange()", "path": "reference/generated/numpy.ma.arange", "type": "numpy.ma.arange", "text": ["Return evenly spaced values within a given interval.", "Values are generated within the half-open interval [start, stop) (in other words, the interval including start but excluding stop). For integer arguments the function is equivalent to the Python built-in range function, but returns an ndarray rather than a list.", "When using a non-integer step, such as 0.1, it is often better to use numpy.linspace. See the warnings section below for more information.", "Start of interval. The interval includes this value. The default start value is 0.", "End of interval. The interval does not include this value, except in some cases where step is not an integer and floating point round-off affects the length of out.", "Spacing between values. For any output out, this is the distance between two adjacent values, out[i+1] - out[i]. The default step size is 1. If step is specified as a position argument, start must also be given.", "The type of the output array. If dtype is not given, infer the data type from the other input arguments.", "Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.", "New in version 1.20.0.", "Array of evenly spaced values.", "For floating point arguments, the length of the result is ceil((stop - start)/step). Because of floating point overflow, this rule may result in the last element of out being greater than stop.", "Warning", "The length of the output might not be numerically stable.", "Another stability issue is due to the internal implementation of numpy.arange. The actual step value used to populate the array is dtype(start + step) - dtype(start) and not step. Precision loss can occur here, due to casting or due to using floating points when start is much larger than step. This can lead to unexpected behaviour. For example:", "In such cases, the use of numpy.linspace should be preferred.", "See also", "Evenly spaced numbers with careful handling of endpoints.", "Arrays of evenly spaced numbers in N-dimensions.", "Grid-shaped arrays of evenly spaced numbers in N-dimensions."]}, {"name": "ma.argmax()", "path": "reference/generated/numpy.ma.argmax", "type": "numpy.ma.argmax", "text": ["Returns array of indices of the maximum values along the given axis. Masked values are treated as if they had the value fill_value.", "If None, the index is into the flattened array, otherwise along the specified axis", "Value used to fill in the masked values. If None, the output of maximum_fill_value(self._data) is used instead.", "Array into which the result can be placed. Its type is preserved and it must be of the right shape to hold the output."]}, {"name": "ma.argmin()", "path": "reference/generated/numpy.ma.argmin", "type": "numpy.ma.argmin", "text": ["Return array of indices to the minimum values along the given axis.", "If None, the index is into the flattened array, otherwise along the specified axis", "Value used to fill in the masked values. If None, the output of minimum_fill_value(self._data) is used instead.", "Array into which the result can be placed. Its type is preserved and it must be of the right shape to hold the output.", "If multi-dimension input, returns a new ndarray of indices to the minimum values along the given axis. Otherwise, returns a scalar of index to the minimum values along the given axis."]}, {"name": "ma.argsort()", "path": "reference/generated/numpy.ma.argsort", "type": "numpy.ma.argsort", "text": ["Return an ndarray of indices that sort the array along the specified axis. Masked values are filled beforehand to fill_value.", "Axis along which to sort. If None, the default, the flattened array is used.", "Changed in version 1.13.0: Previously, the default was documented to be -1, but that was in error. At some future date, the default will change to -1, as originally intended. Until then, the axis should be given explicitly when arr.ndim > 1, to avoid a FutureWarning.", "The sorting algorithm used.", "When a is an array with fields defined, this argument specifies which fields to compare first, second, etc. Not all fields need be specified.", "Whether missing values (if any) should be treated as the largest values (True) or the smallest values (False) When the array contains unmasked values at the same extremes of the datatype, the ordering of these values and the masked values is undefined.", "Value used internally for the masked values. If fill_value is not None, it supersedes endwith.", "Array of indices that sort a along the specified axis. In other words, a[index_array] yields a sorted a.", "See also", "Describes sorting algorithms used.", "Indirect stable sort with multiple keys.", "Inplace sort.", "See sort for notes on the different sorting algorithms."]}, {"name": "ma.around", "path": "reference/generated/numpy.ma.around", "type": "numpy.ma.around", "text": ["Round an array to the given number of decimals.", "See also", "equivalent function; see for details."]}, {"name": "ma.array()", "path": "reference/generated/numpy.ma.array", "type": "numpy.ma.array", "text": ["An array class with possibly masked values.", "Masked values of True exclude the corresponding element from any computation.", "Construction:", "Input data.", "Mask. Must be convertible to an array of booleans with the same shape as data. True indicates a masked (i.e. invalid) data.", "Data type of the output. If dtype is None, the type of the data argument (data.dtype) is used. If dtype is not None and different from data.dtype, a copy is performed.", "Whether to copy the input data (True), or to use a reference instead. Default is False.", "Whether to return a subclass of MaskedArray if possible (True) or a plain MaskedArray. Default is True.", "Minimum number of dimensions. Default is 0.", "Value used to fill in the masked values when necessary. If None, a default based on the data-type is used.", "Whether to combine mask with the mask of the input data, if any (True), or to use only mask for the output (False). Default is True.", "Whether to use a hard mask or not. With a hard mask, masked values cannot be unmasked. Default is False.", "Whether to force compression of an empty mask. Default is True.", "Specify the order of the array. If order is \u2018C\u2019, then the array will be in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019, then the returned array will be in Fortran-contiguous order (first-index varies the fastest). If order is \u2018A\u2019 (default), then the returned array may be in any order (either C-, Fortran-contiguous, or even discontiguous), unless a copy is required, in which case it will be C-contiguous.", "The mask can be initialized with an array of boolean values with the same shape as data.", "Alternatively, the mask can be initialized to homogeneous boolean array with the same shape as data by passing in a scalar boolean value:", "Note", "The recommended practice for initializing mask with a scalar boolean value is to use True/False rather than np.True_/np.False_. The reason is nomask is represented internally as np.False_."]}, {"name": "ma.asanyarray()", "path": "reference/generated/numpy.ma.asanyarray", "type": "numpy.ma.asanyarray", "text": ["Convert the input to a masked array, conserving subclasses.", "If a is a subclass of MaskedArray, its class is conserved. No copy is performed if the input is already an ndarray.", "Input data, in any form that can be converted to an array.", "By default, the data-type is inferred from the input data.", "Whether to use row-major (\u2018C\u2019) or column-major (\u2018FORTRAN\u2019) memory representation. Default is \u2018C\u2019.", "MaskedArray interpretation of a.", "See also", "Similar to asanyarray, but does not conserve subclass."]}, {"name": "ma.asarray()", "path": "reference/generated/numpy.ma.asarray", "type": "numpy.ma.asarray", "text": ["Convert the input to a masked array of the given data-type.", "No copy is performed if the input is already an ndarray. If a is a subclass of MaskedArray, a base class MaskedArray is returned.", "Input data, in any form that can be converted to a masked array. This includes lists, lists of tuples, tuples, tuples of tuples, tuples of lists, ndarrays and masked arrays.", "By default, the data-type is inferred from the input data.", "Whether to use row-major (\u2018C\u2019) or column-major (\u2018FORTRAN\u2019) memory representation. Default is \u2018C\u2019.", "Masked array interpretation of a.", "See also", "Similar to asarray, but conserves subclasses."]}, {"name": "ma.atleast_1d()", "path": "reference/generated/numpy.ma.atleast_1d", "type": "numpy.ma.atleast_1d", "text": ["Convert inputs to arrays with at least one dimension.", "Scalar inputs are converted to 1-dimensional arrays, whilst higher-dimensional inputs are preserved.", "One or more input arrays.", "An array, or list of arrays, each with a.ndim >= 1. Copies are made only if necessary.", "See also", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.atleast_2d()", "path": "reference/generated/numpy.ma.atleast_2d", "type": "numpy.ma.atleast_2d", "text": ["View inputs as arrays with at least two dimensions.", "One or more array-like sequences. Non-array inputs are converted to arrays. Arrays that already have two or more dimensions are preserved.", "An array, or list of arrays, each with a.ndim >= 2. Copies are avoided where possible, and views with two or more dimensions are returned.", "See also", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.atleast_3d()", "path": "reference/generated/numpy.ma.atleast_3d", "type": "numpy.ma.atleast_3d", "text": ["View inputs as arrays with at least three dimensions.", "One or more array-like sequences. Non-array inputs are converted to arrays. Arrays that already have three or more dimensions are preserved.", "An array, or list of arrays, each with a.ndim >= 3. Copies are avoided where possible, and views with three or more dimensions are returned. For example, a 1-D array of shape (N,) becomes a view of shape (1, N, 1), and a 2-D array of shape (M, N) becomes a view of shape (M, N, 1).", "See also", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.average()", "path": "reference/generated/numpy.ma.average", "type": "numpy.ma.average", "text": ["Return the weighted average of array over the given axis.", "Data to be averaged. Masked entries are not taken into account in the computation.", "Axis along which to average a. If None, averaging is done over the flattened array.", "The importance that each element has in the computation of the average. The weights array can either be 1-D (in which case its length must be the size of a along the given axis) or of the same shape as a. If weights=None, then all data in a are assumed to have a weight equal to one. The 1-D calculation is:", "The only constraint on weights is that sum(weights) must not be 0.", "Flag indicating whether a tuple (result, sum of weights) should be returned as output (True), or just the result (False). Default is False.", "The average along the specified axis. When returned is True, return a tuple with the average as the first element and the sum of the weights as the second element. The return type is np.float64 if a is of integer type and floats smaller than float64, or the input data-type, otherwise. If returned, sum_of_weights is always float64."]}, {"name": "ma.choose()", "path": "reference/generated/numpy.ma.choose", "type": "numpy.ma.choose", "text": ["Use an index array to construct a new array from a list of choices.", "Given an array of integers and a list of n choice arrays, this method will create a new array that merges each of the choice arrays. Where a value in index is i, the new array will have the value that choices[i] contains in the same place.", "This array must contain integers in [0, n-1], where n is the number of choices.", "Choice arrays. The index array and all of the choices should be broadcastable to the same shape.", "If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.", "Specifies how out-of-bounds indices will behave.", "See also", "equivalent function"]}, {"name": "ma.clip()", "path": "reference/generated/numpy.ma.clip", "type": "numpy.ma.clip", "text": ["Clip (limit) the values in an array.", "Given an interval, values outside the interval are clipped to the interval edges. For example, if an interval of [0, 1] is specified, values smaller than 0 become 0, and values larger than 1 become 1.", "Equivalent to but faster than np.minimum(a_max, np.maximum(a, a_min)).", "No check is performed to ensure a_min < a_max.", "Array containing elements to clip.", "Minimum and maximum value. If None, clipping is not performed on the corresponding edge. Only one of a_min and a_max may be None. Both are broadcast against a.", "The results will be placed in this array. It may be the input array for in-place clipping. out must be of the right shape to hold the output. Its type is preserved.", "For other keyword-only arguments, see the ufunc docs.", "New in version 1.17.0.", "An array with the elements of a, but where values < a_min are replaced with a_min, and those > a_max with a_max.", "See also", "When a_min is greater than a_max, clip returns an array in which all values are equal to a_max, as shown in the second example."]}, {"name": "ma.clump_masked()", "path": "reference/generated/numpy.ma.clump_masked", "type": "numpy.ma.clump_masked", "text": ["Returns a list of slices corresponding to the masked clumps of a 1-D array. (A \u201cclump\u201d is defined as a contiguous region of the array).", "A one-dimensional masked array.", "The list of slices, one for each continuous region of masked elements in a.", "See also", "New in version 1.4.0."]}, {"name": "ma.clump_unmasked()", "path": "reference/generated/numpy.ma.clump_unmasked", "type": "numpy.ma.clump_unmasked", "text": ["Return list of slices corresponding to the unmasked clumps of a 1-D array. (A \u201cclump\u201d is defined as a contiguous region of the array).", "A one-dimensional masked array.", "The list of slices, one for each continuous region of unmasked elements in a.", "See also", "New in version 1.4.0."]}, {"name": "ma.column_stack()", "path": "reference/generated/numpy.ma.column_stack", "type": "numpy.ma.column_stack", "text": ["Stack 1-D arrays as columns into a 2-D array.", "Take a sequence of 1-D arrays and stack them as columns to make a single 2-D array. 2-D arrays are stacked as-is, just like with hstack. 1-D arrays are turned into 2-D columns first.", "Arrays to stack. All of them must have the same first dimension.", "The array formed by stacking the given arrays.", "See also", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.common_fill_value()", "path": "reference/generated/numpy.ma.common_fill_value", "type": "numpy.ma.common_fill_value", "text": ["Return the common filling value of two masked arrays, if any.", "If a.fill_value == b.fill_value, return the fill value, otherwise return None.", "The masked arrays for which to compare fill values.", "The common fill value, or None."]}, {"name": "ma.compress_cols()", "path": "reference/generated/numpy.ma.compress_cols", "type": "numpy.ma.compress_cols", "text": ["Suppress whole columns of a 2-D array that contain masked values.", "This is equivalent to np.ma.compress_rowcols(a, 1), see compress_rowcols for details.", "See also"]}, {"name": "ma.compress_rowcols()", "path": "reference/generated/numpy.ma.compress_rowcols", "type": "numpy.ma.compress_rowcols", "text": ["Suppress the rows and/or columns of a 2-D array that contain masked values.", "The suppression behavior is selected with the axis parameter.", "The array to operate on. If not a MaskedArray instance (or if no array elements are masked), x is interpreted as a MaskedArray with mask set to nomask. Must be a 2D array.", "Axis along which to perform the operation. Default is None.", "The compressed array."]}, {"name": "ma.compress_rows()", "path": "reference/generated/numpy.ma.compress_rows", "type": "numpy.ma.compress_rows", "text": ["Suppress whole rows of a 2-D array that contain masked values.", "This is equivalent to np.ma.compress_rowcols(a, 0), see compress_rowcols for details.", "See also"]}, {"name": "ma.compressed()", "path": "reference/generated/numpy.ma.compressed", "type": "numpy.ma.compressed", "text": ["Return all the non-masked data as a 1-D array.", "This function is equivalent to calling the \u201ccompressed\u201d method of a ma.MaskedArray, see ma.MaskedArray.compressed for details.", "See also", "Equivalent method."]}, {"name": "ma.concatenate()", "path": "reference/generated/numpy.ma.concatenate", "type": "numpy.ma.concatenate", "text": ["Concatenate a sequence of arrays along the given axis.", "The arrays must have the same shape, except in the dimension corresponding to axis (the first, by default).", "The axis along which the arrays will be joined. Default is 0.", "The concatenated array with any masked entries preserved.", "See also", "Equivalent function in the top-level NumPy module."]}, {"name": "ma.conjugate()", "path": "reference/generated/numpy.ma.conjugate", "type": "numpy.ma.conjugate", "text": ["Return the complex conjugate, element-wise.", "The complex conjugate of a complex number is obtained by changing the sign of its imaginary part.", "Input value.", "A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs.", "This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized.", "For other keyword-only arguments, see the ufunc docs.", "The complex conjugate of x, with same dtype as y. This is a scalar if x is a scalar.", "conj is an alias for conjugate:"]}, {"name": "ma.copy()", "path": "reference/generated/numpy.ma.copy", "type": "numpy.ma.copy", "text": ["Return a copy of the array.", "Controls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of a as closely as possible. (Note that this function and numpy.copy are very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)", "See also", "Similar function with different default behavior numpy.copyto", "This function is the preferred method for creating an array copy. The function numpy.copy is similar, but it defaults to using order \u2018K\u2019, and will not pass sub-classes through by default."]}, {"name": "ma.corrcoef()", "path": "reference/generated/numpy.ma.corrcoef", "type": "numpy.ma.corrcoef", "text": ["Return Pearson product-moment correlation coefficients.", "Except for the handling of missing data this function does the same as numpy.corrcoef. For more details and examples, see numpy.corrcoef.", "A 1-D or 2-D array containing multiple variables and observations. Each row of x represents a variable, and each column a single observation of all those variables. Also see rowvar below.", "An additional set of variables and observations. y has the same shape as x.", "If rowvar is True (default), then each row represents a variable, with observations in the columns. Otherwise, the relationship is transposed: each column represents a variable, while the rows contain observations.", "Has no effect, do not use.", "Deprecated since version 1.10.0.", "If True, masked values are propagated pair-wise: if a value is masked in x, the corresponding value is masked in y. If False, raises an exception. Because bias is deprecated, this argument needs to be treated as keyword only to avoid a warning.", "Has no effect, do not use.", "Deprecated since version 1.10.0.", "See also", "Equivalent function in top-level NumPy module.", "Estimate the covariance matrix.", "This function accepts but discards arguments bias and ddof. This is for backwards compatibility with previous versions of this function. These arguments had no effect on the return values of the function and can be safely ignored in this and previous versions of numpy."]}, {"name": "ma.count()", "path": "reference/generated/numpy.ma.count", "type": "numpy.ma.count", "text": ["Count the non-masked elements of the array along the given axis.", "Axis or axes along which the count is performed. The default, None, performs the count over all the dimensions of the input array. axis may be negative, in which case it counts from the last to the first axis.", "New in version 1.10.0.", "If this is a tuple of ints, the count is performed on multiple axes, instead of a single axis or all the axes as before.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "An array with the same shape as the input array, with the specified axis removed. If the array is a 0-d array, or if axis is None, a scalar is returned.", "See also", "Count masked elements in array or along a given axis.", "When the axis keyword is specified an array of appropriate size is returned."]}, {"name": "ma.count_masked()", "path": "reference/generated/numpy.ma.count_masked", "type": "numpy.ma.count_masked", "text": ["Count the number of masked elements along the given axis.", "An array with (possibly) masked elements.", "Axis along which to count. If None (default), a flattened version of the array is used.", "The total number of masked elements (axis=None) or the number of masked elements along each slice of the given axis.", "See also", "Count non-masked elements.", "When the axis keyword is used an array is returned."]}, {"name": "ma.cov()", "path": "reference/generated/numpy.ma.cov", "type": "numpy.ma.cov", "text": ["Estimate the covariance matrix.", "Except for the handling of missing data this function does the same as numpy.cov. For more details and examples, see numpy.cov.", "By default, masked values are recognized as such. If x and y have the same shape, a common mask is allocated: if x[i,j] is masked, then y[i,j] will also be masked. Setting allow_masked to False will raise an exception if values are missing in either of the input arrays.", "A 1-D or 2-D array containing multiple variables and observations. Each row of x represents a variable, and each column a single observation of all those variables. Also see rowvar below.", "An additional set of variables and observations. y has the same shape as x.", "If rowvar is True (default), then each row represents a variable, with observations in the columns. Otherwise, the relationship is transposed: each column represents a variable, while the rows contain observations.", "Default normalization (False) is by (N-1), where N is the number of observations given (unbiased estimate). If bias is True, then normalization is by N. This keyword can be overridden by the keyword ddof in numpy versions >= 1.5.", "If True, masked values are propagated pair-wise: if a value is masked in x, the corresponding value is masked in y. If False, raises a ValueError exception when some values are missing.", "If not None normalization is by (N - ddof), where N is the number of observations; this overrides the value implied by bias. The default value is None.", "New in version 1.5.", "Raised if some values are missing and allow_masked is False.", "See also"]}, {"name": "ma.cumprod()", "path": "reference/generated/numpy.ma.cumprod", "type": "numpy.ma.cumprod", "text": ["Return the cumulative product of the array elements over the given axis.", "Masked values are set to 1 internally during the computation. However, their position is saved, and the result will be masked at the same locations.", "Refer to numpy.cumprod for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function", "The mask is lost if out is not a valid MaskedArray !", "Arithmetic is modular when using integer types, and no error is raised on overflow."]}, {"name": "ma.cumsum()", "path": "reference/generated/numpy.ma.cumsum", "type": "numpy.ma.cumsum", "text": ["Return the cumulative sum of the array elements over the given axis.", "Masked values are set to 0 internally during the computation. However, their position is saved, and the result will be masked at the same locations.", "Refer to numpy.cumsum for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function", "The mask is lost if out is not a valid ma.MaskedArray !", "Arithmetic is modular when using integer types, and no error is raised on overflow."]}, {"name": "ma.default_fill_value()", "path": "reference/generated/numpy.ma.default_fill_value", "type": "numpy.ma.default_fill_value", "text": ["Return the default fill value for the argument object.", "The default filling value depends on the datatype of the input array or the type of the input scalar:", "datatype", "default", "bool", "True", "int", "999999", "float", "1.e20", "complex", "1.e20+0j", "object", "\u2018?\u2019", "string", "\u2018N/A\u2019", "For structured types, a structured scalar is returned, with each field the default fill value for its type.", "For subarray types, the fill value is an array of the same size containing the default scalar fill value.", "The array data-type or scalar for which the default fill value is returned.", "The default fill value."]}, {"name": "ma.diag()", "path": "reference/generated/numpy.ma.diag", "type": "numpy.ma.diag", "text": ["Extract a diagonal or construct a diagonal array.", "This function is the equivalent of numpy.diag that takes masked values into account, see numpy.diag for details.", "See also", "Equivalent function for ndarrays."]}, {"name": "ma.diff()", "path": "reference/generated/numpy.ma.diff", "type": "numpy.ma.diff", "text": ["Calculate the n-th discrete difference along the given axis.", "The first difference is given by out[i] = a[i+1] - a[i] along the given axis, higher differences are calculated by using diff recursively.", "Input array", "The number of times values are differenced. If zero, the input is returned as-is.", "The axis along which the difference is taken, default is the last axis.", "Values to prepend or append to a along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match a except along axis.", "New in version 1.16.0.", "The n-th differences. The shape of the output is the same as a except along axis where the dimension is smaller by n. The type of the output is the same as the type of the difference between any two elements of a. This is the same as the type of a in most cases. A notable exception is datetime64, which results in a timedelta64 output array.", "See also", "Type is preserved for boolean arrays, so the result will contain False when consecutive elements are the same and True when they differ.", "For unsigned integer arrays, the results will also be unsigned. This should not be surprising, as the result is consistent with calculating the difference directly:", "If this is not desirable, then the array should be cast to a larger integer type first:"]}, {"name": "ma.dot()", "path": "reference/generated/numpy.ma.dot", "type": "numpy.ma.dot", "text": ["Return the dot product of two arrays.", "This function is the equivalent of numpy.dot that takes masked values into account. Note that strict and out are in different position than in the method version. In order to maintain compatibility with the corresponding method, it is recommended that the optional arguments be treated as keyword only. At some point that may be mandatory.", "Note", "Works only with 2-D arrays at the moment.", "Inputs arrays.", "Whether masked data are propagated (True) or set to 0 (False) for the computation. Default is False. Propagating the mask means that if a masked value appears in a row or column, the whole row or column is considered masked.", "Output argument. This must have the exact kind that would be returned if it was not used. In particular, it must have the right type, must be C-contiguous, and its dtype must be the dtype that would be returned for dot(a,b). This is a performance feature. Therefore, if these conditions are not met, an exception is raised, instead of attempting to be flexible.", "New in version 1.10.2.", "See also", "Equivalent function for ndarrays."]}, {"name": "ma.dstack()", "path": "reference/generated/numpy.ma.dstack", "type": "numpy.ma.dstack", "text": ["Stack arrays in sequence depth wise (along third axis).", "This is equivalent to concatenation along the third axis after 2-D arrays of shape (M,N) have been reshaped to (M,N,1) and 1-D arrays of shape (N,) have been reshaped to (1,N,1). Rebuilds arrays divided by dsplit.", "This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions concatenate, stack and block provide more general stacking and concatenation operations.", "The arrays must have the same shape along all but the third axis. 1-D or 2-D arrays must have the same shape.", "The array formed by stacking the given arrays, will be at least 3-D.", "See also", "Join a sequence of arrays along an existing axis.", "Join a sequence of arrays along a new axis.", "Assemble an nd-array from nested lists of blocks.", "Stack arrays in sequence vertically (row wise).", "Stack arrays in sequence horizontally (column wise).", "Stack 1-D arrays as columns into a 2-D array.", "Split array along third axis.", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.ediff1d()", "path": "reference/generated/numpy.ma.ediff1d", "type": "numpy.ma.ediff1d", "text": ["Compute the differences between consecutive elements of an array.", "This function is the equivalent of numpy.ediff1d that takes masked values into account, see numpy.ediff1d for details.", "See also", "Equivalent function for ndarrays."]}, {"name": "ma.empty()", "path": "reference/generated/numpy.ma.empty", "type": "numpy.ma.empty", "text": ["Return a new array of given shape and type, without initializing entries.", "Shape of the empty array, e.g., (2, 3) or 2.", "Desired output data-type for the array, e.g, numpy.int8. Default is numpy.float64.", "Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.", "Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.", "New in version 1.20.0.", "Array of uninitialized (arbitrary) data of the given shape, dtype, and order. Object arrays will be initialized to None.", "See also", "Return an empty array with shape and type of input.", "Return a new array setting values to one.", "Return a new array setting values to zero.", "Return a new array of given shape filled with value.", "empty, unlike zeros, does not set the array values to zero, and may therefore be marginally faster. On the other hand, it requires the user to manually set all the values in the array, and should be used with caution."]}, {"name": "ma.empty_like()", "path": "reference/generated/numpy.ma.empty_like", "type": "numpy.ma.empty_like", "text": ["Return a new array with the same shape and type as a given array.", "The shape and data-type of prototype define these same attributes of the returned array.", "Overrides the data type of the result.", "New in version 1.6.0.", "Overrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if prototype is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of prototype as closely as possible.", "New in version 1.6.0.", "If True, then the newly created array will use the sub-class type of prototype, otherwise it will be a base-class array. Defaults to True.", "Overrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions is unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.", "New in version 1.17.0.", "Array of uninitialized (arbitrary) data with the same shape and type as prototype.", "See also", "Return an array of ones with shape and type of input.", "Return an array of zeros with shape and type of input.", "Return a new array with shape of input filled with value.", "Return a new uninitialized array.", "This function does not initialize the returned array; to do that use zeros_like or ones_like instead. It may be marginally faster than the functions that do set the array values."]}, {"name": "ma.expand_dims()", "path": "reference/generated/numpy.ma.expand_dims", "type": "numpy.ma.expand_dims", "text": ["Expand the shape of an array.", "Insert a new axis that will appear at the axis position in the expanded array shape.", "Input array.", "Position in the expanded axes where the new axis (or axes) is placed.", "Deprecated since version 1.13.0: Passing an axis where axis > a.ndim will be treated as axis == a.ndim, and passing axis < -a.ndim - 1 will be treated as axis == 0. This behavior is deprecated.", "Changed in version 1.18.0: A tuple of axes is now supported. Out of range axes as described above are now forbidden and raise an AxisError.", "View of a with the number of dimensions increased.", "See also", "The inverse operation, removing singleton dimensions", "Insert, remove, and combine dimensions, and resize existing ones", "The following is equivalent to x[np.newaxis, :] or x[np.newaxis]:", "The following is equivalent to x[:, np.newaxis]:", "axis may also be a tuple:", "Note that some examples may use None instead of np.newaxis. These are the same objects:"]}, {"name": "ma.filled()", "path": "reference/generated/numpy.ma.filled", "type": "numpy.ma.filled", "text": ["Return input as an array with masked data replaced by a fill value.", "If a is not a MaskedArray, a itself is returned. If a is a MaskedArray and fill_value is None, fill_value is set to a.fill_value.", "An input object.", "Can be scalar or non-scalar. If non-scalar, the resulting filled array should be broadcastable over input array. Default is None.", "The filled array.", "See also"]}, {"name": "ma.fix_invalid()", "path": "reference/generated/numpy.ma.fix_invalid", "type": "numpy.ma.fix_invalid", "text": ["Return input with invalid data masked and replaced by a fill value.", "Invalid data means values of nan, inf, etc.", "Input array, a (subclass of) ndarray.", "Mask. Must be convertible to an array of booleans with the same shape as data. True indicates a masked (i.e. invalid) data.", "Whether to use a copy of a (True) or to fix a in place (False). Default is True.", "Value used for fixing invalid data. Default is None, in which case the a.fill_value is used.", "The input array with invalid entries fixed.", "A copy is performed by default."]}, {"name": "ma.flatnotmasked_contiguous()", "path": "reference/generated/numpy.ma.flatnotmasked_contiguous", "type": "numpy.ma.flatnotmasked_contiguous", "text": ["Find contiguous unmasked data in a masked array along the given axis.", "The input array.", "A sorted sequence of slice objects (start index, end index).", "Changed in version 1.15.0: Now returns an empty list instead of None for a fully masked array", "See also", "Only accepts 2-D arrays at most."]}, {"name": "ma.flatnotmasked_edges()", "path": "reference/generated/numpy.ma.flatnotmasked_edges", "type": "numpy.ma.flatnotmasked_edges", "text": ["Find the indices of the first and last unmasked values.", "Expects a 1-D MaskedArray, returns None if all values are masked.", "Input 1-D MaskedArray", "The indices of first and last non-masked value in the array. Returns None if all values are masked.", "See also", "Only accepts 1-D arrays."]}, {"name": "ma.frombuffer()", "path": "reference/generated/numpy.ma.frombuffer", "type": "numpy.ma.frombuffer", "text": ["Interpret a buffer as a 1-dimensional array.", "An object that exposes the buffer interface.", "Data-type of the returned array; default: float.", "Number of items to read. -1 means all data in the buffer.", "Start reading the buffer from this offset (in bytes); default: 0.", "Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.", "New in version 1.20.0.", "If the buffer has data that is not in machine byte-order, this should be specified as part of the data-type, e.g.:", "The data of the resulting array will not be byteswapped, but will be interpreted correctly."]}, {"name": "ma.fromfunction()", "path": "reference/generated/numpy.ma.fromfunction", "type": "numpy.ma.fromfunction", "text": ["Construct an array by executing a function over each coordinate.", "The resulting array therefore has a value fn(x, y, z) at coordinate (x, y, z).", "The function is called with N parameters, where N is the rank of shape. Each parameter represents the coordinates of the array varying along a specific axis. For example, if shape were (2, 2), then the parameters would be array([[0, 0], [1, 1]]) and array([[0, 1], [0, 1]])", "Shape of the output array, which also determines the shape of the coordinate arrays passed to function.", "Data-type of the coordinate arrays passed to function. By default, dtype is float.", "Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.", "New in version 1.20.0.", "The result of the call to function is passed back directly. Therefore the shape of fromfunction is completely determined by function. If function returns a scalar value, the shape of fromfunction would not match the shape parameter.", "See also", "Keywords other than dtype are passed to function."]}, {"name": "ma.getdata()", "path": "reference/generated/numpy.ma.getdata", "type": "numpy.ma.getdata", "text": ["Return the data of a masked array as an ndarray.", "Return the data of a (if any) as an ndarray if a is a MaskedArray, else return a as a ndarray or subclass (depending on subok) if not.", "Input MaskedArray, alternatively a ndarray or a subclass thereof.", "Whether to force the output to be a pure ndarray (False) or to return a subclass of ndarray if appropriate (True, default).", "See also", "Return the mask of a masked array, or nomask.", "Return the mask of a masked array, or full array of False.", "Equivalently use the MaskedArray data attribute."]}, {"name": "ma.getmask()", "path": "reference/generated/numpy.ma.getmask", "type": "numpy.ma.getmask", "text": ["Return the mask of a masked array, or nomask.", "Return the mask of a as an ndarray if a is a MaskedArray and the mask is not nomask, else return nomask. To guarantee a full array of booleans of the same shape as a, use getmaskarray.", "Input MaskedArray for which the mask is required.", "See also", "Return the data of a masked array as an ndarray.", "Return the mask of a masked array, or full array of False.", "Equivalently use the MaskedArray mask attribute.", "Result when mask == nomask"]}, {"name": "ma.getmaskarray()", "path": "reference/generated/numpy.ma.getmaskarray", "type": "numpy.ma.getmaskarray", "text": ["Return the mask of a masked array, or full boolean array of False.", "Return the mask of arr as an ndarray if arr is a MaskedArray and the mask is not nomask, else return a full boolean array of False of the same shape as arr.", "Input MaskedArray for which the mask is required.", "See also", "Return the mask of a masked array, or nomask.", "Return the data of a masked array as an ndarray.", "Result when mask == nomask"]}, {"name": "ma.harden_mask()", "path": "reference/generated/numpy.ma.harden_mask", "type": "numpy.ma.harden_mask", "text": ["Force the mask to hard.", "Whether the mask of a masked array is hard or soft is determined by its hardmask property. harden_mask sets hardmask to True.", "See also"]}, {"name": "ma.hsplit()", "path": "reference/generated/numpy.ma.hsplit", "type": "numpy.ma.hsplit", "text": ["Split an array into multiple sub-arrays horizontally (column-wise).", "Please refer to the split documentation. hsplit is equivalent to split with axis=1, the array is always split along the second axis regardless of the array dimension.", "See also", "Split an array into multiple sub-arrays of equal size.", "The function is applied to both the _data and the _mask, if any.", "With a higher dimensional array the split is still along the second axis."]}, {"name": "ma.hstack()", "path": "reference/generated/numpy.ma.hstack", "type": "numpy.ma.hstack", "text": ["Stack arrays in sequence horizontally (column wise).", "This is equivalent to concatenation along the second axis, except for 1-D arrays where it concatenates along the first axis. Rebuilds arrays divided by hsplit.", "This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions concatenate, stack and block provide more general stacking and concatenation operations.", "The arrays must have the same shape along all but the second axis, except 1-D arrays which can be any length.", "The array formed by stacking the given arrays.", "See also", "Join a sequence of arrays along an existing axis.", "Join a sequence of arrays along a new axis.", "Assemble an nd-array from nested lists of blocks.", "Stack arrays in sequence vertically (row wise).", "Stack arrays in sequence depth wise (along third axis).", "Stack 1-D arrays as columns into a 2-D array.", "Split an array into multiple sub-arrays horizontally (column-wise).", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.identity()", "path": "reference/generated/numpy.ma.identity", "type": "numpy.ma.identity", "text": ["Return the identity array.", "The identity array is a square array with ones on the main diagonal.", "Number of rows (and columns) in n x n output.", "Data-type of the output. Defaults to float.", "Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.", "New in version 1.20.0.", "n x n array with its main diagonal set to one, and all other elements 0."]}, {"name": "ma.indices()", "path": "reference/generated/numpy.ma.indices", "type": "numpy.ma.indices", "text": ["Return an array representing the indices of a grid.", "Compute an array where the subarrays contain index values 0, 1, \u2026 varying only along the corresponding axis.", "The shape of the grid.", "Data type of the result.", "Return a sparse representation of the grid instead of a dense representation. Default is False.", "New in version 1.17.", "Returns one array of grid indices, grid.shape = (len(dimensions),) + tuple(dimensions).", "Returns a tuple of arrays, with grid[i].shape = (1, ..., 1, dimensions[i], 1, ..., 1) with dimensions[i] in the ith place", "See also", "The output shape in the dense case is obtained by prepending the number of dimensions in front of the tuple of dimensions, i.e. if dimensions is a tuple (r0, ..., rN-1) of length N, the output shape is (N, r0, ..., rN-1).", "The subarrays grid[k] contains the N-D array of indices along the k-th axis. Explicitly:", "The indices can be used as an index into an array.", "Note that it would be more straightforward in the above example to extract the required elements directly with x[:2, :3].", "If sparse is set to true, the grid will be returned in a sparse representation."]}, {"name": "ma.inner()", "path": "reference/generated/numpy.ma.inner", "type": "numpy.ma.inner", "text": ["Inner product of two arrays.", "Ordinary inner product of vectors for 1-D arrays (without complex conjugation), in higher dimensions a sum product over the last axes.", "If a and b are nonscalar, their last dimensions must match.", "If a and b are both scalars or both 1-D arrays then a scalar is returned; otherwise an array is returned. out.shape = (*a.shape[:-1], *b.shape[:-1])", "If both a and b are nonscalar and their last dimensions have different sizes.", "See also", "Sum products over arbitrary axes.", "Generalised matrix product, using second last dimension of b.", "Einstein summation convention.", "Masked values are replaced by 0.", "For vectors (1-D arrays) it computes the ordinary inner-product:", "More generally, if ndim(a) = r > 0 and ndim(b) = s > 0:", "or explicitly:", "In addition a or b may be scalars, in which case:", "Ordinary inner product for vectors:", "Some multidimensional examples:", "An example where b is a scalar:"]}, {"name": "ma.innerproduct()", "path": "reference/generated/numpy.ma.innerproduct", "type": "numpy.ma.innerproduct", "text": ["Inner product of two arrays.", "Ordinary inner product of vectors for 1-D arrays (without complex conjugation), in higher dimensions a sum product over the last axes.", "If a and b are nonscalar, their last dimensions must match.", "If a and b are both scalars or both 1-D arrays then a scalar is returned; otherwise an array is returned. out.shape = (*a.shape[:-1], *b.shape[:-1])", "If both a and b are nonscalar and their last dimensions have different sizes.", "See also", "Sum products over arbitrary axes.", "Generalised matrix product, using second last dimension of b.", "Einstein summation convention.", "Masked values are replaced by 0.", "For vectors (1-D arrays) it computes the ordinary inner-product:", "More generally, if ndim(a) = r > 0 and ndim(b) = s > 0:", "or explicitly:", "In addition a or b may be scalars, in which case:", "Ordinary inner product for vectors:", "Some multidimensional examples:", "An example where b is a scalar:"]}, {"name": "ma.is_mask()", "path": "reference/generated/numpy.ma.is_mask", "type": "numpy.ma.is_mask", "text": ["Return True if m is a valid, standard mask.", "This function does not check the contents of the input, only that the type is MaskType. In particular, this function returns False if the mask has a flexible dtype.", "Array to test.", "True if m.dtype.type is MaskType, False otherwise.", "See also", "Test whether input is an instance of MaskedArray.", "Input must be an ndarray (or have similar attributes) for it to be considered a valid mask.", "Arrays with complex dtypes don\u2019t return True."]}, {"name": "ma.is_masked()", "path": "reference/generated/numpy.ma.is_masked", "type": "numpy.ma.is_masked", "text": ["Determine whether input has masked values.", "Accepts any object as input, but always returns False unless the input is a MaskedArray containing masked values.", "Array to check for masked values.", "True if x is a MaskedArray with masked values, False otherwise.", "Always returns False if x isn\u2019t a MaskedArray."]}, {"name": "ma.isarray()", "path": "reference/generated/numpy.ma.isarray", "type": "numpy.ma.isarray", "text": ["Test whether input is an instance of MaskedArray.", "This function returns True if x is an instance of MaskedArray and returns False otherwise. Any object is accepted as input.", "Object to test.", "True if x is a MaskedArray.", "See also", "Alias to isMaskedArray.", "Alias to isMaskedArray."]}, {"name": "ma.isMA()", "path": "reference/generated/numpy.ma.isma", "type": "numpy.ma.isMA", "text": ["Test whether input is an instance of MaskedArray.", "This function returns True if x is an instance of MaskedArray and returns False otherwise. Any object is accepted as input.", "Object to test.", "True if x is a MaskedArray.", "See also", "Alias to isMaskedArray.", "Alias to isMaskedArray."]}, {"name": "ma.isMaskedArray()", "path": "reference/generated/numpy.ma.ismaskedarray", "type": "numpy.ma.isMaskedArray", "text": ["Test whether input is an instance of MaskedArray.", "This function returns True if x is an instance of MaskedArray and returns False otherwise. Any object is accepted as input.", "Object to test.", "True if x is a MaskedArray.", "See also", "Alias to isMaskedArray.", "Alias to isMaskedArray."]}, {"name": "ma.make_mask()", "path": "reference/generated/numpy.ma.make_mask", "type": "numpy.ma.make_mask", "text": ["Create a boolean mask from an array.", "Return m as a boolean mask, creating a copy if necessary or requested. The function can accept any sequence that is convertible to integers, or nomask. Does not require that contents must be 0s and 1s, values of 0 are interpreted as False, everything else as True.", "Potential mask.", "Whether to return a copy of m (True) or m itself (False).", "Whether to shrink m to nomask if all its values are False.", "Data-type of the output mask. By default, the output mask has a dtype of MaskType (bool). If the dtype is flexible, each field has a boolean dtype. This is ignored when m is nomask, in which case nomask is always returned.", "A boolean mask derived from m.", "Effect of the shrink parameter.", "Using a flexible dtype."]}, {"name": "ma.make_mask_descr()", "path": "reference/generated/numpy.ma.make_mask_descr", "type": "numpy.ma.make_mask_descr", "text": ["Construct a dtype description list from a given dtype.", "Returns a new dtype object, with the type of all fields in ndtype to a boolean type. Field names are not altered.", "The dtype to convert.", "A dtype that looks like ndtype, the type of all fields is boolean."]}, {"name": "ma.make_mask_none()", "path": "reference/generated/numpy.ma.make_mask_none", "type": "numpy.ma.make_mask_none", "text": ["Return a boolean mask of the given shape, filled with False.", "This function returns a boolean ndarray with all entries False, that can be used in common mask manipulations. If a complex dtype is specified, the type of each field is converted to a boolean type.", "A tuple indicating the shape of the mask.", "If None, use a MaskType instance. Otherwise, use a new datatype with the same fields as dtype, converted to boolean types.", "An ndarray of appropriate shape and dtype, filled with False.", "See also", "Create a boolean mask from an array.", "Construct a dtype description list from a given dtype.", "Defining a more complex dtype."]}, {"name": "ma.mask_cols()", "path": "reference/generated/numpy.ma.mask_cols", "type": "numpy.ma.mask_cols", "text": ["Mask columns of a 2D array that contain masked values.", "This function is a shortcut to mask_rowcols with axis equal to 1.", "See also", "Mask rows and/or columns of a 2D array.", "Mask where a condition is met."]}, {"name": "ma.mask_or()", "path": "reference/generated/numpy.ma.mask_or", "type": "numpy.ma.mask_or", "text": ["Combine two masks with the logical_or operator.", "The result may be a view on m1 or m2 if the other is nomask (i.e. False).", "Input masks.", "If copy is False and one of the inputs is nomask, return a view of the other input mask. Defaults to False.", "Whether to shrink the output to nomask if all its values are False. Defaults to True.", "The result masks values that are masked in either m1 or m2.", "If m1 and m2 have different flexible dtypes."]}, {"name": "ma.mask_rowcols()", "path": "reference/generated/numpy.ma.mask_rowcols", "type": "numpy.ma.mask_rowcols", "text": ["Mask rows and/or columns of a 2D array that contain masked values.", "Mask whole rows and/or columns of a 2D array that contain masked values. The masking behavior is selected using the axis parameter.", "The array to mask. If not a MaskedArray instance (or if no array elements are masked). The result is a MaskedArray with mask set to nomask (False). Must be a 2D array.", "Axis along which to perform the operation. If None, applies to a flattened version of the array.", "A modified version of the input array, masked depending on the value of the axis parameter.", "If input array a is not 2D.", "See also", "Mask rows of a 2D array that contain masked values.", "Mask cols of a 2D array that contain masked values.", "Mask where a condition is met.", "The input array\u2019s mask is modified by this function."]}, {"name": "ma.mask_rows()", "path": "reference/generated/numpy.ma.mask_rows", "type": "numpy.ma.mask_rows", "text": ["Mask rows of a 2D array that contain masked values.", "This function is a shortcut to mask_rowcols with axis equal to 0.", "See also", "Mask rows and/or columns of a 2D array.", "Mask where a condition is met."]}, {"name": "ma.masked_all()", "path": "reference/generated/numpy.ma.masked_all", "type": "numpy.ma.masked_all", "text": ["Empty masked array with all elements masked.", "Return an empty masked array of the given shape and dtype, where all the data are masked.", "Shape of the required MaskedArray.", "Data type of the output.", "A masked array with all data masked.", "See also", "Empty masked array modelled on an existing array.", "The dtype parameter defines the underlying data type."]}, {"name": "ma.masked_all_like()", "path": "reference/generated/numpy.ma.masked_all_like", "type": "numpy.ma.masked_all_like", "text": ["Empty masked array with the properties of an existing array.", "Return an empty masked array of the same shape and dtype as the array arr, where all the data are masked.", "An array describing the shape and dtype of the required MaskedArray.", "A masked array with all data masked.", "If arr doesn\u2019t have a shape attribute (i.e. not an ndarray)", "See also", "Empty masked array with all elements masked.", "The dtype of the masked array matches the dtype of arr."]}, {"name": "ma.masked_equal()", "path": "reference/generated/numpy.ma.masked_equal", "type": "numpy.ma.masked_equal", "text": ["Mask an array where equal to a given value.", "This function is a shortcut to masked_where, with condition = (x == value). For floating point arrays, consider using masked_values(x, value).", "See also", "Mask where a condition is met.", "Mask using floating point equality."]}, {"name": "ma.masked_greater()", "path": "reference/generated/numpy.ma.masked_greater", "type": "numpy.ma.masked_greater", "text": ["Mask an array where greater than a given value.", "This function is a shortcut to masked_where, with condition = (x > value).", "See also", "Mask where a condition is met."]}, {"name": "ma.masked_greater_equal()", "path": "reference/generated/numpy.ma.masked_greater_equal", "type": "numpy.ma.masked_greater_equal", "text": ["Mask an array where greater than or equal to a given value.", "This function is a shortcut to masked_where, with condition = (x >= value).", "See also", "Mask where a condition is met."]}, {"name": "ma.masked_inside()", "path": "reference/generated/numpy.ma.masked_inside", "type": "numpy.ma.masked_inside", "text": ["Mask an array inside a given interval.", "Shortcut to masked_where, where condition is True for x inside the interval [v1,v2] (v1 <= x <= v2). The boundaries v1 and v2 can be given in either order.", "See also", "Mask where a condition is met.", "The array x is prefilled with its filling value.", "The order of v1 and v2 doesn\u2019t matter."]}, {"name": "ma.masked_invalid()", "path": "reference/generated/numpy.ma.masked_invalid", "type": "numpy.ma.masked_invalid", "text": ["Mask an array where invalid values occur (NaNs or infs).", "This function is a shortcut to masked_where, with condition = ~(np.isfinite(a)). Any pre-existing mask is conserved. Only applies to arrays with a dtype where NaNs or infs make sense (i.e. floating point types), but accepts any array_like object.", "See also", "Mask where a condition is met."]}, {"name": "ma.masked_less()", "path": "reference/generated/numpy.ma.masked_less", "type": "numpy.ma.masked_less", "text": ["Mask an array where less than a given value.", "This function is a shortcut to masked_where, with condition = (x < value).", "See also", "Mask where a condition is met."]}, {"name": "ma.masked_less_equal()", "path": "reference/generated/numpy.ma.masked_less_equal", "type": "numpy.ma.masked_less_equal", "text": ["Mask an array where less than or equal to a given value.", "This function is a shortcut to masked_where, with condition = (x <= value).", "See also", "Mask where a condition is met."]}, {"name": "ma.masked_not_equal()", "path": "reference/generated/numpy.ma.masked_not_equal", "type": "numpy.ma.masked_not_equal", "text": ["Mask an array where not equal to a given value.", "This function is a shortcut to masked_where, with condition = (x != value).", "See also", "Mask where a condition is met."]}, {"name": "ma.masked_object()", "path": "reference/generated/numpy.ma.masked_object", "type": "numpy.ma.masked_object", "text": ["Mask the array x where the data are exactly equal to value.", "This function is similar to masked_values, but only suitable for object arrays: for floating point, use masked_values instead.", "Array to mask", "Comparison value", "Whether to return a copy of x.", "Whether to collapse a mask full of False to nomask", "The result of masking x where equal to value.", "See also", "Mask where a condition is met.", "Mask where equal to a given value (integers).", "Mask using floating point equality.", "Note that mask is set to nomask if possible."]}, {"name": "ma.masked_outside()", "path": "reference/generated/numpy.ma.masked_outside", "type": "numpy.ma.masked_outside", "text": ["Mask an array outside a given interval.", "Shortcut to masked_where, where condition is True for x outside the interval [v1,v2] (x < v1)|(x > v2). The boundaries v1 and v2 can be given in either order.", "See also", "Mask where a condition is met.", "The array x is prefilled with its filling value.", "The order of v1 and v2 doesn\u2019t matter."]}, {"name": "ma.masked_values()", "path": "reference/generated/numpy.ma.masked_values", "type": "numpy.ma.masked_values", "text": ["Mask using floating point equality.", "Return a MaskedArray, masked where the data in array x are approximately equal to value, determined using isclose. The default tolerances for masked_values are the same as those for isclose.", "For integer types, exact equality is used, in the same way as masked_equal.", "The fill_value is set to value and the mask is set to nomask if possible.", "Array to mask.", "Masking value.", "Tolerance parameters passed on to isclose", "Whether to return a copy of x.", "Whether to collapse a mask full of False to nomask.", "The result of masking x where approximately equal to value.", "See also", "Mask where a condition is met.", "Mask where equal to a given value (integers).", "Note that mask is set to nomask if possible.", "For integers, the fill value will be different in general to the result of masked_equal."]}, {"name": "ma.masked_where()", "path": "reference/generated/numpy.ma.masked_where", "type": "numpy.ma.masked_where", "text": ["Mask an array where a condition is met.", "Return a as an array masked where condition is True. Any masked values of a or condition are also masked in the output.", "Masking condition. When condition tests floating point values for equality, consider using masked_values instead.", "Array to mask.", "If True (default) make a copy of a in the result. If False modify a in place and return a view.", "The result of masking a where condition is True.", "See also", "Mask using floating point equality.", "Mask where equal to a given value.", "Mask where not equal to a given value.", "Mask where less than or equal to a given value.", "Mask where greater than or equal to a given value.", "Mask where less than a given value.", "Mask where greater than a given value.", "Mask inside a given interval.", "Mask outside a given interval.", "Mask invalid values (NaNs or infs).", "Mask array b conditional on a.", "Effect of the copy argument.", "When condition or a contain masked values."]}, {"name": "ma.MaskedArray.__abs__()", "path": "reference/generated/numpy.ma.maskedarray.__abs__", "type": "Masked arrays", "text": ["method"]}, {"name": "ma.MaskedArray.__add__()", "path": "reference/generated/numpy.ma.maskedarray.__add__", "type": "Masked arrays", "text": ["method", "Add self to other, and return a new masked array."]}, {"name": "ma.MaskedArray.__and__()", "path": "reference/generated/numpy.ma.maskedarray.__and__", "type": "Masked arrays", "text": ["method", "Return self&value."]}, {"name": "ma.MaskedArray.__array__()", "path": "reference/generated/numpy.ma.maskedarray.__array__", "type": "Masked arrays", "text": ["method", "Returns either a new reference to self if dtype is not given or a new array of provided data type if dtype is different from the current dtype of the array."]}, {"name": "ma.MaskedArray.__array_priority__", "path": "reference/generated/numpy.ma.maskedarray.__array_priority__", "type": "Masked arrays", "text": ["attribute"]}, {"name": "ma.MaskedArray.__array_wrap__()", "path": "reference/generated/numpy.ma.maskedarray.__array_wrap__", "type": "Masked arrays", "text": ["method", "Special hook for ufuncs.", "Wraps the numpy array and sets the mask according to context."]}, {"name": "ma.MaskedArray.__bool__()", "path": "reference/generated/numpy.ma.maskedarray.__bool__", "type": "Masked arrays", "text": ["method", "self != 0"]}, {"name": "ma.MaskedArray.__contains__()", "path": "reference/generated/numpy.ma.maskedarray.__contains__", "type": "Masked arrays", "text": ["method", "Return key in self."]}, {"name": "ma.MaskedArray.__copy__()", "path": "reference/generated/numpy.ma.maskedarray.__copy__", "type": "Masked arrays", "text": ["method", "Used if copy.copy is called on an array. Returns a copy of the array.", "Equivalent to a.copy(order='K')."]}, {"name": "ma.MaskedArray.__deepcopy__()", "path": "reference/generated/numpy.ma.maskedarray.__deepcopy__", "type": "Masked arrays", "text": ["method", "Used if copy.deepcopy is called on an array."]}, {"name": "ma.MaskedArray.__delitem__()", "path": "reference/generated/numpy.ma.maskedarray.__delitem__", "type": "Masked arrays", "text": ["method", "Delete self[key]."]}, {"name": "ma.MaskedArray.__div__()", "path": "reference/generated/numpy.ma.maskedarray.__div__", "type": "Masked arrays", "text": ["method", "Divide other into self, and return a new masked array."]}, {"name": "ma.MaskedArray.__divmod__()", "path": "reference/generated/numpy.ma.maskedarray.__divmod__", "type": "Masked arrays", "text": ["method", "Return divmod(self, value)."]}, {"name": "ma.MaskedArray.__eq__()", "path": "reference/generated/numpy.ma.maskedarray.__eq__", "type": "Masked arrays", "text": ["method", "Check whether other equals self elementwise.", "When either of the elements is masked, the result is masked as well, but the underlying boolean data are still set, with self and other considered equal if both are masked, and unequal otherwise.", "For structured arrays, all fields are combined, with masked values ignored. The result is masked if all fields were masked, with self and other considered equal only if both were fully masked."]}, {"name": "ma.MaskedArray.__float__()", "path": "reference/generated/numpy.ma.maskedarray.__float__", "type": "Masked arrays", "text": ["method", "Convert to float."]}, {"name": "ma.MaskedArray.__floordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__floordiv__", "type": "Masked arrays", "text": ["method", "Divide other into self, and return a new masked array."]}, {"name": "ma.MaskedArray.__ge__()", "path": "reference/generated/numpy.ma.maskedarray.__ge__", "type": "Masked arrays", "text": ["method", "Return self>=value."]}, {"name": "ma.MaskedArray.__getitem__()", "path": "reference/generated/numpy.ma.maskedarray.__getitem__", "type": "Masked arrays", "text": ["method", "x.__getitem__(y) <==> x[y]", "Return the item described by i, as a masked array."]}, {"name": "ma.MaskedArray.__getstate__()", "path": "reference/generated/numpy.ma.maskedarray.__getstate__", "type": "Masked arrays", "text": ["method", "Return the internal state of the masked array, for pickling purposes."]}, {"name": "ma.MaskedArray.__gt__()", "path": "reference/generated/numpy.ma.maskedarray.__gt__", "type": "Masked arrays", "text": ["method", "Return self>value."]}, {"name": "ma.MaskedArray.__iadd__()", "path": "reference/generated/numpy.ma.maskedarray.__iadd__", "type": "Masked arrays", "text": ["method", "Add other to self in-place."]}, {"name": "ma.MaskedArray.__iand__()", "path": "reference/generated/numpy.ma.maskedarray.__iand__", "type": "Masked arrays", "text": ["method", "Return self&=value."]}, {"name": "ma.MaskedArray.__idiv__()", "path": "reference/generated/numpy.ma.maskedarray.__idiv__", "type": "Masked arrays", "text": ["method", "Divide self by other in-place."]}, {"name": "ma.MaskedArray.__ifloordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__ifloordiv__", "type": "Masked arrays", "text": ["method", "Floor divide self by other in-place."]}, {"name": "ma.MaskedArray.__ilshift__()", "path": "reference/generated/numpy.ma.maskedarray.__ilshift__", "type": "Masked arrays", "text": ["method", "Return self<<=value."]}, {"name": "ma.MaskedArray.__imod__()", "path": "reference/generated/numpy.ma.maskedarray.__imod__", "type": "Masked arrays", "text": ["method", "Return self%=value."]}, {"name": "ma.MaskedArray.__imul__()", "path": "reference/generated/numpy.ma.maskedarray.__imul__", "type": "Masked arrays", "text": ["method", "Multiply self by other in-place."]}, {"name": "ma.MaskedArray.__int__()", "path": "reference/generated/numpy.ma.maskedarray.__int__", "type": "Masked arrays", "text": ["method", "Convert to int."]}, {"name": "ma.MaskedArray.__ior__()", "path": "reference/generated/numpy.ma.maskedarray.__ior__", "type": "Masked arrays", "text": ["method", "Return self|=value."]}, {"name": "ma.MaskedArray.__ipow__()", "path": "reference/generated/numpy.ma.maskedarray.__ipow__", "type": "Masked arrays", "text": ["method", "Raise self to the power other, in place."]}, {"name": "ma.MaskedArray.__irshift__()", "path": "reference/generated/numpy.ma.maskedarray.__irshift__", "type": "Masked arrays", "text": ["method", "Return self>>=value."]}, {"name": "ma.MaskedArray.__isub__()", "path": "reference/generated/numpy.ma.maskedarray.__isub__", "type": "Masked arrays", "text": ["method", "Subtract other from self in-place."]}, {"name": "ma.MaskedArray.__itruediv__()", "path": "reference/generated/numpy.ma.maskedarray.__itruediv__", "type": "Masked arrays", "text": ["method", "True divide self by other in-place."]}, {"name": "ma.MaskedArray.__ixor__()", "path": "reference/generated/numpy.ma.maskedarray.__ixor__", "type": "Masked arrays", "text": ["method", "Return self^=value."]}, {"name": "ma.MaskedArray.__le__()", "path": "reference/generated/numpy.ma.maskedarray.__le__", "type": "Masked arrays", "text": ["method", "Return self<=value."]}, {"name": "ma.MaskedArray.__len__()", "path": "reference/generated/numpy.ma.maskedarray.__len__", "type": "Masked arrays", "text": ["method", "Return len(self)."]}, {"name": "ma.MaskedArray.__lshift__()", "path": "reference/generated/numpy.ma.maskedarray.__lshift__", "type": "Masked arrays", "text": ["method", "Return self<<value."]}, {"name": "ma.MaskedArray.__lt__()", "path": "reference/generated/numpy.ma.maskedarray.__lt__", "type": "Masked arrays", "text": ["method", "Return self<value."]}, {"name": "ma.MaskedArray.__mod__()", "path": "reference/generated/numpy.ma.maskedarray.__mod__", "type": "Masked arrays", "text": ["method", "Return self%value."]}, {"name": "ma.MaskedArray.__mul__()", "path": "reference/generated/numpy.ma.maskedarray.__mul__", "type": "Masked arrays", "text": ["method", "Multiply self by other, and return a new masked array."]}, {"name": "ma.MaskedArray.__ne__()", "path": "reference/generated/numpy.ma.maskedarray.__ne__", "type": "Masked arrays", "text": ["method", "Check whether other does not equal self elementwise.", "When either of the elements is masked, the result is masked as well, but the underlying boolean data are still set, with self and other considered equal if both are masked, and unequal otherwise.", "For structured arrays, all fields are combined, with masked values ignored. The result is masked if all fields were masked, with self and other considered equal only if both were fully masked."]}, {"name": "ma.MaskedArray.__or__()", "path": "reference/generated/numpy.ma.maskedarray.__or__", "type": "Masked arrays", "text": ["method", "Return self|value."]}, {"name": "ma.MaskedArray.__pow__()", "path": "reference/generated/numpy.ma.maskedarray.__pow__", "type": "Masked arrays", "text": ["method", "Raise self to the power other, masking the potential NaNs/Infs"]}, {"name": "ma.MaskedArray.__radd__()", "path": "reference/generated/numpy.ma.maskedarray.__radd__", "type": "Masked arrays", "text": ["method", "Add other to self, and return a new masked array."]}, {"name": "ma.MaskedArray.__rand__()", "path": "reference/generated/numpy.ma.maskedarray.__rand__", "type": "Masked arrays", "text": ["method", "Return value&self."]}, {"name": "ma.MaskedArray.__rdivmod__()", "path": "reference/generated/numpy.ma.maskedarray.__rdivmod__", "type": "Masked arrays", "text": ["method", "Return divmod(value, self)."]}, {"name": "ma.MaskedArray.__reduce__()", "path": "reference/generated/numpy.ma.maskedarray.__reduce__", "type": "Masked arrays", "text": ["method", "Return a 3-tuple for pickling a MaskedArray."]}, {"name": "ma.MaskedArray.__repr__()", "path": "reference/generated/numpy.ma.maskedarray.__repr__", "type": "Masked arrays", "text": ["method", "Literal string representation."]}, {"name": "ma.MaskedArray.__rfloordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__rfloordiv__", "type": "Masked arrays", "text": ["method", "Divide self into other, and return a new masked array."]}, {"name": "ma.MaskedArray.__rlshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rlshift__", "type": "Masked arrays", "text": ["method", "Return value<<self."]}, {"name": "ma.MaskedArray.__rmod__()", "path": "reference/generated/numpy.ma.maskedarray.__rmod__", "type": "Masked arrays", "text": ["method", "Return value%self."]}, {"name": "ma.MaskedArray.__rmul__()", "path": "reference/generated/numpy.ma.maskedarray.__rmul__", "type": "Masked arrays", "text": ["method", "Multiply other by self, and return a new masked array."]}, {"name": "ma.MaskedArray.__ror__()", "path": "reference/generated/numpy.ma.maskedarray.__ror__", "type": "Masked arrays", "text": ["method", "Return value|self."]}, {"name": "ma.MaskedArray.__rpow__()", "path": "reference/generated/numpy.ma.maskedarray.__rpow__", "type": "Masked arrays", "text": ["method", "Raise other to the power self, masking the potential NaNs/Infs"]}, {"name": "ma.MaskedArray.__rrshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rrshift__", "type": "Masked arrays", "text": ["method", "Return value>>self."]}, {"name": "ma.MaskedArray.__rshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rshift__", "type": "Masked arrays", "text": ["method", "Return self>>value."]}, {"name": "ma.MaskedArray.__rsub__()", "path": "reference/generated/numpy.ma.maskedarray.__rsub__", "type": "Masked arrays", "text": ["method", "Subtract self from other, and return a new masked array."]}, {"name": "ma.MaskedArray.__rtruediv__()", "path": "reference/generated/numpy.ma.maskedarray.__rtruediv__", "type": "Masked arrays", "text": ["method", "Divide self into other, and return a new masked array."]}, {"name": "ma.MaskedArray.__rxor__()", "path": "reference/generated/numpy.ma.maskedarray.__rxor__", "type": "Masked arrays", "text": ["method", "Return value^self."]}, {"name": "ma.MaskedArray.__setitem__()", "path": "reference/generated/numpy.ma.maskedarray.__setitem__", "type": "Masked arrays", "text": ["method", "x.__setitem__(i, y) <==> x[i]=y", "Set item described by index. If value is masked, masks those locations."]}, {"name": "ma.MaskedArray.__setmask__()", "path": "reference/generated/numpy.ma.maskedarray.__setmask__", "type": "Masked arrays", "text": ["method", "Set the mask."]}, {"name": "ma.MaskedArray.__setstate__()", "path": "reference/generated/numpy.ma.maskedarray.__setstate__", "type": "Masked arrays", "text": ["method", "Restore the internal state of the masked array, for pickling purposes. state is typically the output of the __getstate__ output, and is a 5-tuple:"]}, {"name": "ma.MaskedArray.__str__()", "path": "reference/generated/numpy.ma.maskedarray.__str__", "type": "Masked arrays", "text": ["method", "Return str(self)."]}, {"name": "ma.MaskedArray.__sub__()", "path": "reference/generated/numpy.ma.maskedarray.__sub__", "type": "Masked arrays", "text": ["method", "Subtract other from self, and return a new masked array."]}, {"name": "ma.MaskedArray.__truediv__()", "path": "reference/generated/numpy.ma.maskedarray.__truediv__", "type": "Masked arrays", "text": ["method", "Divide other into self, and return a new masked array."]}, {"name": "ma.MaskedArray.__xor__()", "path": "reference/generated/numpy.ma.maskedarray.__xor__", "type": "Masked arrays", "text": ["method", "Return self^value."]}, {"name": "ma.MaskedArray.all()", "path": "reference/generated/numpy.ma.maskedarray.all", "type": "numpy.ma.MaskedArray.all", "text": ["method", "Returns True if all elements evaluate to True.", "The output array is masked where all the values along the given axis are masked: if the output would have been a scalar and that all the values are masked, then the output is masked.", "Refer to numpy.all for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function"]}, {"name": "ma.MaskedArray.anom()", "path": "reference/generated/numpy.ma.maskedarray.anom", "type": "numpy.ma.MaskedArray.anom", "text": ["method", "Compute the anomalies (deviations from the arithmetic mean) along the given axis.", "Returns an array of anomalies, with the same shape as the input and where the arithmetic mean is computed along the given axis.", "Axis over which the anomalies are taken. The default is to use the mean of the flattened array as reference.", "the default is float32; for arrays of float types it is the same as the array type.", "See also", "Compute the mean of the array."]}, {"name": "ma.MaskedArray.any()", "path": "reference/generated/numpy.ma.maskedarray.any", "type": "numpy.ma.MaskedArray.any", "text": ["method", "Returns True if any of the elements of a evaluate to True.", "Masked values are considered as False during computation.", "Refer to numpy.any for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function"]}, {"name": "ma.MaskedArray.argmax()", "path": "reference/generated/numpy.ma.maskedarray.argmax", "type": "numpy.ma.MaskedArray.argmax", "text": ["method", "Returns array of indices of the maximum values along the given axis. Masked values are treated as if they had the value fill_value.", "If None, the index is into the flattened array, otherwise along the specified axis", "Value used to fill in the masked values. If None, the output of maximum_fill_value(self._data) is used instead.", "Array into which the result can be placed. Its type is preserved and it must be of the right shape to hold the output."]}, {"name": "ma.MaskedArray.argmin()", "path": "reference/generated/numpy.ma.maskedarray.argmin", "type": "numpy.ma.MaskedArray.argmin", "text": ["method", "Return array of indices to the minimum values along the given axis.", "If None, the index is into the flattened array, otherwise along the specified axis", "Value used to fill in the masked values. If None, the output of minimum_fill_value(self._data) is used instead.", "Array into which the result can be placed. Its type is preserved and it must be of the right shape to hold the output.", "If multi-dimension input, returns a new ndarray of indices to the minimum values along the given axis. Otherwise, returns a scalar of index to the minimum values along the given axis."]}, {"name": "ma.MaskedArray.argsort()", "path": "reference/generated/numpy.ma.maskedarray.argsort", "type": "numpy.ma.MaskedArray.argsort", "text": ["method", "Return an ndarray of indices that sort the array along the specified axis. Masked values are filled beforehand to fill_value.", "Axis along which to sort. If None, the default, the flattened array is used.", "Changed in version 1.13.0: Previously, the default was documented to be -1, but that was in error. At some future date, the default will change to -1, as originally intended. Until then, the axis should be given explicitly when arr.ndim > 1, to avoid a FutureWarning.", "The sorting algorithm used.", "When a is an array with fields defined, this argument specifies which fields to compare first, second, etc. Not all fields need be specified.", "Whether missing values (if any) should be treated as the largest values (True) or the smallest values (False) When the array contains unmasked values at the same extremes of the datatype, the ordering of these values and the masked values is undefined.", "Value used internally for the masked values. If fill_value is not None, it supersedes endwith.", "Array of indices that sort a along the specified axis. In other words, a[index_array] yields a sorted a.", "See also", "Describes sorting algorithms used.", "Indirect stable sort with multiple keys.", "Inplace sort.", "See sort for notes on the different sorting algorithms."]}, {"name": "ma.MaskedArray.astype()", "path": "reference/generated/numpy.ma.maskedarray.astype", "type": "Masked arrays", "text": ["method", "Copy of the array, cast to a specified type.", "Typecode or data-type to which the array is cast.", "Controls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means Fortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous, \u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements appear in memory as possible. Default is \u2018K\u2019.", "Controls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for backwards compatibility.", "If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.", "By default, astype always returns a newly allocated array. If this is set to false, and the dtype, order, and subok requirements are satisfied, the input array is returned instead of a copy.", "Unless copy is False and the other conditions for returning the input array are satisfied (see description for copy input parameter), arr_t is a new array of the same shape as the input array, with dtype, order given by dtype, order.", "When casting from complex to float or int. To avoid this, one should use a.real.astype(t).", "Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is allowed, but casting from multiple fields is not.", "Changed in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019 casting mode requires that the string dtype length is long enough to store the max integer/float value converted."]}, {"name": "ma.MaskedArray.base", "path": "reference/generated/numpy.ma.maskedarray.base", "type": "Masked arrays", "text": ["attribute", "Base object if memory is from some other object.", "The base of an array that owns its memory is None:", "Slicing creates a view, whose memory is shared with x:"]}, {"name": "ma.MaskedArray.byteswap()", "path": "reference/generated/numpy.ma.maskedarray.byteswap", "type": "Masked arrays", "text": ["method", "Swap the bytes of the array elements", "Toggle between low-endian and big-endian data representation by returning a byteswapped array, optionally swapped in-place. Arrays of byte-strings are not swapped. The real and imaginary parts of a complex number are swapped individually.", "If True, swap bytes in-place, default is False.", "The byteswapped array. If inplace is True, this is a view to self.", "Arrays of byte-strings are not swapped", "but different representation in memory"]}, {"name": "ma.MaskedArray.choose()", "path": "reference/generated/numpy.ma.maskedarray.choose", "type": "Masked arrays", "text": ["method", "Use an index array to construct a new array from a set of choices.", "Refer to numpy.choose for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.clip()", "path": "reference/generated/numpy.ma.maskedarray.clip", "type": "numpy.ma.MaskedArray.clip", "text": ["method", "Return an array whose values are limited to [min, max]. One of max or min must be given.", "Refer to numpy.clip for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.compress()", "path": "reference/generated/numpy.ma.maskedarray.compress", "type": "Masked arrays", "text": ["method", "Return a where condition is True.", "If condition is a MaskedArray, missing values are considered as False.", "Boolean 1-d array selecting which entries to return. If len(condition) is less than the size of a along the axis, then output is truncated to length of condition array.", "Axis along which the operation must be performed.", "Alternative output array in which to place the result. It must have the same shape as the expected output but the type will be cast if necessary.", "A MaskedArray object.", "Please note the difference with compressed ! The output of compress has a mask, the output of compressed does not."]}, {"name": "ma.MaskedArray.compressed()", "path": "reference/generated/numpy.ma.maskedarray.compressed", "type": "numpy.ma.MaskedArray.compressed", "text": ["method", "Return all the non-masked data as a 1-D array.", "A new ndarray holding the non-masked data is returned.", "The result is not a MaskedArray!"]}, {"name": "ma.MaskedArray.conj()", "path": "reference/generated/numpy.ma.maskedarray.conj", "type": "Masked arrays", "text": ["method", "Complex-conjugate all elements.", "Refer to numpy.conjugate for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.conjugate()", "path": "reference/generated/numpy.ma.maskedarray.conjugate", "type": "Masked arrays", "text": ["method", "Return the complex conjugate, element-wise.", "Refer to numpy.conjugate for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.copy()", "path": "reference/generated/numpy.ma.maskedarray.copy", "type": "numpy.ma.MaskedArray.copy", "text": ["method", "Return a copy of the array.", "Controls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of a as closely as possible. (Note that this function and numpy.copy are very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)", "See also", "Similar function with different default behavior", "This function is the preferred method for creating an array copy. The function numpy.copy is similar, but it defaults to using order \u2018K\u2019, and will not pass sub-classes through by default."]}, {"name": "ma.MaskedArray.count()", "path": "reference/generated/numpy.ma.maskedarray.count", "type": "numpy.ma.MaskedArray.count", "text": ["method", "Count the non-masked elements of the array along the given axis.", "Axis or axes along which the count is performed. The default, None, performs the count over all the dimensions of the input array. axis may be negative, in which case it counts from the last to the first axis.", "New in version 1.10.0.", "If this is a tuple of ints, the count is performed on multiple axes, instead of a single axis or all the axes as before.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "An array with the same shape as the input array, with the specified axis removed. If the array is a 0-d array, or if axis is None, a scalar is returned.", "See also", "Count masked elements in array or along a given axis.", "When the axis keyword is specified an array of appropriate size is returned."]}, {"name": "ma.MaskedArray.ctypes", "path": "reference/generated/numpy.ma.maskedarray.ctypes", "type": "Masked arrays", "text": ["attribute", "An object to simplify the interaction of the array with the ctypes module.", "This attribute creates an object that makes it easier to use arrays when calling shared libraries with the ctypes module. The returned object has, among others, data, shape, and strides attributes (see Notes below) which themselves return ctypes objects that can be used as arguments to a shared library.", "Possessing attributes data, shape, strides, etc.", "See also", "Below are the public attributes of this object which were documented in \u201cGuide to NumPy\u201d (we have omitted undocumented public attributes, as well as documented private attributes):", "A pointer to the memory area of the array as a Python integer. This memory area may contain data that is not aligned, or not in correct byte-order. The memory area may not even be writeable. The array flags and data-type of this array should be respected when passing this attribute to arbitrary C-code to avoid trouble that can include Python crashing. User Beware! The value of this attribute is exactly the same as self._array_interface_['data'][0].", "Note that unlike data_as, a reference will not be kept to the array: code like ctypes.c_void_p((a + b).ctypes.data) will result in a pointer to a deallocated array, and should be spelt (a + b).ctypes.data_as(ctypes.c_void_p)", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the C-integer corresponding to dtype('p') on this platform (see c_intp). This base-type could be ctypes.c_int, ctypes.c_long, or ctypes.c_longlong depending on the platform. The ctypes array contains the shape of the underlying array.", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the same as for the shape attribute. This ctypes array contains the strides information from the underlying array. This strides information is important for showing how many bytes must be jumped to get to the next element in the array.", "Return the data pointer cast to a particular c-types object. For example, calling self._as_parameter_ is equivalent to self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a pointer to a ctypes array of floating-point data: self.data_as(ctypes.POINTER(ctypes.c_double)).", "The returned pointer will keep a reference to the array.", "Return the shape tuple as an array of some other c-types type. For example: self.shape_as(ctypes.c_short).", "Return the strides tuple as an array of some other c-types type. For example: self.strides_as(ctypes.c_longlong).", "If the ctypes module is not available, then the ctypes attribute of array objects still returns something useful, but ctypes objects are not returned and errors may be raised instead. In particular, the object will still have the as_parameter attribute which will return an integer equal to the data attribute."]}, {"name": "ma.MaskedArray.cumprod()", "path": "reference/generated/numpy.ma.maskedarray.cumprod", "type": "numpy.ma.MaskedArray.cumprod", "text": ["method", "Return the cumulative product of the array elements over the given axis.", "Masked values are set to 1 internally during the computation. However, their position is saved, and the result will be masked at the same locations.", "Refer to numpy.cumprod for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function", "The mask is lost if out is not a valid MaskedArray !", "Arithmetic is modular when using integer types, and no error is raised on overflow."]}, {"name": "ma.MaskedArray.cumsum()", "path": "reference/generated/numpy.ma.maskedarray.cumsum", "type": "numpy.ma.MaskedArray.cumsum", "text": ["method", "Return the cumulative sum of the array elements over the given axis.", "Masked values are set to 0 internally during the computation. However, their position is saved, and the result will be masked at the same locations.", "Refer to numpy.cumsum for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function", "The mask is lost if out is not a valid ma.MaskedArray !", "Arithmetic is modular when using integer types, and no error is raised on overflow."]}, {"name": "ma.MaskedArray.diagonal()", "path": "reference/generated/numpy.ma.maskedarray.diagonal", "type": "Masked arrays", "text": ["method", "Return specified diagonals. In NumPy 1.9 the returned array is a read-only view instead of a copy as in previous NumPy versions. In a future version the read-only restriction will be removed.", "Refer to numpy.diagonal for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.dump()", "path": "reference/generated/numpy.ma.maskedarray.dump", "type": "Masked arrays", "text": ["method", "Dump a pickle of the array to the specified file. The array can be read back with pickle.load or numpy.load.", "A string naming the dump file.", "Changed in version 1.17.0: pathlib.Path objects are now accepted."]}, {"name": "ma.MaskedArray.dumps()", "path": "reference/generated/numpy.ma.maskedarray.dumps", "type": "Masked arrays", "text": ["method", "Returns the pickle of the array as a string. pickle.loads will convert the string back to an array."]}, {"name": "ma.MaskedArray.fill()", "path": "reference/generated/numpy.ma.maskedarray.fill", "type": "Masked arrays", "text": ["method", "Fill the array with a scalar value.", "All elements of a will be assigned this value."]}, {"name": "ma.MaskedArray.filled()", "path": "reference/generated/numpy.ma.maskedarray.filled", "type": "numpy.ma.MaskedArray.filled", "text": ["method", "Return a copy of self, with masked values filled with a given value. However, if there are no masked values to fill, self will be returned instead as an ndarray.", "The value to use for invalid entries. Can be scalar or non-scalar. If non-scalar, the resulting ndarray must be broadcastable over input array. Default is None, in which case, the fill_value attribute of the array is used instead.", "A copy of self with invalid entries replaced by fill_value (be it the function argument or the attribute of self), or self itself as an ndarray if there are no invalid entries to be replaced.", "The result is not a MaskedArray!", "Subclassing is preserved. This means that if, e.g., the data part of the masked array is a recarray, filled returns a recarray:"]}, {"name": "ma.MaskedArray.flags", "path": "reference/generated/numpy.ma.maskedarray.flags", "type": "Masked arrays", "text": ["attribute", "Information about the memory layout of the array.", "The flags object can be accessed dictionary-like (as in a.flags['WRITEABLE']), or by using lowercased attribute names (as in a.flags.writeable). Short flag names are only supported in dictionary access.", "Only the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by the user, via direct assignment to the attribute or dictionary entry, or by calling ndarray.setflags.", "The array flags cannot be set arbitrarily:", "Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.", "Even for contiguous arrays a stride for a given dimension arr.strides[dim] may be arbitrary if arr.shape[dim] == 1 or the array has no elements. It does not generally hold that self.strides[-1] == self.itemsize for C-style contiguous arrays or self.strides[0] == self.itemsize for Fortran-style contiguous arrays is true.", "The data is in a single, C-style contiguous segment.", "The data is in a single, Fortran-style contiguous segment.", "The array owns the memory it uses or borrows it from another object.", "The data area can be written to. Setting this to False locks the data, making it read-only. A view (slice, etc.) inherits WRITEABLE from its base array at creation time, but a view of a writeable array may be subsequently locked while the base array remains writeable. (The opposite is not true, in that a view of a locked array may not be made writeable. However, currently, locking a base object does not lock any views that already reference it, so under that circumstance it is possible to alter the contents of a locked array via a previously created writeable view onto it.) Attempting to change a non-writeable array raises a RuntimeError exception.", "The data and all elements are aligned appropriately for the hardware.", "This array is a copy of some other array. The C-API function PyArray_ResolveWritebackIfCopy must be called before deallocating to the base array will be updated with the contents of this array.", "(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array. When this array is deallocated, the base array will be updated with the contents of this array.", "F_CONTIGUOUS and not C_CONTIGUOUS.", "F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).", "ALIGNED and WRITEABLE.", "BEHAVED and C_CONTIGUOUS.", "BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS."]}, {"name": "ma.MaskedArray.flatten()", "path": "reference/generated/numpy.ma.maskedarray.flatten", "type": "numpy.ma.MaskedArray.flatten", "text": ["method", "Return a copy of the array collapsed into one dimension.", "\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in column-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major order if a is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019 means to flatten a in the order the elements occur in memory. The default is \u2018C\u2019.", "A copy of the input array, flattened to one dimension.", "See also", "Return a flattened array.", "A 1-D flat iterator over the array."]}, {"name": "ma.MaskedArray.get_fill_value()", "path": "reference/generated/numpy.ma.maskedarray.get_fill_value", "type": "numpy.ma.MaskedArray.get_fill_value", "text": ["method", "The filling value of the masked array is a scalar. When setting, None will set to a default based on the data type.", "Reset to default:"]}, {"name": "ma.MaskedArray.harden_mask()", "path": "reference/generated/numpy.ma.maskedarray.harden_mask", "type": "numpy.ma.MaskedArray.harden_mask", "text": ["method", "Force the mask to hard.", "Whether the mask of a masked array is hard or soft is determined by its hardmask property. harden_mask sets hardmask to True.", "See also"]}, {"name": "ma.MaskedArray.ids()", "path": "reference/generated/numpy.ma.maskedarray.ids", "type": "Masked arrays", "text": ["method", "Return the addresses of the data and mask areas.", "If the array has no mask, the address of nomask is returned. This address is typically not close to the data in memory:"]}, {"name": "ma.MaskedArray.iscontiguous()", "path": "reference/generated/numpy.ma.maskedarray.iscontiguous", "type": "Masked arrays", "text": ["method", "Return a boolean indicating whether the data is contiguous.", "iscontiguous returns one of the flags of the masked array:"]}, {"name": "ma.MaskedArray.item()", "path": "reference/generated/numpy.ma.maskedarray.item", "type": "Masked arrays", "text": ["method", "Copy an element of an array to a standard Python scalar and return it.", "A copy of the specified element of the array as a suitable Python scalar", "When the data type of a is longdouble or clongdouble, item() returns a scalar array object because there is no available Python scalar that would not lose information. Void arrays return a buffer object for item(), unless fields are defined, in which case a tuple is returned.", "item is very similar to a[args], except, instead of an array scalar, a standard Python scalar is returned. This can be useful for speeding up access to elements of the array and doing arithmetic on elements of the array using Python\u2019s optimized math."]}, {"name": "ma.MaskedArray.itemsize", "path": "reference/generated/numpy.ma.maskedarray.itemsize", "type": "Masked arrays", "text": ["attribute", "Length of one array element in bytes."]}, {"name": "ma.MaskedArray.max()", "path": "reference/generated/numpy.ma.maskedarray.max", "type": "numpy.ma.MaskedArray.max", "text": ["method", "Return the maximum along a given axis.", "Axis along which to operate. By default, axis is None and the flattened input is used.", "Alternative output array in which to place the result. Must be of the same shape and buffer length as the expected output.", "Value used to fill in the masked values. If None, use the output of maximum_fill_value().", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "New array holding the result. If out was specified, out is returned.", "See also", "Returns the maximum filling value for a given datatype."]}, {"name": "ma.MaskedArray.mean()", "path": "reference/generated/numpy.ma.maskedarray.mean", "type": "numpy.ma.MaskedArray.mean", "text": ["method", "Returns the average of the array elements along given axis.", "Masked entries are ignored, and result elements which are not finite will be masked.", "Refer to numpy.mean for full documentation.", "See also", "corresponding function for ndarrays", "Equivalent function", "Weighted average."]}, {"name": "ma.MaskedArray.min()", "path": "reference/generated/numpy.ma.maskedarray.min", "type": "numpy.ma.MaskedArray.min", "text": ["method", "Return the minimum along a given axis.", "Axis along which to operate. By default, axis is None and the flattened input is used.", "Alternative output array in which to place the result. Must be of the same shape and buffer length as the expected output.", "Value used to fill in the masked values. If None, use the output of minimum_fill_value.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "New array holding the result. If out was specified, out is returned.", "See also", "Returns the minimum filling value for a given datatype."]}, {"name": "ma.MaskedArray.nbytes", "path": "reference/generated/numpy.ma.maskedarray.nbytes", "type": "Masked arrays", "text": ["attribute", "Total bytes consumed by the elements of the array.", "Does not include memory consumed by non-element attributes of the array object."]}, {"name": "ma.MaskedArray.ndim", "path": "reference/generated/numpy.ma.maskedarray.ndim", "type": "Masked arrays", "text": ["attribute", "Number of array dimensions."]}, {"name": "ma.MaskedArray.nonzero()", "path": "reference/generated/numpy.ma.maskedarray.nonzero", "type": "numpy.ma.MaskedArray.nonzero", "text": ["method", "Return the indices of unmasked elements that are not zero.", "Returns a tuple of arrays, one for each dimension, containing the indices of the non-zero elements in that dimension. The corresponding non-zero values can be obtained with:", "To group the indices by element, rather than dimension, use instead:", "The result of this is always a 2d array, with a row for each non-zero element.", "Indices of elements that are non-zero.", "See also", "Function operating on ndarrays.", "Return indices that are non-zero in the flattened version of the input array.", "Equivalent ndarray method.", "Counts the number of non-zero elements in the input array.", "Masked elements are ignored.", "Indices can also be grouped by element.", "A common use for nonzero is to find the indices of an array, where a condition is True. Given an array a, the condition a > 3 is a boolean array and since False is interpreted as 0, ma.nonzero(a > 3) yields the indices of the a where the condition is true.", "The nonzero method of the condition array can also be called."]}, {"name": "ma.MaskedArray.prod()", "path": "reference/generated/numpy.ma.maskedarray.prod", "type": "numpy.ma.MaskedArray.prod", "text": ["method", "Return the product of the array elements over the given axis.", "Masked elements are set to 1 internally for computation.", "Refer to numpy.prod for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function", "Arithmetic is modular when using integer types, and no error is raised on overflow."]}, {"name": "ma.MaskedArray.product()", "path": "reference/generated/numpy.ma.maskedarray.product", "type": "Masked arrays", "text": ["method", "Return the product of the array elements over the given axis.", "Masked elements are set to 1 internally for computation.", "Refer to numpy.prod for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function", "Arithmetic is modular when using integer types, and no error is raised on overflow."]}, {"name": "ma.MaskedArray.ptp()", "path": "reference/generated/numpy.ma.maskedarray.ptp", "type": "numpy.ma.MaskedArray.ptp", "text": ["method", "Return (maximum - minimum) along the given dimension (i.e. peak-to-peak value).", "Warning", "ptp preserves the data type of the array. This means the return value for an input of signed integers with n bits (e.g. np.int8, np.int16, etc) is also a signed integer with n bits. In that case, peak-to-peak values greater than 2**(n-1)-1 will be returned as negative values. An example with a work-around is shown below.", "Axis along which to find the peaks. If None (default) the flattened array is used.", "Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.", "Value used to fill in the masked values.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "A new array holding the result, unless out was specified, in which case a reference to out is returned.", "This example shows that a negative value can be returned when the input is an array of signed integers.", "A work-around is to use the view() method to view the result as unsigned integers with the same bit width:"]}, {"name": "ma.MaskedArray.put()", "path": "reference/generated/numpy.ma.maskedarray.put", "type": "Masked arrays", "text": ["method", "Set storage-indexed locations to corresponding values.", "Sets self._data.flat[n] = values[n] for each n in indices. If values is shorter than indices then it will repeat. If values has some masked values, the initial mask is updated in consequence, else the corresponding values are unmasked.", "Target indices, interpreted as integers.", "Values to place in self._data copy at target indices.", "Specifies how out-of-bounds indices will behave. \u2018raise\u2019 : raise an error. \u2018wrap\u2019 : wrap around. \u2018clip\u2019 : clip to the range.", "values can be a scalar or length 1 array."]}, {"name": "ma.MaskedArray.ravel()", "path": "reference/generated/numpy.ma.maskedarray.ravel", "type": "numpy.ma.MaskedArray.ravel", "text": ["method", "Returns a 1D version of self, as a view.", "The elements of a are read using this index order. \u2018C\u2019 means to index the elements in C-like order, with the last axis index changing fastest, back to the first axis index changing slowest. \u2018F\u2019 means to index the elements in Fortran-like index order, with the first index changing fastest, and the last index changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of the memory layout of the underlying array, and only refer to the order of axis indexing. \u2018A\u2019 means to read the elements in Fortran-like index order if m is Fortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the elements in the order they occur in memory, except for reversing the data when strides are negative. By default, \u2018C\u2019 index order is used.", "Output view is of shape (self.size,) (or (np.ma.product(self.shape),))."]}, {"name": "ma.MaskedArray.repeat()", "path": "reference/generated/numpy.ma.maskedarray.repeat", "type": "Masked arrays", "text": ["method", "Repeat elements of an array.", "Refer to numpy.repeat for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.reshape()", "path": "reference/generated/numpy.ma.maskedarray.reshape", "type": "numpy.ma.MaskedArray.reshape", "text": ["method", "Give a new shape to the array without changing its data.", "Returns a masked array containing the same data, but with a new shape. The result is a view on the original array; if this is not possible, a ValueError is raised.", "The new shape should be compatible with the original shape. If an integer is supplied, then the result will be a 1-D array of that length.", "Determines whether the array data should be viewed as in C (row-major) or FORTRAN (column-major) order.", "A new view on the array.", "See also", "Equivalent function in the masked array module.", "Equivalent method on ndarray object.", "Equivalent function in the NumPy module.", "The reshaping operation cannot guarantee that a copy will not be made, to modify the shape in place, use a.shape = s"]}, {"name": "ma.MaskedArray.resize()", "path": "reference/generated/numpy.ma.maskedarray.resize", "type": "numpy.ma.MaskedArray.resize", "text": ["method", "Warning", "This method does nothing, except raise a ValueError exception. A masked array does not own its data and therefore cannot safely be resized in place. Use the numpy.ma.resize function instead.", "This method is difficult to implement safely and may be deprecated in future releases of NumPy."]}, {"name": "ma.MaskedArray.round()", "path": "reference/generated/numpy.ma.maskedarray.round", "type": "numpy.ma.MaskedArray.round", "text": ["method", "Return each element rounded to the given number of decimals.", "Refer to numpy.around for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function"]}, {"name": "ma.MaskedArray.searchsorted()", "path": "reference/generated/numpy.ma.maskedarray.searchsorted", "type": "Masked arrays", "text": ["method", "Find indices where elements of v should be inserted in a to maintain order.", "For full documentation, see numpy.searchsorted", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.set_fill_value()", "path": "reference/generated/numpy.ma.maskedarray.set_fill_value", "type": "numpy.ma.MaskedArray.set_fill_value", "text": ["method"]}, {"name": "ma.MaskedArray.shrink_mask()", "path": "reference/generated/numpy.ma.maskedarray.shrink_mask", "type": "numpy.ma.MaskedArray.shrink_mask", "text": ["method", "Reduce a mask to nomask when possible."]}, {"name": "ma.MaskedArray.size", "path": "reference/generated/numpy.ma.maskedarray.size", "type": "Masked arrays", "text": ["attribute", "Number of elements in the array.", "Equal to np.prod(a.shape), i.e., the product of the array\u2019s dimensions.", "a.size returns a standard arbitrary precision Python integer. This may not be the case with other methods of obtaining the same value (like the suggested np.prod(a.shape), which returns an instance of np.int_), and may be relevant if the value is used further in calculations that may overflow a fixed size integer type."]}, {"name": "ma.MaskedArray.soften_mask()", "path": "reference/generated/numpy.ma.maskedarray.soften_mask", "type": "numpy.ma.MaskedArray.soften_mask", "text": ["method", "Force the mask to soft.", "Whether the mask of a masked array is hard or soft is determined by its hardmask property. soften_mask sets hardmask to False.", "See also"]}, {"name": "ma.MaskedArray.sort()", "path": "reference/generated/numpy.ma.maskedarray.sort", "type": "numpy.ma.MaskedArray.sort", "text": ["method", "Sort the array, in-place", "Array to be sorted.", "Axis along which to sort. If None, the array is flattened before sorting. The default is -1, which sorts along the last axis.", "The sorting algorithm used.", "When a is a structured array, this argument specifies which fields to compare first, second, and so on. This list does not need to include all of the fields.", "Whether missing values (if any) should be treated as the largest values (True) or the smallest values (False) When the array contains unmasked values sorting at the same extremes of the datatype, the ordering of these values and the masked values is undefined.", "Value used internally for the masked values. If fill_value is not None, it supersedes endwith.", "Array of the same type and shape as a.", "See also", "Method to sort an array in-place.", "Indirect sort.", "Indirect stable sort on multiple keys.", "Find elements in a sorted array.", "See sort for notes on the different sorting algorithms."]}, {"name": "ma.MaskedArray.squeeze()", "path": "reference/generated/numpy.ma.maskedarray.squeeze", "type": "numpy.ma.MaskedArray.squeeze", "text": ["method", "Remove axes of length one from a.", "Refer to numpy.squeeze for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.std()", "path": "reference/generated/numpy.ma.maskedarray.std", "type": "numpy.ma.MaskedArray.std", "text": ["method", "Returns the standard deviation of the array elements along given axis.", "Masked entries are ignored.", "Refer to numpy.std for full documentation.", "See also", "corresponding function for ndarrays", "Equivalent function"]}, {"name": "ma.MaskedArray.strides", "path": "reference/generated/numpy.ma.maskedarray.strides", "type": "Masked arrays", "text": ["attribute", "Tuple of bytes to step in each dimension when traversing an array.", "The byte offset of element (i[0], i[1], ..., i[n]) in an array a is:", "A more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file in the NumPy reference guide.", "See also", "Imagine an array of 32-bit integers (each 4 bytes):", "This array is stored in memory as 40 bytes, one after the other (known as a contiguous block of memory). The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis. For example, we have to skip 4 bytes (1 value) to move to the next column, but 20 bytes (5 values) to get to the same position in the next row. As such, the strides for the array x will be (20, 4)."]}, {"name": "ma.MaskedArray.sum()", "path": "reference/generated/numpy.ma.maskedarray.sum", "type": "numpy.ma.MaskedArray.sum", "text": ["method", "Return the sum of the array elements over the given axis.", "Masked elements are set to 0 internally.", "Refer to numpy.sum for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function"]}, {"name": "ma.MaskedArray.swapaxes()", "path": "reference/generated/numpy.ma.maskedarray.swapaxes", "type": "numpy.ma.MaskedArray.swapaxes", "text": ["method", "Return a view of the array with axis1 and axis2 interchanged.", "Refer to numpy.swapaxes for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.take()", "path": "reference/generated/numpy.ma.maskedarray.take", "type": "Masked arrays", "text": ["method"]}, {"name": "ma.MaskedArray.tobytes()", "path": "reference/generated/numpy.ma.maskedarray.tobytes", "type": "numpy.ma.MaskedArray.tobytes", "text": ["method", "Return the array data as a string containing the raw bytes in the array.", "The array is filled with a fill value before the string conversion.", "New in version 1.9.0.", "Value used to fill in the masked values. Default is None, in which case MaskedArray.fill_value is used.", "Order of the data item in the copy. Default is \u2018C\u2019.", "See also", "As for ndarray.tobytes, information about the shape, dtype, etc., but also about fill_value, will be lost."]}, {"name": "ma.MaskedArray.tofile()", "path": "reference/generated/numpy.ma.maskedarray.tofile", "type": "numpy.ma.MaskedArray.tofile", "text": ["method", "Save a masked array to a file in binary format.", "Warning", "This function is not implemented yet.", "When tofile is called."]}, {"name": "ma.MaskedArray.toflex()", "path": "reference/generated/numpy.ma.maskedarray.toflex", "type": "Masked arrays", "text": ["method", "Transforms a masked array into a flexible-type array.", "The flexible type array that is returned will have two fields:", "A new flexible-type ndarray with two fields: the first element containing a value, the second element containing the corresponding mask boolean. The returned record shape matches self.shape.", "A side-effect of transforming a masked array into a flexible ndarray is that meta information (fill_value, \u2026) will be lost."]}, {"name": "ma.MaskedArray.tolist()", "path": "reference/generated/numpy.ma.maskedarray.tolist", "type": "numpy.ma.MaskedArray.tolist", "text": ["method", "Return the data portion of the masked array as a hierarchical Python list.", "Data items are converted to the nearest compatible Python type. Masked values are converted to fill_value. If fill_value is None, the corresponding entries in the output list will be None.", "The value to use for invalid entries. Default is None.", "The Python list representation of the masked array."]}, {"name": "ma.MaskedArray.torecords()", "path": "reference/generated/numpy.ma.maskedarray.torecords", "type": "numpy.ma.MaskedArray.torecords", "text": ["method", "Transforms a masked array into a flexible-type array.", "The flexible type array that is returned will have two fields:", "A new flexible-type ndarray with two fields: the first element containing a value, the second element containing the corresponding mask boolean. The returned record shape matches self.shape.", "A side-effect of transforming a masked array into a flexible ndarray is that meta information (fill_value, \u2026) will be lost."]}, {"name": "ma.MaskedArray.tostring()", "path": "reference/generated/numpy.ma.maskedarray.tostring", "type": "Masked arrays", "text": ["method", "A compatibility alias for tobytes, with exactly the same behavior.", "Despite its name, it returns bytes not strs.", "Deprecated since version 1.19.0."]}, {"name": "ma.MaskedArray.trace()", "path": "reference/generated/numpy.ma.maskedarray.trace", "type": "numpy.ma.MaskedArray.trace", "text": ["method", "Return the sum along diagonals of the array.", "Refer to numpy.trace for full documentation.", "See also", "equivalent function"]}, {"name": "ma.MaskedArray.transpose()", "path": "reference/generated/numpy.ma.maskedarray.transpose", "type": "numpy.ma.MaskedArray.transpose", "text": ["method", "Returns a view of the array with axes transposed.", "For a 1-D array this has no effect, as a transposed vector is simply the same vector. To convert a 1-D array into a 2D column vector, an additional dimension must be added. np.atleast2d(a).T achieves this, as does a[:, np.newaxis]. For a 2-D array, this is a standard matrix transpose. For an n-D array, if axes are given, their order indicates how the axes are permuted (see Examples). If axes are not provided and a.shape = (i[0], i[1], ... i[n-2], i[n-1]), then a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0]).", "View of a, with axes suitably permuted.", "See also", "Equivalent function", "Array property returning the array transposed.", "Give a new shape to an array without changing its data."]}, {"name": "ma.MaskedArray.unshare_mask()", "path": "reference/generated/numpy.ma.maskedarray.unshare_mask", "type": "numpy.ma.MaskedArray.unshare_mask", "text": ["method", "Copy the mask and set the sharedmask flag to False.", "Whether the mask is shared between masked arrays can be seen from the sharedmask property. unshare_mask ensures the mask is not shared. A copy of the mask is only made if it was shared.", "See also"]}, {"name": "ma.MaskedArray.var()", "path": "reference/generated/numpy.ma.maskedarray.var", "type": "numpy.ma.MaskedArray.var", "text": ["method", "Compute the variance along the specified axis.", "Returns the variance of the array elements, a measure of the spread of a distribution. The variance is computed for the flattened array by default, otherwise over the specified axis.", "Array containing numbers whose variance is desired. If a is not an array, a conversion is attempted.", "Axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.", "New in version 1.7.0.", "If this is a tuple of ints, a variance is performed over multiple axes, instead of a single axis or all the axes as before.", "Type to use in computing the variance. For arrays of integer type the default is float64; for arrays of float types it is the same as the array type.", "Alternate output array in which to place the result. It must have the same shape as the expected output, but the type is cast if necessary.", "\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is N - ddof, where N represents the number of elements. By default ddof is zero.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.", "If the default value is passed, then keepdims will not be passed through to the var method of sub-classes of ndarray, however any non-default value will be. If the sub-class\u2019 method does not implement keepdims any exceptions will be raised.", "Elements to include in the variance. See reduce for details.", "New in version 1.20.0.", "If out=None, returns a new array containing the variance; otherwise, a reference to the output array is returned.", "See also", "The variance is the average of the squared deviations from the mean, i.e., var = mean(x), where x = abs(a - a.mean())**2.", "The mean is typically calculated as x.sum() / N, where N = len(x). If, however, ddof is specified, the divisor N - ddof is used instead. In standard statistical practice, ddof=1 provides an unbiased estimator of the variance of a hypothetical infinite population. ddof=0 provides a maximum likelihood estimate of the variance for normally distributed variables.", "Note that for complex numbers, the absolute value is taken before squaring, so that the result is always real and nonnegative.", "For floating-point input, the variance is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for float32 (see example below). Specifying a higher-accuracy accumulator using the dtype keyword can alleviate this issue.", "In single precision, var() can be inaccurate:", "Computing the variance in float64 is more accurate:", "Specifying a where argument:"]}, {"name": "ma.MaskedArray.view()", "path": "reference/generated/numpy.ma.maskedarray.view", "type": "Masked arrays", "text": ["method", "Return a view of the MaskedArray data.", "Data-type descriptor of the returned view, e.g., float32 or int16. The default, None, results in the view having the same data-type as a. As with ndarray.view, dtype can also be specified as an ndarray sub-class, which then specifies the type of the returned object (this is equivalent to setting the type parameter).", "Type of the returned view, either ndarray or a subclass. The default None results in type preservation.", "The value to use for invalid entries (None by default). If None, then this argument is inferred from the passed dtype, or in its absence the original array, as discussed in the notes below.", "See also", "Equivalent method on ndarray object.", "a.view() is used two different ways:", "a.view(some_dtype) or a.view(dtype=some_dtype) constructs a view of the array\u2019s memory with a different data-type. This can cause a reinterpretation of the bytes of memory.", "a.view(ndarray_subclass) or a.view(type=ndarray_subclass) just returns an instance of ndarray_subclass that looks at the same array (same shape, dtype, etc.) This does not cause a reinterpretation of the memory.", "If fill_value is not specified, but dtype is specified (and is not an ndarray sub-class), the fill_value of the MaskedArray will be reset. If neither fill_value nor dtype are specified (or if dtype is an ndarray sub-class), then the fill value is preserved. Finally, if fill_value is specified, but dtype is not, the fill value is set to the specified value.", "For a.view(some_dtype), if some_dtype has a different number of bytes per entry than the previous dtype (for example, converting a regular array to a structured array), then the behavior of the view cannot be predicted just from the superficial appearance of a (shown by print(a)). It also depends on exactly how a is stored in memory. Therefore if a is C-ordered versus fortran-ordered, versus defined as a slice or transpose, etc., the view may give different results."]}, {"name": "ma.max()", "path": "reference/generated/numpy.ma.max", "type": "numpy.ma.max", "text": ["Return the maximum along a given axis.", "Axis along which to operate. By default, axis is None and the flattened input is used.", "Alternative output array in which to place the result. Must be of the same shape and buffer length as the expected output.", "Value used to fill in the masked values. If None, use the output of maximum_fill_value().", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "New array holding the result. If out was specified, out is returned.", "See also", "Returns the maximum filling value for a given datatype."]}, {"name": "ma.maximum_fill_value()", "path": "reference/generated/numpy.ma.maximum_fill_value", "type": "numpy.ma.maximum_fill_value", "text": ["Return the minimum value that can be represented by the dtype of an object.", "This function is useful for calculating a fill value suitable for taking the maximum of an array with a given dtype.", "An object that can be queried for it\u2019s numeric type.", "The minimum representable value.", "If obj isn\u2019t a suitable numeric type.", "See also", "The inverse function.", "Set the filling value of a masked array.", "Return current fill value.", "An array of numeric data can also be passed."]}, {"name": "ma.mean()", "path": "reference/generated/numpy.ma.mean", "type": "numpy.ma.mean", "text": ["Returns the average of the array elements along given axis.", "Masked entries are ignored, and result elements which are not finite will be masked.", "Refer to numpy.mean for full documentation.", "See also", "corresponding function for ndarrays", "Equivalent function", "Weighted average."]}, {"name": "ma.median()", "path": "reference/generated/numpy.ma.median", "type": "numpy.ma.median", "text": ["Compute the median along the specified axis.", "Returns the median of the array elements.", "Input array or object that can be converted to an array.", "Axis along which the medians are computed. The default (None) is to compute the median along a flattened version of the array.", "Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.", "If True, then allow use of memory of input array (a) for calculations. The input array will be modified by the call to median. This will save memory when you do not need to preserve the contents of the input array. Treat the input as undefined, but it will probably be fully or partially sorted. Default is False. Note that, if overwrite_input is True, and the input is not already an ndarray, an error will be raised.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.", "New in version 1.10.0.", "A new array holding the result is returned unless out is specified, in which case a reference to out is returned. Return data-type is float64 for integers and floats smaller than float64, or the input data-type, otherwise.", "See also", "Given a vector V with N non masked values, the median of V is the middle value of a sorted copy of V (Vs) - i.e. Vs[(N-1)/2], when N is odd, or {Vs[N/2 - 1] + Vs[N/2]}/2 when N is even."]}, {"name": "ma.min()", "path": "reference/generated/numpy.ma.min", "type": "numpy.ma.min", "text": ["Return the minimum along a given axis.", "Axis along which to operate. By default, axis is None and the flattened input is used.", "Alternative output array in which to place the result. Must be of the same shape and buffer length as the expected output.", "Value used to fill in the masked values. If None, use the output of minimum_fill_value.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "New array holding the result. If out was specified, out is returned.", "See also", "Returns the minimum filling value for a given datatype."]}, {"name": "ma.minimum_fill_value()", "path": "reference/generated/numpy.ma.minimum_fill_value", "type": "numpy.ma.minimum_fill_value", "text": ["Return the maximum value that can be represented by the dtype of an object.", "This function is useful for calculating a fill value suitable for taking the minimum of an array with a given dtype.", "An object that can be queried for it\u2019s numeric type.", "The maximum representable value.", "If obj isn\u2019t a suitable numeric type.", "See also", "The inverse function.", "Set the filling value of a masked array.", "Return current fill value.", "An array of numeric data can also be passed."]}, {"name": "ma.mr_", "path": "reference/generated/numpy.ma.mr_", "type": "numpy.ma.mr_", "text": ["Translate slice objects to concatenation along the first axis.", "This is the masked array version of lib.index_tricks.RClass.", "See also"]}, {"name": "ma.nonzero()", "path": "reference/generated/numpy.ma.nonzero", "type": "numpy.ma.nonzero", "text": ["Return the indices of unmasked elements that are not zero.", "Returns a tuple of arrays, one for each dimension, containing the indices of the non-zero elements in that dimension. The corresponding non-zero values can be obtained with:", "To group the indices by element, rather than dimension, use instead:", "The result of this is always a 2d array, with a row for each non-zero element.", "Indices of elements that are non-zero.", "See also", "Function operating on ndarrays.", "Return indices that are non-zero in the flattened version of the input array.", "Equivalent ndarray method.", "Counts the number of non-zero elements in the input array.", "Masked elements are ignored.", "Indices can also be grouped by element.", "A common use for nonzero is to find the indices of an array, where a condition is True. Given an array a, the condition a > 3 is a boolean array and since False is interpreted as 0, ma.nonzero(a > 3) yields the indices of the a where the condition is true.", "The nonzero method of the condition array can also be called."]}, {"name": "ma.notmasked_contiguous()", "path": "reference/generated/numpy.ma.notmasked_contiguous", "type": "numpy.ma.notmasked_contiguous", "text": ["Find contiguous unmasked data in a masked array along the given axis.", "The input array.", "Axis along which to perform the operation. If None (default), applies to a flattened version of the array, and this is the same as flatnotmasked_contiguous.", "A list of slices (start and end indexes) of unmasked indexes in the array.", "If the input is 2d and axis is specified, the result is a list of lists.", "See also", "Only accepts 2-D arrays at most."]}, {"name": "ma.notmasked_edges()", "path": "reference/generated/numpy.ma.notmasked_edges", "type": "numpy.ma.notmasked_edges", "text": ["Find the indices of the first and last unmasked values along an axis.", "If all values are masked, return None. Otherwise, return a list of two tuples, corresponding to the indices of the first and last unmasked values respectively.", "The input array.", "Axis along which to perform the operation. If None (default), applies to a flattened version of the array.", "An array of start and end indexes if there are any masked data in the array. If there are no masked data in the array, edges is a list of the first and last index.", "See also"]}, {"name": "ma.ones()", "path": "reference/generated/numpy.ma.ones", "type": "numpy.ma.ones", "text": ["Return a new array of given shape and type, filled with ones.", "Shape of the new array, e.g., (2, 3) or 2.", "The desired data-type for the array, e.g., numpy.int8. Default is numpy.float64.", "Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.", "Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.", "New in version 1.20.0.", "Array of ones with the given shape, dtype, and order.", "See also", "Return an array of ones with shape and type of input.", "Return a new uninitialized array.", "Return a new array setting values to zero.", "Return a new array of given shape filled with value."]}, {"name": "ma.ones_like()", "path": "reference/generated/numpy.ma.ones_like", "type": "numpy.ma.ones_like", "text": ["Return an array of ones with the same shape and type as a given array.", "The shape and data-type of a define these same attributes of the returned array.", "Overrides the data type of the result.", "New in version 1.6.0.", "Overrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of a as closely as possible.", "New in version 1.6.0.", "If True, then the newly created array will use the sub-class type of a, otherwise it will be a base-class array. Defaults to True.", "Overrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions is unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.", "New in version 1.17.0.", "Array of ones with the same shape and type as a.", "See also", "Return an empty array with shape and type of input.", "Return an array of zeros with shape and type of input.", "Return a new array with shape of input filled with value.", "Return a new array setting values to one."]}, {"name": "ma.outer()", "path": "reference/generated/numpy.ma.outer", "type": "numpy.ma.outer", "text": ["Compute the outer product of two vectors.", "Given two vectors, a = [a0, a1, ..., aM] and b = [b0, b1, ..., bN], the outer product [1] is:", "First input vector. Input is flattened if not already 1-dimensional.", "Second input vector. Input is flattened if not already 1-dimensional.", "A location where the result is stored", "New in version 1.9.0.", "out[i, j] = a[i] * b[j]", "See also", "einsum('i,j->ij', a.ravel(), b.ravel()) is the equivalent.", "A generalization to dimensions other than 1D and other operations. np.multiply.outer(a.ravel(), b.ravel()) is the equivalent.", "np.tensordot(a.ravel(), b.ravel(), axes=((), ())) is the equivalent.", "Masked values are replaced by 0.", ": G. H. Golub and C. F. Van Loan, Matrix Computations, 3rd ed., Baltimore, MD, Johns Hopkins University Press, 1996, pg. 8.", "Make a (very coarse) grid for computing a Mandelbrot set:", "An example using a \u201cvector\u201d of letters:"]}, {"name": "ma.outerproduct()", "path": "reference/generated/numpy.ma.outerproduct", "type": "numpy.ma.outerproduct", "text": ["Compute the outer product of two vectors.", "Given two vectors, a = [a0, a1, ..., aM] and b = [b0, b1, ..., bN], the outer product [1] is:", "First input vector. Input is flattened if not already 1-dimensional.", "Second input vector. Input is flattened if not already 1-dimensional.", "A location where the result is stored", "New in version 1.9.0.", "out[i, j] = a[i] * b[j]", "See also", "einsum('i,j->ij', a.ravel(), b.ravel()) is the equivalent.", "A generalization to dimensions other than 1D and other operations. np.multiply.outer(a.ravel(), b.ravel()) is the equivalent.", "np.tensordot(a.ravel(), b.ravel(), axes=((), ())) is the equivalent.", "Masked values are replaced by 0.", ": G. H. Golub and C. F. Van Loan, Matrix Computations, 3rd ed., Baltimore, MD, Johns Hopkins University Press, 1996, pg. 8.", "Make a (very coarse) grid for computing a Mandelbrot set:", "An example using a \u201cvector\u201d of letters:"]}, {"name": "ma.polyfit()", "path": "reference/generated/numpy.ma.polyfit", "type": "numpy.ma.polyfit", "text": ["Least squares polynomial fit.", "Note", "This forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in numpy.polynomial is preferred. A summary of the differences can be found in the transition guide.", "Fit a polynomial p(x) = p[0] * x**deg + ... + p[deg] of degree deg to points (x, y). Returns a vector of coefficients p that minimises the squared error in the order deg, deg-1, \u2026 0.", "The Polynomial.fit class method is recommended for new code as it is more stable numerically. See the documentation of the method for more information.", "x-coordinates of the M sample points (x[i], y[i]).", "y-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.", "Degree of the fitting polynomial", "Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.", "Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.", "Weights. If not None, the weight w[i] applies to the unsquared residual y[i] - y_hat[i] at x[i]. Ideally the weights are chosen so that the errors of the products w[i]*y[i] all have the same variance. When using inverse-variance weighting, use w[i] = 1/sigma(y[i]). The default value is None.", "If given and not False, return not just the estimate but also its covariance matrix. By default, the covariance are scaled by chi2/dof, where dof = M - (deg + 1), i.e., the weights are presumed to be unreliable except in a relative sense and everything is scaled such that the reduced chi2 is unity. This scaling is omitted if cov='unscaled', as is relevant for the case that the weights are w = 1/sigma, with sigma known to be a reliable estimate of the uncertainty.", "Polynomial coefficients, highest power first. If y was 2-D, the coefficients for k-th data set are in p[:,k].", "These values are only returned if full == True", "coefficient matrix", "coefficient matrix", "For more details, see numpy.linalg.lstsq.", "Present only if full == False and cov == True. The covariance matrix of the polynomial coefficient estimates. The diagonal of this matrix are the variance estimates for each coefficient. If y is a 2-D array, then the covariance matrix for the k-th data set are in V[:,:,k]", "The rank of the coefficient matrix in the least-squares fit is deficient. The warning is only raised if full == False.", "The warnings can be turned off by", "See also", "Compute polynomial values.", "Computes a least-squares fit.", "Computes spline fits.", "Any masked values in x is propagated in y, and vice-versa.", "The solution minimizes the squared error", "in the equations:", "The coefficient matrix of the coefficients p is a Vandermonde matrix.", "polyfit issues a RankWarning when the least-squares fit is badly conditioned. This implies that the best fit is not well-defined due to numerical error. The results may be improved by lowering the polynomial degree or by replacing x by x - x.mean(). The rcond parameter can also be set to a value smaller than its default, but the resulting fit may be spurious: including contributions from the small singular values can add numerical noise to the result.", "Note that fitting polynomial coefficients is inherently badly conditioned when the degree of the polynomial is large or the interval of sample points is badly centered. The quality of the fit should always be checked in these cases. When polynomial fits are not satisfactory, splines may be a good alternative.", "Wikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting", "Wikipedia, \u201cPolynomial interpolation\u201d, https://en.wikipedia.org/wiki/Polynomial_interpolation", "It is convenient to use poly1d objects for dealing with polynomials:", "High-order polynomials may oscillate wildly:", "Illustration:"]}, {"name": "ma.power()", "path": "reference/generated/numpy.ma.power", "type": "numpy.ma.power", "text": ["Returns element-wise base array raised to power from second array.", "This is the masked array version of numpy.power. For details see numpy.power.", "See also", "The out argument to numpy.power is not supported, third has to be None."]}, {"name": "ma.prod()", "path": "reference/generated/numpy.ma.prod", "type": "numpy.ma.prod", "text": ["Return the product of the array elements over the given axis.", "Masked elements are set to 1 internally for computation.", "Refer to numpy.prod for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function", "Arithmetic is modular when using integer types, and no error is raised on overflow."]}, {"name": "ma.ptp()", "path": "reference/generated/numpy.ma.ptp", "type": "numpy.ma.ptp", "text": ["Return (maximum - minimum) along the given dimension (i.e. peak-to-peak value).", "Warning", "ptp preserves the data type of the array. This means the return value for an input of signed integers with n bits (e.g. np.int8, np.int16, etc) is also a signed integer with n bits. In that case, peak-to-peak values greater than 2**(n-1)-1 will be returned as negative values. An example with a work-around is shown below.", "Axis along which to find the peaks. If None (default) the flattened array is used.", "Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.", "Value used to fill in the masked values.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.", "A new array holding the result, unless out was specified, in which case a reference to out is returned.", "This example shows that a negative value can be returned when the input is an array of signed integers.", "A work-around is to use the view() method to view the result as unsigned integers with the same bit width:"]}, {"name": "ma.ravel()", "path": "reference/generated/numpy.ma.ravel", "type": "numpy.ma.ravel", "text": ["Returns a 1D version of self, as a view.", "The elements of a are read using this index order. \u2018C\u2019 means to index the elements in C-like order, with the last axis index changing fastest, back to the first axis index changing slowest. \u2018F\u2019 means to index the elements in Fortran-like index order, with the first index changing fastest, and the last index changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of the memory layout of the underlying array, and only refer to the order of axis indexing. \u2018A\u2019 means to read the elements in Fortran-like index order if m is Fortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the elements in the order they occur in memory, except for reversing the data when strides are negative. By default, \u2018C\u2019 index order is used.", "Output view is of shape (self.size,) (or (np.ma.product(self.shape),))."]}, {"name": "ma.reshape()", "path": "reference/generated/numpy.ma.reshape", "type": "numpy.ma.reshape", "text": ["Returns an array containing the same data with a new shape.", "Refer to MaskedArray.reshape for full documentation.", "See also", "equivalent function"]}, {"name": "ma.resize()", "path": "reference/generated/numpy.ma.resize", "type": "numpy.ma.resize", "text": ["Return a new masked array with the specified size and shape.", "This is the masked equivalent of the numpy.resize function. The new array is filled with repeated copies of x (in the order that the data are stored in memory). If x is masked, the new array will be masked, and the new mask will be a repetition of the old one.", "See also", "Equivalent function in the top level NumPy module.", "A MaskedArray is always returned, regardless of the input type."]}, {"name": "ma.round()", "path": "reference/generated/numpy.ma.round", "type": "numpy.ma.round", "text": ["Return a copy of a, rounded to \u2018decimals\u2019 places.", "When \u2018decimals\u2019 is negative, it specifies the number of positions to the left of the decimal point. The real and imaginary parts of complex numbers are rounded separately. Nothing is done if the array is not of float type and \u2018decimals\u2019 is greater than or equal to 0.", "Number of decimals to round to. May be negative.", "Existing array to use for output. If not given, returns a default copy of a.", "If out is given and does not have a mask attribute, the mask of a is lost!"]}, {"name": "ma.row_stack()", "path": "reference/generated/numpy.ma.row_stack", "type": "numpy.ma.row_stack", "text": ["Stack arrays in sequence vertically (row wise).", "This is equivalent to concatenation along the first axis after 1-D arrays of shape (N,) have been reshaped to (1,N). Rebuilds arrays divided by vsplit.", "This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions concatenate, stack and block provide more general stacking and concatenation operations.", "The arrays must have the same shape along all but the first axis. 1-D arrays must have the same length.", "The array formed by stacking the given arrays, will be at least 2-D.", "See also", "Join a sequence of arrays along an existing axis.", "Join a sequence of arrays along a new axis.", "Assemble an nd-array from nested lists of blocks.", "Stack arrays in sequence horizontally (column wise).", "Stack arrays in sequence depth wise (along third axis).", "Stack 1-D arrays as columns into a 2-D array.", "Split an array into multiple sub-arrays vertically (row-wise).", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.set_fill_value()", "path": "reference/generated/numpy.ma.set_fill_value", "type": "numpy.ma.set_fill_value", "text": ["Set the filling value of a, if a is a masked array.", "This function changes the fill value of the masked array a in place. If a is not a masked array, the function returns silently, without doing anything.", "Input array.", "Filling value. A consistency test is performed to make sure the value is compatible with the dtype of a.", "Nothing returned by this function.", "See also", "Return the default fill value for a dtype.", "Return current fill value.", "Equivalent method.", "Nothing happens if a is not a masked array."]}, {"name": "ma.shape()", "path": "reference/generated/numpy.ma.shape", "type": "numpy.ma.shape", "text": ["Return the shape of an array.", "Input array.", "The elements of the shape tuple give the lengths of the corresponding array dimensions.", "See also", "Equivalent array method."]}, {"name": "ma.size()", "path": "reference/generated/numpy.ma.size", "type": "numpy.ma.size", "text": ["Return the number of elements along a given axis.", "Input data.", "Axis along which the elements are counted. By default, give the total number of elements.", "Number of elements along the specified axis.", "See also", "dimensions of array", "dimensions of array", "number of elements in array"]}, {"name": "ma.soften_mask()", "path": "reference/generated/numpy.ma.soften_mask", "type": "numpy.ma.soften_mask", "text": ["Force the mask to soft.", "Whether the mask of a masked array is hard or soft is determined by its hardmask property. soften_mask sets hardmask to False.", "See also"]}, {"name": "ma.sort()", "path": "reference/generated/numpy.ma.sort", "type": "numpy.ma.sort", "text": ["Return a sorted copy of the masked array.", "Equivalent to creating a copy of the array and applying the MaskedArray sort() method.", "Refer to MaskedArray.sort for the full documentation", "See also", "equivalent method"]}, {"name": "ma.squeeze()", "path": "reference/generated/numpy.ma.squeeze", "type": "numpy.ma.squeeze", "text": ["Remove axes of length one from a.", "Input data.", "New in version 1.7.0.", "Selects a subset of the entries of length one in the shape. If an axis is selected with shape entry greater than one, an error is raised.", "The input array, but with all or a subset of the dimensions of length 1 removed. This is always a itself or a view into a. Note that if all axes are squeezed, the result is a 0d array and not a scalar.", "If axis is not None, and an axis being squeezed is not of length 1", "See also", "The inverse operation, adding entries of length one", "Insert, remove, and combine dimensions, and resize existing ones"]}, {"name": "ma.stack()", "path": "reference/generated/numpy.ma.stack", "type": "numpy.ma.stack", "text": ["Join a sequence of arrays along a new axis.", "The axis parameter specifies the index of the new axis in the dimensions of the result. For example, if axis=0 it will be the first dimension and if axis=-1 it will be the last dimension.", "New in version 1.10.0.", "Each array must have the same shape.", "The axis in the result array along which the input arrays are stacked.", "If provided, the destination to place the result. The shape must be correct, matching that of what stack would have returned if no out argument were specified.", "The stacked array has one more dimension than the input arrays.", "See also", "Join a sequence of arrays along an existing axis.", "Assemble an nd-array from nested lists of blocks.", "Split array into a list of multiple sub-arrays of equal size.", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.std()", "path": "reference/generated/numpy.ma.std", "type": "numpy.ma.std", "text": ["Returns the standard deviation of the array elements along given axis.", "Masked entries are ignored.", "Refer to numpy.std for full documentation.", "See also", "corresponding function for ndarrays", "Equivalent function"]}, {"name": "ma.sum()", "path": "reference/generated/numpy.ma.sum", "type": "numpy.ma.sum", "text": ["Return the sum of the array elements over the given axis.", "Masked elements are set to 0 internally.", "Refer to numpy.sum for full documentation.", "See also", "corresponding function for ndarrays", "equivalent function"]}, {"name": "ma.swapaxes()", "path": "reference/generated/numpy.ma.swapaxes", "type": "numpy.ma.swapaxes", "text": ["Return a view of the array with axis1 and axis2 interchanged.", "Refer to numpy.swapaxes for full documentation.", "See also", "equivalent function"]}, {"name": "ma.trace()", "path": "reference/generated/numpy.ma.trace", "type": "numpy.ma.trace", "text": ["Return the sum along diagonals of the array.", "Refer to numpy.trace for full documentation.", "See also", "equivalent function"]}, {"name": "ma.transpose()", "path": "reference/generated/numpy.ma.transpose", "type": "numpy.ma.transpose", "text": ["Permute the dimensions of an array.", "This function is exactly equivalent to numpy.transpose.", "See also", "Equivalent function in top-level NumPy module."]}, {"name": "ma.vander()", "path": "reference/generated/numpy.ma.vander", "type": "numpy.ma.vander", "text": ["Generate a Vandermonde matrix.", "The columns of the output matrix are powers of the input vector. The order of the powers is determined by the increasing boolean argument. Specifically, when increasing is False, the i-th output column is the input vector raised element-wise to the power of N - i - 1. Such a matrix with a geometric progression in each row is named for Alexandre- Theophile Vandermonde.", "1-D input array.", "Number of columns in the output. If N is not specified, a square array is returned (N = len(x)).", "Order of the powers of the columns. If True, the powers increase from left to right, if False (the default) they are reversed.", "New in version 1.9.0.", "Vandermonde matrix. If increasing is False, the first column is x^(N-1), the second x^(N-2) and so forth. If increasing is True, the columns are x^0, x^1, ..., x^(N-1).", "See also", "Masked values in the input array result in rows of zeros.", "The determinant of a square Vandermonde matrix is the product of the differences between the values of the input vector:"]}, {"name": "ma.var()", "path": "reference/generated/numpy.ma.var", "type": "numpy.ma.var", "text": ["Compute the variance along the specified axis.", "Returns the variance of the array elements, a measure of the spread of a distribution. The variance is computed for the flattened array by default, otherwise over the specified axis.", "Array containing numbers whose variance is desired. If a is not an array, a conversion is attempted.", "Axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.", "New in version 1.7.0.", "If this is a tuple of ints, a variance is performed over multiple axes, instead of a single axis or all the axes as before.", "Type to use in computing the variance. For arrays of integer type the default is float64; for arrays of float types it is the same as the array type.", "Alternate output array in which to place the result. It must have the same shape as the expected output, but the type is cast if necessary.", "\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is N - ddof, where N represents the number of elements. By default ddof is zero.", "If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.", "If the default value is passed, then keepdims will not be passed through to the var method of sub-classes of ndarray, however any non-default value will be. If the sub-class\u2019 method does not implement keepdims any exceptions will be raised.", "Elements to include in the variance. See reduce for details.", "New in version 1.20.0.", "If out=None, returns a new array containing the variance; otherwise, a reference to the output array is returned.", "See also", "The variance is the average of the squared deviations from the mean, i.e., var = mean(x), where x = abs(a - a.mean())**2.", "The mean is typically calculated as x.sum() / N, where N = len(x). If, however, ddof is specified, the divisor N - ddof is used instead. In standard statistical practice, ddof=1 provides an unbiased estimator of the variance of a hypothetical infinite population. ddof=0 provides a maximum likelihood estimate of the variance for normally distributed variables.", "Note that for complex numbers, the absolute value is taken before squaring, so that the result is always real and nonnegative.", "For floating-point input, the variance is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for float32 (see example below). Specifying a higher-accuracy accumulator using the dtype keyword can alleviate this issue.", "In single precision, var() can be inaccurate:", "Computing the variance in float64 is more accurate:", "Specifying a where argument:"]}, {"name": "ma.vstack()", "path": "reference/generated/numpy.ma.vstack", "type": "numpy.ma.vstack", "text": ["Stack arrays in sequence vertically (row wise).", "This is equivalent to concatenation along the first axis after 1-D arrays of shape (N,) have been reshaped to (1,N). Rebuilds arrays divided by vsplit.", "This function makes most sense for arrays with up to 3 dimensions. For instance, for pixel-data with a height (first axis), width (second axis), and r/g/b channels (third axis). The functions concatenate, stack and block provide more general stacking and concatenation operations.", "The arrays must have the same shape along all but the first axis. 1-D arrays must have the same length.", "The array formed by stacking the given arrays, will be at least 2-D.", "See also", "Join a sequence of arrays along an existing axis.", "Join a sequence of arrays along a new axis.", "Assemble an nd-array from nested lists of blocks.", "Stack arrays in sequence horizontally (column wise).", "Stack arrays in sequence depth wise (along third axis).", "Stack 1-D arrays as columns into a 2-D array.", "Split an array into multiple sub-arrays vertically (row-wise).", "The function is applied to both the _data and the _mask, if any."]}, {"name": "ma.where()", "path": "reference/generated/numpy.ma.where", "type": "numpy.ma.where", "text": ["Return a masked array with elements from x or y, depending on condition.", "Note", "When only condition is provided, this function is identical to nonzero. The rest of this documentation covers only the case where all three arguments are provided.", "Where True, yield x, otherwise yield y.", "Values from which to choose. x, y and condition need to be broadcastable to some shape.", "An masked array with masked elements where the condition is masked, elements from x where condition is True, and elements from y elsewhere.", "See also", "Equivalent function in the top-level NumPy module.", "The function that is called when x and y are omitted"]}, {"name": "ma.zeros()", "path": "reference/generated/numpy.ma.zeros", "type": "numpy.ma.zeros", "text": ["Return a new array of given shape and type, filled with zeros.", "Shape of the new array, e.g., (2, 3) or 2.", "The desired data-type for the array, e.g., numpy.int8. Default is numpy.float64.", "Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.", "Reference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.", "New in version 1.20.0.", "Array of zeros with the given shape, dtype, and order.", "See also", "Return an array of zeros with shape and type of input.", "Return a new uninitialized array.", "Return a new array setting values to one.", "Return a new array of given shape filled with value."]}, {"name": "ma.zeros_like()", "path": "reference/generated/numpy.ma.zeros_like", "type": "numpy.ma.zeros_like", "text": ["Return an array of zeros with the same shape and type as a given array.", "The shape and data-type of a define these same attributes of the returned array.", "Overrides the data type of the result.", "New in version 1.6.0.", "Overrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of a as closely as possible.", "New in version 1.6.0.", "If True, then the newly created array will use the sub-class type of a, otherwise it will be a base-class array. Defaults to True.", "Overrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions is unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.", "New in version 1.17.0.", "Array of zeros with the same shape and type as a.", "See also", "Return an empty array with shape and type of input.", "Return an array of ones with shape and type of input.", "Return a new array with shape of input filled with value.", "Return a new array setting values to zero."]}, {"name": "make_config_py()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.make_config_py", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Generate package __config__.py file containing system_info information used during building the package.", "This file is installed to the package installation directory."]}, {"name": "make_svn_version_py()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.make_svn_version_py", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": ["Appends a data function to the data_files list that will generate __svn_version__.py file to the current package directory.", "Generate package __svn_version__.py file from SVN revision number, it will be removed after python exits but will be available when sdist, etc commands are executed.", "If __svn_version__.py existed before, nothing is done.", "This is intended for working with source directories that are in an SVN repository."]}, {"name": "Masked array operations", "path": "reference/routines.ma", "type": "Masked array operations", "text": ["ma.MaskType", "alias of numpy.bool_", "ma.masked_array", "alias of numpy.ma.core.MaskedArray", "ma.array(data[, dtype, copy, order, mask, ...])", "An array class with possibly masked values.", "ma.copy(self, *args, **params) a.copy(order=)", "Return a copy of the array.", "ma.frombuffer(buffer[, dtype, count, ...])", "Interpret a buffer as a 1-dimensional array.", "ma.fromfunction(function, shape, **dtype)", "Construct an array by executing a function over each coordinate.", "ma.MaskedArray.copy([order])", "Return a copy of the array.", "ma.empty(shape[, dtype, order, like])", "Return a new array of given shape and type, without initializing entries.", "ma.empty_like(prototype[, dtype, order, ...])", "Return a new array with the same shape and type as a given array.", "ma.masked_all(shape[, dtype])", "Empty masked array with all elements masked.", "ma.masked_all_like(arr)", "Empty masked array with the properties of an existing array.", "ma.ones(shape[, dtype, order])", "Return a new array of given shape and type, filled with ones.", "ma.ones_like(*args, **kwargs)", "Return an array of ones with the same shape and type as a given array.", "ma.zeros(shape[, dtype, order, like])", "Return a new array of given shape and type, filled with zeros.", "ma.zeros_like(*args, **kwargs)", "Return an array of zeros with the same shape and type as a given array.", "ma.all(self[, axis, out, keepdims])", "Returns True if all elements evaluate to True.", "ma.any(self[, axis, out, keepdims])", "Returns True if any of the elements of a evaluate to True.", "ma.count(self[, axis, keepdims])", "Count the non-masked elements of the array along the given axis.", "ma.count_masked(arr[, axis])", "Count the number of masked elements along the given axis.", "ma.getmask(a)", "Return the mask of a masked array, or nomask.", "ma.getmaskarray(arr)", "Return the mask of a masked array, or full boolean array of False.", "ma.getdata(a[, subok])", "Return the data of a masked array as an ndarray.", "ma.nonzero(self)", "Return the indices of unmasked elements that are not zero.", "ma.shape(obj)", "Return the shape of an array.", "ma.size(obj[, axis])", "Return the number of elements along a given axis.", "ma.is_masked(x)", "Determine whether input has masked values.", "ma.is_mask(m)", "Return True if m is a valid, standard mask.", "ma.isMaskedArray(x)", "Test whether input is an instance of MaskedArray.", "ma.isMA(x)", "Test whether input is an instance of MaskedArray.", "ma.isarray(x)", "Test whether input is an instance of MaskedArray.", "ma.MaskedArray.all([axis, out, keepdims])", "Returns True if all elements evaluate to True.", "ma.MaskedArray.any([axis, out, keepdims])", "Returns True if any of the elements of a evaluate to True.", "ma.MaskedArray.count([axis, keepdims])", "Count the non-masked elements of the array along the given axis.", "ma.MaskedArray.nonzero()", "Return the indices of unmasked elements that are not zero.", "ma.shape(obj)", "Return the shape of an array.", "ma.size(obj[, axis])", "Return the number of elements along a given axis.", "ma.MaskedArray.data", "Returns the underlying data, as a view of the masked array.", "ma.MaskedArray.mask", "Current mask.", "ma.MaskedArray.recordmask", "Get or set the mask of the array if it has no named fields.", "ma.ravel(self[, order])", "Returns a 1D version of self, as a view.", "ma.reshape(a, new_shape[, order])", "Returns an array containing the same data with a new shape.", "ma.resize(x, new_shape)", "Return a new masked array with the specified size and shape.", "ma.MaskedArray.flatten([order])", "Return a copy of the array collapsed into one dimension.", "ma.MaskedArray.ravel([order])", "Returns a 1D version of self, as a view.", "ma.MaskedArray.reshape(*s, **kwargs)", "Give a new shape to the array without changing its data.", "ma.MaskedArray.resize(newshape[, refcheck, ...])", "ma.swapaxes(self, *args, ...)", "Return a view of the array with axis1 and axis2 interchanged.", "ma.transpose(a[, axes])", "Permute the dimensions of an array.", "ma.MaskedArray.swapaxes(axis1, axis2)", "Return a view of the array with axis1 and axis2 interchanged.", "ma.MaskedArray.transpose(*axes)", "Returns a view of the array with axes transposed.", "ma.atleast_1d(*args, **kwargs)", "Convert inputs to arrays with at least one dimension.", "ma.atleast_2d(*args, **kwargs)", "View inputs as arrays with at least two dimensions.", "ma.atleast_3d(*args, **kwargs)", "View inputs as arrays with at least three dimensions.", "ma.expand_dims(a, axis)", "Expand the shape of an array.", "ma.squeeze(*args, **kwargs)", "Remove axes of length one from a.", "ma.MaskedArray.squeeze([axis])", "Remove axes of length one from a.", "ma.stack(*args, **kwargs)", "Join a sequence of arrays along a new axis.", "ma.column_stack(*args, **kwargs)", "Stack 1-D arrays as columns into a 2-D array.", "ma.concatenate(arrays[, axis])", "Concatenate a sequence of arrays along the given axis.", "ma.dstack(*args, **kwargs)", "Stack arrays in sequence depth wise (along third axis).", "ma.hstack(*args, **kwargs)", "Stack arrays in sequence horizontally (column wise).", "ma.hsplit(*args, **kwargs)", "Split an array into multiple sub-arrays horizontally (column-wise).", "ma.mr_", "Translate slice objects to concatenation along the first axis.", "ma.row_stack(*args, **kwargs)", "Stack arrays in sequence vertically (row wise).", "ma.vstack(*args, **kwargs)", "Stack arrays in sequence vertically (row wise).", "ma.concatenate(arrays[, axis])", "Concatenate a sequence of arrays along the given axis.", "ma.stack(*args, **kwargs)", "Join a sequence of arrays along a new axis.", "ma.vstack(*args, **kwargs)", "Stack arrays in sequence vertically (row wise).", "ma.hstack(*args, **kwargs)", "Stack arrays in sequence horizontally (column wise).", "ma.dstack(*args, **kwargs)", "Stack arrays in sequence depth wise (along third axis).", "ma.column_stack(*args, **kwargs)", "Stack 1-D arrays as columns into a 2-D array.", "ma.append(a, b[, axis])", "Append values to the end of an array.", "ma.make_mask(m[, copy, shrink, dtype])", "Create a boolean mask from an array.", "ma.make_mask_none(newshape[, dtype])", "Return a boolean mask of the given shape, filled with False.", "ma.mask_or(m1, m2[, copy, shrink])", "Combine two masks with the logical_or operator.", "ma.make_mask_descr(ndtype)", "Construct a dtype description list from a given dtype.", "ma.getmask(a)", "Return the mask of a masked array, or nomask.", "ma.getmaskarray(arr)", "Return the mask of a masked array, or full boolean array of False.", "ma.masked_array.mask", "Current mask.", "ma.flatnotmasked_contiguous(a)", "Find contiguous unmasked data in a masked array along the given axis.", "ma.flatnotmasked_edges(a)", "Find the indices of the first and last unmasked values.", "ma.notmasked_contiguous(a[, axis])", "Find contiguous unmasked data in a masked array along the given axis.", "ma.notmasked_edges(a[, axis])", "Find the indices of the first and last unmasked values along an axis.", "ma.clump_masked(a)", "Returns a list of slices corresponding to the masked clumps of a 1-D array.", "ma.clump_unmasked(a)", "Return list of slices corresponding to the unmasked clumps of a 1-D array.", "ma.mask_cols(a[, axis])", "Mask columns of a 2D array that contain masked values.", "ma.mask_or(m1, m2[, copy, shrink])", "Combine two masks with the logical_or operator.", "ma.mask_rowcols(a[, axis])", "Mask rows and/or columns of a 2D array that contain masked values.", "ma.mask_rows(a[, axis])", "Mask rows of a 2D array that contain masked values.", "ma.harden_mask(self)", "Force the mask to hard.", "ma.soften_mask(self)", "Force the mask to soft.", "ma.MaskedArray.harden_mask()", "Force the mask to hard.", "ma.MaskedArray.soften_mask()", "Force the mask to soft.", "ma.MaskedArray.shrink_mask()", "Reduce a mask to nomask when possible.", "ma.MaskedArray.unshare_mask()", "Copy the mask and set the sharedmask flag to False.", "ma.asarray(a[, dtype, order])", "Convert the input to a masked array of the given data-type.", "ma.asanyarray(a[, dtype])", "Convert the input to a masked array, conserving subclasses.", "ma.fix_invalid(a[, mask, copy, fill_value])", "Return input with invalid data masked and replaced by a fill value.", "ma.masked_equal(x, value[, copy])", "Mask an array where equal to a given value.", "ma.masked_greater(x, value[, copy])", "Mask an array where greater than a given value.", "ma.masked_greater_equal(x, value[, copy])", "Mask an array where greater than or equal to a given value.", "ma.masked_inside(x, v1, v2[, copy])", "Mask an array inside a given interval.", "ma.masked_invalid(a[, copy])", "Mask an array where invalid values occur (NaNs or infs).", "ma.masked_less(x, value[, copy])", "Mask an array where less than a given value.", "ma.masked_less_equal(x, value[, copy])", "Mask an array where less than or equal to a given value.", "ma.masked_not_equal(x, value[, copy])", "Mask an array where not equal to a given value.", "ma.masked_object(x, value[, copy, shrink])", "Mask the array x where the data are exactly equal to value.", "ma.masked_outside(x, v1, v2[, copy])", "Mask an array outside a given interval.", "ma.masked_values(x, value[, rtol, atol, ...])", "Mask using floating point equality.", "ma.masked_where(condition, a[, copy])", "Mask an array where a condition is met.", "ma.compress_cols(a)", "Suppress whole columns of a 2-D array that contain masked values.", "ma.compress_rowcols(x[, axis])", "Suppress the rows and/or columns of a 2-D array that contain masked values.", "ma.compress_rows(a)", "Suppress whole rows of a 2-D array that contain masked values.", "ma.compressed(x)", "Return all the non-masked data as a 1-D array.", "ma.filled(a[, fill_value])", "Return input as an array with masked data replaced by a fill value.", "ma.MaskedArray.compressed()", "Return all the non-masked data as a 1-D array.", "ma.MaskedArray.filled([fill_value])", "Return a copy of self, with masked values filled with a given value.", "ma.MaskedArray.tofile(fid[, sep, format])", "Save a masked array to a file in binary format.", "ma.MaskedArray.tolist([fill_value])", "Return the data portion of the masked array as a hierarchical Python list.", "ma.MaskedArray.torecords()", "Transforms a masked array into a flexible-type array.", "ma.MaskedArray.tobytes([fill_value, order])", "Return the array data as a string containing the raw bytes in the array.", "ma.common_fill_value(a, b)", "Return the common filling value of two masked arrays, if any.", "ma.default_fill_value(obj)", "Return the default fill value for the argument object.", "ma.maximum_fill_value(obj)", "Return the minimum value that can be represented by the dtype of an object.", "ma.minimum_fill_value(obj)", "Return the maximum value that can be represented by the dtype of an object.", "ma.set_fill_value(a, fill_value)", "Set the filling value of a, if a is a masked array.", "ma.MaskedArray.get_fill_value()", "The filling value of the masked array is a scalar.", "ma.MaskedArray.set_fill_value([value])", "ma.MaskedArray.fill_value", "The filling value of the masked array is a scalar.", "ma.anom(self[, axis, dtype])", "Compute the anomalies (deviations from the arithmetic mean) along the given axis.", "ma.anomalies(self[, axis, dtype])", "Compute the anomalies (deviations from the arithmetic mean) along the given axis.", "ma.average(a[, axis, weights, returned])", "Return the weighted average of array over the given axis.", "ma.conjugate(x, /[, out, where, casting, ...])", "Return the complex conjugate, element-wise.", "ma.corrcoef(x[, y, rowvar, bias, ...])", "Return Pearson product-moment correlation coefficients.", "ma.cov(x[, y, rowvar, bias, allow_masked, ddof])", "Estimate the covariance matrix.", "ma.cumsum(self[, axis, dtype, out])", "Return the cumulative sum of the array elements over the given axis.", "ma.cumprod(self[, axis, dtype, out])", "Return the cumulative product of the array elements over the given axis.", "ma.mean(self[, axis, dtype, out, keepdims])", "Returns the average of the array elements along given axis.", "ma.median(a[, axis, out, overwrite_input, ...])", "Compute the median along the specified axis.", "ma.power(a, b[, third])", "Returns element-wise base array raised to power from second array.", "ma.prod(self[, axis, dtype, out, keepdims])", "Return the product of the array elements over the given axis.", "ma.std(self[, axis, dtype, out, ddof, keepdims])", "Returns the standard deviation of the array elements along given axis.", "ma.sum(self[, axis, dtype, out, keepdims])", "Return the sum of the array elements over the given axis.", "ma.var(self[, axis, dtype, out, ddof, keepdims])", "Compute the variance along the specified axis.", "ma.MaskedArray.anom([axis, dtype])", "Compute the anomalies (deviations from the arithmetic mean) along the given axis.", "ma.MaskedArray.cumprod([axis, dtype, out])", "Return the cumulative product of the array elements over the given axis.", "ma.MaskedArray.cumsum([axis, dtype, out])", "Return the cumulative sum of the array elements over the given axis.", "ma.MaskedArray.mean([axis, dtype, out, keepdims])", "Returns the average of the array elements along given axis.", "ma.MaskedArray.prod([axis, dtype, out, keepdims])", "Return the product of the array elements over the given axis.", "ma.MaskedArray.std([axis, dtype, out, ddof, ...])", "Returns the standard deviation of the array elements along given axis.", "ma.MaskedArray.sum([axis, dtype, out, keepdims])", "Return the sum of the array elements over the given axis.", "ma.MaskedArray.var([axis, dtype, out, ddof, ...])", "Compute the variance along the specified axis.", "ma.argmax(self[, axis, fill_value, out])", "Returns array of indices of the maximum values along the given axis.", "ma.argmin(self[, axis, fill_value, out])", "Return array of indices to the minimum values along the given axis.", "ma.max(obj[, axis, out, fill_value, keepdims])", "Return the maximum along a given axis.", "ma.min(obj[, axis, out, fill_value, keepdims])", "Return the minimum along a given axis.", "ma.ptp(obj[, axis, out, fill_value, keepdims])", "Return (maximum - minimum) along the given dimension (i.e.", "ma.diff(*args, **kwargs)", "Calculate the n-th discrete difference along the given axis.", "ma.MaskedArray.argmax([axis, fill_value, ...])", "Returns array of indices of the maximum values along the given axis.", "ma.MaskedArray.argmin([axis, fill_value, ...])", "Return array of indices to the minimum values along the given axis.", "ma.MaskedArray.max([axis, out, fill_value, ...])", "Return the maximum along a given axis.", "ma.MaskedArray.min([axis, out, fill_value, ...])", "Return the minimum along a given axis.", "ma.MaskedArray.ptp([axis, out, fill_value, ...])", "Return (maximum - minimum) along the given dimension (i.e.", "ma.argsort(a[, axis, kind, order, endwith, ...])", "Return an ndarray of indices that sort the array along the specified axis.", "ma.sort(a[, axis, kind, order, endwith, ...])", "Return a sorted copy of the masked array.", "ma.MaskedArray.argsort([axis, kind, order, ...])", "Return an ndarray of indices that sort the array along the specified axis.", "ma.MaskedArray.sort([axis, kind, order, ...])", "Sort the array, in-place", "ma.diag(v[, k])", "Extract a diagonal or construct a diagonal array.", "ma.dot(a, b[, strict, out])", "Return the dot product of two arrays.", "ma.identity(n[, dtype])", "Return the identity array.", "ma.inner(a, b, /)", "Inner product of two arrays.", "ma.innerproduct(a, b, /)", "Inner product of two arrays.", "ma.outer(a, b)", "Compute the outer product of two vectors.", "ma.outerproduct(a, b)", "Compute the outer product of two vectors.", "ma.trace(self[, offset, axis1, axis2, ...])", "Return the sum along diagonals of the array.", "ma.transpose(a[, axes])", "Permute the dimensions of an array.", "ma.MaskedArray.trace([offset, axis1, axis2, ...])", "Return the sum along diagonals of the array.", "ma.MaskedArray.transpose(*axes)", "Returns a view of the array with axes transposed.", "ma.vander(x[, n])", "Generate a Vandermonde matrix.", "ma.polyfit(x, y, deg[, rcond, full, w, cov])", "Least squares polynomial fit.", "ma.around", "Round an array to the given number of decimals.", "ma.clip(*args, **kwargs)", "Clip (limit) the values in an array.", "ma.round(a[, decimals, out])", "Return a copy of a, rounded to 'decimals' places.", "ma.MaskedArray.clip([min, max, out])", "Return an array whose values are limited to [min, max].", "ma.MaskedArray.round([decimals, out])", "Return each element rounded to the given number of decimals.", "ma.allequal(a, b[, fill_value])", "Return True if all entries of a and b are equal, using fill_value as a truth value where either or both are masked.", "ma.allclose(a, b[, masked_equal, rtol, atol])", "Returns True if two arrays are element-wise equal within a tolerance.", "ma.apply_along_axis(func1d, axis, arr, ...)", "Apply a function to 1-D slices along the given axis.", "ma.apply_over_axes(func, a, axes)", "Apply a function repeatedly over multiple axes.", "ma.arange([start,] stop[, step,][, dtype, like])", "Return evenly spaced values within a given interval.", "ma.choose(indices, choices[, out, mode])", "Use an index array to construct a new array from a list of choices.", "ma.ediff1d(arr[, to_end, to_begin])", "Compute the differences between consecutive elements of an array.", "ma.indices(dimensions[, dtype, sparse])", "Return an array representing the indices of a grid.", "ma.where(condition[, x, y])", "Return a masked array with elements from x or y, depending on condition."]}, {"name": "Masked arrays", "path": "reference/maskedarray", "type": "Masked arrays", "text": ["Masked arrays are arrays that may have missing or invalid entries. The numpy.ma module provides a nearly work-alike replacement for numpy that supports data arrays with masks."]}, {"name": "MaskedArray.baseclass", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.baseclass", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": ["In addition to the MaskedArray class, the numpy.ma module defines several constants.", "The masked constant is a special case of MaskedArray, with a float datatype and a null shape. It is used to test whether a specific entry of a masked array is masked, or to mask one or several entries of a masked array:", "Value indicating that a masked array has no invalid entry. nomask is used internally to speed up computations when the mask is not needed. It is represented internally as np.False_.", "String used in lieu of missing data when a masked array is printed. By default, this string is '--'."]}, {"name": "MaskedArray.fill_value", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.fill_value", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": ["In addition to the MaskedArray class, the numpy.ma module defines several constants.", "The masked constant is a special case of MaskedArray, with a float datatype and a null shape. It is used to test whether a specific entry of a masked array is masked, or to mask one or several entries of a masked array:", "Value indicating that a masked array has no invalid entry. nomask is used internally to speed up computations when the mask is not needed. It is represented internally as np.False_.", "String used in lieu of missing data when a masked array is printed. By default, this string is '--'."]}, {"name": "MaskedArray.hardmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.hardmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": ["In addition to the MaskedArray class, the numpy.ma module defines several constants.", "The masked constant is a special case of MaskedArray, with a float datatype and a null shape. It is used to test whether a specific entry of a masked array is masked, or to mask one or several entries of a masked array:", "Value indicating that a masked array has no invalid entry. nomask is used internally to speed up computations when the mask is not needed. It is represented internally as np.False_.", "String used in lieu of missing data when a masked array is printed. By default, this string is '--'."]}, {"name": "MaskedArray.mask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.mask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": ["In addition to the MaskedArray class, the numpy.ma module defines several constants.", "The masked constant is a special case of MaskedArray, with a float datatype and a null shape. It is used to test whether a specific entry of a masked array is masked, or to mask one or several entries of a masked array:", "Value indicating that a masked array has no invalid entry. nomask is used internally to speed up computations when the mask is not needed. It is represented internally as np.False_.", "String used in lieu of missing data when a masked array is printed. By default, this string is '--'."]}, {"name": "MaskedArray.recordmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.recordmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": ["In addition to the MaskedArray class, the numpy.ma module defines several constants.", "The masked constant is a special case of MaskedArray, with a float datatype and a null shape. It is used to test whether a specific entry of a masked array is masked, or to mask one or several entries of a masked array:", "Value indicating that a masked array has no invalid entry. nomask is used internally to speed up computations when the mask is not needed. It is represented internally as np.False_.", "String used in lieu of missing data when a masked array is printed. By default, this string is '--'."]}, {"name": "MaskedArray.sharedmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.sharedmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": ["In addition to the MaskedArray class, the numpy.ma module defines several constants.", "The masked constant is a special case of MaskedArray, with a float datatype and a null shape. It is used to test whether a specific entry of a masked array is masked, or to mask one or several entries of a masked array:", "Value indicating that a masked array has no invalid entry. nomask is used internally to speed up computations when the mask is not needed. It is represented internally as np.False_.", "String used in lieu of missing data when a masked array is printed. By default, this string is '--'."]}, {"name": "Mathematical functions", "path": "reference/routines.math", "type": "Mathematical functions", "text": ["sin(x, /[, out, where, casting, order, ...])", "Trigonometric sine, element-wise.", "cos(x, /[, out, where, casting, order, ...])", "Cosine element-wise.", "tan(x, /[, out, where, casting, order, ...])", "Compute tangent element-wise.", "arcsin(x, /[, out, where, casting, order, ...])", "Inverse sine, element-wise.", "arccos(x, /[, out, where, casting, order, ...])", "Trigonometric inverse cosine, element-wise.", "arctan(x, /[, out, where, casting, order, ...])", "Trigonometric inverse tangent, element-wise.", "hypot(x1, x2, /[, out, where, casting, ...])", "Given the \"legs\" of a right triangle, return its hypotenuse.", "arctan2(x1, x2, /[, out, where, casting, ...])", "Element-wise arc tangent of x1/x2 choosing the quadrant correctly.", "degrees(x, /[, out, where, casting, order, ...])", "Convert angles from radians to degrees.", "radians(x, /[, out, where, casting, order, ...])", "Convert angles from degrees to radians.", "unwrap(p[, discont, axis, period])", "Unwrap by taking the complement of large deltas with respect to the period.", "deg2rad(x, /[, out, where, casting, order, ...])", "Convert angles from degrees to radians.", "rad2deg(x, /[, out, where, casting, order, ...])", "Convert angles from radians to degrees.", "sinh(x, /[, out, where, casting, order, ...])", "Hyperbolic sine, element-wise.", "cosh(x, /[, out, where, casting, order, ...])", "Hyperbolic cosine, element-wise.", "tanh(x, /[, out, where, casting, order, ...])", "Compute hyperbolic tangent element-wise.", "arcsinh(x, /[, out, where, casting, order, ...])", "Inverse hyperbolic sine element-wise.", "arccosh(x, /[, out, where, casting, order, ...])", "Inverse hyperbolic cosine, element-wise.", "arctanh(x, /[, out, where, casting, order, ...])", "Inverse hyperbolic tangent element-wise.", "around(a[, decimals, out])", "Evenly round to the given number of decimals.", "round_(a[, decimals, out])", "Round an array to the given number of decimals.", "rint(x, /[, out, where, casting, order, ...])", "Round elements of the array to the nearest integer.", "fix(x[, out])", "Round to nearest integer towards zero.", "floor(x, /[, out, where, casting, order, ...])", "Return the floor of the input, element-wise.", "ceil(x, /[, out, where, casting, order, ...])", "Return the ceiling of the input, element-wise.", "trunc(x, /[, out, where, casting, order, ...])", "Return the truncated value of the input, element-wise.", "prod(a[, axis, dtype, out, keepdims, ...])", "Return the product of array elements over a given axis.", "sum(a[, axis, dtype, out, keepdims, ...])", "Sum of array elements over a given axis.", "nanprod(a[, axis, dtype, out, keepdims, ...])", "Return the product of array elements over a given axis treating Not a Numbers (NaNs) as ones.", "nansum(a[, axis, dtype, out, keepdims, ...])", "Return the sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.", "cumprod(a[, axis, dtype, out])", "Return the cumulative product of elements along a given axis.", "cumsum(a[, axis, dtype, out])", "Return the cumulative sum of the elements along a given axis.", "nancumprod(a[, axis, dtype, out])", "Return the cumulative product of array elements over a given axis treating Not a Numbers (NaNs) as one.", "nancumsum(a[, axis, dtype, out])", "Return the cumulative sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.", "diff(a[, n, axis, prepend, append])", "Calculate the n-th discrete difference along the given axis.", "ediff1d(ary[, to_end, to_begin])", "The differences between consecutive elements of an array.", "gradient(f, *varargs[, axis, edge_order])", "Return the gradient of an N-dimensional array.", "cross(a, b[, axisa, axisb, axisc, axis])", "Return the cross product of two (arrays of) vectors.", "trapz(y[, x, dx, axis])", "Integrate along the given axis using the composite trapezoidal rule.", "exp(x, /[, out, where, casting, order, ...])", "Calculate the exponential of all elements in the input array.", "expm1(x, /[, out, where, casting, order, ...])", "Calculate exp(x) - 1 for all elements in the array.", "exp2(x, /[, out, where, casting, order, ...])", "Calculate 2**p for all p in the input array.", "log(x, /[, out, where, casting, order, ...])", "Natural logarithm, element-wise.", "log10(x, /[, out, where, casting, order, ...])", "Return the base 10 logarithm of the input array, element-wise.", "log2(x, /[, out, where, casting, order, ...])", "Base-2 logarithm of x.", "log1p(x, /[, out, where, casting, order, ...])", "Return the natural logarithm of one plus the input array, element-wise.", "logaddexp(x1, x2, /[, out, where, casting, ...])", "Logarithm of the sum of exponentiations of the inputs.", "logaddexp2(x1, x2, /[, out, where, casting, ...])", "Logarithm of the sum of exponentiations of the inputs in base-2.", "i0(x)", "Modified Bessel function of the first kind, order 0.", "sinc(x)", "Return the normalized sinc function.", "signbit(x, /[, out, where, casting, order, ...])", "Returns element-wise True where signbit is set (less than zero).", "copysign(x1, x2, /[, out, where, casting, ...])", "Change the sign of x1 to that of x2, element-wise.", "frexp(x[, out1, out2], / [[, out, where, ...])", "Decompose the elements of x into mantissa and twos exponent.", "ldexp(x1, x2, /[, out, where, casting, ...])", "Returns x1 * 2**x2, element-wise.", "nextafter(x1, x2, /[, out, where, casting, ...])", "Return the next floating-point value after x1 towards x2, element-wise.", "spacing(x, /[, out, where, casting, order, ...])", "Return the distance between x and the nearest adjacent number.", "lcm(x1, x2, /[, out, where, casting, order, ...])", "Returns the lowest common multiple of |x1| and |x2|", "gcd(x1, x2, /[, out, where, casting, order, ...])", "Returns the greatest common divisor of |x1| and |x2|", "add(x1, x2, /[, out, where, casting, order, ...])", "Add arguments element-wise.", "reciprocal(x, /[, out, where, casting, ...])", "Return the reciprocal of the argument, element-wise.", "positive(x, /[, out, where, casting, order, ...])", "Numerical positive, element-wise.", "negative(x, /[, out, where, casting, order, ...])", "Numerical negative, element-wise.", "multiply(x1, x2, /[, out, where, casting, ...])", "Multiply arguments element-wise.", "divide(x1, x2, /[, out, where, casting, ...])", "Returns a true division of the inputs, element-wise.", "power(x1, x2, /[, out, where, casting, ...])", "First array elements raised to powers from second array, element-wise.", "subtract(x1, x2, /[, out, where, casting, ...])", "Subtract arguments, element-wise.", "true_divide(x1, x2, /[, out, where, ...])", "Returns a true division of the inputs, element-wise.", "floor_divide(x1, x2, /[, out, where, ...])", "Return the largest integer smaller or equal to the division of the inputs.", "float_power(x1, x2, /[, out, where, ...])", "First array elements raised to powers from second array, element-wise.", "fmod(x1, x2, /[, out, where, casting, ...])", "Returns the element-wise remainder of division.", "mod(x1, x2, /[, out, where, casting, order, ...])", "Returns the element-wise remainder of division.", "modf(x[, out1, out2], / [[, out, where, ...])", "Return the fractional and integral parts of an array, element-wise.", "remainder(x1, x2, /[, out, where, casting, ...])", "Returns the element-wise remainder of division.", "divmod(x1, x2[, out1, out2], / [[, out, ...])", "Return element-wise quotient and remainder simultaneously.", "angle(z[, deg])", "Return the angle of the complex argument.", "real(val)", "Return the real part of the complex argument.", "imag(val)", "Return the imaginary part of the complex argument.", "conj(x, /[, out, where, casting, order, ...])", "Return the complex conjugate, element-wise.", "conjugate(x, /[, out, where, casting, ...])", "Return the complex conjugate, element-wise.", "maximum(x1, x2, /[, out, where, casting, ...])", "Element-wise maximum of array elements.", "fmax(x1, x2, /[, out, where, casting, ...])", "Element-wise maximum of array elements.", "amax(a[, axis, out, keepdims, initial, where])", "Return the maximum of an array or maximum along an axis.", "nanmax(a[, axis, out, keepdims, initial, where])", "Return the maximum of an array or maximum along an axis, ignoring any NaNs.", "minimum(x1, x2, /[, out, where, casting, ...])", "Element-wise minimum of array elements.", "fmin(x1, x2, /[, out, where, casting, ...])", "Element-wise minimum of array elements.", "amin(a[, axis, out, keepdims, initial, where])", "Return the minimum of an array or minimum along an axis.", "nanmin(a[, axis, out, keepdims, initial, where])", "Return minimum of an array or minimum along an axis, ignoring any NaNs.", "convolve(a, v[, mode])", "Returns the discrete, linear convolution of two one-dimensional sequences.", "clip(a, a_min, a_max[, out])", "Clip (limit) the values in an array.", "sqrt(x, /[, out, where, casting, order, ...])", "Return the non-negative square-root of an array, element-wise.", "cbrt(x, /[, out, where, casting, order, ...])", "Return the cube-root of an array, element-wise.", "square(x, /[, out, where, casting, order, ...])", "Return the element-wise square of the input.", "absolute(x, /[, out, where, casting, order, ...])", "Calculate the absolute value element-wise.", "fabs(x, /[, out, where, casting, order, ...])", "Compute the absolute values element-wise.", "sign(x, /[, out, where, casting, order, ...])", "Returns an element-wise indication of the sign of a number.", "heaviside(x1, x2, /[, out, where, casting, ...])", "Compute the Heaviside step function.", "nan_to_num(x[, copy, nan, posinf, neginf])", "Replace NaN with zero and infinity with large finite numbers (default behaviour) or with the numbers defined by the user using the nan, posinf and/or neginf keywords.", "real_if_close(a[, tol])", "If input is complex with all imaginary parts close to zero, return real parts.", "interp(x, xp, fp[, left, right, period])", "One-dimensional linear interpolation for monotonically increasing sample points."]}, {"name": "Mathematical functions with automatic domain (numpy.emath)", "path": "reference/routines.emath", "type": "Mathematical functions with automatic domain ( \n      \n       numpy.emath\n      \n      )", "text": ["Note", "numpy.emath is a preferred alias for numpy.lib.scimath, available after numpy is imported.", "Wrapper functions to more user-friendly calling of certain math functions whose output data-type is different than the input data-type in certain domains of the input.", "For example, for functions like log with branch cuts, the versions in this module provide the mathematically valid answers in the complex plane:", "Similarly, sqrt, other base logarithms, power and trig functions are correctly handled. See their respective docstrings for specific examples.", "sqrt(x)", "Compute the square root of x.", "log(x)", "Compute the natural logarithm of x.", "log2(x)", "Compute the logarithm base 2 of x.", "logn(n, x)", "Take log base n of x.", "log10(x)", "Compute the logarithm base 10 of x.", "power(x, p)", "Return x to the power p, (x**p).", "arccos(x)", "Compute the inverse cosine of x.", "arcsin(x)", "Compute the inverse sine of x.", "arctanh(x)", "Compute the inverse hyperbolic tangent of x."]}, {"name": "matlib.empty()", "path": "reference/generated/numpy.matlib.empty", "type": "numpy.matlib.empty", "text": ["Return a new matrix of given shape and type, without initializing entries.", "Shape of the empty matrix.", "Desired output data-type.", "Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.", "See also", "empty, unlike zeros, does not set the matrix values to zero, and may therefore be marginally faster. On the other hand, it requires the user to manually set all the values in the array, and should be used with caution."]}, {"name": "matlib.eye()", "path": "reference/generated/numpy.matlib.eye", "type": "numpy.matlib.eye", "text": ["Return a matrix with ones on the diagonal and zeros elsewhere.", "Number of rows in the output.", "Number of columns in the output, defaults to n.", "Index of the diagonal: 0 refers to the main diagonal, a positive value refers to an upper diagonal, and a negative value to a lower diagonal.", "Data-type of the returned matrix.", "Whether the output should be stored in row-major (C-style) or column-major (Fortran-style) order in memory.", "New in version 1.14.0.", "A n x M matrix where all elements are equal to zero, except for the k-th diagonal, whose values are equal to one.", "See also", "Equivalent array function.", "Square identity matrix."]}, {"name": "matlib.identity()", "path": "reference/generated/numpy.matlib.identity", "type": "numpy.matlib.identity", "text": ["Returns the square identity matrix of given size.", "Size of the returned identity matrix.", "Data-type of the output. Defaults to float.", "n x n matrix with its main diagonal set to one, and all other elements zero.", "See also", "Equivalent array function.", "More general matrix identity function."]}, {"name": "matlib.ones()", "path": "reference/generated/numpy.matlib.ones", "type": "numpy.matlib.ones", "text": ["Matrix of ones.", "Return a matrix of given shape and type, filled with ones.", "Shape of the matrix", "The desired data-type for the matrix, default is np.float64.", "Whether to store matrix in C- or Fortran-contiguous order, default is \u2018C\u2019.", "Matrix of ones of given shape, dtype, and order.", "See also", "Array of ones.", "Zero matrix.", "If shape has length one i.e. (N,), or is a scalar N, out becomes a single row matrix of shape (1,N)."]}, {"name": "matlib.rand()", "path": "reference/generated/numpy.matlib.rand", "type": "numpy.matlib.rand", "text": ["Return a matrix of random values with given shape.", "Create a matrix of the given shape and propagate it with random samples from a uniform distribution over [0, 1).", "Shape of the output. If given as N integers, each integer specifies the size of one dimension. If given as a tuple, this tuple gives the complete shape.", "The matrix of random values with shape given by *args.", "See also", "If the first argument is a tuple, other arguments are ignored:"]}, {"name": "matlib.randn()", "path": "reference/generated/numpy.matlib.randn", "type": "numpy.matlib.randn", "text": ["Return a random matrix with data from the \u201cstandard normal\u201d distribution.", "randn generates a matrix filled with random floats sampled from a univariate \u201cnormal\u201d (Gaussian) distribution of mean 0 and variance 1.", "Shape of the output. If given as N integers, each integer specifies the size of one dimension. If given as a tuple, this tuple gives the complete shape.", "A matrix of floating-point samples drawn from the standard normal distribution.", "See also", "For random samples from \\(N(\\mu, \\sigma^2)\\), use:", "sigma * np.matlib.randn(...) + mu", "Two-by-four matrix of samples from \\(N(3, 6.25)\\):"]}, {"name": "matlib.repmat()", "path": "reference/generated/numpy.matlib.repmat", "type": "numpy.matlib.repmat", "text": ["Repeat a 0-D to 2-D array or matrix MxN times.", "The array or matrix to be repeated.", "The number of times a is repeated along the first and second axes.", "The result of repeating a."]}, {"name": "matlib.zeros()", "path": "reference/generated/numpy.matlib.zeros", "type": "numpy.matlib.zeros", "text": ["Return a matrix of given shape and type, filled with zeros.", "Shape of the matrix", "The desired data-type for the matrix, default is float.", "Whether to store the result in C- or Fortran-contiguous order, default is \u2018C\u2019.", "Zero matrix of given shape, dtype, and order.", "See also", "Equivalent array function.", "Return a matrix of ones.", "If shape has length one i.e. (N,), or is a scalar N, out becomes a single row matrix of shape (1,N)."]}, {"name": "Matrix library (numpy.matlib)", "path": "reference/routines.matlib", "type": "Matrix library ( \n      \n       numpy.matlib\n      \n      )", "text": ["This module contains all functions in the numpy namespace, with the following replacement functions that return matrices instead of ndarrays.", "Functions that are also in the numpy namespace and return matrices", "mat(data[, dtype])", "Interpret the input as a matrix.", "matrix(data[, dtype, copy])", "Note", "It is no longer recommended to use this class, even for linear", "asmatrix(data[, dtype])", "Interpret the input as a matrix.", "bmat(obj[, ldict, gdict])", "Build a matrix object from a string, nested sequence, or array.", "Replacement functions in matlib", "empty(shape[, dtype, order])", "Return a new matrix of given shape and type, without initializing entries.", "zeros(shape[, dtype, order])", "Return a matrix of given shape and type, filled with zeros.", "ones(shape[, dtype, order])", "Matrix of ones.", "eye(n[, M, k, dtype, order])", "Return a matrix with ones on the diagonal and zeros elsewhere.", "identity(n[, dtype])", "Returns the square identity matrix of given size.", "repmat(a, m, n)", "Repeat a 0-D to 2-D array or matrix MxN times.", "rand(*args)", "Return a matrix of random values with given shape.", "randn(*args)", "Return a random matrix with data from the \"standard normal\" distribution."]}, {"name": "matrix.all()", "path": "reference/generated/numpy.matrix.all", "type": "numpy.matrix.all", "text": ["method", "Test whether all matrix elements along a given axis evaluate to True.", "See also", "This is the same as ndarray.all, but it returns a matrix object."]}, {"name": "matrix.any()", "path": "reference/generated/numpy.matrix.any", "type": "numpy.matrix.any", "text": ["method", "Test whether any array element along a given axis evaluates to True.", "Refer to numpy.any for full documentation.", "Axis along which logical OR is performed", "Output to existing array instead of creating new one, must have same shape as expected output", "Returns a single bool if axis is None; otherwise, returns ndarray"]}, {"name": "matrix.argmax()", "path": "reference/generated/numpy.matrix.argmax", "type": "numpy.matrix.argmax", "text": ["method", "Indexes of the maximum values along an axis.", "Return the indexes of the first occurrences of the maximum values along the specified axis. If axis is None, the index is for the flattened matrix.", "See also", "This is the same as ndarray.argmax, but returns a matrix object where ndarray.argmax would return an ndarray."]}, {"name": "matrix.argmin()", "path": "reference/generated/numpy.matrix.argmin", "type": "numpy.matrix.argmin", "text": ["method", "Indexes of the minimum values along an axis.", "Return the indexes of the first occurrences of the minimum values along the specified axis. If axis is None, the index is for the flattened matrix.", "See also", "This is the same as ndarray.argmin, but returns a matrix object where ndarray.argmin would return an ndarray."]}, {"name": "matrix.argpartition()", "path": "reference/generated/numpy.matrix.argpartition", "type": "numpy.matrix.argpartition", "text": ["method", "Returns the indices that would partition this array.", "Refer to numpy.argpartition for full documentation.", "New in version 1.8.0.", "See also", "equivalent function"]}, {"name": "matrix.argsort()", "path": "reference/generated/numpy.matrix.argsort", "type": "numpy.matrix.argsort", "text": ["method", "Returns the indices that would sort this array.", "Refer to numpy.argsort for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.astype()", "path": "reference/generated/numpy.matrix.astype", "type": "numpy.matrix.astype", "text": ["method", "Copy of the array, cast to a specified type.", "Typecode or data-type to which the array is cast.", "Controls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means Fortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous, \u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements appear in memory as possible. Default is \u2018K\u2019.", "Controls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for backwards compatibility.", "If True, then sub-classes will be passed-through (default), otherwise the returned array will be forced to be a base-class array.", "By default, astype always returns a newly allocated array. If this is set to false, and the dtype, order, and subok requirements are satisfied, the input array is returned instead of a copy.", "Unless copy is False and the other conditions for returning the input array are satisfied (see description for copy input parameter), arr_t is a new array of the same shape as the input array, with dtype, order given by dtype, order.", "When casting from complex to float or int. To avoid this, one should use a.real.astype(t).", "Changed in version 1.17.0: Casting between a simple data type and a structured one is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is allowed, but casting from multiple fields is not.", "Changed in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019 casting mode requires that the string dtype length is long enough to store the max integer/float value converted."]}, {"name": "matrix.base", "path": "reference/generated/numpy.matrix.base", "type": "Standard array subclasses", "text": ["attribute", "Base object if memory is from some other object.", "The base of an array that owns its memory is None:", "Slicing creates a view, whose memory is shared with x:"]}, {"name": "matrix.byteswap()", "path": "reference/generated/numpy.matrix.byteswap", "type": "numpy.matrix.byteswap", "text": ["method", "Swap the bytes of the array elements", "Toggle between low-endian and big-endian data representation by returning a byteswapped array, optionally swapped in-place. Arrays of byte-strings are not swapped. The real and imaginary parts of a complex number are swapped individually.", "If True, swap bytes in-place, default is False.", "The byteswapped array. If inplace is True, this is a view to self.", "Arrays of byte-strings are not swapped", "but different representation in memory"]}, {"name": "matrix.choose()", "path": "reference/generated/numpy.matrix.choose", "type": "numpy.matrix.choose", "text": ["method", "Use an index array to construct a new array from a set of choices.", "Refer to numpy.choose for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.clip()", "path": "reference/generated/numpy.matrix.clip", "type": "numpy.matrix.clip", "text": ["method", "Return an array whose values are limited to [min, max]. One of max or min must be given.", "Refer to numpy.clip for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.compress()", "path": "reference/generated/numpy.matrix.compress", "type": "numpy.matrix.compress", "text": ["method", "Return selected slices of this array along given axis.", "Refer to numpy.compress for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.conj()", "path": "reference/generated/numpy.matrix.conj", "type": "numpy.matrix.conj", "text": ["method", "Complex-conjugate all elements.", "Refer to numpy.conjugate for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.conjugate()", "path": "reference/generated/numpy.matrix.conjugate", "type": "numpy.matrix.conjugate", "text": ["method", "Return the complex conjugate, element-wise.", "Refer to numpy.conjugate for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.copy()", "path": "reference/generated/numpy.matrix.copy", "type": "numpy.matrix.copy", "text": ["method", "Return a copy of the array.", "Controls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order, \u2018A\u2019 means \u2018F\u2019 if a is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the layout of a as closely as possible. (Note that this function and numpy.copy are very similar but have different default values for their order= arguments, and this function always passes sub-classes through.)", "See also", "Similar function with different default behavior", "This function is the preferred method for creating an array copy. The function numpy.copy is similar, but it defaults to using order \u2018K\u2019, and will not pass sub-classes through by default."]}, {"name": "matrix.ctypes", "path": "reference/generated/numpy.matrix.ctypes", "type": "Standard array subclasses", "text": ["attribute", "An object to simplify the interaction of the array with the ctypes module.", "This attribute creates an object that makes it easier to use arrays when calling shared libraries with the ctypes module. The returned object has, among others, data, shape, and strides attributes (see Notes below) which themselves return ctypes objects that can be used as arguments to a shared library.", "Possessing attributes data, shape, strides, etc.", "See also", "Below are the public attributes of this object which were documented in \u201cGuide to NumPy\u201d (we have omitted undocumented public attributes, as well as documented private attributes):", "A pointer to the memory area of the array as a Python integer. This memory area may contain data that is not aligned, or not in correct byte-order. The memory area may not even be writeable. The array flags and data-type of this array should be respected when passing this attribute to arbitrary C-code to avoid trouble that can include Python crashing. User Beware! The value of this attribute is exactly the same as self._array_interface_['data'][0].", "Note that unlike data_as, a reference will not be kept to the array: code like ctypes.c_void_p((a + b).ctypes.data) will result in a pointer to a deallocated array, and should be spelt (a + b).ctypes.data_as(ctypes.c_void_p)", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the C-integer corresponding to dtype('p') on this platform (see c_intp). This base-type could be ctypes.c_int, ctypes.c_long, or ctypes.c_longlong depending on the platform. The ctypes array contains the shape of the underlying array.", "(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is the same as for the shape attribute. This ctypes array contains the strides information from the underlying array. This strides information is important for showing how many bytes must be jumped to get to the next element in the array.", "Return the data pointer cast to a particular c-types object. For example, calling self._as_parameter_ is equivalent to self.data_as(ctypes.c_void_p). Perhaps you want to use the data as a pointer to a ctypes array of floating-point data: self.data_as(ctypes.POINTER(ctypes.c_double)).", "The returned pointer will keep a reference to the array.", "Return the shape tuple as an array of some other c-types type. For example: self.shape_as(ctypes.c_short).", "Return the strides tuple as an array of some other c-types type. For example: self.strides_as(ctypes.c_longlong).", "If the ctypes module is not available, then the ctypes attribute of array objects still returns something useful, but ctypes objects are not returned and errors may be raised instead. In particular, the object will still have the as_parameter attribute which will return an integer equal to the data attribute."]}, {"name": "matrix.cumprod()", "path": "reference/generated/numpy.matrix.cumprod", "type": "numpy.matrix.cumprod", "text": ["method", "Return the cumulative product of the elements along the given axis.", "Refer to numpy.cumprod for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.cumsum()", "path": "reference/generated/numpy.matrix.cumsum", "type": "numpy.matrix.cumsum", "text": ["method", "Return the cumulative sum of the elements along the given axis.", "Refer to numpy.cumsum for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.data", "path": "reference/generated/numpy.matrix.data", "type": "Standard array subclasses", "text": ["attribute", "Python buffer object pointing to the start of the array\u2019s data."]}, {"name": "matrix.diagonal()", "path": "reference/generated/numpy.matrix.diagonal", "type": "numpy.matrix.diagonal", "text": ["method", "Return specified diagonals. In NumPy 1.9 the returned array is a read-only view instead of a copy as in previous NumPy versions. In a future version the read-only restriction will be removed.", "Refer to numpy.diagonal for full documentation.", "See also", "equivalent function"]}, {"name": "matrix.dump()", "path": "reference/generated/numpy.matrix.dump", "type": "numpy.matrix.dump", "text": ["method", "Dump a pickle of the array to the specified file. The array can be read back with pickle.load or numpy.load.", "A string naming the dump file.", "Changed in version 1.17.0: pathlib.Path objects are now accepted."]}, {"name": "matrix.dumps()", "path": "reference/generated/numpy.matrix.dumps", "type": "numpy.matrix.dumps", "text": ["method", "Returns the pickle of the array as a string. pickle.loads will convert the string back to an array."]}, {"name": "matrix.fill()", "path": "reference/generated/numpy.matrix.fill", "type": "numpy.matrix.fill", "text": ["method", "Fill the array with a scalar value.", "All elements of a will be assigned this value."]}, {"name": "matrix.flags", "path": "reference/generated/numpy.matrix.flags", "type": "Standard array subclasses", "text": ["attribute", "Information about the memory layout of the array.", "The flags object can be accessed dictionary-like (as in a.flags['WRITEABLE']), or by using lowercased attribute names (as in a.flags.writeable). Short flag names are only supported in dictionary access.", "Only the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be changed by the user, via direct assignment to the attribute or dictionary entry, or by calling ndarray.setflags.", "The array flags cannot be set arbitrarily:", "Arrays can be both C-style and Fortran-style contiguous simultaneously. This is clear for 1-dimensional arrays, but can also be true for higher dimensional arrays.", "Even for contiguous arrays a stride for a given dimension arr.strides[dim] may be arbitrary if arr.shape[dim] == 1 or the array has no elements. It does not generally hold that self.strides[-1] == self.itemsize for C-style contiguous arrays or self.strides[0] == self.itemsize for Fortran-style contiguous arrays is true.", "The data is in a single, C-style contiguous segment.", "The data is in a single, Fortran-style contiguous segment.", "The array owns the memory it uses or borrows it from another object.", "The data area can be written to. Setting this to False locks the data, making it read-only. A view (slice, etc.) inherits WRITEABLE from its base array at creation time, but a view of a writeable array may be subsequently locked while the base array remains writeable. (The opposite is not true, in that a view of a locked array may not be made writeable. However, currently, locking a base object does not lock any views that already reference it, so under that circumstance it is possible to alter the contents of a locked array via a previously created writeable view onto it.) Attempting to change a non-writeable array raises a RuntimeError exception.", "The data and all elements are aligned appropriately for the hardware.", "This array is a copy of some other array. The C-API function PyArray_ResolveWritebackIfCopy must be called before deallocating to the base array will be updated with the contents of this array.", "(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array. When this array is deallocated, the base array will be updated with the contents of this array.", "F_CONTIGUOUS and not C_CONTIGUOUS.", "F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).", "ALIGNED and WRITEABLE.", "BEHAVED and C_CONTIGUOUS.", "BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS."]}, {"name": "matrix.flat", "path": "reference/generated/numpy.matrix.flat", "type": "Standard array subclasses", "text": ["attribute", "A 1-D iterator over the array.", "This is a numpy.flatiter instance, which acts similarly to, but is not a subclass of, Python\u2019s built-in iterator object.", "See also", "Return a copy of the array collapsed into one dimension.", "An assignment example:"]}, {"name": "matrix.flatten()", "path": "reference/generated/numpy.matrix.flatten", "type": "numpy.matrix.flatten", "text": ["method", "Return a flattened copy of the matrix.", "All N elements of the matrix are placed into a single row.", "\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in column-major (Fortran-style) order. \u2018A\u2019 means to flatten in column-major order if m is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019 means to flatten m in the order the elements occur in memory. The default is \u2018C\u2019.", "A copy of the matrix, flattened to a (1, N) matrix where N is the number of elements in the original matrix.", "See also", "Return a flattened array.", "A 1-D flat iterator over the matrix."]}, {"name": "matrix.getA()", "path": "reference/generated/numpy.matrix.geta", "type": "numpy.matrix.getA", "text": ["method", "Return self as an ndarray object.", "Equivalent to np.asarray(self).", "self as an ndarray"]}, {"name": "matrix.getA1()", "path": "reference/generated/numpy.matrix.geta1", "type": "numpy.matrix.getA1", "text": ["method", "Return self as a flattened ndarray.", "Equivalent to np.asarray(x).ravel()", "self, 1-D, as an ndarray"]}, {"name": "matrix.getfield()", "path": "reference/generated/numpy.matrix.getfield", "type": "numpy.matrix.getfield", "text": ["method", "Returns a field of the given array as a certain type.", "A field is a view of the array data 