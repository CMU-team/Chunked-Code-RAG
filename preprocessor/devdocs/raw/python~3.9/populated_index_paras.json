[{"name": "abc", "path": "library/abc", "type": "Runtime", "text": ["Source code: Lib/abc.py", "This module provides the infrastructure for defining abstract base classes (ABCs) in Python, as outlined in PEP 3119; see the PEP for why this was added to Python. (See also PEP 3141 and the numbers module regarding a type hierarchy for numbers based on ABCs.)", "The collections module has some concrete classes that derive from ABCs; these can, of course, be further derived. In addition, the collections.abc submodule has some ABCs that can be used to test whether a class or instance provides a particular interface, for example, if it is hashable or if it is a mapping.", "This module provides the metaclass ABCMeta for defining ABCs and a helper class ABC to alternatively define ABCs through inheritance:", "A helper class that has ABCMeta as its metaclass. With this class, an abstract base class can be created by simply deriving from ABC avoiding sometimes confusing metaclass usage, for example:", "Note that the type of ABC is still ABCMeta, therefore inheriting from ABC requires the usual precautions regarding metaclass usage, as multiple inheritance may lead to metaclass conflicts. One may also define an abstract base class by passing the metaclass keyword and using ABCMeta directly, for example:", "New in version 3.4.", "Metaclass for defining Abstract Base Classes (ABCs).", "Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as \u201cvirtual subclasses\u201d \u2013 these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won\u2019t show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). 1", "Classes created with a metaclass of ABCMeta have the following method:", "Register subclass as a \u201cvirtual subclass\u201d of this ABC. For example:", "Changed in version 3.3: Returns the registered subclass, to allow usage as a class decorator.", "Changed in version 3.4: To detect calls to register(), you can use the get_cache_token() function.", "You can also override this method in an abstract base class:", "(Must be defined as a class method.)", "Check whether subclass is considered a subclass of this ABC. This means that you can customize the behavior of issubclass further without the need to call register() on every class you want to consider a subclass of the ABC. (This class method is called from the __subclasscheck__() method of the ABC.)", "This method should return True, False or NotImplemented. If it returns True, the subclass is considered a subclass of this ABC. If it returns False, the subclass is not considered a subclass of this ABC, even if it would normally be one. If it returns NotImplemented, the subclass check is continued with the usual mechanism.", "For a demonstration of these concepts, look at this example ABC definition:", "The ABC MyIterable defines the standard iterable method, __iter__(), as an abstract method. The implementation given here can still be called from subclasses. The get_iterator() method is also part of the MyIterable abstract base class, but it does not have to be overridden in non-abstract derived classes.", "The __subclasshook__() class method defined here says that any class that has an __iter__() method in its __dict__ (or in that of one of its base classes, accessed via the __mro__ list) is considered a MyIterable too.", "Finally, the last line makes Foo a virtual subclass of MyIterable, even though it does not define an __iter__() method (it uses the old-style iterable protocol, defined in terms of __len__() and __getitem__()). Note that this will not make get_iterator available as a method of Foo, so it is provided separately.", "The abc module also provides the following decorator:", "A decorator indicating abstract methods.", "Using this decorator requires that the class\u2019s metaclass is ABCMeta or is derived from it. A class that has a metaclass derived from ABCMeta cannot be instantiated unless all of its abstract methods and properties are overridden. The abstract methods can be called using any of the normal \u2018super\u2019 call mechanisms. abstractmethod() may be used to declare abstract methods for properties and descriptors.", "Dynamically adding abstract methods to a class, or attempting to modify the abstraction status of a method or class once it is created, are not supported. The abstractmethod() only affects subclasses derived using regular inheritance; \u201cvirtual subclasses\u201d registered with the ABC\u2019s register() method are not affected.", "When abstractmethod() is applied in combination with other method descriptors, it should be applied as the innermost decorator, as shown in the following usage examples:", "In order to correctly interoperate with the abstract base class machinery, the descriptor must identify itself as abstract using __isabstractmethod__. In general, this attribute should be True if any of the methods used to compose the descriptor are abstract. For example, Python\u2019s built-in property does the equivalent of:", "Note", "Unlike Java abstract methods, these abstract methods may have an implementation. This implementation can be called via the super() mechanism from the class that overrides it. This could be useful as an end-point for a super-call in a framework that uses cooperative multiple-inheritance.", "The abc module also supports the following legacy decorators:", "New in version 3.2.", "Deprecated since version 3.3: It is now possible to use classmethod with abstractmethod(), making this decorator redundant.", "A subclass of the built-in classmethod(), indicating an abstract classmethod. Otherwise it is similar to abstractmethod().", "This special case is deprecated, as the classmethod() decorator is now correctly identified as abstract when applied to an abstract method:", "New in version 3.2.", "Deprecated since version 3.3: It is now possible to use staticmethod with abstractmethod(), making this decorator redundant.", "A subclass of the built-in staticmethod(), indicating an abstract staticmethod. Otherwise it is similar to abstractmethod().", "This special case is deprecated, as the staticmethod() decorator is now correctly identified as abstract when applied to an abstract method:", "Deprecated since version 3.3: It is now possible to use property, property.getter(), property.setter() and property.deleter() with abstractmethod(), making this decorator redundant.", "A subclass of the built-in property(), indicating an abstract property.", "This special case is deprecated, as the property() decorator is now correctly identified as abstract when applied to an abstract method:", "The above example defines a read-only property; you can also define a read-write abstract property by appropriately marking one or more of the underlying methods as abstract:", "If only some components are abstract, only those components need to be updated to create a concrete property in a subclass:", "The abc module also provides the following functions:", "Returns the current abstract base class cache token.", "The token is an opaque object (that supports equality testing) identifying the current version of the abstract base class cache for virtual subclasses. The token changes with every call to ABCMeta.register() on any ABC.", "New in version 3.4.", "C++ programmers should note that Python\u2019s virtual base class concept is not the same as C++\u2019s."]}, {"name": "abc.ABC", "path": "library/abc#abc.ABC", "type": "Runtime", "text": ["A helper class that has ABCMeta as its metaclass. With this class, an abstract base class can be created by simply deriving from ABC avoiding sometimes confusing metaclass usage, for example:", "Note that the type of ABC is still ABCMeta, therefore inheriting from ABC requires the usual precautions regarding metaclass usage, as multiple inheritance may lead to metaclass conflicts. One may also define an abstract base class by passing the metaclass keyword and using ABCMeta directly, for example:", "New in version 3.4."]}, {"name": "abc.ABCMeta", "path": "library/abc#abc.ABCMeta", "type": "Runtime", "text": ["Metaclass for defining Abstract Base Classes (ABCs).", "Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as \u201cvirtual subclasses\u201d \u2013 these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won\u2019t show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). 1", "Classes created with a metaclass of ABCMeta have the following method:", "Register subclass as a \u201cvirtual subclass\u201d of this ABC. For example:", "Changed in version 3.3: Returns the registered subclass, to allow usage as a class decorator.", "Changed in version 3.4: To detect calls to register(), you can use the get_cache_token() function.", "You can also override this method in an abstract base class:", "(Must be defined as a class method.)", "Check whether subclass is considered a subclass of this ABC. This means that you can customize the behavior of issubclass further without the need to call register() on every class you want to consider a subclass of the ABC. (This class method is called from the __subclasscheck__() method of the ABC.)", "This method should return True, False or NotImplemented. If it returns True, the subclass is considered a subclass of this ABC. If it returns False, the subclass is not considered a subclass of this ABC, even if it would normally be one. If it returns NotImplemented, the subclass check is continued with the usual mechanism.", "For a demonstration of these concepts, look at this example ABC definition:", "The ABC MyIterable defines the standard iterable method, __iter__(), as an abstract method. The implementation given here can still be called from subclasses. The get_iterator() method is also part of the MyIterable abstract base class, but it does not have to be overridden in non-abstract derived classes.", "The __subclasshook__() class method defined here says that any class that has an __iter__() method in its __dict__ (or in that of one of its base classes, accessed via the __mro__ list) is considered a MyIterable too.", "Finally, the last line makes Foo a virtual subclass of MyIterable, even though it does not define an __iter__() method (it uses the old-style iterable protocol, defined in terms of __len__() and __getitem__()). Note that this will not make get_iterator available as a method of Foo, so it is provided separately."]}, {"name": "abc.ABCMeta.register()", "path": "library/abc#abc.ABCMeta.register", "type": "Runtime", "text": ["Register subclass as a \u201cvirtual subclass\u201d of this ABC. For example:", "Changed in version 3.3: Returns the registered subclass, to allow usage as a class decorator.", "Changed in version 3.4: To detect calls to register(), you can use the get_cache_token() function."]}, {"name": "abc.ABCMeta.__subclasshook__()", "path": "library/abc#abc.ABCMeta.__subclasshook__", "type": "Runtime", "text": ["(Must be defined as a class method.)", "Check whether subclass is considered a subclass of this ABC. This means that you can customize the behavior of issubclass further without the need to call register() on every class you want to consider a subclass of the ABC. (This class method is called from the __subclasscheck__() method of the ABC.)", "This method should return True, False or NotImplemented. If it returns True, the subclass is considered a subclass of this ABC. If it returns False, the subclass is not considered a subclass of this ABC, even if it would normally be one. If it returns NotImplemented, the subclass check is continued with the usual mechanism."]}, {"name": "abc.abstractclassmethod()", "path": "library/abc#abc.abstractclassmethod", "type": "Runtime", "text": ["New in version 3.2.", "Deprecated since version 3.3: It is now possible to use classmethod with abstractmethod(), making this decorator redundant.", "A subclass of the built-in classmethod(), indicating an abstract classmethod. Otherwise it is similar to abstractmethod().", "This special case is deprecated, as the classmethod() decorator is now correctly identified as abstract when applied to an abstract method:"]}, {"name": "abc.abstractmethod()", "path": "library/abc#abc.abstractmethod", "type": "Runtime", "text": ["A decorator indicating abstract methods.", "Using this decorator requires that the class\u2019s metaclass is ABCMeta or is derived from it. A class that has a metaclass derived from ABCMeta cannot be instantiated unless all of its abstract methods and properties are overridden. The abstract methods can be called using any of the normal \u2018super\u2019 call mechanisms. abstractmethod() may be used to declare abstract methods for properties and descriptors.", "Dynamically adding abstract methods to a class, or attempting to modify the abstraction status of a method or class once it is created, are not supported. The abstractmethod() only affects subclasses derived using regular inheritance; \u201cvirtual subclasses\u201d registered with the ABC\u2019s register() method are not affected.", "When abstractmethod() is applied in combination with other method descriptors, it should be applied as the innermost decorator, as shown in the following usage examples:", "In order to correctly interoperate with the abstract base class machinery, the descriptor must identify itself as abstract using __isabstractmethod__. In general, this attribute should be True if any of the methods used to compose the descriptor are abstract. For example, Python\u2019s built-in property does the equivalent of:", "Note", "Unlike Java abstract methods, these abstract methods may have an implementation. This implementation can be called via the super() mechanism from the class that overrides it. This could be useful as an end-point for a super-call in a framework that uses cooperative multiple-inheritance."]}, {"name": "abc.abstractproperty()", "path": "library/abc#abc.abstractproperty", "type": "Runtime", "text": ["Deprecated since version 3.3: It is now possible to use property, property.getter(), property.setter() and property.deleter() with abstractmethod(), making this decorator redundant.", "A subclass of the built-in property(), indicating an abstract property.", "This special case is deprecated, as the property() decorator is now correctly identified as abstract when applied to an abstract method:", "The above example defines a read-only property; you can also define a read-write abstract property by appropriately marking one or more of the underlying methods as abstract:", "If only some components are abstract, only those components need to be updated to create a concrete property in a subclass:"]}, {"name": "abc.abstractstaticmethod()", "path": "library/abc#abc.abstractstaticmethod", "type": "Runtime", "text": ["New in version 3.2.", "Deprecated since version 3.3: It is now possible to use staticmethod with abstractmethod(), making this decorator redundant.", "A subclass of the built-in staticmethod(), indicating an abstract staticmethod. Otherwise it is similar to abstractmethod().", "This special case is deprecated, as the staticmethod() decorator is now correctly identified as abstract when applied to an abstract method:"]}, {"name": "abc.get_cache_token()", "path": "library/abc#abc.get_cache_token", "type": "Runtime", "text": ["Returns the current abstract base class cache token.", "The token is an opaque object (that supports equality testing) identifying the current version of the abstract base class cache for virtual subclasses. The token changes with every call to ABCMeta.register() on any ABC.", "New in version 3.4."]}, {"name": "abs()", "path": "library/functions#abs", "type": "Built-in Functions", "text": ["Return the absolute value of a number. The argument may be an integer, a floating point number, or an object implementing __abs__(). If the argument is a complex number, its magnitude is returned."]}, {"name": "aifc", "path": "library/aifc", "type": "Multimedia", "text": ["Source code: Lib/aifc.py", "This module provides support for reading and writing AIFF and AIFF-C files. AIFF is Audio Interchange File Format, a format for storing digital audio samples in a file. AIFF-C is a newer version of the format that includes the ability to compress the audio data.", "Audio files have a number of parameters that describe the audio data. The sampling rate or frame rate is the number of times per second the sound is sampled. The number of channels indicate if the audio is mono, stereo, or quadro. Each frame consists of one sample per channel. The sample size is the size in bytes of each sample. Thus a frame consists of nchannels * samplesize bytes, and a second\u2019s worth of audio consists of nchannels * samplesize * framerate bytes.", "For example, CD quality audio has a sample size of two bytes (16 bits), uses two channels (stereo) and has a frame rate of 44,100 frames/second. This gives a frame size of 4 bytes (2*2), and a second\u2019s worth occupies 2*2*44100 bytes (176,400 bytes).", "Module aifc defines the following function:", "Open an AIFF or AIFF-C file and return an object instance with methods that are described below. The argument file is either a string naming a file or a file object. mode must be 'r' or 'rb' when the file must be opened for reading, or 'w' or 'wb' when the file must be opened for writing. If omitted, file.mode is used if it exists, otherwise 'rb' is used. When used for writing, the file object should be seekable, unless you know ahead of time how many samples you are going to write in total and use writeframesraw() and setnframes(). The open() function may be used in a with statement. When the with block completes, the close() method is called.", "Changed in version 3.4: Support for the with statement was added.", "Objects returned by open() when a file is opened for reading have the following methods:", "Return the number of audio channels (1 for mono, 2 for stereo).", "Return the size in bytes of individual samples.", "Return the sampling rate (number of audio frames per second).", "Return the number of audio frames in the file.", "Return a bytes array of length 4 describing the type of compression used in the audio file. For AIFF files, the returned value is b'NONE'.", "Return a bytes array convertible to a human-readable description of the type of compression used in the audio file. For AIFF files, the returned value is b'not compressed'.", "Returns a namedtuple() (nchannels, sampwidth,\nframerate, nframes, comptype, compname), equivalent to output of the get*() methods.", "Return a list of markers in the audio file. A marker consists of a tuple of three elements. The first is the mark ID (an integer), the second is the mark position in frames from the beginning of the data (an integer), the third is the name of the mark (a string).", "Return the tuple as described in getmarkers() for the mark with the given id.", "Read and return the next nframes frames from the audio file. The returned data is a string containing for each frame the uncompressed samples of all channels.", "Rewind the read pointer. The next readframes() will start from the beginning.", "Seek to the specified frame number.", "Return the current frame number.", "Close the AIFF file. After calling this method, the object can no longer be used.", "Objects returned by open() when a file is opened for writing have all the above methods, except for readframes() and setpos(). In addition the following methods exist. The get*() methods can only be called after the corresponding set*() methods have been called. Before the first writeframes() or writeframesraw(), all parameters except for the number of frames must be filled in.", "Create an AIFF file. The default is that an AIFF-C file is created, unless the name of the file ends in '.aiff' in which case the default is an AIFF file.", "Create an AIFF-C file. The default is that an AIFF-C file is created, unless the name of the file ends in '.aiff' in which case the default is an AIFF file.", "Specify the number of channels in the audio file.", "Specify the size in bytes of audio samples.", "Specify the sampling frequency in frames per second.", "Specify the number of frames that are to be written to the audio file. If this parameter is not set, or not set correctly, the file needs to support seeking.", "Specify the compression type. If not specified, the audio data will not be compressed. In AIFF files, compression is not possible. The name parameter should be a human-readable description of the compression type as a bytes array, the type parameter should be a bytes array of length 4. Currently the following compression types are supported: b'NONE', b'ULAW', b'ALAW', b'G722'.", "Set all the above parameters at once. The argument is a tuple consisting of the various parameters. This means that it is possible to use the result of a getparams() call as argument to setparams().", "Add a mark with the given id (larger than 0), and the given name at the given position. This method can be called at any time before close().", "Return the current write position in the output file. Useful in combination with setmark().", "Write data to the output file. This method can only be called after the audio file parameters have been set.", "Changed in version 3.4: Any bytes-like object is now accepted.", "Like writeframes(), except that the header of the audio file is not updated.", "Changed in version 3.4: Any bytes-like object is now accepted.", "Close the AIFF file. The header of the file is updated to reflect the actual size of the audio data. After calling this method, the object can no longer be used."]}, {"name": "aifc.aifc.aifc()", "path": "library/aifc#aifc.aifc.aifc", "type": "Multimedia", "text": ["Create an AIFF-C file. The default is that an AIFF-C file is created, unless the name of the file ends in '.aiff' in which case the default is an AIFF file."]}, {"name": "aifc.aifc.aiff()", "path": "library/aifc#aifc.aifc.aiff", "type": "Multimedia", "text": ["Create an AIFF file. The default is that an AIFF-C file is created, unless the name of the file ends in '.aiff' in which case the default is an AIFF file."]}, {"name": "aifc.aifc.close()", "path": "library/aifc#aifc.aifc.close", "type": "Multimedia", "text": ["Close the AIFF file. After calling this method, the object can no longer be used."]}, {"name": "aifc.aifc.getcompname()", "path": "library/aifc#aifc.aifc.getcompname", "type": "Multimedia", "text": ["Return a bytes array convertible to a human-readable description of the type of compression used in the audio file. For AIFF files, the returned value is b'not compressed'."]}, {"name": "aifc.aifc.getcomptype()", "path": "library/aifc#aifc.aifc.getcomptype", "type": "Multimedia", "text": ["Return a bytes array of length 4 describing the type of compression used in the audio file. For AIFF files, the returned value is b'NONE'."]}, {"name": "aifc.aifc.getframerate()", "path": "library/aifc#aifc.aifc.getframerate", "type": "Multimedia", "text": ["Return the sampling rate (number of audio frames per second)."]}, {"name": "aifc.aifc.getmark()", "path": "library/aifc#aifc.aifc.getmark", "type": "Multimedia", "text": ["Return the tuple as described in getmarkers() for the mark with the given id."]}, {"name": "aifc.aifc.getmarkers()", "path": "library/aifc#aifc.aifc.getmarkers", "type": "Multimedia", "text": ["Return a list of markers in the audio file. A marker consists of a tuple of three elements. The first is the mark ID (an integer), the second is the mark position in frames from the beginning of the data (an integer), the third is the name of the mark (a string)."]}, {"name": "aifc.aifc.getnchannels()", "path": "library/aifc#aifc.aifc.getnchannels", "type": "Multimedia", "text": ["Return the number of audio channels (1 for mono, 2 for stereo)."]}, {"name": "aifc.aifc.getnframes()", "path": "library/aifc#aifc.aifc.getnframes", "type": "Multimedia", "text": ["Return the number of audio frames in the file."]}, {"name": "aifc.aifc.getparams()", "path": "library/aifc#aifc.aifc.getparams", "type": "Multimedia", "text": ["Returns a namedtuple() (nchannels, sampwidth,\nframerate, nframes, comptype, compname), equivalent to output of the get*() methods."]}, {"name": "aifc.aifc.getsampwidth()", "path": "library/aifc#aifc.aifc.getsampwidth", "type": "Multimedia", "text": ["Return the size in bytes of individual samples."]}, {"name": "aifc.aifc.readframes()", "path": "library/aifc#aifc.aifc.readframes", "type": "Multimedia", "text": ["Read and return the next nframes frames from the audio file. The returned data is a string containing for each frame the uncompressed samples of all channels."]}, {"name": "aifc.aifc.rewind()", "path": "library/aifc#aifc.aifc.rewind", "type": "Multimedia", "text": ["Rewind the read pointer. The next readframes() will start from the beginning."]}, {"name": "aifc.aifc.setcomptype()", "path": "library/aifc#aifc.aifc.setcomptype", "type": "Multimedia", "text": ["Specify the compression type. If not specified, the audio data will not be compressed. In AIFF files, compression is not possible. The name parameter should be a human-readable description of the compression type as a bytes array, the type parameter should be a bytes array of length 4. Currently the following compression types are supported: b'NONE', b'ULAW', b'ALAW', b'G722'."]}, {"name": "aifc.aifc.setframerate()", "path": "library/aifc#aifc.aifc.setframerate", "type": "Multimedia", "text": ["Specify the sampling frequency in frames per second."]}, {"name": "aifc.aifc.setmark()", "path": "library/aifc#aifc.aifc.setmark", "type": "Multimedia", "text": ["Add a mark with the given id (larger than 0), and the given name at the given position. This method can be called at any time before close()."]}, {"name": "aifc.aifc.setnchannels()", "path": "library/aifc#aifc.aifc.setnchannels", "type": "Multimedia", "text": ["Specify the number of channels in the audio file."]}, {"name": "aifc.aifc.setnframes()", "path": "library/aifc#aifc.aifc.setnframes", "type": "Multimedia", "text": ["Specify the number of frames that are to be written to the audio file. If this parameter is not set, or not set correctly, the file needs to support seeking."]}, {"name": "aifc.aifc.setparams()", "path": "library/aifc#aifc.aifc.setparams", "type": "Multimedia", "text": ["Set all the above parameters at once. The argument is a tuple consisting of the various parameters. This means that it is possible to use the result of a getparams() call as argument to setparams()."]}, {"name": "aifc.aifc.setpos()", "path": "library/aifc#aifc.aifc.setpos", "type": "Multimedia", "text": ["Seek to the specified frame number."]}, {"name": "aifc.aifc.setsampwidth()", "path": "library/aifc#aifc.aifc.setsampwidth", "type": "Multimedia", "text": ["Specify the size in bytes of audio samples."]}, {"name": "aifc.aifc.tell()", "path": "library/aifc#aifc.aifc.tell", "type": "Multimedia", "text": ["Return the current frame number."]}, {"name": "aifc.aifc.writeframes()", "path": "library/aifc#aifc.aifc.writeframes", "type": "Multimedia", "text": ["Write data to the output file. This method can only be called after the audio file parameters have been set.", "Changed in version 3.4: Any bytes-like object is now accepted."]}, {"name": "aifc.aifc.writeframesraw()", "path": "library/aifc#aifc.aifc.writeframesraw", "type": "Multimedia", "text": ["Like writeframes(), except that the header of the audio file is not updated.", "Changed in version 3.4: Any bytes-like object is now accepted."]}, {"name": "aifc.open()", "path": "library/aifc#aifc.open", "type": "Multimedia", "text": ["Open an AIFF or AIFF-C file and return an object instance with methods that are described below. The argument file is either a string naming a file or a file object. mode must be 'r' or 'rb' when the file must be opened for reading, or 'w' or 'wb' when the file must be opened for writing. If omitted, file.mode is used if it exists, otherwise 'rb' is used. When used for writing, the file object should be seekable, unless you know ahead of time how many samples you are going to write in total and use writeframesraw() and setnframes(). The open() function may be used in a with statement. When the with block completes, the close() method is called.", "Changed in version 3.4: Support for the with statement was added."]}, {"name": "all()", "path": "library/functions#all", "type": "Built-in Functions", "text": ["Return True if all elements of the iterable are true (or if the iterable is empty). Equivalent to:"]}, {"name": "any()", "path": "library/functions#any", "type": "Built-in Functions", "text": ["Return True if any element of the iterable is true. If the iterable is empty, return False. Equivalent to:"]}, {"name": "argparse", "path": "library/argparse", "type": "Operating System", "text": ["New in version 3.2.", "Source code: Lib/argparse.py", "Tutorial", "This page contains the API reference information. For a more gentle introduction to Python command-line parsing, have a look at the argparse tutorial.", "The argparse module makes it easy to write user-friendly command-line interfaces. The program defines what arguments it requires, and argparse will figure out how to parse those out of sys.argv. The argparse module also automatically generates help and usage messages and issues errors when users give the program invalid arguments.", "The following code is a Python program that takes a list of integers and produces either the sum or the max:", "Assuming the Python code above is saved into a file called prog.py, it can be run at the command line and provides useful help messages:", "When run with the appropriate arguments, it prints either the sum or the max of the command-line integers:", "If invalid arguments are passed in, it will issue an error:", "The following sections walk you through this example.", "The first step in using the argparse is creating an ArgumentParser object:", "The ArgumentParser object will hold all the information necessary to parse the command line into Python data types.", "Filling an ArgumentParser with information about program arguments is done by making calls to the add_argument() method. Generally, these calls tell the ArgumentParser how to take the strings on the command line and turn them into objects. This information is stored and used when parse_args() is called. For example:", "Later, calling parse_args() will return an object with two attributes, integers and accumulate. The integers attribute will be a list of one or more ints, and the accumulate attribute will be either the sum() function, if --sum was specified at the command line, or the max() function if it was not.", "ArgumentParser parses arguments through the parse_args() method. This will inspect the command line, convert each argument to the appropriate type and then invoke the appropriate action. In most cases, this means a simple Namespace object will be built up from attributes parsed out of the command line:", "In a script, parse_args() will typically be called with no arguments, and the ArgumentParser will automatically determine the command-line arguments from sys.argv.", "Create a new ArgumentParser object. All parameters should be passed as keyword arguments. Each parameter has its own more detailed description below, but in short they are:", "Changed in version 3.5: allow_abbrev parameter was added.", "Changed in version 3.8: In previous versions, allow_abbrev also disabled grouping of short flags such as -vv to mean -v -v.", "Changed in version 3.9: exit_on_error parameter was added.", "The following sections describe how each of these are used.", "By default, ArgumentParser objects use sys.argv[0] to determine how to display the name of the program in help messages. This default is almost always desirable because it will make the help messages match how the program was invoked on the command line. For example, consider a file named myprogram.py with the following code:", "The help for this program will display myprogram.py as the program name (regardless of where the program was invoked from):", "To change this default behavior, another value can be supplied using the prog= argument to ArgumentParser:", "Note that the program name, whether determined from sys.argv[0] or from the prog= argument, is available to help messages using the %(prog)s format specifier.", "By default, ArgumentParser calculates the usage message from the arguments it contains:", "The default message can be overridden with the usage= keyword argument:", "The %(prog)s format specifier is available to fill in the program name in your usage messages.", "Most calls to the ArgumentParser constructor will use the description= keyword argument. This argument gives a brief description of what the program does and how it works. In help messages, the description is displayed between the command-line usage string and the help messages for the various arguments:", "By default, the description will be line-wrapped so that it fits within the given space. To change this behavior, see the formatter_class argument.", "Some programs like to display additional description of the program after the description of the arguments. Such text can be specified using the epilog= argument to ArgumentParser:", "As with the description argument, the epilog= text is by default line-wrapped, but this behavior can be adjusted with the formatter_class argument to ArgumentParser.", "Sometimes, several parsers share a common set of arguments. Rather than repeating the definitions of these arguments, a single parser with all the shared arguments and passed to parents= argument to ArgumentParser can be used. The parents= argument takes a list of ArgumentParser objects, collects all the positional and optional actions from them, and adds these actions to the ArgumentParser object being constructed:", "Note that most parent parsers will specify add_help=False. Otherwise, the ArgumentParser will see two -h/--help options (one in the parent and one in the child) and raise an error.", "Note", "You must fully initialize the parsers before passing them via parents=. If you change the parent parsers after the child parser, those changes will not be reflected in the child.", "ArgumentParser objects allow the help formatting to be customized by specifying an alternate formatting class. Currently, there are four such classes:", "RawDescriptionHelpFormatter and RawTextHelpFormatter give more control over how textual descriptions are displayed. By default, ArgumentParser objects line-wrap the description and epilog texts in command-line help messages:", "Passing RawDescriptionHelpFormatter as formatter_class= indicates that description and epilog are already correctly formatted and should not be line-wrapped:", "RawTextHelpFormatter maintains whitespace for all sorts of help text, including argument descriptions. However, multiple new lines are replaced with one. If you wish to preserve multiple blank lines, add spaces between the newlines.", "ArgumentDefaultsHelpFormatter automatically adds information about default values to each of the argument help messages:", "MetavarTypeHelpFormatter uses the name of the type argument for each argument as the display name for its values (rather than using the dest as the regular formatter does):", "Most command-line options will use - as the prefix, e.g. -f/--foo. Parsers that need to support different or additional prefix characters, e.g. for options like +f or /foo, may specify them using the prefix_chars= argument to the ArgumentParser constructor:", "The prefix_chars= argument defaults to '-'. Supplying a set of characters that does not include - will cause -f/--foo options to be disallowed.", "Sometimes, for example when dealing with a particularly long argument lists, it may make sense to keep the list of arguments in a file rather than typing it out at the command line. If the fromfile_prefix_chars= argument is given to the ArgumentParser constructor, then arguments that start with any of the specified characters will be treated as files, and will be replaced by the arguments they contain. For example:", "Arguments read from a file must by default be one per line (but see also convert_arg_line_to_args()) and are treated as if they were in the same place as the original file referencing argument on the command line. So in the example above, the expression ['-f', 'foo', '@args.txt'] is considered equivalent to the expression ['-f', 'foo', '-f', 'bar'].", "The fromfile_prefix_chars= argument defaults to None, meaning that arguments will never be treated as file references.", "Generally, argument defaults are specified either by passing a default to add_argument() or by calling the set_defaults() methods with a specific set of name-value pairs. Sometimes however, it may be useful to specify a single parser-wide default for arguments. This can be accomplished by passing the argument_default= keyword argument to ArgumentParser. For example, to globally suppress attribute creation on parse_args() calls, we supply argument_default=SUPPRESS:", "Normally, when you pass an argument list to the parse_args() method of an ArgumentParser, it recognizes abbreviations of long options.", "This feature can be disabled by setting allow_abbrev to False:", "New in version 3.5.", "ArgumentParser objects do not allow two actions with the same option string. By default, ArgumentParser objects raise an exception if an attempt is made to create an argument with an option string that is already in use:", "Sometimes (e.g. when using parents) it may be useful to simply override any older arguments with the same option string. To get this behavior, the value 'resolve' can be supplied to the conflict_handler= argument of ArgumentParser:", "Note that ArgumentParser objects only remove an action if all of its option strings are overridden. So, in the example above, the old -f/--foo action is retained as the -f action, because only the --foo option string was overridden.", "By default, ArgumentParser objects add an option which simply displays the parser\u2019s help message. For example, consider a file named myprogram.py containing the following code:", "If -h or --help is supplied at the command line, the ArgumentParser help will be printed:", "Occasionally, it may be useful to disable the addition of this help option. This can be achieved by passing False as the add_help= argument to ArgumentParser:", "The help option is typically -h/--help. The exception to this is if the prefix_chars= is specified and does not include -, in which case -h and --help are not valid options. In this case, the first character in prefix_chars is used to prefix the help options:", "Normally, when you pass an invalid argument list to the parse_args() method of an ArgumentParser, it will exit with error info.", "If the user would like to catch errors manually, the feature can be enabled by setting exit_on_error to False:", "New in version 3.9.", "Define how a single command-line argument should be parsed. Each parameter has its own more detailed description below, but in short they are:", "The following sections describe how each of these are used.", "The add_argument() method must know whether an optional argument, like -f or --foo, or a positional argument, like a list of filenames, is expected. The first arguments passed to add_argument() must therefore be either a series of flags, or a simple argument name. For example, an optional argument could be created like:", "while a positional argument could be created like:", "When parse_args() is called, optional arguments will be identified by the - prefix, and the remaining arguments will be assumed to be positional:", "ArgumentParser objects associate command-line arguments with actions. These actions can do just about anything with the command-line arguments associated with them, though most actions simply add an attribute to the object returned by parse_args(). The action keyword argument specifies how the command-line arguments should be handled. The supplied actions are:", "'store' - This just stores the argument\u2019s value. This is the default action. For example:", "'store_const' - This stores the value specified by the const keyword argument. The 'store_const' action is most commonly used with optional arguments that specify some sort of flag. For example:", "'store_true' and 'store_false' - These are special cases of 'store_const' used for storing the values True and False respectively. In addition, they create default values of False and True respectively. For example:", "'append' - This stores a list, and appends each argument value to the list. This is useful to allow an option to be specified multiple times. Example usage:", "'append_const' - This stores a list, and appends the value specified by the const keyword argument to the list. (Note that the const keyword argument defaults to None.) The 'append_const' action is typically useful when multiple arguments need to store constants to the same list. For example:", "'count' - This counts the number of times a keyword argument occurs. For example, this is useful for increasing verbosity levels:", "Note, the default will be None unless explicitly set to 0.", "'version' - This expects a version= keyword argument in the add_argument() call, and prints version information and exits when invoked:", "'extend' - This stores a list, and extends each argument value to the list. Example usage:", "New in version 3.8.", "You may also specify an arbitrary action by passing an Action subclass or other object that implements the same interface. The BooleanOptionalAction is available in argparse and adds support for boolean actions such as --foo and --no-foo:", "The recommended way to create a custom action is to extend Action, overriding the __call__ method and optionally the __init__ and format_usage methods.", "An example of a custom action:", "For more details, see Action.", "ArgumentParser objects usually associate a single command-line argument with a single action to be taken. The nargs keyword argument associates a different number of command-line arguments with a single action. The supported values are:", "N (an integer). N arguments from the command line will be gathered together into a list. For example:", "Note that nargs=1 produces a list of one item. This is different from the default, in which the item is produced by itself.", "'?'. One argument will be consumed from the command line if possible, and produced as a single item. If no command-line argument is present, the value from default will be produced. Note that for optional arguments, there is an additional case - the option string is present but not followed by a command-line argument. In this case the value from const will be produced. Some examples to illustrate this:", "One of the more common uses of nargs='?' is to allow optional input and output files:", "'*'. All command-line arguments present are gathered into a list. Note that it generally doesn\u2019t make much sense to have more than one positional argument with nargs='*', but multiple optional arguments with nargs='*' is possible. For example:", "'+'. Just like '*', all command-line args present are gathered into a list. Additionally, an error message will be generated if there wasn\u2019t at least one command-line argument present. For example:", "If the nargs keyword argument is not provided, the number of arguments consumed is determined by the action. Generally this means a single command-line argument will be consumed and a single item (not a list) will be produced.", "The const argument of add_argument() is used to hold constant values that are not read from the command line but are required for the various ArgumentParser actions. The two most common uses of it are:", "With the 'store_const' and 'append_const' actions, the const keyword argument must be given. For other actions, it defaults to None.", "All optional arguments and some positional arguments may be omitted at the command line. The default keyword argument of add_argument(), whose value defaults to None, specifies what value should be used if the command-line argument is not present. For optional arguments, the default value is used when the option string was not present at the command line:", "If the target namespace already has an attribute set, the action default will not over write it:", "If the default value is a string, the parser parses the value as if it were a command-line argument. In particular, the parser applies any type conversion argument, if provided, before setting the attribute on the Namespace return value. Otherwise, the parser uses the value as is:", "For positional arguments with nargs equal to ? or *, the default value is used when no command-line argument was present:", "Providing default=argparse.SUPPRESS causes no attribute to be added if the command-line argument was not present:", "By default, the parser reads command-line arguments in as simple strings. However, quite often the command-line string should instead be interpreted as another type, such as a float or int. The type keyword for add_argument() allows any necessary type-checking and type conversions to be performed.", "If the type keyword is used with the default keyword, the type converter is only applied if the default is a string.", "The argument to type can be any callable that accepts a single string. If the function raises ArgumentTypeError, TypeError, or ValueError, the exception is caught and a nicely formatted error message is displayed. No other exception types are handled.", "Common built-in types and functions can be used as type converters:", "User defined functions can be used as well:", "The bool() function is not recommended as a type converter. All it does is convert empty strings to False and non-empty strings to True. This is usually not what is desired.", "In general, the type keyword is a convenience that should only be used for simple conversions that can only raise one of the three supported exceptions. Anything with more interesting error-handling or resource management should be done downstream after the arguments are parsed.", "For example, JSON or YAML conversions have complex error cases that require better reporting than can be given by the type keyword. An JSONDecodeError would not be well formatted and a FileNotFound exception would not be handled at all.", "Even FileType has its limitations for use with the type keyword. If one argument uses FileType and then a subsequent argument fails, an error is reported but the file is not automatically closed. In this case, it would be better to wait until after the parser has run and then use the with-statement to manage the files.", "For type checkers that simply check against a fixed set of values, consider using the choices keyword instead.", "Some command-line arguments should be selected from a restricted set of values. These can be handled by passing a container object as the choices keyword argument to add_argument(). When the command line is parsed, argument values will be checked, and an error message will be displayed if the argument was not one of the acceptable values:", "Note that inclusion in the choices container is checked after any type conversions have been performed, so the type of the objects in the choices container should match the type specified:", "Any container can be passed as the choices value, so list objects, set objects, and custom containers are all supported.", "Use of enum.Enum is not recommended because it is difficult to control its appearance in usage, help, and error messages.", "Formatted choices overrides the default metavar which is normally derived from dest. This is usually what you want because the user never sees the dest parameter. If this display isn\u2019t desirable (perhaps because there are many choices), just specify an explicit metavar.", "In general, the argparse module assumes that flags like -f and --bar indicate optional arguments, which can always be omitted at the command line. To make an option required, True can be specified for the required= keyword argument to add_argument():", "As the example shows, if an option is marked as required, parse_args() will report an error if that option is not present at the command line.", "Note", "Required options are generally considered bad form because users expect options to be optional, and thus they should be avoided when possible.", "The help value is a string containing a brief description of the argument. When a user requests help (usually by using -h or --help at the command line), these help descriptions will be displayed with each argument:", "The help strings can include various format specifiers to avoid repetition of things like the program name or the argument default. The available specifiers include the program name, %(prog)s and most keyword arguments to add_argument(), e.g. %(default)s, %(type)s, etc.:", "As the help string supports %-formatting, if you want a literal % to appear in the help string, you must escape it as %%.", "argparse supports silencing the help entry for certain options, by setting the help value to argparse.SUPPRESS:", "When ArgumentParser generates help messages, it needs some way to refer to each expected argument. By default, ArgumentParser objects use the dest value as the \u201cname\u201d of each object. By default, for positional argument actions, the dest value is used directly, and for optional argument actions, the dest value is uppercased. So, a single positional argument with dest='bar' will be referred to as bar. A single optional argument --foo that should be followed by a single command-line argument will be referred to as FOO. An example:", "An alternative name can be specified with metavar:", "Note that metavar only changes the displayed name - the name of the attribute on the parse_args() object is still determined by the dest value.", "Different values of nargs may cause the metavar to be used multiple times. Providing a tuple to metavar specifies a different display for each of the arguments:", "Most ArgumentParser actions add some value as an attribute of the object returned by parse_args(). The name of this attribute is determined by the dest keyword argument of add_argument(). For positional argument actions, dest is normally supplied as the first argument to add_argument():", "For optional argument actions, the value of dest is normally inferred from the option strings. ArgumentParser generates the value of dest by taking the first long option string and stripping away the initial -- string. If no long option strings were supplied, dest will be derived from the first short option string by stripping the initial - character. Any internal - characters will be converted to _ characters to make sure the string is a valid attribute name. The examples below illustrate this behavior:", "dest allows a custom attribute name to be provided:", "Action classes implement the Action API, a callable which returns a callable which processes arguments from the command-line. Any object which follows this API may be passed as the action parameter to add_argument().", "Action objects are used by an ArgumentParser to represent the information needed to parse a single argument from one or more strings from the command line. The Action class must accept the two positional arguments plus any keyword arguments passed to ArgumentParser.add_argument() except for the action itself.", "Instances of Action (or return value of any callable to the action parameter) should have attributes \u201cdest\u201d, \u201coption_strings\u201d, \u201cdefault\u201d, \u201ctype\u201d, \u201crequired\u201d, \u201chelp\u201d, etc. defined. The easiest way to ensure these attributes are defined is to call Action.__init__.", "Action instances should be callable, so subclasses must override the __call__ method, which should accept four parameters:", "The __call__ method may perform arbitrary actions, but will typically set attributes on the namespace based on dest and values.", "Action subclasses can define a format_usage method that takes no argument and return a string which will be used when printing the usage of the program. If such method is not provided, a sensible default will be used.", "Convert argument strings to objects and assign them as attributes of the namespace. Return the populated namespace.", "Previous calls to add_argument() determine exactly what objects are created and how they are assigned. See the documentation for add_argument() for details.", "The parse_args() method supports several ways of specifying the value of an option (if it takes one). In the simplest case, the option and its value are passed as two separate arguments:", "For long options (options with names longer than a single character), the option and value can also be passed as a single command-line argument, using = to separate them:", "For short options (options only one character long), the option and its value can be concatenated:", "Several short options can be joined together, using only a single - prefix, as long as only the last option (or none of them) requires a value:", "While parsing the command line, parse_args() checks for a variety of errors, including ambiguous options, invalid types, invalid options, wrong number of positional arguments, etc. When it encounters such an error, it exits and prints the error along with a usage message:", "The parse_args() method attempts to give errors whenever the user has clearly made a mistake, but some situations are inherently ambiguous. For example, the command-line argument -1 could either be an attempt to specify an option or an attempt to provide a positional argument. The parse_args() method is cautious here: positional arguments may only begin with - if they look like negative numbers and there are no options in the parser that look like negative numbers:", "If you have positional arguments that must begin with - and don\u2019t look like negative numbers, you can insert the pseudo-argument '--' which tells parse_args() that everything after that is a positional argument:", "The parse_args() method by default allows long options to be abbreviated to a prefix, if the abbreviation is unambiguous (the prefix matches a unique option):", "An error is produced for arguments that could produce more than one options. This feature can be disabled by setting allow_abbrev to False.", "Sometimes it may be useful to have an ArgumentParser parse arguments other than those of sys.argv. This can be accomplished by passing a list of strings to parse_args(). This is useful for testing at the interactive prompt:", "Simple class used by default by parse_args() to create an object holding attributes and return it.", "This class is deliberately simple, just an object subclass with a readable string representation. If you prefer to have dict-like view of the attributes, you can use the standard Python idiom, vars():", "It may also be useful to have an ArgumentParser assign attributes to an already existing object, rather than a new Namespace object. This can be achieved by specifying the namespace= keyword argument:", "Many programs split up their functionality into a number of sub-commands, for example, the svn program can invoke sub-commands like svn\ncheckout, svn update, and svn commit. Splitting up functionality this way can be a particularly good idea when a program performs several different functions which require different kinds of command-line arguments. ArgumentParser supports the creation of such sub-commands with the add_subparsers() method. The add_subparsers() method is normally called with no arguments and returns a special action object. This object has a single method, add_parser(), which takes a command name and any ArgumentParser constructor arguments, and returns an ArgumentParser object that can be modified as usual.", "Description of parameters:", "Some example usage:", "Note that the object returned by parse_args() will only contain attributes for the main parser and the subparser that was selected by the command line (and not any other subparsers). So in the example above, when the a command is specified, only the foo and bar attributes are present, and when the b command is specified, only the foo and baz attributes are present.", "Similarly, when a help message is requested from a subparser, only the help for that particular parser will be printed. The help message will not include parent parser or sibling parser messages. (A help message for each subparser command, however, can be given by supplying the help= argument to add_parser() as above.)", "The add_subparsers() method also supports title and description keyword arguments. When either is present, the subparser\u2019s commands will appear in their own group in the help output. For example:", "Furthermore, add_parser supports an additional aliases argument, which allows multiple strings to refer to the same subparser. This example, like svn, aliases co as a shorthand for checkout:", "One particularly effective way of handling sub-commands is to combine the use of the add_subparsers() method with calls to set_defaults() so that each subparser knows which Python function it should execute. For example:", "This way, you can let parse_args() do the job of calling the appropriate function after argument parsing is complete. Associating functions with actions like this is typically the easiest way to handle the different actions for each of your subparsers. However, if it is necessary to check the name of the subparser that was invoked, the dest keyword argument to the add_subparsers() call will work:", "Changed in version 3.7: New required keyword argument.", "The FileType factory creates objects that can be passed to the type argument of ArgumentParser.add_argument(). Arguments that have FileType objects as their type will open command-line arguments as files with the requested modes, buffer sizes, encodings and error handling (see the open() function for more details):", "FileType objects understand the pseudo-argument '-' and automatically convert this into sys.stdin for readable FileType objects and sys.stdout for writable FileType objects:", "New in version 3.4: The encodings and errors keyword arguments.", "By default, ArgumentParser groups command-line arguments into \u201cpositional arguments\u201d and \u201coptional arguments\u201d when displaying help messages. When there is a better conceptual grouping of arguments than this default one, appropriate groups can be created using the add_argument_group() method:", "The add_argument_group() method returns an argument group object which has an add_argument() method just like a regular ArgumentParser. When an argument is added to the group, the parser treats it just like a normal argument, but displays the argument in a separate group for help messages. The add_argument_group() method accepts title and description arguments which can be used to customize this display:", "Note that any arguments not in your user-defined groups will end up back in the usual \u201cpositional arguments\u201d and \u201coptional arguments\u201d sections.", "Create a mutually exclusive group. argparse will make sure that only one of the arguments in the mutually exclusive group was present on the command line:", "The add_mutually_exclusive_group() method also accepts a required argument, to indicate that at least one of the mutually exclusive arguments is required:", "Note that currently mutually exclusive argument groups do not support the title and description arguments of add_argument_group().", "Most of the time, the attributes of the object returned by parse_args() will be fully determined by inspecting the command-line arguments and the argument actions. set_defaults() allows some additional attributes that are determined without any inspection of the command line to be added:", "Note that parser-level defaults always override argument-level defaults:", "Parser-level defaults can be particularly useful when working with multiple parsers. See the add_subparsers() method for an example of this type.", "Get the default value for a namespace attribute, as set by either add_argument() or by set_defaults():", "In most typical applications, parse_args() will take care of formatting and printing any usage or error messages. However, several formatting methods are available:", "Print a brief description of how the ArgumentParser should be invoked on the command line. If file is None, sys.stdout is assumed.", "Print a help message, including the program usage and information about the arguments registered with the ArgumentParser. If file is None, sys.stdout is assumed.", "There are also variants of these methods that simply return a string instead of printing it:", "Return a string containing a brief description of how the ArgumentParser should be invoked on the command line.", "Return a string containing a help message, including the program usage and information about the arguments registered with the ArgumentParser.", "Sometimes a script may only parse a few of the command-line arguments, passing the remaining arguments on to another script or program. In these cases, the parse_known_args() method can be useful. It works much like parse_args() except that it does not produce an error when extra arguments are present. Instead, it returns a two item tuple containing the populated namespace and the list of remaining argument strings.", "Warning", "Prefix matching rules apply to parse_known_args(). The parser may consume an option even if it\u2019s just a prefix of one of its known options, instead of leaving it in the remaining arguments list.", "Arguments that are read from a file (see the fromfile_prefix_chars keyword argument to the ArgumentParser constructor) are read one argument per line. convert_arg_line_to_args() can be overridden for fancier reading.", "This method takes a single argument arg_line which is a string read from the argument file. It returns a list of arguments parsed from this string. The method is called once per line read from the argument file, in order.", "A useful override of this method is one that treats each space-separated word as an argument. The following example demonstrates how to do this:", "This method terminates the program, exiting with the specified status and, if given, it prints a message before that. The user can override this method to handle these steps differently:", "This method prints a usage message including the message to the standard error and terminates the program with a status code of 2.", "A number of Unix commands allow the user to intermix optional arguments with positional arguments. The parse_intermixed_args() and parse_known_intermixed_args() methods support this parsing style.", "These parsers do not support all the argparse features, and will raise exceptions if unsupported features are used. In particular, subparsers, argparse.REMAINDER, and mutually exclusive groups that include both optionals and positionals are not supported.", "The following example shows the difference between parse_known_args() and parse_intermixed_args(): the former returns ['2',\n'3'] as unparsed arguments, while the latter collects all the positionals into rest.", "parse_known_intermixed_args() returns a two item tuple containing the populated namespace and the list of remaining argument strings. parse_intermixed_args() raises an error if there are any remaining unparsed argument strings.", "New in version 3.7.", "Originally, the argparse module had attempted to maintain compatibility with optparse. However, optparse was difficult to extend transparently, particularly with the changes required to support the new nargs= specifiers and better usage messages. When most everything in optparse had either been copy-pasted over or monkey-patched, it no longer seemed practical to try to maintain the backwards compatibility.", "The argparse module improves on the standard library optparse module in a number of ways including:", "A partial upgrade path from optparse to argparse:"]}, {"name": "argparse.Action", "path": "library/argparse#argparse.Action", "type": "Operating System", "text": []}, {"name": "argparse.ArgumentDefaultsHelpFormatter", "path": "library/argparse#argparse.ArgumentDefaultsHelpFormatter", "type": "Operating System", "text": []}, {"name": "argparse.ArgumentParser", "path": "library/argparse#argparse.ArgumentParser", "type": "Operating System", "text": ["Create a new ArgumentParser object. All parameters should be passed as keyword arguments. Each parameter has its own more detailed description below, but in short they are:", "Changed in version 3.5: allow_abbrev parameter was added.", "Changed in version 3.8: In previous versions, allow_abbrev also disabled grouping of short flags such as -vv to mean -v -v.", "Changed in version 3.9: exit_on_error parameter was added."]}, {"name": "argparse.ArgumentParser.add_argument()", "path": "library/argparse#argparse.ArgumentParser.add_argument", "type": "Operating System", "text": ["Define how a single command-line argument should be parsed. Each parameter has its own more detailed description below, but in short they are:"]}, {"name": "argparse.ArgumentParser.add_argument_group()", "path": "library/argparse#argparse.ArgumentParser.add_argument_group", "type": "Operating System", "text": ["By default, ArgumentParser groups command-line arguments into \u201cpositional arguments\u201d and \u201coptional arguments\u201d when displaying help messages. When there is a better conceptual grouping of arguments than this default one, appropriate groups can be created using the add_argument_group() method:", "The add_argument_group() method returns an argument group object which has an add_argument() method just like a regular ArgumentParser. When an argument is added to the group, the parser treats it just like a normal argument, but displays the argument in a separate group for help messages. The add_argument_group() method accepts title and description arguments which can be used to customize this display:", "Note that any arguments not in your user-defined groups will end up back in the usual \u201cpositional arguments\u201d and \u201coptional arguments\u201d sections."]}, {"name": "argparse.ArgumentParser.add_mutually_exclusive_group()", "path": "library/argparse#argparse.ArgumentParser.add_mutually_exclusive_group", "type": "Operating System", "text": ["Create a mutually exclusive group. argparse will make sure that only one of the arguments in the mutually exclusive group was present on the command line:", "The add_mutually_exclusive_group() method also accepts a required argument, to indicate that at least one of the mutually exclusive arguments is required:", "Note that currently mutually exclusive argument groups do not support the title and description arguments of add_argument_group()."]}, {"name": "argparse.ArgumentParser.add_subparsers()", "path": "library/argparse#argparse.ArgumentParser.add_subparsers", "type": "Operating System", "text": ["Many programs split up their functionality into a number of sub-commands, for example, the svn program can invoke sub-commands like svn\ncheckout, svn update, and svn commit. Splitting up functionality this way can be a particularly good idea when a program performs several different functions which require different kinds of command-line arguments. ArgumentParser supports the creation of such sub-commands with the add_subparsers() method. The add_subparsers() method is normally called with no arguments and returns a special action object. This object has a single method, add_parser(), which takes a command name and any ArgumentParser constructor arguments, and returns an ArgumentParser object that can be modified as usual.", "Description of parameters:", "Some example usage:", "Note that the object returned by parse_args() will only contain attributes for the main parser and the subparser that was selected by the command line (and not any other subparsers). So in the example above, when the a command is specified, only the foo and bar attributes are present, and when the b command is specified, only the foo and baz attributes are present.", "Similarly, when a help message is requested from a subparser, only the help for that particular parser will be printed. The help message will not include parent parser or sibling parser messages. (A help message for each subparser command, however, can be given by supplying the help= argument to add_parser() as above.)", "The add_subparsers() method also supports title and description keyword arguments. When either is present, the subparser\u2019s commands will appear in their own group in the help output. For example:", "Furthermore, add_parser supports an additional aliases argument, which allows multiple strings to refer to the same subparser. This example, like svn, aliases co as a shorthand for checkout:", "One particularly effective way of handling sub-commands is to combine the use of the add_subparsers() method with calls to set_defaults() so that each subparser knows which Python function it should execute. For example:", "This way, you can let parse_args() do the job of calling the appropriate function after argument parsing is complete. Associating functions with actions like this is typically the easiest way to handle the different actions for each of your subparsers. However, if it is necessary to check the name of the subparser that was invoked, the dest keyword argument to the add_subparsers() call will work:", "Changed in version 3.7: New required keyword argument."]}, {"name": "argparse.ArgumentParser.convert_arg_line_to_args()", "path": "library/argparse#argparse.ArgumentParser.convert_arg_line_to_args", "type": "Operating System", "text": ["Arguments that are read from a file (see the fromfile_prefix_chars keyword argument to the ArgumentParser constructor) are read one argument per line. convert_arg_line_to_args() can be overridden for fancier reading.", "This method takes a single argument arg_line which is a string read from the argument file. It returns a list of arguments parsed from this string. The method is called once per line read from the argument file, in order.", "A useful override of this method is one that treats each space-separated word as an argument. The following example demonstrates how to do this:"]}, {"name": "argparse.ArgumentParser.error()", "path": "library/argparse#argparse.ArgumentParser.error", "type": "Operating System", "text": ["This method prints a usage message including the message to the standard error and terminates the program with a status code of 2."]}, {"name": "argparse.ArgumentParser.exit()", "path": "library/argparse#argparse.ArgumentParser.exit", "type": "Operating System", "text": ["This method terminates the program, exiting with the specified status and, if given, it prints a message before that. The user can override this method to handle these steps differently:"]}, {"name": "argparse.ArgumentParser.format_help()", "path": "library/argparse#argparse.ArgumentParser.format_help", "type": "Operating System", "text": ["Return a string containing a help message, including the program usage and information about the arguments registered with the ArgumentParser."]}, {"name": "argparse.ArgumentParser.format_usage()", "path": "library/argparse#argparse.ArgumentParser.format_usage", "type": "Operating System", "text": ["Return a string containing a brief description of how the ArgumentParser should be invoked on the command line."]}, {"name": "argparse.ArgumentParser.get_default()", "path": "library/argparse#argparse.ArgumentParser.get_default", "type": "Operating System", "text": ["Get the default value for a namespace attribute, as set by either add_argument() or by set_defaults():"]}, {"name": "argparse.ArgumentParser.parse_args()", "path": "library/argparse#argparse.ArgumentParser.parse_args", "type": "Operating System", "text": ["Convert argument strings to objects and assign them as attributes of the namespace. Return the populated namespace.", "Previous calls to add_argument() determine exactly what objects are created and how they are assigned. See the documentation for add_argument() for details."]}, {"name": "argparse.ArgumentParser.parse_intermixed_args()", "path": "library/argparse#argparse.ArgumentParser.parse_intermixed_args", "type": "Operating System", "text": []}, {"name": "argparse.ArgumentParser.parse_known_args()", "path": "library/argparse#argparse.ArgumentParser.parse_known_args", "type": "Operating System", "text": []}, {"name": "argparse.ArgumentParser.parse_known_intermixed_args()", "path": "library/argparse#argparse.ArgumentParser.parse_known_intermixed_args", "type": "Operating System", "text": []}, {"name": "argparse.ArgumentParser.print_help()", "path": "library/argparse#argparse.ArgumentParser.print_help", "type": "Operating System", "text": ["Print a help message, including the program usage and information about the arguments registered with the ArgumentParser. If file is None, sys.stdout is assumed."]}, {"name": "argparse.ArgumentParser.print_usage()", "path": "library/argparse#argparse.ArgumentParser.print_usage", "type": "Operating System", "text": ["Print a brief description of how the ArgumentParser should be invoked on the command line. If file is None, sys.stdout is assumed."]}, {"name": "argparse.ArgumentParser.set_defaults()", "path": "library/argparse#argparse.ArgumentParser.set_defaults", "type": "Operating System", "text": ["Most of the time, the attributes of the object returned by parse_args() will be fully determined by inspecting the command-line arguments and the argument actions. set_defaults() allows some additional attributes that are determined without any inspection of the command line to be added:", "Note that parser-level defaults always override argument-level defaults:", "Parser-level defaults can be particularly useful when working with multiple parsers. See the add_subparsers() method for an example of this type."]}, {"name": "argparse.FileType", "path": "library/argparse#argparse.FileType", "type": "Operating System", "text": ["The FileType factory creates objects that can be passed to the type argument of ArgumentParser.add_argument(). Arguments that have FileType objects as their type will open command-line arguments as files with the requested modes, buffer sizes, encodings and error handling (see the open() function for more details):", "FileType objects understand the pseudo-argument '-' and automatically convert this into sys.stdin for readable FileType objects and sys.stdout for writable FileType objects:", "New in version 3.4: The encodings and errors keyword arguments."]}, {"name": "argparse.MetavarTypeHelpFormatter", "path": "library/argparse#argparse.MetavarTypeHelpFormatter", "type": "Operating System", "text": []}, {"name": "argparse.Namespace", "path": "library/argparse#argparse.Namespace", "type": "Operating System", "text": ["Simple class used by default by parse_args() to create an object holding attributes and return it."]}, {"name": "argparse.RawDescriptionHelpFormatter", "path": "library/argparse#argparse.RawDescriptionHelpFormatter", "type": "Operating System", "text": []}, {"name": "argparse.RawTextHelpFormatter", "path": "library/argparse#argparse.RawTextHelpFormatter", "type": "Operating System", "text": []}, {"name": "ArithmeticError", "path": "library/exceptions#ArithmeticError", "type": "Built-in Exceptions", "text": ["The base class for those built-in exceptions that are raised for various arithmetic errors: OverflowError, ZeroDivisionError, FloatingPointError."]}, {"name": "array", "path": "library/array", "type": "Data Types", "text": ["This module defines an object type which can compactly represent an array of basic values: characters, integers, floating point numbers. Arrays are sequence types and behave very much like lists, except that the type of objects stored in them is constrained. The type is specified at object creation time by using a type code, which is a single character. The following type codes are defined:", "Type code", "C Type", "Python Type", "Minimum size in bytes", "Notes", "'b'", "signed char", "int", "1", "'B'", "unsigned char", "int", "1", "'u'", "wchar_t", "Unicode character", "2", "(1)", "'h'", "signed short", "int", "2", "'H'", "unsigned short", "int", "2", "'i'", "signed int", "int", "2", "'I'", "unsigned int", "int", "2", "'l'", "signed long", "int", "4", "'L'", "unsigned long", "int", "4", "'q'", "signed long long", "int", "8", "'Q'", "unsigned long long", "int", "8", "'f'", "float", "float", "4", "'d'", "double", "float", "8", "Notes:", "It can be 16 bits or 32 bits depending on the platform.", "Changed in version 3.9: array('u') now uses wchar_t as C type instead of deprecated Py_UNICODE. This change doesn\u2019t affect to its behavior because Py_UNICODE is alias of wchar_t since Python 3.3.", "Deprecated since version 3.3, will be removed in version 4.0.", "The actual representation of values is determined by the machine architecture (strictly speaking, by the C implementation). The actual size can be accessed through the itemsize attribute.", "The module defines the following type:", "A new array whose items are restricted by typecode, and initialized from the optional initializer value, which must be a list, a bytes-like object, or iterable over elements of the appropriate type.", "If given a list or string, the initializer is passed to the new array\u2019s fromlist(), frombytes(), or fromunicode() method (see below) to add initial items to the array. Otherwise, the iterable initializer is passed to the extend() method.", "Raises an auditing event array.__new__ with arguments typecode, initializer.", "A string with all available type codes.", "Array objects support the ordinary sequence operations of indexing, slicing, concatenation, and multiplication. When using slice assignment, the assigned value must be an array object with the same type code; in all other cases, TypeError is raised. Array objects also implement the buffer interface, and may be used wherever bytes-like objects are supported.", "The following data items and methods are also supported:", "The typecode character used to create the array.", "The length in bytes of one array item in the internal representation.", "Append a new item with value x to the end of the array.", "Return a tuple (address, length) giving the current memory address and the length in elements of the buffer used to hold array\u2019s contents. The size of the memory buffer in bytes can be computed as array.buffer_info()[1] *\narray.itemsize. This is occasionally useful when working with low-level (and inherently unsafe) I/O interfaces that require memory addresses, such as certain ioctl() operations. The returned numbers are valid as long as the array exists and no length-changing operations are applied to it.", "Note", "When using array objects from code written in C or C++ (the only way to effectively make use of this information), it makes more sense to use the buffer interface supported by array objects. This method is maintained for backward compatibility and should be avoided in new code. The buffer interface is documented in Buffer Protocol.", "\u201cByteswap\u201d all items of the array. This is only supported for values which are 1, 2, 4, or 8 bytes in size; for other types of values, RuntimeError is raised. It is useful when reading data from a file written on a machine with a different byte order.", "Return the number of occurrences of x in the array.", "Append items from iterable to the end of the array. If iterable is another array, it must have exactly the same type code; if not, TypeError will be raised. If iterable is not an array, it must be iterable and its elements must be the right type to be appended to the array.", "Appends items from the string, interpreting the string as an array of machine values (as if it had been read from a file using the fromfile() method).", "New in version 3.2: fromstring() is renamed to frombytes() for clarity.", "Read n items (as machine values) from the file object f and append them to the end of the array. If less than n items are available, EOFError is raised, but the items that were available are still inserted into the array.", "Append items from the list. This is equivalent to for x in list:\na.append(x) except that if there is a type error, the array is unchanged.", "Extends this array with data from the given unicode string. The array must be a type 'u' array; otherwise a ValueError is raised. Use array.frombytes(unicodestring.encode(enc)) to append Unicode data to an array of some other type.", "Return the smallest i such that i is the index of the first occurrence of x in the array.", "Insert a new item with value x in the array before position i. Negative values are treated as being relative to the end of the array.", "Removes the item with the index i from the array and returns it. The optional argument defaults to -1, so that by default the last item is removed and returned.", "Remove the first occurrence of x from the array.", "Reverse the order of the items in the array.", "Convert the array to an array of machine values and return the bytes representation (the same sequence of bytes that would be written to a file by the tofile() method.)", "New in version 3.2: tostring() is renamed to tobytes() for clarity.", "Write all items (as machine values) to the file object f.", "Convert the array to an ordinary list with the same items.", "Convert the array to a unicode string. The array must be a type 'u' array; otherwise a ValueError is raised. Use array.tobytes().decode(enc) to obtain a unicode string from an array of some other type.", "When an array object is printed or converted to a string, it is represented as array(typecode, initializer). The initializer is omitted if the array is empty, otherwise it is a string if the typecode is 'u', otherwise it is a list of numbers. The string is guaranteed to be able to be converted back to an array with the same type and value using eval(), so long as the array class has been imported using from array import array. Examples:", "See also", "Packing and unpacking of heterogeneous binary data.", "Packing and unpacking of External Data Representation (XDR) data as used in some remote procedure call systems.", "The Numeric Python extension (NumPy) defines another array type; see http://www.numpy.org/ for further information about Numerical Python."]}, {"name": "array.array", "path": "library/array#array.array", "type": "Data Types", "text": ["A new array whose items are restricted by typecode, and initialized from the optional initializer value, which must be a list, a bytes-like object, or iterable over elements of the appropriate type.", "If given a list or string, the initializer is passed to the new array\u2019s fromlist(), frombytes(), or fromunicode() method (see below) to add initial items to the array. Otherwise, the iterable initializer is passed to the extend() method.", "Raises an auditing event array.__new__ with arguments typecode, initializer."]}, {"name": "array.array.append()", "path": "library/array#array.array.append", "type": "Data Types", "text": ["Append a new item with value x to the end of the array."]}, {"name": "array.array.buffer_info()", "path": "library/array#array.array.buffer_info", "type": "Data Types", "text": ["Return a tuple (address, length) giving the current memory address and the length in elements of the buffer used to hold array\u2019s contents. The size of the memory buffer in bytes can be computed as array.buffer_info()[1] *\narray.itemsize. This is occasionally useful when working with low-level (and inherently unsafe) I/O interfaces that require memory addresses, such as certain ioctl() operations. The returned numbers are valid as long as the array exists and no length-changing operations are applied to it.", "Note", "When using array objects from code written in C or C++ (the only way to effectively make use of this information), it makes more sense to use the buffer interface supported by array objects. This method is maintained for backward compatibility and should be avoided in new code. The buffer interface is documented in Buffer Protocol."]}, {"name": "array.array.byteswap()", "path": "library/array#array.array.byteswap", "type": "Data Types", "text": ["\u201cByteswap\u201d all items of the array. This is only supported for values which are 1, 2, 4, or 8 bytes in size; for other types of values, RuntimeError is raised. It is useful when reading data from a file written on a machine with a different byte order."]}, {"name": "array.array.count()", "path": "library/array#array.array.count", "type": "Data Types", "text": ["Return the number of occurrences of x in the array."]}, {"name": "array.array.extend()", "path": "library/array#array.array.extend", "type": "Data Types", "text": ["Append items from iterable to the end of the array. If iterable is another array, it must have exactly the same type code; if not, TypeError will be raised. If iterable is not an array, it must be iterable and its elements must be the right type to be appended to the array."]}, {"name": "array.array.frombytes()", "path": "library/array#array.array.frombytes", "type": "Data Types", "text": ["Appends items from the string, interpreting the string as an array of machine values (as if it had been read from a file using the fromfile() method).", "New in version 3.2: fromstring() is renamed to frombytes() for clarity."]}, {"name": "array.array.fromfile()", "path": "library/array#array.array.fromfile", "type": "Data Types", "text": ["Read n items (as machine values) from the file object f and append them to the end of the array. If less than n items are available, EOFError is raised, but the items that were available are still inserted into the array."]}, {"name": "array.array.fromlist()", "path": "library/array#array.array.fromlist", "type": "Data Types", "text": ["Append items from the list. This is equivalent to for x in list:\na.append(x) except that if there is a type error, the array is unchanged."]}, {"name": "array.array.fromunicode()", "path": "library/array#array.array.fromunicode", "type": "Data Types", "text": ["Extends this array with data from the given unicode string. The array must be a type 'u' array; otherwise a ValueError is raised. Use array.frombytes(unicodestring.encode(enc)) to append Unicode data to an array of some other type."]}, {"name": "array.array.index()", "path": "library/array#array.array.index", "type": "Data Types", "text": ["Return the smallest i such that i is the index of the first occurrence of x in the array."]}, {"name": "array.array.insert()", "path": "library/array#array.array.insert", "type": "Data Types", "text": ["Insert a new item with value x in the array before position i. Negative values are treated as being relative to the end of the array."]}, {"name": "array.array.itemsize", "path": "library/array#array.array.itemsize", "type": "Data Types", "text": ["The length in bytes of one array item in the internal representation."]}, {"name": "array.array.pop()", "path": "library/array#array.array.pop", "type": "Data Types", "text": ["Removes the item with the index i from the array and returns it. The optional argument defaults to -1, so that by default the last item is removed and returned."]}, {"name": "array.array.remove()", "path": "library/array#array.array.remove", "type": "Data Types", "text": ["Remove the first occurrence of x from the array."]}, {"name": "array.array.reverse()", "path": "library/array#array.array.reverse", "type": "Data Types", "text": ["Reverse the order of the items in the array."]}, {"name": "array.array.tobytes()", "path": "library/array#array.array.tobytes", "type": "Data Types", "text": ["Convert the array to an array of machine values and return the bytes representation (the same sequence of bytes that would be written to a file by the tofile() method.)", "New in version 3.2: tostring() is renamed to tobytes() for clarity."]}, {"name": "array.array.tofile()", "path": "library/array#array.array.tofile", "type": "Data Types", "text": ["Write all items (as machine values) to the file object f."]}, {"name": "array.array.tolist()", "path": "library/array#array.array.tolist", "type": "Data Types", "text": ["Convert the array to an ordinary list with the same items."]}, {"name": "array.array.tounicode()", "path": "library/array#array.array.tounicode", "type": "Data Types", "text": ["Convert the array to a unicode string. The array must be a type 'u' array; otherwise a ValueError is raised. Use array.tobytes().decode(enc) to obtain a unicode string from an array of some other type."]}, {"name": "array.array.typecode", "path": "library/array#array.array.typecode", "type": "Data Types", "text": ["The typecode character used to create the array."]}, {"name": "array.typecodes", "path": "library/array#array.typecodes", "type": "Data Types", "text": ["A string with all available type codes."]}, {"name": "ascii()", "path": "library/functions#ascii", "type": "Built-in Functions", "text": ["As repr(), return a string containing a printable representation of an object, but escape the non-ASCII characters in the string returned by repr() using \\x, \\u or \\U escapes. This generates a string similar to that returned by repr() in Python 2."]}, {"name": "AssertionError", "path": "library/exceptions#AssertionError", "type": "Built-in Exceptions", "text": ["Raised when an assert statement fails."]}, {"name": "ast", "path": "library/ast", "type": "Language", "text": ["Source code: Lib/ast.py", "The ast module helps Python applications to process trees of the Python abstract syntax grammar. The abstract syntax itself might change with each Python release; this module helps to find out programmatically what the current grammar looks like.", "An abstract syntax tree can be generated by passing ast.PyCF_ONLY_AST as a flag to the compile() built-in function, or using the parse() helper provided in this module. The result will be a tree of objects whose classes all inherit from ast.AST. An abstract syntax tree can be compiled into a Python code object using the built-in compile() function.", "The abstract grammar is currently defined as follows:", "This is the base of all AST node classes. The actual node classes are derived from the Parser/Python.asdl file, which is reproduced below. They are defined in the _ast C module and re-exported in ast.", "There is one class defined for each left-hand side symbol in the abstract grammar (for example, ast.stmt or ast.expr). In addition, there is one class defined for each constructor on the right-hand side; these classes inherit from the classes for the left-hand side trees. For example, ast.BinOp inherits from ast.expr. For production rules with alternatives (aka \u201csums\u201d), the left-hand side class is abstract: only instances of specific constructor nodes are ever created.", "Each concrete class has an attribute _fields which gives the names of all child nodes.", "Each instance of a concrete class has one attribute for each child node, of the type as defined in the grammar. For example, ast.BinOp instances have an attribute left of type ast.expr.", "If these attributes are marked as optional in the grammar (using a question mark), the value might be None. If the attributes can have zero-or-more values (marked with an asterisk), the values are represented as Python lists. All possible attributes must be present and have valid values when compiling an AST with compile().", "Instances of ast.expr and ast.stmt subclasses have lineno, col_offset, lineno, and col_offset attributes. The lineno and end_lineno are the first and last line numbers of source text span (1-indexed so the first line is line 1) and the col_offset and end_col_offset are the corresponding UTF-8 byte offsets of the first and last tokens that generated the node. The UTF-8 offset is recorded because the parser uses UTF-8 internally.", "Note that the end positions are not required by the compiler and are therefore optional. The end offset is after the last symbol, for example one can get the source segment of a one-line expression node using source_line[node.col_offset : node.end_col_offset].", "The constructor of a class ast.T parses its arguments as follows:", "For example, to create and populate an ast.UnaryOp node, you could use", "or the more compact", "Changed in version 3.8: Class ast.Constant is now used for all constants.", "Changed in version 3.9: Simple indices are represented by their value, extended slices are represented as tuples.", "Deprecated since version 3.8: Old classes ast.Num, ast.Str, ast.Bytes, ast.NameConstant and ast.Ellipsis are still available, but they will be removed in future Python releases. In the meantime, instantiating them will return an instance of a different class.", "Deprecated since version 3.9: Old classes ast.Index and ast.ExtSlice are still available, but they will be removed in future Python releases. In the meantime, instantiating them will return an instance of a different class.", "Note", "The descriptions of the specific node classes displayed here were initially adapted from the fantastic Green Tree Snakes project and all its contributors.", "A constant value. The value attribute of the Constant literal contains the Python object it represents. The values represented can be simple types such as a number, string or None, but also immutable container types (tuples and frozensets) if all of their elements are constant.", "Node representing a single formatting field in an f-string. If the string contains a single formatting field and nothing else the node can be isolated otherwise it appears in JoinedStr.", "conversion is an integer:", "An f-string, comprising a series of FormattedValue and Constant nodes.", "A list or tuple. elts holds a list of nodes representing the elements. ctx is Store if the container is an assignment target (i.e. (x,y)=something), and Load otherwise.", "A set. elts holds a list of nodes representing the set\u2019s elements.", "A dictionary. keys and values hold lists of nodes representing the keys and the values respectively, in matching order (what would be returned when calling dictionary.keys() and dictionary.values()).", "When doing dictionary unpacking using dictionary literals the expression to be expanded goes in the values list, with a None at the corresponding position in keys.", "A variable name. id holds the name as a string, and ctx is one of the following types.", "Variable references can be used to load the value of a variable, to assign a new value to it, or to delete it. Variable references are given a context to distinguish these cases.", "A *var variable reference. value holds the variable, typically a Name node. This type must be used when building a Call node with *args.", "When an expression, such as a function call, appears as a statement by itself with its return value not used or stored, it is wrapped in this container. value holds one of the other nodes in this section, a Constant, a Name, a Lambda, a Yield or YieldFrom node.", "A unary operation. op is the operator, and operand any expression node.", "Unary operator tokens. Not is the not keyword, Invert is the ~ operator.", "A binary operation (like addition or division). op is the operator, and left and right are any expression nodes.", "Binary operator tokens.", "A boolean operation, \u2018or\u2019 or \u2018and\u2019. op is Or or And. values are the values involved. Consecutive operations with the same operator, such as a or b or c, are collapsed into one node with several values.", "This doesn\u2019t include not, which is a UnaryOp.", "Boolean operator tokens.", "A comparison of two or more values. left is the first value in the comparison, ops the list of operators, and comparators the list of values after the first element in the comparison.", "Comparison operator tokens.", "A function call. func is the function, which will often be a Name or Attribute object. Of the arguments:", "When creating a Call node, args and keywords are required, but they can be empty lists. starargs and kwargs are optional.", "A keyword argument to a function call or class definition. arg is a raw string of the parameter name, value is a node to pass in.", "An expression such as a if b else c. Each field holds a single node, so in the following example, all three are Name nodes.", "Attribute access, e.g. d.keys. value is a node, typically a Name. attr is a bare string giving the name of the attribute, and ctx is Load, Store or Del according to how the attribute is acted on.", "A named expression. This AST node is produced by the assignment expressions operator (also known as the walrus operator). As opposed to the Assign node in which the first argument can be multiple nodes, in this case both target and value must be single nodes.", "A subscript, such as l[1]. value is the subscripted object (usually sequence or mapping). slice is an index, slice or key. It can be a Tuple and contain a Slice. ctx is Load, Store or Del according to the action performed with the subscript.", "Regular slicing (on the form lower:upper or lower:upper:step). Can occur only inside the slice field of Subscript, either directly or as an element of Tuple.", "List and set comprehensions, generator expressions, and dictionary comprehensions. elt (or key and value) is a single node representing the part that will be evaluated for each item.", "generators is a list of comprehension nodes.", "One for clause in a comprehension. target is the reference to use for each element - typically a Name or Tuple node. iter is the object to iterate over. ifs is a list of test expressions: each for clause can have multiple ifs.", "is_async indicates a comprehension is asynchronous (using an async for instead of for). The value is an integer (0 or 1).", "An assignment. targets is a list of nodes, and value is a single node.", "Multiple nodes in targets represents assigning the same value to each. Unpacking is represented by putting a Tuple or List within targets.", "type_comment is an optional string with the type annotation as a comment.", "An assignment with a type annotation. target is a single node and can be a Name, a Attribute or a Subscript. annotation is the annotation, such as a Constant or Name node. value is a single optional node. simple is a boolean integer set to True for a Name node in target that do not appear in between parenthesis and are hence pure names and not expressions.", "Augmented assignment, such as a += 1. In the following example, target is a Name node for x (with the Store context), op is Add, and value is a Constant with value for 1.", "The target attribute connot be of class Tuple or List, unlike the targets of Assign.", "A raise statement. exc is the exception object to be raised, normally a Call or Name, or None for a standalone raise. cause is the optional part for y in raise x from y.", "An assertion. test holds the condition, such as a Compare node. msg holds the failure message.", "Represents a del statement. targets is a list of nodes, such as Name, Attribute or Subscript nodes.", "A pass statement.", "Other statements which are only applicable inside functions or loops are described in other sections.", "An import statement. names is a list of alias nodes.", "Represents from x import y. module is a raw string of the \u2018from\u2019 name, without any leading dots, or None for statements such as from . import foo. level is an integer holding the level of the relative import (0 means absolute import).", "Both parameters are raw strings of the names. asname can be None if the regular name is to be used.", "Note", "Optional clauses such as else are stored as an empty list if they\u2019re not present.", "An if statement. test holds a single node, such as a Compare node. body and orelse each hold a list of nodes.", "elif clauses don\u2019t have a special representation in the AST, but rather appear as extra If nodes within the orelse section of the previous one.", "A for loop. target holds the variable(s) the loop assigns to, as a single Name, Tuple or List node. iter holds the item to be looped over, again as a single node. body and orelse contain lists of nodes to execute. Those in orelse are executed if the loop finishes normally, rather than via a break statement.", "type_comment is an optional string with the type annotation as a comment.", "A while loop. test holds the condition, such as a Compare node.", "The break and continue statements.", "try blocks. All attributes are list of nodes to execute, except for handlers, which is a list of ExceptHandler nodes.", "A single except clause. type is the exception type it will match, typically a Name node (or None for a catch-all except: clause). name is a raw string for the name to hold the exception, or None if the clause doesn\u2019t have as foo. body is a list of nodes.", "A with block. items is a list of withitem nodes representing the context managers, and body is the indented block inside the context.", "type_comment is an optional string with the type annotation as a comment.", "A single context manager in a with block. context_expr is the context manager, often a Call node. optional_vars is a Name, Tuple or List for the as foo part, or None if that isn\u2019t used.", "A function definition.", "type_comment is an optional string with the type annotation as a comment.", "lambda is a minimal function definition that can be used inside an expression. Unlike FunctionDef, body holds a single node.", "The arguments for a function.", "A single argument in a list. arg is a raw string of the argument name, annotation is its annotation, such as a Str or Name node.", "type_comment is an optional string with the type annotation as a comment", "A return statement.", "A yield or yield from expression. Because these are expressions, they must be wrapped in a Expr node if the value sent back is not used.", "global and nonlocal statements. names is a list of raw strings.", "A class definition.", "An async def function definition. Has the same fields as FunctionDef.", "An await expression. value is what it waits for. Only valid in the body of an AsyncFunctionDef.", "async for loops and async with context managers. They have the same fields as For and With, respectively. Only valid in the body of an AsyncFunctionDef.", "Note", "When a string is parsed by ast.parse(), operator nodes (subclasses of ast.operator, ast.unaryop, ast.cmpop, ast.boolop and ast.expr_context) on the returned tree will be singletons. Changes to one will be reflected in all other occurrences of the same value (e.g. ast.Add).", "Apart from the node classes, the ast module defines these utility functions and classes for traversing abstract syntax trees:", "Parse the source into an AST node. Equivalent to compile(source,\nfilename, mode, ast.PyCF_ONLY_AST).", "If type_comments=True is given, the parser is modified to check and return type comments as specified by PEP 484 and PEP 526. This is equivalent to adding ast.PyCF_TYPE_COMMENTS to the flags passed to compile(). This will report syntax errors for misplaced type comments. Without this flag, type comments will be ignored, and the type_comment field on selected AST nodes will always be None. In addition, the locations of # type:\nignore comments will be returned as the type_ignores attribute of Module (otherwise it is always an empty list).", "In addition, if mode is 'func_type', the input syntax is modified to correspond to PEP 484 \u201csignature type comments\u201d, e.g. (str, int) -> List[str].", "Also, setting feature_version to a tuple (major, minor) will attempt to parse using that Python version\u2019s grammar. Currently major must equal to 3. For example, setting feature_version=(3, 4) will allow the use of async and await as variable names. The lowest supported version is (3, 4); the highest is sys.version_info[0:2].", "Warning", "It is possible to crash the Python interpreter with a sufficiently large/complex string due to stack depth limitations in Python\u2019s AST compiler.", "Changed in version 3.8: Added type_comments, mode='func_type' and feature_version.", "Unparse an ast.AST object and generate a string with code that would produce an equivalent ast.AST object if parsed back with ast.parse().", "Warning", "The produced code string will not necessarily be equal to the original code that generated the ast.AST object (without any compiler optimizations, such as constant tuples/frozensets).", "Warning", "Trying to unparse a highly complex expression would result with RecursionError.", "New in version 3.9.", "Safely evaluate an expression node or a string containing a Python literal or container display. The string or node provided may only consist of the following Python literal structures: strings, bytes, numbers, tuples, lists, dicts, sets, booleans, and None.", "This can be used for safely evaluating strings containing Python values from untrusted sources without the need to parse the values oneself. It is not capable of evaluating arbitrarily complex expressions, for example involving operators or indexing.", "Warning", "It is possible to crash the Python interpreter with a sufficiently large/complex string due to stack depth limitations in Python\u2019s AST compiler.", "Changed in version 3.2: Now allows bytes and set literals.", "Changed in version 3.9: Now supports creating empty sets with 'set()'.", "Return the docstring of the given node (which must be a FunctionDef, AsyncFunctionDef, ClassDef, or Module node), or None if it has no docstring. If clean is true, clean up the docstring\u2019s indentation with inspect.cleandoc().", "Changed in version 3.5: AsyncFunctionDef is now supported.", "Get source code segment of the source that generated node. If some location information (lineno, end_lineno, col_offset, or end_col_offset) is missing, return None.", "If padded is True, the first line of a multi-line statement will be padded with spaces to match its original position.", "New in version 3.8.", "When you compile a node tree with compile(), the compiler expects lineno and col_offset attributes for every node that supports them. This is rather tedious to fill in for generated nodes, so this helper adds these attributes recursively where not already set, by setting them to the values of the parent node. It works recursively starting at node.", "Increment the line number and end line number of each node in the tree starting at node by n. This is useful to \u201cmove code\u201d to a different location in a file.", "Copy source location (lineno, col_offset, end_lineno, and end_col_offset) from old_node to new_node if possible, and return new_node.", "Yield a tuple of (fieldname, value) for each field in node._fields that is present on node.", "Yield all direct child nodes of node, that is, all fields that are nodes and all items of fields that are lists of nodes.", "Recursively yield all descendant nodes in the tree starting at node (including node itself), in no specified order. This is useful if you only want to modify nodes in place and don\u2019t care about the context.", "A node visitor base class that walks the abstract syntax tree and calls a visitor function for every node found. This function may return a value which is forwarded by the visit() method.", "This class is meant to be subclassed, with the subclass adding visitor methods.", "Visit a node. The default implementation calls the method called self.visit_classname where classname is the name of the node class, or generic_visit() if that method doesn\u2019t exist.", "This visitor calls visit() on all children of the node.", "Note that child nodes of nodes that have a custom visitor method won\u2019t be visited unless the visitor calls generic_visit() or visits them itself.", "Don\u2019t use the NodeVisitor if you want to apply changes to nodes during traversal. For this a special visitor exists (NodeTransformer) that allows modifications.", "Deprecated since version 3.8: Methods visit_Num(), visit_Str(), visit_Bytes(), visit_NameConstant() and visit_Ellipsis() are deprecated now and will not be called in future Python versions. Add the visit_Constant() method to handle all constant nodes.", "A NodeVisitor subclass that walks the abstract syntax tree and allows modification of nodes.", "The NodeTransformer will walk the AST and use the return value of the visitor methods to replace or remove the old node. If the return value of the visitor method is None, the node will be removed from its location, otherwise it is replaced with the return value. The return value may be the original node in which case no replacement takes place.", "Here is an example transformer that rewrites all occurrences of name lookups (foo) to data['foo']:", "Keep in mind that if the node you\u2019re operating on has child nodes you must either transform the child nodes yourself or call the generic_visit() method for the node first.", "For nodes that were part of a collection of statements (that applies to all statement nodes), the visitor may also return a list of nodes rather than just a single node.", "If NodeTransformer introduces new nodes (that weren\u2019t part of original tree) without giving them location information (such as lineno), fix_missing_locations() should be called with the new sub-tree to recalculate the location information:", "Usually you use the transformer like this:", "Return a formatted dump of the tree in node. This is mainly useful for debugging purposes. If annotate_fields is true (by default), the returned string will show the names and the values for fields. If annotate_fields is false, the result string will be more compact by omitting unambiguous field names. Attributes such as line numbers and column offsets are not dumped by default. If this is wanted, include_attributes can be set to true.", "If indent is a non-negative integer or string, then the tree will be pretty-printed with that indent level. An indent level of 0, negative, or \"\" will only insert newlines. None (the default) selects the single line representation. Using a positive integer indent indents that many spaces per level. If indent is a string (such as \"\\t\"), that string is used to indent each level.", "Changed in version 3.9: Added the indent option.", "The following flags may be passed to compile() in order to change effects on the compilation of a program:", "Enables support for top-level await, async for, async with and async comprehensions.", "New in version 3.8.", "Generates and returns an abstract syntax tree instead of returning a compiled code object.", "Enables support for PEP 484 and PEP 526 style type comments (# type: <type>, # type: ignore <stuff>).", "New in version 3.8.", "New in version 3.9.", "The ast module can be executed as a script from the command line. It is as simple as:", "The following options are accepted:", "Show the help message and exit.", "Specify what kind of code must be compiled, like the mode argument in parse().", "Don\u2019t parse type comments.", "Include attributes such as line numbers and column offsets.", "Indentation of nodes in AST (number of spaces).", "If infile is specified its contents are parsed to AST and dumped to stdout. Otherwise, the content is read from stdin.", "See also", "Green Tree Snakes, an external documentation resource, has good details on working with Python ASTs.", "ASTTokens annotates Python ASTs with the positions of tokens and text in the source code that generated them. This is helpful for tools that make source code transformations.", "leoAst.py unifies the token-based and parse-tree-based views of python programs by inserting two-way links between tokens and ast nodes.", "LibCST parses code as a Concrete Syntax Tree that looks like an ast tree and keeps all formatting details. It\u2019s useful for building automated refactoring (codemod) applications and linters.", "Parso is a Python parser that supports error recovery and round-trip parsing for different Python versions (in multiple Python versions). Parso is also able to list multiple syntax errors in your python file."]}, {"name": "ast.Add", "path": "library/ast#ast.Add", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.alias", "path": "library/ast#ast.alias", "type": "Language", "text": ["Both parameters are raw strings of the names. asname can be None if the regular name is to be used."]}, {"name": "ast.And", "path": "library/ast#ast.And", "type": "Language", "text": ["Boolean operator tokens."]}, {"name": "ast.AnnAssign", "path": "library/ast#ast.AnnAssign", "type": "Language", "text": ["An assignment with a type annotation. target is a single node and can be a Name, a Attribute or a Subscript. annotation is the annotation, such as a Constant or Name node. value is a single optional node. simple is a boolean integer set to True for a Name node in target that do not appear in between parenthesis and are hence pure names and not expressions."]}, {"name": "ast.arg", "path": "library/ast#ast.arg", "type": "Language", "text": ["A single argument in a list. arg is a raw string of the argument name, annotation is its annotation, such as a Str or Name node.", "type_comment is an optional string with the type annotation as a comment"]}, {"name": "ast.arg.type_comment", "path": "library/ast#ast.arg.type_comment", "type": "Language", "text": ["type_comment is an optional string with the type annotation as a comment"]}, {"name": "ast.arguments", "path": "library/ast#ast.arguments", "type": "Language", "text": ["The arguments for a function."]}, {"name": "ast.Assert", "path": "library/ast#ast.Assert", "type": "Language", "text": ["An assertion. test holds the condition, such as a Compare node. msg holds the failure message."]}, {"name": "ast.Assign", "path": "library/ast#ast.Assign", "type": "Language", "text": ["An assignment. targets is a list of nodes, and value is a single node.", "Multiple nodes in targets represents assigning the same value to each. Unpacking is represented by putting a Tuple or List within targets.", "type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.Assign.type_comment", "path": "library/ast#ast.Assign.type_comment", "type": "Language", "text": ["type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.AST", "path": "library/ast#ast.AST", "type": "Language", "text": ["This is the base of all AST node classes. The actual node classes are derived from the Parser/Python.asdl file, which is reproduced below. They are defined in the _ast C module and re-exported in ast.", "There is one class defined for each left-hand side symbol in the abstract grammar (for example, ast.stmt or ast.expr). In addition, there is one class defined for each constructor on the right-hand side; these classes inherit from the classes for the left-hand side trees. For example, ast.BinOp inherits from ast.expr. For production rules with alternatives (aka \u201csums\u201d), the left-hand side class is abstract: only instances of specific constructor nodes are ever created.", "Each concrete class has an attribute _fields which gives the names of all child nodes.", "Each instance of a concrete class has one attribute for each child node, of the type as defined in the grammar. For example, ast.BinOp instances have an attribute left of type ast.expr.", "If these attributes are marked as optional in the grammar (using a question mark), the value might be None. If the attributes can have zero-or-more values (marked with an asterisk), the values are represented as Python lists. All possible attributes must be present and have valid values when compiling an AST with compile().", "Instances of ast.expr and ast.stmt subclasses have lineno, col_offset, lineno, and col_offset attributes. The lineno and end_lineno are the first and last line numbers of source text span (1-indexed so the first line is line 1) and the col_offset and end_col_offset are the corresponding UTF-8 byte offsets of the first and last tokens that generated the node. The UTF-8 offset is recorded because the parser uses UTF-8 internally.", "Note that the end positions are not required by the compiler and are therefore optional. The end offset is after the last symbol, for example one can get the source segment of a one-line expression node using source_line[node.col_offset : node.end_col_offset].", "The constructor of a class ast.T parses its arguments as follows:", "For example, to create and populate an ast.UnaryOp node, you could use", "or the more compact"]}, {"name": "ast.AST.col_offset", "path": "library/ast#ast.AST.col_offset", "type": "Language", "text": ["Instances of ast.expr and ast.stmt subclasses have lineno, col_offset, lineno, and col_offset attributes. The lineno and end_lineno are the first and last line numbers of source text span (1-indexed so the first line is line 1) and the col_offset and end_col_offset are the corresponding UTF-8 byte offsets of the first and last tokens that generated the node. The UTF-8 offset is recorded because the parser uses UTF-8 internally.", "Note that the end positions are not required by the compiler and are therefore optional. The end offset is after the last symbol, for example one can get the source segment of a one-line expression node using source_line[node.col_offset : node.end_col_offset]."]}, {"name": "ast.AST.end_col_offset", "path": "library/ast#ast.AST.end_col_offset", "type": "Language", "text": ["Instances of ast.expr and ast.stmt subclasses have lineno, col_offset, lineno, and col_offset attributes. The lineno and end_lineno are the first and last line numbers of source text span (1-indexed so the first line is line 1) and the col_offset and end_col_offset are the corresponding UTF-8 byte offsets of the first and last tokens that generated the node. The UTF-8 offset is recorded because the parser uses UTF-8 internally.", "Note that the end positions are not required by the compiler and are therefore optional. The end offset is after the last symbol, for example one can get the source segment of a one-line expression node using source_line[node.col_offset : node.end_col_offset]."]}, {"name": "ast.AST.end_lineno", "path": "library/ast#ast.AST.end_lineno", "type": "Language", "text": ["Instances of ast.expr and ast.stmt subclasses have lineno, col_offset, lineno, and col_offset attributes. The lineno and end_lineno are the first and last line numbers of source text span (1-indexed so the first line is line 1) and the col_offset and end_col_offset are the corresponding UTF-8 byte offsets of the first and last tokens that generated the node. The UTF-8 offset is recorded because the parser uses UTF-8 internally.", "Note that the end positions are not required by the compiler and are therefore optional. The end offset is after the last symbol, for example one can get the source segment of a one-line expression node using source_line[node.col_offset : node.end_col_offset]."]}, {"name": "ast.AST.lineno", "path": "library/ast#ast.AST.lineno", "type": "Language", "text": ["Instances of ast.expr and ast.stmt subclasses have lineno, col_offset, lineno, and col_offset attributes. The lineno and end_lineno are the first and last line numbers of source text span (1-indexed so the first line is line 1) and the col_offset and end_col_offset are the corresponding UTF-8 byte offsets of the first and last tokens that generated the node. The UTF-8 offset is recorded because the parser uses UTF-8 internally.", "Note that the end positions are not required by the compiler and are therefore optional. The end offset is after the last symbol, for example one can get the source segment of a one-line expression node using source_line[node.col_offset : node.end_col_offset]."]}, {"name": "ast.AST._fields", "path": "library/ast#ast.AST._fields", "type": "Language", "text": ["Each concrete class has an attribute _fields which gives the names of all child nodes.", "Each instance of a concrete class has one attribute for each child node, of the type as defined in the grammar. For example, ast.BinOp instances have an attribute left of type ast.expr.", "If these attributes are marked as optional in the grammar (using a question mark), the value might be None. If the attributes can have zero-or-more values (marked with an asterisk), the values are represented as Python lists. All possible attributes must be present and have valid values when compiling an AST with compile()."]}, {"name": "ast.AsyncFor", "path": "library/ast#ast.AsyncFor", "type": "Language", "text": ["async for loops and async with context managers. They have the same fields as For and With, respectively. Only valid in the body of an AsyncFunctionDef."]}, {"name": "ast.AsyncFunctionDef", "path": "library/ast#ast.AsyncFunctionDef", "type": "Language", "text": ["An async def function definition. Has the same fields as FunctionDef."]}, {"name": "ast.AsyncWith", "path": "library/ast#ast.AsyncWith", "type": "Language", "text": ["async for loops and async with context managers. They have the same fields as For and With, respectively. Only valid in the body of an AsyncFunctionDef."]}, {"name": "ast.Attribute", "path": "library/ast#ast.Attribute", "type": "Language", "text": ["Attribute access, e.g. d.keys. value is a node, typically a Name. attr is a bare string giving the name of the attribute, and ctx is Load, Store or Del according to how the attribute is acted on."]}, {"name": "ast.AugAssign", "path": "library/ast#ast.AugAssign", "type": "Language", "text": ["Augmented assignment, such as a += 1. In the following example, target is a Name node for x (with the Store context), op is Add, and value is a Constant with value for 1.", "The target attribute connot be of class Tuple or List, unlike the targets of Assign."]}, {"name": "ast.Await", "path": "library/ast#ast.Await", "type": "Language", "text": ["An await expression. value is what it waits for. Only valid in the body of an AsyncFunctionDef."]}, {"name": "ast.BinOp", "path": "library/ast#ast.BinOp", "type": "Language", "text": ["A binary operation (like addition or division). op is the operator, and left and right are any expression nodes."]}, {"name": "ast.BitAnd", "path": "library/ast#ast.BitAnd", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.BitOr", "path": "library/ast#ast.BitOr", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.BitXor", "path": "library/ast#ast.BitXor", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.BoolOp", "path": "library/ast#ast.BoolOp", "type": "Language", "text": ["A boolean operation, \u2018or\u2019 or \u2018and\u2019. op is Or or And. values are the values involved. Consecutive operations with the same operator, such as a or b or c, are collapsed into one node with several values.", "This doesn\u2019t include not, which is a UnaryOp."]}, {"name": "ast.Break", "path": "library/ast#ast.Break", "type": "Language", "text": ["The break and continue statements."]}, {"name": "ast.Call", "path": "library/ast#ast.Call", "type": "Language", "text": ["A function call. func is the function, which will often be a Name or Attribute object. Of the arguments:", "When creating a Call node, args and keywords are required, but they can be empty lists. starargs and kwargs are optional."]}, {"name": "ast.ClassDef", "path": "library/ast#ast.ClassDef", "type": "Language", "text": ["A class definition."]}, {"name": "ast.Compare", "path": "library/ast#ast.Compare", "type": "Language", "text": ["A comparison of two or more values. left is the first value in the comparison, ops the list of operators, and comparators the list of values after the first element in the comparison."]}, {"name": "ast.comprehension", "path": "library/ast#ast.comprehension", "type": "Language", "text": ["One for clause in a comprehension. target is the reference to use for each element - typically a Name or Tuple node. iter is the object to iterate over. ifs is a list of test expressions: each for clause can have multiple ifs.", "is_async indicates a comprehension is asynchronous (using an async for instead of for). The value is an integer (0 or 1)."]}, {"name": "ast.Constant", "path": "library/ast#ast.Constant", "type": "Language", "text": ["A constant value. The value attribute of the Constant literal contains the Python object it represents. The values represented can be simple types such as a number, string or None, but also immutable container types (tuples and frozensets) if all of their elements are constant."]}, {"name": "ast.Continue", "path": "library/ast#ast.Continue", "type": "Language", "text": ["The break and continue statements."]}, {"name": "ast.copy_location()", "path": "library/ast#ast.copy_location", "type": "Language", "text": ["Copy source location (lineno, col_offset, end_lineno, and end_col_offset) from old_node to new_node if possible, and return new_node."]}, {"name": "ast.Del", "path": "library/ast#ast.Del", "type": "Language", "text": ["Variable references can be used to load the value of a variable, to assign a new value to it, or to delete it. Variable references are given a context to distinguish these cases."]}, {"name": "ast.Delete", "path": "library/ast#ast.Delete", "type": "Language", "text": ["Represents a del statement. targets is a list of nodes, such as Name, Attribute or Subscript nodes."]}, {"name": "ast.Dict", "path": "library/ast#ast.Dict", "type": "Language", "text": ["A dictionary. keys and values hold lists of nodes representing the keys and the values respectively, in matching order (what would be returned when calling dictionary.keys() and dictionary.values()).", "When doing dictionary unpacking using dictionary literals the expression to be expanded goes in the values list, with a None at the corresponding position in keys."]}, {"name": "ast.DictComp", "path": "library/ast#ast.DictComp", "type": "Language", "text": ["List and set comprehensions, generator expressions, and dictionary comprehensions. elt (or key and value) is a single node representing the part that will be evaluated for each item.", "generators is a list of comprehension nodes."]}, {"name": "ast.Div", "path": "library/ast#ast.Div", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.dump()", "path": "library/ast#ast.dump", "type": "Language", "text": ["Return a formatted dump of the tree in node. This is mainly useful for debugging purposes. If annotate_fields is true (by default), the returned string will show the names and the values for fields. If annotate_fields is false, the result string will be more compact by omitting unambiguous field names. Attributes such as line numbers and column offsets are not dumped by default. If this is wanted, include_attributes can be set to true.", "If indent is a non-negative integer or string, then the tree will be pretty-printed with that indent level. An indent level of 0, negative, or \"\" will only insert newlines. None (the default) selects the single line representation. Using a positive integer indent indents that many spaces per level. If indent is a string (such as \"\\t\"), that string is used to indent each level.", "Changed in version 3.9: Added the indent option."]}, {"name": "ast.Eq", "path": "library/ast#ast.Eq", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.ExceptHandler", "path": "library/ast#ast.ExceptHandler", "type": "Language", "text": ["A single except clause. type is the exception type it will match, typically a Name node (or None for a catch-all except: clause). name is a raw string for the name to hold the exception, or None if the clause doesn\u2019t have as foo. body is a list of nodes."]}, {"name": "ast.Expr", "path": "library/ast#ast.Expr", "type": "Language", "text": ["When an expression, such as a function call, appears as a statement by itself with its return value not used or stored, it is wrapped in this container. value holds one of the other nodes in this section, a Constant, a Name, a Lambda, a Yield or YieldFrom node."]}, {"name": "ast.fix_missing_locations()", "path": "library/ast#ast.fix_missing_locations", "type": "Language", "text": ["When you compile a node tree with compile(), the compiler expects lineno and col_offset attributes for every node that supports them. This is rather tedious to fill in for generated nodes, so this helper adds these attributes recursively where not already set, by setting them to the values of the parent node. It works recursively starting at node."]}, {"name": "ast.FloorDiv", "path": "library/ast#ast.FloorDiv", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.For", "path": "library/ast#ast.For", "type": "Language", "text": ["A for loop. target holds the variable(s) the loop assigns to, as a single Name, Tuple or List node. iter holds the item to be looped over, again as a single node. body and orelse contain lists of nodes to execute. Those in orelse are executed if the loop finishes normally, rather than via a break statement.", "type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.For.type_comment", "path": "library/ast#ast.For.type_comment", "type": "Language", "text": ["type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.FormattedValue", "path": "library/ast#ast.FormattedValue", "type": "Language", "text": ["Node representing a single formatting field in an f-string. If the string contains a single formatting field and nothing else the node can be isolated otherwise it appears in JoinedStr.", "conversion is an integer:"]}, {"name": "ast.FunctionDef", "path": "library/ast#ast.FunctionDef", "type": "Language", "text": ["A function definition.", "type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.FunctionDef.type_comment", "path": "library/ast#ast.FunctionDef.type_comment", "type": "Language", "text": ["type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.GeneratorExp", "path": "library/ast#ast.GeneratorExp", "type": "Language", "text": ["List and set comprehensions, generator expressions, and dictionary comprehensions. elt (or key and value) is a single node representing the part that will be evaluated for each item.", "generators is a list of comprehension nodes."]}, {"name": "ast.get_docstring()", "path": "library/ast#ast.get_docstring", "type": "Language", "text": ["Return the docstring of the given node (which must be a FunctionDef, AsyncFunctionDef, ClassDef, or Module node), or None if it has no docstring. If clean is true, clean up the docstring\u2019s indentation with inspect.cleandoc().", "Changed in version 3.5: AsyncFunctionDef is now supported."]}, {"name": "ast.get_source_segment()", "path": "library/ast#ast.get_source_segment", "type": "Language", "text": ["Get source code segment of the source that generated node. If some location information (lineno, end_lineno, col_offset, or end_col_offset) is missing, return None.", "If padded is True, the first line of a multi-line statement will be padded with spaces to match its original position.", "New in version 3.8."]}, {"name": "ast.Global", "path": "library/ast#ast.Global", "type": "Language", "text": ["global and nonlocal statements. names is a list of raw strings."]}, {"name": "ast.Gt", "path": "library/ast#ast.Gt", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.GtE", "path": "library/ast#ast.GtE", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.If", "path": "library/ast#ast.If", "type": "Language", "text": ["An if statement. test holds a single node, such as a Compare node. body and orelse each hold a list of nodes.", "elif clauses don\u2019t have a special representation in the AST, but rather appear as extra If nodes within the orelse section of the previous one."]}, {"name": "ast.IfExp", "path": "library/ast#ast.IfExp", "type": "Language", "text": ["An expression such as a if b else c. Each field holds a single node, so in the following example, all three are Name nodes."]}, {"name": "ast.Import", "path": "library/ast#ast.Import", "type": "Language", "text": ["An import statement. names is a list of alias nodes."]}, {"name": "ast.ImportFrom", "path": "library/ast#ast.ImportFrom", "type": "Language", "text": ["Represents from x import y. module is a raw string of the \u2018from\u2019 name, without any leading dots, or None for statements such as from . import foo. level is an integer holding the level of the relative import (0 means absolute import)."]}, {"name": "ast.In", "path": "library/ast#ast.In", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.increment_lineno()", "path": "library/ast#ast.increment_lineno", "type": "Language", "text": ["Increment the line number and end line number of each node in the tree starting at node by n. This is useful to \u201cmove code\u201d to a different location in a file."]}, {"name": "ast.Invert", "path": "library/ast#ast.Invert", "type": "Language", "text": ["Unary operator tokens. Not is the not keyword, Invert is the ~ operator."]}, {"name": "ast.Is", "path": "library/ast#ast.Is", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.IsNot", "path": "library/ast#ast.IsNot", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.iter_child_nodes()", "path": "library/ast#ast.iter_child_nodes", "type": "Language", "text": ["Yield all direct child nodes of node, that is, all fields that are nodes and all items of fields that are lists of nodes."]}, {"name": "ast.iter_fields()", "path": "library/ast#ast.iter_fields", "type": "Language", "text": ["Yield a tuple of (fieldname, value) for each field in node._fields that is present on node."]}, {"name": "ast.JoinedStr", "path": "library/ast#ast.JoinedStr", "type": "Language", "text": ["An f-string, comprising a series of FormattedValue and Constant nodes."]}, {"name": "ast.keyword", "path": "library/ast#ast.keyword", "type": "Language", "text": ["A keyword argument to a function call or class definition. arg is a raw string of the parameter name, value is a node to pass in."]}, {"name": "ast.Lambda", "path": "library/ast#ast.Lambda", "type": "Language", "text": ["lambda is a minimal function definition that can be used inside an expression. Unlike FunctionDef, body holds a single node."]}, {"name": "ast.List", "path": "library/ast#ast.List", "type": "Language", "text": ["A list or tuple. elts holds a list of nodes representing the elements. ctx is Store if the container is an assignment target (i.e. (x,y)=something), and Load otherwise."]}, {"name": "ast.ListComp", "path": "library/ast#ast.ListComp", "type": "Language", "text": ["List and set comprehensions, generator expressions, and dictionary comprehensions. elt (or key and value) is a single node representing the part that will be evaluated for each item.", "generators is a list of comprehension nodes."]}, {"name": "ast.literal_eval()", "path": "library/ast#ast.literal_eval", "type": "Language", "text": ["Safely evaluate an expression node or a string containing a Python literal or container display. The string or node provided may only consist of the following Python literal structures: strings, bytes, numbers, tuples, lists, dicts, sets, booleans, and None.", "This can be used for safely evaluating strings containing Python values from untrusted sources without the need to parse the values oneself. It is not capable of evaluating arbitrarily complex expressions, for example involving operators or indexing.", "Warning", "It is possible to crash the Python interpreter with a sufficiently large/complex string due to stack depth limitations in Python\u2019s AST compiler.", "Changed in version 3.2: Now allows bytes and set literals.", "Changed in version 3.9: Now supports creating empty sets with 'set()'."]}, {"name": "ast.Load", "path": "library/ast#ast.Load", "type": "Language", "text": ["Variable references can be used to load the value of a variable, to assign a new value to it, or to delete it. Variable references are given a context to distinguish these cases."]}, {"name": "ast.LShift", "path": "library/ast#ast.LShift", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.Lt", "path": "library/ast#ast.Lt", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.LtE", "path": "library/ast#ast.LtE", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.MatMult", "path": "library/ast#ast.MatMult", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.Mod", "path": "library/ast#ast.Mod", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.Mult", "path": "library/ast#ast.Mult", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.Name", "path": "library/ast#ast.Name", "type": "Language", "text": ["A variable name. id holds the name as a string, and ctx is one of the following types."]}, {"name": "ast.NamedExpr", "path": "library/ast#ast.NamedExpr", "type": "Language", "text": ["A named expression. This AST node is produced by the assignment expressions operator (also known as the walrus operator). As opposed to the Assign node in which the first argument can be multiple nodes, in this case both target and value must be single nodes."]}, {"name": "ast.NodeTransformer", "path": "library/ast#ast.NodeTransformer", "type": "Language", "text": ["A NodeVisitor subclass that walks the abstract syntax tree and allows modification of nodes.", "The NodeTransformer will walk the AST and use the return value of the visitor methods to replace or remove the old node. If the return value of the visitor method is None, the node will be removed from its location, otherwise it is replaced with the return value. The return value may be the original node in which case no replacement takes place.", "Here is an example transformer that rewrites all occurrences of name lookups (foo) to data['foo']:", "Keep in mind that if the node you\u2019re operating on has child nodes you must either transform the child nodes yourself or call the generic_visit() method for the node first.", "For nodes that were part of a collection of statements (that applies to all statement nodes), the visitor may also return a list of nodes rather than just a single node.", "If NodeTransformer introduces new nodes (that weren\u2019t part of original tree) without giving them location information (such as lineno), fix_missing_locations() should be called with the new sub-tree to recalculate the location information:", "Usually you use the transformer like this:"]}, {"name": "ast.NodeVisitor", "path": "library/ast#ast.NodeVisitor", "type": "Language", "text": ["A node visitor base class that walks the abstract syntax tree and calls a visitor function for every node found. This function may return a value which is forwarded by the visit() method.", "This class is meant to be subclassed, with the subclass adding visitor methods.", "Visit a node. The default implementation calls the method called self.visit_classname where classname is the name of the node class, or generic_visit() if that method doesn\u2019t exist.", "This visitor calls visit() on all children of the node.", "Note that child nodes of nodes that have a custom visitor method won\u2019t be visited unless the visitor calls generic_visit() or visits them itself.", "Don\u2019t use the NodeVisitor if you want to apply changes to nodes during traversal. For this a special visitor exists (NodeTransformer) that allows modifications.", "Deprecated since version 3.8: Methods visit_Num(), visit_Str(), visit_Bytes(), visit_NameConstant() and visit_Ellipsis() are deprecated now and will not be called in future Python versions. Add the visit_Constant() method to handle all constant nodes."]}, {"name": "ast.NodeVisitor.generic_visit()", "path": "library/ast#ast.NodeVisitor.generic_visit", "type": "Language", "text": ["This visitor calls visit() on all children of the node.", "Note that child nodes of nodes that have a custom visitor method won\u2019t be visited unless the visitor calls generic_visit() or visits them itself."]}, {"name": "ast.NodeVisitor.visit()", "path": "library/ast#ast.NodeVisitor.visit", "type": "Language", "text": ["Visit a node. The default implementation calls the method called self.visit_classname where classname is the name of the node class, or generic_visit() if that method doesn\u2019t exist."]}, {"name": "ast.Nonlocal", "path": "library/ast#ast.Nonlocal", "type": "Language", "text": ["global and nonlocal statements. names is a list of raw strings."]}, {"name": "ast.Not", "path": "library/ast#ast.Not", "type": "Language", "text": ["Unary operator tokens. Not is the not keyword, Invert is the ~ operator."]}, {"name": "ast.NotEq", "path": "library/ast#ast.NotEq", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.NotIn", "path": "library/ast#ast.NotIn", "type": "Language", "text": ["Comparison operator tokens."]}, {"name": "ast.Or", "path": "library/ast#ast.Or", "type": "Language", "text": ["Boolean operator tokens."]}, {"name": "ast.parse()", "path": "library/ast#ast.parse", "type": "Language", "text": ["Parse the source into an AST node. Equivalent to compile(source,\nfilename, mode, ast.PyCF_ONLY_AST).", "If type_comments=True is given, the parser is modified to check and return type comments as specified by PEP 484 and PEP 526. This is equivalent to adding ast.PyCF_TYPE_COMMENTS to the flags passed to compile(). This will report syntax errors for misplaced type comments. Without this flag, type comments will be ignored, and the type_comment field on selected AST nodes will always be None. In addition, the locations of # type:\nignore comments will be returned as the type_ignores attribute of Module (otherwise it is always an empty list).", "In addition, if mode is 'func_type', the input syntax is modified to correspond to PEP 484 \u201csignature type comments\u201d, e.g. (str, int) -> List[str].", "Also, setting feature_version to a tuple (major, minor) will attempt to parse using that Python version\u2019s grammar. Currently major must equal to 3. For example, setting feature_version=(3, 4) will allow the use of async and await as variable names. The lowest supported version is (3, 4); the highest is sys.version_info[0:2].", "Warning", "It is possible to crash the Python interpreter with a sufficiently large/complex string due to stack depth limitations in Python\u2019s AST compiler.", "Changed in version 3.8: Added type_comments, mode='func_type' and feature_version."]}, {"name": "ast.Pass", "path": "library/ast#ast.Pass", "type": "Language", "text": ["A pass statement."]}, {"name": "ast.Pow", "path": "library/ast#ast.Pow", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.PyCF_ALLOW_TOP_LEVEL_AWAIT", "path": "library/ast#ast.PyCF_ALLOW_TOP_LEVEL_AWAIT", "type": "Language", "text": ["Enables support for top-level await, async for, async with and async comprehensions.", "New in version 3.8."]}, {"name": "ast.PyCF_ONLY_AST", "path": "library/ast#ast.PyCF_ONLY_AST", "type": "Language", "text": ["Generates and returns an abstract syntax tree instead of returning a compiled code object."]}, {"name": "ast.PyCF_TYPE_COMMENTS", "path": "library/ast#ast.PyCF_TYPE_COMMENTS", "type": "Language", "text": ["Enables support for PEP 484 and PEP 526 style type comments (# type: <type>, # type: ignore <stuff>).", "New in version 3.8."]}, {"name": "ast.Raise", "path": "library/ast#ast.Raise", "type": "Language", "text": ["A raise statement. exc is the exception object to be raised, normally a Call or Name, or None for a standalone raise. cause is the optional part for y in raise x from y."]}, {"name": "ast.Return", "path": "library/ast#ast.Return", "type": "Language", "text": ["A return statement."]}, {"name": "ast.RShift", "path": "library/ast#ast.RShift", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.Set", "path": "library/ast#ast.Set", "type": "Language", "text": ["A set. elts holds a list of nodes representing the set\u2019s elements."]}, {"name": "ast.SetComp", "path": "library/ast#ast.SetComp", "type": "Language", "text": ["List and set comprehensions, generator expressions, and dictionary comprehensions. elt (or key and value) is a single node representing the part that will be evaluated for each item.", "generators is a list of comprehension nodes."]}, {"name": "ast.Slice", "path": "library/ast#ast.Slice", "type": "Language", "text": ["Regular slicing (on the form lower:upper or lower:upper:step). Can occur only inside the slice field of Subscript, either directly or as an element of Tuple."]}, {"name": "ast.Starred", "path": "library/ast#ast.Starred", "type": "Language", "text": ["A *var variable reference. value holds the variable, typically a Name node. This type must be used when building a Call node with *args."]}, {"name": "ast.Store", "path": "library/ast#ast.Store", "type": "Language", "text": ["Variable references can be used to load the value of a variable, to assign a new value to it, or to delete it. Variable references are given a context to distinguish these cases."]}, {"name": "ast.Sub", "path": "library/ast#ast.Sub", "type": "Language", "text": ["Binary operator tokens."]}, {"name": "ast.Subscript", "path": "library/ast#ast.Subscript", "type": "Language", "text": ["A subscript, such as l[1]. value is the subscripted object (usually sequence or mapping). slice is an index, slice or key. It can be a Tuple and contain a Slice. ctx is Load, Store or Del according to the action performed with the subscript."]}, {"name": "ast.Try", "path": "library/ast#ast.Try", "type": "Language", "text": ["try blocks. All attributes are list of nodes to execute, except for handlers, which is a list of ExceptHandler nodes."]}, {"name": "ast.Tuple", "path": "library/ast#ast.Tuple", "type": "Language", "text": ["A list or tuple. elts holds a list of nodes representing the elements. ctx is Store if the container is an assignment target (i.e. (x,y)=something), and Load otherwise."]}, {"name": "ast.UAdd", "path": "library/ast#ast.UAdd", "type": "Language", "text": ["Unary operator tokens. Not is the not keyword, Invert is the ~ operator."]}, {"name": "ast.UnaryOp", "path": "library/ast#ast.UnaryOp", "type": "Language", "text": ["A unary operation. op is the operator, and operand any expression node."]}, {"name": "ast.unparse()", "path": "library/ast#ast.unparse", "type": "Language", "text": ["Unparse an ast.AST object and generate a string with code that would produce an equivalent ast.AST object if parsed back with ast.parse().", "Warning", "The produced code string will not necessarily be equal to the original code that generated the ast.AST object (without any compiler optimizations, such as constant tuples/frozensets).", "Warning", "Trying to unparse a highly complex expression would result with RecursionError.", "New in version 3.9."]}, {"name": "ast.USub", "path": "library/ast#ast.USub", "type": "Language", "text": ["Unary operator tokens. Not is the not keyword, Invert is the ~ operator."]}, {"name": "ast.walk()", "path": "library/ast#ast.walk", "type": "Language", "text": ["Recursively yield all descendant nodes in the tree starting at node (including node itself), in no specified order. This is useful if you only want to modify nodes in place and don\u2019t care about the context."]}, {"name": "ast.While", "path": "library/ast#ast.While", "type": "Language", "text": ["A while loop. test holds the condition, such as a Compare node."]}, {"name": "ast.With", "path": "library/ast#ast.With", "type": "Language", "text": ["A with block. items is a list of withitem nodes representing the context managers, and body is the indented block inside the context.", "type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.With.type_comment", "path": "library/ast#ast.With.type_comment", "type": "Language", "text": ["type_comment is an optional string with the type annotation as a comment."]}, {"name": "ast.withitem", "path": "library/ast#ast.withitem", "type": "Language", "text": ["A single context manager in a with block. context_expr is the context manager, often a Call node. optional_vars is a Name, Tuple or List for the as foo part, or None if that isn\u2019t used."]}, {"name": "ast.Yield", "path": "library/ast#ast.Yield", "type": "Language", "text": ["A yield or yield from expression. Because these are expressions, they must be wrapped in a Expr node if the value sent back is not used."]}, {"name": "ast.YieldFrom", "path": "library/ast#ast.YieldFrom", "type": "Language", "text": ["A yield or yield from expression. Because these are expressions, they must be wrapped in a Expr node if the value sent back is not used."]}, {"name": "asynchat", "path": "library/asynchat", "type": "Networking & Interprocess Communication", "text": ["Source code: Lib/asynchat.py", "Deprecated since version 3.6: Please use asyncio instead.", "Note", "This module exists for backwards compatibility only. For new code we recommend using asyncio.", "This module builds on the asyncore infrastructure, simplifying asynchronous clients and servers and making it easier to handle protocols whose elements are terminated by arbitrary strings, or are of variable length. asynchat defines the abstract class async_chat that you subclass, providing implementations of the collect_incoming_data() and found_terminator() methods. It uses the same asynchronous loop as asyncore, and the two types of channel, asyncore.dispatcher and asynchat.async_chat, can freely be mixed in the channel map. Typically an asyncore.dispatcher server channel generates new asynchat.async_chat channel objects as it receives incoming connection requests.", "This class is an abstract subclass of asyncore.dispatcher. To make practical use of the code you must subclass async_chat, providing meaningful collect_incoming_data() and found_terminator() methods. The asyncore.dispatcher methods can be used, although not all make sense in a message/response context.", "Like asyncore.dispatcher, async_chat defines a set of events that are generated by an analysis of socket conditions after a select() call. Once the polling loop has been started the async_chat object\u2019s methods are called by the event-processing framework with no action on the part of the programmer.", "Two class attributes can be modified, to improve performance, or possibly even to conserve memory.", "The asynchronous input buffer size (default 4096).", "The asynchronous output buffer size (default 4096).", "Unlike asyncore.dispatcher, async_chat allows you to define a FIFO queue of producers. A producer need have only one method, more(), which should return data to be transmitted on the channel. The producer indicates exhaustion (i.e. that it contains no more data) by having its more() method return the empty bytes object. At this point the async_chat object removes the producer from the queue and starts using the next producer, if any. When the producer queue is empty the handle_write() method does nothing. You use the channel object\u2019s set_terminator() method to describe how to recognize the end of, or an important breakpoint in, an incoming transmission from the remote endpoint.", "To build a functioning async_chat subclass your input methods collect_incoming_data() and found_terminator() must handle the data that the channel receives asynchronously. The methods are described below.", "Pushes a None on to the producer queue. When this producer is popped off the queue it causes the channel to be closed.", "Called with data holding an arbitrary amount of received data. The default method, which must be overridden, raises a NotImplementedError exception.", "In emergencies this method will discard any data held in the input and/or output buffers and the producer queue.", "Called when the incoming data stream matches the termination condition set by set_terminator(). The default method, which must be overridden, raises a NotImplementedError exception. The buffered input data should be available via an instance attribute.", "Returns the current terminator for the channel.", "Pushes data on to the channel\u2019s queue to ensure its transmission. This is all you need to do to have the channel write the data out to the network, although it is possible to use your own producers in more complex schemes to implement encryption and chunking, for example.", "Takes a producer object and adds it to the producer queue associated with the channel. When all currently-pushed producers have been exhausted the channel will consume this producer\u2019s data by calling its more() method and send the data to the remote endpoint.", "Sets the terminating condition to be recognized on the channel. term may be any of three types of value, corresponding to three different ways to handle incoming protocol data.", "term", "Description", "string", "Will call found_terminator() when the string is found in the input stream", "integer", "Will call found_terminator() when the indicated number of characters have been received", "None", "The channel continues to collect data forever", "Note that any data following the terminator will be available for reading by the channel after found_terminator() is called.", "The following partial example shows how HTTP requests can be read with async_chat. A web server might create an http_request_handler object for each incoming client connection. Notice that initially the channel terminator is set to match the blank line at the end of the HTTP headers, and a flag indicates that the headers are being read.", "Once the headers have been read, if the request is of type POST (indicating that further data are present in the input stream) then the Content-Length: header is used to set a numeric terminator to read the right amount of data from the channel.", "The handle_request() method is called once all relevant input has been marshalled, after setting the channel terminator to None to ensure that any extraneous data sent by the web client are ignored."]}, {"name": "asynchat.async_chat", "path": "library/asynchat#asynchat.async_chat", "type": "Networking & Interprocess Communication", "text": ["This class is an abstract subclass of asyncore.dispatcher. To make practical use of the code you must subclass async_chat, providing meaningful collect_incoming_data() and found_terminator() methods. The asyncore.dispatcher methods can be used, although not all make sense in a message/response context.", "Like asyncore.dispatcher, async_chat defines a set of events that are generated by an analysis of socket conditions after a select() call. Once the polling loop has been started the async_chat object\u2019s methods are called by the event-processing framework with no action on the part of the programmer.", "Two class attributes can be modified, to improve performance, or possibly even to conserve memory.", "The asynchronous input buffer size (default 4096).", "The asynchronous output buffer size (default 4096).", "Unlike asyncore.dispatcher, async_chat allows you to define a FIFO queue of producers. A producer need have only one method, more(), which should return data to be transmitted on the channel. The producer indicates exhaustion (i.e. that it contains no more data) by having its more() method return the empty bytes object. At this point the async_chat object removes the producer from the queue and starts using the next producer, if any. When the producer queue is empty the handle_write() method does nothing. You use the channel object\u2019s set_terminator() method to describe how to recognize the end of, or an important breakpoint in, an incoming transmission from the remote endpoint.", "To build a functioning async_chat subclass your input methods collect_incoming_data() and found_terminator() must handle the data that the channel receives asynchronously. The methods are described below."]}, {"name": "asynchat.async_chat.ac_in_buffer_size", "path": "library/asynchat#asynchat.async_chat.ac_in_buffer_size", "type": "Networking & Interprocess Communication", "text": ["The asynchronous input buffer size (default 4096)."]}, {"name": "asynchat.async_chat.ac_out_buffer_size", "path": "library/asynchat#asynchat.async_chat.ac_out_buffer_size", "type": "Networking & Interprocess Communication", "text": ["The asynchronous output buffer size (default 4096)."]}, {"name": "asynchat.async_chat.close_when_done()", "path": "library/asynchat#asynchat.async_chat.close_when_done", "type": "Networking & Interprocess Communication", "text": ["Pushes a None on to the producer queue. When this producer is popped off the queue it causes the channel to be closed."]}, {"name": "asynchat.async_chat.collect_incoming_data()", "path": "library/asynchat#asynchat.async_chat.collect_incoming_data", "type": "Networking & Interprocess Communication", "text": ["Called with data holding an arbitrary amount of received data. The default method, which must be overridden, raises a NotImplementedError exception."]}, {"name": "asynchat.async_chat.discard_buffers()", "path": "library/asynchat#asynchat.async_chat.discard_buffers", "type": "Networking & Interprocess Communication", "text": ["In emergencies this method will discard any data held in the input and/or output buffers and the producer queue."]}, {"name": "asynchat.async_chat.found_terminator()", "path": "library/asynchat#asynchat.async_chat.found_terminator", "type": "Networking & Interprocess Communication", "text": ["Called when the incoming data stream matches the termination condition set by set_terminator(). The default method, which must be overridden, raises a NotImplementedError exception. The buffered input data should be available via an instance attribute."]}, {"name": "asynchat.async_chat.get_terminator()", "path": "library/asynchat#asynchat.async_chat.get_terminator", "type": "Networking & Interprocess Communication", "text": ["Returns the current terminator for the channel."]}, {"name": "asynchat.async_chat.push()", "path": "library/asynchat#asynchat.async_chat.push", "type": "Networking & Interprocess Communication", "text": ["Pushes data on to the channel\u2019s queue to ensure its transmission. This is all you need to do to have the channel write the data out to the network, although it is possible to use your own producers in more complex schemes to implement encryption and chunking, for example."]}, {"name": "asynchat.async_chat.push_with_producer()", "path": "library/asynchat#asynchat.async_chat.push_with_producer", "type": "Networking & Interprocess Communication", "text": ["Takes a producer object and adds it to the producer queue associated with the channel. When all currently-pushed producers have been exhausted the channel will consume this producer\u2019s data by calling its more() method and send the data to the remote endpoint."]}, {"name": "asynchat.async_chat.set_terminator()", "path": "library/asynchat#asynchat.async_chat.set_terminator", "type": "Networking & Interprocess Communication", "text": ["Sets the terminating condition to be recognized on the channel. term may be any of three types of value, corresponding to three different ways to handle incoming protocol data.", "term", "Description", "string", "Will call found_terminator() when the string is found in the input stream", "integer", "Will call found_terminator() when the indicated number of characters have been received", "None", "The channel continues to collect data forever", "Note that any data following the terminator will be available for reading by the channel after found_terminator() is called."]}, {"name": "asyncio", "path": "library/asyncio", "type": "Asynchronous I/O", "text": ["Hello World!", "asyncio is a library to write concurrent code using the async/await syntax.", "asyncio is used as a foundation for multiple Python asynchronous frameworks that provide high-performance network and web-servers, database connection libraries, distributed task queues, etc.", "asyncio is often a perfect fit for IO-bound and high-level structured network code.", "asyncio provides a set of high-level APIs to:", "Additionally, there are low-level APIs for library and framework developers to:", "High-level APIs", "Low-level APIs", "Guides and Tutorials", "Note", "The source code for asyncio can be found in Lib/asyncio/."]}, {"name": "asyncio.AbstractChildWatcher", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher", "type": "Asynchronous I/O", "text": ["Register a new child handler.", "Arrange for callback(pid, returncode, *args) to be called when a process with PID equal to pid terminates. Specifying another callback for the same process replaces the previous handler.", "The callback callable must be thread-safe.", "Removes the handler for process with PID equal to pid.", "The function returns True if the handler was successfully removed, False if there was nothing to remove.", "Attach the watcher to an event loop.", "If the watcher was previously attached to an event loop, then it is first detached before attaching to the new loop.", "Note: loop may be None.", "Return True if the watcher is ready to use.", "Spawning a subprocess with inactive current child watcher raises RuntimeError.", "New in version 3.8.", "Close the watcher.", "This method has to be called to ensure that underlying resources are cleaned-up."]}, {"name": "asyncio.AbstractChildWatcher.add_child_handler()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.add_child_handler", "type": "Asynchronous I/O", "text": ["Register a new child handler.", "Arrange for callback(pid, returncode, *args) to be called when a process with PID equal to pid terminates. Specifying another callback for the same process replaces the previous handler.", "The callback callable must be thread-safe."]}, {"name": "asyncio.AbstractChildWatcher.attach_loop()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.attach_loop", "type": "Asynchronous I/O", "text": ["Attach the watcher to an event loop.", "If the watcher was previously attached to an event loop, then it is first detached before attaching to the new loop.", "Note: loop may be None."]}, {"name": "asyncio.AbstractChildWatcher.close()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.close", "type": "Asynchronous I/O", "text": ["Close the watcher.", "This method has to be called to ensure that underlying resources are cleaned-up."]}, {"name": "asyncio.AbstractChildWatcher.is_active()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.is_active", "type": "Asynchronous I/O", "text": ["Return True if the watcher is ready to use.", "Spawning a subprocess with inactive current child watcher raises RuntimeError.", "New in version 3.8."]}, {"name": "asyncio.AbstractChildWatcher.remove_child_handler()", "path": "library/asyncio-policy#asyncio.AbstractChildWatcher.remove_child_handler", "type": "Asynchronous I/O", "text": ["Removes the handler for process with PID equal to pid.", "The function returns True if the handler was successfully removed, False if there was nothing to remove."]}, {"name": "asyncio.AbstractEventLoop", "path": "library/asyncio-eventloop#asyncio.AbstractEventLoop", "type": "Asynchronous I/O", "text": ["Abstract base class for asyncio-compliant event loops.", "The Event Loop Methods section lists all methods that an alternative implementation of AbstractEventLoop should have defined."]}, {"name": "asyncio.AbstractEventLoopPolicy", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy", "type": "Asynchronous I/O", "text": ["An abstract base class for asyncio policies.", "Get the event loop for the current context.", "Return an event loop object implementing the AbstractEventLoop interface.", "This method should never return None.", "Changed in version 3.6.", "Set the event loop for the current context to loop.", "Create and return a new event loop object.", "This method should never return None.", "Get a child process watcher object.", "Return a watcher object implementing the AbstractChildWatcher interface.", "This function is Unix specific.", "Set the current child process watcher to watcher.", "This function is Unix specific."]}, {"name": "asyncio.AbstractEventLoopPolicy.get_child_watcher()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.get_child_watcher", "type": "Asynchronous I/O", "text": ["Get a child process watcher object.", "Return a watcher object implementing the AbstractChildWatcher interface.", "This function is Unix specific."]}, {"name": "asyncio.AbstractEventLoopPolicy.get_event_loop()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.get_event_loop", "type": "Asynchronous I/O", "text": ["Get the event loop for the current context.", "Return an event loop object implementing the AbstractEventLoop interface.", "This method should never return None.", "Changed in version 3.6."]}, {"name": "asyncio.AbstractEventLoopPolicy.new_event_loop()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.new_event_loop", "type": "Asynchronous I/O", "text": ["Create and return a new event loop object.", "This method should never return None."]}, {"name": "asyncio.AbstractEventLoopPolicy.set_child_watcher()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.set_child_watcher", "type": "Asynchronous I/O", "text": ["Set the current child process watcher to watcher.", "This function is Unix specific."]}, {"name": "asyncio.AbstractEventLoopPolicy.set_event_loop()", "path": "library/asyncio-policy#asyncio.AbstractEventLoopPolicy.set_event_loop", "type": "Asynchronous I/O", "text": ["Set the event loop for the current context to loop."]}, {"name": "asyncio.all_tasks()", "path": "library/asyncio-task#asyncio.all_tasks", "type": "Asynchronous I/O", "text": ["Return a set of not yet finished Task objects run by the loop.", "If loop is None, get_running_loop() is used for getting current loop.", "New in version 3.7."]}, {"name": "asyncio.asyncio.subprocess.DEVNULL", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.DEVNULL", "type": "Asynchronous I/O", "text": ["Special value that can be used as the stdin, stdout or stderr argument to process creation functions. It indicates that the special file os.devnull will be used for the corresponding subprocess stream."]}, {"name": "asyncio.asyncio.subprocess.PIPE", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.PIPE", "type": "Asynchronous I/O", "text": ["Can be passed to the stdin, stdout or stderr parameters.", "If PIPE is passed to stdin argument, the Process.stdin attribute will point to a StreamWriter instance.", "If PIPE is passed to stdout or stderr arguments, the Process.stdout and Process.stderr attributes will point to StreamReader instances."]}, {"name": "asyncio.asyncio.subprocess.Process", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process", "type": "Asynchronous I/O", "text": ["An object that wraps OS processes created by the create_subprocess_exec() and create_subprocess_shell() functions.", "This class is designed to have a similar API to the subprocess.Popen class, but there are some notable differences:", "This class is not thread safe.", "See also the Subprocess and Threads section.", "Wait for the child process to terminate.", "Set and return the returncode attribute.", "Note", "This method can deadlock when using stdout=PIPE or stderr=PIPE and the child process generates so much output that it blocks waiting for the OS pipe buffer to accept more data. Use the communicate() method when using pipes to avoid this condition.", "Interact with process:", "The optional input argument is the data (bytes object) that will be sent to the child process.", "Return a tuple (stdout_data, stderr_data).", "If either BrokenPipeError or ConnectionResetError exception is raised when writing input into stdin, the exception is ignored. This condition occurs when the process exits before all data are written into stdin.", "If it is desired to send data to the process\u2019 stdin, the process needs to be created with stdin=PIPE. Similarly, to get anything other than None in the result tuple, the process has to be created with stdout=PIPE and/or stderr=PIPE arguments.", "Note, that the data read is buffered in memory, so do not use this method if the data size is large or unlimited.", "Sends the signal signal to the child process.", "Note", "On Windows, SIGTERM is an alias for terminate(). CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to processes started with a creationflags parameter which includes CREATE_NEW_PROCESS_GROUP.", "Stop the child process.", "On POSIX systems this method sends signal.SIGTERM to the child process.", "On Windows the Win32 API function TerminateProcess() is called to stop the child process.", "Kill the child process.", "On POSIX systems this method sends SIGKILL to the child process.", "On Windows this method is an alias for terminate().", "Standard input stream (StreamWriter) or None if the process was created with stdin=None.", "Standard output stream (StreamReader) or None if the process was created with stdout=None.", "Standard error stream (StreamReader) or None if the process was created with stderr=None.", "Warning", "Use the communicate() method rather than process.stdin.write(), await process.stdout.read() or await process.stderr.read. This avoids deadlocks due to streams pausing reading or writing and blocking the child process.", "Process identification number (PID).", "Note that for processes created by the create_subprocess_shell() function, this attribute is the PID of the spawned shell.", "Return code of the process when it exits.", "A None value indicates that the process has not terminated yet.", "A negative value -N indicates that the child was terminated by signal N (POSIX only)."]}, {"name": "asyncio.asyncio.subprocess.Process.communicate()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.communicate", "type": "Asynchronous I/O", "text": ["Interact with process:", "The optional input argument is the data (bytes object) that will be sent to the child process.", "Return a tuple (stdout_data, stderr_data).", "If either BrokenPipeError or ConnectionResetError exception is raised when writing input into stdin, the exception is ignored. This condition occurs when the process exits before all data are written into stdin.", "If it is desired to send data to the process\u2019 stdin, the process needs to be created with stdin=PIPE. Similarly, to get anything other than None in the result tuple, the process has to be created with stdout=PIPE and/or stderr=PIPE arguments.", "Note, that the data read is buffered in memory, so do not use this method if the data size is large or unlimited."]}, {"name": "asyncio.asyncio.subprocess.Process.kill()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.kill", "type": "Asynchronous I/O", "text": ["Kill the child process.", "On POSIX systems this method sends SIGKILL to the child process.", "On Windows this method is an alias for terminate()."]}, {"name": "asyncio.asyncio.subprocess.Process.pid", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.pid", "type": "Asynchronous I/O", "text": ["Process identification number (PID).", "Note that for processes created by the create_subprocess_shell() function, this attribute is the PID of the spawned shell."]}, {"name": "asyncio.asyncio.subprocess.Process.returncode", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.returncode", "type": "Asynchronous I/O", "text": ["Return code of the process when it exits.", "A None value indicates that the process has not terminated yet.", "A negative value -N indicates that the child was terminated by signal N (POSIX only)."]}, {"name": "asyncio.asyncio.subprocess.Process.send_signal()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.send_signal", "type": "Asynchronous I/O", "text": ["Sends the signal signal to the child process.", "Note", "On Windows, SIGTERM is an alias for terminate(). CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to processes started with a creationflags parameter which includes CREATE_NEW_PROCESS_GROUP."]}, {"name": "asyncio.asyncio.subprocess.Process.stderr", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.stderr", "type": "Asynchronous I/O", "text": ["Standard error stream (StreamReader) or None if the process was created with stderr=None."]}, {"name": "asyncio.asyncio.subprocess.Process.stdin", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.stdin", "type": "Asynchronous I/O", "text": ["Standard input stream (StreamWriter) or None if the process was created with stdin=None."]}, {"name": "asyncio.asyncio.subprocess.Process.stdout", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.stdout", "type": "Asynchronous I/O", "text": ["Standard output stream (StreamReader) or None if the process was created with stdout=None."]}, {"name": "asyncio.asyncio.subprocess.Process.terminate()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.terminate", "type": "Asynchronous I/O", "text": ["Stop the child process.", "On POSIX systems this method sends signal.SIGTERM to the child process.", "On Windows the Win32 API function TerminateProcess() is called to stop the child process."]}, {"name": "asyncio.asyncio.subprocess.Process.wait()", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.Process.wait", "type": "Asynchronous I/O", "text": ["Wait for the child process to terminate.", "Set and return the returncode attribute.", "Note", "This method can deadlock when using stdout=PIPE or stderr=PIPE and the child process generates so much output that it blocks waiting for the OS pipe buffer to accept more data. Use the communicate() method when using pipes to avoid this condition."]}, {"name": "asyncio.asyncio.subprocess.STDOUT", "path": "library/asyncio-subprocess#asyncio.asyncio.subprocess.STDOUT", "type": "Asynchronous I/O", "text": ["Special value that can be used as the stderr argument and indicates that standard error should be redirected into standard output."]}, {"name": "asyncio.as_completed()", "path": "library/asyncio-task#asyncio.as_completed", "type": "Asynchronous I/O", "text": ["Run awaitable objects in the aws iterable concurrently. Return an iterator of coroutines. Each coroutine returned can be awaited to get the earliest next result from the iterable of the remaining awaitables.", "Raises asyncio.TimeoutError if the timeout occurs before all Futures are done.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example:"]}, {"name": "asyncio.BaseProtocol", "path": "library/asyncio-protocol#asyncio.BaseProtocol", "type": "Asynchronous I/O", "text": ["Base protocol with methods that all protocols share."]}, {"name": "asyncio.BaseProtocol.connection_lost()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.connection_lost", "type": "Asynchronous I/O", "text": ["Called when the connection is lost or closed.", "The argument is either an exception object or None. The latter means a regular EOF is received, or the connection was aborted or closed by this side of the connection."]}, {"name": "asyncio.BaseProtocol.connection_made()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.connection_made", "type": "Asynchronous I/O", "text": ["Called when a connection is made.", "The transport argument is the transport representing the connection. The protocol is responsible for storing the reference to its transport."]}, {"name": "asyncio.BaseProtocol.pause_writing()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.pause_writing", "type": "Asynchronous I/O", "text": ["Called when the transport\u2019s buffer goes over the high watermark."]}, {"name": "asyncio.BaseProtocol.resume_writing()", "path": "library/asyncio-protocol#asyncio.BaseProtocol.resume_writing", "type": "Asynchronous I/O", "text": ["Called when the transport\u2019s buffer drains below the low watermark."]}, {"name": "asyncio.BaseTransport", "path": "library/asyncio-protocol#asyncio.BaseTransport", "type": "Asynchronous I/O", "text": ["Base class for all transports. Contains methods that all asyncio transports share."]}, {"name": "asyncio.BaseTransport.close()", "path": "library/asyncio-protocol#asyncio.BaseTransport.close", "type": "Asynchronous I/O", "text": ["Close the transport.", "If the transport has a buffer for outgoing data, buffered data will be flushed asynchronously. No more data will be received. After all buffered data is flushed, the protocol\u2019s protocol.connection_lost() method will be called with None as its argument."]}, {"name": "asyncio.BaseTransport.get_extra_info()", "path": "library/asyncio-protocol#asyncio.BaseTransport.get_extra_info", "type": "Asynchronous I/O", "text": ["Return information about the transport or underlying resources it uses.", "name is a string representing the piece of transport-specific information to get.", "default is the value to return if the information is not available, or if the transport does not support querying it with the given third-party event loop implementation or on the current platform.", "For example, the following code attempts to get the underlying socket object of the transport:", "Categories of information that can be queried on some transports:", "socket:", "SSL socket:", "pipe:", "subprocess:"]}, {"name": "asyncio.BaseTransport.get_protocol()", "path": "library/asyncio-protocol#asyncio.BaseTransport.get_protocol", "type": "Asynchronous I/O", "text": ["Return the current protocol."]}, {"name": "asyncio.BaseTransport.is_closing()", "path": "library/asyncio-protocol#asyncio.BaseTransport.is_closing", "type": "Asynchronous I/O", "text": ["Return True if the transport is closing or is closed."]}, {"name": "asyncio.BaseTransport.set_protocol()", "path": "library/asyncio-protocol#asyncio.BaseTransport.set_protocol", "type": "Asynchronous I/O", "text": ["Set a new protocol.", "Switching protocol should only be done when both protocols are documented to support the switch."]}, {"name": "asyncio.BoundedSemaphore", "path": "library/asyncio-sync#asyncio.BoundedSemaphore", "type": "Asynchronous I/O", "text": ["A bounded semaphore object. Not thread-safe.", "Bounded Semaphore is a version of Semaphore that raises a ValueError in release() if it increases the internal counter above the initial value.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter."]}, {"name": "asyncio.BufferedProtocol", "path": "library/asyncio-protocol#asyncio.BufferedProtocol", "type": "Asynchronous I/O", "text": ["A base class for implementing streaming protocols with manual control of the receive buffer."]}, {"name": "asyncio.BufferedProtocol.buffer_updated()", "path": "library/asyncio-protocol#asyncio.BufferedProtocol.buffer_updated", "type": "Asynchronous I/O", "text": ["Called when the buffer was updated with the received data.", "nbytes is the total number of bytes that were written to the buffer."]}, {"name": "asyncio.BufferedProtocol.eof_received()", "path": "library/asyncio-protocol#asyncio.BufferedProtocol.eof_received", "type": "Asynchronous I/O", "text": ["See the documentation of the protocol.eof_received() method."]}, {"name": "asyncio.BufferedProtocol.get_buffer()", "path": "library/asyncio-protocol#asyncio.BufferedProtocol.get_buffer", "type": "Asynchronous I/O", "text": ["Called to allocate a new receive buffer.", "sizehint is the recommended minimum size for the returned buffer. It is acceptable to return smaller or larger buffers than what sizehint suggests. When set to -1, the buffer size can be arbitrary. It is an error to return a buffer with a zero size.", "get_buffer() must return an object implementing the buffer protocol."]}, {"name": "asyncio.CancelledError", "path": "library/asyncio-exceptions#asyncio.CancelledError", "type": "Asynchronous I/O", "text": ["The operation has been cancelled.", "This exception can be caught to perform custom operations when asyncio Tasks are cancelled. In almost all situations the exception must be re-raised.", "Changed in version 3.8: CancelledError is now a subclass of BaseException."]}, {"name": "asyncio.Condition", "path": "library/asyncio-sync#asyncio.Condition", "type": "Asynchronous I/O", "text": ["A Condition object. Not thread-safe.", "An asyncio condition primitive can be used by a task to wait for some event to happen and then get exclusive access to a shared resource.", "In essence, a Condition object combines the functionality of an Event and a Lock. It is possible to have multiple Condition objects share one Lock, which allows coordinating exclusive access to a shared resource between different tasks interested in particular states of that shared resource.", "The optional lock argument must be a Lock object or None. In the latter case a new Lock object is created automatically.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "The preferred way to use a Condition is an async with statement:", "which is equivalent to:", "Acquire the underlying lock.", "This method waits until the underlying lock is unlocked, sets it to locked and returns True.", "Wake up at most n tasks (1 by default) waiting on this condition. The method is no-op if no tasks are waiting.", "The lock must be acquired before this method is called and released shortly after. If called with an unlocked lock a RuntimeError error is raised.", "Return True if the underlying lock is acquired.", "Wake up all tasks waiting on this condition.", "This method acts like notify(), but wakes up all waiting tasks.", "The lock must be acquired before this method is called and released shortly after. If called with an unlocked lock a RuntimeError error is raised.", "Release the underlying lock.", "When invoked on an unlocked lock, a RuntimeError is raised.", "Wait until notified.", "If the calling task has not acquired the lock when this method is called, a RuntimeError is raised.", "This method releases the underlying lock, and then blocks until it is awakened by a notify() or notify_all() call. Once awakened, the Condition re-acquires its lock and this method returns True.", "Wait until a predicate becomes true.", "The predicate must be a callable which result will be interpreted as a boolean value. The final value is the return value."]}, {"name": "asyncio.Condition.acquire()", "path": "library/asyncio-sync#asyncio.Condition.acquire", "type": "Asynchronous I/O", "text": ["Acquire the underlying lock.", "This method waits until the underlying lock is unlocked, sets it to locked and returns True."]}, {"name": "asyncio.Condition.locked()", "path": "library/asyncio-sync#asyncio.Condition.locked", "type": "Asynchronous I/O", "text": ["Return True if the underlying lock is acquired."]}, {"name": "asyncio.Condition.notify()", "path": "library/asyncio-sync#asyncio.Condition.notify", "type": "Asynchronous I/O", "text": ["Wake up at most n tasks (1 by default) waiting on this condition. The method is no-op if no tasks are waiting.", "The lock must be acquired before this method is called and released shortly after. If called with an unlocked lock a RuntimeError error is raised."]}, {"name": "asyncio.Condition.notify_all()", "path": "library/asyncio-sync#asyncio.Condition.notify_all", "type": "Asynchronous I/O", "text": ["Wake up all tasks waiting on this condition.", "This method acts like notify(), but wakes up all waiting tasks.", "The lock must be acquired before this method is called and released shortly after. If called with an unlocked lock a RuntimeError error is raised."]}, {"name": "asyncio.Condition.release()", "path": "library/asyncio-sync#asyncio.Condition.release", "type": "Asynchronous I/O", "text": ["Release the underlying lock.", "When invoked on an unlocked lock, a RuntimeError is raised."]}, {"name": "asyncio.Condition.wait()", "path": "library/asyncio-sync#asyncio.Condition.wait", "type": "Asynchronous I/O", "text": ["Wait until notified.", "If the calling task has not acquired the lock when this method is called, a RuntimeError is raised.", "This method releases the underlying lock, and then blocks until it is awakened by a notify() or notify_all() call. Once awakened, the Condition re-acquires its lock and this method returns True."]}, {"name": "asyncio.Condition.wait_for()", "path": "library/asyncio-sync#asyncio.Condition.wait_for", "type": "Asynchronous I/O", "text": ["Wait until a predicate becomes true.", "The predicate must be a callable which result will be interpreted as a boolean value. The final value is the return value."]}, {"name": "asyncio.coroutine()", "path": "library/asyncio-task#asyncio.coroutine", "type": "Asynchronous I/O", "text": ["Decorator to mark generator-based coroutines.", "This decorator enables legacy generator-based coroutines to be compatible with async/await code:", "This decorator should not be used for async def coroutines.", "Deprecated since version 3.8, will be removed in version 3.10: Use async def instead."]}, {"name": "asyncio.create_subprocess_exec()", "path": "library/asyncio-subprocess#asyncio.create_subprocess_exec", "type": "Asynchronous I/O", "text": ["Create a subprocess.", "The limit argument sets the buffer limit for StreamReader wrappers for Process.stdout and Process.stderr (if subprocess.PIPE is passed to stdout and stderr arguments).", "Return a Process instance.", "See the documentation of loop.subprocess_exec() for other parameters.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter."]}, {"name": "asyncio.create_subprocess_shell()", "path": "library/asyncio-subprocess#asyncio.create_subprocess_shell", "type": "Asynchronous I/O", "text": ["Run the cmd shell command.", "The limit argument sets the buffer limit for StreamReader wrappers for Process.stdout and Process.stderr (if subprocess.PIPE is passed to stdout and stderr arguments).", "Return a Process instance.", "See the documentation of loop.subprocess_shell() for other parameters.", "Important", "It is the application\u2019s responsibility to ensure that all whitespace and special characters are quoted appropriately to avoid shell injection vulnerabilities. The shlex.quote() function can be used to properly escape whitespace and special shell characters in strings that are going to be used to construct shell commands.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter."]}, {"name": "asyncio.create_task()", "path": "library/asyncio-task#asyncio.create_task", "type": "Asynchronous I/O", "text": ["Wrap the coro coroutine into a Task and schedule its execution. Return the Task object.", "If name is not None, it is set as the name of the task using Task.set_name().", "The task is executed in the loop returned by get_running_loop(), RuntimeError is raised if there is no running loop in current thread.", "This function has been added in Python 3.7. Prior to Python 3.7, the low-level asyncio.ensure_future() function can be used instead:", "New in version 3.7.", "Changed in version 3.8: Added the name parameter."]}, {"name": "asyncio.current_task()", "path": "library/asyncio-task#asyncio.current_task", "type": "Asynchronous I/O", "text": ["Return the currently running Task instance, or None if no task is running.", "If loop is None get_running_loop() is used to get the current loop.", "New in version 3.7."]}, {"name": "asyncio.DatagramProtocol", "path": "library/asyncio-protocol#asyncio.DatagramProtocol", "type": "Asynchronous I/O", "text": ["The base class for implementing datagram (UDP) protocols."]}, {"name": "asyncio.DatagramProtocol.datagram_received()", "path": "library/asyncio-protocol#asyncio.DatagramProtocol.datagram_received", "type": "Asynchronous I/O", "text": ["Called when a datagram is received. data is a bytes object containing the incoming data. addr is the address of the peer sending the data; the exact format depends on the transport."]}, {"name": "asyncio.DatagramProtocol.error_received()", "path": "library/asyncio-protocol#asyncio.DatagramProtocol.error_received", "type": "Asynchronous I/O", "text": ["Called when a previous send or receive operation raises an OSError. exc is the OSError instance.", "This method is called in rare conditions, when the transport (e.g. UDP) detects that a datagram could not be delivered to its recipient. In many conditions though, undeliverable datagrams will be silently dropped."]}, {"name": "asyncio.DatagramTransport", "path": "library/asyncio-protocol#asyncio.DatagramTransport", "type": "Asynchronous I/O", "text": ["A transport for datagram (UDP) connections.", "Instances of the DatagramTransport class are returned from the loop.create_datagram_endpoint() event loop method."]}, {"name": "asyncio.DatagramTransport.abort()", "path": "library/asyncio-protocol#asyncio.DatagramTransport.abort", "type": "Asynchronous I/O", "text": ["Close the transport immediately, without waiting for pending operations to complete. Buffered data will be lost. No more data will be received. The protocol\u2019s protocol.connection_lost() method will eventually be called with None as its argument."]}, {"name": "asyncio.DatagramTransport.sendto()", "path": "library/asyncio-protocol#asyncio.DatagramTransport.sendto", "type": "Asynchronous I/O", "text": ["Send the data bytes to the remote peer given by addr (a transport-dependent target address). If addr is None, the data is sent to the target address given on transport creation.", "This method does not block; it buffers the data and arranges for it to be sent out asynchronously."]}, {"name": "asyncio.DefaultEventLoopPolicy", "path": "library/asyncio-policy#asyncio.DefaultEventLoopPolicy", "type": "Asynchronous I/O", "text": ["The default asyncio policy. Uses SelectorEventLoop on Unix and ProactorEventLoop on Windows.", "There is no need to install the default policy manually. asyncio is configured to use the default policy automatically.", "Changed in version 3.8: On Windows, ProactorEventLoop is now used by default."]}, {"name": "asyncio.ensure_future()", "path": "library/asyncio-future#asyncio.ensure_future", "type": "Asynchronous I/O", "text": ["Return:", "If obj is neither of the above a TypeError is raised.", "Important", "See also the create_task() function which is the preferred way for creating new Tasks.", "Changed in version 3.5.1: The function accepts any awaitable object."]}, {"name": "asyncio.Event", "path": "library/asyncio-sync#asyncio.Event", "type": "Asynchronous I/O", "text": ["An event object. Not thread-safe.", "An asyncio event can be used to notify multiple asyncio tasks that some event has happened.", "An Event object manages an internal flag that can be set to true with the set() method and reset to false with the clear() method. The wait() method blocks until the flag is set to true. The flag is set to false initially.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example:", "Wait until the event is set.", "If the event is set, return True immediately. Otherwise block until another task calls set().", "Set the event.", "All tasks waiting for event to be set will be immediately awakened.", "Clear (unset) the event.", "Tasks awaiting on wait() will now block until the set() method is called again.", "Return True if the event is set."]}, {"name": "asyncio.Event.clear()", "path": "library/asyncio-sync#asyncio.Event.clear", "type": "Asynchronous I/O", "text": ["Clear (unset) the event.", "Tasks awaiting on wait() will now block until the set() method is called again."]}, {"name": "asyncio.Event.is_set()", "path": "library/asyncio-sync#asyncio.Event.is_set", "type": "Asynchronous I/O", "text": ["Return True if the event is set."]}, {"name": "asyncio.Event.set()", "path": "library/asyncio-sync#asyncio.Event.set", "type": "Asynchronous I/O", "text": ["Set the event.", "All tasks waiting for event to be set will be immediately awakened."]}, {"name": "asyncio.Event.wait()", "path": "library/asyncio-sync#asyncio.Event.wait", "type": "Asynchronous I/O", "text": ["Wait until the event is set.", "If the event is set, return True immediately. Otherwise block until another task calls set()."]}, {"name": "asyncio.FastChildWatcher", "path": "library/asyncio-policy#asyncio.FastChildWatcher", "type": "Asynchronous I/O", "text": ["This implementation reaps every terminated processes by calling os.waitpid(-1) directly, possibly breaking other code spawning processes and waiting for their termination.", "There is no noticeable overhead when handling a big number of children (O(1) each time a child terminates).", "This solution requires a running event loop in the main thread to work, as SafeChildWatcher."]}, {"name": "asyncio.Future", "path": "library/asyncio-future#asyncio.Future", "type": "Asynchronous I/O", "text": ["A Future represents an eventual result of an asynchronous operation. Not thread-safe.", "Future is an awaitable object. Coroutines can await on Future objects until they either have a result or an exception set, or until they are cancelled.", "Typically Futures are used to enable low-level callback-based code (e.g. in protocols implemented using asyncio transports) to interoperate with high-level async/await code.", "The rule of thumb is to never expose Future objects in user-facing APIs, and the recommended way to create a Future object is to call loop.create_future(). This way alternative event loop implementations can inject their own optimized implementations of a Future object.", "Changed in version 3.7: Added support for the contextvars module.", "Return the result of the Future.", "If the Future is done and has a result set by the set_result() method, the result value is returned.", "If the Future is done and has an exception set by the set_exception() method, this method raises the exception.", "If the Future has been cancelled, this method raises a CancelledError exception.", "If the Future\u2019s result isn\u2019t yet available, this method raises a InvalidStateError exception.", "Mark the Future as done and set its result.", "Raises a InvalidStateError error if the Future is already done.", "Mark the Future as done and set an exception.", "Raises a InvalidStateError error if the Future is already done.", "Return True if the Future is done.", "A Future is done if it was cancelled or if it has a result or an exception set with set_result() or set_exception() calls.", "Return True if the Future was cancelled.", "The method is usually used to check if a Future is not cancelled before setting a result or an exception for it:", "Add a callback to be run when the Future is done.", "The callback is called with the Future object as its only argument.", "If the Future is already done when this method is called, the callback is scheduled with loop.call_soon().", "An optional keyword-only context argument allows specifying a custom contextvars.Context for the callback to run in. The current context is used when no context is provided.", "functools.partial() can be used to pass parameters to the callback, e.g.:", "Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details.", "Remove callback from the callbacks list.", "Returns the number of callbacks removed, which is typically 1, unless a callback was added more than once.", "Cancel the Future and schedule callbacks.", "If the Future is already done or cancelled, return False. Otherwise, change the Future\u2019s state to cancelled, schedule the callbacks, and return True.", "Changed in version 3.9: Added the msg parameter.", "Return the exception that was set on this Future.", "The exception (or None if no exception was set) is returned only if the Future is done.", "If the Future has been cancelled, this method raises a CancelledError exception.", "If the Future isn\u2019t done yet, this method raises an InvalidStateError exception.", "Return the event loop the Future object is bound to.", "New in version 3.7."]}, {"name": "asyncio.Future.add_done_callback()", "path": "library/asyncio-future#asyncio.Future.add_done_callback", "type": "Asynchronous I/O", "text": ["Add a callback to be run when the Future is done.", "The callback is called with the Future object as its only argument.", "If the Future is already done when this method is called, the callback is scheduled with loop.call_soon().", "An optional keyword-only context argument allows specifying a custom contextvars.Context for the callback to run in. The current context is used when no context is provided.", "functools.partial() can be used to pass parameters to the callback, e.g.:", "Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details."]}, {"name": "asyncio.Future.cancel()", "path": "library/asyncio-future#asyncio.Future.cancel", "type": "Asynchronous I/O", "text": ["Cancel the Future and schedule callbacks.", "If the Future is already done or cancelled, return False. Otherwise, change the Future\u2019s state to cancelled, schedule the callbacks, and return True.", "Changed in version 3.9: Added the msg parameter."]}, {"name": "asyncio.Future.cancelled()", "path": "library/asyncio-future#asyncio.Future.cancelled", "type": "Asynchronous I/O", "text": ["Return True if the Future was cancelled.", "The method is usually used to check if a Future is not cancelled before setting a result or an exception for it:"]}, {"name": "asyncio.Future.done()", "path": "library/asyncio-future#asyncio.Future.done", "type": "Asynchronous I/O", "text": ["Return True if the Future is done.", "A Future is done if it was cancelled or if it has a result or an exception set with set_result() or set_exception() calls."]}, {"name": "asyncio.Future.exception()", "path": "library/asyncio-future#asyncio.Future.exception", "type": "Asynchronous I/O", "text": ["Return the exception that was set on this Future.", "The exception (or None if no exception was set) is returned only if the Future is done.", "If the Future has been cancelled, this method raises a CancelledError exception.", "If the Future isn\u2019t done yet, this method raises an InvalidStateError exception."]}, {"name": "asyncio.Future.get_loop()", "path": "library/asyncio-future#asyncio.Future.get_loop", "type": "Asynchronous I/O", "text": ["Return the event loop the Future object is bound to.", "New in version 3.7."]}, {"name": "asyncio.Future.remove_done_callback()", "path": "library/asyncio-future#asyncio.Future.remove_done_callback", "type": "Asynchronous I/O", "text": ["Remove callback from the callbacks list.", "Returns the number of callbacks removed, which is typically 1, unless a callback was added more than once."]}, {"name": "asyncio.Future.result()", "path": "library/asyncio-future#asyncio.Future.result", "type": "Asynchronous I/O", "text": ["Return the result of the Future.", "If the Future is done and has a result set by the set_result() method, the result value is returned.", "If the Future is done and has an exception set by the set_exception() method, this method raises the exception.", "If the Future has been cancelled, this method raises a CancelledError exception.", "If the Future\u2019s result isn\u2019t yet available, this method raises a InvalidStateError exception."]}, {"name": "asyncio.Future.set_exception()", "path": "library/asyncio-future#asyncio.Future.set_exception", "type": "Asynchronous I/O", "text": ["Mark the Future as done and set an exception.", "Raises a InvalidStateError error if the Future is already done."]}, {"name": "asyncio.Future.set_result()", "path": "library/asyncio-future#asyncio.Future.set_result", "type": "Asynchronous I/O", "text": ["Mark the Future as done and set its result.", "Raises a InvalidStateError error if the Future is already done."]}, {"name": "asyncio.gather()", "path": "library/asyncio-task#asyncio.gather", "type": "Asynchronous I/O", "text": ["Run awaitable objects in the aws sequence concurrently.", "If any awaitable in aws is a coroutine, it is automatically scheduled as a Task.", "If all awaitables are completed successfully, the result is an aggregate list of returned values. The order of result values corresponds to the order of awaitables in aws.", "If return_exceptions is False (default), the first raised exception is immediately propagated to the task that awaits on gather(). Other awaitables in the aws sequence won\u2019t be cancelled and will continue to run.", "If return_exceptions is True, exceptions are treated the same as successful results, and aggregated in the result list.", "If gather() is cancelled, all submitted awaitables (that have not completed yet) are also cancelled.", "If any Task or Future from the aws sequence is cancelled, it is treated as if it raised CancelledError \u2013 the gather() call is not cancelled in this case. This is to prevent the cancellation of one submitted Task/Future to cause other Tasks/Futures to be cancelled.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example:", "Note", "If return_exceptions is False, cancelling gather() after it has been marked done won\u2019t cancel any submitted awaitables. For instance, gather can be marked done after propagating an exception to the caller, therefore, calling gather.cancel() after catching an exception (raised by one of the awaitables) from gather won\u2019t cancel any other awaitables.", "Changed in version 3.7: If the gather itself is cancelled, the cancellation is propagated regardless of return_exceptions."]}, {"name": "asyncio.get_child_watcher()", "path": "library/asyncio-policy#asyncio.get_child_watcher", "type": "Asynchronous I/O", "text": ["Return the current child watcher for the current policy."]}, {"name": "asyncio.get_event_loop()", "path": "library/asyncio-eventloop#asyncio.get_event_loop", "type": "Asynchronous I/O", "text": ["Get the current event loop.", "If there is no current event loop set in the current OS thread, the OS thread is main, and set_event_loop() has not yet been called, asyncio will create a new event loop and set it as the current one.", "Because this function has rather complex behavior (especially when custom event loop policies are in use), using the get_running_loop() function is preferred to get_event_loop() in coroutines and callbacks.", "Consider also using the asyncio.run() function instead of using lower level functions to manually create and close an event loop."]}, {"name": "asyncio.get_event_loop_policy()", "path": "library/asyncio-policy#asyncio.get_event_loop_policy", "type": "Asynchronous I/O", "text": ["Return the current process-wide policy."]}, {"name": "asyncio.get_running_loop()", "path": "library/asyncio-eventloop#asyncio.get_running_loop", "type": "Asynchronous I/O", "text": ["Return the running event loop in the current OS thread.", "If there is no running event loop a RuntimeError is raised. This function can only be called from a coroutine or a callback.", "New in version 3.7."]}, {"name": "asyncio.Handle", "path": "library/asyncio-eventloop#asyncio.Handle", "type": "Asynchronous I/O", "text": ["A callback wrapper object returned by loop.call_soon(), loop.call_soon_threadsafe().", "Cancel the callback. If the callback has already been canceled or executed, this method has no effect.", "Return True if the callback was cancelled.", "New in version 3.7."]}, {"name": "asyncio.Handle.cancel()", "path": "library/asyncio-eventloop#asyncio.Handle.cancel", "type": "Asynchronous I/O", "text": ["Cancel the callback. If the callback has already been canceled or executed, this method has no effect."]}, {"name": "asyncio.Handle.cancelled()", "path": "library/asyncio-eventloop#asyncio.Handle.cancelled", "type": "Asynchronous I/O", "text": ["Return True if the callback was cancelled.", "New in version 3.7."]}, {"name": "asyncio.IncompleteReadError", "path": "library/asyncio-exceptions#asyncio.IncompleteReadError", "type": "Asynchronous I/O", "text": ["The requested read operation did not complete fully.", "Raised by the asyncio stream APIs.", "This exception is a subclass of EOFError.", "The total number (int) of expected bytes.", "A string of bytes read before the end of stream was reached."]}, {"name": "asyncio.IncompleteReadError.expected", "path": "library/asyncio-exceptions#asyncio.IncompleteReadError.expected", "type": "Asynchronous I/O", "text": ["The total number (int) of expected bytes."]}, {"name": "asyncio.IncompleteReadError.partial", "path": "library/asyncio-exceptions#asyncio.IncompleteReadError.partial", "type": "Asynchronous I/O", "text": ["A string of bytes read before the end of stream was reached."]}, {"name": "asyncio.InvalidStateError", "path": "library/asyncio-exceptions#asyncio.InvalidStateError", "type": "Asynchronous I/O", "text": ["Invalid internal state of Task or Future.", "Can be raised in situations like setting a result value for a Future object that already has a result value set."]}, {"name": "asyncio.iscoroutine()", "path": "library/asyncio-task#asyncio.iscoroutine", "type": "Asynchronous I/O", "text": ["Return True if obj is a coroutine object.", "This method is different from inspect.iscoroutine() because it returns True for generator-based coroutines."]}, {"name": "asyncio.iscoroutinefunction()", "path": "library/asyncio-task#asyncio.iscoroutinefunction", "type": "Asynchronous I/O", "text": ["Return True if func is a coroutine function.", "This method is different from inspect.iscoroutinefunction() because it returns True for generator-based coroutine functions decorated with @coroutine."]}, {"name": "asyncio.isfuture()", "path": "library/asyncio-future#asyncio.isfuture", "type": "Asynchronous I/O", "text": ["Return True if obj is either of:", "New in version 3.5."]}, {"name": "asyncio.LifoQueue", "path": "library/asyncio-queue#asyncio.LifoQueue", "type": "Asynchronous I/O", "text": ["A variant of Queue that retrieves most recently added entries first (last in, first out)."]}, {"name": "asyncio.LimitOverrunError", "path": "library/asyncio-exceptions#asyncio.LimitOverrunError", "type": "Asynchronous I/O", "text": ["Reached the buffer size limit while looking for a separator.", "Raised by the asyncio stream APIs.", "The total number of to be consumed bytes."]}, {"name": "asyncio.LimitOverrunError.consumed", "path": "library/asyncio-exceptions#asyncio.LimitOverrunError.consumed", "type": "Asynchronous I/O", "text": ["The total number of to be consumed bytes."]}, {"name": "asyncio.Lock", "path": "library/asyncio-sync#asyncio.Lock", "type": "Asynchronous I/O", "text": ["Implements a mutex lock for asyncio tasks. Not thread-safe.", "An asyncio lock can be used to guarantee exclusive access to a shared resource.", "The preferred way to use a Lock is an async with statement:", "which is equivalent to:", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Acquire the lock.", "This method waits until the lock is unlocked, sets it to locked and returns True.", "When more than one coroutine is blocked in acquire() waiting for the lock to be unlocked, only one coroutine eventually proceeds.", "Acquiring a lock is fair: the coroutine that proceeds will be the first coroutine that started waiting on the lock.", "Release the lock.", "When the lock is locked, reset it to unlocked and return.", "If the lock is unlocked, a RuntimeError is raised.", "Return True if the lock is locked."]}, {"name": "asyncio.Lock.acquire()", "path": "library/asyncio-sync#asyncio.Lock.acquire", "type": "Asynchronous I/O", "text": ["Acquire the lock.", "This method waits until the lock is unlocked, sets it to locked and returns True.", "When more than one coroutine is blocked in acquire() waiting for the lock to be unlocked, only one coroutine eventually proceeds.", "Acquiring a lock is fair: the coroutine that proceeds will be the first coroutine that started waiting on the lock."]}, {"name": "asyncio.Lock.locked()", "path": "library/asyncio-sync#asyncio.Lock.locked", "type": "Asynchronous I/O", "text": ["Return True if the lock is locked."]}, {"name": "asyncio.Lock.release()", "path": "library/asyncio-sync#asyncio.Lock.release", "type": "Asynchronous I/O", "text": ["Release the lock.", "When the lock is locked, reset it to unlocked and return.", "If the lock is unlocked, a RuntimeError is raised."]}, {"name": "asyncio.loop.add_reader()", "path": "library/asyncio-eventloop#asyncio.loop.add_reader", "type": "Asynchronous I/O", "text": ["Start monitoring the fd file descriptor for read availability and invoke callback with the specified arguments once fd is available for reading."]}, {"name": "asyncio.loop.add_signal_handler()", "path": "library/asyncio-eventloop#asyncio.loop.add_signal_handler", "type": "Asynchronous I/O", "text": ["Set callback as the handler for the signum signal.", "The callback will be invoked by loop, along with other queued callbacks and runnable coroutines of that event loop. Unlike signal handlers registered using signal.signal(), a callback registered with this function is allowed to interact with the event loop.", "Raise ValueError if the signal number is invalid or uncatchable. Raise RuntimeError if there is a problem setting up the handler.", "Use functools.partial() to pass keyword arguments to callback.", "Like signal.signal(), this function must be invoked in the main thread."]}, {"name": "asyncio.loop.add_writer()", "path": "library/asyncio-eventloop#asyncio.loop.add_writer", "type": "Asynchronous I/O", "text": ["Start monitoring the fd file descriptor for write availability and invoke callback with the specified arguments once fd is available for writing.", "Use functools.partial() to pass keyword arguments to callback."]}, {"name": "asyncio.loop.call_at()", "path": "library/asyncio-eventloop#asyncio.loop.call_at", "type": "Asynchronous I/O", "text": ["Schedule callback to be called at the given absolute timestamp when (an int or a float), using the same time reference as loop.time().", "This method\u2019s behavior is the same as call_later().", "An instance of asyncio.TimerHandle is returned which can be used to cancel the callback.", "Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details.", "Changed in version 3.8: In Python 3.7 and earlier with the default event loop implementation, the difference between when and the current time could not exceed one day. This has been fixed in Python 3.8."]}, {"name": "asyncio.loop.call_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.call_exception_handler", "type": "Asynchronous I/O", "text": ["Call the current event loop exception handler.", "context is a dict object containing the following keys (new keys may be introduced in future Python versions):", "Note", "This method should not be overloaded in subclassed event loops. For custom exception handling, use the set_exception_handler() method."]}, {"name": "asyncio.loop.call_later()", "path": "library/asyncio-eventloop#asyncio.loop.call_later", "type": "Asynchronous I/O", "text": ["Schedule callback to be called after the given delay number of seconds (can be either an int or a float).", "An instance of asyncio.TimerHandle is returned which can be used to cancel the callback.", "callback will be called exactly once. If two callbacks are scheduled for exactly the same time, the order in which they are called is undefined.", "The optional positional args will be passed to the callback when it is called. If you want the callback to be called with keyword arguments use functools.partial().", "An optional keyword-only context argument allows specifying a custom contextvars.Context for the callback to run in. The current context is used when no context is provided.", "Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details.", "Changed in version 3.8: In Python 3.7 and earlier with the default event loop implementation, the delay could not exceed one day. This has been fixed in Python 3.8."]}, {"name": "asyncio.loop.call_soon()", "path": "library/asyncio-eventloop#asyncio.loop.call_soon", "type": "Asynchronous I/O", "text": ["Schedule the callback callback to be called with args arguments at the next iteration of the event loop.", "Callbacks are called in the order in which they are registered. Each callback will be called exactly once.", "An optional keyword-only context argument allows specifying a custom contextvars.Context for the callback to run in. The current context is used when no context is provided.", "An instance of asyncio.Handle is returned, which can be used later to cancel the callback.", "This method is not thread-safe."]}, {"name": "asyncio.loop.call_soon_threadsafe()", "path": "library/asyncio-eventloop#asyncio.loop.call_soon_threadsafe", "type": "Asynchronous I/O", "text": ["A thread-safe variant of call_soon(). Must be used to schedule callbacks from another thread.", "See the concurrency and multithreading section of the documentation."]}, {"name": "asyncio.loop.close()", "path": "library/asyncio-eventloop#asyncio.loop.close", "type": "Asynchronous I/O", "text": ["Close the event loop.", "The loop must not be running when this function is called. Any pending callbacks will be discarded.", "This method clears all queues and shuts down the executor, but does not wait for the executor to finish.", "This method is idempotent and irreversible. No other methods should be called after the event loop is closed."]}, {"name": "asyncio.loop.connect_accepted_socket()", "path": "library/asyncio-eventloop#asyncio.loop.connect_accepted_socket", "type": "Asynchronous I/O", "text": ["Wrap an already accepted connection into a transport/protocol pair.", "This method can be used by servers that accept connections outside of asyncio but that use asyncio to handle them.", "Parameters:", "Returns a (transport, protocol) pair.", "New in version 3.7: The ssl_handshake_timeout parameter.", "New in version 3.5.3."]}, {"name": "asyncio.loop.connect_read_pipe()", "path": "library/asyncio-eventloop#asyncio.loop.connect_read_pipe", "type": "Asynchronous I/O", "text": ["Register the read end of pipe in the event loop.", "protocol_factory must be a callable returning an asyncio protocol implementation.", "pipe is a file-like object.", "Return pair (transport, protocol), where transport supports the ReadTransport interface and protocol is an object instantiated by the protocol_factory.", "With SelectorEventLoop event loop, the pipe is set to non-blocking mode."]}, {"name": "asyncio.loop.connect_write_pipe()", "path": "library/asyncio-eventloop#asyncio.loop.connect_write_pipe", "type": "Asynchronous I/O", "text": ["Register the write end of pipe in the event loop.", "protocol_factory must be a callable returning an asyncio protocol implementation.", "pipe is file-like object.", "Return pair (transport, protocol), where transport supports WriteTransport interface and protocol is an object instantiated by the protocol_factory.", "With SelectorEventLoop event loop, the pipe is set to non-blocking mode."]}, {"name": "asyncio.loop.create_connection()", "path": "library/asyncio-eventloop#asyncio.loop.create_connection", "type": "Asynchronous I/O", "text": ["Open a streaming transport connection to a given address specified by host and port.", "The socket family can be either AF_INET or AF_INET6 depending on host (or the family argument, if provided).", "The socket type will be SOCK_STREAM.", "protocol_factory must be a callable returning an asyncio protocol implementation.", "This method will try to establish the connection in the background. When successful, it returns a (transport, protocol) pair.", "The chronological synopsis of the underlying operation is as follows:", "The created transport is an implementation-dependent bidirectional stream.", "Other arguments:", "ssl: if given and not false, a SSL/TLS transport is created (by default a plain TCP transport is created). If ssl is a ssl.SSLContext object, this context is used to create the transport; if ssl is True, a default context returned from ssl.create_default_context() is used.", "See also", "SSL/TLS security considerations", "New in version 3.8: Added the happy_eyeballs_delay and interleave parameters.", "Happy Eyeballs Algorithm: Success with Dual-Stack Hosts. When a server\u2019s IPv4 path and protocol are working, but the server\u2019s IPv6 path and protocol are not working, a dual-stack client application experiences significant connection delay compared to an IPv4-only client. This is undesirable because it causes the dual- stack client to have a worse user experience. This document specifies requirements for algorithms that reduce this user-visible delay and provides an algorithm.", "For more information: https://tools.ietf.org/html/rfc6555", "New in version 3.7: The ssl_handshake_timeout parameter.", "Changed in version 3.6: The socket option TCP_NODELAY is set by default for all TCP connections.", "Changed in version 3.5: Added support for SSL/TLS in ProactorEventLoop.", "See also", "The open_connection() function is a high-level alternative API. It returns a pair of (StreamReader, StreamWriter) that can be used directly in async/await code."]}, {"name": "asyncio.loop.create_datagram_endpoint()", "path": "library/asyncio-eventloop#asyncio.loop.create_datagram_endpoint", "type": "Asynchronous I/O", "text": ["Note", "The parameter reuse_address is no longer supported, as using SO_REUSEADDR poses a significant security concern for UDP. Explicitly passing reuse_address=True will raise an exception.", "When multiple processes with differing UIDs assign sockets to an identical UDP socket address with SO_REUSEADDR, incoming packets can become randomly distributed among the sockets.", "For supported platforms, reuse_port can be used as a replacement for similar functionality. With reuse_port, SO_REUSEPORT is used instead, which specifically prevents processes with differing UIDs from assigning sockets to the same socket address.", "Create a datagram connection.", "The socket family can be either AF_INET, AF_INET6, or AF_UNIX, depending on host (or the family argument, if provided).", "The socket type will be SOCK_DGRAM.", "protocol_factory must be a callable returning a protocol implementation.", "A tuple of (transport, protocol) is returned on success.", "Other arguments:", "See UDP echo client protocol and UDP echo server protocol examples.", "Changed in version 3.4.4: The family, proto, flags, reuse_address, reuse_port, *allow_broadcast, and sock parameters were added.", "Changed in version 3.8.1: The reuse_address parameter is no longer supported due to security concerns.", "Changed in version 3.8: Added support for Windows."]}, {"name": "asyncio.loop.create_future()", "path": "library/asyncio-eventloop#asyncio.loop.create_future", "type": "Asynchronous I/O", "text": ["Create an asyncio.Future object attached to the event loop.", "This is the preferred way to create Futures in asyncio. This lets third-party event loops provide alternative implementations of the Future object (with better performance or instrumentation).", "New in version 3.5.2."]}, {"name": "asyncio.loop.create_server()", "path": "library/asyncio-eventloop#asyncio.loop.create_server", "type": "Asynchronous I/O", "text": ["Create a TCP server (socket type SOCK_STREAM) listening on port of the host address.", "Returns a Server object.", "Arguments:", "The host parameter can be set to several types which determine where the server would be listening:", "New in version 3.7: Added ssl_handshake_timeout and start_serving parameters.", "Changed in version 3.6: The socket option TCP_NODELAY is set by default for all TCP connections.", "Changed in version 3.5: Added support for SSL/TLS in ProactorEventLoop.", "Changed in version 3.5.1: The host parameter can be a sequence of strings.", "See also", "The start_server() function is a higher-level alternative API that returns a pair of StreamReader and StreamWriter that can be used in an async/await code."]}, {"name": "asyncio.loop.create_task()", "path": "library/asyncio-eventloop#asyncio.loop.create_task", "type": "Asynchronous I/O", "text": ["Schedule the execution of a Coroutines. Return a Task object.", "Third-party event loops can use their own subclass of Task for interoperability. In this case, the result type is a subclass of Task.", "If the name argument is provided and not None, it is set as the name of the task using Task.set_name().", "Changed in version 3.8: Added the name parameter."]}, {"name": "asyncio.loop.create_unix_connection()", "path": "library/asyncio-eventloop#asyncio.loop.create_unix_connection", "type": "Asynchronous I/O", "text": ["Create a Unix connection.", "The socket family will be AF_UNIX; socket type will be SOCK_STREAM.", "A tuple of (transport, protocol) is returned on success.", "path is the name of a Unix domain socket and is required, unless a sock parameter is specified. Abstract Unix sockets, str, bytes, and Path paths are supported.", "See the documentation of the loop.create_connection() method for information about arguments to this method.", "Availability: Unix.", "New in version 3.7: The ssl_handshake_timeout parameter.", "Changed in version 3.7: The path parameter can now be a path-like object."]}, {"name": "asyncio.loop.create_unix_server()", "path": "library/asyncio-eventloop#asyncio.loop.create_unix_server", "type": "Asynchronous I/O", "text": ["Similar to loop.create_server() but works with the AF_UNIX socket family.", "path is the name of a Unix domain socket, and is required, unless a sock argument is provided. Abstract Unix sockets, str, bytes, and Path paths are supported.", "See the documentation of the loop.create_server() method for information about arguments to this method.", "Availability: Unix.", "New in version 3.7: The ssl_handshake_timeout and start_serving parameters.", "Changed in version 3.7: The path parameter can now be a Path object."]}, {"name": "asyncio.loop.default_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.default_exception_handler", "type": "Asynchronous I/O", "text": ["Default exception handler.", "This is called when an exception occurs and no exception handler is set. This can be called by a custom exception handler that wants to defer to the default handler behavior.", "context parameter has the same meaning as in call_exception_handler()."]}, {"name": "asyncio.loop.getaddrinfo()", "path": "library/asyncio-eventloop#asyncio.loop.getaddrinfo", "type": "Asynchronous I/O", "text": ["Asynchronous version of socket.getaddrinfo()."]}, {"name": "asyncio.loop.getnameinfo()", "path": "library/asyncio-eventloop#asyncio.loop.getnameinfo", "type": "Asynchronous I/O", "text": ["Asynchronous version of socket.getnameinfo()."]}, {"name": "asyncio.loop.get_debug()", "path": "library/asyncio-eventloop#asyncio.loop.get_debug", "type": "Asynchronous I/O", "text": ["Get the debug mode (bool) of the event loop.", "The default value is True if the environment variable PYTHONASYNCIODEBUG is set to a non-empty string, False otherwise."]}, {"name": "asyncio.loop.get_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.get_exception_handler", "type": "Asynchronous I/O", "text": ["Return the current exception handler, or None if no custom exception handler was set.", "New in version 3.5.2."]}, {"name": "asyncio.loop.get_task_factory()", "path": "library/asyncio-eventloop#asyncio.loop.get_task_factory", "type": "Asynchronous I/O", "text": ["Return a task factory or None if the default one is in use."]}, {"name": "asyncio.loop.is_closed()", "path": "library/asyncio-eventloop#asyncio.loop.is_closed", "type": "Asynchronous I/O", "text": ["Return True if the event loop was closed."]}, {"name": "asyncio.loop.is_running()", "path": "library/asyncio-eventloop#asyncio.loop.is_running", "type": "Asynchronous I/O", "text": ["Return True if the event loop is currently running."]}, {"name": "asyncio.loop.remove_reader()", "path": "library/asyncio-eventloop#asyncio.loop.remove_reader", "type": "Asynchronous I/O", "text": ["Stop monitoring the fd file descriptor for read availability."]}, {"name": "asyncio.loop.remove_signal_handler()", "path": "library/asyncio-eventloop#asyncio.loop.remove_signal_handler", "type": "Asynchronous I/O", "text": ["Remove the handler for the sig signal.", "Return True if the signal handler was removed, or False if no handler was set for the given signal.", "Availability: Unix."]}, {"name": "asyncio.loop.remove_writer()", "path": "library/asyncio-eventloop#asyncio.loop.remove_writer", "type": "Asynchronous I/O", "text": ["Stop monitoring the fd file descriptor for write availability."]}, {"name": "asyncio.loop.run_forever()", "path": "library/asyncio-eventloop#asyncio.loop.run_forever", "type": "Asynchronous I/O", "text": ["Run the event loop until stop() is called.", "If stop() is called before run_forever() is called, the loop will poll the I/O selector once with a timeout of zero, run all callbacks scheduled in response to I/O events (and those that were already scheduled), and then exit.", "If stop() is called while run_forever() is running, the loop will run the current batch of callbacks and then exit. Note that new callbacks scheduled by callbacks will not run in this case; instead, they will run the next time run_forever() or run_until_complete() is called."]}, {"name": "asyncio.loop.run_in_executor()", "path": "library/asyncio-eventloop#asyncio.loop.run_in_executor", "type": "Asynchronous I/O", "text": ["Arrange for func to be called in the specified executor.", "The executor argument should be an concurrent.futures.Executor instance. The default executor is used if executor is None.", "Example:", "This method returns a asyncio.Future object.", "Use functools.partial() to pass keyword arguments to func.", "Changed in version 3.5.3: loop.run_in_executor() no longer configures the max_workers of the thread pool executor it creates, instead leaving it up to the thread pool executor (ThreadPoolExecutor) to set the default."]}, {"name": "asyncio.loop.run_until_complete()", "path": "library/asyncio-eventloop#asyncio.loop.run_until_complete", "type": "Asynchronous I/O", "text": ["Run until the future (an instance of Future) has completed.", "If the argument is a coroutine object it is implicitly scheduled to run as a asyncio.Task.", "Return the Future\u2019s result or raise its exception."]}, {"name": "asyncio.loop.sendfile()", "path": "library/asyncio-eventloop#asyncio.loop.sendfile", "type": "Asynchronous I/O", "text": ["Send a file over a transport. Return the total number of bytes sent.", "The method uses high-performance os.sendfile() if available.", "file must be a regular file object opened in binary mode.", "offset tells from where to start reading the file. If specified, count is the total number of bytes to transmit as opposed to sending the file until EOF is reached. File position is always updated, even when this method raises an error, and file.tell() can be used to obtain the actual number of bytes sent.", "fallback set to True makes asyncio to manually read and send the file when the platform does not support the sendfile system call (e.g. Windows or SSL socket on Unix).", "Raise SendfileNotAvailableError if the system does not support the sendfile syscall and fallback is False.", "New in version 3.7."]}, {"name": "asyncio.loop.set_debug()", "path": "library/asyncio-eventloop#asyncio.loop.set_debug", "type": "Asynchronous I/O", "text": ["Set the debug mode of the event loop.", "Changed in version 3.7: The new Python Development Mode can now also be used to enable the debug mode."]}, {"name": "asyncio.loop.set_default_executor()", "path": "library/asyncio-eventloop#asyncio.loop.set_default_executor", "type": "Asynchronous I/O", "text": ["Set executor as the default executor used by run_in_executor(). executor should be an instance of ThreadPoolExecutor.", "Deprecated since version 3.8: Using an executor that is not an instance of ThreadPoolExecutor is deprecated and will trigger an error in Python 3.9.", "executor must be an instance of concurrent.futures.ThreadPoolExecutor."]}, {"name": "asyncio.loop.set_exception_handler()", "path": "library/asyncio-eventloop#asyncio.loop.set_exception_handler", "type": "Asynchronous I/O", "text": ["Set handler as the new event loop exception handler.", "If handler is None, the default exception handler will be set. Otherwise, handler must be a callable with the signature matching (loop, context), where loop is a reference to the active event loop, and context is a dict object containing the details of the exception (see call_exception_handler() documentation for details about context)."]}, {"name": "asyncio.loop.set_task_factory()", "path": "library/asyncio-eventloop#asyncio.loop.set_task_factory", "type": "Asynchronous I/O", "text": ["Set a task factory that will be used by loop.create_task().", "If factory is None the default task factory will be set. Otherwise, factory must be a callable with the signature matching (loop, coro), where loop is a reference to the active event loop, and coro is a coroutine object. The callable must return a asyncio.Future-compatible object."]}, {"name": "asyncio.loop.shutdown_asyncgens()", "path": "library/asyncio-eventloop#asyncio.loop.shutdown_asyncgens", "type": "Asynchronous I/O", "text": ["Schedule all currently open asynchronous generator objects to close with an aclose() call. After calling this method, the event loop will issue a warning if a new asynchronous generator is iterated. This should be used to reliably finalize all scheduled asynchronous generators.", "Note that there is no need to call this function when asyncio.run() is used.", "Example:", "New in version 3.6."]}, {"name": "asyncio.loop.shutdown_default_executor()", "path": "library/asyncio-eventloop#asyncio.loop.shutdown_default_executor", "type": "Asynchronous I/O", "text": ["Schedule the closure of the default executor and wait for it to join all of the threads in the ThreadPoolExecutor. After calling this method, a RuntimeError will be raised if loop.run_in_executor() is called while using the default executor.", "Note that there is no need to call this function when asyncio.run() is used.", "New in version 3.9."]}, {"name": "asyncio.loop.sock_accept()", "path": "library/asyncio-eventloop#asyncio.loop.sock_accept", "type": "Asynchronous I/O", "text": ["Accept a connection. Modeled after the blocking socket.accept() method.", "The socket must be bound to an address and listening for connections. The return value is a pair (conn, address) where conn is a new socket object usable to send and receive data on the connection, and address is the address bound to the socket on the other end of the connection.", "sock must be a non-blocking socket.", "Changed in version 3.7: Even though the method was always documented as a coroutine method, before Python 3.7 it returned a Future. Since Python 3.7, this is an async def method.", "See also", "loop.create_server() and start_server()."]}, {"name": "asyncio.loop.sock_connect()", "path": "library/asyncio-eventloop#asyncio.loop.sock_connect", "type": "Asynchronous I/O", "text": ["Connect sock to a remote socket at address.", "Asynchronous version of socket.connect().", "sock must be a non-blocking socket.", "Changed in version 3.5.2: address no longer needs to be resolved. sock_connect will try to check if the address is already resolved by calling socket.inet_pton(). If not, loop.getaddrinfo() will be used to resolve the address.", "See also", "loop.create_connection() and asyncio.open_connection()."]}, {"name": "asyncio.loop.sock_recv()", "path": "library/asyncio-eventloop#asyncio.loop.sock_recv", "type": "Asynchronous I/O", "text": ["Receive up to nbytes from sock. Asynchronous version of socket.recv().", "Return the received data as a bytes object.", "sock must be a non-blocking socket.", "Changed in version 3.7: Even though this method was always documented as a coroutine method, releases before Python 3.7 returned a Future. Since Python 3.7 this is an async def method."]}, {"name": "asyncio.loop.sock_recv_into()", "path": "library/asyncio-eventloop#asyncio.loop.sock_recv_into", "type": "Asynchronous I/O", "text": ["Receive data from sock into the buf buffer. Modeled after the blocking socket.recv_into() method.", "Return the number of bytes written to the buffer.", "sock must be a non-blocking socket.", "New in version 3.7."]}, {"name": "asyncio.loop.sock_sendall()", "path": "library/asyncio-eventloop#asyncio.loop.sock_sendall", "type": "Asynchronous I/O", "text": ["Send data to the sock socket. Asynchronous version of socket.sendall().", "This method continues to send to the socket until either all data in data has been sent or an error occurs. None is returned on success. On error, an exception is raised. Additionally, there is no way to determine how much data, if any, was successfully processed by the receiving end of the connection.", "sock must be a non-blocking socket.", "Changed in version 3.7: Even though the method was always documented as a coroutine method, before Python 3.7 it returned an Future. Since Python 3.7, this is an async def method."]}, {"name": "asyncio.loop.sock_sendfile()", "path": "library/asyncio-eventloop#asyncio.loop.sock_sendfile", "type": "Asynchronous I/O", "text": ["Send a file using high-performance os.sendfile if possible. Return the total number of bytes sent.", "Asynchronous version of socket.sendfile().", "sock must be a non-blocking socket.SOCK_STREAM socket.", "file must be a regular file object open in binary mode.", "offset tells from where to start reading the file. If specified, count is the total number of bytes to transmit as opposed to sending the file until EOF is reached. File position is always updated, even when this method raises an error, and file.tell() can be used to obtain the actual number of bytes sent.", "fallback, when set to True, makes asyncio manually read and send the file when the platform does not support the sendfile syscall (e.g. Windows or SSL socket on Unix).", "Raise SendfileNotAvailableError if the system does not support sendfile syscall and fallback is False.", "sock must be a non-blocking socket.", "New in version 3.7."]}, {"name": "asyncio.loop.start_tls()", "path": "library/asyncio-eventloop#asyncio.loop.start_tls", "type": "Asynchronous I/O", "text": ["Upgrade an existing transport-based connection to TLS.", "Return a new transport instance, that the protocol must start using immediately after the await. The transport instance passed to the start_tls method should never be used again.", "Parameters:", "New in version 3.7."]}, {"name": "asyncio.loop.stop()", "path": "library/asyncio-eventloop#asyncio.loop.stop", "type": "Asynchronous I/O", "text": ["Stop the event loop."]}, {"name": "asyncio.loop.subprocess_exec()", "path": "library/asyncio-eventloop#asyncio.loop.subprocess_exec", "type": "Asynchronous I/O", "text": ["Create a subprocess from one or more string arguments specified by args.", "args must be a list of strings represented by:", "The first string specifies the program executable, and the remaining strings specify the arguments. Together, string arguments form the argv of the program.", "This is similar to the standard library subprocess.Popen class called with shell=False and the list of strings passed as the first argument; however, where Popen takes a single argument which is list of strings, subprocess_exec takes multiple string arguments.", "The protocol_factory must be a callable returning a subclass of the asyncio.SubprocessProtocol class.", "Other parameters:", "stdin can be any of these:", "stdout can be any of these:", "stderr can be any of these:", "All other keyword arguments are passed to subprocess.Popen without interpretation, except for bufsize, universal_newlines, shell, text, encoding and errors, which should not be specified at all.", "The asyncio subprocess API does not support decoding the streams as text. bytes.decode() can be used to convert the bytes returned from the stream to text.", "See the constructor of the subprocess.Popen class for documentation on other arguments.", "Returns a pair of (transport, protocol), where transport conforms to the asyncio.SubprocessTransport base class and protocol is an object instantiated by the protocol_factory."]}, {"name": "asyncio.loop.subprocess_shell()", "path": "library/asyncio-eventloop#asyncio.loop.subprocess_shell", "type": "Asynchronous I/O", "text": ["Create a subprocess from cmd, which can be a str or a bytes string encoded to the filesystem encoding, using the platform\u2019s \u201cshell\u201d syntax.", "This is similar to the standard library subprocess.Popen class called with shell=True.", "The protocol_factory must be a callable returning a subclass of the SubprocessProtocol class.", "See subprocess_exec() for more details about the remaining arguments.", "Returns a pair of (transport, protocol), where transport conforms to the SubprocessTransport base class and protocol is an object instantiated by the protocol_factory."]}, {"name": "asyncio.loop.time()", "path": "library/asyncio-eventloop#asyncio.loop.time", "type": "Asynchronous I/O", "text": ["Return the current time, as a float value, according to the event loop\u2019s internal monotonic clock."]}, {"name": "asyncio.MultiLoopChildWatcher", "path": "library/asyncio-policy#asyncio.MultiLoopChildWatcher", "type": "Asynchronous I/O", "text": ["This implementation registers a SIGCHLD signal handler on instantiation. That can break third-party code that installs a custom handler for SIGCHLD signal.", "The watcher avoids disrupting other code spawning processes by polling every process explicitly on a SIGCHLD signal.", "There is no limitation for running subprocesses from different threads once the watcher is installed.", "The solution is safe but it has a significant overhead when handling a big number of processes (O(n) each time a SIGCHLD is received).", "New in version 3.8."]}, {"name": "asyncio.new_event_loop()", "path": "library/asyncio-eventloop#asyncio.new_event_loop", "type": "Asynchronous I/O", "text": ["Create a new event loop object."]}, {"name": "asyncio.open_connection()", "path": "library/asyncio-stream#asyncio.open_connection", "type": "Asynchronous I/O", "text": ["Establish a network connection and return a pair of (reader, writer) objects.", "The returned reader and writer objects are instances of StreamReader and StreamWriter classes.", "The loop argument is optional and can always be determined automatically when this function is awaited from a coroutine.", "limit determines the buffer size limit used by the returned StreamReader instance. By default the limit is set to 64 KiB.", "The rest of the arguments are passed directly to loop.create_connection().", "New in version 3.7: The ssl_handshake_timeout parameter."]}, {"name": "asyncio.open_unix_connection()", "path": "library/asyncio-stream#asyncio.open_unix_connection", "type": "Asynchronous I/O", "text": ["Establish a Unix socket connection and return a pair of (reader, writer).", "Similar to open_connection() but operates on Unix sockets.", "See also the documentation of loop.create_unix_connection().", "Availability: Unix.", "New in version 3.7: The ssl_handshake_timeout parameter.", "Changed in version 3.7: The path parameter can now be a path-like object"]}, {"name": "asyncio.PidfdChildWatcher", "path": "library/asyncio-policy#asyncio.PidfdChildWatcher", "type": "Asynchronous I/O", "text": ["This implementation polls process file descriptors (pidfds) to await child process termination. In some respects, PidfdChildWatcher is a \u201cGoldilocks\u201d child watcher implementation. It doesn\u2019t require signals or threads, doesn\u2019t interfere with any processes launched outside the event loop, and scales linearly with the number of subprocesses launched by the event loop. The main disadvantage is that pidfds are specific to Linux, and only work on recent (5.3+) kernels.", "New in version 3.9."]}, {"name": "asyncio.PriorityQueue", "path": "library/asyncio-queue#asyncio.PriorityQueue", "type": "Asynchronous I/O", "text": ["A variant of Queue; retrieves entries in priority order (lowest first).", "Entries are typically tuples of the form (priority_number, data)."]}, {"name": "asyncio.ProactorEventLoop", "path": "library/asyncio-eventloop#asyncio.ProactorEventLoop", "type": "Asynchronous I/O", "text": ["An event loop for Windows that uses \u201cI/O Completion Ports\u201d (IOCP).", "Availability: Windows.", "See also", "MSDN documentation on I/O Completion Ports."]}, {"name": "asyncio.Protocol", "path": "library/asyncio-protocol#asyncio.Protocol", "type": "Asynchronous I/O", "text": ["The base class for implementing streaming protocols (TCP, Unix sockets, etc)."]}, {"name": "asyncio.Protocol.data_received()", "path": "library/asyncio-protocol#asyncio.Protocol.data_received", "type": "Asynchronous I/O", "text": ["Called when some data is received. data is a non-empty bytes object containing the incoming data.", "Whether the data is buffered, chunked or reassembled depends on the transport. In general, you shouldn\u2019t rely on specific semantics and instead make your parsing generic and flexible. However, data is always received in the correct order.", "The method can be called an arbitrary number of times while a connection is open.", "However, protocol.eof_received() is called at most once. Once eof_received() is called, data_received() is not called anymore."]}, {"name": "asyncio.Protocol.eof_received()", "path": "library/asyncio-protocol#asyncio.Protocol.eof_received", "type": "Asynchronous I/O", "text": ["Called when the other end signals it won\u2019t send any more data (for example by calling transport.write_eof(), if the other end also uses asyncio).", "This method may return a false value (including None), in which case the transport will close itself. Conversely, if this method returns a true value, the protocol used determines whether to close the transport. Since the default implementation returns None, it implicitly closes the connection.", "Some transports, including SSL, don\u2019t support half-closed connections, in which case returning true from this method will result in the connection being closed."]}, {"name": "asyncio.Queue", "path": "library/asyncio-queue#asyncio.Queue", "type": "Asynchronous I/O", "text": ["A first in, first out (FIFO) queue.", "If maxsize is less than or equal to zero, the queue size is infinite. If it is an integer greater than 0, then await put() blocks when the queue reaches maxsize until an item is removed by get().", "Unlike the standard library threading queue, the size of the queue is always known and can be returned by calling the qsize() method.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "This class is not thread safe.", "Number of items allowed in the queue.", "Return True if the queue is empty, False otherwise.", "Return True if there are maxsize items in the queue.", "If the queue was initialized with maxsize=0 (the default), then full() never returns True.", "Remove and return an item from the queue. If queue is empty, wait until an item is available.", "Return an item if one is immediately available, else raise QueueEmpty.", "Block until all items in the queue have been received and processed.", "The count of unfinished tasks goes up whenever an item is added to the queue. The count goes down whenever a consumer coroutine calls task_done() to indicate that the item was retrieved and all work on it is complete. When the count of unfinished tasks drops to zero, join() unblocks.", "Put an item into the queue. If the queue is full, wait until a free slot is available before adding the item.", "Put an item into the queue without blocking.", "If no free slot is immediately available, raise QueueFull.", "Return the number of items in the queue.", "Indicate that a formerly enqueued task is complete.", "Used by queue consumers. For each get() used to fetch a task, a subsequent call to task_done() tells the queue that the processing on the task is complete.", "If a join() is currently blocking, it will resume when all items have been processed (meaning that a task_done() call was received for every item that had been put() into the queue).", "Raises ValueError if called more times than there were items placed in the queue."]}, {"name": "asyncio.Queue.empty()", "path": "library/asyncio-queue#asyncio.Queue.empty", "type": "Asynchronous I/O", "text": ["Return True if the queue is empty, False otherwise."]}, {"name": "asyncio.Queue.full()", "path": "library/asyncio-queue#asyncio.Queue.full", "type": "Asynchronous I/O", "text": ["Return True if there are maxsize items in the queue.", "If the queue was initialized with maxsize=0 (the default), then full() never returns True."]}, {"name": "asyncio.Queue.get()", "path": "library/asyncio-queue#asyncio.Queue.get", "type": "Asynchronous I/O", "text": ["Remove and return an item from the queue. If queue is empty, wait until an item is available."]}, {"name": "asyncio.Queue.get_nowait()", "path": "library/asyncio-queue#asyncio.Queue.get_nowait", "type": "Asynchronous I/O", "text": ["Return an item if one is immediately available, else raise QueueEmpty."]}, {"name": "asyncio.Queue.join()", "path": "library/asyncio-queue#asyncio.Queue.join", "type": "Asynchronous I/O", "text": ["Block until all items in the queue have been received and processed.", "The count of unfinished tasks goes up whenever an item is added to the queue. The count goes down whenever a consumer coroutine calls task_done() to indicate that the item was retrieved and all work on it is complete. When the count of unfinished tasks drops to zero, join() unblocks."]}, {"name": "asyncio.Queue.maxsize", "path": "library/asyncio-queue#asyncio.Queue.maxsize", "type": "Asynchronous I/O", "text": ["Number of items allowed in the queue."]}, {"name": "asyncio.Queue.put()", "path": "library/asyncio-queue#asyncio.Queue.put", "type": "Asynchronous I/O", "text": ["Put an item into the queue. If the queue is full, wait until a free slot is available before adding the item."]}, {"name": "asyncio.Queue.put_nowait()", "path": "library/asyncio-queue#asyncio.Queue.put_nowait", "type": "Asynchronous I/O", "text": ["Put an item into the queue without blocking.", "If no free slot is immediately available, raise QueueFull."]}, {"name": "asyncio.Queue.qsize()", "path": "library/asyncio-queue#asyncio.Queue.qsize", "type": "Asynchronous I/O", "text": ["Return the number of items in the queue."]}, {"name": "asyncio.Queue.task_done()", "path": "library/asyncio-queue#asyncio.Queue.task_done", "type": "Asynchronous I/O", "text": ["Indicate that a formerly enqueued task is complete.", "Used by queue consumers. For each get() used to fetch a task, a subsequent call to task_done() tells the queue that the processing on the task is complete.", "If a join() is currently blocking, it will resume when all items have been processed (meaning that a task_done() call was received for every item that had been put() into the queue).", "Raises ValueError if called more times than there were items placed in the queue."]}, {"name": "asyncio.QueueEmpty", "path": "library/asyncio-queue#asyncio.QueueEmpty", "type": "Asynchronous I/O", "text": ["This exception is raised when the get_nowait() method is called on an empty queue."]}, {"name": "asyncio.QueueFull", "path": "library/asyncio-queue#asyncio.QueueFull", "type": "Asynchronous I/O", "text": ["Exception raised when the put_nowait() method is called on a queue that has reached its maxsize."]}, {"name": "asyncio.ReadTransport", "path": "library/asyncio-protocol#asyncio.ReadTransport", "type": "Asynchronous I/O", "text": ["A base transport for read-only connections.", "Instances of the ReadTransport class are returned from the loop.connect_read_pipe() event loop method and are also used by subprocess-related methods like loop.subprocess_exec()."]}, {"name": "asyncio.ReadTransport.is_reading()", "path": "library/asyncio-protocol#asyncio.ReadTransport.is_reading", "type": "Asynchronous I/O", "text": ["Return True if the transport is receiving new data.", "New in version 3.7."]}, {"name": "asyncio.ReadTransport.pause_reading()", "path": "library/asyncio-protocol#asyncio.ReadTransport.pause_reading", "type": "Asynchronous I/O", "text": ["Pause the receiving end of the transport. No data will be passed to the protocol\u2019s protocol.data_received() method until resume_reading() is called.", "Changed in version 3.7: The method is idempotent, i.e. it can be called when the transport is already paused or closed."]}, {"name": "asyncio.ReadTransport.resume_reading()", "path": "library/asyncio-protocol#asyncio.ReadTransport.resume_reading", "type": "Asynchronous I/O", "text": ["Resume the receiving end. The protocol\u2019s protocol.data_received() method will be called once again if some data is available for reading.", "Changed in version 3.7: The method is idempotent, i.e. it can be called when the transport is already reading."]}, {"name": "asyncio.run()", "path": "library/asyncio-task#asyncio.run", "type": "Asynchronous I/O", "text": ["Execute the coroutine coro and return the result.", "This function runs the passed coroutine, taking care of managing the asyncio event loop, finalizing asynchronous generators, and closing the threadpool.", "This function cannot be called when another asyncio event loop is running in the same thread.", "If debug is True, the event loop will be run in debug mode.", "This function always creates a new event loop and closes it at the end. It should be used as a main entry point for asyncio programs, and should ideally only be called once.", "Example:", "New in version 3.7.", "Changed in version 3.9: Updated to use loop.shutdown_default_executor().", "Note", "The source code for asyncio.run() can be found in Lib/asyncio/runners.py."]}, {"name": "asyncio.run_coroutine_threadsafe()", "path": "library/asyncio-task#asyncio.run_coroutine_threadsafe", "type": "Asynchronous I/O", "text": ["Submit a coroutine to the given event loop. Thread-safe.", "Return a concurrent.futures.Future to wait for the result from another OS thread.", "This function is meant to be called from a different OS thread than the one where the event loop is running. Example:", "If an exception is raised in the coroutine, the returned Future will be notified. It can also be used to cancel the task in the event loop:", "See the concurrency and multithreading section of the documentation.", "Unlike other asyncio functions this function requires the loop argument to be passed explicitly.", "New in version 3.5.1."]}, {"name": "asyncio.SafeChildWatcher", "path": "library/asyncio-policy#asyncio.SafeChildWatcher", "type": "Asynchronous I/O", "text": ["This implementation uses active event loop from the main thread to handle SIGCHLD signal. If the main thread has no running event loop another thread cannot spawn a subprocess (RuntimeError is raised).", "The watcher avoids disrupting other code spawning processes by polling every process explicitly on a SIGCHLD signal.", "This solution is as safe as MultiLoopChildWatcher and has the same O(N) complexity but requires a running event loop in the main thread to work."]}, {"name": "asyncio.SelectorEventLoop", "path": "library/asyncio-eventloop#asyncio.SelectorEventLoop", "type": "Asynchronous I/O", "text": ["An event loop based on the selectors module.", "Uses the most efficient selector available for the given platform. It is also possible to manually configure the exact selector implementation to be used:", "Availability: Unix, Windows."]}, {"name": "asyncio.Semaphore", "path": "library/asyncio-sync#asyncio.Semaphore", "type": "Asynchronous I/O", "text": ["A Semaphore object. Not thread-safe.", "A semaphore manages an internal counter which is decremented by each acquire() call and incremented by each release() call. The counter can never go below zero; when acquire() finds that it is zero, it blocks, waiting until some task calls release().", "The optional value argument gives the initial value for the internal counter (1 by default). If the given value is less than 0 a ValueError is raised.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "The preferred way to use a Semaphore is an async with statement:", "which is equivalent to:", "Acquire a semaphore.", "If the internal counter is greater than zero, decrement it by one and return True immediately. If it is zero, wait until a release() is called and return True.", "Returns True if semaphore can not be acquired immediately.", "Release a semaphore, incrementing the internal counter by one. Can wake up a task waiting to acquire the semaphore.", "Unlike BoundedSemaphore, Semaphore allows making more release() calls than acquire() calls."]}, {"name": "asyncio.Semaphore.acquire()", "path": "library/asyncio-sync#asyncio.Semaphore.acquire", "type": "Asynchronous I/O", "text": ["Acquire a semaphore.", "If the internal counter is greater than zero, decrement it by one and return True immediately. If it is zero, wait until a release() is called and return True."]}, {"name": "asyncio.Semaphore.locked()", "path": "library/asyncio-sync#asyncio.Semaphore.locked", "type": "Asynchronous I/O", "text": ["Returns True if semaphore can not be acquired immediately."]}, {"name": "asyncio.Semaphore.release()", "path": "library/asyncio-sync#asyncio.Semaphore.release", "type": "Asynchronous I/O", "text": ["Release a semaphore, incrementing the internal counter by one. Can wake up a task waiting to acquire the semaphore.", "Unlike BoundedSemaphore, Semaphore allows making more release() calls than acquire() calls."]}, {"name": "asyncio.SendfileNotAvailableError", "path": "library/asyncio-exceptions#asyncio.SendfileNotAvailableError", "type": "Asynchronous I/O", "text": ["The \u201csendfile\u201d syscall is not available for the given socket or file type.", "A subclass of RuntimeError."]}, {"name": "asyncio.Server", "path": "library/asyncio-eventloop#asyncio.Server", "type": "Asynchronous I/O", "text": ["Server objects are asynchronous context managers. When used in an async with statement, it\u2019s guaranteed that the Server object is closed and not accepting new connections when the async with statement is completed:", "Changed in version 3.7: Server object is an asynchronous context manager since Python 3.7.", "Stop serving: close listening sockets and set the sockets attribute to None.", "The sockets that represent existing incoming client connections are left open.", "The server is closed asynchronously, use the wait_closed() coroutine to wait until the server is closed.", "Return the event loop associated with the server object.", "New in version 3.7.", "Start accepting connections.", "This method is idempotent, so it can be called when the server is already being serving.", "The start_serving keyword-only parameter to loop.create_server() and asyncio.start_server() allows creating a Server object that is not accepting connections initially. In this case Server.start_serving(), or Server.serve_forever() can be used to make the Server start accepting connections.", "New in version 3.7.", "Start accepting connections until the coroutine is cancelled. Cancellation of serve_forever task causes the server to be closed.", "This method can be called if the server is already accepting connections. Only one serve_forever task can exist per one Server object.", "Example:", "New in version 3.7.", "Return True if the server is accepting new connections.", "New in version 3.7.", "Wait until the close() method completes.", "List of socket.socket objects the server is listening on.", "Changed in version 3.7: Prior to Python 3.7 Server.sockets used to return an internal list of server sockets directly. In 3.7 a copy of that list is returned."]}, {"name": "asyncio.Server.close()", "path": "library/asyncio-eventloop#asyncio.Server.close", "type": "Asynchronous I/O", "text": ["Stop serving: close listening sockets and set the sockets attribute to None.", "The sockets that represent existing incoming client connections are left open.", "The server is closed asynchronously, use the wait_closed() coroutine to wait until the server is closed."]}, {"name": "asyncio.Server.get_loop()", "path": "library/asyncio-eventloop#asyncio.Server.get_loop", "type": "Asynchronous I/O", "text": ["Return the event loop associated with the server object.", "New in version 3.7."]}, {"name": "asyncio.Server.is_serving()", "path": "library/asyncio-eventloop#asyncio.Server.is_serving", "type": "Asynchronous I/O", "text": ["Return True if the server is accepting new connections.", "New in version 3.7."]}, {"name": "asyncio.Server.serve_forever()", "path": "library/asyncio-eventloop#asyncio.Server.serve_forever", "type": "Asynchronous I/O", "text": ["Start accepting connections until the coroutine is cancelled. Cancellation of serve_forever task causes the server to be closed.", "This method can be called if the server is already accepting connections. Only one serve_forever task can exist per one Server object.", "Example:", "New in version 3.7."]}, {"name": "asyncio.Server.sockets", "path": "library/asyncio-eventloop#asyncio.Server.sockets", "type": "Asynchronous I/O", "text": ["List of socket.socket objects the server is listening on.", "Changed in version 3.7: Prior to Python 3.7 Server.sockets used to return an internal list of server sockets directly. In 3.7 a copy of that list is returned."]}, {"name": "asyncio.Server.start_serving()", "path": "library/asyncio-eventloop#asyncio.Server.start_serving", "type": "Asynchronous I/O", "text": ["Start accepting connections.", "This method is idempotent, so it can be called when the server is already being serving.", "The start_serving keyword-only parameter to loop.create_server() and asyncio.start_server() allows creating a Server object that is not accepting connections initially. In this case Server.start_serving(), or Server.serve_forever() can be used to make the Server start accepting connections.", "New in version 3.7."]}, {"name": "asyncio.Server.wait_closed()", "path": "library/asyncio-eventloop#asyncio.Server.wait_closed", "type": "Asynchronous I/O", "text": ["Wait until the close() method completes."]}, {"name": "asyncio.set_child_watcher()", "path": "library/asyncio-policy#asyncio.set_child_watcher", "type": "Asynchronous I/O", "text": ["Set the current child watcher to watcher for the current policy. watcher must implement methods defined in the AbstractChildWatcher base class."]}, {"name": "asyncio.set_event_loop()", "path": "library/asyncio-eventloop#asyncio.set_event_loop", "type": "Asynchronous I/O", "text": ["Set loop as a current event loop for the current OS thread."]}, {"name": "asyncio.set_event_loop_policy()", "path": "library/asyncio-policy#asyncio.set_event_loop_policy", "type": "Asynchronous I/O", "text": ["Set the current process-wide policy to policy.", "If policy is set to None, the default policy is restored."]}, {"name": "asyncio.shield()", "path": "library/asyncio-task#asyncio.shield", "type": "Asynchronous I/O", "text": ["Protect an awaitable object from being cancelled.", "If aw is a coroutine it is automatically scheduled as a Task.", "The statement:", "is equivalent to:", "except that if the coroutine containing it is cancelled, the Task running in something() is not cancelled. From the point of view of something(), the cancellation did not happen. Although its caller is still cancelled, so the \u201cawait\u201d expression still raises a CancelledError.", "If something() is cancelled by other means (i.e. from within itself) that would also cancel shield().", "If it is desired to completely ignore cancellation (not recommended) the shield() function should be combined with a try/except clause, as follows:", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter."]}, {"name": "asyncio.sleep()", "path": "library/asyncio-task#asyncio.sleep", "type": "Asynchronous I/O", "text": ["Block for delay seconds.", "If result is provided, it is returned to the caller when the coroutine completes.", "sleep() always suspends the current task, allowing other tasks to run.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example of coroutine displaying the current date every second for 5 seconds:"]}, {"name": "asyncio.start_server()", "path": "library/asyncio-stream#asyncio.start_server", "type": "Asynchronous I/O", "text": ["Start a socket server.", "The client_connected_cb callback is called whenever a new client connection is established. It receives a (reader, writer) pair as two arguments, instances of the StreamReader and StreamWriter classes.", "client_connected_cb can be a plain callable or a coroutine function; if it is a coroutine function, it will be automatically scheduled as a Task.", "The loop argument is optional and can always be determined automatically when this method is awaited from a coroutine.", "limit determines the buffer size limit used by the returned StreamReader instance. By default the limit is set to 64 KiB.", "The rest of the arguments are passed directly to loop.create_server().", "New in version 3.7: The ssl_handshake_timeout and start_serving parameters."]}, {"name": "asyncio.start_unix_server()", "path": "library/asyncio-stream#asyncio.start_unix_server", "type": "Asynchronous I/O", "text": ["Start a Unix socket server.", "Similar to start_server() but works with Unix sockets.", "See also the documentation of loop.create_unix_server().", "Availability: Unix.", "New in version 3.7: The ssl_handshake_timeout and start_serving parameters.", "Changed in version 3.7: The path parameter can now be a path-like object."]}, {"name": "asyncio.StreamReader", "path": "library/asyncio-stream#asyncio.StreamReader", "type": "Asynchronous I/O", "text": ["Represents a reader object that provides APIs to read data from the IO stream.", "It is not recommended to instantiate StreamReader objects directly; use open_connection() and start_server() instead.", "Read up to n bytes. If n is not provided, or set to -1, read until EOF and return all read bytes.", "If EOF was received and the internal buffer is empty, return an empty bytes object.", "Read one line, where \u201cline\u201d is a sequence of bytes ending with \\n.", "If EOF is received and \\n was not found, the method returns partially read data.", "If EOF is received and the internal buffer is empty, return an empty bytes object.", "Read exactly n bytes.", "Raise an IncompleteReadError if EOF is reached before n can be read. Use the IncompleteReadError.partial attribute to get the partially read data.", "Read data from the stream until separator is found.", "On success, the data and separator will be removed from the internal buffer (consumed). Returned data will include the separator at the end.", "If the amount of data read exceeds the configured stream limit, a LimitOverrunError exception is raised, and the data is left in the internal buffer and can be read again.", "If EOF is reached before the complete separator is found, an IncompleteReadError exception is raised, and the internal buffer is reset. The IncompleteReadError.partial attribute may contain a portion of the separator.", "New in version 3.5.2.", "Return True if the buffer is empty and feed_eof() was called."]}, {"name": "asyncio.StreamReader.at_eof()", "path": "library/asyncio-stream#asyncio.StreamReader.at_eof", "type": "Asynchronous I/O", "text": ["Return True if the buffer is empty and feed_eof() was called."]}, {"name": "asyncio.StreamReader.read()", "path": "library/asyncio-stream#asyncio.StreamReader.read", "type": "Asynchronous I/O", "text": ["Read up to n bytes. If n is not provided, or set to -1, read until EOF and return all read bytes.", "If EOF was received and the internal buffer is empty, return an empty bytes object."]}, {"name": "asyncio.StreamReader.readexactly()", "path": "library/asyncio-stream#asyncio.StreamReader.readexactly", "type": "Asynchronous I/O", "text": ["Read exactly n bytes.", "Raise an IncompleteReadError if EOF is reached before n can be read. Use the IncompleteReadError.partial attribute to get the partially read data."]}, {"name": "asyncio.StreamReader.readline()", "path": "library/asyncio-stream#asyncio.StreamReader.readline", "type": "Asynchronous I/O", "text": ["Read one line, where \u201cline\u201d is a sequence of bytes ending with \\n.", "If EOF is received and \\n was not found, the method returns partially read data.", "If EOF is received and the internal buffer is empty, return an empty bytes object."]}, {"name": "asyncio.StreamReader.readuntil()", "path": "library/asyncio-stream#asyncio.StreamReader.readuntil", "type": "Asynchronous I/O", "text": ["Read data from the stream until separator is found.", "On success, the data and separator will be removed from the internal buffer (consumed). Returned data will include the separator at the end.", "If the amount of data read exceeds the configured stream limit, a LimitOverrunError exception is raised, and the data is left in the internal buffer and can be read again.", "If EOF is reached before the complete separator is found, an IncompleteReadError exception is raised, and the internal buffer is reset. The IncompleteReadError.partial attribute may contain a portion of the separator.", "New in version 3.5.2."]}, {"name": "asyncio.StreamWriter", "path": "library/asyncio-stream#asyncio.StreamWriter", "type": "Asynchronous I/O", "text": ["Represents a writer object that provides APIs to write data to the IO stream.", "It is not recommended to instantiate StreamWriter objects directly; use open_connection() and start_server() instead.", "The method attempts to write the data to the underlying socket immediately. If that fails, the data is queued in an internal write buffer until it can be sent.", "The method should be used along with the drain() method:", "The method writes a list (or any iterable) of bytes to the underlying socket immediately. If that fails, the data is queued in an internal write buffer until it can be sent.", "The method should be used along with the drain() method:", "The method closes the stream and the underlying socket.", "The method should be used along with the wait_closed() method:", "Return True if the underlying transport supports the write_eof() method, False otherwise.", "Close the write end of the stream after the buffered write data is flushed.", "Return the underlying asyncio transport.", "Access optional transport information; see BaseTransport.get_extra_info() for details.", "Wait until it is appropriate to resume writing to the stream. Example:", "This is a flow control method that interacts with the underlying IO write buffer. When the size of the buffer reaches the high watermark, drain() blocks until the size of the buffer is drained down to the low watermark and writing can be resumed. When there is nothing to wait for, the drain() returns immediately.", "Return True if the stream is closed or in the process of being closed.", "New in version 3.7.", "Wait until the stream is closed.", "Should be called after close() to wait until the underlying connection is closed.", "New in version 3.7."]}, {"name": "asyncio.StreamWriter.can_write_eof()", "path": "library/asyncio-stream#asyncio.StreamWriter.can_write_eof", "type": "Asynchronous I/O", "text": ["Return True if the underlying transport supports the write_eof() method, False otherwise."]}, {"name": "asyncio.StreamWriter.close()", "path": "library/asyncio-stream#asyncio.StreamWriter.close", "type": "Asynchronous I/O", "text": ["The method closes the stream and the underlying socket.", "The method should be used along with the wait_closed() method:"]}, {"name": "asyncio.StreamWriter.drain()", "path": "library/asyncio-stream#asyncio.StreamWriter.drain", "type": "Asynchronous I/O", "text": ["Wait until it is appropriate to resume writing to the stream. Example:", "This is a flow control method that interacts with the underlying IO write buffer. When the size of the buffer reaches the high watermark, drain() blocks until the size of the buffer is drained down to the low watermark and writing can be resumed. When there is nothing to wait for, the drain() returns immediately."]}, {"name": "asyncio.StreamWriter.get_extra_info()", "path": "library/asyncio-stream#asyncio.StreamWriter.get_extra_info", "type": "Asynchronous I/O", "text": ["Access optional transport information; see BaseTransport.get_extra_info() for details."]}, {"name": "asyncio.StreamWriter.is_closing()", "path": "library/asyncio-stream#asyncio.StreamWriter.is_closing", "type": "Asynchronous I/O", "text": ["Return True if the stream is closed or in the process of being closed.", "New in version 3.7."]}, {"name": "asyncio.StreamWriter.transport", "path": "library/asyncio-stream#asyncio.StreamWriter.transport", "type": "Asynchronous I/O", "text": ["Return the underlying asyncio transport."]}, {"name": "asyncio.StreamWriter.wait_closed()", "path": "library/asyncio-stream#asyncio.StreamWriter.wait_closed", "type": "Asynchronous I/O", "text": ["Wait until the stream is closed.", "Should be called after close() to wait until the underlying connection is closed.", "New in version 3.7."]}, {"name": "asyncio.StreamWriter.write()", "path": "library/asyncio-stream#asyncio.StreamWriter.write", "type": "Asynchronous I/O", "text": ["The method attempts to write the data to the underlying socket immediately. If that fails, the data is queued in an internal write buffer until it can be sent.", "The method should be used along with the drain() method:"]}, {"name": "asyncio.StreamWriter.writelines()", "path": "library/asyncio-stream#asyncio.StreamWriter.writelines", "type": "Asynchronous I/O", "text": ["The method writes a list (or any iterable) of bytes to the underlying socket immediately. If that fails, the data is queued in an internal write buffer until it can be sent.", "The method should be used along with the drain() method:"]}, {"name": "asyncio.StreamWriter.write_eof()", "path": "library/asyncio-stream#asyncio.StreamWriter.write_eof", "type": "Asynchronous I/O", "text": ["Close the write end of the stream after the buffered write data is flushed."]}, {"name": "asyncio.SubprocessProtocol", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol", "type": "Asynchronous I/O", "text": ["The base class for implementing protocols communicating with child processes (unidirectional pipes)."]}, {"name": "asyncio.SubprocessProtocol.pipe_connection_lost()", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol.pipe_connection_lost", "type": "Asynchronous I/O", "text": ["Called when one of the pipes communicating with the child process is closed.", "fd is the integer file descriptor that was closed."]}, {"name": "asyncio.SubprocessProtocol.pipe_data_received()", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol.pipe_data_received", "type": "Asynchronous I/O", "text": ["Called when the child process writes data into its stdout or stderr pipe.", "fd is the integer file descriptor of the pipe.", "data is a non-empty bytes object containing the received data."]}, {"name": "asyncio.SubprocessProtocol.process_exited()", "path": "library/asyncio-protocol#asyncio.SubprocessProtocol.process_exited", "type": "Asynchronous I/O", "text": ["Called when the child process has exited."]}, {"name": "asyncio.SubprocessTransport", "path": "library/asyncio-protocol#asyncio.SubprocessTransport", "type": "Asynchronous I/O", "text": ["An abstraction to represent a connection between a parent and its child OS process.", "Instances of the SubprocessTransport class are returned from event loop methods loop.subprocess_shell() and loop.subprocess_exec()."]}, {"name": "asyncio.SubprocessTransport.close()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.close", "type": "Asynchronous I/O", "text": ["Kill the subprocess by calling the kill() method.", "If the subprocess hasn\u2019t returned yet, and close transports of stdin, stdout, and stderr pipes."]}, {"name": "asyncio.SubprocessTransport.get_pid()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.get_pid", "type": "Asynchronous I/O", "text": ["Return the subprocess process id as an integer."]}, {"name": "asyncio.SubprocessTransport.get_pipe_transport()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.get_pipe_transport", "type": "Asynchronous I/O", "text": ["Return the transport for the communication pipe corresponding to the integer file descriptor fd:"]}, {"name": "asyncio.SubprocessTransport.get_returncode()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.get_returncode", "type": "Asynchronous I/O", "text": ["Return the subprocess return code as an integer or None if it hasn\u2019t returned, which is similar to the subprocess.Popen.returncode attribute."]}, {"name": "asyncio.SubprocessTransport.kill()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.kill", "type": "Asynchronous I/O", "text": ["Kill the subprocess.", "On POSIX systems, the function sends SIGKILL to the subprocess. On Windows, this method is an alias for terminate().", "See also subprocess.Popen.kill()."]}, {"name": "asyncio.SubprocessTransport.send_signal()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.send_signal", "type": "Asynchronous I/O", "text": ["Send the signal number to the subprocess, as in subprocess.Popen.send_signal()."]}, {"name": "asyncio.SubprocessTransport.terminate()", "path": "library/asyncio-protocol#asyncio.SubprocessTransport.terminate", "type": "Asynchronous I/O", "text": ["Stop the subprocess.", "On POSIX systems, this method sends SIGTERM to the subprocess. On Windows, the Windows API function TerminateProcess() is called to stop the subprocess.", "See also subprocess.Popen.terminate()."]}, {"name": "asyncio.Task", "path": "library/asyncio-task#asyncio.Task", "type": "Asynchronous I/O", "text": ["A Future-like object that runs a Python coroutine. Not thread-safe.", "Tasks are used to run coroutines in event loops. If a coroutine awaits on a Future, the Task suspends the execution of the coroutine and waits for the completion of the Future. When the Future is done, the execution of the wrapped coroutine resumes.", "Event loops use cooperative scheduling: an event loop runs one Task at a time. While a Task awaits for the completion of a Future, the event loop runs other Tasks, callbacks, or performs IO operations.", "Use the high-level asyncio.create_task() function to create Tasks, or the low-level loop.create_task() or ensure_future() functions. Manual instantiation of Tasks is discouraged.", "To cancel a running Task use the cancel() method. Calling it will cause the Task to throw a CancelledError exception into the wrapped coroutine. If a coroutine is awaiting on a Future object during cancellation, the Future object will be cancelled.", "cancelled() can be used to check if the Task was cancelled. The method returns True if the wrapped coroutine did not suppress the CancelledError exception and was actually cancelled.", "asyncio.Task inherits from Future all of its APIs except Future.set_result() and Future.set_exception().", "Tasks support the contextvars module. When a Task is created it copies the current context and later runs its coroutine in the copied context.", "Changed in version 3.7: Added support for the contextvars module.", "Changed in version 3.8: Added the name parameter.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Request the Task to be cancelled.", "This arranges for a CancelledError exception to be thrown into the wrapped coroutine on the next cycle of the event loop.", "The coroutine then has a chance to clean up or even deny the request by suppressing the exception with a try \u2026 \u2026 except CancelledError \u2026 finally block. Therefore, unlike Future.cancel(), Task.cancel() does not guarantee that the Task will be cancelled, although suppressing cancellation completely is not common and is actively discouraged.", "Changed in version 3.9: Added the msg parameter.", "The following example illustrates how coroutines can intercept the cancellation request:", "Return True if the Task is cancelled.", "The Task is cancelled when the cancellation was requested with cancel() and the wrapped coroutine propagated the CancelledError exception thrown into it.", "Return True if the Task is done.", "A Task is done when the wrapped coroutine either returned a value, raised an exception, or the Task was cancelled.", "Return the result of the Task.", "If the Task is done, the result of the wrapped coroutine is returned (or if the coroutine raised an exception, that exception is re-raised.)", "If the Task has been cancelled, this method raises a CancelledError exception.", "If the Task\u2019s result isn\u2019t yet available, this method raises a InvalidStateError exception.", "Return the exception of the Task.", "If the wrapped coroutine raised an exception that exception is returned. If the wrapped coroutine returned normally this method returns None.", "If the Task has been cancelled, this method raises a CancelledError exception.", "If the Task isn\u2019t done yet, this method raises an InvalidStateError exception.", "Add a callback to be run when the Task is done.", "This method should only be used in low-level callback-based code.", "See the documentation of Future.add_done_callback() for more details.", "Remove callback from the callbacks list.", "This method should only be used in low-level callback-based code.", "See the documentation of Future.remove_done_callback() for more details.", "Return the list of stack frames for this Task.", "If the wrapped coroutine is not done, this returns the stack where it is suspended. If the coroutine has completed successfully or was cancelled, this returns an empty list. If the coroutine was terminated by an exception, this returns the list of traceback frames.", "The frames are always ordered from oldest to newest.", "Only one stack frame is returned for a suspended coroutine.", "The optional limit argument sets the maximum number of frames to return; by default all available frames are returned. The ordering of the returned list differs depending on whether a stack or a traceback is returned: the newest frames of a stack are returned, but the oldest frames of a traceback are returned. (This matches the behavior of the traceback module.)", "Print the stack or traceback for this Task.", "This produces output similar to that of the traceback module for the frames retrieved by get_stack().", "The limit argument is passed to get_stack() directly.", "The file argument is an I/O stream to which the output is written; by default output is written to sys.stderr.", "Return the coroutine object wrapped by the Task.", "New in version 3.8.", "Return the name of the Task.", "If no name has been explicitly assigned to the Task, the default asyncio Task implementation generates a default name during instantiation.", "New in version 3.8.", "Set the name of the Task.", "The value argument can be any object, which is then converted to a string.", "In the default Task implementation, the name will be visible in the repr() output of a task object.", "New in version 3.8."]}, {"name": "asyncio.Task.add_done_callback()", "path": "library/asyncio-task#asyncio.Task.add_done_callback", "type": "Asynchronous I/O", "text": ["Add a callback to be run when the Task is done.", "This method should only be used in low-level callback-based code.", "See the documentation of Future.add_done_callback() for more details."]}, {"name": "asyncio.Task.cancel()", "path": "library/asyncio-task#asyncio.Task.cancel", "type": "Asynchronous I/O", "text": ["Request the Task to be cancelled.", "This arranges for a CancelledError exception to be thrown into the wrapped coroutine on the next cycle of the event loop.", "The coroutine then has a chance to clean up or even deny the request by suppressing the exception with a try \u2026 \u2026 except CancelledError \u2026 finally block. Therefore, unlike Future.cancel(), Task.cancel() does not guarantee that the Task will be cancelled, although suppressing cancellation completely is not common and is actively discouraged.", "Changed in version 3.9: Added the msg parameter.", "The following example illustrates how coroutines can intercept the cancellation request:"]}, {"name": "asyncio.Task.cancelled()", "path": "library/asyncio-task#asyncio.Task.cancelled", "type": "Asynchronous I/O", "text": ["Return True if the Task is cancelled.", "The Task is cancelled when the cancellation was requested with cancel() and the wrapped coroutine propagated the CancelledError exception thrown into it."]}, {"name": "asyncio.Task.done()", "path": "library/asyncio-task#asyncio.Task.done", "type": "Asynchronous I/O", "text": ["Return True if the Task is done.", "A Task is done when the wrapped coroutine either returned a value, raised an exception, or the Task was cancelled."]}, {"name": "asyncio.Task.exception()", "path": "library/asyncio-task#asyncio.Task.exception", "type": "Asynchronous I/O", "text": ["Return the exception of the Task.", "If the wrapped coroutine raised an exception that exception is returned. If the wrapped coroutine returned normally this method returns None.", "If the Task has been cancelled, this method raises a CancelledError exception.", "If the Task isn\u2019t done yet, this method raises an InvalidStateError exception."]}, {"name": "asyncio.Task.get_coro()", "path": "library/asyncio-task#asyncio.Task.get_coro", "type": "Asynchronous I/O", "text": ["Return the coroutine object wrapped by the Task.", "New in version 3.8."]}, {"name": "asyncio.Task.get_name()", "path": "library/asyncio-task#asyncio.Task.get_name", "type": "Asynchronous I/O", "text": ["Return the name of the Task.", "If no name has been explicitly assigned to the Task, the default asyncio Task implementation generates a default name during instantiation.", "New in version 3.8."]}, {"name": "asyncio.Task.get_stack()", "path": "library/asyncio-task#asyncio.Task.get_stack", "type": "Asynchronous I/O", "text": ["Return the list of stack frames for this Task.", "If the wrapped coroutine is not done, this returns the stack where it is suspended. If the coroutine has completed successfully or was cancelled, this returns an empty list. If the coroutine was terminated by an exception, this returns the list of traceback frames.", "The frames are always ordered from oldest to newest.", "Only one stack frame is returned for a suspended coroutine.", "The optional limit argument sets the maximum number of frames to return; by default all available frames are returned. The ordering of the returned list differs depending on whether a stack or a traceback is returned: the newest frames of a stack are returned, but the oldest frames of a traceback are returned. (This matches the behavior of the traceback module.)"]}, {"name": "asyncio.Task.print_stack()", "path": "library/asyncio-task#asyncio.Task.print_stack", "type": "Asynchronous I/O", "text": ["Print the stack or traceback for this Task.", "This produces output similar to that of the traceback module for the frames retrieved by get_stack().", "The limit argument is passed to get_stack() directly.", "The file argument is an I/O stream to which the output is written; by default output is written to sys.stderr."]}, {"name": "asyncio.Task.remove_done_callback()", "path": "library/asyncio-task#asyncio.Task.remove_done_callback", "type": "Asynchronous I/O", "text": ["Remove callback from the callbacks list.", "This method should only be used in low-level callback-based code.", "See the documentation of Future.remove_done_callback() for more details."]}, {"name": "asyncio.Task.result()", "path": "library/asyncio-task#asyncio.Task.result", "type": "Asynchronous I/O", "text": ["Return the result of the Task.", "If the Task is done, the result of the wrapped coroutine is returned (or if the coroutine raised an exception, that exception is re-raised.)", "If the Task has been cancelled, this method raises a CancelledError exception.", "If the Task\u2019s result isn\u2019t yet available, this method raises a InvalidStateError exception."]}, {"name": "asyncio.Task.set_name()", "path": "library/asyncio-task#asyncio.Task.set_name", "type": "Asynchronous I/O", "text": ["Set the name of the Task.", "The value argument can be any object, which is then converted to a string.", "In the default Task implementation, the name will be visible in the repr() output of a task object.", "New in version 3.8."]}, {"name": "asyncio.ThreadedChildWatcher", "path": "library/asyncio-policy#asyncio.ThreadedChildWatcher", "type": "Asynchronous I/O", "text": ["This implementation starts a new waiting thread for every subprocess spawn.", "It works reliably even when the asyncio event loop is run in a non-main OS thread.", "There is no noticeable overhead when handling a big number of children (O(1) each time a child terminates), but starting a thread per process requires extra memory.", "This watcher is used by default.", "New in version 3.8."]}, {"name": "asyncio.TimeoutError", "path": "library/asyncio-exceptions#asyncio.TimeoutError", "type": "Asynchronous I/O", "text": ["The operation has exceeded the given deadline.", "Important", "This exception is different from the builtin TimeoutError exception."]}, {"name": "asyncio.TimerHandle", "path": "library/asyncio-eventloop#asyncio.TimerHandle", "type": "Asynchronous I/O", "text": ["A callback wrapper object returned by loop.call_later(), and loop.call_at().", "This class is a subclass of Handle.", "Return a scheduled callback time as float seconds.", "The time is an absolute timestamp, using the same time reference as loop.time().", "New in version 3.7."]}, {"name": "asyncio.TimerHandle.when()", "path": "library/asyncio-eventloop#asyncio.TimerHandle.when", "type": "Asynchronous I/O", "text": ["Return a scheduled callback time as float seconds.", "The time is an absolute timestamp, using the same time reference as loop.time().", "New in version 3.7."]}, {"name": "asyncio.to_thread()", "path": "library/asyncio-task#asyncio.to_thread", "type": "Asynchronous I/O", "text": ["Asynchronously run function func in a separate thread.", "Any *args and **kwargs supplied for this function are directly passed to func. Also, the current contextvars.Context is propagated, allowing context variables from the event loop thread to be accessed in the separate thread.", "Return a coroutine that can be awaited to get the eventual result of func.", "This coroutine function is primarily intended to be used for executing IO-bound functions/methods that would otherwise block the event loop if they were ran in the main thread. For example:", "Directly calling blocking_io() in any coroutine would block the event loop for its duration, resulting in an additional 1 second of run time. Instead, by using asyncio.to_thread(), we can run it in a separate thread without blocking the event loop.", "Note", "Due to the GIL, asyncio.to_thread() can typically only be used to make IO-bound functions non-blocking. However, for extension modules that release the GIL or alternative Python implementations that don\u2019t have one, asyncio.to_thread() can also be used for CPU-bound functions.", "New in version 3.9."]}, {"name": "asyncio.Transport", "path": "library/asyncio-protocol#asyncio.Transport", "type": "Asynchronous I/O", "text": ["Interface representing a bidirectional transport, such as a TCP connection.", "The user does not instantiate a transport directly; they call a utility function, passing it a protocol factory and other information necessary to create the transport and protocol.", "Instances of the Transport class are returned from or used by event loop methods like loop.create_connection(), loop.create_unix_connection(), loop.create_server(), loop.sendfile(), etc."]}, {"name": "asyncio.wait()", "path": "library/asyncio-task#asyncio.wait", "type": "Asynchronous I/O", "text": ["Run awaitable objects in the aws iterable concurrently and block until the condition specified by return_when.", "The aws iterable must not be empty.", "Returns two sets of Tasks/Futures: (done, pending).", "Usage:", "timeout (a float or int), if specified, can be used to control the maximum number of seconds to wait before returning.", "Note that this function does not raise asyncio.TimeoutError. Futures or Tasks that aren\u2019t done when the timeout occurs are simply returned in the second set.", "return_when indicates when this function should return. It must be one of the following constants:", "Constant", "Description", "FIRST_COMPLETED", "The function will return when any future finishes or is cancelled.", "FIRST_EXCEPTION", "The function will return when any future finishes by raising an exception. If no future raises an exception then it is equivalent to ALL_COMPLETED.", "ALL_COMPLETED", "The function will return when all futures finish or are cancelled.", "Unlike wait_for(), wait() does not cancel the futures when a timeout occurs.", "Deprecated since version 3.8: If any awaitable in aws is a coroutine, it is automatically scheduled as a Task. Passing coroutines objects to wait() directly is deprecated as it leads to confusing behavior.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Note", "wait() schedules coroutines as Tasks automatically and later returns those implicitly created Task objects in (done, pending) sets. Therefore the following code won\u2019t work as expected:", "Here is how the above snippet can be fixed:", "Deprecated since version 3.8, will be removed in version 3.11: Passing coroutine objects to wait() directly is deprecated."]}, {"name": "asyncio.wait_for()", "path": "library/asyncio-task#asyncio.wait_for", "type": "Asynchronous I/O", "text": ["Wait for the aw awaitable to complete with a timeout.", "If aw is a coroutine it is automatically scheduled as a Task.", "timeout can either be None or a float or int number of seconds to wait for. If timeout is None, block until the future completes.", "If a timeout occurs, it cancels the task and raises asyncio.TimeoutError.", "To avoid the task cancellation, wrap it in shield().", "The function will wait until the future is actually cancelled, so the total wait time may exceed the timeout. If an exception happens during cancellation, it is propagated.", "If the wait is cancelled, the future aw is also cancelled.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example:", "Changed in version 3.7: When aw is cancelled due to a timeout, wait_for waits for aw to be cancelled. Previously, it raised asyncio.TimeoutError immediately."]}, {"name": "asyncio.WindowsProactorEventLoopPolicy", "path": "library/asyncio-policy#asyncio.WindowsProactorEventLoopPolicy", "type": "Asynchronous I/O", "text": ["An alternative event loop policy that uses the ProactorEventLoop event loop implementation.", "Availability: Windows."]}, {"name": "asyncio.WindowsSelectorEventLoopPolicy", "path": "library/asyncio-policy#asyncio.WindowsSelectorEventLoopPolicy", "type": "Asynchronous I/O", "text": ["An alternative event loop policy that uses the SelectorEventLoop event loop implementation.", "Availability: Windows."]}, {"name": "asyncio.wrap_future()", "path": "library/asyncio-future#asyncio.wrap_future", "type": "Asynchronous I/O", "text": ["Wrap a concurrent.futures.Future object in a asyncio.Future object."]}, {"name": "asyncio.WriteTransport", "path": "library/asyncio-protocol#asyncio.WriteTransport", "type": "Asynchronous I/O", "text": ["A base transport for write-only connections.", "Instances of the WriteTransport class are returned from the loop.connect_write_pipe() event loop method and are also used by subprocess-related methods like loop.subprocess_exec()."]}, {"name": "asyncio.WriteTransport.abort()", "path": "library/asyncio-protocol#asyncio.WriteTransport.abort", "type": "Asynchronous I/O", "text": ["Close the transport immediately, without waiting for pending operations to complete. Buffered data will be lost. No more data will be received. The protocol\u2019s protocol.connection_lost() method will eventually be called with None as its argument."]}, {"name": "asyncio.WriteTransport.can_write_eof()", "path": "library/asyncio-protocol#asyncio.WriteTransport.can_write_eof", "type": "Asynchronous I/O", "text": ["Return True if the transport supports write_eof(), False if not."]}, {"name": "asyncio.WriteTransport.get_write_buffer_limits()", "path": "library/asyncio-protocol#asyncio.WriteTransport.get_write_buffer_limits", "type": "Asynchronous I/O", "text": ["Get the high and low watermarks for write flow control. Return a tuple (low, high) where low and high are positive number of bytes.", "Use set_write_buffer_limits() to set the limits.", "New in version 3.4.2."]}, {"name": "asyncio.WriteTransport.get_write_buffer_size()", "path": "library/asyncio-protocol#asyncio.WriteTransport.get_write_buffer_size", "type": "Asynchronous I/O", "text": ["Return the current size of the output buffer used by the transport."]}, {"name": "asyncio.WriteTransport.set_write_buffer_limits()", "path": "library/asyncio-protocol#asyncio.WriteTransport.set_write_buffer_limits", "type": "Asynchronous I/O", "text": ["Set the high and low watermarks for write flow control.", "These two values (measured in number of bytes) control when the protocol\u2019s protocol.pause_writing() and protocol.resume_writing() methods are called. If specified, the low watermark must be less than or equal to the high watermark. Neither high nor low can be negative.", "pause_writing() is called when the buffer size becomes greater than or equal to the high value. If writing has been paused, resume_writing() is called when the buffer size becomes less than or equal to the low value.", "The defaults are implementation-specific. If only the high watermark is given, the low watermark defaults to an implementation-specific value less than or equal to the high watermark. Setting high to zero forces low to zero as well, and causes pause_writing() to be called whenever the buffer becomes non-empty. Setting low to zero causes resume_writing() to be called only once the buffer is empty. Use of zero for either limit is generally sub-optimal as it reduces opportunities for doing I/O and computation concurrently.", "Use get_write_buffer_limits() to get the limits."]}, {"name": "asyncio.WriteTransport.write()", "path": "library/asyncio-protocol#asyncio.WriteTransport.write", "type": "Asynchronous I/O", "text": ["Write some data bytes to the transport.", "This method does not block; it buffers the data and arranges for it to be sent out asynchronously."]}, {"name": "asyncio.WriteTransport.writelines()", "path": "library/asyncio-protocol#asyncio.WriteTransport.writelines", "type": "Asynchronous I/O", "text": ["Write a list (or any iterable) of data bytes to the transport. This is functionally equivalent to calling write() on each element yielded by the iterable, but may be implemented more efficiently."]}, {"name": "asyncio.WriteTransport.write_eof()", "path": "library/asyncio-protocol#asyncio.WriteTransport.write_eof", "type": "Asynchronous I/O", "text": ["Close the write end of the transport after flushing all buffered data. Data may still be received.", "This method can raise NotImplementedError if the transport (e.g. SSL) doesn\u2019t support half-closed connections."]}, {"name": "asyncore", "path": "library/asyncore", "type": "Networking & Interprocess Communication", "text": ["Source code: Lib/asyncore.py", "Deprecated since version 3.6: Please use asyncio instead.", "Note", "This module exists for backwards compatibility only. For new code we recommend using asyncio.", "This module provides the basic infrastructure for writing asynchronous socket service clients and servers.", "There are only two ways to have a program on a single processor do \u201cmore than one thing at a time.\u201d Multi-threaded programming is the simplest and most popular way to do it, but there is another very different technique, that lets you have nearly all the advantages of multi-threading, without actually using multiple threads. It\u2019s really only practical if your program is largely I/O bound. If your program is processor bound, then pre-emptive scheduled threads are probably what you really need. Network servers are rarely processor bound, however.", "If your operating system supports the select() system call in its I/O library (and nearly all do), then you can use it to juggle multiple communication channels at once; doing other work while your I/O is taking place in the \u201cbackground.\u201d Although this strategy can seem strange and complex, especially at first, it is in many ways easier to understand and control than multi-threaded programming. The asyncore module solves many of the difficult problems for you, making the task of building sophisticated high-performance network servers and clients a snap. For \u201cconversational\u201d applications and protocols the companion asynchat module is invaluable.", "The basic idea behind both modules is to create one or more network channels, instances of class asyncore.dispatcher and asynchat.async_chat. Creating the channels adds them to a global map, used by the loop() function if you do not provide it with your own map.", "Once the initial channel(s) is(are) created, calling the loop() function activates channel service, which continues until the last channel (including any that have been added to the map during asynchronous service) is closed.", "Enter a polling loop that terminates after count passes or all open channels have been closed. All arguments are optional. The count parameter defaults to None, resulting in the loop terminating only when all channels have been closed. The timeout argument sets the timeout parameter for the appropriate select() or poll() call, measured in seconds; the default is 30 seconds. The use_poll parameter, if true, indicates that poll() should be used in preference to select() (the default is False).", "The map parameter is a dictionary whose items are the channels to watch. As channels are closed they are deleted from their map. If map is omitted, a global map is used. Channels (instances of asyncore.dispatcher, asynchat.async_chat and subclasses thereof) can freely be mixed in the map.", "The dispatcher class is a thin wrapper around a low-level socket object. To make it more useful, it has a few methods for event-handling which are called from the asynchronous loop. Otherwise, it can be treated as a normal non-blocking socket object.", "The firing of low-level events at certain times or in certain connection states tells the asynchronous loop that certain higher-level events have taken place. For example, if we have asked for a socket to connect to another host, we know that the connection has been made when the socket becomes writable for the first time (at this point you know that you may write to it with the expectation of success). The implied higher-level events are:", "Event", "Description", "handle_connect()", "Implied by the first read or write event", "handle_close()", "Implied by a read event with no data available", "handle_accepted()", "Implied by a read event on a listening socket", "During asynchronous processing, each mapped channel\u2019s readable() and writable() methods are used to determine whether the channel\u2019s socket should be added to the list of channels select()ed or poll()ed for read and write events.", "Thus, the set of channel events is larger than the basic socket events. The full set of methods that can be overridden in your subclass follows:", "Called when the asynchronous loop detects that a read() call on the channel\u2019s socket will succeed.", "Called when the asynchronous loop detects that a writable socket can be written. Often this method will implement the necessary buffering for performance. For example:", "Called when there is out of band (OOB) data for a socket connection. This will almost never happen, as OOB is tenuously supported and rarely used.", "Called when the active opener\u2019s socket actually makes a connection. Might send a \u201cwelcome\u201d banner, or initiate a protocol negotiation with the remote endpoint, for example.", "Called when the socket is closed.", "Called when an exception is raised and not otherwise handled. The default version prints a condensed traceback.", "Called on listening channels (passive openers) when a connection can be established with a new remote endpoint that has issued a connect() call for the local endpoint. Deprecated in version 3.2; use handle_accepted() instead.", "Deprecated since version 3.2.", "Called on listening channels (passive openers) when a connection has been established with a new remote endpoint that has issued a connect() call for the local endpoint. sock is a new socket object usable to send and receive data on the connection, and addr is the address bound to the socket on the other end of the connection.", "New in version 3.2.", "Called each time around the asynchronous loop to determine whether a channel\u2019s socket should be added to the list on which read events can occur. The default method simply returns True, indicating that by default, all channels will be interested in read events.", "Called each time around the asynchronous loop to determine whether a channel\u2019s socket should be added to the list on which write events can occur. The default method simply returns True, indicating that by default, all channels will be interested in write events.", "In addition, each channel delegates or extends many of the socket methods. Most of these are nearly identical to their socket partners.", "This is identical to the creation of a normal socket, and will use the same options for creation. Refer to the socket documentation for information on creating sockets.", "Changed in version 3.3: family and type arguments can be omitted.", "As with the normal socket object, address is a tuple with the first element the host to connect to, and the second the port number.", "Send data to the remote end-point of the socket.", "Read at most buffer_size bytes from the socket\u2019s remote end-point. An empty bytes object implies that the channel has been closed from the other end.", "Note that recv() may raise BlockingIOError , even though select.select() or select.poll() has reported the socket ready for reading.", "Listen for connections made to the socket. The backlog argument specifies the maximum number of queued connections and should be at least 1; the maximum value is system-dependent (usually 5).", "Bind the socket to address. The socket must not already be bound. (The format of address depends on the address family \u2014 refer to the socket documentation for more information.) To mark the socket as re-usable (setting the SO_REUSEADDR option), call the dispatcher object\u2019s set_reuse_addr() method.", "Accept a connection. The socket must be bound to an address and listening for connections. The return value can be either None or a pair (conn, address) where conn is a new socket object usable to send and receive data on the connection, and address is the address bound to the socket on the other end of the connection. When None is returned it means the connection didn\u2019t take place, in which case the server should just ignore this event and keep listening for further incoming connections.", "Close the socket. All future operations on the socket object will fail. The remote end-point will receive no more data (after queued data is flushed). Sockets are automatically closed when they are garbage-collected.", "A dispatcher subclass which adds simple buffered output capability, useful for simple clients. For more sophisticated usage use asynchat.async_chat.", "A file_dispatcher takes a file descriptor or file object along with an optional map argument and wraps it for use with the poll() or loop() functions. If provided a file object or anything with a fileno() method, that method will be called and passed to the file_wrapper constructor.", "Availability: Unix.", "A file_wrapper takes an integer file descriptor and calls os.dup() to duplicate the handle so that the original handle may be closed independently of the file_wrapper. This class implements sufficient methods to emulate a socket for use by the file_dispatcher class.", "Availability: Unix.", "Here is a very basic HTTP client that uses the dispatcher class to implement its socket handling:", "Here is a basic echo server that uses the dispatcher class to accept connections and dispatches the incoming connections to a handler:"]}, {"name": "asyncore.dispatcher", "path": "library/asyncore#asyncore.dispatcher", "type": "Networking & Interprocess Communication", "text": ["The dispatcher class is a thin wrapper around a low-level socket object. To make it more useful, it has a few methods for event-handling which are called from the asynchronous loop. Otherwise, it can be treated as a normal non-blocking socket object.", "The firing of low-level events at certain times or in certain connection states tells the asynchronous loop that certain higher-level events have taken place. For example, if we have asked for a socket to connect to another host, we know that the connection has been made when the socket becomes writable for the first time (at this point you know that you may write to it with the expectation of success). The implied higher-level events are:", "Event", "Description", "handle_connect()", "Implied by the first read or write event", "handle_close()", "Implied by a read event with no data available", "handle_accepted()", "Implied by a read event on a listening socket", "During asynchronous processing, each mapped channel\u2019s readable() and writable() methods are used to determine whether the channel\u2019s socket should be added to the list of channels select()ed or poll()ed for read and write events.", "Thus, the set of channel events is larger than the basic socket events. The full set of methods that can be overridden in your subclass follows:", "Called when the asynchronous loop detects that a read() call on the channel\u2019s socket will succeed.", "Called when the asynchronous loop detects that a writable socket can be written. Often this method will implement the necessary buffering for performance. For example:", "Called when there is out of band (OOB) data for a socket connection. This will almost never happen, as OOB is tenuously supported and rarely used.", "Called when the active opener\u2019s socket actually makes a connection. Might send a \u201cwelcome\u201d banner, or initiate a protocol negotiation with the remote endpoint, for example.", "Called when the socket is closed.", "Called when an exception is raised and not otherwise handled. The default version prints a condensed traceback.", "Called on listening channels (passive openers) when a connection can be established with a new remote endpoint that has issued a connect() call for the local endpoint. Deprecated in version 3.2; use handle_accepted() instead.", "Deprecated since version 3.2.", "Called on listening channels (passive openers) when a connection has been established with a new remote endpoint that has issued a connect() call for the local endpoint. sock is a new socket object usable to send and receive data on the connection, and addr is the address bound to the socket on the other end of the connection.", "New in version 3.2.", "Called each time around the asynchronous loop to determine whether a channel\u2019s socket should be added to the list on which read events can occur. The default method simply returns True, indicating that by default, all channels will be interested in read events.", "Called each time around the asynchronous loop to determine whether a channel\u2019s socket should be added to the list on which write events can occur. The default method simply returns True, indicating that by default, all channels will be interested in write events.", "In addition, each channel delegates or extends many of the socket methods. Most of these are nearly identical to their socket partners.", "This is identical to the creation of a normal socket, and will use the same options for creation. Refer to the socket documentation for information on creating sockets.", "Changed in version 3.3: family and type arguments can be omitted.", "As with the normal socket object, address is a tuple with the first element the host to connect to, and the second the port number.", "Send data to the remote end-point of the socket.", "Read at most buffer_size bytes from the socket\u2019s remote end-point. An empty bytes object implies that the channel has been closed from the other end.", "Note that recv() may raise BlockingIOError , even though select.select() or select.poll() has reported the socket ready for reading.", "Listen for connections made to the socket. The backlog argument specifies the maximum number of queued connections and should be at least 1; the maximum value is system-dependent (usually 5).", "Bind the socket to address. The socket must not already be bound. (The format of address depends on the address family \u2014 refer to the socket documentation for more information.) To mark the socket as re-usable (setting the SO_REUSEADDR option), call the dispatcher object\u2019s set_reuse_addr() method.", "Accept a connection. The socket must be bound to an address and listening for connections. The return value can be either None or a pair (conn, address) where conn is a new socket object usable to send and receive data on the connection, and address is the address bound to the socket on the other end of the connection. When None is returned it means the connection didn\u2019t take place, in which case the server should just ignore this event and keep listening for further incoming connections.", "Close the socket. All future operations on the socket object will fail. The remote end-point will receive no more data (after queued data is flushed). Sockets are automatically closed when they are garbage-collected."]}, {"name": "asyncore.dispatcher.accept()", "path": "library/asyncore#asyncore.dispatcher.accept", "type": "Networking & Interprocess Communication", "text": ["Accept a connection. The socket must be bound to an address and listening for connections. The return value can be either None or a pair (conn, address) where conn is a new socket object usable to send and receive data on the connection, and address is the address bound to the socket on the other end of the connection. When None is returned it means the connection didn\u2019t take place, in which case the server should just ignore this event and keep listening for further incoming connections."]}, {"name": "asyncore.dispatcher.bind()", "path": "library/asyncore#asyncore.dispatcher.bind", "type": "Networking & Interprocess Communication", "text": ["Bind the socket to address. The socket must not already be bound. (The format of address depends on the address family \u2014 refer to the socket documentation for more information.) To mark the socket as re-usable (setting the SO_REUSEADDR option), call the dispatcher object\u2019s set_reuse_addr() method."]}, {"name": "asyncore.dispatcher.close()", "path": "library/asyncore#asyncore.dispatcher.close", "type": "Networking & Interprocess Communication", "text": ["Close the socket. All future operations on the socket object will fail. The remote end-point will receive no more data (after queued data is flushed). Sockets are automatically closed when they are garbage-collected."]}, {"name": "asyncore.dispatcher.connect()", "path": "library/asyncore#asyncore.dispatcher.connect", "type": "Networking & Interprocess Communication", "text": ["As with the normal socket object, address is a tuple with the first element the host to connect to, and the second the port number."]}, {"name": "asyncore.dispatcher.create_socket()", "path": "library/asyncore#asyncore.dispatcher.create_socket", "type": "Networking & Interprocess Communication", "text": ["This is identical to the creation of a normal socket, and will use the same options for creation. Refer to the socket documentation for information on creating sockets.", "Changed in version 3.3: family and type arguments can be omitted."]}, {"name": "asyncore.dispatcher.handle_accept()", "path": "library/asyncore#asyncore.dispatcher.handle_accept", "type": "Networking & Interprocess Communication", "text": ["Called on listening channels (passive openers) when a connection can be established with a new remote endpoint that has issued a connect() call for the local endpoint. Deprecated in version 3.2; use handle_accepted() instead.", "Deprecated since version 3.2."]}, {"name": "asyncore.dispatcher.handle_accepted()", "path": "library/asyncore#asyncore.dispatcher.handle_accepted", "type": "Networking & Interprocess Communication", "text": ["Called on listening channels (passive openers) when a connection has been established with a new remote endpoint that has issued a connect() call for the local endpoint. sock is a new socket object usable to send and receive data on the connection, and addr is the address bound to the socket on the other end of the connection.", "New in version 3.2."]}, {"name": "asyncore.dispatcher.handle_close()", "path": "library/asyncore#asyncore.dispatcher.handle_close", "type": "Networking & Interprocess Communication", "text": ["Called when the socket is closed."]}, {"name": "asyncore.dispatcher.handle_connect()", "path": "library/asyncore#asyncore.dispatcher.handle_connect", "type": "Networking & Interprocess Communication", "text": ["Called when the active opener\u2019s socket actually makes a connection. Might send a \u201cwelcome\u201d banner, or initiate a protocol negotiation with the remote endpoint, for example."]}, {"name": "asyncore.dispatcher.handle_error()", "path": "library/asyncore#asyncore.dispatcher.handle_error", "type": "Networking & Interprocess Communication", "text": ["Called when an exception is raised and not otherwise handled. The default version prints a condensed traceback."]}, {"name": "asyncore.dispatcher.handle_expt()", "path": "library/asyncore#asyncore.dispatcher.handle_expt", "type": "Networking & Interprocess Communication", "text": ["Called when there is out of band (OOB) data for a socket connection. This will almost never happen, as OOB is tenuously supported and rarely used."]}, {"name": "asyncore.dispatcher.handle_read()", "path": "library/asyncore#asyncore.dispatcher.handle_read", "type": "Networking & Interprocess Communication", "text": ["Called when the asynchronous loop detects that a read() call on the channel\u2019s socket will succeed."]}, {"name": "asyncore.dispatcher.handle_write()", "path": "library/asyncore#asyncore.dispatcher.handle_write", "type": "Networking & Interprocess Communication", "text": ["Called when the asynchronous loop detects that a writable socket can be written. Often this method will implement the necessary buffering for performance. For example:"]}, {"name": "asyncore.dispatcher.listen()", "path": "library/asyncore#asyncore.dispatcher.listen", "type": "Networking & Interprocess Communication", "text": ["Listen for connections made to the socket. The backlog argument specifies the maximum number of queued connections and should be at least 1; the maximum value is system-dependent (usually 5)."]}, {"name": "asyncore.dispatcher.readable()", "path": "library/asyncore#asyncore.dispatcher.readable", "type": "Networking & Interprocess Communication", "text": ["Called each time around the asynchronous loop to determine whether a channel\u2019s socket should be added to the list on which read events can occur. The default method simply returns True, indicating that by default, all channels will be interested in read events."]}, {"name": "asyncore.dispatcher.recv()", "path": "library/asyncore#asyncore.dispatcher.recv", "type": "Networking & Interprocess Communication", "text": ["Read at most buffer_size bytes from the socket\u2019s remote end-point. An empty bytes object implies that the channel has been closed from the other end.", "Note that recv() may raise BlockingIOError , even though select.select() or select.poll() has reported the socket ready for reading."]}, {"name": "asyncore.dispatcher.send()", "path": "library/asyncore#asyncore.dispatcher.send", "type": "Networking & Interprocess Communication", "text": ["Send data to the remote end-point of the socket."]}, {"name": "asyncore.dispatcher.writable()", "path": "library/asyncore#asyncore.dispatcher.writable", "type": "Networking & Interprocess Communication", "text": ["Called each time around the asynchronous loop to determine whether a channel\u2019s socket should be added to the list on which write events can occur. The default method simply returns True, indicating that by default, all channels will be interested in write events."]}, {"name": "asyncore.dispatcher_with_send", "path": "library/asyncore#asyncore.dispatcher_with_send", "type": "Networking & Interprocess Communication", "text": ["A dispatcher subclass which adds simple buffered output capability, useful for simple clients. For more sophisticated usage use asynchat.async_chat."]}, {"name": "asyncore.file_dispatcher", "path": "library/asyncore#asyncore.file_dispatcher", "type": "Networking & Interprocess Communication", "text": ["A file_dispatcher takes a file descriptor or file object along with an optional map argument and wraps it for use with the poll() or loop() functions. If provided a file object or anything with a fileno() method, that method will be called and passed to the file_wrapper constructor.", "Availability: Unix."]}, {"name": "asyncore.file_wrapper", "path": "library/asyncore#asyncore.file_wrapper", "type": "Networking & Interprocess Communication", "text": ["A file_wrapper takes an integer file descriptor and calls os.dup() to duplicate the handle so that the original handle may be closed independently of the file_wrapper. This class implements sufficient methods to emulate a socket for use by the file_dispatcher class.", "Availability: Unix."]}, {"name": "asyncore.loop()", "path": "library/asyncore#asyncore.loop", "type": "Networking & Interprocess Communication", "text": ["Enter a polling loop that terminates after count passes or all open channels have been closed. All arguments are optional. The count parameter defaults to None, resulting in the loop terminating only when all channels have been closed. The timeout argument sets the timeout parameter for the appropriate select() or poll() call, measured in seconds; the default is 30 seconds. The use_poll parameter, if true, indicates that poll() should be used in preference to select() (the default is False).", "The map parameter is a dictionary whose items are the channels to watch. As channels are closed they are deleted from their map. If map is omitted, a global map is used. Channels (instances of asyncore.dispatcher, asynchat.async_chat and subclasses thereof) can freely be mixed in the map."]}, {"name": "atexit", "path": "library/atexit", "type": "Runtime", "text": ["The atexit module defines functions to register and unregister cleanup functions. Functions thus registered are automatically executed upon normal interpreter termination. atexit runs these functions in the reverse order in which they were registered; if you register A, B, and C, at interpreter termination time they will be run in the order C, B, A.", "Note: The functions registered via this module are not called when the program is killed by a signal not handled by Python, when a Python fatal internal error is detected, or when os._exit() is called.", "Changed in version 3.7: When used with C-API subinterpreters, registered functions are local to the interpreter they were registered in.", "Register func as a function to be executed at termination. Any optional arguments that are to be passed to func must be passed as arguments to register(). It is possible to register the same function and arguments more than once.", "At normal program termination (for instance, if sys.exit() is called or the main module\u2019s execution completes), all functions registered are called in last in, first out order. The assumption is that lower level modules will normally be imported before higher level modules and thus must be cleaned up later.", "If an exception is raised during execution of the exit handlers, a traceback is printed (unless SystemExit is raised) and the exception information is saved. After all exit handlers have had a chance to run the last exception to be raised is re-raised.", "This function returns func, which makes it possible to use it as a decorator.", "Remove func from the list of functions to be run at interpreter shutdown. After calling unregister(), func is guaranteed not to be called when the interpreter shuts down, even if it was registered more than once. unregister() silently does nothing if func was not previously registered.", "See also", "Useful example of atexit to read and write readline history files.", "The following simple example demonstrates how a module can initialize a counter from a file when it is imported and save the counter\u2019s updated value automatically when the program terminates without relying on the application making an explicit call into this module at termination.", "Positional and keyword arguments may also be passed to register() to be passed along to the registered function when it is called:", "Usage as a decorator:", "This only works with functions that can be called without arguments."]}, {"name": "atexit.register()", "path": "library/atexit#atexit.register", "type": "Runtime", "text": ["Register func as a function to be executed at termination. Any optional arguments that are to be passed to func must be passed as arguments to register(). It is possible to register the same function and arguments more than once.", "At normal program termination (for instance, if sys.exit() is called or the main module\u2019s execution completes), all functions registered are called in last in, first out order. The assumption is that lower level modules will normally be imported before higher level modules and thus must be cleaned up later.", "If an exception is raised during execution of the exit handlers, a traceback is printed (unless SystemExit is raised) and the exception information is saved. After all exit handlers have had a chance to run the last exception to be raised is re-raised.", "This function returns func, which makes it possible to use it as a decorator."]}, {"name": "atexit.unregister()", "path": "library/atexit#atexit.unregister", "type": "Runtime", "text": ["Remove func from the list of functions to be run at interpreter shutdown. After calling unregister(), func is guaranteed not to be called when the interpreter shuts down, even if it was registered more than once. unregister() silently does nothing if func was not previously registered."]}, {"name": "AttributeError", "path": "library/exceptions#AttributeError", "type": "Built-in Exceptions", "text": ["Raised when an attribute reference (see Attribute references) or assignment fails. (When an object does not support attribute references or attribute assignments at all, TypeError is raised.)"]}, {"name": "audioop", "path": "library/audioop", "type": "Multimedia", "text": ["The audioop module contains some useful operations on sound fragments. It operates on sound fragments consisting of signed integer samples 8, 16, 24 or 32 bits wide, stored in bytes-like objects. All scalar items are integers, unless specified otherwise.", "Changed in version 3.4: Support for 24-bit samples was added. All functions now accept any bytes-like object. String input now results in an immediate error.", "This module provides support for a-LAW, u-LAW and Intel/DVI ADPCM encodings.", "A few of the more complicated operations only take 16-bit samples, otherwise the sample size (in bytes) is always a parameter of the operation.", "The module defines the following variables and functions:", "This exception is raised on all errors, such as unknown number of bytes per sample, etc.", "Return a fragment which is the addition of the two samples passed as parameters. width is the sample width in bytes, either 1, 2, 3 or 4. Both fragments should have the same length. Samples are truncated in case of overflow.", "Decode an Intel/DVI ADPCM coded fragment to a linear fragment. See the description of lin2adpcm() for details on ADPCM coding. Return a tuple (sample, newstate) where the sample has the width specified in width.", "Convert sound fragments in a-LAW encoding to linearly encoded sound fragments. a-LAW encoding always uses 8 bits samples, so width refers only to the sample width of the output fragment here.", "Return the average over all samples in the fragment.", "Return the average peak-peak value over all samples in the fragment. No filtering is done, so the usefulness of this routine is questionable.", "Return a fragment that is the original fragment with a bias added to each sample. Samples wrap around in case of overflow.", "\u201cByteswap\u201d all samples in a fragment and returns the modified fragment. Converts big-endian samples to little-endian and vice versa.", "New in version 3.4.", "Return the number of zero crossings in the fragment passed as an argument.", "Return a factor F such that rms(add(fragment, mul(reference, -F))) is minimal, i.e., return the factor with which you should multiply reference to make it match as well as possible to fragment. The fragments should both contain 2-byte samples.", "The time taken by this routine is proportional to len(fragment).", "Try to match reference as well as possible to a portion of fragment (which should be the longer fragment). This is (conceptually) done by taking slices out of fragment, using findfactor() to compute the best match, and minimizing the result. The fragments should both contain 2-byte samples. Return a tuple (offset, factor) where offset is the (integer) offset into fragment where the optimal match started and factor is the (floating-point) factor as per findfactor().", "Search fragment for a slice of length length samples (not bytes!) with maximum energy, i.e., return i for which rms(fragment[i*2:(i+length)*2]) is maximal. The fragments should both contain 2-byte samples.", "The routine takes time proportional to len(fragment).", "Return the value of sample index from the fragment.", "Convert samples to 4 bit Intel/DVI ADPCM encoding. ADPCM coding is an adaptive coding scheme, whereby each 4 bit number is the difference between one sample and the next, divided by a (varying) step. The Intel/DVI ADPCM algorithm has been selected for use by the IMA, so it may well become a standard.", "state is a tuple containing the state of the coder. The coder returns a tuple (adpcmfrag, newstate), and the newstate should be passed to the next call of lin2adpcm(). In the initial call, None can be passed as the state. adpcmfrag is the ADPCM coded fragment packed 2 4-bit values per byte.", "Convert samples in the audio fragment to a-LAW encoding and return this as a bytes object. a-LAW is an audio encoding format whereby you get a dynamic range of about 13 bits using only 8 bit samples. It is used by the Sun audio hardware, among others.", "Convert samples between 1-, 2-, 3- and 4-byte formats.", "Note", "In some audio formats, such as .WAV files, 16, 24 and 32 bit samples are signed, but 8 bit samples are unsigned. So when converting to 8 bit wide samples for these formats, you need to also add 128 to the result:", "The same, in reverse, has to be applied when converting from 8 to 16, 24 or 32 bit width samples.", "Convert samples in the audio fragment to u-LAW encoding and return this as a bytes object. u-LAW is an audio encoding format whereby you get a dynamic range of about 14 bits using only 8 bit samples. It is used by the Sun audio hardware, among others.", "Return the maximum of the absolute value of all samples in a fragment.", "Return the maximum peak-peak value in the sound fragment.", "Return a tuple consisting of the minimum and maximum values of all samples in the sound fragment.", "Return a fragment that has all samples in the original fragment multiplied by the floating-point value factor. Samples are truncated in case of overflow.", "Convert the frame rate of the input fragment.", "state is a tuple containing the state of the converter. The converter returns a tuple (newfragment, newstate), and newstate should be passed to the next call of ratecv(). The initial call should pass None as the state.", "The weightA and weightB arguments are parameters for a simple digital filter and default to 1 and 0 respectively.", "Reverse the samples in a fragment and returns the modified fragment.", "Return the root-mean-square of the fragment, i.e. sqrt(sum(S_i^2)/n).", "This is a measure of the power in an audio signal.", "Convert a stereo fragment to a mono fragment. The left channel is multiplied by lfactor and the right channel by rfactor before adding the two channels to give a mono signal.", "Generate a stereo fragment from a mono fragment. Each pair of samples in the stereo fragment are computed from the mono sample, whereby left channel samples are multiplied by lfactor and right channel samples by rfactor.", "Convert sound fragments in u-LAW encoding to linearly encoded sound fragments. u-LAW encoding always uses 8 bits samples, so width refers only to the sample width of the output fragment here.", "Note that operations such as mul() or max() make no distinction between mono and stereo fragments, i.e. all samples are treated equal. If this is a problem the stereo fragment should be split into two mono fragments first and recombined later. Here is an example of how to do that:", "If you use the ADPCM coder to build network packets and you want your protocol to be stateless (i.e. to be able to tolerate packet loss) you should not only transmit the data but also the state. Note that you should send the initial state (the one you passed to lin2adpcm()) along to the decoder, not the final state (as returned by the coder). If you want to use struct.Struct to store the state in binary you can code the first element (the predicted value) in 16 bits and the second (the delta index) in 8.", "The ADPCM coders have never been tried against other ADPCM coders, only against themselves. It could well be that I misinterpreted the standards in which case they will not be interoperable with the respective standards.", "The find*() routines might look a bit funny at first sight. They are primarily meant to do echo cancellation. A reasonably fast way to do this is to pick the most energetic piece of the output sample, locate that in the input sample and subtract the whole output sample from the input sample:"]}, {"name": "audioop.add()", "path": "library/audioop#audioop.add", "type": "Multimedia", "text": ["Return a fragment which is the addition of the two samples passed as parameters. width is the sample width in bytes, either 1, 2, 3 or 4. Both fragments should have the same length. Samples are truncated in case of overflow."]}, {"name": "audioop.adpcm2lin()", "path": "library/audioop#audioop.adpcm2lin", "type": "Multimedia", "text": ["Decode an Intel/DVI ADPCM coded fragment to a linear fragment. See the description of lin2adpcm() for details on ADPCM coding. Return a tuple (sample, newstate) where the sample has the width specified in width."]}, {"name": "audioop.alaw2lin()", "path": "library/audioop#audioop.alaw2lin", "type": "Multimedia", "text": ["Convert sound fragments in a-LAW encoding to linearly encoded sound fragments. a-LAW encoding always uses 8 bits samples, so width refers only to the sample width of the output fragment here."]}, {"name": "audioop.avg()", "path": "library/audioop#audioop.avg", "type": "Multimedia", "text": ["Return the average over all samples in the fragment."]}, {"name": "audioop.avgpp()", "path": "library/audioop#audioop.avgpp", "type": "Multimedia", "text": ["Return the average peak-peak value over all samples in the fragment. No filtering is done, so the usefulness of this routine is questionable."]}, {"name": "audioop.bias()", "path": "library/audioop#audioop.bias", "type": "Multimedia", "text": ["Return a fragment that is the original fragment with a bias added to each sample. Samples wrap around in case of overflow."]}, {"name": "audioop.byteswap()", "path": "library/audioop#audioop.byteswap", "type": "Multimedia", "text": ["\u201cByteswap\u201d all samples in a fragment and returns the modified fragment. Converts big-endian samples to little-endian and vice versa.", "New in version 3.4."]}, {"name": "audioop.cross()", "path": "library/audioop#audioop.cross", "type": "Multimedia", "text": ["Return the number of zero crossings in the fragment passed as an argument."]}, {"name": "audioop.error", "path": "library/audioop#audioop.error", "type": "Multimedia", "text": ["This exception is raised on all errors, such as unknown number of bytes per sample, etc."]}, {"name": "audioop.findfactor()", "path": "library/audioop#audioop.findfactor", "type": "Multimedia", "text": ["Return a factor F such that rms(add(fragment, mul(reference, -F))) is minimal, i.e., return the factor with which you should multiply reference to make it match as well as possible to fragment. The fragments should both contain 2-byte samples.", "The time taken by this routine is proportional to len(fragment)."]}, {"name": "audioop.findfit()", "path": "library/audioop#audioop.findfit", "type": "Multimedia", "text": ["Try to match reference as well as possible to a portion of fragment (which should be the longer fragment). This is (conceptually) done by taking slices out of fragment, using findfactor() to compute the best match, and minimizing the result. The fragments should both contain 2-byte samples. Return a tuple (offset, factor) where offset is the (integer) offset into fragment where the optimal match started and factor is the (floating-point) factor as per findfactor()."]}, {"name": "audioop.findmax()", "path": "library/audioop#audioop.findmax", "type": "Multimedia", "text": ["Search fragment for a slice of length length samples (not bytes!) with maximum energy, i.e., return i for which rms(fragment[i*2:(i+length)*2]) is maximal. The fragments should both contain 2-byte samples.", "The routine takes time proportional to len(fragment)."]}, {"name": "audioop.getsample()", "path": "library/audioop#audioop.getsample", "type": "Multimedia", "text": ["Return the value of sample index from the fragment."]}, {"name": "audioop.lin2adpcm()", "path": "library/audioop#audioop.lin2adpcm", "type": "Multimedia", "text": ["Convert samples to 4 bit Intel/DVI ADPCM encoding. ADPCM coding is an adaptive coding scheme, whereby each 4 bit number is the difference between one sample and the next, divided by a (varying) step. The Intel/DVI ADPCM algorithm has been selected for use by the IMA, so it may well become a standard.", "state is a tuple containing the state of the coder. The coder returns a tuple (adpcmfrag, newstate), and the newstate should be passed to the next call of lin2adpcm(). In the initial call, None can be passed as the state. adpcmfrag is the ADPCM coded fragment packed 2 4-bit values per byte."]}, {"name": "audioop.lin2alaw()", "path": "library/audioop#audioop.lin2alaw", "type": "Multimedia", "text": ["Convert samples in the audio fragment to a-LAW encoding and return this as a bytes object. a-LAW is an audio encoding format whereby you get a dynamic range of about 13 bits using only 8 bit samples. It is used by the Sun audio hardware, among others."]}, {"name": "audioop.lin2lin()", "path": "library/audioop#audioop.lin2lin", "type": "Multimedia", "text": ["Convert samples between 1-, 2-, 3- and 4-byte formats.", "Note", "In some audio formats, such as .WAV files, 16, 24 and 32 bit samples are signed, but 8 bit samples are unsigned. So when converting to 8 bit wide samples for these formats, you need to also add 128 to the result:", "The same, in reverse, has to be applied when converting from 8 to 16, 24 or 32 bit width samples."]}, {"name": "audioop.lin2ulaw()", "path": "library/audioop#audioop.lin2ulaw", "type": "Multimedia", "text": ["Convert samples in the audio fragment to u-LAW encoding and return this as a bytes object. u-LAW is an audio encoding format whereby you get a dynamic range of about 14 bits using only 8 bit samples. It is used by the Sun audio hardware, among others."]}, {"name": "audioop.max()", "path": "library/audioop#audioop.max", "type": "Multimedia", "text": ["Return the maximum of the absolute value of all samples in a fragment."]}, {"name": "audioop.maxpp()", "path": "library/audioop#audioop.maxpp", "type": "Multimedia", "text": ["Return the maximum peak-peak value in the sound fragment."]}, {"name": "audioop.minmax()", "path": "library/audioop#audioop.minmax", "type": "Multimedia", "text": ["Return a tuple consisting of the minimum and maximum values of all samples in the sound fragment."]}, {"name": "audioop.mul()", "path": "library/audioop#audioop.mul", "type": "Multimedia", "text": ["Return a fragment that has all samples in the original fragment multiplied by the floating-point value factor. Samples are truncated in case of overflow."]}, {"name": "audioop.ratecv()", "path": "library/audioop#audioop.ratecv", "type": "Multimedia", "text": ["Convert the frame rate of the input fragment.", "state is a tuple containing the state of the converter. The converter returns a tuple (newfragment, newstate), and newstate should be passed to the next call of ratecv(). The initial call should pass None as the state.", "The weightA and weightB arguments are parameters for a simple digital filter and default to 1 and 0 respectively."]}, {"name": "audioop.reverse()", "path": "library/audioop#audioop.reverse", "type": "Multimedia", "text": ["Reverse the samples in a fragment and returns the modified fragment."]}, {"name": "audioop.rms()", "path": "library/audioop#audioop.rms", "type": "Multimedia", "text": ["Return the root-mean-square of the fragment, i.e. sqrt(sum(S_i^2)/n).", "This is a measure of the power in an audio signal."]}, {"name": "audioop.tomono()", "path": "library/audioop#audioop.tomono", "type": "Multimedia", "text": ["Convert a stereo fragment to a mono fragment. The left channel is multiplied by lfactor and the right channel by rfactor before adding the two channels to give a mono signal."]}, {"name": "audioop.tostereo()", "path": "library/audioop#audioop.tostereo", "type": "Multimedia", "text": ["Generate a stereo fragment from a mono fragment. Each pair of samples in the stereo fragment are computed from the mono sample, whereby left channel samples are multiplied by lfactor and right channel samples by rfactor."]}, {"name": "audioop.ulaw2lin()", "path": "library/audioop#audioop.ulaw2lin", "type": "Multimedia", "text": ["Convert sound fragments in u-LAW encoding to linearly encoded sound fragments. u-LAW encoding always uses 8 bits samples, so width refers only to the sample width of the output fragment here."]}, {"name": "Audit events table", "path": "library/audit_events", "type": "Debugging & Profiling", "text": ["This table contains all events raised by sys.audit() or PySys_Audit() calls throughout the CPython runtime and the standard library. These calls were added in 3.8.0 or later.", "See sys.addaudithook() and PySys_AddAuditHook() for information on handling these events.", "CPython implementation detail: This table is generated from the CPython documentation, and may not represent events raised by other implementations. See your runtime specific documentation for actual events raised.", "Audit event", "Arguments", "References", "array.__new__", "typecode, initializer", "[1]", "builtins.breakpoint", "breakpointhook", "[1]", "builtins.id", "id", "[1]", "builtins.input", "prompt", "[1]", "builtins.input/result", "result", "[1]", "code.__new__", "code, filename, name, argcount, posonlyargcount, kwonlyargcount, nlocals, stacksize, flags", "[1]", "compile", "source, filename", "[1]", "cpython.PyInterpreterState_Clear", "[1]", "cpython.PyInterpreterState_New", "[1]", "cpython._PySys_ClearAuditHooks", "[1]", "cpython.run_command", "command", "[1]", "cpython.run_file", "filename", "[1]", "cpython.run_interactivehook", "hook", "[1]", "cpython.run_module", "module-name", "[1]", "cpython.run_startup", "filename", "[1]", "cpython.run_stdin", "[1]", "ctypes.addressof", "obj", "[1]", "ctypes.call_function", "func_pointer, arguments", "[1]", "ctypes.cdata", "address", "[1]", "ctypes.cdata/buffer", "pointer, size, offset", "[1][2]", "ctypes.create_string_buffer", "init, size", "[1]", "ctypes.create_unicode_buffer", "init, size", "[1]", "ctypes.dlopen", "name", "[1]", "ctypes.dlsym", "library, name", "[1]", "ctypes.dlsym/handle", "handle, name", "[1]", "ctypes.get_errno", "[1]", "ctypes.get_last_error", "[1]", "ctypes.seh_exception", "code", "[1]", "ctypes.set_errno", "errno", "[1]", "ctypes.set_last_error", "error", "[1]", "ctypes.string_at", "address, size", "[1]", "ctypes.wstring_at", "address, size", "[1]", "ensurepip.bootstrap", "root", "[1]", "exec", "code_object", "[1][2]", "fcntl.fcntl", "fd, cmd, arg", "[1]", "fcntl.flock", "fd, operation", "[1]", "fcntl.ioctl", "fd, request, arg", "[1]", "fcntl.lockf", "fd, cmd, len, start, whence", "[1]", "ftplib.connect", "self, host, port", "[1]", "ftplib.sendcmd", "self, cmd", "[1][2]", "function.__new__", "code", "[1]", "gc.get_objects", "generation", "[1]", "gc.get_referents", "objs", "[1]", "gc.get_referrers", "objs", "[1]", "glob.glob", "pathname, recursive", "[1][2]", "imaplib.open", "self, host, port", "[1]", "imaplib.send", "self, data", "[1]", "import", "module, filename, sys.path, sys.meta_path, sys.path_hooks", "[1]", "mmap.__new__", "fileno, length, access, offset", "[1]", "msvcrt.get_osfhandle", "fd", "[1]", "msvcrt.locking", "fd, mode, nbytes", "[1]", "msvcrt.open_osfhandle", "handle, flags", "[1]", "nntplib.connect", "self, host, port", "[1][2]", "nntplib.putline", "self, line", "[1][2]", "object.__delattr__", "obj, name", "[1]", "object.__getattr__", "obj, name", "[1]", "object.__setattr__", "obj, name, value", "[1]", "open", "file, mode, flags", "[1][2][3]", "os.add_dll_directory", "path", "[1]", "os.chdir", "path", "[1][2]", "os.chflags", "path, flags", "[1][2]", "os.chmod", "path, mode, dir_fd", "[1][2][3]", "os.chown", "path, uid, gid, dir_fd", "[1][2][3]", "os.exec", "path, args, env", "[1]", "os.fork", "[1]", "os.forkpty", "[1]", "os.fwalk", "top, topdown, onerror, follow_symlinks, dir_fd", "[1]", "os.getxattr", "path, attribute", "[1]", "os.kill", "pid, sig", "[1]", "os.killpg", "pgid, sig", "[1]", "os.link", "src, dst, src_dir_fd, dst_dir_fd", "[1]", "os.listdir", "path", "[1]", "os.listxattr", "path", "[1]", "os.lockf", "fd, cmd, len", "[1]", "os.mkdir", "path, mode, dir_fd", "[1][2]", "os.posix_spawn", "path, argv, env", "[1][2]", "os.putenv", "key, value", "[1]", "os.remove", "path, dir_fd", "[1][2][3]", "os.removexattr", "path, attribute", "[1]", "os.rename", "src, dst, src_dir_fd, dst_dir_fd", "[1][2][3]", "os.rmdir", "path, dir_fd", "[1]", "os.scandir", "path", "[1]", "os.setxattr", "path, attribute, value, flags", "[1]", "os.spawn", "mode, path, args, env", "[1]", "os.startfile", "path, operation", "[1]", "os.symlink", "src, dst, dir_fd", "[1]", "os.system", "command", "[1]", "os.truncate", "fd, length", "[1][2]", "os.unsetenv", "key", "[1]", "os.utime", "path, times, ns, dir_fd", "[1]", "os.walk", "top, topdown, onerror, followlinks", "[1]", "pathlib.Path.glob", "self, pattern", "[1]", "pathlib.Path.rglob", "self, pattern", "[1]", "pdb.Pdb", "[1]", "pickle.find_class", "module, name", "[1]", "poplib.connect", "self, host, port", "[1][2]", "poplib.putline", "self, line", "[1][2]", "pty.spawn", "argv", "[1]", "resource.prlimit", "pid, resource, limits", "[1]", "resource.setrlimit", "resource, limits", "[1]", "setopencodehook", "[1]", "shutil.chown", "path, user, group", "[1]", "shutil.copyfile", "src, dst", "[1][2][3]", "shutil.copymode", "src, dst", "[1][2]", "shutil.copystat", "src, dst", "[1][2]", "shutil.copytree", "src, dst", "[1]", "shutil.make_archive", "base_name, format, root_dir, base_dir", "[1]", "shutil.move", "src, dst", "[1]", "shutil.rmtree", "path", "[1]", "shutil.unpack_archive", "filename, extract_dir, format", "[1]", "signal.pthread_kill", "thread_id, signalnum", "[1]", "smtplib.connect", "self, host, port", "[1]", "smtplib.send", "self, data", "[1]", "socket.__new__", "self, family, type, protocol", "[1]", "socket.bind", "self, address", "[1]", "socket.connect", "self, address", "[1][2]", "socket.getaddrinfo", "host, port, family, type, protocol", "[1]", "socket.gethostbyaddr", "ip_address", "[1]", "socket.gethostbyname", "hostname", "[1][2]", "socket.gethostname", "[1]", "socket.getnameinfo", "sockaddr", "[1]", "socket.getservbyname", "servicename, protocolname", "[1]", "socket.getservbyport", "port, protocolname", "[1]", "socket.sendmsg", "self, address", "[1]", "socket.sendto", "self, address", "[1]", "socket.sethostname", "name", "[1]", "sqlite3.connect", "database", "[1]", "subprocess.Popen", "executable, args, cwd, env", "[1]", "sys._current_frames", "[1]", "sys._getframe", "[1]", "sys.addaudithook", "[1][2]", "sys.excepthook", "hook, type, value, traceback", "[1]", "sys.set_asyncgen_hooks_finalizer", "[1]", "sys.set_asyncgen_hooks_firstiter", "[1]", "sys.setprofile", "[1]", "sys.settrace", "[1]", "sys.unraisablehook", "hook, unraisable", "[1]", "syslog.closelog", "[1]", "syslog.openlog", "ident, logoption, facility", "[1]", "syslog.setlogmask", "maskpri", "[1]", "syslog.syslog", "priority, message", "[1]", "telnetlib.Telnet.open", "self, host, port", "[1]", "telnetlib.Telnet.write", "self, buffer", "[1]", "tempfile.mkdtemp", "fullpath", "[1][2]", "tempfile.mkstemp", "fullpath", "[1][2][3]", "urllib.Request", "fullurl, data, headers, method", "[1]", "webbrowser.open", "url", "[1]", "winreg.ConnectRegistry", "computer_name, key", "[1]", "winreg.CreateKey", "key, sub_key, access", "[1][2]", "winreg.DeleteKey", "key, sub_key, access", "[1][2]", "winreg.DeleteValue", "key, value", "[1]", "winreg.DisableReflectionKey", "key", "[1]", "winreg.EnableReflectionKey", "key", "[1]", "winreg.EnumKey", "key, index", "[1]", "winreg.EnumValue", "key, index", "[1]", "winreg.ExpandEnvironmentStrings", "str", "[1]", "winreg.LoadKey", "key, sub_key, file_name", "[1]", "winreg.OpenKey", "key, sub_key, access", "[1]", "winreg.OpenKey/result", "key", "[1][2][3]", "winreg.PyHKEY.Detach", "key", "[1]", "winreg.QueryInfoKey", "key", "[1]", "winreg.QueryReflectionKey", "key", "[1]", "winreg.QueryValue", "key, sub_key, value_name", "[1][2]", "winreg.SaveKey", "key, file_name", "[1]", "winreg.SetValue", "key, sub_key, type, value", "[1][2]", "The following events are raised internally and do not correspond to any public API of CPython:", "Audit event", "Arguments", "_winapi.CreateFile", "file_name, desired_access, share_mode, creation_disposition, flags_and_attributes", "_winapi.CreateJunction", "src_path, dst_path", "_winapi.CreateNamedPipe", "name, open_mode, pipe_mode", "_winapi.CreatePipe", "_winapi.CreateProcess", "application_name, command_line, current_directory", "_winapi.OpenProcess", "process_id, desired_access", "_winapi.TerminateProcess", "handle, exit_code", "ctypes.PyObj_FromPtr", "obj"]}, {"name": "base64", "path": "library/base64", "type": "Internet Data", "text": ["Source code: Lib/base64.py", "This module provides functions for encoding binary data to printable ASCII characters and decoding such encodings back to binary data. It provides encoding and decoding functions for the encodings specified in RFC 3548, which defines the Base16, Base32, and Base64 algorithms, and for the de-facto standard Ascii85 and Base85 encodings.", "The RFC 3548 encodings are suitable for encoding binary data so that it can safely sent by email, used as parts of URLs, or included as part of an HTTP POST request. The encoding algorithm is not the same as the uuencode program.", "There are two interfaces provided by this module. The modern interface supports encoding bytes-like objects to ASCII bytes, and decoding bytes-like objects or strings containing ASCII to bytes. Both base-64 alphabets defined in RFC 3548 (normal, and URL- and filesystem-safe) are supported.", "The legacy interface does not support decoding from strings, but it does provide functions for encoding and decoding to and from file objects. It only supports the Base64 standard alphabet, and it adds newlines every 76 characters as per RFC 2045. Note that if you are looking for RFC 2045 support you probably want to be looking at the email package instead.", "Changed in version 3.3: ASCII-only Unicode strings are now accepted by the decoding functions of the modern interface.", "Changed in version 3.4: Any bytes-like objects are now accepted by all encoding and decoding functions in this module. Ascii85/Base85 support added.", "The modern interface provides:", "Encode the bytes-like object s using Base64 and return the encoded bytes.", "Optional altchars must be a bytes-like object of at least length 2 (additional characters are ignored) which specifies an alternative alphabet for the + and / characters. This allows an application to e.g. generate URL or filesystem safe Base64 strings. The default is None, for which the standard Base64 alphabet is used.", "Decode the Base64 encoded bytes-like object or ASCII string s and return the decoded bytes.", "Optional altchars must be a bytes-like object or ASCII string of at least length 2 (additional characters are ignored) which specifies the alternative alphabet used instead of the + and / characters.", "A binascii.Error exception is raised if s is incorrectly padded.", "If validate is False (the default), characters that are neither in the normal base-64 alphabet nor the alternative alphabet are discarded prior to the padding check. If validate is True, these non-alphabet characters in the input result in a binascii.Error.", "Encode bytes-like object s using the standard Base64 alphabet and return the encoded bytes.", "Decode bytes-like object or ASCII string s using the standard Base64 alphabet and return the decoded bytes.", "Encode bytes-like object s using the URL- and filesystem-safe alphabet, which substitutes - instead of + and _ instead of / in the standard Base64 alphabet, and return the encoded bytes. The result can still contain =.", "Decode bytes-like object or ASCII string s using the URL- and filesystem-safe alphabet, which substitutes - instead of + and _ instead of / in the standard Base64 alphabet, and return the decoded bytes.", "Encode the bytes-like object s using Base32 and return the encoded bytes.", "Decode the Base32 encoded bytes-like object or ASCII string s and return the decoded bytes.", "Optional casefold is a flag specifying whether a lowercase alphabet is acceptable as input. For security purposes, the default is False.", "RFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O (oh), and for optional mapping of the digit 1 (one) to either the letter I (eye) or letter L (el). The optional argument map01 when not None, specifies which letter the digit 1 should be mapped to (when map01 is not None, the digit 0 is always mapped to the letter O). For security purposes the default is None, so that 0 and 1 are not allowed in the input.", "A binascii.Error is raised if s is incorrectly padded or if there are non-alphabet characters present in the input.", "Encode the bytes-like object s using Base16 and return the encoded bytes.", "Decode the Base16 encoded bytes-like object or ASCII string s and return the decoded bytes.", "Optional casefold is a flag specifying whether a lowercase alphabet is acceptable as input. For security purposes, the default is False.", "A binascii.Error is raised if s is incorrectly padded or if there are non-alphabet characters present in the input.", "Encode the bytes-like object b using Ascii85 and return the encoded bytes.", "foldspaces is an optional flag that uses the special short sequence \u2018y\u2019 instead of 4 consecutive spaces (ASCII 0x20) as supported by \u2018btoa\u2019. This feature is not supported by the \u201cstandard\u201d Ascii85 encoding.", "wrapcol controls whether the output should have newline (b'\\n') characters added to it. If this is non-zero, each output line will be at most this many characters long.", "pad controls whether the input is padded to a multiple of 4 before encoding. Note that the btoa implementation always pads.", "adobe controls whether the encoded byte sequence is framed with <~ and ~>, which is used by the Adobe implementation.", "New in version 3.4.", "Decode the Ascii85 encoded bytes-like object or ASCII string b and return the decoded bytes.", "foldspaces is a flag that specifies whether the \u2018y\u2019 short sequence should be accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is not supported by the \u201cstandard\u201d Ascii85 encoding.", "adobe controls whether the input sequence is in Adobe Ascii85 format (i.e. is framed with <~ and ~>).", "ignorechars should be a bytes-like object or ASCII string containing characters to ignore from the input. This should only contain whitespace characters, and by default contains all whitespace characters in ASCII.", "New in version 3.4.", "Encode the bytes-like object b using base85 (as used in e.g. git-style binary diffs) and return the encoded bytes.", "If pad is true, the input is padded with b'\\0' so its length is a multiple of 4 bytes before encoding.", "New in version 3.4.", "Decode the base85-encoded bytes-like object or ASCII string b and return the decoded bytes. Padding is implicitly removed, if necessary.", "New in version 3.4.", "The legacy interface:", "Decode the contents of the binary input file and write the resulting binary data to the output file. input and output must be file objects. input will be read until input.readline() returns an empty bytes object.", "Decode the bytes-like object s, which must contain one or more lines of base64 encoded data, and return the decoded bytes.", "New in version 3.1.", "Encode the contents of the binary input file and write the resulting base64 encoded data to the output file. input and output must be file objects. input will be read until input.read() returns an empty bytes object. encode() inserts a newline character (b'\\n') after every 76 bytes of the output, as well as ensuring that the output always ends with a newline, as per RFC 2045 (MIME).", "Encode the bytes-like object s, which can contain arbitrary binary data, and return bytes containing the base64-encoded data, with newlines (b'\\n') inserted after every 76 bytes of output, and ensuring that there is a trailing newline, as per RFC 2045 (MIME).", "New in version 3.1.", "An example usage of the module:", "See also", "Support module containing ASCII-to-binary and binary-to-ASCII conversions.", "Section 5.2, \u201cBase64 Content-Transfer-Encoding,\u201d provides the definition of the base64 encoding."]}, {"name": "base64.a85decode()", "path": "library/base64#base64.a85decode", "type": "Internet Data", "text": ["Decode the Ascii85 encoded bytes-like object or ASCII string b and return the decoded bytes.", "foldspaces is a flag that specifies whether the \u2018y\u2019 short sequence should be accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is not supported by the \u201cstandard\u201d Ascii85 encoding.", "adobe controls whether the input sequence is in Adobe Ascii85 format (i.e. is framed with <~ and ~>).", "ignorechars should be a bytes-like object or ASCII string containing characters to ignore from the input. This should only contain whitespace characters, and by default contains all whitespace characters in ASCII.", "New in version 3.4."]}, {"name": "base64.a85encode()", "path": "library/base64#base64.a85encode", "type": "Internet Data", "text": ["Encode the bytes-like object b using Ascii85 and return the encoded bytes.", "foldspaces is an optional flag that uses the special short sequence \u2018y\u2019 instead of 4 consecutive spaces (ASCII 0x20) as supported by \u2018btoa\u2019. This feature is not supported by the \u201cstandard\u201d Ascii85 encoding.", "wrapcol controls whether the output should have newline (b'\\n') characters added to it. If this is non-zero, each output line will be at most this many characters long.", "pad controls whether the input is padded to a multiple of 4 before encoding. Note that the btoa implementation always pads.", "adobe controls whether the encoded byte sequence is framed with <~ and ~>, which is used by the Adobe implementation.", "New in version 3.4."]}, {"name": "base64.b16decode()", "path": "library/base64#base64.b16decode", "type": "Internet Data", "text": ["Decode the Base16 encoded bytes-like object or ASCII string s and return the decoded bytes.", "Optional casefold is a flag specifying whether a lowercase alphabet is acceptable as input. For security purposes, the default is False.", "A binascii.Error is raised if s is incorrectly padded or if there are non-alphabet characters present in the input."]}, {"name": "base64.b16encode()", "path": "library/base64#base64.b16encode", "type": "Internet Data", "text": ["Encode the bytes-like object s using Base16 and return the encoded bytes."]}, {"name": "base64.b32decode()", "path": "library/base64#base64.b32decode", "type": "Internet Data", "text": ["Decode the Base32 encoded bytes-like object or ASCII string s and return the decoded bytes.", "Optional casefold is a flag specifying whether a lowercase alphabet is acceptable as input. For security purposes, the default is False.", "RFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O (oh), and for optional mapping of the digit 1 (one) to either the letter I (eye) or letter L (el). The optional argument map01 when not None, specifies which letter the digit 1 should be mapped to (when map01 is not None, the digit 0 is always mapped to the letter O). For security purposes the default is None, so that 0 and 1 are not allowed in the input.", "A binascii.Error is raised if s is incorrectly padded or if there are non-alphabet characters present in the input."]}, {"name": "base64.b32encode()", "path": "library/base64#base64.b32encode", "type": "Internet Data", "text": ["Encode the bytes-like object s using Base32 and return the encoded bytes."]}, {"name": "base64.b64decode()", "path": "library/base64#base64.b64decode", "type": "Internet Data", "text": ["Decode the Base64 encoded bytes-like object or ASCII string s and return the decoded bytes.", "Optional altchars must be a bytes-like object or ASCII string of at least length 2 (additional characters are ignored) which specifies the alternative alphabet used instead of the + and / characters.", "A binascii.Error exception is raised if s is incorrectly padded.", "If validate is False (the default), characters that are neither in the normal base-64 alphabet nor the alternative alphabet are discarded prior to the padding check. If validate is True, these non-alphabet characters in the input result in a binascii.Error."]}, {"name": "base64.b64encode()", "path": "library/base64#base64.b64encode", "type": "Internet Data", "text": ["Encode the bytes-like object s using Base64 and return the encoded bytes.", "Optional altchars must be a bytes-like object of at least length 2 (additional characters are ignored) which specifies an alternative alphabet for the + and / characters. This allows an application to e.g. generate URL or filesystem safe Base64 strings. The default is None, for which the standard Base64 alphabet is used."]}, {"name": "base64.b85decode()", "path": "library/base64#base64.b85decode", "type": "Internet Data", "text": ["Decode the base85-encoded bytes-like object or ASCII string b and return the decoded bytes. Padding is implicitly removed, if necessary.", "New in version 3.4."]}, {"name": "base64.b85encode()", "path": "library/base64#base64.b85encode", "type": "Internet Data", "text": ["Encode the bytes-like object b using base85 (as used in e.g. git-style binary diffs) and return the encoded bytes.", "If pad is true, the input is padded with b'\\0' so its length is a multiple of 4 bytes before encoding.", "New in version 3.4."]}, {"name": "base64.decode()", "path": "library/base64#base64.decode", "type": "Internet Data", "text": ["Decode the contents of the binary input file and write the resulting binary data to the output file. input and output must be file objects. input will be read until input.readline() returns an empty bytes object."]}, {"name": "base64.decodebytes()", "path": "library/base64#base64.decodebytes", "type": "Internet Data", "text": ["Decode the bytes-like object s, which must contain one or more lines of base64 encoded data, and return the decoded bytes.", "New in version 3.1."]}, {"name": "base64.encode()", "path": "library/base64#base64.encode", "type": "Internet Data", "text": ["Encode the contents of the binary input file and write the resulting base64 encoded data to the output file. input and output must be file objects. input will be read until input.read() returns an empty bytes object. encode() inserts a newline character (b'\\n') after every 76 bytes of the output, as well as ensuring that the output always ends with a newline, as per RFC 2045 (MIME)."]}, {"name": "base64.encodebytes()", "path": "library/base64#base64.encodebytes", "type": "Internet Data", "text": ["Encode the bytes-like object s, which can contain arbitrary binary data, and return bytes containing the base64-encoded data, with newlines (b'\\n') inserted after every 76 bytes of output, and ensuring that there is a trailing newline, as per RFC 2045 (MIME).", "New in version 3.1."]}, {"name": "base64.standard_b64decode()", "path": "library/base64#base64.standard_b64decode", "type": "Internet Data", "text": ["Decode bytes-like object or ASCII string s using the standard Base64 alphabet and return the decoded bytes."]}, {"name": "base64.standard_b64encode()", "path": "library/base64#base64.standard_b64encode", "type": "Internet Data", "text": ["Encode bytes-like object s using the standard Base64 alphabet and return the encoded bytes."]}, {"name": "base64.urlsafe_b64decode()", "path": "library/base64#base64.urlsafe_b64decode", "type": "Internet Data", "text": ["Decode bytes-like object or ASCII string s using the URL- and filesystem-safe alphabet, which substitutes - instead of + and _ instead of / in the standard Base64 alphabet, and return the decoded bytes."]}, {"name": "base64.urlsafe_b64encode()", "path": "library/base64#base64.urlsafe_b64encode", "type": "Internet Data", "text": ["Encode bytes-like object s using the URL- and filesystem-safe alphabet, which substitutes - instead of + and _ instead of / in the standard Base64 alphabet, and return the encoded bytes. The result can still contain =."]}, {"name": "BaseException", "path": "library/exceptions#BaseException", "type": "Built-in Exceptions", "text": ["The base class for all built-in exceptions. It is not meant to be directly inherited by user-defined classes (for that, use Exception). If str() is called on an instance of this class, the representation of the argument(s) to the instance are returned, or the empty string when there were no arguments.", "The tuple of arguments given to the exception constructor. Some built-in exceptions (like OSError) expect a certain number of arguments and assign a special meaning to the elements of this tuple, while others are usually called only with a single string giving an error message.", "This method sets tb as the new traceback for the exception and returns the exception object. It is usually used in exception handling code like this:"]}, {"name": "BaseException.args", "path": "library/exceptions#BaseException.args", "type": "Built-in Exceptions", "text": ["The tuple of arguments given to the exception constructor. Some built-in exceptions (like OSError) expect a certain number of arguments and assign a special meaning to the elements of this tuple, while others are usually called only with a single string giving an error message."]}, {"name": "BaseException.with_traceback()", "path": "library/exceptions#BaseException.with_traceback", "type": "Built-in Exceptions", "text": ["This method sets tb as the new traceback for the exception and returns the exception object. It is usually used in exception handling code like this:"]}, {"name": "bdb", "path": "library/bdb", "type": "Debugging & Profiling", "text": ["Source code: Lib/bdb.py", "The bdb module handles basic debugger functions, like setting breakpoints or managing execution via the debugger.", "The following exception is defined:", "Exception raised by the Bdb class for quitting the debugger.", "The bdb module also defines two classes:", "This class implements temporary breakpoints, ignore counts, disabling and (re-)enabling, and conditionals.", "Breakpoints are indexed by number through a list called bpbynumber and by (file, line) pairs through bplist. The former points to a single instance of class Breakpoint. The latter points to a list of such instances since there may be more than one breakpoint per line.", "When creating a breakpoint, its associated filename should be in canonical form. If a funcname is defined, a breakpoint hit will be counted when the first line of that function is executed. A conditional breakpoint always counts a hit.", "Breakpoint instances have the following methods:", "Delete the breakpoint from the list associated to a file/line. If it is the last breakpoint in that position, it also deletes the entry for the file/line.", "Mark the breakpoint as enabled.", "Mark the breakpoint as disabled.", "Return a string with all the information about the breakpoint, nicely formatted:", "New in version 3.2.", "Print the output of bpformat() to the file out, or if it is None, to standard output.", "The Bdb class acts as a generic Python debugger base class.", "This class takes care of the details of the trace facility; a derived class should implement user interaction. The standard debugger class (pdb.Pdb) is an example.", "The skip argument, if given, must be an iterable of glob-style module name patterns. The debugger will not step into frames that originate in a module that matches one of these patterns. Whether a frame is considered to originate in a certain module is determined by the __name__ in the frame globals.", "New in version 3.1: The skip argument.", "The following methods of Bdb normally don\u2019t need to be overridden.", "Auxiliary method for getting a filename in a canonical form, that is, as a case-normalized (on case-insensitive filesystems) absolute path, stripped of surrounding angle brackets.", "Set the botframe, stopframe, returnframe and quitting attributes with values ready to start debugging.", "This function is installed as the trace function of debugged frames. Its return value is the new trace function (in most cases, that is, itself).", "The default implementation decides how to dispatch a frame, depending on the type of event (passed as a string) that is about to be executed. event can be one of the following:", "For the Python events, specialized functions (see below) are called. For the C events, no action is taken.", "The arg parameter depends on the previous event.", "See the documentation for sys.settrace() for more information on the trace function. For more information on code and frame objects, refer to The standard type hierarchy.", "If the debugger should stop on the current line, invoke the user_line() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_line()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "If the debugger should stop on this function call, invoke the user_call() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_call()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "If the debugger should stop on this function return, invoke the user_return() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_return()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "If the debugger should stop at this exception, invokes the user_exception() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_exception()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "Normally derived classes don\u2019t override the following methods, but they may if they want to redefine the definition of stopping and breakpoints.", "This method checks if the frame is somewhere below botframe in the call stack. botframe is the frame in which debugging started.", "This method checks if there is a breakpoint in the filename and line belonging to frame or, at least, in the current function. If the breakpoint is a temporary one, this method deletes it.", "This method checks if there is a breakpoint in the filename of the current frame.", "Derived classes should override these methods to gain control over debugger operation.", "This method is called from dispatch_call() when there is the possibility that a break might be necessary anywhere inside the called function.", "This method is called from dispatch_line() when either stop_here() or break_here() yields True.", "This method is called from dispatch_return() when stop_here() yields True.", "This method is called from dispatch_exception() when stop_here() yields True.", "Handle how a breakpoint must be removed when it is a temporary one.", "This method must be implemented by derived classes.", "Derived classes and clients can call the following methods to affect the stepping state.", "Stop after one line of code.", "Stop on the next line in or below the given frame.", "Stop when returning from the given frame.", "Stop when the line with the line no greater than the current one is reached or when returning from current frame.", "Start debugging from frame. If frame is not specified, debugging starts from caller\u2019s frame.", "Stop only at breakpoints or when finished. If there are no breakpoints, set the system trace function to None.", "Set the quitting attribute to True. This raises BdbQuit in the next call to one of the dispatch_*() methods.", "Derived classes and clients can call the following methods to manipulate breakpoints. These methods return a string containing an error message if something went wrong, or None if all is well.", "Set a new breakpoint. If the lineno line doesn\u2019t exist for the filename passed as argument, return an error message. The filename should be in canonical form, as described in the canonic() method.", "Delete the breakpoints in filename and lineno. If none were set, an error message is returned.", "Delete the breakpoint which has the index arg in the Breakpoint.bpbynumber. If arg is not numeric or out of range, return an error message.", "Delete all breakpoints in filename. If none were set, an error message is returned.", "Delete all existing breakpoints.", "Return a breakpoint specified by the given number. If arg is a string, it will be converted to a number. If arg is a non-numeric string, if the given breakpoint never existed or has been deleted, a ValueError is raised.", "New in version 3.2.", "Check if there is a breakpoint for lineno of filename.", "Return all breakpoints for lineno in filename, or an empty list if none are set.", "Return all breakpoints in filename, or an empty list if none are set.", "Return all breakpoints that are set.", "Derived classes and clients can call the following methods to get a data structure representing a stack trace.", "Get a list of records for a frame and all higher (calling) and lower frames, and the size of the higher part.", "Return a string with information about a stack entry, identified by a (frame, lineno) tuple:", "The following two methods can be called by clients to use a debugger to debug a statement, given as a string.", "Debug a statement executed via the exec() function. globals defaults to __main__.__dict__, locals defaults to globals.", "Debug an expression executed via the eval() function. globals and locals have the same meaning as in run().", "For backwards compatibility. Calls the run() method.", "Debug a single function call, and return its result.", "Finally, the module defines the following functions:", "Check whether we should break here, depending on the way the breakpoint b was set.", "If it was set via line number, it checks if b.line is the same as the one in the frame also passed as argument. If the breakpoint was set via function name, we have to check we are in the right frame (the right function) and if we are in its first executable line.", "Determine if there is an effective (active) breakpoint at this line of code. Return a tuple of the breakpoint and a boolean that indicates if it is ok to delete a temporary breakpoint. Return (None, None) if there is no matching breakpoint.", "Start debugging with a Bdb instance from caller\u2019s frame."]}, {"name": "bdb.Bdb", "path": "library/bdb#bdb.Bdb", "type": "Debugging & Profiling", "text": ["The Bdb class acts as a generic Python debugger base class.", "This class takes care of the details of the trace facility; a derived class should implement user interaction. The standard debugger class (pdb.Pdb) is an example.", "The skip argument, if given, must be an iterable of glob-style module name patterns. The debugger will not step into frames that originate in a module that matches one of these patterns. Whether a frame is considered to originate in a certain module is determined by the __name__ in the frame globals.", "New in version 3.1: The skip argument.", "The following methods of Bdb normally don\u2019t need to be overridden.", "Auxiliary method for getting a filename in a canonical form, that is, as a case-normalized (on case-insensitive filesystems) absolute path, stripped of surrounding angle brackets.", "Set the botframe, stopframe, returnframe and quitting attributes with values ready to start debugging.", "This function is installed as the trace function of debugged frames. Its return value is the new trace function (in most cases, that is, itself).", "The default implementation decides how to dispatch a frame, depending on the type of event (passed as a string) that is about to be executed. event can be one of the following:", "For the Python events, specialized functions (see below) are called. For the C events, no action is taken.", "The arg parameter depends on the previous event.", "See the documentation for sys.settrace() for more information on the trace function. For more information on code and frame objects, refer to The standard type hierarchy.", "If the debugger should stop on the current line, invoke the user_line() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_line()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "If the debugger should stop on this function call, invoke the user_call() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_call()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "If the debugger should stop on this function return, invoke the user_return() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_return()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "If the debugger should stop at this exception, invokes the user_exception() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_exception()). Return a reference to the trace_dispatch() method for further tracing in that scope.", "Normally derived classes don\u2019t override the following methods, but they may if they want to redefine the definition of stopping and breakpoints.", "This method checks if the frame is somewhere below botframe in the call stack. botframe is the frame in which debugging started.", "This method checks if there is a breakpoint in the filename and line belonging to frame or, at least, in the current function. If the breakpoint is a temporary one, this method deletes it.", "This method checks if there is a breakpoint in the filename of the current frame.", "Derived classes should override these methods to gain control over debugger operation.", "This method is called from dispatch_call() when there is the possibility that a break might be necessary anywhere inside the called function.", "This method is called from dispatch_line() when either stop_here() or break_here() yields True.", "This method is called from dispatch_return() when stop_here() yields True.", "This method is called from dispatch_exception() when stop_here() yields True.", "Handle how a breakpoint must be removed when it is a temporary one.", "This method must be implemented by derived classes.", "Derived classes and clients can call the following methods to affect the stepping state.", "Stop after one line of code.", "Stop on the next line in or below the given frame.", "Stop when returning from the given frame.", "Stop when the line with the line no greater than the current one is reached or when returning from current frame.", "Start debugging from frame. If frame is not specified, debugging starts from caller\u2019s frame.", "Stop only at breakpoints or when finished. If there are no breakpoints, set the system trace function to None.", "Set the quitting attribute to True. This raises BdbQuit in the next call to one of the dispatch_*() methods.", "Derived classes and clients can call the following methods to manipulate breakpoints. These methods return a string containing an error message if something went wrong, or None if all is well.", "Set a new breakpoint. If the lineno line doesn\u2019t exist for the filename passed as argument, return an error message. The filename should be in canonical form, as described in the canonic() method.", "Delete the breakpoints in filename and lineno. If none were set, an error message is returned.", "Delete the breakpoint which has the index arg in the Breakpoint.bpbynumber. If arg is not numeric or out of range, return an error message.", "Delete all breakpoints in filename. If none were set, an error message is returned.", "Delete all existing breakpoints.", "Return a breakpoint specified by the given number. If arg is a string, it will be converted to a number. If arg is a non-numeric string, if the given breakpoint never existed or has been deleted, a ValueError is raised.", "New in version 3.2.", "Check if there is a breakpoint for lineno of filename.", "Return all breakpoints for lineno in filename, or an empty list if none are set.", "Return all breakpoints in filename, or an empty list if none are set.", "Return all breakpoints that are set.", "Derived classes and clients can call the following methods to get a data structure representing a stack trace.", "Get a list of records for a frame and all higher (calling) and lower frames, and the size of the higher part.", "Return a string with information about a stack entry, identified by a (frame, lineno) tuple:", "The following two methods can be called by clients to use a debugger to debug a statement, given as a string.", "Debug a statement executed via the exec() function. globals defaults to __main__.__dict__, locals defaults to globals.", "Debug an expression executed via the eval() function. globals and locals have the same meaning as in run().", "For backwards compatibility. Calls the run() method.", "Debug a single function call, and return its result."]}, {"name": "bdb.Bdb.break_anywhere()", "path": "library/bdb#bdb.Bdb.break_anywhere", "type": "Debugging & Profiling", "text": ["This method checks if there is a breakpoint in the filename of the current frame."]}, {"name": "bdb.Bdb.break_here()", "path": "library/bdb#bdb.Bdb.break_here", "type": "Debugging & Profiling", "text": ["This method checks if there is a breakpoint in the filename and line belonging to frame or, at least, in the current function. If the breakpoint is a temporary one, this method deletes it."]}, {"name": "bdb.Bdb.canonic()", "path": "library/bdb#bdb.Bdb.canonic", "type": "Debugging & Profiling", "text": ["Auxiliary method for getting a filename in a canonical form, that is, as a case-normalized (on case-insensitive filesystems) absolute path, stripped of surrounding angle brackets."]}, {"name": "bdb.Bdb.clear_all_breaks()", "path": "library/bdb#bdb.Bdb.clear_all_breaks", "type": "Debugging & Profiling", "text": ["Delete all existing breakpoints."]}, {"name": "bdb.Bdb.clear_all_file_breaks()", "path": "library/bdb#bdb.Bdb.clear_all_file_breaks", "type": "Debugging & Profiling", "text": ["Delete all breakpoints in filename. If none were set, an error message is returned."]}, {"name": "bdb.Bdb.clear_bpbynumber()", "path": "library/bdb#bdb.Bdb.clear_bpbynumber", "type": "Debugging & Profiling", "text": ["Delete the breakpoint which has the index arg in the Breakpoint.bpbynumber. If arg is not numeric or out of range, return an error message."]}, {"name": "bdb.Bdb.clear_break()", "path": "library/bdb#bdb.Bdb.clear_break", "type": "Debugging & Profiling", "text": ["Delete the breakpoints in filename and lineno. If none were set, an error message is returned."]}, {"name": "bdb.Bdb.dispatch_call()", "path": "library/bdb#bdb.Bdb.dispatch_call", "type": "Debugging & Profiling", "text": ["If the debugger should stop on this function call, invoke the user_call() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_call()). Return a reference to the trace_dispatch() method for further tracing in that scope."]}, {"name": "bdb.Bdb.dispatch_exception()", "path": "library/bdb#bdb.Bdb.dispatch_exception", "type": "Debugging & Profiling", "text": ["If the debugger should stop at this exception, invokes the user_exception() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_exception()). Return a reference to the trace_dispatch() method for further tracing in that scope."]}, {"name": "bdb.Bdb.dispatch_line()", "path": "library/bdb#bdb.Bdb.dispatch_line", "type": "Debugging & Profiling", "text": ["If the debugger should stop on the current line, invoke the user_line() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_line()). Return a reference to the trace_dispatch() method for further tracing in that scope."]}, {"name": "bdb.Bdb.dispatch_return()", "path": "library/bdb#bdb.Bdb.dispatch_return", "type": "Debugging & Profiling", "text": ["If the debugger should stop on this function return, invoke the user_return() method (which should be overridden in subclasses). Raise a BdbQuit exception if the Bdb.quitting flag is set (which can be set from user_return()). Return a reference to the trace_dispatch() method for further tracing in that scope."]}, {"name": "bdb.Bdb.do_clear()", "path": "library/bdb#bdb.Bdb.do_clear", "type": "Debugging & Profiling", "text": ["Handle how a breakpoint must be removed when it is a temporary one.", "This method must be implemented by derived classes."]}, {"name": "bdb.Bdb.format_stack_entry()", "path": "library/bdb#bdb.Bdb.format_stack_entry", "type": "Debugging & Profiling", "text": ["Return a string with information about a stack entry, identified by a (frame, lineno) tuple:"]}, {"name": "bdb.Bdb.get_all_breaks()", "path": "library/bdb#bdb.Bdb.get_all_breaks", "type": "Debugging & Profiling", "text": ["Return all breakpoints that are set."]}, {"name": "bdb.Bdb.get_bpbynumber()", "path": "library/bdb#bdb.Bdb.get_bpbynumber", "type": "Debugging & Profiling", "text": ["Return a breakpoint specified by the given number. If arg is a string, it will be converted to a number. If arg is a non-numeric string, if the given breakpoint never existed or has been deleted, a ValueError is raised.", "New in version 3.2."]}, {"name": "bdb.Bdb.get_break()", "path": "library/bdb#bdb.Bdb.get_break", "type": "Debugging & Profiling", "text": ["Check if there is a breakpoint for lineno of filename."]}, {"name": "bdb.Bdb.get_breaks()", "path": "library/bdb#bdb.Bdb.get_breaks", "type": "Debugging & Profiling", "text": ["Return all breakpoints for lineno in filename, or an empty list if none are set."]}, {"name": "bdb.Bdb.get_file_breaks()", "path": "library/bdb#bdb.Bdb.get_file_breaks", "type": "Debugging & Profiling", "text": ["Return all breakpoints in filename, or an empty list if none are set."]}, {"name": "bdb.Bdb.get_stack()", "path": "library/bdb#bdb.Bdb.get_stack", "type": "Debugging & Profiling", "text": ["Get a list of records for a frame and all higher (calling) and lower frames, and the size of the higher part."]}, {"name": "bdb.Bdb.reset()", "path": "library/bdb#bdb.Bdb.reset", "type": "Debugging & Profiling", "text": ["Set the botframe, stopframe, returnframe and quitting attributes with values ready to start debugging."]}, {"name": "bdb.Bdb.run()", "path": "library/bdb#bdb.Bdb.run", "type": "Debugging & Profiling", "text": ["Debug a statement executed via the exec() function. globals defaults to __main__.__dict__, locals defaults to globals."]}, {"name": "bdb.Bdb.runcall()", "path": "library/bdb#bdb.Bdb.runcall", "type": "Debugging & Profiling", "text": ["Debug a single function call, and return its result."]}, {"name": "bdb.Bdb.runctx()", "path": "library/bdb#bdb.Bdb.runctx", "type": "Debugging & Profiling", "text": ["For backwards compatibility. Calls the run() method."]}, {"name": "bdb.Bdb.runeval()", "path": "library/bdb#bdb.Bdb.runeval", "type": "Debugging & Profiling", "text": ["Debug an expression executed via the eval() function. globals and locals have the same meaning as in run()."]}, {"name": "bdb.Bdb.set_break()", "path": "library/bdb#bdb.Bdb.set_break", "type": "Debugging & Profiling", "text": ["Set a new breakpoint. If the lineno line doesn\u2019t exist for the filename passed as argument, return an error message. The filename should be in canonical form, as described in the canonic() method."]}, {"name": "bdb.Bdb.set_continue()", "path": "library/bdb#bdb.Bdb.set_continue", "type": "Debugging & Profiling", "text": ["Stop only at breakpoints or when finished. If there are no breakpoints, set the system trace function to None."]}, {"name": "bdb.Bdb.set_next()", "path": "library/bdb#bdb.Bdb.set_next", "type": "Debugging & Profiling", "text": ["Stop on the next line in or below the given frame."]}, {"name": "bdb.Bdb.set_quit()", "path": "library/bdb#bdb.Bdb.set_quit", "type": "Debugging & Profiling", "text": ["Set the quitting attribute to True. This raises BdbQuit in the next call to one of the dispatch_*() methods."]}, {"name": "bdb.Bdb.set_return()", "path": "library/bdb#bdb.Bdb.set_return", "type": "Debugging & Profiling", "text": ["Stop when returning from the given frame."]}, {"name": "bdb.Bdb.set_step()", "path": "library/bdb#bdb.Bdb.set_step", "type": "Debugging & Profiling", "text": ["Stop after one line of code."]}, {"name": "bdb.Bdb.set_trace()", "path": "library/bdb#bdb.Bdb.set_trace", "type": "Debugging & Profiling", "text": ["Start debugging from frame. If frame is not specified, debugging starts from caller\u2019s frame."]}, {"name": "bdb.Bdb.set_until()", "path": "library/bdb#bdb.Bdb.set_until", "type": "Debugging & Profiling", "text": ["Stop when the line with the line no greater than the current one is reached or when returning from current frame."]}, {"name": "bdb.Bdb.stop_here()", "path": "library/bdb#bdb.Bdb.stop_here", "type": "Debugging & Profiling", "text": ["This method checks if the frame is somewhere below botframe in the call stack. botframe is the frame in which debugging started."]}, {"name": "bdb.Bdb.trace_dispatch()", "path": "library/bdb#bdb.Bdb.trace_dispatch", "type": "Debugging & Profiling", "text": ["This function is installed as the trace function of debugged frames. Its return value is the new trace function (in most cases, that is, itself).", "The default implementation decides how to dispatch a frame, depending on the type of event (passed as a string) that is about to be executed. event can be one of the following:", "For the Python events, specialized functions (see below) are called. For the C events, no action is taken.", "The arg parameter depends on the previous event.", "See the documentation for sys.settrace() for more information on the trace function. For more information on code and frame objects, refer to The standard type hierarchy."]}, {"name": "bdb.Bdb.user_call()", "path": "library/bdb#bdb.Bdb.user_call", "type": "Debugging & Profiling", "text": ["This method is called from dispatch_call() when there is the possibility that a break might be necessary anywhere inside the called function."]}, {"name": "bdb.Bdb.user_exception()", "path": "library/bdb#bdb.Bdb.user_exception", "type": "Debugging & Profiling", "text": ["This method is called from dispatch_exception() when stop_here() yields True."]}, {"name": "bdb.Bdb.user_line()", "path": "library/bdb#bdb.Bdb.user_line", "type": "Debugging & Profiling", "text": ["This method is called from dispatch_line() when either stop_here() or break_here() yields True."]}, {"name": "bdb.Bdb.user_return()", "path": "library/bdb#bdb.Bdb.user_return", "type": "Debugging & Profiling", "text": ["This method is called from dispatch_return() when stop_here() yields True."]}, {"name": "bdb.BdbQuit", "path": "library/bdb#bdb.BdbQuit", "type": "Debugging & Profiling", "text": ["Exception raised by the Bdb class for quitting the debugger."]}, {"name": "bdb.Breakpoint", "path": "library/bdb#bdb.Breakpoint", "type": "Debugging & Profiling", "text": ["This class implements temporary breakpoints, ignore counts, disabling and (re-)enabling, and conditionals.", "Breakpoints are indexed by number through a list called bpbynumber and by (file, line) pairs through bplist. The former points to a single instance of class Breakpoint. The latter points to a list of such instances since there may be more than one breakpoint per line.", "When creating a breakpoint, its associated filename should be in canonical form. If a funcname is defined, a breakpoint hit will be counted when the first line of that function is executed. A conditional breakpoint always counts a hit.", "Breakpoint instances have the following methods:", "Delete the breakpoint from the list associated to a file/line. If it is the last breakpoint in that position, it also deletes the entry for the file/line.", "Mark the breakpoint as enabled.", "Mark the breakpoint as disabled.", "Return a string with all the information about the breakpoint, nicely formatted:", "New in version 3.2.", "Print the output of bpformat() to the file out, or if it is None, to standard output."]}, {"name": "bdb.Breakpoint.bpformat()", "path": "library/bdb#bdb.Breakpoint.bpformat", "type": "Debugging & Profiling", "text": ["Return a string with all the information about the breakpoint, nicely formatted:", "New in version 3.2."]}, {"name": "bdb.Breakpoint.bpprint()", "path": "library/bdb#bdb.Breakpoint.bpprint", "type": "Debugging & Profiling", "text": ["Print the output of bpformat() to the file out, or if it is None, to standard output."]}, {"name": "bdb.Breakpoint.deleteMe()", "path": "library/bdb#bdb.Breakpoint.deleteMe", "type": "Debugging & Profiling", "text": ["Delete the breakpoint from the list associated to a file/line. If it is the last breakpoint in that position, it also deletes the entry for the file/line."]}, {"name": "bdb.Breakpoint.disable()", "path": "library/bdb#bdb.Breakpoint.disable", "type": "Debugging & Profiling", "text": ["Mark the breakpoint as disabled."]}, {"name": "bdb.Breakpoint.enable()", "path": "library/bdb#bdb.Breakpoint.enable", "type": "Debugging & Profiling", "text": ["Mark the breakpoint as enabled."]}, {"name": "bdb.checkfuncname()", "path": "library/bdb#bdb.checkfuncname", "type": "Debugging & Profiling", "text": ["Check whether we should break here, depending on the way the breakpoint b was set.", "If it was set via line number, it checks if b.line is the same as the one in the frame also passed as argument. If the breakpoint was set via function name, we have to check we are in the right frame (the right function) and if we are in its first executable line."]}, {"name": "bdb.effective()", "path": "library/bdb#bdb.effective", "type": "Debugging & Profiling", "text": ["Determine if there is an effective (active) breakpoint at this line of code. Return a tuple of the breakpoint and a boolean that indicates if it is ok to delete a temporary breakpoint. Return (None, None) if there is no matching breakpoint."]}, {"name": "bdb.set_trace()", "path": "library/bdb#bdb.set_trace", "type": "Debugging & Profiling", "text": ["Start debugging with a Bdb instance from caller\u2019s frame."]}, {"name": "bin()", "path": "library/functions#bin", "type": "Built-in Functions", "text": ["Convert an integer number to a binary string prefixed with \u201c0b\u201d. The result is a valid Python expression. If x is not a Python int object, it has to define an __index__() method that returns an integer. Some examples:", "If prefix \u201c0b\u201d is desired or not, you can use either of the following ways.", "See also format() for more information."]}, {"name": "binascii", "path": "library/binascii", "type": "Internet Data", "text": ["The binascii module contains a number of methods to convert between binary and various ASCII-encoded binary representations. Normally, you will not use these functions directly but use wrapper modules like uu, base64, or binhex instead. The binascii module contains low-level functions written in C for greater speed that are used by the higher-level modules.", "Note", "a2b_* functions accept Unicode strings containing only ASCII characters. Other functions only accept bytes-like objects (such as bytes, bytearray and other objects that support the buffer protocol).", "Changed in version 3.3: ASCII-only unicode strings are now accepted by the a2b_* functions.", "The binascii module defines the following functions:", "Convert a single line of uuencoded data back to binary and return the binary data. Lines normally contain 45 (binary) bytes, except for the last line. Line data may be followed by whitespace.", "Convert binary data to a line of ASCII characters, the return value is the converted line, including a newline char. The length of data should be at most 45. If backtick is true, zeros are represented by '`' instead of spaces.", "Changed in version 3.7: Added the backtick parameter.", "Convert a block of base64 data back to binary and return the binary data. More than one line may be passed at a time.", "Convert binary data to a line of ASCII characters in base64 coding. The return value is the converted line, including a newline char if newline is true. The output of this function conforms to RFC 3548.", "Changed in version 3.6: Added the newline parameter.", "Convert a block of quoted-printable data back to binary and return the binary data. More than one line may be passed at a time. If the optional argument header is present and true, underscores will be decoded as spaces.", "Convert binary data to a line(s) of ASCII characters in quoted-printable encoding. The return value is the converted line(s). If the optional argument quotetabs is present and true, all tabs and spaces will be encoded. If the optional argument istext is present and true, newlines are not encoded but trailing whitespace will be encoded. If the optional argument header is present and true, spaces will be encoded as underscores per RFC 1522. If the optional argument header is present and false, newline characters will be encoded as well; otherwise linefeed conversion might corrupt the binary data stream.", "Convert binhex4 formatted ASCII data to binary, without doing RLE-decompression. The string should contain a complete number of binary bytes, or (in case of the last portion of the binhex4 data) have the remaining bits zero.", "Deprecated since version 3.9.", "Perform RLE-decompression on the data, as per the binhex4 standard. The algorithm uses 0x90 after a byte as a repeat indicator, followed by a count. A count of 0 specifies a byte value of 0x90. The routine returns the decompressed data, unless data input data ends in an orphaned repeat indicator, in which case the Incomplete exception is raised.", "Changed in version 3.2: Accept only bytestring or bytearray objects as input.", "Deprecated since version 3.9.", "Perform binhex4 style RLE-compression on data and return the result.", "Deprecated since version 3.9.", "Perform hexbin4 binary-to-ASCII translation and return the resulting string. The argument should already be RLE-coded, and have a length divisible by 3 (except possibly the last fragment).", "Deprecated since version 3.9.", "Compute a 16-bit CRC value of data, starting with value as the initial CRC, and return the result. This uses the CRC-CCITT polynomial x16 + x12 + x5 + 1, often represented as 0x1021. This CRC is used in the binhex4 format.", "Compute CRC-32, the 32-bit checksum of data, starting with an initial CRC of value. The default initial CRC is zero. The algorithm is consistent with the ZIP file checksum. Since the algorithm is designed for use as a checksum algorithm, it is not suitable for use as a general hash algorithm. Use as follows:", "Changed in version 3.0: The result is always unsigned. To generate the same numeric value across all Python versions and platforms, use crc32(data) & 0xffffffff.", "Return the hexadecimal representation of the binary data. Every byte of data is converted into the corresponding 2-digit hex representation. The returned bytes object is therefore twice as long as the length of data.", "Similar functionality (but returning a text string) is also conveniently accessible using the bytes.hex() method.", "If sep is specified, it must be a single character str or bytes object. It will be inserted in the output after every bytes_per_sep input bytes. Separator placement is counted from the right end of the output by default, if you wish to count from the left, supply a negative bytes_per_sep value.", "Changed in version 3.8: The sep and bytes_per_sep parameters were added.", "Return the binary data represented by the hexadecimal string hexstr. This function is the inverse of b2a_hex(). hexstr must contain an even number of hexadecimal digits (which can be upper or lower case), otherwise an Error exception is raised.", "Similar functionality (accepting only text string arguments, but more liberal towards whitespace) is also accessible using the bytes.fromhex() class method.", "Exception raised on errors. These are usually programming errors.", "Exception raised on incomplete data. These are usually not programming errors, but may be handled by reading a little more data and trying again.", "See also", "Support for RFC compliant base64-style encoding in base 16, 32, 64, and 85.", "Support for the binhex format used on the Macintosh.", "Support for UU encoding used on Unix.", "Support for quoted-printable encoding used in MIME email messages."]}, {"name": "binascii.a2b_base64()", "path": "library/binascii#binascii.a2b_base64", "type": "Internet Data", "text": ["Convert a block of base64 data back to binary and return the binary data. More than one line may be passed at a time."]}, {"name": "binascii.a2b_hex()", "path": "library/binascii#binascii.a2b_hex", "type": "Internet Data", "text": ["Return the binary data represented by the hexadecimal string hexstr. This function is the inverse of b2a_hex(). hexstr must contain an even number of hexadecimal digits (which can be upper or lower case), otherwise an Error exception is raised.", "Similar functionality (accepting only text string arguments, but more liberal towards whitespace) is also accessible using the bytes.fromhex() class method."]}, {"name": "binascii.a2b_hqx()", "path": "library/binascii#binascii.a2b_hqx", "type": "Internet Data", "text": ["Convert binhex4 formatted ASCII data to binary, without doing RLE-decompression. The string should contain a complete number of binary bytes, or (in case of the last portion of the binhex4 data) have the remaining bits zero.", "Deprecated since version 3.9."]}, {"name": "binascii.a2b_qp()", "path": "library/binascii#binascii.a2b_qp", "type": "Internet Data", "text": ["Convert a block of quoted-printable data back to binary and return the binary data. More than one line may be passed at a time. If the optional argument header is present and true, underscores will be decoded as spaces."]}, {"name": "binascii.a2b_uu()", "path": "library/binascii#binascii.a2b_uu", "type": "Internet Data", "text": ["Convert a single line of uuencoded data back to binary and return the binary data. Lines normally contain 45 (binary) bytes, except for the last line. Line data may be followed by whitespace."]}, {"name": "binascii.b2a_base64()", "path": "library/binascii#binascii.b2a_base64", "type": "Internet Data", "text": ["Convert binary data to a line of ASCII characters in base64 coding. The return value is the converted line, including a newline char if newline is true. The output of this function conforms to RFC 3548.", "Changed in version 3.6: Added the newline parameter."]}, {"name": "binascii.b2a_hex()", "path": "library/binascii#binascii.b2a_hex", "type": "Internet Data", "text": ["Return the hexadecimal representation of the binary data. Every byte of data is converted into the corresponding 2-digit hex representation. The returned bytes object is therefore twice as long as the length of data.", "Similar functionality (but returning a text string) is also conveniently accessible using the bytes.hex() method.", "If sep is specified, it must be a single character str or bytes object. It will be inserted in the output after every bytes_per_sep input bytes. Separator placement is counted from the right end of the output by default, if you wish to count from the left, supply a negative bytes_per_sep value.", "Changed in version 3.8: The sep and bytes_per_sep parameters were added."]}, {"name": "binascii.b2a_hqx()", "path": "library/binascii#binascii.b2a_hqx", "type": "Internet Data", "text": ["Perform hexbin4 binary-to-ASCII translation and return the resulting string. The argument should already be RLE-coded, and have a length divisible by 3 (except possibly the last fragment).", "Deprecated since version 3.9."]}, {"name": "binascii.b2a_qp()", "path": "library/binascii#binascii.b2a_qp", "type": "Internet Data", "text": ["Convert binary data to a line(s) of ASCII characters in quoted-printable encoding. The return value is the converted line(s). If the optional argument quotetabs is present and true, all tabs and spaces will be encoded. If the optional argument istext is present and true, newlines are not encoded but trailing whitespace will be encoded. If the optional argument header is present and true, spaces will be encoded as underscores per RFC 1522. If the optional argument header is present and false, newline characters will be encoded as well; otherwise linefeed conversion might corrupt the binary data stream."]}, {"name": "binascii.b2a_uu()", "path": "library/binascii#binascii.b2a_uu", "type": "Internet Data", "text": ["Convert binary data to a line of ASCII characters, the return value is the converted line, including a newline char. The length of data should be at most 45. If backtick is true, zeros are represented by '`' instead of spaces.", "Changed in version 3.7: Added the backtick parameter."]}, {"name": "binascii.crc32()", "path": "library/binascii#binascii.crc32", "type": "Internet Data", "text": ["Compute CRC-32, the 32-bit checksum of data, starting with an initial CRC of value. The default initial CRC is zero. The algorithm is consistent with the ZIP file checksum. Since the algorithm is designed for use as a checksum algorithm, it is not suitable for use as a general hash algorithm. Use as follows:", "Changed in version 3.0: The result is always unsigned. To generate the same numeric value across all Python versions and platforms, use crc32(data) & 0xffffffff."]}, {"name": "binascii.crc_hqx()", "path": "library/binascii#binascii.crc_hqx", "type": "Internet Data", "text": ["Compute a 16-bit CRC value of data, starting with value as the initial CRC, and return the result. This uses the CRC-CCITT polynomial x16 + x12 + x5 + 1, often represented as 0x1021. This CRC is used in the binhex4 format."]}, {"name": "binascii.Error", "path": "library/binascii#binascii.Error", "type": "Internet Data", "text": ["Exception raised on errors. These are usually programming errors."]}, {"name": "binascii.hexlify()", "path": "library/binascii#binascii.hexlify", "type": "Internet Data", "text": ["Return the hexadecimal representation of the binary data. Every byte of data is converted into the corresponding 2-digit hex representation. The returned bytes object is therefore twice as long as the length of data.", "Similar functionality (but returning a text string) is also conveniently accessible using the bytes.hex() method.", "If sep is specified, it must be a single character str or bytes object. It will be inserted in the output after every bytes_per_sep input bytes. Separator placement is counted from the right end of the output by default, if you wish to count from the left, supply a negative bytes_per_sep value.", "Changed in version 3.8: The sep and bytes_per_sep parameters were added."]}, {"name": "binascii.Incomplete", "path": "library/binascii#binascii.Incomplete", "type": "Internet Data", "text": ["Exception raised on incomplete data. These are usually not programming errors, but may be handled by reading a little more data and trying again."]}, {"name": "binascii.rlecode_hqx()", "path": "library/binascii#binascii.rlecode_hqx", "type": "Internet Data", "text": ["Perform binhex4 style RLE-compression on data and return the result.", "Deprecated since version 3.9."]}, {"name": "binascii.rledecode_hqx()", "path": "library/binascii#binascii.rledecode_hqx", "type": "Internet Data", "text": ["Perform RLE-decompression on the data, as per the binhex4 standard. The algorithm uses 0x90 after a byte as a repeat indicator, followed by a count. A count of 0 specifies a byte value of 0x90. The routine returns the decompressed data, unless data input data ends in an orphaned repeat indicator, in which case the Incomplete exception is raised.", "Changed in version 3.2: Accept only bytestring or bytearray objects as input.", "Deprecated since version 3.9."]}, {"name": "binascii.unhexlify()", "path": "library/binascii#binascii.unhexlify", "type": "Internet Data", "text": ["Return the binary data represented by the hexadecimal string hexstr. This function is the inverse of b2a_hex(). hexstr must contain an even number of hexadecimal digits (which can be upper or lower case), otherwise an Error exception is raised.", "Similar functionality (accepting only text string arguments, but more liberal towards whitespace) is also accessible using the bytes.fromhex() class method."]}, {"name": "binhex", "path": "library/binhex", "type": "Internet Data", "text": ["Source code: Lib/binhex.py", "Deprecated since version 3.9.", "This module encodes and decodes files in binhex4 format, a format allowing representation of Macintosh files in ASCII. Only the data fork is handled.", "The binhex module defines the following functions:", "Convert a binary file with filename input to binhex file output. The output parameter can either be a filename or a file-like object (any object supporting a write() and close() method).", "Decode a binhex file input. input may be a filename or a file-like object supporting read() and close() methods. The resulting file is written to a file named output, unless the argument is None in which case the output filename is read from the binhex file.", "The following exception is also defined:", "Exception raised when something can\u2019t be encoded using the binhex format (for example, a filename is too long to fit in the filename field), or when input is not properly encoded binhex data.", "See also", "Support module containing ASCII-to-binary and binary-to-ASCII conversions.", "There is an alternative, more powerful interface to the coder and decoder, see the source for details.", "If you code or decode textfiles on non-Macintosh platforms they will still use the old Macintosh newline convention (carriage-return as end of line)."]}, {"name": "binhex.binhex()", "path": "library/binhex#binhex.binhex", "type": "Internet Data", "text": ["Convert a binary file with filename input to binhex file output. The output parameter can either be a filename or a file-like object (any object supporting a write() and close() method)."]}, {"name": "binhex.Error", "path": "library/binhex#binhex.Error", "type": "Internet Data", "text": ["Exception raised when something can\u2019t be encoded using the binhex format (for example, a filename is too long to fit in the filename field), or when input is not properly encoded binhex data."]}, {"name": "binhex.hexbin()", "path": "library/binhex#binhex.hexbin", "type": "Internet Data", "text": ["Decode a binhex file input. input may be a filename or a file-like object supporting read() and close() methods. The resulting file is written to a file named output, unless the argument is None in which case the output filename is read from the binhex file."]}, {"name": "bisect", "path": "library/bisect", "type": "Data Types", "text": ["Source code: Lib/bisect.py", "This module provides support for maintaining a list in sorted order without having to sort the list after each insertion. For long lists of items with expensive comparison operations, this can be an improvement over the more common approach. The module is called bisect because it uses a basic bisection algorithm to do its work. The source code may be most useful as a working example of the algorithm (the boundary conditions are already right!).", "The following functions are provided:", "Locate the insertion point for x in a to maintain sorted order. The parameters lo and hi may be used to specify a subset of the list which should be considered; by default the entire list is used. If x is already present in a, the insertion point will be before (to the left of) any existing entries. The return value is suitable for use as the first parameter to list.insert() assuming that a is already sorted.", "The returned insertion point i partitions the array a into two halves so that all(val < x for val in a[lo:i]) for the left side and all(val >= x for val in a[i:hi]) for the right side.", "Similar to bisect_left(), but returns an insertion point which comes after (to the right of) any existing entries of x in a.", "The returned insertion point i partitions the array a into two halves so that all(val <= x for val in a[lo:i]) for the left side and all(val > x for val in a[i:hi]) for the right side.", "Insert x in a in sorted order. This is equivalent to a.insert(bisect.bisect_left(a, x, lo, hi), x) assuming that a is already sorted. Keep in mind that the O(log n) search is dominated by the slow O(n) insertion step.", "Similar to insort_left(), but inserting x in a after any existing entries of x.", "See also", "SortedCollection recipe that uses bisect to build a full-featured collection class with straight-forward search methods and support for a key-function. The keys are precomputed to save unnecessary calls to the key function during searches.", "The above bisect() functions are useful for finding insertion points but can be tricky or awkward to use for common searching tasks. The following five functions show how to transform them into the standard lookups for sorted lists:", "The bisect() function can be useful for numeric table lookups. This example uses bisect() to look up a letter grade for an exam score (say) based on a set of ordered numeric breakpoints: 90 and up is an \u2018A\u2019, 80 to 89 is a \u2018B\u2019, and so on:", "Unlike the sorted() function, it does not make sense for the bisect() functions to have key or reversed arguments because that would lead to an inefficient design (successive calls to bisect functions would not \u201cremember\u201d all of the previous key lookups).", "Instead, it is better to search a list of precomputed keys to find the index of the record in question:"]}, {"name": "bisect.bisect()", "path": "library/bisect#bisect.bisect", "type": "Data Types", "text": ["Similar to bisect_left(), but returns an insertion point which comes after (to the right of) any existing entries of x in a.", "The returned insertion point i partitions the array a into two halves so that all(val <= x for val in a[lo:i]) for the left side and all(val > x for val in a[i:hi]) for the right side."]}, {"name": "bisect.bisect_left()", "path": "library/bisect#bisect.bisect_left", "type": "Data Types", "text": ["Locate the insertion point for x in a to maintain sorted order. The parameters lo and hi may be used to specify a subset of the list which should be considered; by default the entire list is used. If x is already present in a, the insertion point will be before (to the left of) any existing entries. The return value is suitable for use as the first parameter to list.insert() assuming that a is already sorted.", "The returned insertion point i partitions the array a into two halves so that all(val < x for val in a[lo:i]) for the left side and all(val >= x for val in a[i:hi]) for the right side."]}, {"name": "bisect.bisect_right()", "path": "library/bisect#bisect.bisect_right", "type": "Data Types", "text": ["Similar to bisect_left(), but returns an insertion point which comes after (to the right of) any existing entries of x in a.", "The returned insertion point i partitions the array a into two halves so that all(val <= x for val in a[lo:i]) for the left side and all(val > x for val in a[i:hi]) for the right side."]}, {"name": "bisect.insort()", "path": "library/bisect#bisect.insort", "type": "Data Types", "text": ["Similar to insort_left(), but inserting x in a after any existing entries of x."]}, {"name": "bisect.insort_left()", "path": "library/bisect#bisect.insort_left", "type": "Data Types", "text": ["Insert x in a in sorted order. This is equivalent to a.insert(bisect.bisect_left(a, x, lo, hi), x) assuming that a is already sorted. Keep in mind that the O(log n) search is dominated by the slow O(n) insertion step."]}, {"name": "bisect.insort_right()", "path": "library/bisect#bisect.insort_right", "type": "Data Types", "text": ["Similar to insort_left(), but inserting x in a after any existing entries of x."]}, {"name": "BlockingIOError", "path": "library/exceptions#BlockingIOError", "type": "Built-in Exceptions", "text": ["Raised when an operation would block on an object (e.g. socket) set for non-blocking operation. Corresponds to errno EAGAIN, EALREADY, EWOULDBLOCK and EINPROGRESS.", "In addition to those of OSError, BlockingIOError can have one more attribute:", "An integer containing the number of characters written to the stream before it blocked. This attribute is available when using the buffered I/O classes from the io module."]}, {"name": "BlockingIOError.characters_written", "path": "library/exceptions#BlockingIOError.characters_written", "type": "Built-in Exceptions", "text": ["An integer containing the number of characters written to the stream before it blocked. This attribute is available when using the buffered I/O classes from the io module."]}, {"name": "bool", "path": "library/functions#bool", "type": "Built-in Functions", "text": ["Return a Boolean value, i.e. one of True or False. x is converted using the standard truth testing procedure. If x is false or omitted, this returns False; otherwise it returns True. The bool class is a subclass of int (see Numeric Types \u2014 int, float, complex). It cannot be subclassed further. Its only instances are False and True (see Boolean Values).", "Changed in version 3.7: x is now a positional-only parameter."]}, {"name": "breakpoint()", "path": "library/functions#breakpoint", "type": "Built-in Functions", "text": ["This function drops you into the debugger at the call site. Specifically, it calls sys.breakpointhook(), passing args and kws straight through. By default, sys.breakpointhook() calls pdb.set_trace() expecting no arguments. In this case, it is purely a convenience function so you don\u2019t have to explicitly import pdb or type as much code to enter the debugger. However, sys.breakpointhook() can be set to some other function and breakpoint() will automatically call that, allowing you to drop into the debugger of choice.", "Raises an auditing event builtins.breakpoint with argument breakpointhook.", "New in version 3.7."]}, {"name": "BrokenPipeError", "path": "library/exceptions#BrokenPipeError", "type": "Built-in Exceptions", "text": ["A subclass of ConnectionError, raised when trying to write on a pipe while the other end has been closed, or trying to write on a socket which has been shutdown for writing. Corresponds to errno EPIPE and ESHUTDOWN."]}, {"name": "BufferError", "path": "library/exceptions#BufferError", "type": "Built-in Exceptions", "text": ["Raised when a buffer related operation cannot be performed."]}, {"name": "builtins", "path": "library/builtins", "type": "Runtime", "text": ["This module provides direct access to all \u2018built-in\u2019 identifiers of Python; for example, builtins.open is the full name for the built-in function open(). See Built-in Functions and Built-in Constants for documentation.", "This module is not normally accessed explicitly by most applications, but can be useful in modules that provide objects with the same name as a built-in value, but in which the built-in of that name is also needed. For example, in a module that wants to implement an open() function that wraps the built-in open(), this module can be used directly:", "As an implementation detail, most modules have the name __builtins__ made available as part of their globals. The value of __builtins__ is normally either this module or the value of this module\u2019s __dict__ attribute. Since this is an implementation detail, it may not be used by alternate implementations of Python."]}, {"name": "bytearray", "path": "library/functions#bytearray", "type": "Built-in Functions", "text": ["Return a new array of bytes. The bytearray class is a mutable sequence of integers in the range 0 <= x < 256. It has most of the usual methods of mutable sequences, described in Mutable Sequence Types, as well as most methods that the bytes type has, see Bytes and Bytearray Operations.", "The optional source parameter can be used to initialize the array in a few different ways:", "Without an argument, an array of size 0 is created.", "See also Binary Sequence Types \u2014 bytes, bytearray, memoryview and Bytearray Objects."]}, {"name": "bytearray", "path": "library/stdtypes#bytearray", "type": "Built-in Types", "text": ["There is no dedicated literal syntax for bytearray objects, instead they are always created by calling the constructor:", "As bytearray objects are mutable, they support the mutable sequence operations in addition to the common bytes and bytearray operations described in Bytes and Bytearray Operations.", "Also see the bytearray built-in.", "Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used format for describing binary data. Accordingly, the bytearray type has an additional class method to read data in that format:", "This bytearray class method returns bytearray object, decoding the given string object. The string must contain two hexadecimal digits per byte, with ASCII whitespace being ignored.", "Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string, not just spaces.", "A reverse conversion function exists to transform a bytearray object into its hexadecimal representation.", "Return a string object containing two hexadecimal digits for each byte in the instance.", "New in version 3.5.", "Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output."]}, {"name": "bytearray.capitalize()", "path": "library/stdtypes#bytearray.capitalize", "type": "Built-in Types", "text": ["Return a copy of the sequence with each byte interpreted as an ASCII character, and the first byte capitalized and the rest lowercased. Non-ASCII byte values are passed through unchanged.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.center()", "path": "library/stdtypes#bytearray.center", "type": "Built-in Types", "text": ["Return a copy of the object centered in a sequence of length width. Padding is done using the specified fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than or equal to len(s).", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.count()", "path": "library/stdtypes#bytearray.count", "type": "Built-in Types", "text": ["Return the number of non-overlapping occurrences of subsequence sub in the range [start, end]. Optional arguments start and end are interpreted as in slice notation.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytearray.decode()", "path": "library/stdtypes#bytearray.decode", "type": "Built-in Types", "text": ["Return a string decoded from the given bytes. Default encoding is 'utf-8'. errors may be given to set a different error handling scheme. The default for errors is 'strict', meaning that encoding errors raise a UnicodeError. Other possible values are 'ignore', 'replace' and any other name registered via codecs.register_error(), see section Error Handlers. For a list of possible encodings, see section Standard Encodings.", "By default, the errors argument is not checked for best performances, but only used at the first decoding error. Enable the Python Development Mode, or use a debug build to check errors.", "Note", "Passing the encoding argument to str allows decoding any bytes-like object directly, without needing to make a temporary bytes or bytearray object.", "Changed in version 3.1: Added support for keyword arguments.", "Changed in version 3.9: The errors is now checked in development mode and in debug mode."]}, {"name": "bytearray.endswith()", "path": "library/stdtypes#bytearray.endswith", "type": "Built-in Types", "text": ["Return True if the binary data ends with the specified suffix, otherwise return False. suffix can also be a tuple of suffixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at that position.", "The suffix(es) to search for may be any bytes-like object."]}, {"name": "bytearray.expandtabs()", "path": "library/stdtypes#bytearray.expandtabs", "type": "Built-in Types", "text": ["Return a copy of the sequence where all ASCII tab characters are replaced by one or more ASCII spaces, depending on the current column and the given tab size. Tab positions occur every tabsize bytes (default is 8, giving tab positions at columns 0, 8, 16 and so on). To expand the sequence, the current column is set to zero and the sequence is examined byte by byte. If the byte is an ASCII tab character (b'\\t'), one or more space characters are inserted in the result until the current column is equal to the next tab position. (The tab character itself is not copied.) If the current byte is an ASCII newline (b'\\n') or carriage return (b'\\r'), it is copied and the current column is reset to zero. Any other byte value is copied unchanged and the current column is incremented by one regardless of how the byte value is represented when printed:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.find()", "path": "library/stdtypes#bytearray.find", "type": "Built-in Types", "text": ["Return the lowest index in the data where the subsequence sub is found, such that sub is contained in the slice s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Note", "The find() method should be used only if you need to know the position of sub. To check if sub is a substring or not, use the in operator:", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytearray.fromhex()", "path": "library/stdtypes#bytearray.fromhex", "type": "Built-in Types", "text": ["This bytearray class method returns bytearray object, decoding the given string object. The string must contain two hexadecimal digits per byte, with ASCII whitespace being ignored.", "Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string, not just spaces."]}, {"name": "bytearray.hex()", "path": "library/stdtypes#bytearray.hex", "type": "Built-in Types", "text": ["Return a string object containing two hexadecimal digits for each byte in the instance.", "New in version 3.5.", "Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output."]}, {"name": "bytearray.index()", "path": "library/stdtypes#bytearray.index", "type": "Built-in Types", "text": ["Like find(), but raise ValueError when the subsequence is not found.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytearray.isalnum()", "path": "library/stdtypes#bytearray.isalnum", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are alphabetical ASCII characters or ASCII decimal digits and the sequence is not empty, False otherwise. Alphabetic ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal digits are those byte values in the sequence b'0123456789'.", "For example:"]}, {"name": "bytearray.isalpha()", "path": "library/stdtypes#bytearray.isalpha", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are alphabetic ASCII characters and the sequence is not empty, False otherwise. Alphabetic ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "For example:"]}, {"name": "bytearray.isascii()", "path": "library/stdtypes#bytearray.isascii", "type": "Built-in Types", "text": ["Return True if the sequence is empty or all bytes in the sequence are ASCII, False otherwise. ASCII bytes are in the range 0-0x7F.", "New in version 3.7."]}, {"name": "bytearray.isdigit()", "path": "library/stdtypes#bytearray.isdigit", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are ASCII decimal digits and the sequence is not empty, False otherwise. ASCII decimal digits are those byte values in the sequence b'0123456789'.", "For example:"]}, {"name": "bytearray.islower()", "path": "library/stdtypes#bytearray.islower", "type": "Built-in Types", "text": ["Return True if there is at least one lowercase ASCII character in the sequence and no uppercase ASCII characters, False otherwise.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."]}, {"name": "bytearray.isspace()", "path": "library/stdtypes#bytearray.isspace", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are ASCII whitespace and the sequence is not empty, False otherwise. ASCII whitespace characters are those byte values in the sequence b' \\t\\n\\r\\x0b\\f' (space, tab, newline, carriage return, vertical tab, form feed)."]}, {"name": "bytearray.istitle()", "path": "library/stdtypes#bytearray.istitle", "type": "Built-in Types", "text": ["Return True if the sequence is ASCII titlecase and the sequence is not empty, False otherwise. See bytes.title() for more details on the definition of \u201ctitlecase\u201d.", "For example:"]}, {"name": "bytearray.isupper()", "path": "library/stdtypes#bytearray.isupper", "type": "Built-in Types", "text": ["Return True if there is at least one uppercase alphabetic ASCII character in the sequence and no lowercase ASCII characters, False otherwise.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."]}, {"name": "bytearray.join()", "path": "library/stdtypes#bytearray.join", "type": "Built-in Types", "text": ["Return a bytes or bytearray object which is the concatenation of the binary data sequences in iterable. A TypeError will be raised if there are any values in iterable that are not bytes-like objects, including str objects. The separator between elements is the contents of the bytes or bytearray object providing this method."]}, {"name": "bytearray.ljust()", "path": "library/stdtypes#bytearray.ljust", "type": "Built-in Types", "text": ["Return a copy of the object left justified in a sequence of length width. Padding is done using the specified fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than or equal to len(s).", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.lower()", "path": "library/stdtypes#bytearray.lower", "type": "Built-in Types", "text": ["Return a copy of the sequence with all the uppercase ASCII characters converted to their corresponding lowercase counterpart.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.lstrip()", "path": "library/stdtypes#bytearray.lstrip", "type": "Built-in Types", "text": ["Return a copy of the sequence with specified leading bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a prefix; rather, all combinations of its values are stripped:", "The binary sequence of byte values to remove may be any bytes-like object. See removeprefix() for a method that will remove a single prefix string rather than all of a set of characters. For example:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.maketrans()", "path": "library/stdtypes#bytearray.maketrans", "type": "Built-in Types", "text": ["This static method returns a translation table usable for bytes.translate() that will map each character in from into the character at the same position in to; from and to must both be bytes-like objects and have the same length.", "New in version 3.1."]}, {"name": "bytearray.partition()", "path": "library/stdtypes#bytearray.partition", "type": "Built-in Types", "text": ["Split the sequence at the first occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself or its bytearray copy, and the part after the separator. If the separator is not found, return a 3-tuple containing a copy of the original sequence, followed by two empty bytes or bytearray objects.", "The separator to search for may be any bytes-like object."]}, {"name": "bytearray.removeprefix()", "path": "library/stdtypes#bytearray.removeprefix", "type": "Built-in Types", "text": ["If the binary data starts with the prefix string, return bytes[len(prefix):]. Otherwise, return a copy of the original binary data:", "The prefix may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.", "New in version 3.9."]}, {"name": "bytearray.removesuffix()", "path": "library/stdtypes#bytearray.removesuffix", "type": "Built-in Types", "text": ["If the binary data ends with the suffix string and that suffix is not empty, return bytes[:-len(suffix)]. Otherwise, return a copy of the original binary data:", "The suffix may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.", "New in version 3.9."]}, {"name": "bytearray.replace()", "path": "library/stdtypes#bytearray.replace", "type": "Built-in Types", "text": ["Return a copy of the sequence with all occurrences of subsequence old replaced by new. If the optional argument count is given, only the first count occurrences are replaced.", "The subsequence to search for and its replacement may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.rfind()", "path": "library/stdtypes#bytearray.rfind", "type": "Built-in Types", "text": ["Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytearray.rindex()", "path": "library/stdtypes#bytearray.rindex", "type": "Built-in Types", "text": ["Like rfind() but raises ValueError when the subsequence sub is not found.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytearray.rjust()", "path": "library/stdtypes#bytearray.rjust", "type": "Built-in Types", "text": ["Return a copy of the object right justified in a sequence of length width. Padding is done using the specified fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than or equal to len(s).", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.rpartition()", "path": "library/stdtypes#bytearray.rpartition", "type": "Built-in Types", "text": ["Split the sequence at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself or its bytearray copy, and the part after the separator. If the separator is not found, return a 3-tuple containing two empty bytes or bytearray objects, followed by a copy of the original sequence.", "The separator to search for may be any bytes-like object."]}, {"name": "bytearray.rsplit()", "path": "library/stdtypes#bytearray.rsplit", "type": "Built-in Types", "text": ["Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done, the rightmost ones. If sep is not specified or None, any subsequence consisting solely of ASCII whitespace is a separator. Except for splitting from the right, rsplit() behaves like split() which is described in detail below."]}, {"name": "bytearray.rstrip()", "path": "library/stdtypes#bytearray.rstrip", "type": "Built-in Types", "text": ["Return a copy of the sequence with specified trailing bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a suffix; rather, all combinations of its values are stripped:", "The binary sequence of byte values to remove may be any bytes-like object. See removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.split()", "path": "library/stdtypes#bytearray.split", "type": "Built-in Types", "text": ["Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or is -1, then there is no limit on the number of splits (all possible splits are made).", "If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences (for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns [b'1', b'2', b'3']). Splitting an empty sequence with a specified separator returns [b''] or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like object.", "For example:", "If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely of ASCII whitespace without a specified separator returns [].", "For example:"]}, {"name": "bytearray.splitlines()", "path": "library/stdtypes#bytearray.splitlines", "type": "Built-in Types", "text": ["Return a list of the lines in the binary sequence, breaking at ASCII line boundaries. This method uses the universal newlines approach to splitting lines. Line breaks are not included in the resulting list unless keepends is given and true.", "For example:", "Unlike split() when a delimiter string sep is given, this method returns an empty list for the empty string, and a terminal line break does not result in an extra line:"]}, {"name": "bytearray.startswith()", "path": "library/stdtypes#bytearray.startswith", "type": "Built-in Types", "text": ["Return True if the binary data starts with the specified prefix, otherwise return False. prefix can also be a tuple of prefixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at that position.", "The prefix(es) to search for may be any bytes-like object."]}, {"name": "bytearray.strip()", "path": "library/stdtypes#bytearray.strip", "type": "Built-in Types", "text": ["Return a copy of the sequence with specified leading and trailing bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:", "The binary sequence of byte values to remove may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.swapcase()", "path": "library/stdtypes#bytearray.swapcase", "type": "Built-in Types", "text": ["Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart and vice-versa.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "Unlike str.swapcase(), it is always the case that bin.swapcase().swapcase() == bin for the binary versions. Case conversions are symmetrical in ASCII, even though that is not generally true for arbitrary Unicode code points.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.title()", "path": "library/stdtypes#bytearray.title", "type": "Built-in Types", "text": ["Return a titlecased version of the binary sequence where words start with an uppercase ASCII character and the remaining characters are lowercase. Uncased byte values are left unmodified.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'. All other byte values are uncased.", "The algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The definition works in many contexts but it means that apostrophes in contractions and possessives form word boundaries, which may not be the desired result:", "A workaround for apostrophes can be constructed using regular expressions:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.translate()", "path": "library/stdtypes#bytearray.translate", "type": "Built-in Types", "text": ["Return a copy of the bytes or bytearray object where all bytes occurring in the optional argument delete are removed, and the remaining bytes have been mapped through the given translation table, which must be a bytes object of length 256.", "You can use the bytes.maketrans() method to create a translation table.", "Set the table argument to None for translations that only delete characters:", "Changed in version 3.6: delete is now supported as a keyword argument."]}, {"name": "bytearray.upper()", "path": "library/stdtypes#bytearray.upper", "type": "Built-in Types", "text": ["Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytearray.zfill()", "path": "library/stdtypes#bytearray.zfill", "type": "Built-in Types", "text": ["Return a copy of the sequence left filled with ASCII b'0' digits to make a sequence of length width. A leading sign prefix (b'+'/ b'-') is handled by inserting the padding after the sign character rather than before. For bytes objects, the original sequence is returned if width is less than or equal to len(seq).", "For example:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes", "path": "library/stdtypes#bytes", "type": "Built-in Types", "text": ["Firstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:", "Only ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any binary values over 127 must be entered into bytes literals using the appropriate escape sequence.", "As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See String and Bytes literals for more about the various forms of bytes literal, including supported escape sequences.", "While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable sequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate this restriction will trigger ValueError). This is done deliberately to emphasise that while many binary formats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms, this is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary data formats that are not ASCII compatible will usually lead to data corruption).", "In addition to the literal forms, bytes objects can be created in a number of other ways:", "Also see the bytes built-in.", "Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used format for describing binary data. Accordingly, the bytes type has an additional class method to read data in that format:", "This bytes class method returns a bytes object, decoding the given string object. The string must contain two hexadecimal digits per byte, with ASCII whitespace being ignored.", "Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just spaces.", "A reverse conversion function exists to transform a bytes object into its hexadecimal representation.", "Return a string object containing two hexadecimal digits for each byte in the instance.", "If you want to make the hex string easier to read, you can specify a single character separator sep parameter to include in the output. By default between each byte. A second optional bytes_per_sep parameter controls the spacing. Positive values calculate the separator position from the right, negative values from the left.", "New in version 3.5.", "Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output."]}, {"name": "bytes", "path": "library/functions#bytes", "type": "Built-in Functions", "text": ["Return a new \u201cbytes\u201d object, which is an immutable sequence of integers in the range 0 <= x < 256. bytes is an immutable version of bytearray \u2013 it has the same non-mutating methods and the same indexing and slicing behavior.", "Accordingly, constructor arguments are interpreted as for bytearray().", "Bytes objects can also be created with literals, see String and Bytes literals.", "See also Binary Sequence Types \u2014 bytes, bytearray, memoryview, Bytes Objects, and Bytes and Bytearray Operations."]}, {"name": "bytes.capitalize()", "path": "library/stdtypes#bytes.capitalize", "type": "Built-in Types", "text": ["Return a copy of the sequence with each byte interpreted as an ASCII character, and the first byte capitalized and the rest lowercased. Non-ASCII byte values are passed through unchanged.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.center()", "path": "library/stdtypes#bytes.center", "type": "Built-in Types", "text": ["Return a copy of the object centered in a sequence of length width. Padding is done using the specified fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than or equal to len(s).", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.count()", "path": "library/stdtypes#bytes.count", "type": "Built-in Types", "text": ["Return the number of non-overlapping occurrences of subsequence sub in the range [start, end]. Optional arguments start and end are interpreted as in slice notation.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytes.decode()", "path": "library/stdtypes#bytes.decode", "type": "Built-in Types", "text": ["Return a string decoded from the given bytes. Default encoding is 'utf-8'. errors may be given to set a different error handling scheme. The default for errors is 'strict', meaning that encoding errors raise a UnicodeError. Other possible values are 'ignore', 'replace' and any other name registered via codecs.register_error(), see section Error Handlers. For a list of possible encodings, see section Standard Encodings.", "By default, the errors argument is not checked for best performances, but only used at the first decoding error. Enable the Python Development Mode, or use a debug build to check errors.", "Note", "Passing the encoding argument to str allows decoding any bytes-like object directly, without needing to make a temporary bytes or bytearray object.", "Changed in version 3.1: Added support for keyword arguments.", "Changed in version 3.9: The errors is now checked in development mode and in debug mode."]}, {"name": "bytes.endswith()", "path": "library/stdtypes#bytes.endswith", "type": "Built-in Types", "text": ["Return True if the binary data ends with the specified suffix, otherwise return False. suffix can also be a tuple of suffixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at that position.", "The suffix(es) to search for may be any bytes-like object."]}, {"name": "bytes.expandtabs()", "path": "library/stdtypes#bytes.expandtabs", "type": "Built-in Types", "text": ["Return a copy of the sequence where all ASCII tab characters are replaced by one or more ASCII spaces, depending on the current column and the given tab size. Tab positions occur every tabsize bytes (default is 8, giving tab positions at columns 0, 8, 16 and so on). To expand the sequence, the current column is set to zero and the sequence is examined byte by byte. If the byte is an ASCII tab character (b'\\t'), one or more space characters are inserted in the result until the current column is equal to the next tab position. (The tab character itself is not copied.) If the current byte is an ASCII newline (b'\\n') or carriage return (b'\\r'), it is copied and the current column is reset to zero. Any other byte value is copied unchanged and the current column is incremented by one regardless of how the byte value is represented when printed:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.find()", "path": "library/stdtypes#bytes.find", "type": "Built-in Types", "text": ["Return the lowest index in the data where the subsequence sub is found, such that sub is contained in the slice s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Note", "The find() method should be used only if you need to know the position of sub. To check if sub is a substring or not, use the in operator:", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytes.fromhex()", "path": "library/stdtypes#bytes.fromhex", "type": "Built-in Types", "text": ["This bytes class method returns a bytes object, decoding the given string object. The string must contain two hexadecimal digits per byte, with ASCII whitespace being ignored.", "Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just spaces."]}, {"name": "bytes.hex()", "path": "library/stdtypes#bytes.hex", "type": "Built-in Types", "text": ["Return a string object containing two hexadecimal digits for each byte in the instance.", "If you want to make the hex string easier to read, you can specify a single character separator sep parameter to include in the output. By default between each byte. A second optional bytes_per_sep parameter controls the spacing. Positive values calculate the separator position from the right, negative values from the left.", "New in version 3.5.", "Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output."]}, {"name": "bytes.index()", "path": "library/stdtypes#bytes.index", "type": "Built-in Types", "text": ["Like find(), but raise ValueError when the subsequence is not found.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytes.isalnum()", "path": "library/stdtypes#bytes.isalnum", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are alphabetical ASCII characters or ASCII decimal digits and the sequence is not empty, False otherwise. Alphabetic ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal digits are those byte values in the sequence b'0123456789'.", "For example:"]}, {"name": "bytes.isalpha()", "path": "library/stdtypes#bytes.isalpha", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are alphabetic ASCII characters and the sequence is not empty, False otherwise. Alphabetic ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "For example:"]}, {"name": "bytes.isascii()", "path": "library/stdtypes#bytes.isascii", "type": "Built-in Types", "text": ["Return True if the sequence is empty or all bytes in the sequence are ASCII, False otherwise. ASCII bytes are in the range 0-0x7F.", "New in version 3.7."]}, {"name": "bytes.isdigit()", "path": "library/stdtypes#bytes.isdigit", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are ASCII decimal digits and the sequence is not empty, False otherwise. ASCII decimal digits are those byte values in the sequence b'0123456789'.", "For example:"]}, {"name": "bytes.islower()", "path": "library/stdtypes#bytes.islower", "type": "Built-in Types", "text": ["Return True if there is at least one lowercase ASCII character in the sequence and no uppercase ASCII characters, False otherwise.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."]}, {"name": "bytes.isspace()", "path": "library/stdtypes#bytes.isspace", "type": "Built-in Types", "text": ["Return True if all bytes in the sequence are ASCII whitespace and the sequence is not empty, False otherwise. ASCII whitespace characters are those byte values in the sequence b' \\t\\n\\r\\x0b\\f' (space, tab, newline, carriage return, vertical tab, form feed)."]}, {"name": "bytes.istitle()", "path": "library/stdtypes#bytes.istitle", "type": "Built-in Types", "text": ["Return True if the sequence is ASCII titlecase and the sequence is not empty, False otherwise. See bytes.title() for more details on the definition of \u201ctitlecase\u201d.", "For example:"]}, {"name": "bytes.isupper()", "path": "library/stdtypes#bytes.isupper", "type": "Built-in Types", "text": ["Return True if there is at least one uppercase alphabetic ASCII character in the sequence and no lowercase ASCII characters, False otherwise.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'."]}, {"name": "bytes.join()", "path": "library/stdtypes#bytes.join", "type": "Built-in Types", "text": ["Return a bytes or bytearray object which is the concatenation of the binary data sequences in iterable. A TypeError will be raised if there are any values in iterable that are not bytes-like objects, including str objects. The separator between elements is the contents of the bytes or bytearray object providing this method."]}, {"name": "bytes.ljust()", "path": "library/stdtypes#bytes.ljust", "type": "Built-in Types", "text": ["Return a copy of the object left justified in a sequence of length width. Padding is done using the specified fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than or equal to len(s).", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.lower()", "path": "library/stdtypes#bytes.lower", "type": "Built-in Types", "text": ["Return a copy of the sequence with all the uppercase ASCII characters converted to their corresponding lowercase counterpart.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.lstrip()", "path": "library/stdtypes#bytes.lstrip", "type": "Built-in Types", "text": ["Return a copy of the sequence with specified leading bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a prefix; rather, all combinations of its values are stripped:", "The binary sequence of byte values to remove may be any bytes-like object. See removeprefix() for a method that will remove a single prefix string rather than all of a set of characters. For example:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.maketrans()", "path": "library/stdtypes#bytes.maketrans", "type": "Built-in Types", "text": ["This static method returns a translation table usable for bytes.translate() that will map each character in from into the character at the same position in to; from and to must both be bytes-like objects and have the same length.", "New in version 3.1."]}, {"name": "bytes.partition()", "path": "library/stdtypes#bytes.partition", "type": "Built-in Types", "text": ["Split the sequence at the first occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself or its bytearray copy, and the part after the separator. If the separator is not found, return a 3-tuple containing a copy of the original sequence, followed by two empty bytes or bytearray objects.", "The separator to search for may be any bytes-like object."]}, {"name": "bytes.removeprefix()", "path": "library/stdtypes#bytes.removeprefix", "type": "Built-in Types", "text": ["If the binary data starts with the prefix string, return bytes[len(prefix):]. Otherwise, return a copy of the original binary data:", "The prefix may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.", "New in version 3.9."]}, {"name": "bytes.removesuffix()", "path": "library/stdtypes#bytes.removesuffix", "type": "Built-in Types", "text": ["If the binary data ends with the suffix string and that suffix is not empty, return bytes[:-len(suffix)]. Otherwise, return a copy of the original binary data:", "The suffix may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.", "New in version 3.9."]}, {"name": "bytes.replace()", "path": "library/stdtypes#bytes.replace", "type": "Built-in Types", "text": ["Return a copy of the sequence with all occurrences of subsequence old replaced by new. If the optional argument count is given, only the first count occurrences are replaced.", "The subsequence to search for and its replacement may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.rfind()", "path": "library/stdtypes#bytes.rfind", "type": "Built-in Types", "text": ["Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytes.rindex()", "path": "library/stdtypes#bytes.rindex", "type": "Built-in Types", "text": ["Like rfind() but raises ValueError when the subsequence sub is not found.", "The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.", "Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence."]}, {"name": "bytes.rjust()", "path": "library/stdtypes#bytes.rjust", "type": "Built-in Types", "text": ["Return a copy of the object right justified in a sequence of length width. Padding is done using the specified fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than or equal to len(s).", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.rpartition()", "path": "library/stdtypes#bytes.rpartition", "type": "Built-in Types", "text": ["Split the sequence at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself or its bytearray copy, and the part after the separator. If the separator is not found, return a 3-tuple containing two empty bytes or bytearray objects, followed by a copy of the original sequence.", "The separator to search for may be any bytes-like object."]}, {"name": "bytes.rsplit()", "path": "library/stdtypes#bytes.rsplit", "type": "Built-in Types", "text": ["Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done, the rightmost ones. If sep is not specified or None, any subsequence consisting solely of ASCII whitespace is a separator. Except for splitting from the right, rsplit() behaves like split() which is described in detail below."]}, {"name": "bytes.rstrip()", "path": "library/stdtypes#bytes.rstrip", "type": "Built-in Types", "text": ["Return a copy of the sequence with specified trailing bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a suffix; rather, all combinations of its values are stripped:", "The binary sequence of byte values to remove may be any bytes-like object. See removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.split()", "path": "library/stdtypes#bytes.split", "type": "Built-in Types", "text": ["Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or is -1, then there is no limit on the number of splits (all possible splits are made).", "If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences (for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns [b'1', b'2', b'3']). Splitting an empty sequence with a specified separator returns [b''] or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like object.", "For example:", "If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely of ASCII whitespace without a specified separator returns [].", "For example:"]}, {"name": "bytes.splitlines()", "path": "library/stdtypes#bytes.splitlines", "type": "Built-in Types", "text": ["Return a list of the lines in the binary sequence, breaking at ASCII line boundaries. This method uses the universal newlines approach to splitting lines. Line breaks are not included in the resulting list unless keepends is given and true.", "For example:", "Unlike split() when a delimiter string sep is given, this method returns an empty list for the empty string, and a terminal line break does not result in an extra line:"]}, {"name": "bytes.startswith()", "path": "library/stdtypes#bytes.startswith", "type": "Built-in Types", "text": ["Return True if the binary data starts with the specified prefix, otherwise return False. prefix can also be a tuple of prefixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at that position.", "The prefix(es) to search for may be any bytes-like object."]}, {"name": "bytes.strip()", "path": "library/stdtypes#bytes.strip", "type": "Built-in Types", "text": ["Return a copy of the sequence with specified leading and trailing bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:", "The binary sequence of byte values to remove may be any bytes-like object.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.swapcase()", "path": "library/stdtypes#bytes.swapcase", "type": "Built-in Types", "text": ["Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart and vice-versa.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "Unlike str.swapcase(), it is always the case that bin.swapcase().swapcase() == bin for the binary versions. Case conversions are symmetrical in ASCII, even though that is not generally true for arbitrary Unicode code points.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.title()", "path": "library/stdtypes#bytes.title", "type": "Built-in Types", "text": ["Return a titlecased version of the binary sequence where words start with an uppercase ASCII character and the remaining characters are lowercase. Uncased byte values are left unmodified.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'. All other byte values are uncased.", "The algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The definition works in many contexts but it means that apostrophes in contractions and possessives form word boundaries, which may not be the desired result:", "A workaround for apostrophes can be constructed using regular expressions:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.translate()", "path": "library/stdtypes#bytes.translate", "type": "Built-in Types", "text": ["Return a copy of the bytes or bytearray object where all bytes occurring in the optional argument delete are removed, and the remaining bytes have been mapped through the given translation table, which must be a bytes object of length 256.", "You can use the bytes.maketrans() method to create a translation table.", "Set the table argument to None for translations that only delete characters:", "Changed in version 3.6: delete is now supported as a keyword argument."]}, {"name": "bytes.upper()", "path": "library/stdtypes#bytes.upper", "type": "Built-in Types", "text": ["Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart.", "For example:", "Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "bytes.zfill()", "path": "library/stdtypes#bytes.zfill", "type": "Built-in Types", "text": ["Return a copy of the sequence left filled with ASCII b'0' digits to make a sequence of length width. A leading sign prefix (b'+'/ b'-') is handled by inserting the padding after the sign character rather than before. For bytes objects, the original sequence is returned if width is less than or equal to len(seq).", "For example:", "Note", "The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made."]}, {"name": "BytesWarning", "path": "library/exceptions#BytesWarning", "type": "Built-in Exceptions", "text": ["Base class for warnings related to bytes and bytearray."]}, {"name": "bz2", "path": "library/bz2", "type": "Data Compression", "text": ["Source code: Lib/bz2.py", "This module provides a comprehensive interface for compressing and decompressing data using the bzip2 compression algorithm.", "The bz2 module contains:", "All of the classes in this module may safely be accessed from multiple threads.", "Open a bzip2-compressed file in binary or text mode, returning a file object.", "As with the constructor for BZ2File, the filename argument can be an actual filename (a str or bytes object), or an existing file object to read from or write to.", "The mode argument can be any of 'r', 'rb', 'w', 'wb', 'x', 'xb', 'a' or 'ab' for binary mode, or 'rt', 'wt', 'xt', or 'at' for text mode. The default is 'rb'.", "The compresslevel argument is an integer from 1 to 9, as for the BZ2File constructor.", "For binary mode, this function is equivalent to the BZ2File constructor: BZ2File(filename, mode, compresslevel=compresslevel). In this case, the encoding, errors and newline arguments must not be provided.", "For text mode, a BZ2File object is created, and wrapped in an io.TextIOWrapper instance with the specified encoding, error handling behavior, and line ending(s).", "New in version 3.3.", "Changed in version 3.4: The 'x' (exclusive creation) mode was added.", "Changed in version 3.6: Accepts a path-like object.", "Open a bzip2-compressed file in binary mode.", "If filename is a str or bytes object, open the named file directly. Otherwise, filename should be a file object, which will be used to read or write the compressed data.", "The mode argument can be either 'r' for reading (default), 'w' for overwriting, 'x' for exclusive creation, or 'a' for appending. These can equivalently be given as 'rb', 'wb', 'xb' and 'ab' respectively.", "If filename is a file object (rather than an actual file name), a mode of 'w' does not truncate the file, and is instead equivalent to 'a'.", "If mode is 'w' or 'a', compresslevel can be an integer between 1 and 9 specifying the level of compression: 1 produces the least compression, and 9 (default) produces the most compression.", "If mode is 'r', the input file may be the concatenation of multiple compressed streams.", "BZ2File provides all of the members specified by the io.BufferedIOBase, except for detach() and truncate(). Iteration and the with statement are supported.", "BZ2File also provides the following method:", "Return buffered data without advancing the file position. At least one byte of data will be returned (unless at EOF). The exact number of bytes returned is unspecified.", "Note", "While calling peek() does not change the file position of the BZ2File, it may change the position of the underlying file object (e.g. if the BZ2File was constructed by passing a file object for filename).", "New in version 3.3.", "Changed in version 3.1: Support for the with statement was added.", "Changed in version 3.3: The fileno(), readable(), seekable(), writable(), read1() and readinto() methods were added.", "Changed in version 3.3: Support was added for filename being a file object instead of an actual filename.", "Changed in version 3.3: The 'a' (append) mode was added, along with support for reading multi-stream files.", "Changed in version 3.4: The 'x' (exclusive creation) mode was added.", "Changed in version 3.5: The read() method now accepts an argument of None.", "Changed in version 3.6: Accepts a path-like object.", "Changed in version 3.9: The buffering parameter has been removed. It was ignored and deprecated since Python 3.0. Pass an open file object to control how the file is opened.", "The compresslevel parameter became keyword-only.", "Create a new compressor object. This object may be used to compress data incrementally. For one-shot compression, use the compress() function instead.", "compresslevel, if given, must be an integer between 1 and 9. The default is 9.", "Provide data to the compressor object. Returns a chunk of compressed data if possible, or an empty byte string otherwise.", "When you have finished providing data to the compressor, call the flush() method to finish the compression process.", "Finish the compression process. Returns the compressed data left in internal buffers.", "The compressor object may not be used after this method has been called.", "Create a new decompressor object. This object may be used to decompress data incrementally. For one-shot compression, use the decompress() function instead.", "Note", "This class does not transparently handle inputs containing multiple compressed streams, unlike decompress() and BZ2File. If you need to decompress a multi-stream input with BZ2Decompressor, you must use a new decompressor for each stream.", "Decompress data (a bytes-like object), returning uncompressed data as bytes. Some of data may be buffered internally, for use in later calls to decompress(). The returned data should be concatenated with the output of any previous calls to decompress().", "If max_length is nonnegative, returns at most max_length bytes of decompressed data. If this limit is reached and further output can be produced, the needs_input attribute will be set to False. In this case, the next call to decompress() may provide data as b'' to obtain more of the output.", "If all of the input data was decompressed and returned (either because this was less than max_length bytes, or because max_length was negative), the needs_input attribute will be set to True.", "Attempting to decompress data after the end of stream is reached raises an EOFError. Any data found after the end of the stream is ignored and saved in the unused_data attribute.", "Changed in version 3.5: Added the max_length parameter.", "True if the end-of-stream marker has been reached.", "New in version 3.3.", "Data found after the end of the compressed stream.", "If this attribute is accessed before the end of the stream has been reached, its value will be b''.", "False if the decompress() method can provide more decompressed data before requiring new uncompressed input.", "New in version 3.5.", "Compress data, a bytes-like object.", "compresslevel, if given, must be an integer between 1 and 9. The default is 9.", "For incremental compression, use a BZ2Compressor instead.", "Decompress data, a bytes-like object.", "If data is the concatenation of multiple compressed streams, decompress all of the streams.", "For incremental decompression, use a BZ2Decompressor instead.", "Changed in version 3.3: Support for multi-stream inputs was added.", "Below are some examples of typical usage of the bz2 module.", "Using compress() and decompress() to demonstrate round-trip compression:", "Using BZ2Compressor for incremental compression:", "The example above uses a very \u201cnonrandom\u201d stream of data (a stream of b\u201dz\u201d chunks). Random data tends to compress poorly, while ordered, repetitive data usually yields a high compression ratio.", "Writing and reading a bzip2-compressed file in binary mode:"]}, {"name": "bz2.BZ2Compressor", "path": "library/bz2#bz2.BZ2Compressor", "type": "Data Compression", "text": ["Create a new compressor object. This object may be used to compress data incrementally. For one-shot compression, use the compress() function instead.", "compresslevel, if given, must be an integer between 1 and 9. The default is 9.", "Provide data to the compressor object. Returns a chunk of compressed data if possible, or an empty byte string otherwise.", "When you have finished providing data to the compressor, call the flush() method to finish the compression process.", "Finish the compression process. Returns the compressed data left in internal buffers.", "The compressor object may not be used after this method has been called."]}, {"name": "bz2.BZ2Compressor.compress()", "path": "library/bz2#bz2.BZ2Compressor.compress", "type": "Data Compression", "text": ["Provide data to the compressor object. Returns a chunk of compressed data if possible, or an empty byte string otherwise.", "When you have finished providing data to the compressor, call the flush() method to finish the compression process."]}, {"name": "bz2.BZ2Compressor.flush()", "path": "library/bz2#bz2.BZ2Compressor.flush", "type": "Data Compression", "text": ["Finish the compression process. Returns the compressed data left in internal buffers.", "The compressor object may not be used after this method has been called."]}, {"name": "bz2.BZ2Decompressor", "path": "library/bz2#bz2.BZ2Decompressor", "type": "Data Compression", "text": ["Create a new decompressor object. This object may be used to decompress data incrementally. For one-shot compression, use the decompress() function instead.", "Note", "This class does not transparently handle inputs containing multiple compressed streams, unlike decompress() and BZ2File. If you need to decompress a multi-stream input with BZ2Decompressor, you must use a new decompressor for each stream.", "Decompress data (a bytes-like object), returning uncompressed data as bytes. Some of data may be buffered internally, for use in later calls to decompress(). The returned data should be concatenated with the output of any previous calls to decompress().", "If max_length is nonnegative, returns at most max_length bytes of decompressed data. If this limit is reached and further output can be produced, the needs_input attribute will be set to False. In this case, the next call to decompress() may provide data as b'' to obtain more of the output.", "If all of the input data was decompressed and returned (either because this was less than max_length bytes, or because max_length was negative), the needs_input attribute will be set to True.", "Attempting to decompress data after the end of stream is reached raises an EOFError. Any data found after the end of the stream is ignored and saved in the unused_data attribute.", "Changed in version 3.5: Added the max_length parameter.", "True if the end-of-stream marker has been reached.", "New in version 3.3.", "Data found after the end of the compressed stream.", "If this attribute is accessed before the end of the stream has been reached, its value will be b''.", "False if the decompress() method can provide more decompressed data before requiring new uncompressed input.", "New in version 3.5."]}, {"name": "bz2.BZ2Decompressor.decompress()", "path": "library/bz2#bz2.BZ2Decompressor.decompress", "type": "Data Compression", "text": ["Decompress data (a bytes-like object), returning uncompressed data as bytes. Some of data may be buffered internally, for use in later calls to decompress(). The returned data should be concatenated with the output of any previous calls to decompress().", "If max_length is nonnegative, returns at most max_length bytes of decompressed data. If this limit is reached and further output can be produced, the needs_input attribute will be set to False. In this case, the next call to decompress() may provide data as b'' to obtain more of the output.", "If all of the input data was decompressed and returned (either because this was less than max_length bytes, or because max_length was negative), the needs_input attribute will be set to True.", "Attempting to decompress data after the end of stream is reached raises an EOFError. Any data found after the end of the stream is ignored and saved in the unused_data attribute.", "Changed in version 3.5: Added the max_length parameter."]}, {"name": "bz2.BZ2Decompressor.eof", "path": "library/bz2#bz2.BZ2Decompressor.eof", "type": "Data Compression", "text": ["True if the end-of-stream marker has been reached.", "New in version 3.3."]}, {"name": "bz2.BZ2Decompressor.needs_input", "path": "library/bz2#bz2.BZ2Decompressor.needs_input", "type": "Data Compression", "text": ["False if the decompress() method can provide more decompressed data before requiring new uncompressed input.", "New in version 3.5."]}, {"name": "bz2.BZ2Decompressor.unused_data", "path": "library/bz2#bz2.BZ2Decompressor.unused_data", "type": "Data Compression", "text": ["Data found after the end of the compressed stream.", "If this attribute is accessed before the end of the stream has been reached, its value will be b''."]}, {"name": "bz2.BZ2File", "path": "library/bz2#bz2.BZ2File", "type": "Data Compression", "text": ["Open a bzip2-compressed file in binary mode.", "If filename is a str or bytes object, open the named file directly. Otherwise, filename should be a file object, which will be used to read or write the compressed data.", "The mode argument can be either 'r' for reading (default), 'w' for overwriting, 'x' for exclusive creation, or 'a' for appending. These can equivalently be given as 'rb', 'wb', 'xb' and 'ab' respectively.", "If filename is a file object (rather than an actual file name), a mode of 'w' does not truncate the file, and is instead equivalent to 'a'.", "If mode is 'w' or 'a', compresslevel can be an integer between 1 and 9 specifying the level of compression: 1 produces the least compression, and 9 (default) produces the most compression.", "If mode is 'r', the input file may be the concatenation of multiple compressed streams.", "BZ2File provides all of the members specified by the io.BufferedIOBase, except for detach() and truncate(). Iteration and the with statement are supported.", "BZ2File also provides the following method:", "Return buffered data without advancing the file position. At least one byte of data will be returned (unless at EOF). The exact number of bytes returned is unspecified.", "Note", "While calling peek() does not change the file position of the BZ2File, it may change the position of the underlying file object (e.g. if the BZ2File was constructed by passing a file object for filename).", "New in version 3.3.", "Changed in version 3.1: Support for the with statement was added.", "Changed in version 3.3: The fileno(), readable(), seekable(), writable(), read1() and readinto() methods were added.", "Changed in version 3.3: Support was added for filename being a file object instead of an actual filename.", "Changed in version 3.3: The 'a' (append) mode was added, along with support for reading multi-stream files.", "Changed in version 3.4: The 'x' (exclusive creation) mode was added.", "Changed in version 3.5: The read() method now accepts an argument of None.", "Changed in version 3.6: Accepts a path-like object.", "Changed in version 3.9: The buffering parameter has been removed. It was ignored and deprecated since Python 3.0. Pass an open file object to control how the file is opened.", "The compresslevel parameter became keyword-only."]}, {"name": "bz2.BZ2File.peek()", "path": "library/bz2#bz2.BZ2File.peek", "type": "Data Compression", "text": ["Return buffered data without advancing the file position. At least one byte of data will be returned (unless at EOF). The exact number of bytes returned is unspecified.", "Note", "While calling peek() does not change the file position of the BZ2File, it may change the position of the underlying file object (e.g. if the BZ2File was constructed by passing a file object for filename).", "New in version 3.3."]}, {"name": "bz2.compress()", "path": "library/bz2#bz2.compress", "type": "Data Compression", "text": ["Compress data, a bytes-like object.", "compresslevel, if given, must be an integer between 1 and 9. The default is 9.", "For incremental compression, use a BZ2Compressor instead."]}, {"name": "bz2.decompress()", "path": "library/bz2#bz2.decompress", "type": "Data Compression", "text": ["Decompress data, a bytes-like object.", "If data is the concatenation of multiple compressed streams, decompress all of the streams.", "For incremental decompression, use a BZ2Decompressor instead.", "Changed in version 3.3: Support for multi-stream inputs was added."]}, {"name": "bz2.open()", "path": "library/bz2#bz2.open", "type": "Data Compression", "text": ["Open a bzip2-compressed file in binary or text mode, returning a file object.", "As with the constructor for BZ2File, the filename argument can be an actual filename (a str or bytes object), or an existing file object to read from or write to.", "The mode argument can be any of 'r', 'rb', 'w', 'wb', 'x', 'xb', 'a' or 'ab' for binary mode, or 'rt', 'wt', 'xt', or 'at' for text mode. The default is 'rb'.", "The compresslevel argument is an integer from 1 to 9, as for the BZ2File constructor.", "For binary mode, this function is equivalent to the BZ2File constructor: BZ2File(filename, mode, compresslevel=compresslevel). In this case, the encoding, errors and newline arguments must not be provided.", "For text mode, a BZ2File object is created, and wrapped in an io.TextIOWrapper instance with the specified encoding, error handling behavior, and line ending(s).", "New in version 3.3.", "Changed in version 3.4: The 'x' (exclusive creation) mode was added.", "Changed in version 3.6: Accepts a path-like object."]}, {"name": "calendar", "path": "library/calendar", "type": "Data Types", "text": ["Source code: Lib/calendar.py", "This module allows you to output calendars like the Unix cal program, and provides additional useful functions related to the calendar. By default, these calendars have Monday as the first day of the week, and Sunday as the last (the European convention). Use setfirstweekday() to set the first day of the week to Sunday (6) or to any other weekday. Parameters that specify dates are given as integers. For related functionality, see also the datetime and time modules.", "The functions and classes defined in this module use an idealized calendar, the current Gregorian calendar extended indefinitely in both directions. This matches the definition of the \u201cproleptic Gregorian\u201d calendar in Dershowitz and Reingold\u2019s book \u201cCalendrical Calculations\u201d, where it\u2019s the base calendar for all computations. Zero and negative years are interpreted as prescribed by the ISO 8601 standard. Year 0 is 1 BC, year -1 is 2 BC, and so on.", "Creates a Calendar object. firstweekday is an integer specifying the first day of the week. 0 is Monday (the default), 6 is Sunday.", "A Calendar object provides several methods that can be used for preparing the calendar data for formatting. This class doesn\u2019t do any formatting itself. This is the job of subclasses.", "Calendar instances have the following methods:", "Return an iterator for the week day numbers that will be used for one week. The first value from the iterator will be the same as the value of the firstweekday property.", "Return an iterator for the month month (1\u201312) in the year year. This iterator will return all days (as datetime.date objects) for the month and all days before the start of the month or after the end of the month that are required to get a complete week.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will simply be day of the month numbers. For the days outside of the specified month, the day number is 0.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a day of the month number and a week day number.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a year, a month and a day of the month numbers.", "New in version 3.7.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a year, a month, a day of the month, and a day of the week numbers.", "New in version 3.7.", "Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven datetime.date objects.", "Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven tuples of day numbers and weekday numbers.", "Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven day numbers.", "Return the data for the specified year ready for formatting. The return value is a list of month rows. Each month row contains up to width months (defaulting to 3). Each month contains between 4 and 6 weeks and each week contains 1\u20137 days. Days are datetime.date objects.", "Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are tuples of day numbers and weekday numbers. Day numbers outside this month are zero.", "Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are day numbers. Day numbers outside this month are zero.", "This class can be used to generate plain text calendars.", "TextCalendar instances have the following methods:", "Return a month\u2019s calendar in a multi-line string. If w is provided, it specifies the width of the date columns, which are centered. If l is given, it specifies the number of lines that each week will use. Depends on the first weekday as specified in the constructor or set by the setfirstweekday() method.", "Print a month\u2019s calendar as returned by formatmonth().", "Return a m-column calendar for an entire year as a multi-line string. Optional parameters w, l, and c are for date column width, lines per week, and number of spaces between month columns, respectively. Depends on the first weekday as specified in the constructor or set by the setfirstweekday() method. The earliest year for which a calendar can be generated is platform-dependent.", "Print the calendar for an entire year as returned by formatyear().", "This class can be used to generate HTML calendars.", "HTMLCalendar instances have the following methods:", "Return a month\u2019s calendar as an HTML table. If withyear is true the year will be included in the header, otherwise just the month name will be used.", "Return a year\u2019s calendar as an HTML table. width (defaulting to 3) specifies the number of months per row.", "Return a year\u2019s calendar as a complete HTML page. width (defaulting to 3) specifies the number of months per row. css is the name for the cascading style sheet to be used. None can be passed if no style sheet should be used. encoding specifies the encoding to be used for the output (defaulting to the system default encoding).", "HTMLCalendar has the following attributes you can override to customize the CSS classes used by the calendar:", "A list of CSS classes used for each weekday. The default class list is:", "more styles can be added for each day:", "Note that the length of this list must be seven items.", "The CSS class for a weekday occurring in the previous or coming month.", "New in version 3.7.", "A list of CSS classes used for weekday names in the header row. The default is the same as cssclasses.", "New in version 3.7.", "The month\u2019s head CSS class (used by formatmonthname()). The default value is \"month\".", "New in version 3.7.", "The CSS class for the whole month\u2019s table (used by formatmonth()). The default value is \"month\".", "New in version 3.7.", "The CSS class for the whole year\u2019s table of tables (used by formatyear()). The default value is \"year\".", "New in version 3.7.", "The CSS class for the table head for the whole year (used by formatyear()). The default value is \"year\".", "New in version 3.7.", "Note that although the naming for the above described class attributes is singular (e.g. cssclass_month cssclass_noday), one can replace the single CSS class with a space separated list of CSS classes, for example:", "Here is an example how HTMLCalendar can be customized:", "This subclass of TextCalendar can be passed a locale name in the constructor and will return month and weekday names in the specified locale. If this locale includes an encoding all strings containing month and weekday names will be returned as unicode.", "This subclass of HTMLCalendar can be passed a locale name in the constructor and will return month and weekday names in the specified locale. If this locale includes an encoding all strings containing month and weekday names will be returned as unicode.", "Note", "The formatweekday() and formatmonthname() methods of these two classes temporarily change the current locale to the given locale. Because the current locale is a process-wide setting, they are not thread-safe.", "For simple text calendars this module provides the following functions.", "Sets the weekday (0 is Monday, 6 is Sunday) to start each week. The values MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, and SUNDAY are provided for convenience. For example, to set the first weekday to Sunday:", "Returns the current setting for the weekday to start each week.", "Returns True if year is a leap year, otherwise False.", "Returns the number of leap years in the range from y1 to y2 (exclusive), where y1 and y2 are years.", "This function works for ranges spanning a century change.", "Returns the day of the week (0 is Monday) for year (1970\u2013\u2026), month (1\u201312), day (1\u201331).", "Return a header containing abbreviated weekday names. n specifies the width in characters for one weekday.", "Returns weekday of first day of the month and number of days in month, for the specified year and month.", "Returns a matrix representing a month\u2019s calendar. Each row represents a week; days outside of the month are represented by zeros. Each week begins with Monday unless set by setfirstweekday().", "Prints a month\u2019s calendar as returned by month().", "Returns a month\u2019s calendar in a multi-line string using the formatmonth() of the TextCalendar class.", "Prints the calendar for an entire year as returned by calendar().", "Returns a 3-column calendar for an entire year as a multi-line string using the formatyear() of the TextCalendar class.", "An unrelated but handy function that takes a time tuple such as returned by the gmtime() function in the time module, and returns the corresponding Unix timestamp value, assuming an epoch of 1970, and the POSIX encoding. In fact, time.gmtime() and timegm() are each others\u2019 inverse.", "The calendar module exports the following data attributes:", "An array that represents the days of the week in the current locale.", "An array that represents the abbreviated days of the week in the current locale.", "An array that represents the months of the year in the current locale. This follows normal convention of January being month number 1, so it has a length of 13 and month_name[0] is the empty string.", "An array that represents the abbreviated months of the year in the current locale. This follows normal convention of January being month number 1, so it has a length of 13 and month_abbr[0] is the empty string.", "See also", "Object-oriented interface to dates and times with similar functionality to the time module.", "Low-level time related functions."]}, {"name": "calendar.Calendar", "path": "library/calendar#calendar.Calendar", "type": "Data Types", "text": ["Creates a Calendar object. firstweekday is an integer specifying the first day of the week. 0 is Monday (the default), 6 is Sunday.", "A Calendar object provides several methods that can be used for preparing the calendar data for formatting. This class doesn\u2019t do any formatting itself. This is the job of subclasses.", "Calendar instances have the following methods:", "Return an iterator for the week day numbers that will be used for one week. The first value from the iterator will be the same as the value of the firstweekday property.", "Return an iterator for the month month (1\u201312) in the year year. This iterator will return all days (as datetime.date objects) for the month and all days before the start of the month or after the end of the month that are required to get a complete week.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will simply be day of the month numbers. For the days outside of the specified month, the day number is 0.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a day of the month number and a week day number.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a year, a month and a day of the month numbers.", "New in version 3.7.", "Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a year, a month, a day of the month, and a day of the week numbers.", "New in version 3.7.", "Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven datetime.date objects.", "Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven tuples of day numbers and weekday numbers.", "Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven day numbers.", "Return the data for the specified year ready for formatting. The return value is a list of month rows. Each month row contains up to width months (defaulting to 3). Each month contains between 4 and 6 weeks and each week contains 1\u20137 days. Days are datetime.date objects.", "Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are tuples of day numbers and weekday numbers. Day numbers outside this month are zero.", "Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are day numbers. Day numbers outside this month are zero."]}, {"name": "calendar.calendar()", "path": "library/calendar#calendar.calendar", "type": "Data Types", "text": ["Returns a 3-column calendar for an entire year as a multi-line string using the formatyear() of the TextCalendar class."]}, {"name": "calendar.Calendar.itermonthdates()", "path": "library/calendar#calendar.Calendar.itermonthdates", "type": "Data Types", "text": ["Return an iterator for the month month (1\u201312) in the year year. This iterator will return all days (as datetime.date objects) for the month and all days before the start of the month or after the end of the month that are required to get a complete week."]}, {"name": "calendar.Calendar.itermonthdays()", "path": "library/calendar#calendar.Calendar.itermonthdays", "type": "Data Types", "text": ["Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will simply be day of the month numbers. For the days outside of the specified month, the day number is 0."]}, {"name": "calendar.Calendar.itermonthdays2()", "path": "library/calendar#calendar.Calendar.itermonthdays2", "type": "Data Types", "text": ["Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a day of the month number and a week day number."]}, {"name": "calendar.Calendar.itermonthdays3()", "path": "library/calendar#calendar.Calendar.itermonthdays3", "type": "Data Types", "text": ["Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a year, a month and a day of the month numbers.", "New in version 3.7."]}, {"name": "calendar.Calendar.itermonthdays4()", "path": "library/calendar#calendar.Calendar.itermonthdays4", "type": "Data Types", "text": ["Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted by the datetime.date range. Days returned will be tuples consisting of a year, a month, a day of the month, and a day of the week numbers.", "New in version 3.7."]}, {"name": "calendar.Calendar.iterweekdays()", "path": "library/calendar#calendar.Calendar.iterweekdays", "type": "Data Types", "text": ["Return an iterator for the week day numbers that will be used for one week. The first value from the iterator will be the same as the value of the firstweekday property."]}, {"name": "calendar.Calendar.monthdatescalendar()", "path": "library/calendar#calendar.Calendar.monthdatescalendar", "type": "Data Types", "text": ["Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven datetime.date objects."]}, {"name": "calendar.Calendar.monthdays2calendar()", "path": "library/calendar#calendar.Calendar.monthdays2calendar", "type": "Data Types", "text": ["Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven tuples of day numbers and weekday numbers."]}, {"name": "calendar.Calendar.monthdayscalendar()", "path": "library/calendar#calendar.Calendar.monthdayscalendar", "type": "Data Types", "text": ["Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven day numbers."]}, {"name": "calendar.Calendar.yeardatescalendar()", "path": "library/calendar#calendar.Calendar.yeardatescalendar", "type": "Data Types", "text": ["Return the data for the specified year ready for formatting. The return value is a list of month rows. Each month row contains up to width months (defaulting to 3). Each month contains between 4 and 6 weeks and each week contains 1\u20137 days. Days are datetime.date objects."]}, {"name": "calendar.Calendar.yeardays2calendar()", "path": "library/calendar#calendar.Calendar.yeardays2calendar", "type": "Data Types", "text": ["Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are tuples of day numbers and weekday numbers. Day numbers outside this month are zero."]}, {"name": "calendar.Calendar.yeardayscalendar()", "path": "library/calendar#calendar.Calendar.yeardayscalendar", "type": "Data Types", "text": ["Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are day numbers. Day numbers outside this month are zero."]}, {"name": "calendar.day_abbr", "path": "library/calendar#calendar.day_abbr", "type": "Data Types", "text": ["An array that represents the abbreviated days of the week in the current locale."]}, {"name": "calendar.day_name", "path": "library/calendar#calendar.day_name", "type": "Data Types", "text": ["An array that represents the days of the week in the current locale."]}, {"name": "calendar.firstweekday()", "path": "library/calendar#calendar.firstweekday", "type": "Data Types", "text": ["Returns the current setting for the weekday to start each week."]}, {"name": "calendar.HTMLCalendar", "path": "library/calendar#calendar.HTMLCalendar", "type": "Data Types", "text": ["This class can be used to generate HTML calendars.", "HTMLCalendar instances have the following methods:", "Return a month\u2019s calendar as an HTML table. If withyear is true the year will be included in the header, otherwise just the month name will be used.", "Return a year\u2019s calendar as an HTML table. width (defaulting to 3) specifies the number of months per row.", "Return a year\u2019s calendar as a complete HTML page. width (defaulting to 3) specifies the number of months per row. css is the name for the cascading style sheet to be used. None can be passed if no style sheet should be used. encoding specifies the encoding to be used for the output (defaulting to the system default encoding).", "HTMLCalendar has the following attributes you can override to customize the CSS classes used by the calendar:", "A list of CSS classes used for each weekday. The default class list is:", "more styles can be added for each day:", "Note that the length of this list must be seven items.", "The CSS class for a weekday occurring in the previous or coming month.", "New in version 3.7.", "A list of CSS classes used for weekday names in the header row. The default is the same as cssclasses.", "New in version 3.7.", "The month\u2019s head CSS class (used by formatmonthname()). The default value is \"month\".", "New in version 3.7.", "The CSS class for the whole month\u2019s table (used by formatmonth()). The default value is \"month\".", "New in version 3.7.", "The CSS class for the whole year\u2019s table of tables (used by formatyear()). The default value is \"year\".", "New in version 3.7.", "The CSS class for the table head for the whole year (used by formatyear()). The default value is \"year\".", "New in version 3.7.", "Note that although the naming for the above described class attributes is singular (e.g. cssclass_month cssclass_noday), one can replace the single CSS class with a space separated list of CSS classes, for example:", "Here is an example how HTMLCalendar can be customized:"]}, {"name": "calendar.HTMLCalendar.cssclasses", "path": "library/calendar#calendar.HTMLCalendar.cssclasses", "type": "Data Types", "text": ["A list of CSS classes used for each weekday. The default class list is:", "more styles can be added for each day:", "Note that the length of this list must be seven items."]}, {"name": "calendar.HTMLCalendar.cssclasses_weekday_head", "path": "library/calendar#calendar.HTMLCalendar.cssclasses_weekday_head", "type": "Data Types", "text": ["A list of CSS classes used for weekday names in the header row. The default is the same as cssclasses.", "New in version 3.7."]}, {"name": "calendar.HTMLCalendar.cssclass_month", "path": "library/calendar#calendar.HTMLCalendar.cssclass_month", "type": "Data Types", "text": ["The CSS class for the whole month\u2019s table (used by formatmonth()). The default value is \"month\".", "New in version 3.7."]}, {"name": "calendar.HTMLCalendar.cssclass_month_head", "path": "library/calendar#calendar.HTMLCalendar.cssclass_month_head", "type": "Data Types", "text": ["The month\u2019s head CSS class (used by formatmonthname()). The default value is \"month\".", "New in version 3.7."]}, {"name": "calendar.HTMLCalendar.cssclass_noday", "path": "library/calendar#calendar.HTMLCalendar.cssclass_noday", "type": "Data Types", "text": ["The CSS class for a weekday occurring in the previous or coming month.", "New in version 3.7."]}, {"name": "calendar.HTMLCalendar.cssclass_year", "path": "library/calendar#calendar.HTMLCalendar.cssclass_year", "type": "Data Types", "text": ["The CSS class for the whole year\u2019s table of tables (used by formatyear()). The default value is \"year\".", "New in version 3.7."]}, {"name": "calendar.HTMLCalendar.cssclass_year_head", "path": "library/calendar#calendar.HTMLCalendar.cssclass_year_head", "type": "Data Types", "text": ["The CSS class for the table head for the whole year (used by formatyear()). The default value is \"year\".", "New in version 3.7."]}, {"name": "calendar.HTMLCalendar.formatmonth()", "path": "library/calendar#calendar.HTMLCalendar.formatmonth", "type": "Data Types", "text": ["Return a month\u2019s calendar as an HTML table. If withyear is true the year will be included in the header, otherwise just the month name will be used."]}, {"name": "calendar.HTMLCalendar.formatyear()", "path": "library/calendar#calendar.HTMLCalendar.formatyear", "type": "Data Types", "text": ["Return a year\u2019s calendar as an HTML table. width (defaulting to 3) specifies the number of months per row."]}, {"name": "calendar.HTMLCalendar.formatyearpage()", "path": "library/calendar#calendar.HTMLCalendar.formatyearpage", "type": "Data Types", "text": ["Return a year\u2019s calendar as a complete HTML page. width (defaulting to 3) specifies the number of months per row. css is the name for the cascading style sheet to be used. None can be passed if no style sheet should be used. encoding specifies the encoding to be used for the output (defaulting to the system default encoding)."]}, {"name": "calendar.isleap()", "path": "library/calendar#calendar.isleap", "type": "Data Types", "text": ["Returns True if year is a leap year, otherwise False."]}, {"name": "calendar.leapdays()", "path": "library/calendar#calendar.leapdays", "type": "Data Types", "text": ["Returns the number of leap years in the range from y1 to y2 (exclusive), where y1 and y2 are years.", "This function works for ranges spanning a century change."]}, {"name": "calendar.LocaleHTMLCalendar", "path": "library/calendar#calendar.LocaleHTMLCalendar", "type": "Data Types", "text": ["This subclass of HTMLCalendar can be passed a locale name in the constructor and will return month and weekday names in the specified locale. If this locale includes an encoding all strings containing month and weekday names will be returned as unicode."]}, {"name": "calendar.LocaleTextCalendar", "path": "library/calendar#calendar.LocaleTextCalendar", "type": "Data Types", "text": ["This subclass of TextCalendar can be passed a locale name in the constructor and will return month and weekday names in the specified locale. If this locale includes an encoding all strings containing month and weekday names will be returned as unicode."]}, {"name": "calendar.month()", "path": "library/calendar#calendar.month", "type": "Data Types", "text": ["Returns a month\u2019s calendar in a multi-line string using the formatmonth() of the TextCalendar class."]}, {"name": "calendar.monthcalendar()", "path": "library/calendar#calendar.monthcalendar", "type": "Data Types", "text": ["Returns a matrix representing a month\u2019s calendar. Each row represents a week; days outside of the month are represented by zeros. Each week begins with Monday unless set by setfirstweekday()."]}, {"name": "calendar.monthrange()", "path": "library/calendar#calendar.monthrange", "type": "Data Types", "text": ["Returns weekday of first day of the month and number of days in month, for the specified year and month."]}, {"name": "calendar.month_abbr", "path": "library/calendar#calendar.month_abbr", "type": "Data Types", "text": ["An array that represents the abbreviated months of the year in the current locale. This follows normal convention of January being month number 1, so it has a length of 13 and month_abbr[0] is the empty string."]}, {"name": "calendar.month_name", "path": "library/calendar#calendar.month_name", "type": "Data Types", "text": ["An array that represents the months of the year in the current locale. This follows normal convention of January being month number 1, so it has a length of 13 and month_name[0] is the empty string."]}, {"name": "calendar.prcal()", "path": "library/calendar#calendar.prcal", "type": "Data Types", "text": ["Prints the calendar for an entire year as returned by calendar()."]}, {"name": "calendar.prmonth()", "path": "library/calendar#calendar.prmonth", "type": "Data Types", "text": ["Prints a month\u2019s calendar as returned by month()."]}, {"name": "calendar.setfirstweekday()", "path": "library/calendar#calendar.setfirstweekday", "type": "Data Types", "text": ["Sets the weekday (0 is Monday, 6 is Sunday) to start each week. The values MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, and SUNDAY are provided for convenience. For example, to set the first weekday to Sunday:"]}, {"name": "calendar.TextCalendar", "path": "library/calendar#calendar.TextCalendar", "type": "Data Types", "text": ["This class can be used to generate plain text calendars.", "TextCalendar instances have the following methods:", "Return a month\u2019s calendar in a multi-line string. If w is provided, it specifies the width of the date columns, which are centered. If l is given, it specifies the number of lines that each week will use. Depends on the first weekday as specified in the constructor or set by the setfirstweekday() method.", "Print a month\u2019s calendar as returned by formatmonth().", "Return a m-column calendar for an entire year as a multi-line string. Optional parameters w, l, and c are for date column width, lines per week, and number of spaces between month columns, respectively. Depends on the first weekday as specified in the constructor or set by the setfirstweekday() method. The earliest year for which a calendar can be generated is platform-dependent.", "Print the calendar for an entire year as returned by formatyear()."]}, {"name": "calendar.TextCalendar.formatmonth()", "path": "library/calendar#calendar.TextCalendar.formatmonth", "type": "Data Types", "text": ["Return a month\u2019s calendar in a multi-line string. If w is provided, it specifies the width of the date columns, which are centered. If l is given, it specifies the number of lines that each week will use. Depends on the first weekday as specified in the constructor or set by the setfirstweekday() method."]}, {"name": "calendar.TextCalendar.formatyear()", "path": "library/calendar#calendar.TextCalendar.formatyear", "type": "Data Types", "text": ["Return a m-column calendar for an entire year as a multi-line string. Optional parameters w, l, and c are for date column width, lines per week, and number of spaces between month columns, respectively. Depends on the first weekday as specified in the constructor or set by the setfirstweekday() method. The earliest year for which a calendar can be generated is platform-dependent."]}, {"name": "calendar.TextCalendar.prmonth()", "path": "library/calendar#calendar.TextCalendar.prmonth", "type": "Data Types", "text": ["Print a month\u2019s calendar as returned by formatmonth()."]}, {"name": "calendar.TextCalendar.pryear()", "path": "library/calendar#calendar.TextCalendar.pryear", "type": "Data Types", "text": ["Print the calendar for an entire year as returned by formatyear()."]}, {"name": "calendar.timegm()", "path": "library/calendar#calendar.timegm", "type": "Data Types", "text": ["An unrelated but handy function that takes a time tuple such as returned by the gmtime() function in the time module, and returns the corresponding Unix timestamp value, assuming an epoch of 1970, and the POSIX encoding. In fact, time.gmtime() and timegm() are each others\u2019 inverse."]}, {"name": "calendar.weekday()", "path": "library/calendar#calendar.weekday", "type": "Data Types", "text": ["Returns the day of the week (0 is Monday) for year (1970\u2013\u2026), month (1\u201312), day (1\u201331)."]}, {"name": "calendar.weekheader()", "path": "library/calendar#calendar.weekheader", "type": "Data Types", "text": ["Return a header containing abbreviated weekday names. n specifies the width in characters for one weekday."]}, {"name": "callable()", "path": "library/functions#callable", "type": "Built-in Functions", "text": ["Return True if the object argument appears callable, False if not. If this returns True, it is still possible that a call fails, but if it is False, calling object will never succeed. Note that classes are callable (calling a class returns a new instance); instances are callable if their class has a __call__() method.", "New in version 3.2: This function was first removed in Python 3.0 and then brought back in Python 3.2."]}, {"name": "cgi", "path": "library/cgi", "type": "Internet", "text": ["Source code: Lib/cgi.py", "Support module for Common Gateway Interface (CGI) scripts.", "This module defines a number of utilities for use by CGI scripts written in Python.", "A CGI script is invoked by an HTTP server, usually to process user input submitted through an HTML <FORM> or <ISINDEX> element.", "Most often, CGI scripts live in the server\u2019s special cgi-bin directory. The HTTP server places all sorts of information about the request (such as the client\u2019s hostname, the requested URL, the query string, and lots of other goodies) in the script\u2019s shell environment, executes the script, and sends the script\u2019s output back to the client.", "The script\u2019s input is connected to the client too, and sometimes the form data is read this way; at other times the form data is passed via the \u201cquery string\u201d part of the URL. This module is intended to take care of the different cases and provide a simpler interface to the Python script. It also provides a number of utilities that help in debugging scripts, and the latest addition is support for file uploads from a form (if your browser supports it).", "The output of a CGI script should consist of two sections, separated by a blank line. The first section contains a number of headers, telling the client what kind of data is following. Python code to generate a minimal header section looks like this:", "The second section is usually HTML, which allows the client software to display nicely formatted text with header, in-line images, etc. Here\u2019s Python code that prints a simple piece of HTML:", "Begin by writing import cgi.", "When you write a new script, consider adding these lines:", "This activates a special exception handler that will display detailed reports in the Web browser if any errors occur. If you\u2019d rather not show the guts of your program to users of your script, you can have the reports saved to files instead, with code like this:", "It\u2019s very helpful to use this feature during script development. The reports produced by cgitb provide information that can save you a lot of time in tracking down bugs. You can always remove the cgitb line later when you have tested your script and are confident that it works correctly.", "To get at submitted form data, use the FieldStorage class. If the form contains non-ASCII characters, use the encoding keyword parameter set to the value of the encoding defined for the document. It is usually contained in the META tag in the HEAD section of the HTML document or by the Content-Type header). This reads the form contents from the standard input or the environment (depending on the value of various environment variables set according to the CGI standard). Since it may consume standard input, it should be instantiated only once.", "The FieldStorage instance can be indexed like a Python dictionary. It allows membership testing with the in operator, and also supports the standard dictionary method keys() and the built-in function len(). Form fields containing empty strings are ignored and do not appear in the dictionary; to keep such values, provide a true value for the optional keep_blank_values keyword parameter when creating the FieldStorage instance.", "For instance, the following code (which assumes that the Content-Type header and blank line have already been printed) checks that the fields name and addr are both set to a non-empty string:", "Here the fields, accessed through form[key], are themselves instances of FieldStorage (or MiniFieldStorage, depending on the form encoding). The value attribute of the instance yields the string value of the field. The getvalue() method returns this string value directly; it also accepts an optional second argument as a default to return if the requested key is not present.", "If the submitted form data contains more than one field with the same name, the object retrieved by form[key] is not a FieldStorage or MiniFieldStorage instance but a list of such instances. Similarly, in this situation, form.getvalue(key) would return a list of strings. If you expect this possibility (when your HTML form contains multiple fields with the same name), use the getlist() method, which always returns a list of values (so that you do not need to special-case the single item case). For example, this code concatenates any number of username fields, separated by commas:", "If a field represents an uploaded file, accessing the value via the value attribute or the getvalue() method reads the entire file in memory as bytes. This may not be what you want. You can test for an uploaded file by testing either the filename attribute or the file attribute. You can then read the data from the file attribute before it is automatically closed as part of the garbage collection of the FieldStorage instance (the read() and readline() methods will return bytes):", "FieldStorage objects also support being used in a with statement, which will automatically close them when done.", "If an error is encountered when obtaining the contents of an uploaded file (for example, when the user interrupts the form submission by clicking on a Back or Cancel button) the done attribute of the object for the field will be set to the value -1.", "The file upload draft standard entertains the possibility of uploading multiple files from one field (using a recursive multipart/* encoding). When this occurs, the item will be a dictionary-like FieldStorage item. This can be determined by testing its type attribute, which should be multipart/form-data (or perhaps another MIME type matching multipart/*). In this case, it can be iterated over recursively just like the top-level form object.", "When a form is submitted in the \u201cold\u201d format (as the query string or as a single data part of type application/x-www-form-urlencoded), the items will actually be instances of the class MiniFieldStorage. In this case, the list, file, and filename attributes are always None.", "A form submitted via POST that also has a query string will contain both FieldStorage and MiniFieldStorage items.", "Changed in version 3.4: The file attribute is automatically closed upon the garbage collection of the creating FieldStorage instance.", "Changed in version 3.5: Added support for the context management protocol to the FieldStorage class.", "The previous section explains how to read CGI form data using the FieldStorage class. This section describes a higher level interface which was added to this class to allow one to do it in a more readable and intuitive way. The interface doesn\u2019t make the techniques described in previous sections obsolete \u2014 they are still useful to process file uploads efficiently, for example.", "The interface consists of two simple methods. Using the methods you can process form data in a generic way, without the need to worry whether only one or more values were posted under one name.", "In the previous section, you learned to write following code anytime you expected a user to post more than one value under one name:", "This situation is common for example when a form contains a group of multiple checkboxes with the same name:", "In most situations, however, there\u2019s only one form control with a particular name in a form and then you expect and need only one value associated with this name. So you write a script containing for example this code:", "The problem with the code is that you should never expect that a client will provide valid input to your scripts. For example, if a curious user appends another user=foo pair to the query string, then the script would crash, because in this situation the getvalue(\"user\") method call returns a list instead of a string. Calling the upper() method on a list is not valid (since lists do not have a method of this name) and results in an AttributeError exception.", "Therefore, the appropriate way to read form data values was to always use the code which checks whether the obtained value is a single value or a list of values. That\u2019s annoying and leads to less readable scripts.", "A more convenient approach is to use the methods getfirst() and getlist() provided by this higher level interface.", "This method always returns only one value associated with form field name. The method returns only the first value in case that more values were posted under such name. Please note that the order in which the values are received may vary from browser to browser and should not be counted on. 1 If no such form field or value exists then the method returns the value specified by the optional parameter default. This parameter defaults to None if not specified.", "This method always returns a list of values associated with form field name. The method returns an empty list if no such form field or value exists for name. It returns a list consisting of one item if only one such value exists.", "Using these methods you can write nice compact code:", "These are useful if you want more control, or if you want to employ some of the algorithms implemented in this module in other circumstances.", "Parse a query in the environment or from a file (the file defaults to sys.stdin). The keep_blank_values, strict_parsing and separator parameters are passed to urllib.parse.parse_qs() unchanged.", "Parse input of type multipart/form-data (for file uploads). Arguments are fp for the input file, pdict for a dictionary containing other parameters in the Content-Type header, and encoding, the request encoding.", "Returns a dictionary just like urllib.parse.parse_qs(): keys are the field names, each value is a list of values for that field. For non-file fields, the value is a list of strings.", "This is easy to use but not much good if you are expecting megabytes to be uploaded \u2014 in that case, use the FieldStorage class instead which is much more flexible.", "Changed in version 3.7: Added the encoding and errors parameters. For non-file fields, the value is now a list of strings, not bytes.", "Changed in version 3.9.2: Added the separator parameter.", "Parse a MIME header (such as Content-Type) into a main value and a dictionary of parameters.", "Robust test CGI script, usable as main program. Writes minimal HTTP headers and formats all information provided to the script in HTML form.", "Format the shell environment in HTML.", "Format a form in HTML.", "Format the current directory in HTML.", "Print a list of useful (used by CGI) environment variables in HTML.", "There\u2019s one important rule: if you invoke an external program (via the os.system() or os.popen() functions. or others with similar functionality), make very sure you don\u2019t pass arbitrary strings received from the client to the shell. This is a well-known security hole whereby clever hackers anywhere on the Web can exploit a gullible CGI script to invoke arbitrary shell commands. Even parts of the URL or field names cannot be trusted, since the request doesn\u2019t have to come from your form!", "To be on the safe side, if you must pass a string gotten from a form to a shell command, you should make sure the string contains only alphanumeric characters, dashes, underscores, and periods.", "Read the documentation for your HTTP server and check with your local system administrator to find the directory where CGI scripts should be installed; usually this is in a directory cgi-bin in the server tree.", "Make sure that your script is readable and executable by \u201cothers\u201d; the Unix file mode should be 0o755 octal (use chmod 0755 filename). Make sure that the first line of the script contains #! starting in column 1 followed by the pathname of the Python interpreter, for instance:", "Make sure the Python interpreter exists and is executable by \u201cothers\u201d.", "Make sure that any files your script needs to read or write are readable or writable, respectively, by \u201cothers\u201d \u2014 their mode should be 0o644 for readable and 0o666 for writable. This is because, for security reasons, the HTTP server executes your script as user \u201cnobody\u201d, without any special privileges. It can only read (write, execute) files that everybody can read (write, execute). The current directory at execution time is also different (it is usually the server\u2019s cgi-bin directory) and the set of environment variables is also different from what you get when you log in. In particular, don\u2019t count on the shell\u2019s search path for executables (PATH) or the Python module search path (PYTHONPATH) to be set to anything interesting.", "If you need to load modules from a directory which is not on Python\u2019s default module search path, you can change the path in your script, before importing other modules. For example:", "(This way, the directory inserted last will be searched first!)", "Instructions for non-Unix systems will vary; check your HTTP server\u2019s documentation (it will usually have a section on CGI scripts).", "Unfortunately, a CGI script will generally not run when you try it from the command line, and a script that works perfectly from the command line may fail mysteriously when run from the server. There\u2019s one reason why you should still test your script from the command line: if it contains a syntax error, the Python interpreter won\u2019t execute it at all, and the HTTP server will most likely send a cryptic error to the client.", "Assuming your script has no syntax errors, yet it does not work, you have no choice but to read the next section.", "First of all, check for trivial installation errors \u2014 reading the section above on installing your CGI script carefully can save you a lot of time. If you wonder whether you have understood the installation procedure correctly, try installing a copy of this module file (cgi.py) as a CGI script. When invoked as a script, the file will dump its environment and the contents of the form in HTML form. Give it the right mode etc, and send it a request. If it\u2019s installed in the standard cgi-bin directory, it should be possible to send it a request by entering a URL into your browser of the form:", "If this gives an error of type 404, the server cannot find the script \u2013 perhaps you need to install it in a different directory. If it gives another error, there\u2019s an installation problem that you should fix before trying to go any further. If you get a nicely formatted listing of the environment and form content (in this example, the fields should be listed as \u201caddr\u201d with value \u201cAt Home\u201d and \u201cname\u201d with value \u201cJoe Blow\u201d), the cgi.py script has been installed correctly. If you follow the same procedure for your own script, you should now be able to debug it.", "The next step could be to call the cgi module\u2019s test() function from your script: replace its main code with the single statement", "This should produce the same results as those gotten from installing the cgi.py file itself.", "When an ordinary Python script raises an unhandled exception (for whatever reason: of a typo in a module name, a file that can\u2019t be opened, etc.), the Python interpreter prints a nice traceback and exits. While the Python interpreter will still do this when your CGI script raises an exception, most likely the traceback will end up in one of the HTTP server\u2019s log files, or be discarded altogether.", "Fortunately, once you have managed to get your script to execute some code, you can easily send tracebacks to the Web browser using the cgitb module. If you haven\u2019t done so already, just add the lines:", "to the top of your script. Then try running it again; when a problem occurs, you should see a detailed report that will likely make apparent the cause of the crash.", "If you suspect that there may be a problem in importing the cgitb module, you can use an even more robust approach (which only uses built-in modules):", "This relies on the Python interpreter to print the traceback. The content type of the output is set to plain text, which disables all HTML processing. If your script works, the raw HTML will be displayed by your client. If it raises an exception, most likely after the first two lines have been printed, a traceback will be displayed. Because no HTML interpretation is going on, the traceback will be readable.", "Note that some recent versions of the HTML specification do state what order the field values should be supplied in, but knowing whether a request was received from a conforming browser, or even from a browser at all, is tedious and error-prone."]}, {"name": "cgi.FieldStorage.getfirst()", "path": "library/cgi#cgi.FieldStorage.getfirst", "type": "Internet", "text": ["This method always returns only one value associated with form field name. The method returns only the first value in case that more values were posted under such name. Please note that the order in which the values are received may vary from browser to browser and should not be counted on. 1 If no such form field or value exists then the method returns the value specified by the optional parameter default. This parameter defaults to None if not specified."]}, {"name": "cgi.FieldStorage.getlist()", "path": "library/cgi#cgi.FieldStorage.getlist", "type": "Internet", "text": ["This method always returns a list of values associated with form field name. The method returns an empty list if no such form field or value exists for name. It returns a list consisting of one item if only one such value exists."]}, {"name": "cgi.parse()", "path": "library/cgi#cgi.parse", "type": "Internet", "text": ["Parse a query in the environment or from a file (the file defaults to sys.stdin). The keep_blank_values, strict_parsing and separator parameters are passed to urllib.parse.parse_qs() unchanged."]}, {"name": "cgi.parse_header()", "path": "library/cgi#cgi.parse_header", "type": "Internet", "text": ["Parse a MIME header (such as Content-Type) into a main value and a dictionary of parameters."]}, {"name": "cgi.parse_multipart()", "path": "library/cgi#cgi.parse_multipart", "type": "Internet", "text": ["Parse input of type multipart/form-data (for file uploads). Arguments are fp for the input file, pdict for a dictionary containing other parameters in the Content-Type header, and encoding, the request encoding.", "Returns a dictionary just like urllib.parse.parse_qs(): keys are the field names, each value is a list of values for that field. For non-file fields, the value is a list of strings.", "This is easy to use but not much good if you are expecting megabytes to be uploaded \u2014 in that case, use the FieldStorage class instead which is much more flexible.", "Changed in version 3.7: Added the encoding and errors parameters. For non-file fields, the value is now a list of strings, not bytes.", "Changed in version 3.9.2: Added the separator parameter."]}, {"name": "cgi.print_directory()", "path": "library/cgi#cgi.print_directory", "type": "Internet", "text": ["Format the current directory in HTML."]}, {"name": "cgi.print_environ()", "path": "library/cgi#cgi.print_environ", "type": "Internet", "text": ["Format the shell environment in HTML."]}, {"name": "cgi.print_environ_usage()", "path": "library/cgi#cgi.print_environ_usage", "type": "Internet", "text": ["Print a list of useful (used by CGI) environment variables in HTML."]}, {"name": "cgi.print_form()", "path": "library/cgi#cgi.print_form", "type": "Internet", "text": ["Format a form in HTML."]}, {"name": "cgi.test()", "path": "library/cgi#cgi.test", "type": "Internet", "text": ["Robust test CGI script, usable as main program. Writes minimal HTTP headers and formats all information provided to the script in HTML form."]}, {"name": "cgitb", "path": "library/cgitb", "type": "Internet", "text": ["Source code: Lib/cgitb.py", "The cgitb module provides a special exception handler for Python scripts. (Its name is a bit misleading. It was originally designed to display extensive traceback information in HTML for CGI scripts. It was later generalized to also display this information in plain text.) After this module is activated, if an uncaught exception occurs, a detailed, formatted report will be displayed. The report includes a traceback showing excerpts of the source code for each level, as well as the values of the arguments and local variables to currently running functions, to help you debug the problem. Optionally, you can save this information to a file instead of sending it to the browser.", "To enable this feature, simply add this to the top of your CGI script:", "The options to the enable() function control whether the report is displayed in the browser and whether the report is logged to a file for later analysis.", "This function causes the cgitb module to take over the interpreter\u2019s default handling for exceptions by setting the value of sys.excepthook.", "The optional argument display defaults to 1 and can be set to 0 to suppress sending the traceback to the browser. If the argument logdir is present, the traceback reports are written to files. The value of logdir should be a directory where these files will be placed. The optional argument context is the number of lines of context to display around the current line of source code in the traceback; this defaults to 5. If the optional argument format is \"html\", the output is formatted as HTML. Any other value forces plain text output. The default value is \"html\".", "This function handles the exception described by info (a 3-tuple containing the result of sys.exc_info()), formatting its traceback as text and returning the result as a string. The optional argument context is the number of lines of context to display around the current line of source code in the traceback; this defaults to 5.", "This function handles the exception described by info (a 3-tuple containing the result of sys.exc_info()), formatting its traceback as HTML and returning the result as a string. The optional argument context is the number of lines of context to display around the current line of source code in the traceback; this defaults to 5.", "This function handles an exception using the default settings (that is, show a report in the browser, but don\u2019t log to a file). This can be used when you\u2019ve caught an exception and want to report it using cgitb. The optional info argument should be a 3-tuple containing an exception type, exception value, and traceback object, exactly like the tuple returned by sys.exc_info(). If the info argument is not supplied, the current exception is obtained from sys.exc_info()."]}, {"name": "cgitb.enable()", "path": "library/cgitb#cgitb.enable", "type": "Internet", "text": ["This function causes the cgitb module to take over the interpreter\u2019s default handling for exceptions by setting the value of sys.excepthook.", "The optional argument display defaults to 1 and can be set to 0 to suppress sending the traceback to the browser. If the argument logdir is present, the traceback reports are written to files. The value of logdir should be a directory where these files will be placed. The optional argument context is the number of lines of context to display around the current line of source code in the traceback; this defaults to 5. If the optional argument format is \"html\", the output is formatted as HTML. Any other value forces plain text output. The default value is \"html\"."]}, {"name": "cgitb.handler()", "path": "library/cgitb#cgitb.handler", "type": "Internet", "text": ["This function handles an exception using the default settings (that is, show a report in the browser, but don\u2019t log to a file). This can be used when you\u2019ve caught an exception and want to report it using cgitb. The optional info argument should be a 3-tuple containing an exception type, exception value, and traceback object, exactly like the tuple returned by sys.exc_info(). If the info argument is not supplied, the current exception is obtained from sys.exc_info()."]}, {"name": "cgitb.html()", "path": "library/cgitb#cgitb.html", "type": "Internet", "text": ["This function handles the exception described by info (a 3-tuple containing the result of sys.exc_info()), formatting its traceback as HTML and returning the result as a string. The optional argument context is the number of lines of context to display around the current line of source code in the traceback; this defaults to 5."]}, {"name": "cgitb.text()", "path": "library/cgitb#cgitb.text", "type": "Internet", "text": ["This function handles the exception described by info (a 3-tuple containing the result of sys.exc_info()), formatting its traceback as text and returning the result as a string. The optional argument context is the number of lines of context to display around the current line of source code in the traceback; this defaults to 5."]}, {"name": "ChildProcessError", "path": "library/exceptions#ChildProcessError", "type": "Built-in Exceptions", "text": ["Raised when an operation on a child process failed. Corresponds to errno ECHILD."]}, {"name": "chr()", "path": "library/functions#chr", "type": "Built-in Functions", "text": ["Return the string representing a character whose Unicode code point is the integer i. For example, chr(97) returns the string 'a', while chr(8364) returns the string '\u20ac'. This is the inverse of ord().", "The valid range for the argument is from 0 through 1,114,111 (0x10FFFF in base 16). ValueError will be raised if i is outside that range."]}, {"name": "chunk", "path": "library/chunk", "type": "Multimedia", "text": ["Source code: Lib/chunk.py", "This module provides an interface for reading files that use EA IFF 85 chunks. 1 This format is used in at least the Audio Interchange File Format (AIFF/AIFF-C) and the Real Media File Format (RMFF). The WAVE audio file format is closely related and can also be read using this module.", "A chunk has the following structure:", "Offset", "Length", "Contents", "0", "4", "Chunk ID", "4", "4", "Size of chunk in big-endian byte order, not including the header", "8", "n", "Data bytes, where n is the size given in the preceding field", "8 + n", "0 or 1", "Pad byte needed if n is odd and chunk alignment is used", "The ID is a 4-byte string which identifies the type of chunk.", "The size field (a 32-bit value, encoded using big-endian byte order) gives the size of the chunk data, not including the 8-byte header.", "Usually an IFF-type file consists of one or more chunks. The proposed usage of the Chunk class defined here is to instantiate an instance at the start of each chunk and read from the instance until it reaches the end, after which a new instance can be instantiated. At the end of the file, creating a new instance will fail with an EOFError exception.", "Class which represents a chunk. The file argument is expected to be a file-like object. An instance of this class is specifically allowed. The only method that is needed is read(). If the methods seek() and tell() are present and don\u2019t raise an exception, they are also used. If these methods are present and raise an exception, they are expected to not have altered the object. If the optional argument align is true, chunks are assumed to be aligned on 2-byte boundaries. If align is false, no alignment is assumed. The default value is true. If the optional argument bigendian is false, the chunk size is assumed to be in little-endian order. This is needed for WAVE audio files. The default value is true. If the optional argument inclheader is true, the size given in the chunk header includes the size of the header. The default value is false.", "A Chunk object supports the following methods:", "Returns the name (ID) of the chunk. This is the first 4 bytes of the chunk.", "Returns the size of the chunk.", "Close and skip to the end of the chunk. This does not close the underlying file.", "The remaining methods will raise OSError if called after the close() method has been called. Before Python 3.3, they used to raise IOError, now an alias of OSError.", "Returns False.", "Set the chunk\u2019s current position. The whence argument is optional and defaults to 0 (absolute file positioning); other values are 1 (seek relative to the current position) and 2 (seek relative to the file\u2019s end). There is no return value. If the underlying file does not allow seek, only forward seeks are allowed.", "Return the current position into the chunk.", "Read at most size bytes from the chunk (less if the read hits the end of the chunk before obtaining size bytes). If the size argument is negative or omitted, read all data until the end of the chunk. An empty bytes object is returned when the end of the chunk is encountered immediately.", "Skip to the end of the chunk. All further calls to read() for the chunk will return b''. If you are not interested in the contents of the chunk, this method should be called so that the file points to the start of the next chunk.", "\u201cEA IFF 85\u201d Standard for Interchange Format Files, Jerry Morrison, Electronic Arts, January 1985."]}, {"name": "chunk.Chunk", "path": "library/chunk#chunk.Chunk", "type": "Multimedia", "text": ["Class which represents a chunk. The file argument is expected to be a file-like object. An instance of this class is specifically allowed. The only method that is needed is read(). If the methods seek() and tell() are present and don\u2019t raise an exception, they are also used. If these methods are present and raise an exception, they are expected to not have altered the object. If the optional argument align is true, chunks are assumed to be aligned on 2-byte boundaries. If align is false, no alignment is assumed. The default value is true. If the optional argument bigendian is false, the chunk size is assumed to be in little-endian order. This is needed for WAVE audio files. The default value is true. If the optional argument inclheader is true, the size given in the chunk header includes the size of the header. The default value is false.", "A Chunk object supports the following methods:", "Returns the name (ID) of the chunk. This is the first 4 bytes of the chunk.", "Returns the size of the chunk.", "Close and skip to the end of the chunk. This does not close the underlying file.", "The remaining methods will raise OSError if called after the close() method has been called. Before Python 3.3, they used to raise IOError, now an alias of OSError.", "Returns False.", "Set the chunk\u2019s current position. The whence argument is optional and defaults to 0 (absolute file positioning); other values are 1 (seek relative to the current position) and 2 (seek relative to the file\u2019s end). There is no return value. If the underlying file does not allow seek, only forward seeks are allowed.", "Return the current position into the chunk.", "Read at most size bytes from the chunk (less if the read hits the end of the chunk before obtaining size bytes). If the size argument is negative or omitted, read all data until the end of the chunk. An empty bytes object is returned when the end of the chunk is encountered immediately.", "Skip to the end of the chunk. All further calls to read() for the chunk will return b''. If you are not interested in the contents of the chunk, this method should be called so that the file points to the start of the next chunk."]}, {"name": "chunk.Chunk.close()", "path": "library/chunk#chunk.Chunk.close", "type": "Multimedia", "text": ["Close and skip to the end of the chunk. This does not close the underlying file."]}, {"name": "chunk.Chunk.getname()", "path": "library/chunk#chunk.Chunk.getname", "type": "Multimedia", "text": ["Returns the name (ID) of the chunk. This is the first 4 bytes of the chunk."]}, {"name": "chunk.Chunk.getsize()", "path": "library/chunk#chunk.Chunk.getsize", "type": "Multimedia", "text": ["Returns the size of the chunk."]}, {"name": "chunk.Chunk.isatty()", "path": "library/chunk#chunk.Chunk.isatty", "type": "Multimedia", "text": ["Returns False."]}, {"name": "chunk.Chunk.read()", "path": "library/chunk#chunk.Chunk.read", "type": "Multimedia", "text": ["Read at most size bytes from the chunk (less if the read hits the end of the chunk before obtaining size bytes). If the size argument is negative or omitted, read all data until the end of the chunk. An empty bytes object is returned when the end of the chunk is encountered immediately."]}, {"name": "chunk.Chunk.seek()", "path": "library/chunk#chunk.Chunk.seek", "type": "Multimedia", "text": ["Set the chunk\u2019s current position. The whence argument is optional and defaults to 0 (absolute file positioning); other values are 1 (seek relative to the current position) and 2 (seek relative to the file\u2019s end). There is no return value. If the underlying file does not allow seek, only forward seeks are allowed."]}, {"name": "chunk.Chunk.skip()", "path": "library/chunk#chunk.Chunk.skip", "type": "Multimedia", "text": ["Skip to the end of the chunk. All further calls to read() for the chunk will return b''. If you are not interested in the contents of the chunk, this method should be called so that the file points to the start of the next chunk."]}, {"name": "chunk.Chunk.tell()", "path": "library/chunk#chunk.Chunk.tell", "type": "Multimedia", "text": ["Return the current position into the chunk."]}, {"name": "class.mro()", "path": "library/stdtypes#class.mro", "type": "Built-in Types", "text": ["This method can be overridden by a metaclass to customize the method resolution order for its instances. It is called at class instantiation, and its result is stored in __mro__."]}, {"name": "class.__bases__", "path": "library/stdtypes#class.__bases__", "type": "Built-in Types", "text": ["The tuple of base classes of a class object."]}, {"name": "class.__mro__", "path": "library/stdtypes#class.__mro__", "type": "Built-in Types", "text": ["This attribute is a tuple of classes that are considered when looking for base classes during method resolution."]}, {"name": "class.__subclasses__()", "path": "library/stdtypes#class.__subclasses__", "type": "Built-in Types", "text": ["Each class keeps a list of weak references to its immediate subclasses. This method returns a list of all those references still alive. The list is in definition order. Example:"]}, {"name": "classmethod()", "path": "library/functions#classmethod", "type": "Built-in Functions", "text": ["Transform a method into a class method.", "A class method receives the class as implicit first argument, just like an instance method receives the instance. To declare a class method, use this idiom:", "The @classmethod form is a function decorator \u2013 see Function definitions for details.", "A class method can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class. If a class method is called for a derived class, the derived class object is passed as the implied first argument.", "Class methods are different than C++ or Java static methods. If you want those, see staticmethod() in this section. For more information on class methods, see The standard type hierarchy.", "Changed in version 3.9: Class methods can now wrap other descriptors such as property()."]}, {"name": "cmath", "path": "library/cmath", "type": "Numeric & Mathematical", "text": ["This module provides access to mathematical functions for complex numbers. The functions in this module accept integers, floating-point numbers or complex numbers as arguments. They will also accept any Python object that has either a __complex__() or a __float__() method: these methods are used to convert the object to a complex or floating-point number, respectively, and the function is then applied to the result of the conversion.", "Note", "On platforms with hardware and system-level support for signed zeros, functions involving branch cuts are continuous on both sides of the branch cut: the sign of the zero distinguishes one side of the branch cut from the other. On platforms that do not support signed zeros the continuity is as specified below.", "A Python complex number z is stored internally using rectangular or Cartesian coordinates. It is completely determined by its real part z.real and its imaginary part z.imag. In other words:", "Polar coordinates give an alternative way to represent a complex number. In polar coordinates, a complex number z is defined by the modulus r and the phase angle phi. The modulus r is the distance from z to the origin, while the phase phi is the counterclockwise angle, measured in radians, from the positive x-axis to the line segment that joins the origin to z.", "The following functions can be used to convert from the native rectangular coordinates to polar coordinates and back.", "Return the phase of x (also known as the argument of x), as a float. phase(x) is equivalent to math.atan2(x.imag,\nx.real). The result lies in the range [-\u03c0, \u03c0], and the branch cut for this operation lies along the negative real axis, continuous from above. On systems with support for signed zeros (which includes most systems in current use), this means that the sign of the result is the same as the sign of x.imag, even when x.imag is zero:", "Note", "The modulus (absolute value) of a complex number x can be computed using the built-in abs() function. There is no separate cmath module function for this operation.", "Return the representation of x in polar coordinates. Returns a pair (r, phi) where r is the modulus of x and phi is the phase of x. polar(x) is equivalent to (abs(x),\nphase(x)).", "Return the complex number x with polar coordinates r and phi. Equivalent to r * (math.cos(phi) + math.sin(phi)*1j).", "Return e raised to the power x, where e is the base of natural logarithms.", "Returns the logarithm of x to the given base. If the base is not specified, returns the natural logarithm of x. There is one branch cut, from 0 along the negative real axis to -\u221e, continuous from above.", "Return the base-10 logarithm of x. This has the same branch cut as log().", "Return the square root of x. This has the same branch cut as log().", "Return the arc cosine of x. There are two branch cuts: One extends right from 1 along the real axis to \u221e, continuous from below. The other extends left from -1 along the real axis to -\u221e, continuous from above.", "Return the arc sine of x. This has the same branch cuts as acos().", "Return the arc tangent of x. There are two branch cuts: One extends from 1j along the imaginary axis to \u221ej, continuous from the right. The other extends from -1j along the imaginary axis to -\u221ej, continuous from the left.", "Return the cosine of x.", "Return the sine of x.", "Return the tangent of x.", "Return the inverse hyperbolic cosine of x. There is one branch cut, extending left from 1 along the real axis to -\u221e, continuous from above.", "Return the inverse hyperbolic sine of x. There are two branch cuts: One extends from 1j along the imaginary axis to \u221ej, continuous from the right. The other extends from -1j along the imaginary axis to -\u221ej, continuous from the left.", "Return the inverse hyperbolic tangent of x. There are two branch cuts: One extends from 1 along the real axis to \u221e, continuous from below. The other extends from -1 along the real axis to -\u221e, continuous from above.", "Return the hyperbolic cosine of x.", "Return the hyperbolic sine of x.", "Return the hyperbolic tangent of x.", "Return True if both the real and imaginary parts of x are finite, and False otherwise.", "New in version 3.2.", "Return True if either the real or the imaginary part of x is an infinity, and False otherwise.", "Return True if either the real or the imaginary part of x is a NaN, and False otherwise.", "Return True if the values a and b are close to each other and False otherwise.", "Whether or not two values are considered close is determined according to given absolute and relative tolerances.", "rel_tol is the relative tolerance \u2013 it is the maximum allowed difference between a and b, relative to the larger absolute value of a or b. For example, to set a tolerance of 5%, pass rel_tol=0.05. The default tolerance is 1e-09, which assures that the two values are the same within about 9 decimal digits. rel_tol must be greater than zero.", "abs_tol is the minimum absolute tolerance \u2013 useful for comparisons near zero. abs_tol must be at least zero.", "If no errors occur, the result will be: abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol).", "The IEEE 754 special values of NaN, inf, and -inf will be handled according to IEEE rules. Specifically, NaN is not considered close to any other value, including NaN. inf and -inf are only considered close to themselves.", "New in version 3.5.", "See also", "PEP 485 \u2013 A function for testing approximate equality", "The mathematical constant \u03c0, as a float.", "The mathematical constant e, as a float.", "The mathematical constant \u03c4, as a float.", "New in version 3.6.", "Floating-point positive infinity. Equivalent to float('inf').", "New in version 3.6.", "Complex number with zero real part and positive infinity imaginary part. Equivalent to complex(0.0, float('inf')).", "New in version 3.6.", "A floating-point \u201cnot a number\u201d (NaN) value. Equivalent to float('nan').", "New in version 3.6.", "Complex number with zero real part and NaN imaginary part. Equivalent to complex(0.0, float('nan')).", "New in version 3.6.", "Note that the selection of functions is similar, but not identical, to that in module math. The reason for having two modules is that some users aren\u2019t interested in complex numbers, and perhaps don\u2019t even know what they are. They would rather have math.sqrt(-1) raise an exception than return a complex number. Also note that the functions defined in cmath always return a complex number, even if the answer can be expressed as a real number (in which case the complex number has an imaginary part of zero).", "A note on branch cuts: They are curves along which the given function fails to be continuous. They are a necessary feature of many complex functions. It is assumed that if you need to compute with complex functions, you will understand about branch cuts. Consult almost any (not too elementary) book on complex variables for enlightenment. For information of the proper choice of branch cuts for numerical purposes, a good reference should be the following:", "See also", "Kahan, W: Branch cuts for complex elementary functions; or, Much ado about nothing\u2019s sign bit. In Iserles, A., and Powell, M. (eds.), The state of the art in numerical analysis. Clarendon Press (1987) pp165\u2013211."]}, {"name": "cmath.acos()", "path": "library/cmath#cmath.acos", "type": "Numeric & Mathematical", "text": ["Return the arc cosine of x. There are two branch cuts: One extends right from 1 along the real axis to \u221e, continuous from below. The other extends left from -1 along the real axis to -\u221e, continuous from above."]}, {"name": "cmath.acosh()", "path": "library/cmath#cmath.acosh", "type": "Numeric & Mathematical", "text": ["Return the inverse hyperbolic cosine of x. There is one branch cut, extending left from 1 along the real axis to -\u221e, continuous from above."]}, {"name": "cmath.asin()", "path": "library/cmath#cmath.asin", "type": "Numeric & Mathematical", "text": ["Return the arc sine of x. This has the same branch cuts as acos()."]}, {"name": "cmath.asinh()", "path": "library/cmath#cmath.asinh", "type": "Numeric & Mathematical", "text": ["Return the inverse hyperbolic sine of x. There are two branch cuts: One extends from 1j along the imaginary axis to \u221ej, continuous from the right. The other extends from -1j along the imaginary axis to -\u221ej, continuous from the left."]}, {"name": "cmath.atan()", "path": "library/cmath#cmath.atan", "type": "Numeric & Mathematical", "text": ["Return the arc tangent of x. There are two branch cuts: One extends from 1j along the imaginary axis to \u221ej, continuous from the right. The other extends from -1j along the imaginary axis to -\u221ej, continuous from the left."]}, {"name": "cmath.atanh()", "path": "library/cmath#cmath.atanh", "type": "Numeric & Mathematical", "text": ["Return the inverse hyperbolic tangent of x. There are two branch cuts: One extends from 1 along the real axis to \u221e, continuous from below. The other extends from -1 along the real axis to -\u221e, continuous from above."]}, {"name": "cmath.cos()", "path": "library/cmath#cmath.cos", "type": "Numeric & Mathematical", "text": ["Return the cosine of x."]}, {"name": "cmath.cosh()", "path": "library/cmath#cmath.cosh", "type": "Numeric & Mathematical", "text": ["Return the hyperbolic cosine of x."]}, {"name": "cmath.e", "path": "library/cmath#cmath.e", "type": "Numeric & Mathematical", "text": ["The mathematical constant e, as a float."]}, {"name": "cmath.exp()", "path": "library/cmath#cmath.exp", "type": "Numeric & Mathematical", "text": ["Return e raised to the power x, where e is the base of natural logarithms."]}, {"name": "cmath.inf", "path": "library/cmath#cmath.inf", "type": "Numeric & Mathematical", "text": ["Floating-point positive infinity. Equivalent to float('inf').", "New in version 3.6."]}, {"name": "cmath.infj", "path": "library/cmath#cmath.infj", "type": "Numeric & Mathematical", "text": ["Complex number with zero real part and positive infinity imaginary part. Equivalent to complex(0.0, float('inf')).", "New in version 3.6."]}, {"name": "cmath.isclose()", "path": "library/cmath#cmath.isclose", "type": "Numeric & Mathematical", "text": ["Return True if the values a and b are close to each other and False otherwise.", "Whether or not two values are considered close is determined according to given absolute and relative tolerances.", "rel_tol is the relative tolerance \u2013 it is the maximum allowed difference between a and b, relative to the larger absolute value of a or b. For example, to set a tolerance of 5%, pass rel_tol=0.05. The default tolerance is 1e-09, which assures that the two values are the same within about 9 decimal digits. rel_tol must be greater than zero.", "abs_tol is the minimum absolute tolerance \u2013 useful for comparisons near zero. abs_tol must be at least zero.", "If no errors occur, the result will be: abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol).", "The IEEE 754 special values of NaN, inf, and -inf will be handled according to IEEE rules. Specifically, NaN is not considered close to any other value, including NaN. inf and -inf are only considered close to themselves.", "New in version 3.5.", "See also", "PEP 485 \u2013 A function for testing approximate equality"]}, {"name": "cmath.isfinite()", "path": "library/cmath#cmath.isfinite", "type": "Numeric & Mathematical", "text": ["Return True if both the real and imaginary parts of x are finite, and False otherwise.", "New in version 3.2."]}, {"name": "cmath.isinf()", "path": "library/cmath#cmath.isinf", "type": "Numeric & Mathematical", "text": ["Return True if either the real or the imaginary part of x is an infinity, and False otherwise."]}, {"name": "cmath.isnan()", "path": "library/cmath#cmath.isnan", "type": "Numeric & Mathematical", "text": ["Return True if either the real or the imaginary part of x is a NaN, and False otherwise."]}, {"name": "cmath.log()", "path": "library/cmath#cmath.log", "type": "Numeric & Mathematical", "text": ["Returns the logarithm of x to the given base. If the base is not specified, returns the natural logarithm of x. There is one branch cut, from 0 along the negative real axis to -\u221e, continuous from above."]}, {"name": "cmath.log10()", "path": "library/cmath#cmath.log10", "type": "Numeric & Mathematical", "text": ["Return the base-10 logarithm of x. This has the same branch cut as log()."]}, {"name": "cmath.nan", "path": "library/cmath#cmath.nan", "type": "Numeric & Mathematical", "text": ["A floating-point \u201cnot a number\u201d (NaN) value. Equivalent to float('nan').", "New in version 3.6."]}, {"name": "cmath.nanj", "path": "library/cmath#cmath.nanj", "type": "Numeric & Mathematical", "text": ["Complex number with zero real part and NaN imaginary part. Equivalent to complex(0.0, float('nan')).", "New in version 3.6."]}, {"name": "cmath.phase()", "path": "library/cmath#cmath.phase", "type": "Numeric & Mathematical", "text": ["Return the phase of x (also known as the argument of x), as a float. phase(x) is equivalent to math.atan2(x.imag,\nx.real). The result lies in the range [-\u03c0, \u03c0], and the branch cut for this operation lies along the negative real axis, continuous from above. On systems with support for signed zeros (which includes most systems in current use), this means that the sign of the result is the same as the sign of x.imag, even when x.imag is zero:"]}, {"name": "cmath.pi", "path": "library/cmath#cmath.pi", "type": "Numeric & Mathematical", "text": ["The mathematical constant \u03c0, as a float."]}, {"name": "cmath.polar()", "path": "library/cmath#cmath.polar", "type": "Numeric & Mathematical", "text": ["Return the representation of x in polar coordinates. Returns a pair (r, phi) where r is the modulus of x and phi is the phase of x. polar(x) is equivalent to (abs(x),\nphase(x))."]}, {"name": "cmath.rect()", "path": "library/cmath#cmath.rect", "type": "Numeric & Mathematical", "text": ["Return the complex number x with polar coordinates r and phi. Equivalent to r * (math.cos(phi) + math.sin(phi)*1j)."]}, {"name": "cmath.sin()", "path": "library/cmath#cmath.sin", "type": "Numeric & Mathematical", "text": ["Return the sine of x."]}, {"name": "cmath.sinh()", "path": "library/cmath#cmath.sinh", "type": "Numeric & Mathematical", "text": ["Return the hyperbolic sine of x."]}, {"name": "cmath.sqrt()", "path": "library/cmath#cmath.sqrt", "type": "Numeric & Mathematical", "text": ["Return the square root of x. This has the same branch cut as log()."]}, {"name": "cmath.tan()", "path": "library/cmath#cmath.tan", "type": "Numeric & Mathematical", "text": ["Return the tangent of x."]}, {"name": "cmath.tanh()", "path": "library/cmath#cmath.tanh", "type": "Numeric & Mathematical", "text": ["Return the hyperbolic tangent of x."]}, {"name": "cmath.tau", "path": "library/cmath#cmath.tau", "type": "Numeric & Mathematical", "text": ["The mathematical constant \u03c4, as a float.", "New in version 3.6."]}, {"name": "cmd", "path": "library/cmd", "type": "Frameworks", "text": ["Source code: Lib/cmd.py", "The Cmd class provides a simple framework for writing line-oriented command interpreters. These are often useful for test harnesses, administrative tools, and prototypes that will later be wrapped in a more sophisticated interface.", "A Cmd instance or subclass instance is a line-oriented interpreter framework. There is no good reason to instantiate Cmd itself; rather, it\u2019s useful as a superclass of an interpreter class you define yourself in order to inherit Cmd\u2019s methods and encapsulate action methods.", "The optional argument completekey is the readline name of a completion key; it defaults to Tab. If completekey is not None and readline is available, command completion is done automatically.", "The optional arguments stdin and stdout specify the input and output file objects that the Cmd instance or subclass instance will use for input and output. If not specified, they will default to sys.stdin and sys.stdout.", "If you want a given stdin to be used, make sure to set the instance\u2019s use_rawinput attribute to False, otherwise stdin will be ignored.", "A Cmd instance has the following methods:", "Repeatedly issue a prompt, accept input, parse an initial prefix off the received input, and dispatch to action methods, passing them the remainder of the line as argument.", "The optional argument is a banner or intro string to be issued before the first prompt (this overrides the intro class attribute).", "If the readline module is loaded, input will automatically inherit bash-like history-list editing (e.g. Control-P scrolls back to the last command, Control-N forward to the next one, Control-F moves the cursor to the right non-destructively, Control-B moves the cursor to the left non-destructively, etc.).", "An end-of-file on input is passed back as the string 'EOF'.", "An interpreter instance will recognize a command name foo if and only if it has a method do_foo(). As a special case, a line beginning with the character '?' is dispatched to the method do_help(). As another special case, a line beginning with the character '!' is dispatched to the method do_shell() (if such a method is defined).", "This method will return when the postcmd() method returns a true value. The stop argument to postcmd() is the return value from the command\u2019s corresponding do_*() method.", "If completion is enabled, completing commands will be done automatically, and completing of commands args is done by calling complete_foo() with arguments text, line, begidx, and endidx. text is the string prefix we are attempting to match: all returned matches must begin with it. line is the current input line with leading whitespace removed, begidx and endidx are the beginning and ending indexes of the prefix text, which could be used to provide different completion depending upon which position the argument is in.", "All subclasses of Cmd inherit a predefined do_help(). This method, called with an argument 'bar', invokes the corresponding method help_bar(), and if that is not present, prints the docstring of do_bar(), if available. With no argument, do_help() lists all available help topics (that is, all commands with corresponding help_*() methods or commands that have docstrings), and also lists any undocumented commands.", "Interpret the argument as though it had been typed in response to the prompt. This may be overridden, but should not normally need to be; see the precmd() and postcmd() methods for useful execution hooks. The return value is a flag indicating whether interpretation of commands by the interpreter should stop. If there is a do_*() method for the command str, the return value of that method is returned, otherwise the return value from the default() method is returned.", "Method called when an empty line is entered in response to the prompt. If this method is not overridden, it repeats the last nonempty command entered.", "Method called on an input line when the command prefix is not recognized. If this method is not overridden, it prints an error message and returns.", "Method called to complete an input line when no command-specific complete_*() method is available. By default, it returns an empty list.", "Hook method executed just before the command line line is interpreted, but after the input prompt is generated and issued. This method is a stub in Cmd; it exists to be overridden by subclasses. The return value is used as the command which will be executed by the onecmd() method; the precmd() implementation may re-write the command or simply return line unchanged.", "Hook method executed just after a command dispatch is finished. This method is a stub in Cmd; it exists to be overridden by subclasses. line is the command line which was executed, and stop is a flag which indicates whether execution will be terminated after the call to postcmd(); this will be the return value of the onecmd() method. The return value of this method will be used as the new value for the internal flag which corresponds to stop; returning false will cause interpretation to continue.", "Hook method executed once when cmdloop() is called. This method is a stub in Cmd; it exists to be overridden by subclasses.", "Hook method executed once when cmdloop() is about to return. This method is a stub in Cmd; it exists to be overridden by subclasses.", "Instances of Cmd subclasses have some public instance variables:", "The prompt issued to solicit input.", "The string of characters accepted for the command prefix.", "The last nonempty command prefix seen.", "A list of queued input lines. The cmdqueue list is checked in cmdloop() when new input is needed; if it is nonempty, its elements will be processed in order, as if entered at the prompt.", "A string to issue as an intro or banner. May be overridden by giving the cmdloop() method an argument.", "The header to issue if the help output has a section for documented commands.", "The header to issue if the help output has a section for miscellaneous help topics (that is, there are help_*() methods without corresponding do_*() methods).", "The header to issue if the help output has a section for undocumented commands (that is, there are do_*() methods without corresponding help_*() methods).", "The character used to draw separator lines under the help-message headers. If empty, no ruler line is drawn. It defaults to '='.", "A flag, defaulting to true. If true, cmdloop() uses input() to display a prompt and read the next command; if false, sys.stdout.write() and sys.stdin.readline() are used. (This means that by importing readline, on systems that support it, the interpreter will automatically support Emacs-like line editing and command-history keystrokes.)", "The cmd module is mainly useful for building custom shells that let a user work with a program interactively.", "This section presents a simple example of how to build a shell around a few of the commands in the turtle module.", "Basic turtle commands such as forward() are added to a Cmd subclass with method named do_forward(). The argument is converted to a number and dispatched to the turtle module. The docstring is used in the help utility provided by the shell.", "The example also includes a basic record and playback facility implemented with the precmd() method which is responsible for converting the input to lowercase and writing the commands to a file. The do_playback() method reads the file and adds the recorded commands to the cmdqueue for immediate playback:", "Here is a sample session with the turtle shell showing the help functions, using blank lines to repeat commands, and the simple record and playback facility:"]}, {"name": "cmd.Cmd", "path": "library/cmd#cmd.Cmd", "type": "Frameworks", "text": ["A Cmd instance or subclass instance is a line-oriented interpreter framework. There is no good reason to instantiate Cmd itself; rather, it\u2019s useful as a superclass of an interpreter class you define yourself in order to inherit Cmd\u2019s methods and encapsulate action methods.", "The optional argument completekey is the readline name of a completion key; it defaults to Tab. If completekey is not None and readline is available, command completion is done automatically.", "The optional arguments stdin and stdout specify the input and output file objects that the Cmd instance or subclass instance will use for input and output. If not specified, they will default to sys.stdin and sys.stdout.", "If you want a given stdin to be used, make sure to set the instance\u2019s use_rawinput attribute to False, otherwise stdin will be ignored."]}, {"name": "cmd.Cmd.cmdloop()", "path": "library/cmd#cmd.Cmd.cmdloop", "type": "Frameworks", "text": ["Repeatedly issue a prompt, accept input, parse an initial prefix off the received input, and dispatch to action methods, passing them the remainder of the line as argument.", "The optional argument is a banner or intro string to be issued before the first prompt (this overrides the intro class attribute).", "If the readline module is loaded, input will automatically inherit bash-like history-list editing (e.g. Control-P scrolls back to the last command, Control-N forward to the next one, Control-F moves the cursor to the right non-destructively, Control-B moves the cursor to the left non-destructively, etc.).", "An end-of-file on input is passed back as the string 'EOF'.", "An interpreter instance will recognize a command name foo if and only if it has a method do_foo(). As a special case, a line beginning with the character '?' is dispatched to the method do_help(). As another special case, a line beginning with the character '!' is dispatched to the method do_shell() (if such a method is defined).", "This method will return when the postcmd() method returns a true value. The stop argument to postcmd() is the return value from the command\u2019s corresponding do_*() method.", "If completion is enabled, completing commands will be done automatically, and completing of commands args is done by calling complete_foo() with arguments text, line, begidx, and endidx. text is the string prefix we are attempting to match: all returned matches must begin with it. line is the current input line with leading whitespace removed, begidx and endidx are the beginning and ending indexes of the prefix text, which could be used to provide different completion depending upon which position the argument is in.", "All subclasses of Cmd inherit a predefined do_help(). This method, called with an argument 'bar', invokes the corresponding method help_bar(), and if that is not present, prints the docstring of do_bar(), if available. With no argument, do_help() lists all available help topics (that is, all commands with corresponding help_*() methods or commands that have docstrings), and also lists any undocumented commands."]}, {"name": "cmd.Cmd.cmdqueue", "path": "library/cmd#cmd.Cmd.cmdqueue", "type": "Frameworks", "text": ["A list of queued input lines. The cmdqueue list is checked in cmdloop() when new input is needed; if it is nonempty, its elements will be processed in order, as if entered at the prompt."]}, {"name": "cmd.Cmd.completedefault()", "path": "library/cmd#cmd.Cmd.completedefault", "type": "Frameworks", "text": ["Method called to complete an input line when no command-specific complete_*() method is available. By default, it returns an empty list."]}, {"name": "cmd.Cmd.default()", "path": "library/cmd#cmd.Cmd.default", "type": "Frameworks", "text": ["Method called on an input line when the command prefix is not recognized. If this method is not overridden, it prints an error message and returns."]}, {"name": "cmd.Cmd.doc_header", "path": "library/cmd#cmd.Cmd.doc_header", "type": "Frameworks", "text": ["The header to issue if the help output has a section for documented commands."]}, {"name": "cmd.Cmd.emptyline()", "path": "library/cmd#cmd.Cmd.emptyline", "type": "Frameworks", "text": ["Method called when an empty line is entered in response to the prompt. If this method is not overridden, it repeats the last nonempty command entered."]}, {"name": "cmd.Cmd.identchars", "path": "library/cmd#cmd.Cmd.identchars", "type": "Frameworks", "text": ["The string of characters accepted for the command prefix."]}, {"name": "cmd.Cmd.intro", "path": "library/cmd#cmd.Cmd.intro", "type": "Frameworks", "text": ["A string to issue as an intro or banner. May be overridden by giving the cmdloop() method an argument."]}, {"name": "cmd.Cmd.lastcmd", "path": "library/cmd#cmd.Cmd.lastcmd", "type": "Frameworks", "text": ["The last nonempty command prefix seen."]}, {"name": "cmd.Cmd.misc_header", "path": "library/cmd#cmd.Cmd.misc_header", "type": "Frameworks", "text": ["The header to issue if the help output has a section for miscellaneous help topics (that is, there are help_*() methods without corresponding do_*() methods)."]}, {"name": "cmd.Cmd.onecmd()", "path": "library/cmd#cmd.Cmd.onecmd", "type": "Frameworks", "text": ["Interpret the argument as though it had been typed in response to the prompt. This may be overridden, but should not normally need to be; see the precmd() and postcmd() methods for useful execution hooks. The return value is a flag indicating whether interpretation of commands by the interpreter should stop. If there is a do_*() method for the command str, the return value of that method is returned, otherwise the return value from the default() method is returned."]}, {"name": "cmd.Cmd.postcmd()", "path": "library/cmd#cmd.Cmd.postcmd", "type": "Frameworks", "text": ["Hook method executed just after a command dispatch is finished. This method is a stub in Cmd; it exists to be overridden by subclasses. line is the command line which was executed, and stop is a flag which indicates whether execution will be terminated after the call to postcmd(); this will be the return value of the onecmd() method. The return value of this method will be used as the new value for the internal flag which corresponds to stop; returning false will cause interpretation to continue."]}, {"name": "cmd.Cmd.postloop()", "path": "library/cmd#cmd.Cmd.postloop", "type": "Frameworks", "text": ["Hook method executed once when cmdloop() is about to return. This method is a stub in Cmd; it exists to be overridden by subclasses."]}, {"name": "cmd.Cmd.precmd()", "path": "library/cmd#cmd.Cmd.precmd", "type": "Frameworks", "text": ["Hook method executed just before the command line line is interpreted, but after the input prompt is generated and issued. This method is a stub in Cmd; it exists to be overridden by subclasses. The return value is used as the command which will be executed by the onecmd() method; the precmd() implementation may re-write the command or simply return line unchanged."]}, {"name": "cmd.Cmd.preloop()", "path": "library/cmd#cmd.Cmd.preloop", "type": "Frameworks", "text": ["Hook method executed once when cmdloop() is called. This method is a stub in Cmd; it exists to be overridden by subclasses."]}, {"name": "cmd.Cmd.prompt", "path": "library/cmd#cmd.Cmd.prompt", "type": "Frameworks", "text": ["The prompt issued to solicit input."]}, {"name": "cmd.Cmd.ruler", "path": "library/cmd#cmd.Cmd.ruler", "type": "Frameworks", "text": ["The character used to draw separator lines under the help-message headers. If empty, no ruler line is drawn. It defaults to '='."]}, {"name": "cmd.Cmd.undoc_header", "path": "library/cmd#cmd.Cmd.undoc_header", "type": "Frameworks", "text": ["The header to issue if the help output has a section for undocumented commands (that is, there are do_*() methods without corresponding help_*() methods)."]}, {"name": "cmd.Cmd.use_rawinput", "path": "library/cmd#cmd.Cmd.use_rawinput", "type": "Frameworks", "text": ["A flag, defaulting to true. If true, cmdloop() uses input() to display a prompt and read the next command; if false, sys.stdout.write() and sys.stdin.readline() are used. (This means that by importing readline, on systems that support it, the interpreter will automatically support Emacs-like line editing and command-history keystrokes.)"]}, {"name": "code", "path": "library/code", "type": "Interpreters", "text": ["Source code: Lib/code.py", "The code module provides facilities to implement read-eval-print loops in Python. Two classes and convenience functions are included which can be used to build applications which provide an interactive interpreter prompt.", "This class deals with parsing and interpreter state (the user\u2019s namespace); it does not deal with input buffering or prompting or input file naming (the filename is always passed in explicitly). The optional locals argument specifies the dictionary in which code will be executed; it defaults to a newly created dictionary with key '__name__' set to '__console__' and key '__doc__' set to None.", "Closely emulate the behavior of the interactive Python interpreter. This class builds on InteractiveInterpreter and adds prompting using the familiar sys.ps1 and sys.ps2, and input buffering.", "Convenience function to run a read-eval-print loop. This creates a new instance of InteractiveConsole and sets readfunc to be used as the InteractiveConsole.raw_input() method, if provided. If local is provided, it is passed to the InteractiveConsole constructor for use as the default namespace for the interpreter loop. The interact() method of the instance is then run with banner and exitmsg passed as the banner and exit message to use, if provided. The console object is discarded after use.", "Changed in version 3.6: Added exitmsg parameter.", "This function is useful for programs that want to emulate Python\u2019s interpreter main loop (a.k.a. the read-eval-print loop). The tricky part is to determine when the user has entered an incomplete command that can be completed by entering more text (as opposed to a complete command or a syntax error). This function almost always makes the same decision as the real interpreter main loop.", "source is the source string; filename is the optional filename from which source was read, defaulting to '<input>'; and symbol is the optional grammar start symbol, which should be 'single' (the default), 'eval' or 'exec'.", "Returns a code object (the same as compile(source, filename, symbol)) if the command is complete and valid; None if the command is incomplete; raises SyntaxError if the command is complete and contains a syntax error, or raises OverflowError or ValueError if the command contains an invalid literal.", "Compile and run some source in the interpreter. Arguments are the same as for compile_command(); the default for filename is '<input>', and for symbol is 'single'. One of several things can happen:", "The return value can be used to decide whether to use sys.ps1 or sys.ps2 to prompt the next line.", "Execute a code object. When an exception occurs, showtraceback() is called to display a traceback. All exceptions are caught except SystemExit, which is allowed to propagate.", "A note about KeyboardInterrupt: this exception may occur elsewhere in this code, and may not always be caught. The caller should be prepared to deal with it.", "Display the syntax error that just occurred. This does not display a stack trace because there isn\u2019t one for syntax errors. If filename is given, it is stuffed into the exception instead of the default filename provided by Python\u2019s parser, because it always uses '<string>' when reading from a string. The output is written by the write() method.", "Display the exception that just occurred. We remove the first stack item because it is within the interpreter object implementation. The output is written by the write() method.", "Changed in version 3.5: The full chained traceback is displayed instead of just the primary traceback.", "Write a string to the standard error stream (sys.stderr). Derived classes should override this to provide the appropriate output handling as needed.", "The InteractiveConsole class is a subclass of InteractiveInterpreter, and so offers all the methods of the interpreter objects as well as the following additions.", "Closely emulate the interactive Python console. The optional banner argument specify the banner to print before the first interaction; by default it prints a banner similar to the one printed by the standard Python interpreter, followed by the class name of the console object in parentheses (so as not to confuse this with the real interpreter \u2013 since it\u2019s so close!).", "The optional exitmsg argument specifies an exit message printed when exiting. Pass the empty string to suppress the exit message. If exitmsg is not given or None, a default message is printed.", "Changed in version 3.4: To suppress printing any banner, pass an empty string.", "Changed in version 3.6: Print an exit message when exiting.", "Push a line of source text to the interpreter. The line should not have a trailing newline; it may have internal newlines. The line is appended to a buffer and the interpreter\u2019s runsource() method is called with the concatenated contents of the buffer as source. If this indicates that the command was executed or invalid, the buffer is reset; otherwise, the command is incomplete, and the buffer is left as it was after the line was appended. The return value is True if more input is required, False if the line was dealt with in some way (this is the same as runsource()).", "Remove any unhandled source text from the input buffer.", "Write a prompt and read a line. The returned line does not include the trailing newline. When the user enters the EOF key sequence, EOFError is raised. The base implementation reads from sys.stdin; a subclass may replace this with a different implementation."]}, {"name": "code.compile_command()", "path": "library/code#code.compile_command", "type": "Interpreters", "text": ["This function is useful for programs that want to emulate Python\u2019s interpreter main loop (a.k.a. the read-eval-print loop). The tricky part is to determine when the user has entered an incomplete command that can be completed by entering more text (as opposed to a complete command or a syntax error). This function almost always makes the same decision as the real interpreter main loop.", "source is the source string; filename is the optional filename from which source was read, defaulting to '<input>'; and symbol is the optional grammar start symbol, which should be 'single' (the default), 'eval' or 'exec'.", "Returns a code object (the same as compile(source, filename, symbol)) if the command is complete and valid; None if the command is incomplete; raises SyntaxError if the command is complete and contains a syntax error, or raises OverflowError or ValueError if the command contains an invalid literal."]}, {"name": "code.interact()", "path": "library/code#code.interact", "type": "Interpreters", "text": ["Convenience function to run a read-eval-print loop. This creates a new instance of InteractiveConsole and sets readfunc to be used as the InteractiveConsole.raw_input() method, if provided. If local is provided, it is passed to the InteractiveConsole constructor for use as the default namespace for the interpreter loop. The interact() method of the instance is then run with banner and exitmsg passed as the banner and exit message to use, if provided. The console object is discarded after use.", "Changed in version 3.6: Added exitmsg parameter."]}, {"name": "code.InteractiveConsole", "path": "library/code#code.InteractiveConsole", "type": "Interpreters", "text": ["Closely emulate the behavior of the interactive Python interpreter. This class builds on InteractiveInterpreter and adds prompting using the familiar sys.ps1 and sys.ps2, and input buffering."]}, {"name": "code.InteractiveConsole.interact()", "path": "library/code#code.InteractiveConsole.interact", "type": "Interpreters", "text": ["Closely emulate the interactive Python console. The optional banner argument specify the banner to print before the first interaction; by default it prints a banner similar to the one printed by the standard Python interpreter, followed by the class name of the console object in parentheses (so as not to confuse this with the real interpreter \u2013 since it\u2019s so close!).", "The optional exitmsg argument specifies an exit message printed when exiting. Pass the empty string to suppress the exit message. If exitmsg is not given or None, a default message is printed.", "Changed in version 3.4: To suppress printing any banner, pass an empty string.", "Changed in version 3.6: Print an exit message when exiting."]}, {"name": "code.InteractiveConsole.push()", "path": "library/code#code.InteractiveConsole.push", "type": "Interpreters", "text": ["Push a line of source text to the interpreter. The line should not have a trailing newline; it may have internal newlines. The line is appended to a buffer and the interpreter\u2019s runsource() method is called with the concatenated contents of the buffer as source. If this indicates that the command was executed or invalid, the buffer is reset; otherwise, the command is incomplete, and the buffer is left as it was after the line was appended. The return value is True if more input is required, False if the line was dealt with in some way (this is the same as runsource())."]}, {"name": "code.InteractiveConsole.raw_input()", "path": "library/code#code.InteractiveConsole.raw_input", "type": "Interpreters", "text": ["Write a prompt and read a line. The returned line does not include the trailing newline. When the user enters the EOF key sequence, EOFError is raised. The base implementation reads from sys.stdin; a subclass may replace this with a different implementation."]}, {"name": "code.InteractiveConsole.resetbuffer()", "path": "library/code#code.InteractiveConsole.resetbuffer", "type": "Interpreters", "text": ["Remove any unhandled source text from the input buffer."]}, {"name": "code.InteractiveInterpreter", "path": "library/code#code.InteractiveInterpreter", "type": "Interpreters", "text": ["This class deals with parsing and interpreter state (the user\u2019s namespace); it does not deal with input buffering or prompting or input file naming (the filename is always passed in explicitly). The optional locals argument specifies the dictionary in which code will be executed; it defaults to a newly created dictionary with key '__name__' set to '__console__' and key '__doc__' set to None."]}, {"name": "code.InteractiveInterpreter.runcode()", "path": "library/code#code.InteractiveInterpreter.runcode", "type": "Interpreters", "text": ["Execute a code object. When an exception occurs, showtraceback() is called to display a traceback. All exceptions are caught except SystemExit, which is allowed to propagate.", "A note about KeyboardInterrupt: this exception may occur elsewhere in this code, and may not always be caught. The caller should be prepared to deal with it."]}, {"name": "code.InteractiveInterpreter.runsource()", "path": "library/code#code.InteractiveInterpreter.runsource", "type": "Interpreters", "text": ["Compile and run some source in the interpreter. Arguments are the same as for compile_command(); the default for filename is '<input>', and for symbol is 'single'. One of several things can happen:", "The return value can be used to decide whether to use sys.ps1 or sys.ps2 to prompt the next line."]}, {"name": "code.InteractiveInterpreter.showsyntaxerror()", "path": "library/code#code.InteractiveInterpreter.showsyntaxerror", "type": "Interpreters", "text": ["Display the syntax error that just occurred. This does not display a stack trace because there isn\u2019t one for syntax errors. If filename is given, it is stuffed into the exception instead of the default filename provided by Python\u2019s parser, because it always uses '<string>' when reading from a string. The output is written by the write() method."]}, {"name": "code.InteractiveInterpreter.showtraceback()", "path": "library/code#code.InteractiveInterpreter.showtraceback", "type": "Interpreters", "text": ["Display the exception that just occurred. We remove the first stack item because it is within the interpreter object implementation. The output is written by the write() method.", "Changed in version 3.5: The full chained traceback is displayed instead of just the primary traceback."]}, {"name": "code.InteractiveInterpreter.write()", "path": "library/code#code.InteractiveInterpreter.write", "type": "Interpreters", "text": ["Write a string to the standard error stream (sys.stderr). Derived classes should override this to provide the appropriate output handling as needed."]}, {"name": "codecs", "path": "library/codecs", "type": "Binary Data", "text": ["Source code: Lib/codecs.py", "This module defines base classes for standard Python codecs (encoders and decoders) and provides access to the internal Python codec registry, which manages the codec and error handling lookup process. Most standard codecs are text encodings, which encode text to bytes, but there are also codecs provided that encode text to text, and bytes to bytes. Custom codecs may encode and decode between arbitrary types, but some module features are restricted to use specifically with text encodings, or with codecs that encode to bytes.", "The module defines the following functions for encoding and decoding with any codec:", "Encodes obj using the codec registered for encoding.", "Errors may be given to set the desired error handling scheme. The default error handler is 'strict' meaning that encoding errors raise ValueError (or a more codec specific subclass, such as UnicodeEncodeError). Refer to Codec Base Classes for more information on codec error handling.", "Decodes obj using the codec registered for encoding.", "Errors may be given to set the desired error handling scheme. The default error handler is 'strict' meaning that decoding errors raise ValueError (or a more codec specific subclass, such as UnicodeDecodeError). Refer to Codec Base Classes for more information on codec error handling.", "The full details for each codec can also be looked up directly:", "Looks up the codec info in the Python codec registry and returns a CodecInfo object as defined below.", "Encodings are first looked up in the registry\u2019s cache. If not found, the list of registered search functions is scanned. If no CodecInfo object is found, a LookupError is raised. Otherwise, the CodecInfo object is stored in the cache and returned to the caller.", "Codec details when looking up the codec registry. The constructor arguments are stored in attributes of the same name:", "The name of the encoding.", "The stateless encoding and decoding functions. These must be functions or methods which have the same interface as the encode() and decode() methods of Codec instances (see Codec Interface). The functions or methods are expected to work in a stateless mode.", "Incremental encoder and decoder classes or factory functions. These have to provide the interface defined by the base classes IncrementalEncoder and IncrementalDecoder, respectively. Incremental codecs can maintain state.", "Stream writer and reader classes or factory functions. These have to provide the interface defined by the base classes StreamWriter and StreamReader, respectively. Stream codecs can maintain state.", "To simplify access to the various codec components, the module provides these additional functions which use lookup() for the codec lookup:", "Look up the codec for the given encoding and return its encoder function.", "Raises a LookupError in case the encoding cannot be found.", "Look up the codec for the given encoding and return its decoder function.", "Raises a LookupError in case the encoding cannot be found.", "Look up the codec for the given encoding and return its incremental encoder class or factory function.", "Raises a LookupError in case the encoding cannot be found or the codec doesn\u2019t support an incremental encoder.", "Look up the codec for the given encoding and return its incremental decoder class or factory function.", "Raises a LookupError in case the encoding cannot be found or the codec doesn\u2019t support an incremental decoder.", "Look up the codec for the given encoding and return its StreamReader class or factory function.", "Raises a LookupError in case the encoding cannot be found.", "Look up the codec for the given encoding and return its StreamWriter class or factory function.", "Raises a LookupError in case the encoding cannot be found.", "Custom codecs are made available by registering a suitable codec search function:", "Register a codec search function. Search functions are expected to take one argument, being the encoding name in all lower case letters with hyphens and spaces converted to underscores, and return a CodecInfo object. In case a search function cannot find a given encoding, it should return None.", "Changed in version 3.9: Hyphens and spaces are converted to underscore.", "Note", "Search function registration is not currently reversible, which may cause problems in some cases, such as unit testing or module reloading.", "While the builtin open() and the associated io module are the recommended approach for working with encoded text files, this module provides additional utility functions and classes that allow the use of a wider range of codecs when working with binary files:", "Open an encoded file using the given mode and return an instance of StreamReaderWriter, providing transparent encoding/decoding. The default file mode is 'r', meaning to open the file in read mode.", "Note", "Underlying encoded files are always opened in binary mode. No automatic conversion of '\\n' is done on reading and writing. The mode argument may be any binary mode acceptable to the built-in open() function; the 'b' is automatically added.", "encoding specifies the encoding which is to be used for the file. Any encoding that encodes to and decodes from bytes is allowed, and the data types supported by the file methods depend on the codec used.", "errors may be given to define the error handling. It defaults to 'strict' which causes a ValueError to be raised in case an encoding error occurs.", "buffering has the same meaning as for the built-in open() function. It defaults to -1 which means that the default buffer size will be used.", "Return a StreamRecoder instance, a wrapped version of file which provides transparent transcoding. The original file is closed when the wrapped version is closed.", "Data written to the wrapped file is decoded according to the given data_encoding and then written to the original file as bytes using file_encoding. Bytes read from the original file are decoded according to file_encoding, and the result is encoded using data_encoding.", "If file_encoding is not given, it defaults to data_encoding.", "errors may be given to define the error handling. It defaults to 'strict', which causes ValueError to be raised in case an encoding error occurs.", "Uses an incremental encoder to iteratively encode the input provided by iterator. This function is a generator. The errors argument (as well as any other keyword argument) is passed through to the incremental encoder.", "This function requires that the codec accept text str objects to encode. Therefore it does not support bytes-to-bytes encoders such as base64_codec.", "Uses an incremental decoder to iteratively decode the input provided by iterator. This function is a generator. The errors argument (as well as any other keyword argument) is passed through to the incremental decoder.", "This function requires that the codec accept bytes objects to decode. Therefore it does not support text-to-text encoders such as rot_13, although rot_13 may be used equivalently with iterencode().", "The module also provides the following constants which are useful for reading and writing to platform dependent files:", "These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings.", "The codecs module defines a set of base classes which define the interfaces for working with codec objects, and can also be used as the basis for custom codec implementations.", "Each codec has to define four interfaces to make it usable as codec in Python: stateless encoder, stateless decoder, stream reader and stream writer. The stream reader and writers typically reuse the stateless encoder/decoder to implement the file protocols. Codec authors also need to define how the codec will handle encoding and decoding errors.", "To simplify and standardize error handling, codecs may implement different error handling schemes by accepting the errors string argument. The following string values are defined and implemented by all standard Python codecs:", "Value", "Meaning", "'strict'", "Raise UnicodeError (or a subclass); this is the default. Implemented in strict_errors().", "'ignore'", "Ignore the malformed data and continue without further notice. Implemented in ignore_errors().", "The following error handlers are only applicable to text encodings:", "Value", "Meaning", "'replace'", "Replace with a suitable replacement marker; Python will use the official U+FFFD REPLACEMENT CHARACTER for the built-in codecs on decoding, and \u2018?\u2019 on encoding. Implemented in replace_errors().", "'xmlcharrefreplace'", "Replace with the appropriate XML character reference (only for encoding). Implemented in xmlcharrefreplace_errors().", "'backslashreplace'", "Replace with backslashed escape sequences. Implemented in backslashreplace_errors().", "'namereplace'", "Replace with \\N{...} escape sequences (only for encoding). Implemented in namereplace_errors().", "'surrogateescape'", "On decoding, replace byte with individual surrogate code ranging from U+DC80 to U+DCFF. This code will then be turned back into the same byte when the 'surrogateescape' error handler is used when encoding the data. (See PEP 383 for more.)", "In addition, the following error handler is specific to the given codecs:", "Value", "Codecs", "Meaning", "'surrogatepass'", "utf-8, utf-16, utf-32, utf-16-be, utf-16-le, utf-32-be, utf-32-le", "Allow encoding and decoding of surrogate codes. These codecs normally treat the presence of surrogates as an error.", "New in version 3.1: The 'surrogateescape' and 'surrogatepass' error handlers.", "Changed in version 3.4: The 'surrogatepass' error handlers now works with utf-16* and utf-32* codecs.", "New in version 3.5: The 'namereplace' error handler.", "Changed in version 3.5: The 'backslashreplace' error handlers now works with decoding and translating.", "The set of allowed values can be extended by registering a new named error handler:", "Register the error handling function error_handler under the name name. The error_handler argument will be called during encoding and decoding in case of an error, when name is specified as the errors parameter.", "For encoding, error_handler will be called with a UnicodeEncodeError instance, which contains information about the location of the error. The error handler must either raise this or a different exception, or return a tuple with a replacement for the unencodable part of the input and a position where encoding should continue. The replacement may be either str or bytes. If the replacement is bytes, the encoder will simply copy them into the output buffer. If the replacement is a string, the encoder will encode the replacement. Encoding continues on original input at the specified position. Negative position values will be treated as being relative to the end of the input string. If the resulting position is out of bound an IndexError will be raised.", "Decoding and translating works similarly, except UnicodeDecodeError or UnicodeTranslateError will be passed to the handler and that the replacement from the error handler will be put into the output directly.", "Previously registered error handlers (including the standard error handlers) can be looked up by name:", "Return the error handler previously registered under the name name.", "Raises a LookupError in case the handler cannot be found.", "The following standard error handlers are also made available as module level functions:", "Implements the 'strict' error handling: each encoding or decoding error raises a UnicodeError.", "Implements the 'replace' error handling (for text encodings only): substitutes '?' for encoding errors (to be encoded by the codec), and '\\ufffd' (the Unicode replacement character) for decoding errors.", "Implements the 'ignore' error handling: malformed data is ignored and encoding or decoding is continued without further notice.", "Implements the 'xmlcharrefreplace' error handling (for encoding with text encodings only): the unencodable character is replaced by an appropriate XML character reference.", "Implements the 'backslashreplace' error handling (for text encodings only): malformed data is replaced by a backslashed escape sequence.", "Implements the 'namereplace' error handling (for encoding with text encodings only): the unencodable character is replaced by a \\N{...} escape sequence.", "New in version 3.5.", "The base Codec class defines these methods which also define the function interfaces of the stateless encoder and decoder:", "Encodes the object input and returns a tuple (output object, length consumed). For instance, text encoding converts a string object to a bytes object using a particular character set encoding (e.g., cp1252 or iso-8859-1).", "The errors argument defines the error handling to apply. It defaults to 'strict' handling.", "The method may not store state in the Codec instance. Use StreamWriter for codecs which have to keep state in order to make encoding efficient.", "The encoder must be able to handle zero length input and return an empty object of the output object type in this situation.", "Decodes the object input and returns a tuple (output object, length consumed). For instance, for a text encoding, decoding converts a bytes object encoded using a particular character set encoding to a string object.", "For text encodings and bytes-to-bytes codecs, input must be a bytes object or one which provides the read-only buffer interface \u2013 for example, buffer objects and memory mapped files.", "The errors argument defines the error handling to apply. It defaults to 'strict' handling.", "The method may not store state in the Codec instance. Use StreamReader for codecs which have to keep state in order to make decoding efficient.", "The decoder must be able to handle zero length input and return an empty object of the output object type in this situation.", "The IncrementalEncoder and IncrementalDecoder classes provide the basic interface for incremental encoding and decoding. Encoding/decoding the input isn\u2019t done with one call to the stateless encoder/decoder function, but with multiple calls to the encode()/decode() method of the incremental encoder/decoder. The incremental encoder/decoder keeps track of the encoding/decoding process during method calls.", "The joined output of calls to the encode()/decode() method is the same as if all the single inputs were joined into one, and this input was encoded/decoded with the stateless encoder/decoder.", "The IncrementalEncoder class is used for encoding an input in multiple steps. It defines the following methods which every incremental encoder must define in order to be compatible with the Python codec registry.", "Constructor for an IncrementalEncoder instance.", "All incremental encoders must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The IncrementalEncoder may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for possible values.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the IncrementalEncoder object.", "Encodes object (taking the current state of the encoder into account) and returns the resulting encoded object. If this is the last call to encode() final must be true (the default is false).", "Reset the encoder to the initial state. The output is discarded: call .encode(object, final=True), passing an empty byte or text string if necessary, to reset the encoder and to get the output.", "Return the current state of the encoder which must be an integer. The implementation should make sure that 0 is the most common state. (States that are more complicated than integers can be converted into an integer by marshaling/pickling the state and encoding the bytes of the resulting string into an integer.)", "Set the state of the encoder to state. state must be an encoder state returned by getstate().", "The IncrementalDecoder class is used for decoding an input in multiple steps. It defines the following methods which every incremental decoder must define in order to be compatible with the Python codec registry.", "Constructor for an IncrementalDecoder instance.", "All incremental decoders must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The IncrementalDecoder may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for possible values.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the IncrementalDecoder object.", "Decodes object (taking the current state of the decoder into account) and returns the resulting decoded object. If this is the last call to decode() final must be true (the default is false). If final is true the decoder must decode the input completely and must flush all buffers. If this isn\u2019t possible (e.g. because of incomplete byte sequences at the end of the input) it must initiate error handling just like in the stateless case (which might raise an exception).", "Reset the decoder to the initial state.", "Return the current state of the decoder. This must be a tuple with two items, the first must be the buffer containing the still undecoded input. The second must be an integer and can be additional state info. (The implementation should make sure that 0 is the most common additional state info.) If this additional state info is 0 it must be possible to set the decoder to the state which has no input buffered and 0 as the additional state info, so that feeding the previously buffered input to the decoder returns it to the previous state without producing any output. (Additional state info that is more complicated than integers can be converted into an integer by marshaling/pickling the info and encoding the bytes of the resulting string into an integer.)", "Set the state of the decoder to state. state must be a decoder state returned by getstate().", "The StreamWriter and StreamReader classes provide generic working interfaces which can be used to implement new encoding submodules very easily. See encodings.utf_8 for an example of how this is done.", "The StreamWriter class is a subclass of Codec and defines the following methods which every stream writer must define in order to be compatible with the Python codec registry.", "Constructor for a StreamWriter instance.", "All stream writers must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The stream argument must be a file-like object open for writing text or binary data, as appropriate for the specific codec.", "The StreamWriter may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for the standard error handlers the underlying stream codec may support.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the StreamWriter object.", "Writes the object\u2019s contents encoded to the stream.", "Writes the concatenated list of strings to the stream (possibly by reusing the write() method). The standard bytes-to-bytes codecs do not support this method.", "Resets the codec buffers used for keeping internal state.", "Calling this method should ensure that the data on the output is put into a clean state that allows appending of new fresh data without having to rescan the whole stream to recover state.", "In addition to the above methods, the StreamWriter must also inherit all other methods and attributes from the underlying stream.", "The StreamReader class is a subclass of Codec and defines the following methods which every stream reader must define in order to be compatible with the Python codec registry.", "Constructor for a StreamReader instance.", "All stream readers must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The stream argument must be a file-like object open for reading text or binary data, as appropriate for the specific codec.", "The StreamReader may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for the standard error handlers the underlying stream codec may support.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the StreamReader object.", "The set of allowed values for the errors argument can be extended with register_error().", "Decodes data from the stream and returns the resulting object.", "The chars argument indicates the number of decoded code points or bytes to return. The read() method will never return more data than requested, but it might return less, if there is not enough available.", "The size argument indicates the approximate maximum number of encoded bytes or code points to read for decoding. The decoder can modify this setting as appropriate. The default value -1 indicates to read and decode as much as possible. This parameter is intended to prevent having to decode huge files in one step.", "The firstline flag indicates that it would be sufficient to only return the first line, if there are decoding errors on later lines.", "The method should use a greedy read strategy meaning that it should read as much data as is allowed within the definition of the encoding and the given size, e.g. if optional encoding endings or state markers are available on the stream, these should be read too.", "Read one line from the input stream and return the decoded data.", "size, if given, is passed as size argument to the stream\u2019s read() method.", "If keepends is false line-endings will be stripped from the lines returned.", "Read all lines available on the input stream and return them as a list of lines.", "Line-endings are implemented using the codec\u2019s decode() method and are included in the list entries if keepends is true.", "sizehint, if given, is passed as the size argument to the stream\u2019s read() method.", "Resets the codec buffers used for keeping internal state.", "Note that no stream repositioning should take place. This method is primarily intended to be able to recover from decoding errors.", "In addition to the above methods, the StreamReader must also inherit all other methods and attributes from the underlying stream.", "The StreamReaderWriter is a convenience class that allows wrapping streams which work in both read and write modes.", "The design is such that one can use the factory functions returned by the lookup() function to construct the instance.", "Creates a StreamReaderWriter instance. stream must be a file-like object. Reader and Writer must be factory functions or classes providing the StreamReader and StreamWriter interface resp. Error handling is done in the same way as defined for the stream readers and writers.", "StreamReaderWriter instances define the combined interfaces of StreamReader and StreamWriter classes. They inherit all other methods and attributes from the underlying stream.", "The StreamRecoder translates data from one encoding to another, which is sometimes useful when dealing with different encoding environments.", "The design is such that one can use the factory functions returned by the lookup() function to construct the instance.", "Creates a StreamRecoder instance which implements a two-way conversion: encode and decode work on the frontend \u2014 the data visible to code calling read() and write(), while Reader and Writer work on the backend \u2014 the data in stream.", "You can use these objects to do transparent transcodings, e.g., from Latin-1 to UTF-8 and back.", "The stream argument must be a file-like object.", "The encode and decode arguments must adhere to the Codec interface. Reader and Writer must be factory functions or classes providing objects of the StreamReader and StreamWriter interface respectively.", "Error handling is done in the same way as defined for the stream readers and writers.", "StreamRecoder instances define the combined interfaces of StreamReader and StreamWriter classes. They inherit all other methods and attributes from the underlying stream.", "Strings are stored internally as sequences of code points in range 0x0\u20130x10FFFF. (See PEP 393 for more details about the implementation.) Once a string object is used outside of CPU and memory, endianness and how these arrays are stored as bytes become an issue. As with other codecs, serialising a string into a sequence of bytes is known as encoding, and recreating the string from the sequence of bytes is known as decoding. There are a variety of different text serialisation codecs, which are collectivity referred to as text encodings.", "The simplest text encoding (called 'latin-1' or 'iso-8859-1') maps the code points 0\u2013255 to the bytes 0x0\u20130xff, which means that a string object that contains code points above U+00FF can\u2019t be encoded with this codec. Doing so will raise a UnicodeEncodeError that looks like the following (although the details of the error message may differ): UnicodeEncodeError: 'latin-1' codec can't encode character '\\u1234' in\nposition 3: ordinal not in range(256).", "There\u2019s another group of encodings (the so called charmap encodings) that choose a different subset of all Unicode code points and how these code points are mapped to the bytes 0x0\u20130xff. To see how this is done simply open e.g. encodings/cp1252.py (which is an encoding that is used primarily on Windows). There\u2019s a string constant with 256 characters that shows you which character is mapped to which byte value.", "All of these encodings can only encode 256 of the 1114112 code points defined in Unicode. A simple and straightforward way that can store each Unicode code point, is to store each code point as four consecutive bytes. There are two possibilities: store the bytes in big endian or in little endian order. These two encodings are called UTF-32-BE and UTF-32-LE respectively. Their disadvantage is that if e.g. you use UTF-32-BE on a little endian machine you will always have to swap bytes on encoding and decoding. UTF-32 avoids this problem: bytes will always be in natural endianness. When these bytes are read by a CPU with a different endianness, then bytes have to be swapped though. To be able to detect the endianness of a UTF-16 or UTF-32 byte sequence, there\u2019s the so called BOM (\u201cByte Order Mark\u201d). This is the Unicode character U+FEFF. This character can be prepended to every UTF-16 or UTF-32 byte sequence. The byte swapped version of this character (0xFFFE) is an illegal character that may not appear in a Unicode text. So when the first character in an UTF-16 or UTF-32 byte sequence appears to be a U+FFFE the bytes have to be swapped on decoding. Unfortunately the character U+FEFF had a second purpose as a ZERO WIDTH NO-BREAK SPACE: a character that has no width and doesn\u2019t allow a word to be split. It can e.g. be used to give hints to a ligature algorithm. With Unicode 4.0 using U+FEFF as a ZERO WIDTH NO-BREAK SPACE has been deprecated (with U+2060 (WORD JOINER) assuming this role). Nevertheless Unicode software still must be able to handle U+FEFF in both roles: as a BOM it\u2019s a device to determine the storage layout of the encoded bytes, and vanishes once the byte sequence has been decoded into a string; as a ZERO WIDTH\nNO-BREAK SPACE it\u2019s a normal character that will be decoded like any other.", "There\u2019s another encoding that is able to encoding the full range of Unicode characters: UTF-8. UTF-8 is an 8-bit encoding, which means there are no issues with byte order in UTF-8. Each byte in a UTF-8 byte sequence consists of two parts: marker bits (the most significant bits) and payload bits. The marker bits are a sequence of zero to four 1 bits followed by a 0 bit. Unicode characters are encoded like this (with x being payload bits, which when concatenated give the Unicode character):", "Range", "Encoding", "U-00000000 \u2026 U-0000007F", "0xxxxxxx", "U-00000080 \u2026 U-000007FF", "110xxxxx 10xxxxxx", "U-00000800 \u2026 U-0000FFFF", "1110xxxx 10xxxxxx 10xxxxxx", "U-00010000 \u2026 U-0010FFFF", "11110xxx 10xxxxxx 10xxxxxx 10xxxxxx", "The least significant bit of the Unicode character is the rightmost x bit.", "As UTF-8 is an 8-bit encoding no BOM is required and any U+FEFF character in the decoded string (even if it\u2019s the first character) is treated as a ZERO\nWIDTH NO-BREAK SPACE.", "Without external information it\u2019s impossible to reliably determine which encoding was used for encoding a string. Each charmap encoding can decode any random byte sequence. However that\u2019s not possible with UTF-8, as UTF-8 byte sequences have a structure that doesn\u2019t allow arbitrary byte sequences. To increase the reliability with which a UTF-8 encoding can be detected, Microsoft invented a variant of UTF-8 (that Python 2.5 calls \"utf-8-sig\") for its Notepad program: Before any of the Unicode characters is written to the file, a UTF-8 encoded BOM (which looks like this as a byte sequence: 0xef, 0xbb, 0xbf) is written. As it\u2019s rather improbable that any charmap encoded file starts with these byte values (which would e.g. map to", "in iso-8859-1), this increases the probability that a utf-8-sig encoding can be correctly guessed from the byte sequence. So here the BOM is not used to be able to determine the byte order used for generating the byte sequence, but as a signature that helps in guessing the encoding. On encoding the utf-8-sig codec will write 0xef, 0xbb, 0xbf as the first three bytes to the file. On decoding utf-8-sig will skip those three bytes if they appear as the first three bytes in the file. In UTF-8, the use of the BOM is discouraged and should generally be avoided.", "Python comes with a number of codecs built-in, either implemented as C functions or with dictionaries as mapping tables. The following table lists the codecs by name, together with a few common aliases, and the languages for which the encoding is likely used. Neither the list of aliases nor the list of languages is meant to be exhaustive. Notice that spelling alternatives that only differ in case or use a hyphen instead of an underscore are also valid aliases; therefore, e.g. 'utf-8' is a valid alias for the 'utf_8' codec.", "CPython implementation detail: Some common encodings can bypass the codecs lookup machinery to improve performance. These optimization opportunities are only recognized by CPython for a limited set of (case insensitive) aliases: utf-8, utf8, latin-1, latin1, iso-8859-1, iso8859-1, mbcs (Windows only), ascii, us-ascii, utf-16, utf16, utf-32, utf32, and the same using underscores instead of dashes. Using alternative aliases for these encodings may result in slower execution.", "Changed in version 3.6: Optimization opportunity recognized for us-ascii.", "Many of the character sets support the same languages. They vary in individual characters (e.g. whether the EURO SIGN is supported or not), and in the assignment of characters to code positions. For the European languages in particular, the following variants typically exist:", "Codec", "Aliases", "Languages", "ascii", "646, us-ascii", "English", "big5", "big5-tw, csbig5", "Traditional Chinese", "big5hkscs", "big5-hkscs, hkscs", "Traditional Chinese", "cp037", "IBM037, IBM039", "English", "cp273", "273, IBM273, csIBM273", "German", "New in version 3.4.", "cp424", "EBCDIC-CP-HE, IBM424", "Hebrew", "cp437", "437, IBM437", "English", "cp500", "EBCDIC-CP-BE, EBCDIC-CP-CH, IBM500", "Western Europe", "cp720", "Arabic", "cp737", "Greek", "cp775", "IBM775", "Baltic languages", "cp850", "850, IBM850", "Western Europe", "cp852", "852, IBM852", "Central and Eastern Europe", "cp855", "855, IBM855", "Bulgarian, Byelorussian, Macedonian, Russian, Serbian", "cp856", "Hebrew", "cp857", "857, IBM857", "Turkish", "cp858", "858, IBM858", "Western Europe", "cp860", "860, IBM860", "Portuguese", "cp861", "861, CP-IS, IBM861", "Icelandic", "cp862", "862, IBM862", "Hebrew", "cp863", "863, IBM863", "Canadian", "cp864", "IBM864", "Arabic", "cp865", "865, IBM865", "Danish, Norwegian", "cp866", "866, IBM866", "Russian", "cp869", "869, CP-GR, IBM869", "Greek", "cp874", "Thai", "cp875", "Greek", "cp932", "932, ms932, mskanji, ms-kanji", "Japanese", "cp949", "949, ms949, uhc", "Korean", "cp950", "950, ms950", "Traditional Chinese", "cp1006", "Urdu", "cp1026", "ibm1026", "Turkish", "cp1125", "1125, ibm1125, cp866u, ruscii", "Ukrainian", "New in version 3.4.", "cp1140", "ibm1140", "Western Europe", "cp1250", "windows-1250", "Central and Eastern Europe", "cp1251", "windows-1251", "Bulgarian, Byelorussian, Macedonian, Russian, Serbian", "cp1252", "windows-1252", "Western Europe", "cp1253", "windows-1253", "Greek", "cp1254", "windows-1254", "Turkish", "cp1255", "windows-1255", "Hebrew", "cp1256", "windows-1256", "Arabic", "cp1257", "windows-1257", "Baltic languages", "cp1258", "windows-1258", "Vietnamese", "euc_jp", "eucjp, ujis, u-jis", "Japanese", "euc_jis_2004", "jisx0213, eucjis2004", "Japanese", "euc_jisx0213", "eucjisx0213", "Japanese", "euc_kr", "euckr, korean, ksc5601, ks_c-5601, ks_c-5601-1987, ksx1001, ks_x-1001", "Korean", "gb2312", "chinese, csiso58gb231280, euc-cn, euccn, eucgb2312-cn, gb2312-1980, gb2312-80, iso-ir-58", "Simplified Chinese", "gbk", "936, cp936, ms936", "Unified Chinese", "gb18030", "gb18030-2000", "Unified Chinese", "hz", "hzgb, hz-gb, hz-gb-2312", "Simplified Chinese", "iso2022_jp", "csiso2022jp, iso2022jp, iso-2022-jp", "Japanese", "iso2022_jp_1", "iso2022jp-1, iso-2022-jp-1", "Japanese", "iso2022_jp_2", "iso2022jp-2, iso-2022-jp-2", "Japanese, Korean, Simplified Chinese, Western Europe, Greek", "iso2022_jp_2004", "iso2022jp-2004, iso-2022-jp-2004", "Japanese", "iso2022_jp_3", "iso2022jp-3, iso-2022-jp-3", "Japanese", "iso2022_jp_ext", "iso2022jp-ext, iso-2022-jp-ext", "Japanese", "iso2022_kr", "csiso2022kr, iso2022kr, iso-2022-kr", "Korean", "latin_1", "iso-8859-1, iso8859-1, 8859, cp819, latin, latin1, L1", "Western Europe", "iso8859_2", "iso-8859-2, latin2, L2", "Central and Eastern Europe", "iso8859_3", "iso-8859-3, latin3, L3", "Esperanto, Maltese", "iso8859_4", "iso-8859-4, latin4, L4", "Baltic languages", "iso8859_5", "iso-8859-5, cyrillic", "Bulgarian, Byelorussian, Macedonian, Russian, Serbian", "iso8859_6", "iso-8859-6, arabic", "Arabic", "iso8859_7", "iso-8859-7, greek, greek8", "Greek", "iso8859_8", "iso-8859-8, hebrew", "Hebrew", "iso8859_9", "iso-8859-9, latin5, L5", "Turkish", "iso8859_10", "iso-8859-10, latin6, L6", "Nordic languages", "iso8859_11", "iso-8859-11, thai", "Thai languages", "iso8859_13", "iso-8859-13, latin7, L7", "Baltic languages", "iso8859_14", "iso-8859-14, latin8, L8", "Celtic languages", "iso8859_15", "iso-8859-15, latin9, L9", "Western Europe", "iso8859_16", "iso-8859-16, latin10, L10", "South-Eastern Europe", "johab", "cp1361, ms1361", "Korean", "koi8_r", "Russian", "koi8_t", "Tajik", "New in version 3.5.", "koi8_u", "Ukrainian", "kz1048", "kz_1048, strk1048_2002, rk1048", "Kazakh", "New in version 3.5.", "mac_cyrillic", "maccyrillic", "Bulgarian, Byelorussian, Macedonian, Russian, Serbian", "mac_greek", "macgreek", "Greek", "mac_iceland", "maciceland", "Icelandic", "mac_latin2", "maclatin2, maccentraleurope, mac_centeuro", "Central and Eastern Europe", "mac_roman", "macroman, macintosh", "Western Europe", "mac_turkish", "macturkish", "Turkish", "ptcp154", "csptcp154, pt154, cp154, cyrillic-asian", "Kazakh", "shift_jis", "csshiftjis, shiftjis, sjis, s_jis", "Japanese", "shift_jis_2004", "shiftjis2004, sjis_2004, sjis2004", "Japanese", "shift_jisx0213", "shiftjisx0213, sjisx0213, s_jisx0213", "Japanese", "utf_32", "U32, utf32", "all languages", "utf_32_be", "UTF-32BE", "all languages", "utf_32_le", "UTF-32LE", "all languages", "utf_16", "U16, utf16", "all languages", "utf_16_be", "UTF-16BE", "all languages", "utf_16_le", "UTF-16LE", "all languages", "utf_7", "U7, unicode-1-1-utf-7", "all languages", "utf_8", "U8, UTF, utf8, cp65001", "all languages", "utf_8_sig", "all languages", "Changed in version 3.4: The utf-16* and utf-32* encoders no longer allow surrogate code points (U+D800\u2013U+DFFF) to be encoded. The utf-32* decoders no longer decode byte sequences that correspond to surrogate code points.", "Changed in version 3.8: cp65001 is now an alias to utf_8.", "A number of predefined codecs are specific to Python, so their codec names have no meaning outside Python. These are listed in the tables below based on the expected input and output types (note that while text encodings are the most common use case for codecs, the underlying codec infrastructure supports arbitrary data transforms rather than just text encodings). For asymmetric codecs, the stated meaning describes the encoding direction.", "The following codecs provide str to bytes encoding and bytes-like object to str decoding, similar to the Unicode text encodings.", "Codec", "Aliases", "Meaning", "idna", "Implement RFC 3490, see also encodings.idna. Only errors='strict' is supported.", "mbcs", "ansi, dbcs", "Windows only: Encode the operand according to the ANSI codepage (CP_ACP).", "oem", "Windows only: Encode the operand according to the OEM codepage (CP_OEMCP).", "New in version 3.6.", "palmos", "Encoding of PalmOS 3.5.", "punycode", "Implement RFC 3492. Stateful codecs are not supported.", "raw_unicode_escape", "Latin-1 encoding with \\uXXXX and \\UXXXXXXXX for other code points. Existing backslashes are not escaped in any way. It is used in the Python pickle protocol.", "undefined", "Raise an exception for all conversions, even empty strings. The error handler is ignored.", "unicode_escape", "Encoding suitable as the contents of a Unicode literal in ASCII-encoded Python source code, except that quotes are not escaped. Decode from Latin-1 source code. Beware that Python source code actually uses UTF-8 by default.", "Changed in version 3.8: \u201cunicode_internal\u201d codec is removed.", "The following codecs provide binary transforms: bytes-like object to bytes mappings. They are not supported by bytes.decode() (which only produces str output).", "Codec", "Aliases", "Meaning", "Encoder / decoder", "base64_codec 1", "base64, base_64", "Convert the operand to multiline MIME base64 (the result always includes a trailing '\\n').", "Changed in version 3.4: accepts any bytes-like object as input for encoding and decoding", "base64.encodebytes() / base64.decodebytes()", "bz2_codec", "bz2", "Compress the operand using bz2.", "bz2.compress() / bz2.decompress()", "hex_codec", "hex", "Convert the operand to hexadecimal representation, with two digits per byte.", "binascii.b2a_hex() / binascii.a2b_hex()", "quopri_codec", "quopri, quotedprintable, quoted_printable", "Convert the operand to MIME quoted printable.", "quopri.encode() with quotetabs=True / quopri.decode()", "uu_codec", "uu", "Convert the operand using uuencode.", "uu.encode() / uu.decode()", "zlib_codec", "zip, zlib", "Compress the operand using gzip.", "zlib.compress() / zlib.decompress()", "In addition to bytes-like objects, 'base64_codec' also accepts ASCII-only instances of str for decoding", "New in version 3.2: Restoration of the binary transforms.", "Changed in version 3.4: Restoration of the aliases for the binary transforms.", "The following codec provides a text transform: a str to str mapping. It is not supported by str.encode() (which only produces bytes output).", "Codec", "Aliases", "Meaning", "rot_13", "rot13", "Return the Caesar-cypher encryption of the operand.", "New in version 3.2: Restoration of the rot_13 text transform.", "Changed in version 3.4: Restoration of the rot13 alias.", "This module implements RFC 3490 (Internationalized Domain Names in Applications) and RFC 3492 (Nameprep: A Stringprep Profile for Internationalized Domain Names (IDN)). It builds upon the punycode encoding and stringprep.", "If you need the IDNA 2008 standard from RFC 5891 and RFC 5895, use the third-party idna module <https://pypi.org/project/idna/>_.", "These RFCs together define a protocol to support non-ASCII characters in domain names. A domain name containing non-ASCII characters (such as www.Alliancefran\u00e7aise.nu) is converted into an ASCII-compatible encoding (ACE, such as www.xn--alliancefranaise-npb.nu). The ACE form of the domain name is then used in all places where arbitrary characters are not allowed by the protocol, such as DNS queries, HTTP Host fields, and so on. This conversion is carried out in the application; if possible invisible to the user: The application should transparently convert Unicode domain labels to IDNA on the wire, and convert back ACE labels to Unicode before presenting them to the user.", "Python supports this conversion in several ways: the idna codec performs conversion between Unicode and ACE, separating an input string into labels based on the separator characters defined in section 3.1 of RFC 3490 and converting each label to ACE as required, and conversely separating an input byte string into labels based on the . separator and converting any ACE labels found into unicode. Furthermore, the socket module transparently converts Unicode host names to ACE, so that applications need not be concerned about converting host names themselves when they pass them to the socket module. On top of that, modules that have host names as function parameters, such as http.client and ftplib, accept Unicode host names (http.client then also transparently sends an IDNA hostname in the Host field if it sends that field at all).", "When receiving host names from the wire (such as in reverse name lookup), no automatic conversion to Unicode is performed: applications wishing to present such host names to the user should decode them to Unicode.", "The module encodings.idna also implements the nameprep procedure, which performs certain normalizations on host names, to achieve case-insensitivity of international domain names, and to unify similar characters. The nameprep functions can be used directly if desired.", "Return the nameprepped version of label. The implementation currently assumes query strings, so AllowUnassigned is true.", "Convert a label to ASCII, as specified in RFC 3490. UseSTD3ASCIIRules is assumed to be false.", "Convert a label to Unicode, as specified in RFC 3490.", "This module implements the ANSI codepage (CP_ACP).", "Availability: Windows only.", "Changed in version 3.3: Support any error handler.", "Changed in version 3.2: Before 3.2, the errors argument was ignored; 'replace' was always used to encode, and 'ignore' to decode.", "This module implements a variant of the UTF-8 codec. On encoding, a UTF-8 encoded BOM will be prepended to the UTF-8 encoded bytes. For the stateful encoder this is only done once (on the first write to the byte stream). On decoding, an optional UTF-8 encoded BOM at the start of the data will be skipped."]}, {"name": "codecs.backslashreplace_errors()", "path": "library/codecs#codecs.backslashreplace_errors", "type": "Binary Data", "text": ["Implements the 'backslashreplace' error handling (for text encodings only): malformed data is replaced by a backslashed escape sequence."]}, {"name": "codecs.BOM", "path": "library/codecs#codecs.BOM", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_BE", "path": "library/codecs#codecs.BOM_BE", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_LE", "path": "library/codecs#codecs.BOM_LE", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_UTF16", "path": "library/codecs#codecs.BOM_UTF16", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_UTF16_BE", "path": "library/codecs#codecs.BOM_UTF16_BE", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_UTF16_LE", "path": "library/codecs#codecs.BOM_UTF16_LE", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_UTF32", "path": "library/codecs#codecs.BOM_UTF32", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_UTF32_BE", "path": "library/codecs#codecs.BOM_UTF32_BE", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_UTF32_LE", "path": "library/codecs#codecs.BOM_UTF32_LE", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.BOM_UTF8", "path": "library/codecs#codecs.BOM_UTF8", "type": "Binary Data", "text": ["These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings. They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform\u2019s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings."]}, {"name": "codecs.Codec.decode()", "path": "library/codecs#codecs.Codec.decode", "type": "Binary Data", "text": ["Decodes the object input and returns a tuple (output object, length consumed). For instance, for a text encoding, decoding converts a bytes object encoded using a particular character set encoding to a string object.", "For text encodings and bytes-to-bytes codecs, input must be a bytes object or one which provides the read-only buffer interface \u2013 for example, buffer objects and memory mapped files.", "The errors argument defines the error handling to apply. It defaults to 'strict' handling.", "The method may not store state in the Codec instance. Use StreamReader for codecs which have to keep state in order to make decoding efficient.", "The decoder must be able to handle zero length input and return an empty object of the output object type in this situation."]}, {"name": "codecs.Codec.encode()", "path": "library/codecs#codecs.Codec.encode", "type": "Binary Data", "text": ["Encodes the object input and returns a tuple (output object, length consumed). For instance, text encoding converts a string object to a bytes object using a particular character set encoding (e.g., cp1252 or iso-8859-1).", "The errors argument defines the error handling to apply. It defaults to 'strict' handling.", "The method may not store state in the Codec instance. Use StreamWriter for codecs which have to keep state in order to make encoding efficient.", "The encoder must be able to handle zero length input and return an empty object of the output object type in this situation."]}, {"name": "codecs.CodecInfo", "path": "library/codecs#codecs.CodecInfo", "type": "Binary Data", "text": ["Codec details when looking up the codec registry. The constructor arguments are stored in attributes of the same name:", "The name of the encoding.", "The stateless encoding and decoding functions. These must be functions or methods which have the same interface as the encode() and decode() methods of Codec instances (see Codec Interface). The functions or methods are expected to work in a stateless mode.", "Incremental encoder and decoder classes or factory functions. These have to provide the interface defined by the base classes IncrementalEncoder and IncrementalDecoder, respectively. Incremental codecs can maintain state.", "Stream writer and reader classes or factory functions. These have to provide the interface defined by the base classes StreamWriter and StreamReader, respectively. Stream codecs can maintain state."]}, {"name": "codecs.CodecInfo.decode", "path": "library/codecs#codecs.CodecInfo.decode", "type": "Binary Data", "text": ["The stateless encoding and decoding functions. These must be functions or methods which have the same interface as the encode() and decode() methods of Codec instances (see Codec Interface). The functions or methods are expected to work in a stateless mode."]}, {"name": "codecs.CodecInfo.encode", "path": "library/codecs#codecs.CodecInfo.encode", "type": "Binary Data", "text": ["The stateless encoding and decoding functions. These must be functions or methods which have the same interface as the encode() and decode() methods of Codec instances (see Codec Interface). The functions or methods are expected to work in a stateless mode."]}, {"name": "codecs.CodecInfo.incrementaldecoder", "path": "library/codecs#codecs.CodecInfo.incrementaldecoder", "type": "Binary Data", "text": ["Incremental encoder and decoder classes or factory functions. These have to provide the interface defined by the base classes IncrementalEncoder and IncrementalDecoder, respectively. Incremental codecs can maintain state."]}, {"name": "codecs.CodecInfo.incrementalencoder", "path": "library/codecs#codecs.CodecInfo.incrementalencoder", "type": "Binary Data", "text": ["Incremental encoder and decoder classes or factory functions. These have to provide the interface defined by the base classes IncrementalEncoder and IncrementalDecoder, respectively. Incremental codecs can maintain state."]}, {"name": "codecs.CodecInfo.name", "path": "library/codecs#codecs.CodecInfo.name", "type": "Binary Data", "text": ["The name of the encoding."]}, {"name": "codecs.CodecInfo.streamreader", "path": "library/codecs#codecs.CodecInfo.streamreader", "type": "Binary Data", "text": ["Stream writer and reader classes or factory functions. These have to provide the interface defined by the base classes StreamWriter and StreamReader, respectively. Stream codecs can maintain state."]}, {"name": "codecs.CodecInfo.streamwriter", "path": "library/codecs#codecs.CodecInfo.streamwriter", "type": "Binary Data", "text": ["Stream writer and reader classes or factory functions. These have to provide the interface defined by the base classes StreamWriter and StreamReader, respectively. Stream codecs can maintain state."]}, {"name": "codecs.decode()", "path": "library/codecs#codecs.decode", "type": "Binary Data", "text": ["Decodes obj using the codec registered for encoding.", "Errors may be given to set the desired error handling scheme. The default error handler is 'strict' meaning that decoding errors raise ValueError (or a more codec specific subclass, such as UnicodeDecodeError). Refer to Codec Base Classes for more information on codec error handling."]}, {"name": "codecs.encode()", "path": "library/codecs#codecs.encode", "type": "Binary Data", "text": ["Encodes obj using the codec registered for encoding.", "Errors may be given to set the desired error handling scheme. The default error handler is 'strict' meaning that encoding errors raise ValueError (or a more codec specific subclass, such as UnicodeEncodeError). Refer to Codec Base Classes for more information on codec error handling."]}, {"name": "codecs.EncodedFile()", "path": "library/codecs#codecs.EncodedFile", "type": "Binary Data", "text": ["Return a StreamRecoder instance, a wrapped version of file which provides transparent transcoding. The original file is closed when the wrapped version is closed.", "Data written to the wrapped file is decoded according to the given data_encoding and then written to the original file as bytes using file_encoding. Bytes read from the original file are decoded according to file_encoding, and the result is encoded using data_encoding.", "If file_encoding is not given, it defaults to data_encoding.", "errors may be given to define the error handling. It defaults to 'strict', which causes ValueError to be raised in case an encoding error occurs."]}, {"name": "codecs.getdecoder()", "path": "library/codecs#codecs.getdecoder", "type": "Binary Data", "text": ["Look up the codec for the given encoding and return its decoder function.", "Raises a LookupError in case the encoding cannot be found."]}, {"name": "codecs.getencoder()", "path": "library/codecs#codecs.getencoder", "type": "Binary Data", "text": ["Look up the codec for the given encoding and return its encoder function.", "Raises a LookupError in case the encoding cannot be found."]}, {"name": "codecs.getincrementaldecoder()", "path": "library/codecs#codecs.getincrementaldecoder", "type": "Binary Data", "text": ["Look up the codec for the given encoding and return its incremental decoder class or factory function.", "Raises a LookupError in case the encoding cannot be found or the codec doesn\u2019t support an incremental decoder."]}, {"name": "codecs.getincrementalencoder()", "path": "library/codecs#codecs.getincrementalencoder", "type": "Binary Data", "text": ["Look up the codec for the given encoding and return its incremental encoder class or factory function.", "Raises a LookupError in case the encoding cannot be found or the codec doesn\u2019t support an incremental encoder."]}, {"name": "codecs.getreader()", "path": "library/codecs#codecs.getreader", "type": "Binary Data", "text": ["Look up the codec for the given encoding and return its StreamReader class or factory function.", "Raises a LookupError in case the encoding cannot be found."]}, {"name": "codecs.getwriter()", "path": "library/codecs#codecs.getwriter", "type": "Binary Data", "text": ["Look up the codec for the given encoding and return its StreamWriter class or factory function.", "Raises a LookupError in case the encoding cannot be found."]}, {"name": "codecs.ignore_errors()", "path": "library/codecs#codecs.ignore_errors", "type": "Binary Data", "text": ["Implements the 'ignore' error handling: malformed data is ignored and encoding or decoding is continued without further notice."]}, {"name": "codecs.IncrementalDecoder", "path": "library/codecs#codecs.IncrementalDecoder", "type": "Binary Data", "text": ["Constructor for an IncrementalDecoder instance.", "All incremental decoders must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The IncrementalDecoder may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for possible values.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the IncrementalDecoder object.", "Decodes object (taking the current state of the decoder into account) and returns the resulting decoded object. If this is the last call to decode() final must be true (the default is false). If final is true the decoder must decode the input completely and must flush all buffers. If this isn\u2019t possible (e.g. because of incomplete byte sequences at the end of the input) it must initiate error handling just like in the stateless case (which might raise an exception).", "Reset the decoder to the initial state.", "Return the current state of the decoder. This must be a tuple with two items, the first must be the buffer containing the still undecoded input. The second must be an integer and can be additional state info. (The implementation should make sure that 0 is the most common additional state info.) If this additional state info is 0 it must be possible to set the decoder to the state which has no input buffered and 0 as the additional state info, so that feeding the previously buffered input to the decoder returns it to the previous state without producing any output. (Additional state info that is more complicated than integers can be converted into an integer by marshaling/pickling the info and encoding the bytes of the resulting string into an integer.)", "Set the state of the decoder to state. state must be a decoder state returned by getstate()."]}, {"name": "codecs.IncrementalDecoder.decode()", "path": "library/codecs#codecs.IncrementalDecoder.decode", "type": "Binary Data", "text": ["Decodes object (taking the current state of the decoder into account) and returns the resulting decoded object. If this is the last call to decode() final must be true (the default is false). If final is true the decoder must decode the input completely and must flush all buffers. If this isn\u2019t possible (e.g. because of incomplete byte sequences at the end of the input) it must initiate error handling just like in the stateless case (which might raise an exception)."]}, {"name": "codecs.IncrementalDecoder.getstate()", "path": "library/codecs#codecs.IncrementalDecoder.getstate", "type": "Binary Data", "text": ["Return the current state of the decoder. This must be a tuple with two items, the first must be the buffer containing the still undecoded input. The second must be an integer and can be additional state info. (The implementation should make sure that 0 is the most common additional state info.) If this additional state info is 0 it must be possible to set the decoder to the state which has no input buffered and 0 as the additional state info, so that feeding the previously buffered input to the decoder returns it to the previous state without producing any output. (Additional state info that is more complicated than integers can be converted into an integer by marshaling/pickling the info and encoding the bytes of the resulting string into an integer.)"]}, {"name": "codecs.IncrementalDecoder.reset()", "path": "library/codecs#codecs.IncrementalDecoder.reset", "type": "Binary Data", "text": ["Reset the decoder to the initial state."]}, {"name": "codecs.IncrementalDecoder.setstate()", "path": "library/codecs#codecs.IncrementalDecoder.setstate", "type": "Binary Data", "text": ["Set the state of the decoder to state. state must be a decoder state returned by getstate()."]}, {"name": "codecs.IncrementalEncoder", "path": "library/codecs#codecs.IncrementalEncoder", "type": "Binary Data", "text": ["Constructor for an IncrementalEncoder instance.", "All incremental encoders must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The IncrementalEncoder may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for possible values.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the IncrementalEncoder object.", "Encodes object (taking the current state of the encoder into account) and returns the resulting encoded object. If this is the last call to encode() final must be true (the default is false).", "Reset the encoder to the initial state. The output is discarded: call .encode(object, final=True), passing an empty byte or text string if necessary, to reset the encoder and to get the output.", "Return the current state of the encoder which must be an integer. The implementation should make sure that 0 is the most common state. (States that are more complicated than integers can be converted into an integer by marshaling/pickling the state and encoding the bytes of the resulting string into an integer.)", "Set the state of the encoder to state. state must be an encoder state returned by getstate()."]}, {"name": "codecs.IncrementalEncoder.encode()", "path": "library/codecs#codecs.IncrementalEncoder.encode", "type": "Binary Data", "text": ["Encodes object (taking the current state of the encoder into account) and returns the resulting encoded object. If this is the last call to encode() final must be true (the default is false)."]}, {"name": "codecs.IncrementalEncoder.getstate()", "path": "library/codecs#codecs.IncrementalEncoder.getstate", "type": "Binary Data", "text": ["Return the current state of the encoder which must be an integer. The implementation should make sure that 0 is the most common state. (States that are more complicated than integers can be converted into an integer by marshaling/pickling the state and encoding the bytes of the resulting string into an integer.)"]}, {"name": "codecs.IncrementalEncoder.reset()", "path": "library/codecs#codecs.IncrementalEncoder.reset", "type": "Binary Data", "text": ["Reset the encoder to the initial state. The output is discarded: call .encode(object, final=True), passing an empty byte or text string if necessary, to reset the encoder and to get the output."]}, {"name": "codecs.IncrementalEncoder.setstate()", "path": "library/codecs#codecs.IncrementalEncoder.setstate", "type": "Binary Data", "text": ["Set the state of the encoder to state. state must be an encoder state returned by getstate()."]}, {"name": "codecs.iterdecode()", "path": "library/codecs#codecs.iterdecode", "type": "Binary Data", "text": ["Uses an incremental decoder to iteratively decode the input provided by iterator. This function is a generator. The errors argument (as well as any other keyword argument) is passed through to the incremental decoder.", "This function requires that the codec accept bytes objects to decode. Therefore it does not support text-to-text encoders such as rot_13, although rot_13 may be used equivalently with iterencode()."]}, {"name": "codecs.iterencode()", "path": "library/codecs#codecs.iterencode", "type": "Binary Data", "text": ["Uses an incremental encoder to iteratively encode the input provided by iterator. This function is a generator. The errors argument (as well as any other keyword argument) is passed through to the incremental encoder.", "This function requires that the codec accept text str objects to encode. Therefore it does not support bytes-to-bytes encoders such as base64_codec."]}, {"name": "codecs.lookup()", "path": "library/codecs#codecs.lookup", "type": "Binary Data", "text": ["Looks up the codec info in the Python codec registry and returns a CodecInfo object as defined below.", "Encodings are first looked up in the registry\u2019s cache. If not found, the list of registered search functions is scanned. If no CodecInfo object is found, a LookupError is raised. Otherwise, the CodecInfo object is stored in the cache and returned to the caller."]}, {"name": "codecs.lookup_error()", "path": "library/codecs#codecs.lookup_error", "type": "Binary Data", "text": ["Return the error handler previously registered under the name name.", "Raises a LookupError in case the handler cannot be found."]}, {"name": "codecs.namereplace_errors()", "path": "library/codecs#codecs.namereplace_errors", "type": "Binary Data", "text": ["Implements the 'namereplace' error handling (for encoding with text encodings only): the unencodable character is replaced by a \\N{...} escape sequence.", "New in version 3.5."]}, {"name": "codecs.open()", "path": "library/codecs#codecs.open", "type": "Binary Data", "text": ["Open an encoded file using the given mode and return an instance of StreamReaderWriter, providing transparent encoding/decoding. The default file mode is 'r', meaning to open the file in read mode.", "Note", "Underlying encoded files are always opened in binary mode. No automatic conversion of '\\n' is done on reading and writing. The mode argument may be any binary mode acceptable to the built-in open() function; the 'b' is automatically added.", "encoding specifies the encoding which is to be used for the file. Any encoding that encodes to and decodes from bytes is allowed, and the data types supported by the file methods depend on the codec used.", "errors may be given to define the error handling. It defaults to 'strict' which causes a ValueError to be raised in case an encoding error occurs.", "buffering has the same meaning as for the built-in open() function. It defaults to -1 which means that the default buffer size will be used."]}, {"name": "codecs.register()", "path": "library/codecs#codecs.register", "type": "Binary Data", "text": ["Register a codec search function. Search functions are expected to take one argument, being the encoding name in all lower case letters with hyphens and spaces converted to underscores, and return a CodecInfo object. In case a search function cannot find a given encoding, it should return None.", "Changed in version 3.9: Hyphens and spaces are converted to underscore.", "Note", "Search function registration is not currently reversible, which may cause problems in some cases, such as unit testing or module reloading."]}, {"name": "codecs.register_error()", "path": "library/codecs#codecs.register_error", "type": "Binary Data", "text": ["Register the error handling function error_handler under the name name. The error_handler argument will be called during encoding and decoding in case of an error, when name is specified as the errors parameter.", "For encoding, error_handler will be called with a UnicodeEncodeError instance, which contains information about the location of the error. The error handler must either raise this or a different exception, or return a tuple with a replacement for the unencodable part of the input and a position where encoding should continue. The replacement may be either str or bytes. If the replacement is bytes, the encoder will simply copy them into the output buffer. If the replacement is a string, the encoder will encode the replacement. Encoding continues on original input at the specified position. Negative position values will be treated as being relative to the end of the input string. If the resulting position is out of bound an IndexError will be raised.", "Decoding and translating works similarly, except UnicodeDecodeError or UnicodeTranslateError will be passed to the handler and that the replacement from the error handler will be put into the output directly."]}, {"name": "codecs.replace_errors()", "path": "library/codecs#codecs.replace_errors", "type": "Binary Data", "text": ["Implements the 'replace' error handling (for text encodings only): substitutes '?' for encoding errors (to be encoded by the codec), and '\\ufffd' (the Unicode replacement character) for decoding errors."]}, {"name": "codecs.StreamReader", "path": "library/codecs#codecs.StreamReader", "type": "Binary Data", "text": ["Constructor for a StreamReader instance.", "All stream readers must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The stream argument must be a file-like object open for reading text or binary data, as appropriate for the specific codec.", "The StreamReader may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for the standard error handlers the underlying stream codec may support.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the StreamReader object.", "The set of allowed values for the errors argument can be extended with register_error().", "Decodes data from the stream and returns the resulting object.", "The chars argument indicates the number of decoded code points or bytes to return. The read() method will never return more data than requested, but it might return less, if there is not enough available.", "The size argument indicates the approximate maximum number of encoded bytes or code points to read for decoding. The decoder can modify this setting as appropriate. The default value -1 indicates to read and decode as much as possible. This parameter is intended to prevent having to decode huge files in one step.", "The firstline flag indicates that it would be sufficient to only return the first line, if there are decoding errors on later lines.", "The method should use a greedy read strategy meaning that it should read as much data as is allowed within the definition of the encoding and the given size, e.g. if optional encoding endings or state markers are available on the stream, these should be read too.", "Read one line from the input stream and return the decoded data.", "size, if given, is passed as size argument to the stream\u2019s read() method.", "If keepends is false line-endings will be stripped from the lines returned.", "Read all lines available on the input stream and return them as a list of lines.", "Line-endings are implemented using the codec\u2019s decode() method and are included in the list entries if keepends is true.", "sizehint, if given, is passed as the size argument to the stream\u2019s read() method.", "Resets the codec buffers used for keeping internal state.", "Note that no stream repositioning should take place. This method is primarily intended to be able to recover from decoding errors."]}, {"name": "codecs.StreamReader.read()", "path": "library/codecs#codecs.StreamReader.read", "type": "Binary Data", "text": ["Decodes data from the stream and returns the resulting object.", "The chars argument indicates the number of decoded code points or bytes to return. The read() method will never return more data than requested, but it might return less, if there is not enough available.", "The size argument indicates the approximate maximum number of encoded bytes or code points to read for decoding. The decoder can modify this setting as appropriate. The default value -1 indicates to read and decode as much as possible. This parameter is intended to prevent having to decode huge files in one step.", "The firstline flag indicates that it would be sufficient to only return the first line, if there are decoding errors on later lines.", "The method should use a greedy read strategy meaning that it should read as much data as is allowed within the definition of the encoding and the given size, e.g. if optional encoding endings or state markers are available on the stream, these should be read too."]}, {"name": "codecs.StreamReader.readline()", "path": "library/codecs#codecs.StreamReader.readline", "type": "Binary Data", "text": ["Read one line from the input stream and return the decoded data.", "size, if given, is passed as size argument to the stream\u2019s read() method.", "If keepends is false line-endings will be stripped from the lines returned."]}, {"name": "codecs.StreamReader.readlines()", "path": "library/codecs#codecs.StreamReader.readlines", "type": "Binary Data", "text": ["Read all lines available on the input stream and return them as a list of lines.", "Line-endings are implemented using the codec\u2019s decode() method and are included in the list entries if keepends is true.", "sizehint, if given, is passed as the size argument to the stream\u2019s read() method."]}, {"name": "codecs.StreamReader.reset()", "path": "library/codecs#codecs.StreamReader.reset", "type": "Binary Data", "text": ["Resets the codec buffers used for keeping internal state.", "Note that no stream repositioning should take place. This method is primarily intended to be able to recover from decoding errors."]}, {"name": "codecs.StreamReaderWriter", "path": "library/codecs#codecs.StreamReaderWriter", "type": "Binary Data", "text": ["Creates a StreamReaderWriter instance. stream must be a file-like object. Reader and Writer must be factory functions or classes providing the StreamReader and StreamWriter interface resp. Error handling is done in the same way as defined for the stream readers and writers."]}, {"name": "codecs.StreamRecoder", "path": "library/codecs#codecs.StreamRecoder", "type": "Binary Data", "text": ["Creates a StreamRecoder instance which implements a two-way conversion: encode and decode work on the frontend \u2014 the data visible to code calling read() and write(), while Reader and Writer work on the backend \u2014 the data in stream.", "You can use these objects to do transparent transcodings, e.g., from Latin-1 to UTF-8 and back.", "The stream argument must be a file-like object.", "The encode and decode arguments must adhere to the Codec interface. Reader and Writer must be factory functions or classes providing objects of the StreamReader and StreamWriter interface respectively.", "Error handling is done in the same way as defined for the stream readers and writers."]}, {"name": "codecs.StreamWriter", "path": "library/codecs#codecs.StreamWriter", "type": "Binary Data", "text": ["Constructor for a StreamWriter instance.", "All stream writers must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry.", "The stream argument must be a file-like object open for writing text or binary data, as appropriate for the specific codec.", "The StreamWriter may implement different error handling schemes by providing the errors keyword argument. See Error Handlers for the standard error handlers the underlying stream codec may support.", "The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the StreamWriter object.", "Writes the object\u2019s contents encoded to the stream.", "Writes the concatenated list of strings to the stream (possibly by reusing the write() method). The standard bytes-to-bytes codecs do not support this method.", "Resets the codec buffers used for keeping internal state.", "Calling this method should ensure that the data on the output is put into a clean state that allows appending of new fresh data without having to rescan the whole stream to recover state."]}, {"name": "codecs.StreamWriter.reset()", "path": "library/codecs#codecs.StreamWriter.reset", "type": "Binary Data", "text": ["Resets the codec buffers used for keeping internal state.", "Calling this method should ensure that the data on the output is put into a clean state that allows appending of new fresh data without having to rescan the whole stream to recover state."]}, {"name": "codecs.StreamWriter.write()", "path": "library/codecs#codecs.StreamWriter.write", "type": "Binary Data", "text": ["Writes the object\u2019s contents encoded to the stream."]}, {"name": "codecs.StreamWriter.writelines()", "path": "library/codecs#codecs.StreamWriter.writelines", "type": "Binary Data", "text": ["Writes the concatenated list of strings to the stream (possibly by reusing the write() method). The standard bytes-to-bytes codecs do not support this method."]}, {"name": "codecs.strict_errors()", "path": "library/codecs#codecs.strict_errors", "type": "Binary Data", "text": ["Implements the 'strict' error handling: each encoding or decoding error raises a UnicodeError."]}, {"name": "codecs.xmlcharrefreplace_errors()", "path": "library/codecs#codecs.xmlcharrefreplace_errors", "type": "Binary Data", "text": ["Implements the 'xmlcharrefreplace' error handling (for encoding with text encodings only): the unencodable character is replaced by an appropriate XML character reference."]}, {"name": "codeop", "path": "library/codeop", "type": "Interpreters", "text": ["Source code: Lib/codeop.py", "The codeop module provides utilities upon which the Python read-eval-print loop can be emulated, as is done in the code module. As a result, you probably don\u2019t want to use the module directly; if you want to include such a loop in your program you probably want to use the code module instead.", "There are two parts to this job:", "The codeop module provides a way of doing each of these things, and a way of doing them both.", "To do just the former:", "Tries to compile source, which should be a string of Python code and return a code object if source is valid Python code. In that case, the filename attribute of the code object will be filename, which defaults to '<input>'. Returns None if source is not valid Python code, but is a prefix of valid Python code.", "If there is a problem with source, an exception will be raised. SyntaxError is raised if there is invalid Python syntax, and OverflowError or ValueError if there is an invalid literal.", "The symbol argument determines whether source is compiled as a statement ('single', the default), as a sequence of statements ('exec') or as an expression ('eval'). Any other value will cause ValueError to be raised.", "Note", "It is possible (but not likely) that the parser stops parsing with a successful outcome before reaching the end of the source; in this case, trailing symbols may be ignored instead of causing an error. For example, a backslash followed by two newlines may be followed by arbitrary garbage. This will be fixed once the API for the parser is better.", "Instances of this class have __call__() methods identical in signature to the built-in function compile(), but with the difference that if the instance compiles program text containing a __future__ statement, the instance \u2018remembers\u2019 and compiles all subsequent program texts with the statement in force.", "Instances of this class have __call__() methods identical in signature to compile_command(); the difference is that if the instance compiles program text containing a __future__ statement, the instance \u2018remembers\u2019 and compiles all subsequent program texts with the statement in force."]}, {"name": "codeop.CommandCompiler", "path": "library/codeop#codeop.CommandCompiler", "type": "Interpreters", "text": ["Instances of this class have __call__() methods identical in signature to compile_command(); the difference is that if the instance compiles program text containing a __future__ statement, the instance \u2018remembers\u2019 and compiles all subsequent program texts with the statement in force."]}, {"name": "codeop.Compile", "path": "library/codeop#codeop.Compile", "type": "Interpreters", "text": ["Instances of this class have __call__() methods identical in signature to the built-in function compile(), but with the difference that if the instance compiles program text containing a __future__ statement, the instance \u2018remembers\u2019 and compiles all subsequent program texts with the statement in force."]}, {"name": "codeop.compile_command()", "path": "library/codeop#codeop.compile_command", "type": "Interpreters", "text": ["Tries to compile source, which should be a string of Python code and return a code object if source is valid Python code. In that case, the filename attribute of the code object will be filename, which defaults to '<input>'. Returns None if source is not valid Python code, but is a prefix of valid Python code.", "If there is a problem with source, an exception will be raised. SyntaxError is raised if there is invalid Python syntax, and OverflowError or ValueError if there is an invalid literal.", "The symbol argument determines whether source is compiled as a statement ('single', the default), as a sequence of statements ('exec') or as an expression ('eval'). Any other value will cause ValueError to be raised.", "Note", "It is possible (but not likely) that the parser stops parsing with a successful outcome before reaching the end of the source; in this case, trailing symbols may be ignored instead of causing an error. For example, a backslash followed by two newlines may be followed by arbitrary garbage. This will be fixed once the API for the parser is better."]}, {"name": "collections", "path": "library/collections", "type": "Data Types", "text": ["Source code: Lib/collections/__init__.py", "This module implements specialized container datatypes providing alternatives to Python\u2019s general purpose built-in containers, dict, list, set, and tuple.", "namedtuple()", "factory function for creating tuple subclasses with named fields", "deque", "list-like container with fast appends and pops on either end", "ChainMap", "dict-like class for creating a single view of multiple mappings", "Counter", "dict subclass for counting hashable objects", "OrderedDict", "dict subclass that remembers the order entries were added", "defaultdict", "dict subclass that calls a factory function to supply missing values", "UserDict", "wrapper around dictionary objects for easier dict subclassing", "UserList", "wrapper around list objects for easier list subclassing", "UserString", "wrapper around string objects for easier string subclassing", "Deprecated since version 3.3, will be removed in version 3.10: Moved Collections Abstract Base Classes to the collections.abc module. For backwards compatibility, they continue to be visible in this module through Python 3.9.", "New in version 3.3.", "A ChainMap class is provided for quickly linking a number of mappings so they can be treated as a single unit. It is often much faster than creating a new dictionary and running multiple update() calls.", "The class can be used to simulate nested scopes and is useful in templating.", "A ChainMap groups multiple dicts or other mappings together to create a single, updateable view. If no maps are specified, a single empty dictionary is provided so that a new chain always has at least one mapping.", "The underlying mappings are stored in a list. That list is public and can be accessed or updated using the maps attribute. There is no other state.", "Lookups search the underlying mappings successively until a key is found. In contrast, writes, updates, and deletions only operate on the first mapping.", "A ChainMap incorporates the underlying mappings by reference. So, if one of the underlying mappings gets updated, those changes will be reflected in ChainMap.", "All of the usual dictionary methods are supported. In addition, there is a maps attribute, a method for creating new subcontexts, and a property for accessing all but the first mapping:", "A user updateable list of mappings. The list is ordered from first-searched to last-searched. It is the only stored state and can be modified to change which mappings are searched. The list should always contain at least one mapping.", "Returns a new ChainMap containing a new map followed by all of the maps in the current instance. If m is specified, it becomes the new map at the front of the list of mappings; if not specified, an empty dict is used, so that a call to d.new_child() is equivalent to: ChainMap({}, *d.maps). This method is used for creating subcontexts that can be updated without altering values in any of the parent mappings.", "Changed in version 3.4: The optional m parameter was added.", "Property returning a new ChainMap containing all of the maps in the current instance except the first one. This is useful for skipping the first map in the search. Use cases are similar to those for the nonlocal keyword used in nested scopes. The use cases also parallel those for the built-in super() function. A reference to d.parents is equivalent to: ChainMap(*d.maps[1:]).", "Note, the iteration order of a ChainMap() is determined by scanning the mappings last to first:", "This gives the same ordering as a series of dict.update() calls starting with the last mapping:", "Changed in version 3.9: Added support for | and |= operators, specified in PEP 584.", "See also", "This section shows various approaches to working with chained maps.", "Example of simulating Python\u2019s internal lookup chain:", "Example of letting user specified command-line arguments take precedence over environment variables which in turn take precedence over default values:", "Example patterns for using the ChainMap class to simulate nested contexts:", "The ChainMap class only makes updates (writes and deletions) to the first mapping in the chain while lookups will search the full chain. However, if deep writes and deletions are desired, it is easy to make a subclass that updates keys found deeper in the chain:", "A counter tool is provided to support convenient and rapid tallies. For example:", "A Counter is a dict subclass for counting hashable objects. It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages.", "Elements are counted from an iterable or initialized from another mapping (or counter):", "Counter objects have a dictionary interface except that they return a zero count for missing items instead of raising a KeyError:", "Setting a count to zero does not remove an element from a counter. Use del to remove it entirely:", "New in version 3.1.", "Changed in version 3.7: As a dict subclass, Counter Inherited the capability to remember insertion order. Math operations on Counter objects also preserve order. Results are ordered according to when an element is first encountered in the left operand and then by the order encountered in the right operand.", "Counter objects support three methods beyond those available for all dictionaries:", "Return an iterator over elements repeating each as many times as its count. Elements are returned in the order first encountered. If an element\u2019s count is less than one, elements() will ignore it.", "Return a list of the n most common elements and their counts from the most common to the least. If n is omitted or None, most_common() returns all elements in the counter. Elements with equal counts are ordered in the order first encountered:", "Elements are subtracted from an iterable or from another mapping (or counter). Like dict.update() but subtracts counts instead of replacing them. Both inputs and outputs may be zero or negative.", "New in version 3.2.", "The usual dictionary methods are available for Counter objects except for two which work differently for counters.", "This class method is not implemented for Counter objects.", "Elements are counted from an iterable or added-in from another mapping (or counter). Like dict.update() but adds counts instead of replacing them. Also, the iterable is expected to be a sequence of elements, not a sequence of (key, value) pairs.", "Common patterns for working with Counter objects:", "Several mathematical operations are provided for combining Counter objects to produce multisets (counters that have counts greater than zero). Addition and subtraction combine counters by adding or subtracting the counts of corresponding elements. Intersection and union return the minimum and maximum of corresponding counts. Each operation can accept inputs with signed counts, but the output will exclude results with counts of zero or less.", "Unary addition and subtraction are shortcuts for adding an empty counter or subtracting from an empty counter.", "New in version 3.3: Added support for unary plus, unary minus, and in-place multiset operations.", "Note", "Counters were primarily designed to work with positive integers to represent running counts; however, care was taken to not unnecessarily preclude use cases needing other types or negative values. To help with those use cases, this section documents the minimum range and type restrictions.", "See also", "To enumerate all distinct multisets of a given size over a given set of elements, see itertools.combinations_with_replacement():", "Returns a new deque object initialized left-to-right (using append()) with data from iterable. If iterable is not specified, the new deque is empty.", "Deques are a generalization of stacks and queues (the name is pronounced \u201cdeck\u201d and is short for \u201cdouble-ended queue\u201d). Deques support thread-safe, memory efficient appends and pops from either side of the deque with approximately the same O(1) performance in either direction.", "Though list objects support similar operations, they are optimized for fast fixed-length operations and incur O(n) memory movement costs for pop(0) and insert(0, v) operations which change both the size and position of the underlying data representation.", "If maxlen is not specified or is None, deques may grow to an arbitrary length. Otherwise, the deque is bounded to the specified maximum length. Once a bounded length deque is full, when new items are added, a corresponding number of items are discarded from the opposite end. Bounded length deques provide functionality similar to the tail filter in Unix. They are also useful for tracking transactions and other pools of data where only the most recent activity is of interest.", "Deque objects support the following methods:", "Add x to the right side of the deque.", "Add x to the left side of the deque.", "Remove all elements from the deque leaving it with length 0.", "Create a shallow copy of the deque.", "New in version 3.5.", "Count the number of deque elements equal to x.", "New in version 3.2.", "Extend the right side of the deque by appending elements from the iterable argument.", "Extend the left side of the deque by appending elements from iterable. Note, the series of left appends results in reversing the order of elements in the iterable argument.", "Return the position of x in the deque (at or after index start and before index stop). Returns the first match or raises ValueError if not found.", "New in version 3.5.", "Insert x into the deque at position i.", "If the insertion would cause a bounded deque to grow beyond maxlen, an IndexError is raised.", "New in version 3.5.", "Remove and return an element from the right side of the deque. If no elements are present, raises an IndexError.", "Remove and return an element from the left side of the deque. If no elements are present, raises an IndexError.", "Remove the first occurrence of value. If not found, raises a ValueError.", "Reverse the elements of the deque in-place and then return None.", "New in version 3.2.", "Rotate the deque n steps to the right. If n is negative, rotate to the left.", "When the deque is not empty, rotating one step to the right is equivalent to d.appendleft(d.pop()), and rotating one step to the left is equivalent to d.append(d.popleft()).", "Deque objects also provide one read-only attribute:", "Maximum size of a deque or None if unbounded.", "New in version 3.1.", "In addition to the above, deques support iteration, pickling, len(d), reversed(d), copy.copy(d), copy.deepcopy(d), membership testing with the in operator, and subscript references such as d[0] to access the first element. Indexed access is O(1) at both ends but slows to O(n) in the middle. For fast random access, use lists instead.", "Starting in version 3.5, deques support __add__(), __mul__(), and __imul__().", "Example:", "This section shows various approaches to working with deques.", "Bounded length deques provide functionality similar to the tail filter in Unix:", "Another approach to using deques is to maintain a sequence of recently added elements by appending to the right and popping to the left:", "A round-robin scheduler can be implemented with input iterators stored in a deque. Values are yielded from the active iterator in position zero. If that iterator is exhausted, it can be removed with popleft(); otherwise, it can be cycled back to the end with the rotate() method:", "The rotate() method provides a way to implement deque slicing and deletion. For example, a pure Python implementation of del d[n] relies on the rotate() method to position elements to be popped:", "To implement deque slicing, use a similar approach applying rotate() to bring a target element to the left side of the deque. Remove old entries with popleft(), add new entries with extend(), and then reverse the rotation. With minor variations on that approach, it is easy to implement Forth style stack manipulations such as dup, drop, swap, over, pick, rot, and roll.", "Returns a new dictionary-like object. defaultdict is a subclass of the built-in dict class. It overrides one method and adds one writable instance variable. The remaining functionality is the same as for the dict class and is not documented here.", "The first argument provides the initial value for the default_factory attribute; it defaults to None. All remaining arguments are treated the same as if they were passed to the dict constructor, including keyword arguments.", "defaultdict objects support the following method in addition to the standard dict operations:", "If the default_factory attribute is None, this raises a KeyError exception with the key as argument.", "If default_factory is not None, it is called without arguments to provide a default value for the given key, this value is inserted in the dictionary for the key, and returned.", "If calling default_factory raises an exception this exception is propagated unchanged.", "This method is called by the __getitem__() method of the dict class when the requested key is not found; whatever it returns or raises is then returned or raised by __getitem__().", "Note that __missing__() is not called for any operations besides __getitem__(). This means that get() will, like normal dictionaries, return None as a default rather than using default_factory.", "defaultdict objects support the following instance variable:", "This attribute is used by the __missing__() method; it is initialized from the first argument to the constructor, if present, or to None, if absent.", "Changed in version 3.9: Added merge (|) and update (|=) operators, specified in PEP 584.", "Using list as the default_factory, it is easy to group a sequence of key-value pairs into a dictionary of lists:", "When each key is encountered for the first time, it is not already in the mapping; so an entry is automatically created using the default_factory function which returns an empty list. The list.append() operation then attaches the value to the new list. When keys are encountered again, the look-up proceeds normally (returning the list for that key) and the list.append() operation adds another value to the list. This technique is simpler and faster than an equivalent technique using dict.setdefault():", "Setting the default_factory to int makes the defaultdict useful for counting (like a bag or multiset in other languages):", "When a letter is first encountered, it is missing from the mapping, so the default_factory function calls int() to supply a default count of zero. The increment operation then builds up the count for each letter.", "The function int() which always returns zero is just a special case of constant functions. A faster and more flexible way to create constant functions is to use a lambda function which can supply any constant value (not just zero):", "Setting the default_factory to set makes the defaultdict useful for building a dictionary of sets:", "Named tuples assign meaning to each position in a tuple and allow for more readable, self-documenting code. They can be used wherever regular tuples are used, and they add the ability to access fields by name instead of position index.", "Returns a new tuple subclass named typename. The new subclass is used to create tuple-like objects that have fields accessible by attribute lookup as well as being indexable and iterable. Instances of the subclass also have a helpful docstring (with typename and field_names) and a helpful __repr__() method which lists the tuple contents in a name=value format.", "The field_names are a sequence of strings such as ['x', 'y']. Alternatively, field_names can be a single string with each fieldname separated by whitespace and/or commas, for example 'x y' or 'x, y'.", "Any valid Python identifier may be used for a fieldname except for names starting with an underscore. Valid identifiers consist of letters, digits, and underscores but do not start with a digit or underscore and cannot be a keyword such as class, for, return, global, pass, or raise.", "If rename is true, invalid fieldnames are automatically replaced with positional names. For example, ['abc', 'def', 'ghi', 'abc'] is converted to ['abc', '_1', 'ghi', '_3'], eliminating the keyword def and the duplicate fieldname abc.", "defaults can be None or an iterable of default values. Since fields with a default value must come after any fields without a default, the defaults are applied to the rightmost parameters. For example, if the fieldnames are ['x', 'y', 'z'] and the defaults are (1, 2), then x will be a required argument, y will default to 1, and z will default to 2.", "If module is defined, the __module__ attribute of the named tuple is set to that value.", "Named tuple instances do not have per-instance dictionaries, so they are lightweight and require no more memory than regular tuples.", "To support pickling, the named tuple class should be assigned to a variable that matches typename.", "Changed in version 3.1: Added support for rename.", "Changed in version 3.6: The verbose and rename parameters became keyword-only arguments.", "Changed in version 3.6: Added the module parameter.", "Changed in version 3.7: Removed the verbose parameter and the _source attribute.", "Changed in version 3.7: Added the defaults parameter and the _field_defaults attribute.", "Named tuples are especially useful for assigning field names to result tuples returned by the csv or sqlite3 modules:", "In addition to the methods inherited from tuples, named tuples support three additional methods and two attributes. To prevent conflicts with field names, the method and attribute names start with an underscore.", "Class method that makes a new instance from an existing sequence or iterable.", "Return a new dict which maps field names to their corresponding values:", "Changed in version 3.1: Returns an OrderedDict instead of a regular dict.", "Changed in version 3.8: Returns a regular dict instead of an OrderedDict. As of Python 3.7, regular dicts are guaranteed to be ordered. If the extra features of OrderedDict are required, the suggested remediation is to cast the result to the desired type: OrderedDict(nt._asdict()).", "Return a new instance of the named tuple replacing specified fields with new values:", "Tuple of strings listing the field names. Useful for introspection and for creating new named tuple types from existing named tuples.", "Dictionary mapping field names to default values.", "To retrieve a field whose name is stored in a string, use the getattr() function:", "To convert a dictionary to a named tuple, use the double-star-operator (as described in Unpacking Argument Lists):", "Since a named tuple is a regular Python class, it is easy to add or change functionality with a subclass. Here is how to add a calculated field and a fixed-width print format:", "The subclass shown above sets __slots__ to an empty tuple. This helps keep memory requirements low by preventing the creation of instance dictionaries.", "Subclassing is not useful for adding new, stored fields. Instead, simply create a new named tuple type from the _fields attribute:", "Docstrings can be customized by making direct assignments to the __doc__ fields:", "Changed in version 3.5: Property docstrings became writeable.", "See also", "See typing.NamedTuple for a way to add type hints for named tuples. It also provides an elegant notation using the class keyword:", "Ordered dictionaries are just like regular dictionaries but have some extra capabilities relating to ordering operations. They have become less important now that the built-in dict class gained the ability to remember insertion order (this new behavior became guaranteed in Python 3.7).", "Some differences from dict still remain:", "Return an instance of a dict subclass that has methods specialized for rearranging dictionary order.", "New in version 3.1.", "The popitem() method for ordered dictionaries returns and removes a (key, value) pair. The pairs are returned in LIFO order if last is true or FIFO order if false.", "Move an existing key to either end of an ordered dictionary. The item is moved to the right end if last is true (the default) or to the beginning if last is false. Raises KeyError if the key does not exist:", "New in version 3.2.", "In addition to the usual mapping methods, ordered dictionaries also support reverse iteration using reversed().", "Equality tests between OrderedDict objects are order-sensitive and are implemented as list(od1.items())==list(od2.items()). Equality tests between OrderedDict objects and other Mapping objects are order-insensitive like regular dictionaries. This allows OrderedDict objects to be substituted anywhere a regular dictionary is used.", "Changed in version 3.5: The items, keys, and values views of OrderedDict now support reverse iteration using reversed().", "Changed in version 3.6: With the acceptance of PEP 468, order is retained for keyword arguments passed to the OrderedDict constructor and its update() method.", "Changed in version 3.9: Added merge (|) and update (|=) operators, specified in PEP 584.", "It is straightforward to create an ordered dictionary variant that remembers the order the keys were last inserted. If a new entry overwrites an existing entry, the original insertion position is changed and moved to the end:", "An OrderedDict would also be useful for implementing variants of functools.lru_cache():", "The class, UserDict acts as a wrapper around dictionary objects. The need for this class has been partially supplanted by the ability to subclass directly from dict; however, this class can be easier to work with because the underlying dictionary is accessible as an attribute.", "Class that simulates a dictionary. The instance\u2019s contents are kept in a regular dictionary, which is accessible via the data attribute of UserDict instances. If initialdata is provided, data is initialized with its contents; note that a reference to initialdata will not be kept, allowing it be used for other purposes.", "In addition to supporting the methods and operations of mappings, UserDict instances provide the following attribute:", "A real dictionary used to store the contents of the UserDict class.", "This class acts as a wrapper around list objects. It is a useful base class for your own list-like classes which can inherit from them and override existing methods or add new ones. In this way, one can add new behaviors to lists.", "The need for this class has been partially supplanted by the ability to subclass directly from list; however, this class can be easier to work with because the underlying list is accessible as an attribute.", "Class that simulates a list. The instance\u2019s contents are kept in a regular list, which is accessible via the data attribute of UserList instances. The instance\u2019s contents are initially set to a copy of list, defaulting to the empty list []. list can be any iterable, for example a real Python list or a UserList object.", "In addition to supporting the methods and operations of mutable sequences, UserList instances provide the following attribute:", "A real list object used to store the contents of the UserList class.", "Subclassing requirements: Subclasses of UserList are expected to offer a constructor which can be called with either no arguments or one argument. List operations which return a new sequence attempt to create an instance of the actual implementation class. To do so, it assumes that the constructor can be called with a single parameter, which is a sequence object used as a data source.", "If a derived class does not wish to comply with this requirement, all of the special methods supported by this class will need to be overridden; please consult the sources for information about the methods which need to be provided in that case.", "The class, UserString acts as a wrapper around string objects. The need for this class has been partially supplanted by the ability to subclass directly from str; however, this class can be easier to work with because the underlying string is accessible as an attribute.", "Class that simulates a string object. The instance\u2019s content is kept in a regular string object, which is accessible via the data attribute of UserString instances. The instance\u2019s contents are initially set to a copy of seq. The seq argument can be any object which can be converted into a string using the built-in str() function.", "In addition to supporting the methods and operations of strings, UserString instances provide the following attribute:", "A real str object used to store the contents of the UserString class.", "Changed in version 3.5: New methods __getnewargs__, __rmod__, casefold, format_map, isprintable, and maketrans."]}, {"name": "collections.abc", "path": "library/collections.abc", "type": "Data Types", "text": ["New in version 3.3: Formerly, this module was part of the collections module.", "Source code: Lib/_collections_abc.py", "This module provides abstract base classes that can be used to test whether a class provides a particular interface; for example, whether it is hashable or whether it is a mapping.", "The collections module offers the following ABCs:", "ABC", "Inherits from", "Abstract Methods", "Mixin Methods", "Container", "__contains__", "Hashable", "__hash__", "Iterable", "__iter__", "Iterator", "Iterable", "__next__", "__iter__", "Reversible", "Iterable", "__reversed__", "Generator", "Iterator", "send, throw", "close, __iter__, __next__", "Sized", "__len__", "Callable", "__call__", "Collection", "Sized, Iterable, Container", "__contains__, __iter__, __len__", "Sequence", "Reversible, Collection", "__getitem__, __len__", "__contains__, __iter__, __reversed__, index, and count", "MutableSequence", "Sequence", "__getitem__, __setitem__, __delitem__, __len__, insert", "Inherited Sequence methods and append, reverse, extend, pop, remove, and __iadd__", "ByteString", "Sequence", "__getitem__, __len__", "Inherited Sequence methods", "Set", "Collection", "__contains__, __iter__, __len__", "__le__, __lt__, __eq__, __ne__, __gt__, __ge__, __and__, __or__, __sub__, __xor__, and isdisjoint", "MutableSet", "Set", "__contains__, __iter__, __len__, add, discard", "Inherited Set methods and clear, pop, remove, __ior__, __iand__, __ixor__, and __isub__", "Mapping", "Collection", "__getitem__, __iter__, __len__", "__contains__, keys, items, values, get, __eq__, and __ne__", "MutableMapping", "Mapping", "__getitem__, __setitem__, __delitem__, __iter__, __len__", "Inherited Mapping methods and pop, popitem, clear, update, and setdefault", "MappingView", "Sized", "__len__", "ItemsView", "MappingView, Set", "__contains__, __iter__", "KeysView", "MappingView, Set", "__contains__, __iter__", "ValuesView", "MappingView, Collection", "__contains__, __iter__", "Awaitable", "__await__", "Coroutine", "Awaitable", "send, throw", "close", "AsyncIterable", "__aiter__", "AsyncIterator", "AsyncIterable", "__anext__", "__aiter__", "AsyncGenerator", "AsyncIterator", "asend, athrow", "aclose, __aiter__, __anext__", "ABC for classes that provide the __contains__() method.", "ABC for classes that provide the __hash__() method.", "ABC for classes that provide the __len__() method.", "ABC for classes that provide the __call__() method.", "ABC for classes that provide the __iter__() method.", "Checking isinstance(obj, Iterable) detects classes that are registered as Iterable or that have an __iter__() method, but it does not detect classes that iterate with the __getitem__() method. The only reliable way to determine whether an object is iterable is to call iter(obj).", "ABC for sized iterable container classes.", "New in version 3.6.", "ABC for classes that provide the __iter__() and __next__() methods. See also the definition of iterator.", "ABC for iterable classes that also provide the __reversed__() method.", "New in version 3.6.", "ABC for generator classes that implement the protocol defined in PEP 342 that extends iterators with the send(), throw() and close() methods. See also the definition of generator.", "New in version 3.5.", "ABCs for read-only and mutable sequences.", "Implementation note: Some of the mixin methods, such as __iter__(), __reversed__() and index(), make repeated calls to the underlying __getitem__() method. Consequently, if __getitem__() is implemented with constant access speed, the mixin methods will have linear performance; however, if the underlying method is linear (as it would be with a linked list), the mixins will have quadratic performance and will likely need to be overridden.", "Changed in version 3.5: The index() method added support for stop and start arguments.", "ABCs for read-only and mutable sets.", "ABCs for read-only and mutable mappings.", "ABCs for mapping, items, keys, and values views.", "ABC for awaitable objects, which can be used in await expressions. Custom implementations must provide the __await__() method.", "Coroutine objects and instances of the Coroutine ABC are all instances of this ABC.", "Note", "In CPython, generator-based coroutines (generators decorated with types.coroutine() or asyncio.coroutine()) are awaitables, even though they do not have an __await__() method. Using isinstance(gencoro, Awaitable) for them will return False. Use inspect.isawaitable() to detect them.", "New in version 3.5.", "ABC for coroutine compatible classes. These implement the following methods, defined in Coroutine Objects: send(), throw(), and close(). Custom implementations must also implement __await__(). All Coroutine instances are also instances of Awaitable. See also the definition of coroutine.", "Note", "In CPython, generator-based coroutines (generators decorated with types.coroutine() or asyncio.coroutine()) are awaitables, even though they do not have an __await__() method. Using isinstance(gencoro, Coroutine) for them will return False. Use inspect.isawaitable() to detect them.", "New in version 3.5.", "ABC for classes that provide __aiter__ method. See also the definition of asynchronous iterable.", "New in version 3.5.", "ABC for classes that provide __aiter__ and __anext__ methods. See also the definition of asynchronous iterator.", "New in version 3.5.", "ABC for asynchronous generator classes that implement the protocol defined in PEP 525 and PEP 492.", "New in version 3.6.", "These ABCs allow us to ask classes or instances if they provide particular functionality, for example:", "Several of the ABCs are also useful as mixins that make it easier to develop classes supporting container APIs. For example, to write a class supporting the full Set API, it is only necessary to supply the three underlying abstract methods: __contains__(), __iter__(), and __len__(). The ABC supplies the remaining methods such as __and__() and isdisjoint():", "Notes on using Set and MutableSet as a mixin:", "See also"]}, {"name": "collections.abc.AsyncGenerator", "path": "library/collections.abc#collections.abc.AsyncGenerator", "type": "Data Types", "text": ["ABC for asynchronous generator classes that implement the protocol defined in PEP 525 and PEP 492.", "New in version 3.6."]}, {"name": "collections.abc.AsyncIterable", "path": "library/collections.abc#collections.abc.AsyncIterable", "type": "Data Types", "text": ["ABC for classes that provide __aiter__ method. See also the definition of asynchronous iterable.", "New in version 3.5."]}, {"name": "collections.abc.AsyncIterator", "path": "library/collections.abc#collections.abc.AsyncIterator", "type": "Data Types", "text": ["ABC for classes that provide __aiter__ and __anext__ methods. See also the definition of asynchronous iterator.", "New in version 3.5."]}, {"name": "collections.abc.Awaitable", "path": "library/collections.abc#collections.abc.Awaitable", "type": "Data Types", "text": ["ABC for awaitable objects, which can be used in await expressions. Custom implementations must provide the __await__() method.", "Coroutine objects and instances of the Coroutine ABC are all instances of this ABC.", "Note", "In CPython, generator-based coroutines (generators decorated with types.coroutine() or asyncio.coroutine()) are awaitables, even though they do not have an __await__() method. Using isinstance(gencoro, Awaitable) for them will return False. Use inspect.isawaitable() to detect them.", "New in version 3.5."]}, {"name": "collections.abc.ByteString", "path": "library/collections.abc#collections.abc.ByteString", "type": "Data Types", "text": ["ABCs for read-only and mutable sequences.", "Implementation note: Some of the mixin methods, such as __iter__(), __reversed__() and index(), make repeated calls to the underlying __getitem__() method. Consequently, if __getitem__() is implemented with constant access speed, the mixin methods will have linear performance; however, if the underlying method is linear (as it would be with a linked list), the mixins will have quadratic performance and will likely need to be overridden.", "Changed in version 3.5: The index() method added support for stop and start arguments."]}, {"name": "collections.abc.Callable", "path": "library/collections.abc#collections.abc.Callable", "type": "Data Types", "text": ["ABC for classes that provide the __call__() method."]}, {"name": "collections.abc.Collection", "path": "library/collections.abc#collections.abc.Collection", "type": "Data Types", "text": ["ABC for sized iterable container classes.", "New in version 3.6."]}, {"name": "collections.abc.Container", "path": "library/collections.abc#collections.abc.Container", "type": "Data Types", "text": ["ABC for classes that provide the __contains__() method."]}, {"name": "collections.abc.Coroutine", "path": "library/collections.abc#collections.abc.Coroutine", "type": "Data Types", "text": ["ABC for coroutine compatible classes. These implement the following methods, defined in Coroutine Objects: send(), throw(), and close(). Custom implementations must also implement __await__(). All Coroutine instances are also instances of Awaitable. See also the definition of coroutine.", "Note", "In CPython, generator-based coroutines (generators decorated with types.coroutine() or asyncio.coroutine()) are awaitables, even though they do not have an __await__() method. Using isinstance(gencoro, Coroutine) for them will return False. Use inspect.isawaitable() to detect them.", "New in version 3.5."]}, {"name": "collections.abc.Generator", "path": "library/collections.abc#collections.abc.Generator", "type": "Data Types", "text": ["ABC for generator classes that implement the protocol defined in PEP 342 that extends iterators with the send(), throw() and close() methods. See also the definition of generator.", "New in version 3.5."]}, {"name": "collections.abc.Hashable", "path": "library/collections.abc#collections.abc.Hashable", "type": "Data Types", "text": ["ABC for classes that provide the __hash__() method."]}, {"name": "collections.abc.ItemsView", "path": "library/collections.abc#collections.abc.ItemsView", "type": "Data Types", "text": ["ABCs for mapping, items, keys, and values views."]}, {"name": "collections.abc.Iterable", "path": "library/collections.abc#collections.abc.Iterable", "type": "Data Types", "text": ["ABC for classes that provide the __iter__() method.", "Checking isinstance(obj, Iterable) detects classes that are registered as Iterable or that have an __iter__() method, but it does not detect classes that iterate with the __getitem__() method. The only reliable way to determine whether an object is iterable is to call iter(obj)."]}, {"name": "collections.abc.Iterator", "path": "library/collections.abc#collections.abc.Iterator", "type": "Data Types", "text": ["ABC for classes that provide the __iter__() and __next__() methods. See also the definition of iterator."]}, {"name": "collections.abc.KeysView", "path": "library/collections.abc#collections.abc.KeysView", "type": "Data Types", "text": ["ABCs for mapping, items, keys, and values views."]}, {"name": "collections.abc.Mapping", "path": "library/collections.abc#collections.abc.Mapping", "type": "Data Types", "text": ["ABCs for read-only and mutable mappings."]}, {"name": "collections.abc.MappingView", "path": "library/collections.abc#collections.abc.MappingView", "type": "Data Types", "text": ["ABCs for mapping, items, keys, and values views."]}, {"name": "collections.abc.MutableMapping", "path": "library/collections.abc#collections.abc.MutableMapping", "type": "Data Types", "text": ["ABCs for read-only and mutable mappings."]}, {"name": "collections.abc.MutableSequence", "path": "library/collections.abc#collections.abc.MutableSequence", "type": "Data Types", "text": ["ABCs for read-only and mutable sequences.", "Implementation note: Some of the mixin methods, such as __iter__(), __reversed__() and index(), make repeated calls to the underlying __getitem__() method. Consequently, if __getitem__() is implemented with constant access speed, the mixin methods will have linear performance; however, if the underlying method is linear (as it would be with a linked list), the mixins will have quadratic performance and will likely need to be overridden.", "Changed in version 3.5: The index() method added support for stop and start arguments."]}, {"name": "collections.abc.MutableSet", "path": "library/collections.abc#collections.abc.MutableSet", "type": "Data Types", "text": ["ABCs for read-only and mutable sets."]}, {"name": "collections.abc.Reversible", "path": "library/collections.abc#collections.abc.Reversible", "type": "Data Types", "text": ["ABC for iterable classes that also provide the __reversed__() method.", "New in version 3.6."]}, {"name": "collections.abc.Sequence", "path": "library/collections.abc#collections.abc.Sequence", "type": "Data Types", "text": ["ABCs for read-only and mutable sequences.", "Implementation note: Some of the mixin methods, such as __iter__(), __reversed__() and index(), make repeated calls to the underlying __getitem__() method. Consequently, if __getitem__() is implemented with constant access speed, the mixin methods will have linear performance; however, if the underlying method is linear (as it would be with a linked list), the mixins will have quadratic performance and will likely need to be overridden.", "Changed in version 3.5: The index() method added support for stop and start arguments."]}, {"name": "collections.abc.Set", "path": "library/collections.abc#collections.abc.Set", "type": "Data Types", "text": ["ABCs for read-only and mutable sets."]}, {"name": "collections.abc.Sized", "path": "library/collections.abc#collections.abc.Sized", "type": "Data Types", "text": ["ABC for classes that provide the __len__() method."]}, {"name": "collections.abc.ValuesView", "path": "library/collections.abc#collections.abc.ValuesView", "type": "Data Types", "text": ["ABCs for mapping, items, keys, and values views."]}, {"name": "collections.ChainMap", "path": "library/collections#collections.ChainMap", "type": "Data Types", "text": ["A ChainMap groups multiple dicts or other mappings together to create a single, updateable view. If no maps are specified, a single empty dictionary is provided so that a new chain always has at least one mapping.", "The underlying mappings are stored in a list. That list is public and can be accessed or updated using the maps attribute. There is no other state.", "Lookups search the underlying mappings successively until a key is found. In contrast, writes, updates, and deletions only operate on the first mapping.", "A ChainMap incorporates the underlying mappings by reference. So, if one of the underlying mappings gets updated, those changes will be reflected in ChainMap.", "All of the usual dictionary methods are supported. In addition, there is a maps attribute, a method for creating new subcontexts, and a property for accessing all but the first mapping:", "A user updateable list of mappings. The list is ordered from first-searched to last-searched. It is the only stored state and can be modified to change which mappings are searched. The list should always contain at least one mapping.", "Returns a new ChainMap containing a new map followed by all of the maps in the current instance. If m is specified, it becomes the new map at the front of the list of mappings; if not specified, an empty dict is used, so that a call to d.new_child() is equivalent to: ChainMap({}, *d.maps). This method is used for creating subcontexts that can be updated without altering values in any of the parent mappings.", "Changed in version 3.4: The optional m parameter was added.", "Property returning a new ChainMap containing all of the maps in the current instance except the first one. This is useful for skipping the first map in the search. Use cases are similar to those for the nonlocal keyword used in nested scopes. The use cases also parallel those for the built-in super() function. A reference to d.parents is equivalent to: ChainMap(*d.maps[1:]).", "Note, the iteration order of a ChainMap() is determined by scanning the mappings last to first:", "This gives the same ordering as a series of dict.update() calls starting with the last mapping:", "Changed in version 3.9: Added support for | and |= operators, specified in PEP 584."]}, {"name": "collections.ChainMap.maps", "path": "library/collections#collections.ChainMap.maps", "type": "Data Types", "text": ["A user updateable list of mappings. The list is ordered from first-searched to last-searched. It is the only stored state and can be modified to change which mappings are searched. The list should always contain at least one mapping."]}, {"name": "collections.ChainMap.new_child()", "path": "library/collections#collections.ChainMap.new_child", "type": "Data Types", "text": ["Returns a new ChainMap containing a new map followed by all of the maps in the current instance. If m is specified, it becomes the new map at the front of the list of mappings; if not specified, an empty dict is used, so that a call to d.new_child() is equivalent to: ChainMap({}, *d.maps). This method is used for creating subcontexts that can be updated without altering values in any of the parent mappings.", "Changed in version 3.4: The optional m parameter was added."]}, {"name": "collections.ChainMap.parents", "path": "library/collections#collections.ChainMap.parents", "type": "Data Types", "text": ["Property returning a new ChainMap containing all of the maps in the current instance except the first one. This is useful for skipping the first map in the search. Use cases are similar to those for the nonlocal keyword used in nested scopes. The use cases also parallel those for the built-in super() function. A reference to d.parents is equivalent to: ChainMap(*d.maps[1:])."]}, {"name": "collections.Counter", "path": "library/collections#collections.Counter", "type": "Data Types", "text": ["A Counter is a dict subclass for counting hashable objects. It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages.", "Elements are counted from an iterable or initialized from another mapping (or counter):", "Counter objects have a dictionary interface except that they return a zero count for missing items instead of raising a KeyError:", "Setting a count to zero does not remove an element from a counter. Use del to remove it entirely:", "New in version 3.1.", "Changed in version 3.7: As a dict subclass, Counter Inherited the capability to remember insertion order. Math operations on Counter objects also preserve order. Results are ordered according to when an element is first encountered in the left operand and then by the order encountered in the right operand.", "Counter objects support three methods beyond those available for all dictionaries:", "Return an iterator over elements repeating each as many times as its count. Elements are returned in the order first encountered. If an element\u2019s count is less than one, elements() will ignore it.", "Return a list of the n most common elements and their counts from the most common to the least. If n is omitted or None, most_common() returns all elements in the counter. Elements with equal counts are ordered in the order first encountered:", "Elements are subtracted from an iterable or from another mapping (or counter). Like dict.update() but subtracts counts instead of replacing them. Both inputs and outputs may be zero or negative.", "New in version 3.2.", "The usual dictionary methods are available for Counter objects except for two which work differently for counters.", "This class method is not implemented for Counter objects.", "Elements are counted from an iterable or added-in from another mapping (or counter). Like dict.update() but adds counts instead of replacing them. Also, the iterable is expected to be a sequence of elements, not a sequence of (key, value) pairs."]}, {"name": "collections.Counter.elements()", "path": "library/collections#collections.Counter.elements", "type": "Data Types", "text": ["Return an iterator over elements repeating each as many times as its count. Elements are returned in the order first encountered. If an element\u2019s count is less than one, elements() will ignore it."]}, {"name": "collections.Counter.fromkeys()", "path": "library/collections#collections.Counter.fromkeys", "type": "Data Types", "text": ["This class method is not implemented for Counter objects."]}, {"name": "collections.Counter.most_common()", "path": "library/collections#collections.Counter.most_common", "type": "Data Types", "text": ["Return a list of the n most common elements and their counts from the most common to the least. If n is omitted or None, most_common() returns all elements in the counter. Elements with equal counts are ordered in the order first encountered:"]}, {"name": "collections.Counter.subtract()", "path": "library/collections#collections.Counter.subtract", "type": "Data Types", "text": ["Elements are subtracted from an iterable or from another mapping (or counter). Like dict.update() but subtracts counts instead of replacing them. Both inputs and outputs may be zero or negative.", "New in version 3.2."]}, {"name": "collections.Counter.update()", "path": "library/collections#collections.Counter.update", "type": "Data Types", "text": ["Elements are counted from an iterable or added-in from another mapping (or counter). Like dict.update() but adds counts instead of replacing them. Also, the iterable is expected to be a sequence of elements, not a sequence of (key, value) pairs."]}, {"name": "collections.defaultdict", "path": "library/collections#collections.defaultdict", "type": "Data Types", "text": ["Returns a new dictionary-like object. defaultdict is a subclass of the built-in dict class. It overrides one method and adds one writable instance variable. The remaining functionality is the same as for the dict class and is not documented here.", "The first argument provides the initial value for the default_factory attribute; it defaults to None. All remaining arguments are treated the same as if they were passed to the dict constructor, including keyword arguments.", "defaultdict objects support the following method in addition to the standard dict operations:", "If the default_factory attribute is None, this raises a KeyError exception with the key as argument.", "If default_factory is not None, it is called without arguments to provide a default value for the given key, this value is inserted in the dictionary for the key, and returned.", "If calling default_factory raises an exception this exception is propagated unchanged.", "This method is called by the __getitem__() method of the dict class when the requested key is not found; whatever it returns or raises is then returned or raised by __getitem__().", "Note that __missing__() is not called for any operations besides __getitem__(). This means that get() will, like normal dictionaries, return None as a default rather than using default_factory.", "defaultdict objects support the following instance variable:", "This attribute is used by the __missing__() method; it is initialized from the first argument to the constructor, if present, or to None, if absent.", "Changed in version 3.9: Added merge (|) and update (|=) operators, specified in PEP 584."]}, {"name": "collections.defaultdict.default_factory", "path": "library/collections#collections.defaultdict.default_factory", "type": "Data Types", "text": ["This attribute is used by the __missing__() method; it is initialized from the first argument to the constructor, if present, or to None, if absent."]}, {"name": "collections.defaultdict.__missing__()", "path": "library/collections#collections.defaultdict.__missing__", "type": "Data Types", "text": ["If the default_factory attribute is None, this raises a KeyError exception with the key as argument.", "If default_factory is not None, it is called without arguments to provide a default value for the given key, this value is inserted in the dictionary for the key, and returned.", "If calling default_factory raises an exception this exception is propagated unchanged.", "This method is called by the __getitem__() method of the dict class when the requested key is not found; whatever it returns or raises is then returned or raised by __getitem__().", "Note that __missing__() is not called for any operations besides __getitem__(). This means that get() will, like normal dictionaries, return None as a default rather than using default_factory."]}, {"name": "collections.deque", "path": "library/collections#collections.deque", "type": "Data Types", "text": ["Returns a new deque object initialized left-to-right (using append()) with data from iterable. If iterable is not specified, the new deque is empty.", "Deques are a generalization of stacks and queues (the name is pronounced \u201cdeck\u201d and is short for \u201cdouble-ended queue\u201d). Deques support thread-safe, memory efficient appends and pops from either side of the deque with approximately the same O(1) performance in either direction.", "Though list objects support similar operations, they are optimized for fast fixed-length operations and incur O(n) memory movement costs for pop(0) and insert(0, v) operations which change both the size and position of the underlying data representation.", "If maxlen is not specified or is None, deques may grow to an arbitrary length. Otherwise, the deque is bounded to the specified maximum length. Once a bounded length deque is full, when new items are added, a corresponding number of items are discarded from the opposite end. Bounded length deques provide functionality similar to the tail filter in Unix. They are also useful for tracking transactions and other pools of data where only the most recent activity is of interest.", "Deque objects support the following methods:", "Add x to the right side of the deque.", "Add x to the left side of the deque.", "Remove all elements from the deque leaving it with length 0.", "Create a shallow copy of the deque.", "New in version 3.5.", "Count the number of deque elements equal to x.", "New in version 3.2.", "Extend the right side of the deque by appending elements from the iterable argument.", "Extend the left side of the deque by appending elements from iterable. Note, the series of left appends results in reversing the order of elements in the iterable argument.", "Return the position of x in the deque (at or after index start and before index stop). Returns the first match or raises ValueError if not found.", "New in version 3.5.", "Insert x into the deque at position i.", "If the insertion would cause a bounded deque to grow beyond maxlen, an IndexError is raised.", "New in version 3.5.", "Remove and return an element from the right side of the deque. If no elements are present, raises an IndexError.", "Remove and return an element from the left side of the deque. If no elements are present, raises an IndexError.", "Remove the first occurrence of value. If not found, raises a ValueError.", "Reverse the elements of the deque in-place and then return None.", "New in version 3.2.", "Rotate the deque n steps to the right. If n is negative, rotate to the left.", "When the deque is not empty, rotating one step to the right is equivalent to d.appendleft(d.pop()), and rotating one step to the left is equivalent to d.append(d.popleft()).", "Deque objects also provide one read-only attribute:", "Maximum size of a deque or None if unbounded.", "New in version 3.1."]}, {"name": "collections.deque.append()", "path": "library/collections#collections.deque.append", "type": "Data Types", "text": ["Add x to the right side of the deque."]}, {"name": "collections.deque.appendleft()", "path": "library/collections#collections.deque.appendleft", "type": "Data Types", "text": ["Add x to the left side of the deque."]}, {"name": "collections.deque.clear()", "path": "library/collections#collections.deque.clear", "type": "Data Types", "text": ["Remove all elements from the deque leaving it with length 0."]}, {"name": "collections.deque.copy()", "path": "library/collections#collections.deque.copy", "type": "Data Types", "text": ["Create a shallow copy of the deque.", "New in version 3.5."]}, {"name": "collections.deque.count()", "path": "library/collections#collections.deque.count", "type": "Data Types", "text": ["Count the number of deque elements equal to x.", "New in version 3.2."]}, {"name": "collections.deque.extend()", "path": "library/collections#collections.deque.extend", "type": "Data Types", "text": ["Extend the right side of the deque by appending elements from the iterable argument."]}, {"name": "collections.deque.extendleft()", "path": "library/collections#collections.deque.extendleft", "type": "Data Types", "text": ["Extend the left side of the deque by appending elements from iterable. Note, the series of left appends results in reversing the order of elements in the iterable argument."]}, {"name": "collections.deque.index()", "path": "library/collections#collections.deque.index", "type": "Data Types", "text": ["Return the position of x in the deque (at or after index start and before index stop). Returns the first match or raises ValueError if not found.", "New in version 3.5."]}, {"name": "collections.deque.insert()", "path": "library/collections#collections.deque.insert", "type": "Data Types", "text": ["Insert x into the deque at position i.", "If the insertion would cause a bounded deque to grow beyond maxlen, an IndexError is raised.", "New in version 3.5."]}, {"name": "collections.deque.maxlen", "path": "library/collections#collections.deque.maxlen", "type": "Data Types", "text": ["Maximum size of a deque or None if unbounded.", "New in version 3.1."]}, {"name": "collections.deque.pop()", "path": "library/collections#collections.deque.pop", "type": "Data Types", "text": ["Remove and return an element from the right side of the deque. If no elements are present, raises an IndexError."]}, {"name": "collections.deque.popleft()", "path": "library/collections#collections.deque.popleft", "type": "Data Types", "text": ["Remove and return an element from the left side of the deque. If no elements are present, raises an IndexError."]}, {"name": "collections.deque.remove()", "path": "library/collections#collections.deque.remove", "type": "Data Types", "text": ["Remove the first occurrence of value. If not found, raises a ValueError."]}, {"name": "collections.deque.reverse()", "path": "library/collections#collections.deque.reverse", "type": "Data Types", "text": ["Reverse the elements of the deque in-place and then return None.", "New in version 3.2."]}, {"name": "collections.deque.rotate()", "path": "library/collections#collections.deque.rotate", "type": "Data Types", "text": ["Rotate the deque n steps to the right. If n is negative, rotate to the left.", "When the deque is not empty, rotating one step to the right is equivalent to d.appendleft(d.pop()), and rotating one step to the left is equivalent to d.append(d.popleft())."]}, {"name": "collections.namedtuple()", "path": "library/collections#collections.namedtuple", "type": "Data Types", "text": ["Returns a new tuple subclass named typename. The new subclass is used to create tuple-like objects that have fields accessible by attribute lookup as well as being indexable and iterable. Instances of the subclass also have a helpful docstring (with typename and field_names) and a helpful __repr__() method which lists the tuple contents in a name=value format.", "The field_names are a sequence of strings such as ['x', 'y']. Alternatively, field_names can be a single string with each fieldname separated by whitespace and/or commas, for example 'x y' or 'x, y'.", "Any valid Python identifier may be used for a fieldname except for names starting with an underscore. Valid identifiers consist of letters, digits, and underscores but do not start with a digit or underscore and cannot be a keyword such as class, for, return, global, pass, or raise.", "If rename is true, invalid fieldnames are automatically replaced with positional names. For example, ['abc', 'def', 'ghi', 'abc'] is converted to ['abc', '_1', 'ghi', '_3'], eliminating the keyword def and the duplicate fieldname abc.", "defaults can be None or an iterable of default values. Since fields with a default value must come after any fields without a default, the defaults are applied to the rightmost parameters. For example, if the fieldnames are ['x', 'y', 'z'] and the defaults are (1, 2), then x will be a required argument, y will default to 1, and z will default to 2.", "If module is defined, the __module__ attribute of the named tuple is set to that value.", "Named tuple instances do not have per-instance dictionaries, so they are lightweight and require no more memory than regular tuples.", "To support pickling, the named tuple class should be assigned to a variable that matches typename.", "Changed in version 3.1: Added support for rename.", "Changed in version 3.6: The verbose and rename parameters became keyword-only arguments.", "Changed in version 3.6: Added the module parameter.", "Changed in version 3.7: Removed the verbose parameter and the _source attribute.", "Changed in version 3.7: Added the defaults parameter and the _field_defaults attribute."]}, {"name": "collections.OrderedDict", "path": "library/collections#collections.OrderedDict", "type": "Data Types", "text": ["Return an instance of a dict subclass that has methods specialized for rearranging dictionary order.", "New in version 3.1.", "The popitem() method for ordered dictionaries returns and removes a (key, value) pair. The pairs are returned in LIFO order if last is true or FIFO order if false.", "Move an existing key to either end of an ordered dictionary. The item is moved to the right end if last is true (the default) or to the beginning if last is false. Raises KeyError if the key does not exist:", "New in version 3.2."]}, {"name": "collections.OrderedDict.move_to_end()", "path": "library/collections#collections.OrderedDict.move_to_end", "type": "Data Types", "text": ["Move an existing key to either end of an ordered dictionary. The item is moved to the right end if last is true (the default) or to the beginning if last is false. Raises KeyError if the key does not exist:", "New in version 3.2."]}, {"name": "collections.OrderedDict.popitem()", "path": "library/collections#collections.OrderedDict.popitem", "type": "Data Types", "text": ["The popitem() method for ordered dictionaries returns and removes a (key, value) pair. The pairs are returned in LIFO order if last is true or FIFO order if false."]}, {"name": "collections.somenamedtuple._asdict()", "path": "library/collections#collections.somenamedtuple._asdict", "type": "Data Types", "text": ["Return a new dict which maps field names to their corresponding values:", "Changed in version 3.1: Returns an OrderedDict instead of a regular dict.", "Changed in version 3.8: Returns a regular dict instead of an OrderedDict. As of Python 3.7, regular dicts are guaranteed to be ordered. If the extra features of OrderedDict are required, the suggested remediation is to cast the result to the desired type: OrderedDict(nt._asdict())."]}, {"name": "collections.somenamedtuple._fields", "path": "library/collections#collections.somenamedtuple._fields", "type": "Data Types", "text": ["Tuple of strings listing the field names. Useful for introspection and for creating new named tuple types from existing named tuples."]}, {"name": "collections.somenamedtuple._field_defaults", "path": "library/collections#collections.somenamedtuple._field_defaults", "type": "Data Types", "text": ["Dictionary mapping field names to default values."]}, {"name": "collections.somenamedtuple._make()", "path": "library/collections#collections.somenamedtuple._make", "type": "Data Types", "text": ["Class method that makes a new instance from an existing sequence or iterable."]}, {"name": "collections.somenamedtuple._replace()", "path": "library/collections#collections.somenamedtuple._replace", "type": "Data Types", "text": ["Return a new instance of the named tuple replacing specified fields with new values:"]}, {"name": "collections.UserDict", "path": "library/collections#collections.UserDict", "type": "Data Types", "text": ["Class that simulates a dictionary. The instance\u2019s contents are kept in a regular dictionary, which is accessible via the data attribute of UserDict instances. If initialdata is provided, data is initialized with its contents; note that a reference to initialdata will not be kept, allowing it be used for other purposes.", "In addition to supporting the methods and operations of mappings, UserDict instances provide the following attribute:", "A real dictionary used to store the contents of the UserDict class."]}, {"name": "collections.UserDict.data", "path": "library/collections#collections.UserDict.data", "type": "Data Types", "text": ["A real dictionary used to store the contents of the UserDict class."]}, {"name": "collections.UserList", "path": "library/collections#collections.UserList", "type": "Data Types", "text": ["Class that simulates a list. The instance\u2019s contents are kept in a regular list, which is accessible via the data attribute of UserList instances. The instance\u2019s contents are initially set to a copy of list, defaulting to the empty list []. list can be any iterable, for example a real Python list or a UserList object.", "In addition to supporting the methods and operations of mutable sequences, UserList instances provide the following attribute:", "A real list object used to store the contents of the UserList class."]}, {"name": "collections.UserList.data", "path": "library/collections#collections.UserList.data", "type": "Data Types", "text": ["A real list object used to store the contents of the UserList class."]}, {"name": "collections.UserString", "path": "library/collections#collections.UserString", "type": "Data Types", "text": ["Class that simulates a string object. The instance\u2019s content is kept in a regular string object, which is accessible via the data attribute of UserString instances. The instance\u2019s contents are initially set to a copy of seq. The seq argument can be any object which can be converted into a string using the built-in str() function.", "In addition to supporting the methods and operations of strings, UserString instances provide the following attribute:", "A real str object used to store the contents of the UserString class.", "Changed in version 3.5: New methods __getnewargs__, __rmod__, casefold, format_map, isprintable, and maketrans."]}, {"name": "collections.UserString.data", "path": "library/collections#collections.UserString.data", "type": "Data Types", "text": ["A real str object used to store the contents of the UserString class."]}, {"name": "colorsys", "path": "library/colorsys", "type": "Multimedia", "text": ["Source code: Lib/colorsys.py", "The colorsys module defines bidirectional conversions of color values between colors expressed in the RGB (Red Green Blue) color space used in computer monitors and three other coordinate systems: YIQ, HLS (Hue Lightness Saturation) and HSV (Hue Saturation Value). Coordinates in all of these color spaces are floating point values. In the YIQ space, the Y coordinate is between 0 and 1, but the I and Q coordinates can be positive or negative. In all other spaces, the coordinates are all between 0 and 1.", "See also", "More information about color spaces can be found at https://poynton.ca/ColorFAQ.html and https://www.cambridgeincolour.com/tutorials/color-spaces.htm.", "The colorsys module defines the following functions:", "Convert the color from RGB coordinates to YIQ coordinates.", "Convert the color from YIQ coordinates to RGB coordinates.", "Convert the color from RGB coordinates to HLS coordinates.", "Convert the color from HLS coordinates to RGB coordinates.", "Convert the color from RGB coordinates to HSV coordinates.", "Convert the color from HSV coordinates to RGB coordinates.", "Example:"]}, {"name": "colorsys.hls_to_rgb()", "path": "library/colorsys#colorsys.hls_to_rgb", "type": "Multimedia", "text": ["Convert the color from HLS coordinates to RGB coordinates."]}, {"name": "colorsys.hsv_to_rgb()", "path": "library/colorsys#colorsys.hsv_to_rgb", "type": "Multimedia", "text": ["Convert the color from HSV coordinates to RGB coordinates."]}, {"name": "colorsys.rgb_to_hls()", "path": "library/colorsys#colorsys.rgb_to_hls", "type": "Multimedia", "text": ["Convert the color from RGB coordinates to HLS coordinates."]}, {"name": "colorsys.rgb_to_hsv()", "path": "library/colorsys#colorsys.rgb_to_hsv", "type": "Multimedia", "text": ["Convert the color from RGB coordinates to HSV coordinates."]}, {"name": "colorsys.rgb_to_yiq()", "path": "library/colorsys#colorsys.rgb_to_yiq", "type": "Multimedia", "text": ["Convert the color from RGB coordinates to YIQ coordinates."]}, {"name": "colorsys.yiq_to_rgb()", "path": "library/colorsys#colorsys.yiq_to_rgb", "type": "Multimedia", "text": ["Convert the color from YIQ coordinates to RGB coordinates."]}, {"name": "compile()", "path": "library/functions#compile", "type": "Built-in Functions", "text": ["Compile the source into a code or AST object. Code objects can be executed by exec() or eval(). source can either be a normal string, a byte string, or an AST object. Refer to the ast module documentation for information on how to work with AST objects.", "The filename argument should give the file from which the code was read; pass some recognizable value if it wasn\u2019t read from a file ('<string>' is commonly used).", "The mode argument specifies what kind of code must be compiled; it can be 'exec' if source consists of a sequence of statements, 'eval' if it consists of a single expression, or 'single' if it consists of a single interactive statement (in the latter case, expression statements that evaluate to something other than None will be printed).", "The optional arguments flags and dont_inherit control which compiler options should be activated and which future features should be allowed. If neither is present (or both are zero) the code is compiled with the same flags that affect the code that is calling compile(). If the flags argument is given and dont_inherit is not (or is zero) then the compiler options and the future statements specified by the flags argument are used in addition to those that would be used anyway. If dont_inherit is a non-zero integer then the flags argument is it \u2013 the flags (future features and compiler options) in the surrounding code are ignored.", "Compiler options and future statements are specified by bits which can be bitwise ORed together to specify multiple options. The bitfield required to specify a given future feature can be found as the compiler_flag attribute on the _Feature instance in the __future__ module. Compiler flags can be found in ast module, with PyCF_ prefix.", "The argument optimize specifies the optimization level of the compiler; the default value of -1 selects the optimization level of the interpreter as given by -O options. Explicit levels are 0 (no optimization; __debug__ is true), 1 (asserts are removed, __debug__ is false) or 2 (docstrings are removed too).", "This function raises SyntaxError if the compiled source is invalid, and ValueError if the source contains null bytes.", "If you want to parse Python code into its AST representation, see ast.parse().", "Raises an auditing event compile with arguments source and filename. This event may also be raised by implicit compilation.", "Note", "When compiling a string with multi-line code in 'single' or 'eval' mode, input must be terminated by at least one newline character. This is to facilitate detection of incomplete and complete statements in the code module.", "Warning", "It is possible to crash the Python interpreter with a sufficiently large/complex string when compiling to an AST object due to stack depth limitations in Python\u2019s AST compiler.", "Changed in version 3.2: Allowed use of Windows and Mac newlines. Also input in 'exec' mode does not have to end in a newline anymore. Added the optimize parameter.", "Changed in version 3.5: Previously, TypeError was raised when null bytes were encountered in source.", "New in version 3.8: ast.PyCF_ALLOW_TOP_LEVEL_AWAIT can now be passed in flags to enable support for top-level await, async for, and async with."]}, {"name": "compileall", "path": "library/compileall", "type": "Language", "text": ["Source code: Lib/compileall.py", "This module provides some utility functions to support installing Python libraries. These functions compile Python source files in a directory tree. This module can be used to create the cached byte-code files at library installation time, which makes them available for use even by users who don\u2019t have write permission to the library directories.", "This module can work as a script (using python -m compileall) to compile Python sources.", "Positional arguments are files to compile or directories that contain source files, traversed recursively. If no argument is given, behave as if the command line was -l <directories from sys.path>.", "Do not recurse into subdirectories, only compile source code files directly contained in the named or implied directories.", "Force rebuild even if timestamps are up-to-date.", "Do not print the list of files compiled. If passed once, error messages will still be printed. If passed twice (-qq), all output is suppressed.", "Directory prepended to the path to each file being compiled. This will appear in compilation time tracebacks, and is also compiled in to the byte-code file, where it will be used in tracebacks and other messages in cases where the source file does not exist at the time the byte-code file is executed.", "Remove (-s) or append (-p) the given prefix of paths recorded in the .pyc files. Cannot be combined with -d.", "regex is used to search the full path to each file considered for compilation, and if the regex produces a match, the file is skipped.", "Read the file list and add each line that it contains to the list of files and directories to compile. If list is -, read lines from stdin.", "Write the byte-code files to their legacy locations and names, which may overwrite byte-code files created by another version of Python. The default is to write files to their PEP 3147 locations and names, which allows byte-code files from multiple versions of Python to coexist.", "Control the maximum recursion level for subdirectories. If this is given, then -l option will not be taken into account. python -m compileall <directory> -r 0 is equivalent to python -m compileall <directory> -l.", "Use N workers to compile the files within the given directory. If 0 is used, then the result of os.cpu_count() will be used.", "Control how the generated byte-code files are invalidated at runtime. The timestamp value, means that .pyc files with the source timestamp and size embedded will be generated. The checked-hash and unchecked-hash values cause hash-based pycs to be generated. Hash-based pycs embed a hash of the source file contents rather than a timestamp. See Cached bytecode invalidation for more information on how Python validates bytecode cache files at runtime. The default is timestamp if the SOURCE_DATE_EPOCH environment variable is not set, and checked-hash if the SOURCE_DATE_EPOCH environment variable is set.", "Compile with the given optimization level. May be used multiple times to compile for multiple levels at a time (for example, compileall -o 1 -o 2).", "Ignore symlinks pointing outside the given directory.", "If two .pyc files with different optimization level have the same content, use hard links to consolidate duplicate files.", "Changed in version 3.2: Added the -i, -b and -h options.", "Changed in version 3.5: Added the -j, -r, and -qq options. -q option was changed to a multilevel value. -b will always produce a byte-code file ending in .pyc, never .pyo.", "Changed in version 3.7: Added the --invalidation-mode option.", "Changed in version 3.9: Added the -s, -p, -e and --hardlink-dupes options. Raised the default recursion limit from 10 to sys.getrecursionlimit(). Added the possibility to specify the -o option multiple times.", "There is no command-line option to control the optimization level used by the compile() function, because the Python interpreter itself already provides the option: python -O -m compileall.", "Similarly, the compile() function respects the sys.pycache_prefix setting. The generated bytecode cache will only be useful if compile() is run with the same sys.pycache_prefix (if any) that will be used at runtime.", "Recursively descend the directory tree named by dir, compiling all .py files along the way. Return a true value if all the files compiled successfully, and a false value otherwise.", "The maxlevels parameter is used to limit the depth of the recursion; it defaults to sys.getrecursionlimit().", "If ddir is given, it is prepended to the path to each file being compiled for use in compilation time tracebacks, and is also compiled in to the byte-code file, where it will be used in tracebacks and other messages in cases where the source file does not exist at the time the byte-code file is executed.", "If force is true, modules are re-compiled even if the timestamps are up to date.", "If rx is given, its search method is called on the complete path to each file considered for compilation, and if it returns a true value, the file is skipped.", "If quiet is False or 0 (the default), the filenames and other information are printed to standard out. Set to 1, only errors are printed. Set to 2, all output is suppressed.", "If legacy is true, byte-code files are written to their legacy locations and names, which may overwrite byte-code files created by another version of Python. The default is to write files to their PEP 3147 locations and names, which allows byte-code files from multiple versions of Python to coexist.", "optimize specifies the optimization level for the compiler. It is passed to the built-in compile() function. Accepts also a sequence of optimization levels which lead to multiple compilations of one .py file in one call.", "The argument workers specifies how many workers are used to compile files in parallel. The default is to not use multiple workers. If the platform can\u2019t use multiple workers and workers argument is given, then sequential compilation will be used as a fallback. If workers is 0, the number of cores in the system is used. If workers is lower than 0, a ValueError will be raised.", "invalidation_mode should be a member of the py_compile.PycInvalidationMode enum and controls how the generated pycs are invalidated at runtime.", "The stripdir, prependdir and limit_sl_dest arguments correspond to the -s, -p and -e options described above. They may be specified as str, bytes or os.PathLike.", "If hardlink_dupes is true and two .pyc files with different optimization level have the same content, use hard links to consolidate duplicate files.", "Changed in version 3.2: Added the legacy and optimize parameter.", "Changed in version 3.5: Added the workers parameter.", "Changed in version 3.5: quiet parameter was changed to a multilevel value.", "Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files no matter what the value of optimize is.", "Changed in version 3.6: Accepts a path-like object.", "Changed in version 3.7: The invalidation_mode parameter was added.", "Changed in version 3.7.2: The invalidation_mode parameter\u2019s default value is updated to None.", "Changed in version 3.8: Setting workers to 0 now chooses the optimal number of cores.", "Changed in version 3.9: Added stripdir, prependdir, limit_sl_dest and hardlink_dupes arguments. Default value of maxlevels was changed from 10 to sys.getrecursionlimit()", "Compile the file with path fullname. Return a true value if the file compiled successfully, and a false value otherwise.", "If ddir is given, it is prepended to the path to the file being compiled for use in compilation time tracebacks, and is also compiled in to the byte-code file, where it will be used in tracebacks and other messages in cases where the source file does not exist at the time the byte-code file is executed.", "If rx is given, its search method is passed the full path name to the file being compiled, and if it returns a true value, the file is not compiled and True is returned.", "If quiet is False or 0 (the default), the filenames and other information are printed to standard out. Set to 1, only errors are printed. Set to 2, all output is suppressed.", "If legacy is true, byte-code files are written to their legacy locations and names, which may overwrite byte-code files created by another version of Python. The default is to write files to their PEP 3147 locations and names, which allows byte-code files from multiple versions of Python to coexist.", "optimize specifies the optimization level for the compiler. It is passed to the built-in compile() function. Accepts also a sequence of optimization levels which lead to multiple compilations of one .py file in one call.", "invalidation_mode should be a member of the py_compile.PycInvalidationMode enum and controls how the generated pycs are invalidated at runtime.", "The stripdir, prependdir and limit_sl_dest arguments correspond to the -s, -p and -e options described above. They may be specified as str, bytes or os.PathLike.", "If hardlink_dupes is true and two .pyc files with different optimization level have the same content, use hard links to consolidate duplicate files.", "New in version 3.2.", "Changed in version 3.5: quiet parameter was changed to a multilevel value.", "Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files no matter what the value of optimize is.", "Changed in version 3.7: The invalidation_mode parameter was added.", "Changed in version 3.7.2: The invalidation_mode parameter\u2019s default value is updated to None.", "Changed in version 3.9: Added stripdir, prependdir, limit_sl_dest and hardlink_dupes arguments.", "Byte-compile all the .py files found along sys.path. Return a true value if all the files compiled successfully, and a false value otherwise.", "If skip_curdir is true (the default), the current directory is not included in the search. All other parameters are passed to the compile_dir() function. Note that unlike the other compile functions, maxlevels defaults to 0.", "Changed in version 3.2: Added the legacy and optimize parameter.", "Changed in version 3.5: quiet parameter was changed to a multilevel value.", "Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files no matter what the value of optimize is.", "Changed in version 3.7: The invalidation_mode parameter was added.", "Changed in version 3.7.2: The invalidation_mode parameter\u2019s default value is updated to None.", "To force a recompile of all the .py files in the Lib/ subdirectory and all its subdirectories:", "See also", "Byte-compile a single source file."]}, {"name": "compileall.compile_dir()", "path": "library/compileall#compileall.compile_dir", "type": "Language", "text": ["Recursively descend the directory tree named by dir, compiling all .py files along the way. Return a true value if all the files compiled successfully, and a false value otherwise.", "The maxlevels parameter is used to limit the depth of the recursion; it defaults to sys.getrecursionlimit().", "If ddir is given, it is prepended to the path to each file being compiled for use in compilation time tracebacks, and is also compiled in to the byte-code file, where it will be used in tracebacks and other messages in cases where the source file does not exist at the time the byte-code file is executed.", "If force is true, modules are re-compiled even if the timestamps are up to date.", "If rx is given, its search method is called on the complete path to each file considered for compilation, and if it returns a true value, the file is skipped.", "If quiet is False or 0 (the default), the filenames and other information are printed to standard out. Set to 1, only errors are printed. Set to 2, all output is suppressed.", "If legacy is true, byte-code files are written to their legacy locations and names, which may overwrite byte-code files created by another version of Python. The default is to write files to their PEP 3147 locations and names, which allows byte-code files from multiple versions of Python to coexist.", "optimize specifies the optimization level for the compiler. It is passed to the built-in compile() function. Accepts also a sequence of optimization levels which lead to multiple compilations of one .py file in one call.", "The argument workers specifies how many workers are used to compile files in parallel. The default is to not use multiple workers. If the platform can\u2019t use multiple workers and workers argument is given, then sequential compilation will be used as a fallback. If workers is 0, the number of cores in the system is used. If workers is lower than 0, a ValueError will be raised.", "invalidation_mode should be a member of the py_compile.PycInvalidationMode enum and controls how the generated pycs are invalidated at runtime.", "The stripdir, prependdir and limit_sl_dest arguments correspond to the -s, -p and -e options described above. They may be specified as str, bytes or os.PathLike.", "If hardlink_dupes is true and two .pyc files with different optimization level have the same content, use hard links to consolidate duplicate files.", "Changed in version 3.2: Added the legacy and optimize parameter.", "Changed in version 3.5: Added the workers parameter.", "Changed in version 3.5: quiet parameter was changed to a multilevel value.", "Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files no matter what the value of optimize is.", "Changed in version 3.6: Accepts a path-like object.", "Changed in version 3.7: The invalidation_mode parameter was added.", "Changed in version 3.7.2: The invalidation_mode parameter\u2019s default value is updated to None.", "Changed in version 3.8: Setting workers to 0 now chooses the optimal number of cores.", "Changed in version 3.9: Added stripdir, prependdir, limit_sl_dest and hardlink_dupes arguments. Default value of maxlevels was changed from 10 to sys.getrecursionlimit()"]}, {"name": "compileall.compile_file()", "path": "library/compileall#compileall.compile_file", "type": "Language", "text": ["Compile the file with path fullname. Return a true value if the file compiled successfully, and a false value otherwise.", "If ddir is given, it is prepended to the path to the file being compiled for use in compilation time tracebacks, and is also compiled in to the byte-code file, where it will be used in tracebacks and other messages in cases where the source file does not exist at the time the byte-code file is executed.", "If rx is given, its search method is passed the full path name to the file being compiled, and if it returns a true value, the file is not compiled and True is returned.", "If quiet is False or 0 (the default), the filenames and other information are printed to standard out. Set to 1, only errors are printed. Set to 2, all output is suppressed.", "If legacy is true, byte-code files are written to their legacy locations and names, which may overwrite byte-code files created by another version of Python. The default is to write files to their PEP 3147 locations and names, which allows byte-code files from multiple versions of Python to coexist.", "optimize specifies the optimization level for the compiler. It is passed to the built-in compile() function. Accepts also a sequence of optimization levels which lead to multiple compilations of one .py file in one call.", "invalidation_mode should be a member of the py_compile.PycInvalidationMode enum and controls how the generated pycs are invalidated at runtime.", "The stripdir, prependdir and limit_sl_dest arguments correspond to the -s, -p and -e options described above. They may be specified as str, bytes or os.PathLike.", "If hardlink_dupes is true and two .pyc files with different optimization level have the same content, use hard links to consolidate duplicate files.", "New in version 3.2.", "Changed in version 3.5: quiet parameter was changed to a multilevel value.", "Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files no matter what the value of optimize is.", "Changed in version 3.7: The invalidation_mode parameter was added.", "Changed in version 3.7.2: The invalidation_mode parameter\u2019s default value is updated to None.", "Changed in version 3.9: Added stripdir, prependdir, limit_sl_dest and hardlink_dupes arguments."]}, {"name": "compileall.compile_path()", "path": "library/compileall#compileall.compile_path", "type": "Language", "text": ["Byte-compile all the .py files found along sys.path. Return a true value if all the files compiled successfully, and a false value otherwise.", "If skip_curdir is true (the default), the current directory is not included in the search. All other parameters are passed to the compile_dir() function. Note that unlike the other compile functions, maxlevels defaults to 0.", "Changed in version 3.2: Added the legacy and optimize parameter.", "Changed in version 3.5: quiet parameter was changed to a multilevel value.", "Changed in version 3.5: The legacy parameter only writes out .pyc files, not .pyo files no matter what the value of optimize is.", "Changed in version 3.7: The invalidation_mode parameter was added.", "Changed in version 3.7.2: The invalidation_mode parameter\u2019s default value is updated to None."]}, {"name": "complex", "path": "library/functions#complex", "type": "Built-in Functions", "text": ["Return a complex number with the value real + imag*1j or convert a string or number to a complex number. If the first parameter is a string, it will be interpreted as a complex number and the function must be called without a second parameter. The second parameter can never be a string. Each argument may be any numeric type (including complex). If imag is omitted, it defaults to zero and the constructor serves as a numeric conversion like int and float. If both arguments are omitted, returns 0j.", "For a general Python object x, complex(x) delegates to x.__complex__(). If __complex__() is not defined then it falls back to __float__(). If __float__() is not defined then it falls back to __index__().", "Note", "When converting from a string, the string must not contain whitespace around the central + or - operator. For example, complex('1+2j') is fine, but complex('1 + 2j') raises ValueError.", "The complex type is described in Numeric Types \u2014 int, float, complex.", "Changed in version 3.6: Grouping digits with underscores as in code literals is allowed.", "Changed in version 3.8: Falls back to __index__() if __complex__() and __float__() are not defined."]}, {"name": "concurrent.futures", "path": "library/concurrent.futures", "type": "Concurrent Execution", "text": ["New in version 3.2.", "Source code: Lib/concurrent/futures/thread.py and Lib/concurrent/futures/process.py", "The concurrent.futures module provides a high-level interface for asynchronously executing callables.", "The asynchronous execution can be performed with threads, using ThreadPoolExecutor, or separate processes, using ProcessPoolExecutor. Both implement the same interface, which is defined by the abstract Executor class.", "An abstract class that provides methods to execute calls asynchronously. It should not be used directly, but through its concrete subclasses.", "Schedules the callable, fn, to be executed as fn(*args **kwargs) and returns a Future object representing the execution of the callable.", "Similar to map(func, *iterables) except:", "The returned iterator raises a concurrent.futures.TimeoutError if __next__() is called and the result isn\u2019t available after timeout seconds from the original call to Executor.map(). timeout can be an int or a float. If timeout is not specified or None, there is no limit to the wait time.", "If a func call raises an exception, then that exception will be raised when its value is retrieved from the iterator.", "When using ProcessPoolExecutor, this method chops iterables into a number of chunks which it submits to the pool as separate tasks. The (approximate) size of these chunks can be specified by setting chunksize to a positive integer. For very long iterables, using a large value for chunksize can significantly improve performance compared to the default size of 1. With ThreadPoolExecutor, chunksize has no effect.", "Changed in version 3.5: Added the chunksize argument.", "Signal the executor that it should free any resources that it is using when the currently pending futures are done executing. Calls to Executor.submit() and Executor.map() made after shutdown will raise RuntimeError.", "If wait is True then this method will not return until all the pending futures are done executing and the resources associated with the executor have been freed. If wait is False then this method will return immediately and the resources associated with the executor will be freed when all pending futures are done executing. Regardless of the value of wait, the entire Python program will not exit until all pending futures are done executing.", "If cancel_futures is True, this method will cancel all pending futures that the executor has not started running. Any futures that are completed or running won\u2019t be cancelled, regardless of the value of cancel_futures.", "If both cancel_futures and wait are True, all futures that the executor has started running will be completed prior to this method returning. The remaining futures are cancelled.", "You can avoid having to call this method explicitly if you use the with statement, which will shutdown the Executor (waiting as if Executor.shutdown() were called with wait set to True):", "Changed in version 3.9: Added cancel_futures.", "ThreadPoolExecutor is an Executor subclass that uses a pool of threads to execute calls asynchronously.", "Deadlocks can occur when the callable associated with a Future waits on the results of another Future. For example:", "And:", "An Executor subclass that uses a pool of at most max_workers threads to execute calls asynchronously.", "initializer is an optional callable that is called at the start of each worker thread; initargs is a tuple of arguments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a BrokenThreadPool, as well as any attempt to submit more jobs to the pool.", "Changed in version 3.5: If max_workers is None or not given, it will default to the number of processors on the machine, multiplied by 5, assuming that ThreadPoolExecutor is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for ProcessPoolExecutor.", "New in version 3.6: The thread_name_prefix argument was added to allow users to control the threading.Thread names for worker threads created by the pool for easier debugging.", "Changed in version 3.7: Added the initializer and initargs arguments.", "Changed in version 3.8: Default value of max_workers is changed to min(32, os.cpu_count() + 4). This default value preserves at least 5 workers for I/O bound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which release the GIL. And it avoids using very large resources implicitly on many-core machines.", "ThreadPoolExecutor now reuses idle worker threads before starting max_workers worker threads too.", "The ProcessPoolExecutor class is an Executor subclass that uses a pool of processes to execute calls asynchronously. ProcessPoolExecutor uses the multiprocessing module, which allows it to side-step the Global Interpreter Lock but also means that only picklable objects can be executed and returned.", "The __main__ module must be importable by worker subprocesses. This means that ProcessPoolExecutor will not work in the interactive interpreter.", "Calling Executor or Future methods from a callable submitted to a ProcessPoolExecutor will result in deadlock.", "An Executor subclass that executes calls asynchronously using a pool of at most max_workers processes. If max_workers is None or not given, it will default to the number of processors on the machine. If max_workers is less than or equal to 0, then a ValueError will be raised. On Windows, max_workers must be less than or equal to 61. If it is not then ValueError will be raised. If max_workers is None, then the default chosen will be at most 61, even if more processors are available. mp_context can be a multiprocessing context or None. It will be used to launch the workers. If mp_context is None or not given, the default multiprocessing context is used.", "initializer is an optional callable that is called at the start of each worker process; initargs is a tuple of arguments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a BrokenProcessPool, as well as any attempt to submit more jobs to the pool.", "Changed in version 3.3: When one of the worker processes terminates abruptly, a BrokenProcessPool error is now raised. Previously, behaviour was undefined but operations on the executor or its futures would often freeze or deadlock.", "Changed in version 3.7: The mp_context argument was added to allow users to control the start_method for worker processes created by the pool.", "Added the initializer and initargs arguments.", "The Future class encapsulates the asynchronous execution of a callable. Future instances are created by Executor.submit().", "Encapsulates the asynchronous execution of a callable. Future instances are created by Executor.submit() and should not be created directly except for testing.", "Attempt to cancel the call. If the call is currently being executed or finished running and cannot be cancelled then the method will return False, otherwise the call will be cancelled and the method will return True.", "Return True if the call was successfully cancelled.", "Return True if the call is currently being executed and cannot be cancelled.", "Return True if the call was successfully cancelled or finished running.", "Return the value returned by the call. If the call hasn\u2019t yet completed then this method will wait up to timeout seconds. If the call hasn\u2019t completed in timeout seconds, then a concurrent.futures.TimeoutError will be raised. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "If the future is cancelled before completing then CancelledError will be raised.", "If the call raised, this method will raise the same exception.", "Return the exception raised by the call. If the call hasn\u2019t yet completed then this method will wait up to timeout seconds. If the call hasn\u2019t completed in timeout seconds, then a concurrent.futures.TimeoutError will be raised. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "If the future is cancelled before completing then CancelledError will be raised.", "If the call completed without raising, None is returned.", "Attaches the callable fn to the future. fn will be called, with the future as its only argument, when the future is cancelled or finishes running.", "Added callables are called in the order that they were added and are always called in a thread belonging to the process that added them. If the callable raises an Exception subclass, it will be logged and ignored. If the callable raises a BaseException subclass, the behavior is undefined.", "If the future has already completed or been cancelled, fn will be called immediately.", "The following Future methods are meant for use in unit tests and Executor implementations.", "This method should only be called by Executor implementations before executing the work associated with the Future and by unit tests.", "If the method returns False then the Future was cancelled, i.e. Future.cancel() was called and returned True. Any threads waiting on the Future completing (i.e. through as_completed() or wait()) will be woken up.", "If the method returns True then the Future was not cancelled and has been put in the running state, i.e. calls to Future.running() will return True.", "This method can only be called once and cannot be called after Future.set_result() or Future.set_exception() have been called.", "Sets the result of the work associated with the Future to result.", "This method should only be used by Executor implementations and unit tests.", "Changed in version 3.8: This method raises concurrent.futures.InvalidStateError if the Future is already done.", "Sets the result of the work associated with the Future to the Exception exception.", "This method should only be used by Executor implementations and unit tests.", "Changed in version 3.8: This method raises concurrent.futures.InvalidStateError if the Future is already done.", "Wait for the Future instances (possibly created by different Executor instances) given by fs to complete. Returns a named 2-tuple of sets. The first set, named done, contains the futures that completed (finished or cancelled futures) before the wait completed. The second set, named not_done, contains the futures that did not complete (pending or running futures).", "timeout can be used to control the maximum number of seconds to wait before returning. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "return_when indicates when this function should return. It must be one of the following constants:", "Constant", "Description", "FIRST_COMPLETED", "The function will return when any future finishes or is cancelled.", "FIRST_EXCEPTION", "The function will return when any future finishes by raising an exception. If no future raises an exception then it is equivalent to ALL_COMPLETED.", "ALL_COMPLETED", "The function will return when all futures finish or are cancelled.", "Returns an iterator over the Future instances (possibly created by different Executor instances) given by fs that yields futures as they complete (finished or cancelled futures). Any futures given by fs that are duplicated will be returned once. Any futures that completed before as_completed() is called will be yielded first. The returned iterator raises a concurrent.futures.TimeoutError if __next__() is called and the result isn\u2019t available after timeout seconds from the original call to as_completed(). timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "See also", "The proposal which described this feature for inclusion in the Python standard library.", "Raised when a future is cancelled.", "Raised when a future operation exceeds the given timeout.", "Derived from RuntimeError, this exception class is raised when an executor is broken for some reason, and cannot be used to submit or execute new tasks.", "New in version 3.7.", "Raised when an operation is performed on a future that is not allowed in the current state.", "New in version 3.8.", "Derived from BrokenExecutor, this exception class is raised when one of the workers of a ThreadPoolExecutor has failed initializing.", "New in version 3.7.", "Derived from BrokenExecutor (formerly RuntimeError), this exception class is raised when one of the workers of a ProcessPoolExecutor has terminated in a non-clean fashion (for example, if it was killed from the outside).", "New in version 3.3."]}, {"name": "concurrent.futures.as_completed()", "path": "library/concurrent.futures#concurrent.futures.as_completed", "type": "Concurrent Execution", "text": ["Returns an iterator over the Future instances (possibly created by different Executor instances) given by fs that yields futures as they complete (finished or cancelled futures). Any futures given by fs that are duplicated will be returned once. Any futures that completed before as_completed() is called will be yielded first. The returned iterator raises a concurrent.futures.TimeoutError if __next__() is called and the result isn\u2019t available after timeout seconds from the original call to as_completed(). timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time."]}, {"name": "concurrent.futures.BrokenExecutor", "path": "library/concurrent.futures#concurrent.futures.BrokenExecutor", "type": "Concurrent Execution", "text": ["Derived from RuntimeError, this exception class is raised when an executor is broken for some reason, and cannot be used to submit or execute new tasks.", "New in version 3.7."]}, {"name": "concurrent.futures.CancelledError", "path": "library/concurrent.futures#concurrent.futures.CancelledError", "type": "Concurrent Execution", "text": ["Raised when a future is cancelled."]}, {"name": "concurrent.futures.Executor", "path": "library/concurrent.futures#concurrent.futures.Executor", "type": "Concurrent Execution", "text": ["An abstract class that provides methods to execute calls asynchronously. It should not be used directly, but through its concrete subclasses.", "Schedules the callable, fn, to be executed as fn(*args **kwargs) and returns a Future object representing the execution of the callable.", "Similar to map(func, *iterables) except:", "The returned iterator raises a concurrent.futures.TimeoutError if __next__() is called and the result isn\u2019t available after timeout seconds from the original call to Executor.map(). timeout can be an int or a float. If timeout is not specified or None, there is no limit to the wait time.", "If a func call raises an exception, then that exception will be raised when its value is retrieved from the iterator.", "When using ProcessPoolExecutor, this method chops iterables into a number of chunks which it submits to the pool as separate tasks. The (approximate) size of these chunks can be specified by setting chunksize to a positive integer. For very long iterables, using a large value for chunksize can significantly improve performance compared to the default size of 1. With ThreadPoolExecutor, chunksize has no effect.", "Changed in version 3.5: Added the chunksize argument.", "Signal the executor that it should free any resources that it is using when the currently pending futures are done executing. Calls to Executor.submit() and Executor.map() made after shutdown will raise RuntimeError.", "If wait is True then this method will not return until all the pending futures are done executing and the resources associated with the executor have been freed. If wait is False then this method will return immediately and the resources associated with the executor will be freed when all pending futures are done executing. Regardless of the value of wait, the entire Python program will not exit until all pending futures are done executing.", "If cancel_futures is True, this method will cancel all pending futures that the executor has not started running. Any futures that are completed or running won\u2019t be cancelled, regardless of the value of cancel_futures.", "If both cancel_futures and wait are True, all futures that the executor has started running will be completed prior to this method returning. The remaining futures are cancelled.", "You can avoid having to call this method explicitly if you use the with statement, which will shutdown the Executor (waiting as if Executor.shutdown() were called with wait set to True):", "Changed in version 3.9: Added cancel_futures."]}, {"name": "concurrent.futures.Executor.map()", "path": "library/concurrent.futures#concurrent.futures.Executor.map", "type": "Concurrent Execution", "text": ["Similar to map(func, *iterables) except:", "The returned iterator raises a concurrent.futures.TimeoutError if __next__() is called and the result isn\u2019t available after timeout seconds from the original call to Executor.map(). timeout can be an int or a float. If timeout is not specified or None, there is no limit to the wait time.", "If a func call raises an exception, then that exception will be raised when its value is retrieved from the iterator.", "When using ProcessPoolExecutor, this method chops iterables into a number of chunks which it submits to the pool as separate tasks. The (approximate) size of these chunks can be specified by setting chunksize to a positive integer. For very long iterables, using a large value for chunksize can significantly improve performance compared to the default size of 1. With ThreadPoolExecutor, chunksize has no effect.", "Changed in version 3.5: Added the chunksize argument."]}, {"name": "concurrent.futures.Executor.shutdown()", "path": "library/concurrent.futures#concurrent.futures.Executor.shutdown", "type": "Concurrent Execution", "text": ["Signal the executor that it should free any resources that it is using when the currently pending futures are done executing. Calls to Executor.submit() and Executor.map() made after shutdown will raise RuntimeError.", "If wait is True then this method will not return until all the pending futures are done executing and the resources associated with the executor have been freed. If wait is False then this method will return immediately and the resources associated with the executor will be freed when all pending futures are done executing. Regardless of the value of wait, the entire Python program will not exit until all pending futures are done executing.", "If cancel_futures is True, this method will cancel all pending futures that the executor has not started running. Any futures that are completed or running won\u2019t be cancelled, regardless of the value of cancel_futures.", "If both cancel_futures and wait are True, all futures that the executor has started running will be completed prior to this method returning. The remaining futures are cancelled.", "You can avoid having to call this method explicitly if you use the with statement, which will shutdown the Executor (waiting as if Executor.shutdown() were called with wait set to True):", "Changed in version 3.9: Added cancel_futures."]}, {"name": "concurrent.futures.Executor.submit()", "path": "library/concurrent.futures#concurrent.futures.Executor.submit", "type": "Concurrent Execution", "text": ["Schedules the callable, fn, to be executed as fn(*args **kwargs) and returns a Future object representing the execution of the callable."]}, {"name": "concurrent.futures.Future", "path": "library/concurrent.futures#concurrent.futures.Future", "type": "Concurrent Execution", "text": ["Encapsulates the asynchronous execution of a callable. Future instances are created by Executor.submit() and should not be created directly except for testing.", "Attempt to cancel the call. If the call is currently being executed or finished running and cannot be cancelled then the method will return False, otherwise the call will be cancelled and the method will return True.", "Return True if the call was successfully cancelled.", "Return True if the call is currently being executed and cannot be cancelled.", "Return True if the call was successfully cancelled or finished running.", "Return the value returned by the call. If the call hasn\u2019t yet completed then this method will wait up to timeout seconds. If the call hasn\u2019t completed in timeout seconds, then a concurrent.futures.TimeoutError will be raised. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "If the future is cancelled before completing then CancelledError will be raised.", "If the call raised, this method will raise the same exception.", "Return the exception raised by the call. If the call hasn\u2019t yet completed then this method will wait up to timeout seconds. If the call hasn\u2019t completed in timeout seconds, then a concurrent.futures.TimeoutError will be raised. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "If the future is cancelled before completing then CancelledError will be raised.", "If the call completed without raising, None is returned.", "Attaches the callable fn to the future. fn will be called, with the future as its only argument, when the future is cancelled or finishes running.", "Added callables are called in the order that they were added and are always called in a thread belonging to the process that added them. If the callable raises an Exception subclass, it will be logged and ignored. If the callable raises a BaseException subclass, the behavior is undefined.", "If the future has already completed or been cancelled, fn will be called immediately.", "The following Future methods are meant for use in unit tests and Executor implementations.", "This method should only be called by Executor implementations before executing the work associated with the Future and by unit tests.", "If the method returns False then the Future was cancelled, i.e. Future.cancel() was called and returned True. Any threads waiting on the Future completing (i.e. through as_completed() or wait()) will be woken up.", "If the method returns True then the Future was not cancelled and has been put in the running state, i.e. calls to Future.running() will return True.", "This method can only be called once and cannot be called after Future.set_result() or Future.set_exception() have been called.", "Sets the result of the work associated with the Future to result.", "This method should only be used by Executor implementations and unit tests.", "Changed in version 3.8: This method raises concurrent.futures.InvalidStateError if the Future is already done.", "Sets the result of the work associated with the Future to the Exception exception.", "This method should only be used by Executor implementations and unit tests.", "Changed in version 3.8: This method raises concurrent.futures.InvalidStateError if the Future is already done."]}, {"name": "concurrent.futures.Future.add_done_callback()", "path": "library/concurrent.futures#concurrent.futures.Future.add_done_callback", "type": "Concurrent Execution", "text": ["Attaches the callable fn to the future. fn will be called, with the future as its only argument, when the future is cancelled or finishes running.", "Added callables are called in the order that they were added and are always called in a thread belonging to the process that added them. If the callable raises an Exception subclass, it will be logged and ignored. If the callable raises a BaseException subclass, the behavior is undefined.", "If the future has already completed or been cancelled, fn will be called immediately."]}, {"name": "concurrent.futures.Future.cancel()", "path": "library/concurrent.futures#concurrent.futures.Future.cancel", "type": "Concurrent Execution", "text": ["Attempt to cancel the call. If the call is currently being executed or finished running and cannot be cancelled then the method will return False, otherwise the call will be cancelled and the method will return True."]}, {"name": "concurrent.futures.Future.cancelled()", "path": "library/concurrent.futures#concurrent.futures.Future.cancelled", "type": "Concurrent Execution", "text": ["Return True if the call was successfully cancelled."]}, {"name": "concurrent.futures.Future.done()", "path": "library/concurrent.futures#concurrent.futures.Future.done", "type": "Concurrent Execution", "text": ["Return True if the call was successfully cancelled or finished running."]}, {"name": "concurrent.futures.Future.exception()", "path": "library/concurrent.futures#concurrent.futures.Future.exception", "type": "Concurrent Execution", "text": ["Return the exception raised by the call. If the call hasn\u2019t yet completed then this method will wait up to timeout seconds. If the call hasn\u2019t completed in timeout seconds, then a concurrent.futures.TimeoutError will be raised. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "If the future is cancelled before completing then CancelledError will be raised.", "If the call completed without raising, None is returned."]}, {"name": "concurrent.futures.Future.result()", "path": "library/concurrent.futures#concurrent.futures.Future.result", "type": "Concurrent Execution", "text": ["Return the value returned by the call. If the call hasn\u2019t yet completed then this method will wait up to timeout seconds. If the call hasn\u2019t completed in timeout seconds, then a concurrent.futures.TimeoutError will be raised. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "If the future is cancelled before completing then CancelledError will be raised.", "If the call raised, this method will raise the same exception."]}, {"name": "concurrent.futures.Future.running()", "path": "library/concurrent.futures#concurrent.futures.Future.running", "type": "Concurrent Execution", "text": ["Return True if the call is currently being executed and cannot be cancelled."]}, {"name": "concurrent.futures.Future.set_exception()", "path": "library/concurrent.futures#concurrent.futures.Future.set_exception", "type": "Concurrent Execution", "text": ["Sets the result of the work associated with the Future to the Exception exception.", "This method should only be used by Executor implementations and unit tests.", "Changed in version 3.8: This method raises concurrent.futures.InvalidStateError if the Future is already done."]}, {"name": "concurrent.futures.Future.set_result()", "path": "library/concurrent.futures#concurrent.futures.Future.set_result", "type": "Concurrent Execution", "text": ["Sets the result of the work associated with the Future to result.", "This method should only be used by Executor implementations and unit tests.", "Changed in version 3.8: This method raises concurrent.futures.InvalidStateError if the Future is already done."]}, {"name": "concurrent.futures.Future.set_running_or_notify_cancel()", "path": "library/concurrent.futures#concurrent.futures.Future.set_running_or_notify_cancel", "type": "Concurrent Execution", "text": ["This method should only be called by Executor implementations before executing the work associated with the Future and by unit tests.", "If the method returns False then the Future was cancelled, i.e. Future.cancel() was called and returned True. Any threads waiting on the Future completing (i.e. through as_completed() or wait()) will be woken up.", "If the method returns True then the Future was not cancelled and has been put in the running state, i.e. calls to Future.running() will return True.", "This method can only be called once and cannot be called after Future.set_result() or Future.set_exception() have been called."]}, {"name": "concurrent.futures.InvalidStateError", "path": "library/concurrent.futures#concurrent.futures.InvalidStateError", "type": "Concurrent Execution", "text": ["Raised when an operation is performed on a future that is not allowed in the current state.", "New in version 3.8."]}, {"name": "concurrent.futures.process.BrokenProcessPool", "path": "library/concurrent.futures#concurrent.futures.process.BrokenProcessPool", "type": "Concurrent Execution", "text": ["Derived from BrokenExecutor (formerly RuntimeError), this exception class is raised when one of the workers of a ProcessPoolExecutor has terminated in a non-clean fashion (for example, if it was killed from the outside).", "New in version 3.3."]}, {"name": "concurrent.futures.ProcessPoolExecutor", "path": "library/concurrent.futures#concurrent.futures.ProcessPoolExecutor", "type": "Concurrent Execution", "text": ["An Executor subclass that executes calls asynchronously using a pool of at most max_workers processes. If max_workers is None or not given, it will default to the number of processors on the machine. If max_workers is less than or equal to 0, then a ValueError will be raised. On Windows, max_workers must be less than or equal to 61. If it is not then ValueError will be raised. If max_workers is None, then the default chosen will be at most 61, even if more processors are available. mp_context can be a multiprocessing context or None. It will be used to launch the workers. If mp_context is None or not given, the default multiprocessing context is used.", "initializer is an optional callable that is called at the start of each worker process; initargs is a tuple of arguments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a BrokenProcessPool, as well as any attempt to submit more jobs to the pool.", "Changed in version 3.3: When one of the worker processes terminates abruptly, a BrokenProcessPool error is now raised. Previously, behaviour was undefined but operations on the executor or its futures would often freeze or deadlock.", "Changed in version 3.7: The mp_context argument was added to allow users to control the start_method for worker processes created by the pool.", "Added the initializer and initargs arguments."]}, {"name": "concurrent.futures.thread.BrokenThreadPool", "path": "library/concurrent.futures#concurrent.futures.thread.BrokenThreadPool", "type": "Concurrent Execution", "text": ["Derived from BrokenExecutor, this exception class is raised when one of the workers of a ThreadPoolExecutor has failed initializing.", "New in version 3.7."]}, {"name": "concurrent.futures.ThreadPoolExecutor", "path": "library/concurrent.futures#concurrent.futures.ThreadPoolExecutor", "type": "Concurrent Execution", "text": ["An Executor subclass that uses a pool of at most max_workers threads to execute calls asynchronously.", "initializer is an optional callable that is called at the start of each worker thread; initargs is a tuple of arguments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a BrokenThreadPool, as well as any attempt to submit more jobs to the pool.", "Changed in version 3.5: If max_workers is None or not given, it will default to the number of processors on the machine, multiplied by 5, assuming that ThreadPoolExecutor is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for ProcessPoolExecutor.", "New in version 3.6: The thread_name_prefix argument was added to allow users to control the threading.Thread names for worker threads created by the pool for easier debugging.", "Changed in version 3.7: Added the initializer and initargs arguments.", "Changed in version 3.8: Default value of max_workers is changed to min(32, os.cpu_count() + 4). This default value preserves at least 5 workers for I/O bound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which release the GIL. And it avoids using very large resources implicitly on many-core machines.", "ThreadPoolExecutor now reuses idle worker threads before starting max_workers worker threads too."]}, {"name": "concurrent.futures.TimeoutError", "path": "library/concurrent.futures#concurrent.futures.TimeoutError", "type": "Concurrent Execution", "text": ["Raised when a future operation exceeds the given timeout."]}, {"name": "concurrent.futures.wait()", "path": "library/concurrent.futures#concurrent.futures.wait", "type": "Concurrent Execution", "text": ["Wait for the Future instances (possibly created by different Executor instances) given by fs to complete. Returns a named 2-tuple of sets. The first set, named done, contains the futures that completed (finished or cancelled futures) before the wait completed. The second set, named not_done, contains the futures that did not complete (pending or running futures).", "timeout can be used to control the maximum number of seconds to wait before returning. timeout can be an int or float. If timeout is not specified or None, there is no limit to the wait time.", "return_when indicates when this function should return. It must be one of the following constants:", "Constant", "Description", "FIRST_COMPLETED", "The function will return when any future finishes or is cancelled.", "FIRST_EXCEPTION", "The function will return when any future finishes by raising an exception. If no future raises an exception then it is equivalent to ALL_COMPLETED.", "ALL_COMPLETED", "The function will return when all futures finish or are cancelled."]}, {"name": "configparser", "path": "library/configparser", "type": "File Formats", "text": ["Source code: Lib/configparser.py", "This module provides the ConfigParser class which implements a basic configuration language which provides a structure similar to what\u2019s found in Microsoft Windows INI files. You can use this to write Python programs which can be customized by end users easily.", "Note", "This library does not interpret or write the value-type prefixes used in the Windows Registry extended version of INI syntax.", "See also", "Support for creating Unix shell-like mini-languages which can be used as an alternate format for application configuration files.", "The json module implements a subset of JavaScript syntax which can also be used for this purpose.", "Let\u2019s take a very basic configuration file that looks like this:", "The structure of INI files is described in the following section. Essentially, the file consists of sections, each of which contains keys with values. configparser classes can read and write such files. Let\u2019s start by creating the above configuration file programmatically.", "As you can see, we can treat a config parser much like a dictionary. There are differences, outlined later, but the behavior is very close to what you would expect from a dictionary.", "Now that we have created and saved a configuration file, let\u2019s read it back and explore the data it holds.", "As we can see above, the API is pretty straightforward. The only bit of magic involves the DEFAULT section which provides default values for all other sections 1. Note also that keys in sections are case-insensitive and stored in lowercase 1.", "Config parsers do not guess datatypes of values in configuration files, always storing them internally as strings. This means that if you need other datatypes, you should convert on your own:", "Since this task is so common, config parsers provide a range of handy getter methods to handle integers, floats and booleans. The last one is the most interesting because simply passing the value to bool() would do no good since bool('False') is still True. This is why config parsers also provide getboolean(). This method is case-insensitive and recognizes Boolean values from 'yes'/'no', 'on'/'off', 'true'/'false' and '1'/'0' 1. For example:", "Apart from getboolean(), config parsers also provide equivalent getint() and getfloat() methods. You can register your own converters and customize the provided ones. 1", "As with a dictionary, you can use a section\u2019s get() method to provide fallback values:", "Please note that default values have precedence over fallback values. For instance, in our example the 'CompressionLevel' key was specified only in the 'DEFAULT' section. If we try to get it from the section 'topsecret.server.com', we will always get the default, even if we specify a fallback:", "One more thing to be aware of is that the parser-level get() method provides a custom, more complex interface, maintained for backwards compatibility. When using this method, a fallback value can be provided via the fallback keyword-only argument:", "The same fallback argument can be used with the getint(), getfloat() and getboolean() methods, for example:", "A configuration file consists of sections, each led by a [section] header, followed by key/value entries separated by a specific string (= or : by default 1). By default, section names are case sensitive but keys are not 1. Leading and trailing whitespace is removed from keys and values. Values can be omitted, in which case the key/value delimiter may also be left out. Values can also span multiple lines, as long as they are indented deeper than the first line of the value. Depending on the parser\u2019s mode, blank lines may be treated as parts of multiline values or ignored.", "Configuration files may include comments, prefixed by specific characters (# and ; by default 1). Comments may appear on their own on an otherwise empty line, possibly indented. 1", "For example:", "On top of the core functionality, ConfigParser supports interpolation. This means values can be preprocessed before returning them from get() calls.", "The default implementation used by ConfigParser. It enables values to contain format strings which refer to other values in the same section, or values in the special default section 1. Additional default values can be provided on initialization.", "For example:", "In the example above, ConfigParser with interpolation set to BasicInterpolation() would resolve %(home_dir)s to the value of home_dir (/Users in this case). %(my_dir)s in effect would resolve to /Users/lumberjack. All interpolations are done on demand so keys used in the chain of references do not have to be specified in any specific order in the configuration file.", "With interpolation set to None, the parser would simply return %(my_dir)s/Pictures as the value of my_pictures and %(home_dir)s/lumberjack as the value of my_dir.", "An alternative handler for interpolation which implements a more advanced syntax, used for instance in zc.buildout. Extended interpolation is using ${section:option} to denote a value from a foreign section. Interpolation can span multiple levels. For convenience, if the section: part is omitted, interpolation defaults to the current section (and possibly the default values from the special section).", "For example, the configuration specified above with basic interpolation, would look like this with extended interpolation:", "Values from other sections can be fetched as well:", "New in version 3.2.", "Mapping protocol access is a generic name for functionality that enables using custom objects as if they were dictionaries. In case of configparser, the mapping interface implementation is using the parser['section']['option'] notation.", "parser['section'] in particular returns a proxy for the section\u2019s data in the parser. This means that the values are not copied but they are taken from the original parser on demand. What\u2019s even more important is that when values are changed on a section proxy, they are actually mutated in the original parser.", "configparser objects behave as close to actual dictionaries as possible. The mapping interface is complete and adheres to the MutableMapping ABC. However, there are a few differences that should be taken into account:", "By default, all keys in sections are accessible in a case-insensitive manner 1. E.g. for option in parser[\"section\"] yields only optionxform\u2019ed option key names. This means lowercased keys by default. At the same time, for a section that holds the key 'a', both expressions return True:", "DEFAULTSECT cannot be removed from the parser:", "The mapping protocol is implemented on top of the existing legacy API so that subclasses overriding the original interface still should have mappings working as expected.", "There are nearly as many INI format variants as there are applications using it. configparser goes a long way to provide support for the largest sensible set of INI styles available. The default functionality is mainly dictated by historical background and it\u2019s very likely that you will want to customize some of the features.", "The most common way to change the way a specific config parser works is to use the __init__() options:", "defaults, default value: None", "This option accepts a dictionary of key-value pairs which will be initially put in the DEFAULT section. This makes for an elegant way to support concise configuration files that don\u2019t specify values which are the same as the documented default.", "Hint: if you want to specify default values for a specific section, use read_dict() before you read the actual file.", "dict_type, default value: dict", "This option has a major impact on how the mapping protocol will behave and how the written configuration files look. With the standard dictionary, every section is stored in the order they were added to the parser. Same goes for options within sections.", "An alternative dictionary type can be used for example to sort sections and options on write-back.", "Please note: there are ways to add a set of key-value pairs in a single operation. When you use a regular dictionary in those operations, the order of the keys will be ordered. For example:", "allow_no_value, default value: False", "Some configuration files are known to include settings without values, but which otherwise conform to the syntax supported by configparser. The allow_no_value parameter to the constructor can be used to indicate that such values should be accepted:", "delimiters, default value: ('=', ':')", "Delimiters are substrings that delimit keys from values within a section. The first occurrence of a delimiting substring on a line is considered a delimiter. This means values (but not keys) can contain the delimiters.", "See also the space_around_delimiters argument to ConfigParser.write().", "inline_comment_prefixes, default value: None", "Comment prefixes are strings that indicate the start of a valid comment within a config file. comment_prefixes are used only on otherwise empty lines (optionally indented) whereas inline_comment_prefixes can be used after every valid value (e.g. section names, options and empty lines as well). By default inline comments are disabled and '#' and ';' are used as prefixes for whole line comments.", "Changed in version 3.2: In previous versions of configparser behaviour matched comment_prefixes=('#',';') and inline_comment_prefixes=(';',).", "Please note that config parsers don\u2019t support escaping of comment prefixes so using inline_comment_prefixes may prevent users from specifying option values with characters used as comment prefixes. When in doubt, avoid setting inline_comment_prefixes. In any circumstances, the only way of storing comment prefix characters at the beginning of a line in multiline values is to interpolate the prefix, for example:", "strict, default value: True", "When set to True, the parser will not allow for any section or option duplicates while reading from a single source (using read_file(), read_string() or read_dict()). It is recommended to use strict parsers in new applications.", "Changed in version 3.2: In previous versions of configparser behaviour matched strict=False.", "empty_lines_in_values, default value: True", "In config parsers, values can span multiple lines as long as they are indented more than the key that holds them. By default parsers also let empty lines to be parts of values. At the same time, keys can be arbitrarily indented themselves to improve readability. In consequence, when configuration files get big and complex, it is easy for the user to lose track of the file structure. Take for instance:", "This can be especially problematic for the user to see if she\u2019s using a proportional font to edit the file. That is why when your application does not need values with empty lines, you should consider disallowing them. This will make empty lines split keys every time. In the example above, it would produce two keys, key and this.", "default_section, default value: configparser.DEFAULTSECT (that is: \"DEFAULT\")", "The convention of allowing a special section of default values for other sections or interpolation purposes is a powerful concept of this library, letting users create complex declarative configurations. This section is normally called \"DEFAULT\" but this can be customized to point to any other valid section name. Some typical values include: \"general\" or \"common\". The name provided is used for recognizing default sections when reading from any source and is used when writing configuration back to a file. Its current value can be retrieved using the parser_instance.default_section attribute and may be modified at runtime (i.e. to convert files from one format to another).", "interpolation, default value: configparser.BasicInterpolation", "Interpolation behaviour may be customized by providing a custom handler through the interpolation argument. None can be used to turn off interpolation completely, ExtendedInterpolation() provides a more advanced variant inspired by zc.buildout. More on the subject in the dedicated documentation section. RawConfigParser has a default value of None.", "converters, default value: not set", "Config parsers provide option value getters that perform type conversion. By default getint(), getfloat(), and getboolean() are implemented. Should other getters be desirable, users may define them in a subclass or pass a dictionary where each key is a name of the converter and each value is a callable implementing said conversion. For instance, passing {'decimal': decimal.Decimal} would add getdecimal() on both the parser object and all section proxies. In other words, it will be possible to write both parser_instance.getdecimal('section', 'key', fallback=0) and parser_instance['section'].getdecimal('key', 0).", "If the converter needs to access the state of the parser, it can be implemented as a method on a config parser subclass. If the name of this method starts with get, it will be available on all section proxies, in the dict-compatible form (see the getdecimal() example above).", "More advanced customization may be achieved by overriding default values of these parser attributes. The defaults are defined on the classes, so they may be overridden by subclasses or by attribute assignment.", "By default when using getboolean(), config parsers consider the following values True: '1', 'yes', 'true', 'on' and the following values False: '0', 'no', 'false', 'off'. You can override this by specifying a custom dictionary of strings and their Boolean outcomes. For example:", "Other typical Boolean pairs include accept/reject or enabled/disabled.", "This method transforms option names on every read, get, or set operation. The default converts the name to lowercase. This also means that when a configuration file gets written, all keys will be lowercase. Override this method if that\u2019s unsuitable. For example:", "Note", "The optionxform function transforms option names to a canonical form. This should be an idempotent function: if the name is already in canonical form, it should be returned unchanged.", "A compiled regular expression used to parse section headers. The default matches [section] to the name \"section\". Whitespace is considered part of the section name, thus [\u00a0 larch\u00a0 ] will be read as a section of name \"\u00a0 larch\u00a0 \". Override this attribute if that\u2019s unsuitable. For example:", "Note", "While ConfigParser objects also use an OPTCRE attribute for recognizing option lines, it\u2019s not recommended to override it because that would interfere with constructor options allow_no_value and delimiters.", "Mainly because of backwards compatibility concerns, configparser provides also a legacy API with explicit get/set methods. While there are valid use cases for the methods outlined below, mapping protocol access is preferred for new projects. The legacy API is at times more advanced, low-level and downright counterintuitive.", "An example of writing to a configuration file:", "An example of reading the configuration file again:", "To get interpolation, use ConfigParser:", "Default values are available in both types of ConfigParsers. They are used in interpolation if an option used is not defined elsewhere.", "The main configuration parser. When defaults is given, it is initialized into the dictionary of intrinsic defaults. When dict_type is given, it will be used to create the dictionary objects for the list of sections, for the options within a section, and for the default values.", "When delimiters is given, it is used as the set of substrings that divide keys from values. When comment_prefixes is given, it will be used as the set of substrings that prefix comments in otherwise empty lines. Comments can be indented. When inline_comment_prefixes is given, it will be used as the set of substrings that prefix comments in non-empty lines.", "When strict is True (the default), the parser won\u2019t allow for any section or option duplicates while reading from a single source (file, string or dictionary), raising DuplicateSectionError or DuplicateOptionError. When empty_lines_in_values is False (default: True), each empty line marks the end of an option. Otherwise, internal empty lines of a multiline option are kept as part of the value. When allow_no_value is True (default: False), options without values are accepted; the value held for these is None and they are serialized without the trailing delimiter.", "When default_section is given, it specifies the name for the special section holding default values for other sections and interpolation purposes (normally named \"DEFAULT\"). This value can be retrieved and changed on runtime using the default_section instance attribute.", "Interpolation behaviour may be customized by providing a custom handler through the interpolation argument. None can be used to turn off interpolation completely, ExtendedInterpolation() provides a more advanced variant inspired by zc.buildout. More on the subject in the dedicated documentation section.", "All option names used in interpolation will be passed through the optionxform() method just like any other option name reference. For example, using the default implementation of optionxform() (which converts option names to lower case), the values foo %(bar)s and foo\n%(BAR)s are equivalent.", "When converters is given, it should be a dictionary where each key represents the name of a type converter and each value is a callable implementing the conversion from string to the desired datatype. Every converter gets its own corresponding get*() method on the parser object and section proxies.", "Changed in version 3.1: The default dict_type is collections.OrderedDict.", "Changed in version 3.2: allow_no_value, delimiters, comment_prefixes, strict, empty_lines_in_values, default_section and interpolation were added.", "Changed in version 3.5: The converters argument was added.", "Changed in version 3.7: The defaults argument is read with read_dict(), providing consistent behavior across the parser: non-string keys and values are implicitly converted to strings.", "Changed in version 3.8: The default dict_type is dict, since it now preserves insertion order.", "Return a dictionary containing the instance-wide defaults.", "Return a list of the sections available; the default section is not included in the list.", "Add a section named section to the instance. If a section by the given name already exists, DuplicateSectionError is raised. If the default section name is passed, ValueError is raised. The name of the section must be a string; if not, TypeError is raised.", "Changed in version 3.2: Non-string section names raise TypeError.", "Indicates whether the named section is present in the configuration. The default section is not acknowledged.", "Return a list of options available in the specified section.", "If the given section exists, and contains the given option, return True; otherwise return False. If the specified section is None or an empty string, DEFAULT is assumed.", "Attempt to read and parse an iterable of filenames, returning a list of filenames which were successfully parsed.", "If filenames is a string, a bytes object or a path-like object, it is treated as a single filename. If a file named in filenames cannot be opened, that file will be ignored. This is designed so that you can specify an iterable of potential configuration file locations (for example, the current directory, the user\u2019s home directory, and some system-wide directory), and all existing configuration files in the iterable will be read.", "If none of the named files exist, the ConfigParser instance will contain an empty dataset. An application which requires initial values to be loaded from a file should load the required file or files using read_file() before calling read() for any optional files:", "New in version 3.2: The encoding parameter. Previously, all files were read using the default encoding for open().", "New in version 3.6.1: The filenames parameter accepts a path-like object.", "New in version 3.7: The filenames parameter accepts a bytes object.", "Read and parse configuration data from f which must be an iterable yielding Unicode strings (for example files opened in text mode).", "Optional argument source specifies the name of the file being read. If not given and f has a name attribute, that is used for source; the default is '<???>'.", "New in version 3.2: Replaces readfp().", "Parse configuration data from a string.", "Optional argument source specifies a context-specific name of the string passed. If not given, '<string>' is used. This should commonly be a filesystem path or a URL.", "New in version 3.2.", "Load configuration from any object that provides a dict-like items() method. Keys are section names, values are dictionaries with keys and values that should be present in the section. If the used dictionary type preserves order, sections and their keys will be added in order. Values are automatically converted to strings.", "Optional argument source specifies a context-specific name of the dictionary passed. If not given, <dict> is used.", "This method can be used to copy state between parsers.", "New in version 3.2.", "Get an option value for the named section. If vars is provided, it must be a dictionary. The option is looked up in vars (if provided), section, and in DEFAULTSECT in that order. If the key is not found and fallback is provided, it is used as a fallback value. None can be provided as a fallback value.", "All the '%' interpolations are expanded in the return values, unless the raw argument is true. Values for interpolation keys are looked up in the same manner as the option.", "Changed in version 3.2: Arguments raw, vars and fallback are keyword only to protect users from trying to use the third argument as the fallback fallback (especially when using the mapping protocol).", "A convenience method which coerces the option in the specified section to an integer. See get() for explanation of raw, vars and fallback.", "A convenience method which coerces the option in the specified section to a floating point number. See get() for explanation of raw, vars and fallback.", "A convenience method which coerces the option in the specified section to a Boolean value. Note that the accepted values for the option are '1', 'yes', 'true', and 'on', which cause this method to return True, and '0', 'no', 'false', and 'off', which cause it to return False. These string values are checked in a case-insensitive manner. Any other value will cause it to raise ValueError. See get() for explanation of raw, vars and fallback.", "When section is not given, return a list of section_name, section_proxy pairs, including DEFAULTSECT.", "Otherwise, return a list of name, value pairs for the options in the given section. Optional arguments have the same meaning as for the get() method.", "Changed in version 3.8: Items present in vars no longer appear in the result. The previous behaviour mixed actual parser options with variables provided for interpolation.", "If the given section exists, set the given option to the specified value; otherwise raise NoSectionError. option and value must be strings; if not, TypeError is raised.", "Write a representation of the configuration to the specified file object, which must be opened in text mode (accepting strings). This representation can be parsed by a future read() call. If space_around_delimiters is true, delimiters between keys and values are surrounded by spaces.", "Remove the specified option from the specified section. If the section does not exist, raise NoSectionError. If the option existed to be removed, return True; otherwise return False.", "Remove the specified section from the configuration. If the section in fact existed, return True. Otherwise return False.", "Transforms the option name option as found in an input file or as passed in by client code to the form that should be used in the internal structures. The default implementation returns a lower-case version of option; subclasses may override this or client code can set an attribute of this name on instances to affect this behavior.", "You don\u2019t need to subclass the parser to use this method, you can also set it on an instance, to a function that takes a string argument and returns a string. Setting it to str, for example, would make option names case sensitive:", "Note that when reading configuration files, whitespace around the option names is stripped before optionxform() is called.", "Deprecated since version 3.2: Use read_file() instead.", "Changed in version 3.2: readfp() now iterates on fp instead of calling fp.readline().", "For existing code calling readfp() with arguments which don\u2019t support iteration, the following generator may be used as a wrapper around the file-like object:", "Instead of parser.readfp(fp) use parser.read_file(readline_generator(fp)).", "The maximum depth for recursive interpolation for get() when the raw parameter is false. This is relevant only when the default interpolation is used.", "Legacy variant of the ConfigParser. It has interpolation disabled by default and allows for non-string section names, option names, and values via its unsafe add_section and set methods, as well as the legacy defaults= keyword argument handling.", "Changed in version 3.8: The default dict_type is dict, since it now preserves insertion order.", "Note", "Consider using ConfigParser instead which checks types of the values to be stored internally. If you don\u2019t want interpolation, you can use ConfigParser(interpolation=None).", "Add a section named section to the instance. If a section by the given name already exists, DuplicateSectionError is raised. If the default section name is passed, ValueError is raised.", "Type of section is not checked which lets users create non-string named sections. This behaviour is unsupported and may cause internal errors.", "If the given section exists, set the given option to the specified value; otherwise raise NoSectionError. While it is possible to use RawConfigParser (or ConfigParser with raw parameters set to true) for internal storage of non-string values, full functionality (including interpolation and output to files) can only be achieved using string values.", "This method lets users assign non-string values to keys internally. This behaviour is unsupported and will cause errors when attempting to write to a file or get it in non-raw mode. Use the mapping protocol API which does not allow such assignments to take place.", "Base class for all other configparser exceptions.", "Exception raised when a specified section is not found.", "Exception raised if add_section() is called with the name of a section that is already present or in strict parsers when a section if found more than once in a single input file, string or dictionary.", "New in version 3.2: Optional source and lineno attributes and arguments to __init__() were added.", "Exception raised by strict parsers if a single option appears twice during reading from a single file, string or dictionary. This catches misspellings and case sensitivity-related errors, e.g. a dictionary may have two keys representing the same case-insensitive configuration key.", "Exception raised when a specified option is not found in the specified section.", "Base class for exceptions raised when problems occur performing string interpolation.", "Exception raised when string interpolation cannot be completed because the number of iterations exceeds MAX_INTERPOLATION_DEPTH. Subclass of InterpolationError.", "Exception raised when an option referenced from a value does not exist. Subclass of InterpolationError.", "Exception raised when the source text into which substitutions are made does not conform to the required syntax. Subclass of InterpolationError.", "Exception raised when attempting to parse a file which has no section headers.", "Exception raised when errors occur attempting to parse a file.", "Changed in version 3.2: The filename attribute and __init__() argument were renamed to source for consistency.", "Config parsers allow for heavy customization. If you are interested in changing the behaviour outlined by the footnote reference, consult the Customizing Parser Behaviour section."]}, {"name": "configparser.BasicInterpolation", "path": "library/configparser#configparser.BasicInterpolation", "type": "File Formats", "text": ["The default implementation used by ConfigParser. It enables values to contain format strings which refer to other values in the same section, or values in the special default section 1. Additional default values can be provided on initialization.", "For example:", "In the example above, ConfigParser with interpolation set to BasicInterpolation() would resolve %(home_dir)s to the value of home_dir (/Users in this case). %(my_dir)s in effect would resolve to /Users/lumberjack. All interpolations are done on demand so keys used in the chain of references do not have to be specified in any specific order in the configuration file.", "With interpolation set to None, the parser would simply return %(my_dir)s/Pictures as the value of my_pictures and %(home_dir)s/lumberjack as the value of my_dir."]}, {"name": "configparser.ConfigParser", "path": "library/configparser#configparser.ConfigParser", "type": "File Formats", "text": ["The main configuration parser. When defaults is given, it is initialized into the dictionary of intrinsic defaults. When dict_type is given, it will be used to create the dictionary objects for the list of sections, for the options within a section, and for the default values.", "When delimiters is given, it is used as the set of substrings that divide keys from values. When comment_prefixes is given, it will be used as the set of substrings that prefix comments in otherwise empty lines. Comments can be indented. When inline_comment_prefixes is given, it will be used as the set of substrings that prefix comments in non-empty lines.", "When strict is True (the default), the parser won\u2019t allow for any section or option duplicates while reading from a single source (file, string or dictionary), raising DuplicateSectionError or DuplicateOptionError. When empty_lines_in_values is False (default: True), each empty line marks the end of an option. Otherwise, internal empty lines of a multiline option are kept as part of the value. When allow_no_value is True (default: False), options without values are accepted; the value held for these is None and they are serialized without the trailing delimiter.", "When default_section is given, it specifies the name for the special section holding default values for other sections and interpolation purposes (normally named \"DEFAULT\"). This value can be retrieved and changed on runtime using the default_section instance attribute.", "Interpolation behaviour may be customized by providing a custom handler through the interpolation argument. None can be used to turn off interpolation completely, ExtendedInterpolation() provides a more advanced variant inspired by zc.buildout. More on the subject in the dedicated documentation section.", "All option names used in interpolation will be passed through the optionxform() method just like any other option name reference. For example, using the default implementation of optionxform() (which converts option names to lower case), the values foo %(bar)s and foo\n%(BAR)s are equivalent.", "When converters is given, it should be a dictionary where each key represents the name of a type converter and each value is a callable implementing the conversion from string to the desired datatype. Every converter gets its own corresponding get*() method on the parser object and section proxies.", "Changed in version 3.1: The default dict_type is collections.OrderedDict.", "Changed in version 3.2: allow_no_value, delimiters, comment_prefixes, strict, empty_lines_in_values, default_section and interpolation were added.", "Changed in version 3.5: The converters argument was added.", "Changed in version 3.7: The defaults argument is read with read_dict(), providing consistent behavior across the parser: non-string keys and values are implicitly converted to strings.", "Changed in version 3.8: The default dict_type is dict, since it now preserves insertion order.", "Return a dictionary containing the instance-wide defaults.", "Return a list of the sections available; the default section is not included in the list.", "Add a section named section to the instance. If a section by the given name already exists, DuplicateSectionError is raised. If the default section name is passed, ValueError is raised. The name of the section must be a string; if not, TypeError is raised.", "Changed in version 3.2: Non-string section names raise TypeError.", "Indicates whether the named section is present in the configuration. The default section is not acknowledged.", "Return a list of options available in the specified section.", "If the given section exists, and contains the given option, return True; otherwise return False. If the specified section is None or an empty string, DEFAULT is assumed.", "Attempt to read and parse an iterable of filenames, returning a list of filenames which were successfully parsed.", "If filenames is a string, a bytes object or a path-like object, it is treated as a single filename. If a file named in filenames cannot be opened, that file will be ignored. This is designed so that you can specify an iterable of potential configuration file locations (for example, the current directory, the user\u2019s home directory, and some system-wide directory), and all existing configuration files in the iterable will be read.", "If none of the named files exist, the ConfigParser instance will contain an empty dataset. An application which requires initial values to be loaded from a file should load the required file or files using read_file() before calling read() for any optional files:", "New in version 3.2: The encoding parameter. Previously, all files were read using the default encoding for open().", "New in version 3.6.1: The filenames parameter accepts a path-like object.", "New in version 3.7: The filenames parameter accepts a bytes object.", "Read and parse configuration data from f which must be an iterable yielding Unicode strings (for example files opened in text mode).", "Optional argument source specifies the name of the file being read. If not given and f has a name attribute, that is used for source; the default is '<???>'.", "New in version 3.2: Replaces readfp().", "Parse configuration data from a string.", "Optional argument source specifies a context-specific name of the string passed. If not given, '<string>' is used. This should commonly be a filesystem path or a URL.", "New in version 3.2.", "Load configuration from any object that provides a dict-like items() method. Keys are section names, values are dictionaries with keys and values that should be present in the section. If the used dictionary type preserves order, sections and their keys will be added in order. Values are automatically converted to strings.", "Optional argument source specifies a context-specific name of the dictionary passed. If not given, <dict> is used.", "This method can be used to copy state between parsers.", "New in version 3.2.", "Get an option value for the named section. If vars is provided, it must be a dictionary. The option is looked up in vars (if provided), section, and in DEFAULTSECT in that order. If the key is not found and fallback is provided, it is used as a fallback value. None can be provided as a fallback value.", "All the '%' interpolations are expanded in the return values, unless the raw argument is true. Values for interpolation keys are looked up in the same manner as the option.", "Changed in version 3.2: Arguments raw, vars and fallback are keyword only to protect users from trying to use the third argument as the fallback fallback (especially when using the mapping protocol).", "A convenience method which coerces the option in the specified section to an integer. See get() for explanation of raw, vars and fallback.", "A convenience method which coerces the option in the specified section to a floating point number. See get() for explanation of raw, vars and fallback.", "A convenience method which coerces the option in the specified section to a Boolean value. Note that the accepted values for the option are '1', 'yes', 'true', and 'on', which cause this method to return True, and '0', 'no', 'false', and 'off', which cause it to return False. These string values are checked in a case-insensitive manner. Any other value will cause it to raise ValueError. See get() for explanation of raw, vars and fallback.", "When section is not given, return a list of section_name, section_proxy pairs, including DEFAULTSECT.", "Otherwise, return a list of name, value pairs for the options in the given section. Optional arguments have the same meaning as for the get() method.", "Changed in version 3.8: Items present in vars no longer appear in the result. The previous behaviour mixed actual parser options with variables provided for interpolation.", "If the given section exists, set the given option to the specified value; otherwise raise NoSectionError. option and value must be strings; if not, TypeError is raised.", "Write a representation of the configuration to the specified file object, which must be opened in text mode (accepting strings). This representation can be parsed by a future read() call. If space_around_delimiters is true, delimiters between keys and values are surrounded by spaces.", "Remove the specified option from the specified section. If the section does not exist, raise NoSectionError. If the option existed to be removed, return True; otherwise return False.", "Remove the specified section from the configuration. If the section in fact existed, return True. Otherwise return False.", "Transforms the option name option as found in an input file or as passed in by client code to the form that should be used in the internal structures. The default implementation returns a lower-case version of option; subclasses may override this or client code can set an attribute of this name on instances to affect this behavior.", "You don\u2019t need to subclass the parser to use this method, you can also set it on an instance, to a function that takes a string argument and returns a string. Setting it to str, for example, would make option names case sensitive:", "Note that when reading configuration files, whitespace around the option names is stripped before optionxform() is called.", "Deprecated since version 3.2: Use read_file() instead.", "Changed in version 3.2: readfp() now iterates on fp instead of calling fp.readline().", "For existing code calling readfp() with arguments which don\u2019t support iteration, the following generator may be used as a wrapper around the file-like object:", "Instead of parser.readfp(fp) use parser.read_file(readline_generator(fp))."]}, {"name": "configparser.ConfigParser.add_section()", "path": "library/configparser#configparser.ConfigParser.add_section", "type": "File Formats", "text": ["Add a section named section to the instance. If a section by the given name already exists, DuplicateSectionError is raised. If the default section name is passed, ValueError is raised. The name of the section must be a string; if not, TypeError is raised.", "Changed in version 3.2: Non-string section names raise TypeError."]}, {"name": "configparser.ConfigParser.BOOLEAN_STATES", "path": "library/configparser#configparser.ConfigParser.BOOLEAN_STATES", "type": "File Formats", "text": ["By default when using getboolean(), config parsers consider the following values True: '1', 'yes', 'true', 'on' and the following values False: '0', 'no', 'false', 'off'. You can override this by specifying a custom dictionary of strings and their Boolean outcomes. For example:", "Other typical Boolean pairs include accept/reject or enabled/disabled."]}, {"name": "configparser.ConfigParser.defaults()", "path": "library/configparser#configparser.ConfigParser.defaults", "type": "File Formats", "text": ["Return a dictionary containing the instance-wide defaults."]}, {"name": "configparser.ConfigParser.get()", "path": "library/configparser#configparser.ConfigParser.get", "type": "File Formats", "text": ["Get an option value for the named section. If vars is provided, it must be a dictionary. The option is looked up in vars (if provided), section, and in DEFAULTSECT in that order. If the key is not found and fallback is provided, it is used as a fallback value. None can be provided as a fallback value.", "All the '%' interpolations are expanded in the return values, unless the raw argument is true. Values for interpolation keys are looked up in the same manner as the option.", "Changed in version 3.2: Arguments raw, vars and fallback are keyword only to protect users from trying to use the third argument as the fallback fallback (especially when using the mapping protocol)."]}, {"name": "configparser.ConfigParser.getboolean()", "path": "library/configparser#configparser.ConfigParser.getboolean", "type": "File Formats", "text": ["A convenience method which coerces the option in the specified section to a Boolean value. Note that the accepted values for the option are '1', 'yes', 'true', and 'on', which cause this method to return True, and '0', 'no', 'false', and 'off', which cause it to return False. These string values are checked in a case-insensitive manner. Any other value will cause it to raise ValueError. See get() for explanation of raw, vars and fallback."]}, {"name": "configparser.ConfigParser.getfloat()", "path": "library/configparser#configparser.ConfigParser.getfloat", "type": "File Formats", "text": ["A convenience method which coerces the option in the specified section to a floating point number. See get() for explanation of raw, vars and fallback."]}, {"name": "configparser.ConfigParser.getint()", "path": "library/configparser#configparser.ConfigParser.getint", "type": "File Formats", "text": ["A convenience method which coerces the option in the specified section to an integer. See get() for explanation of raw, vars and fallback."]}, {"name": "configparser.ConfigParser.has_option()", "path": "library/configparser#configparser.ConfigParser.has_option", "type": "File Formats", "text": ["If the given section exists, and contains the given option, return True; otherwise return False. If the specified section is None or an empty string, DEFAULT is assumed."]}, {"name": "configparser.ConfigParser.has_section()", "path": "library/configparser#configparser.ConfigParser.has_section", "type": "File Formats", "text": ["Indicates whether the named section is present in the configuration. The default section is not acknowledged."]}, {"name": "configparser.ConfigParser.items()", "path": "library/configparser#configparser.ConfigParser.items", "type": "File Formats", "text": ["When section is not given, return a list of section_name, section_proxy pairs, including DEFAULTSECT.", "Otherwise, return a list of name, value pairs for the options in the given section. Optional arguments have the same meaning as for the get() method.", "Changed in version 3.8: Items present in vars no longer appear in the result. The previous behaviour mixed actual parser options with variables provided for interpolation."]}, {"name": "configparser.ConfigParser.options()", "path": "library/configparser#configparser.ConfigParser.options", "type": "File Formats", "text": ["Return a list of options available in the specified section."]}, {"name": "configparser.ConfigParser.optionxform()", "path": "library/configparser#configparser.ConfigParser.optionxform", "type": "File Formats", "text": ["Transforms the option name option as found in an input file or as passed in by client code to the form that should be used in the internal structures. The default implementation returns a lower-case version of option; subclasses may override this or client code can set an attribute of this name on instances to affect this behavior.", "You don\u2019t need to subclass the parser to use this method, you can also set it on an instance, to a function that takes a string argument and returns a string. Setting it to str, for example, would make option names case sensitive:", "Note that when reading configuration files, whitespace around the option names is stripped before optionxform() is called."]}, {"name": "configparser.ConfigParser.read()", "path": "library/configparser#configparser.ConfigParser.read", "type": "File Formats", "text": ["Attempt to read and parse an iterable of filenames, returning a list of filenames which were successfully parsed.", "If filenames is a string, a bytes object or a path-like object, it is treated as a single filename. If a file named in filenames cannot be opened, that file will be ignored. This is designed so that you can specify an iterable of potential configuration file locations (for example, the current directory, the user\u2019s home directory, and some system-wide directory), and all existing configuration files in the iterable will be read.", "If none of the named files exist, the ConfigParser instance will contain an empty dataset. An application which requires initial values to be loaded from a file should load the required file or files using read_file() before calling read() for any optional files:", "New in version 3.2: The encoding parameter. Previously, all files were read using the default encoding for open().", "New in version 3.6.1: The filenames parameter accepts a path-like object.", "New in version 3.7: The filenames parameter accepts a bytes object."]}, {"name": "configparser.ConfigParser.readfp()", "path": "library/configparser#configparser.ConfigParser.readfp", "type": "File Formats", "text": ["Deprecated since version 3.2: Use read_file() instead.", "Changed in version 3.2: readfp() now iterates on fp instead of calling fp.readline().", "For existing code calling readfp() with arguments which don\u2019t support iteration, the following generator may be used as a wrapper around the file-like object:", "Instead of parser.readfp(fp) use parser.read_file(readline_generator(fp))."]}, {"name": "configparser.ConfigParser.read_dict()", "path": "library/configparser#configparser.ConfigParser.read_dict", "type": "File Formats", "text": ["Load configuration from any object that provides a dict-like items() method. Keys are section names, values are dictionaries with keys and values that should be present in the section. If the used dictionary type preserves order, sections and their keys will be added in order. Values are automatically converted to strings.", "Optional argument source specifies a context-specific name of the dictionary passed. If not given, <dict> is used.", "This method can be used to copy state between parsers.", "New in version 3.2."]}, {"name": "configparser.ConfigParser.read_file()", "path": "library/configparser#configparser.ConfigParser.read_file", "type": "File Formats", "text": ["Read and parse configuration data from f which must be an iterable yielding Unicode strings (for example files opened in text mode).", "Optional argument source specifies the name of the file being read. If not given and f has a name attribute, that is used for source; the default is '<???>'.", "New in version 3.2: Replaces readfp()."]}, {"name": "configparser.ConfigParser.read_string()", "path": "library/configparser#configparser.ConfigParser.read_string", "type": "File Formats", "text": ["Parse configuration data from a string.", "Optional argument source specifies a context-specific name of the string passed. If not given, '<string>' is used. This should commonly be a filesystem path or a URL.", "New in version 3.2."]}, {"name": "configparser.ConfigParser.remove_option()", "path": "library/configparser#configparser.ConfigParser.remove_option", "type": "File Formats", "text": ["Remove the specified option from the specified section. If the section does not exist, raise NoSectionError. If the option existed to be removed, return True; otherwise return False."]}, {"name": "configparser.ConfigParser.remove_section()", "path": "library/configparser#configparser.ConfigParser.remove_section", "type": "File Formats", "text": ["Remove the specified section from the configuration. If the section in fact existed, return True. Otherwise return False."]}, {"name": "configparser.ConfigParser.SECTCRE", "path": "library/configparser#configparser.ConfigParser.SECTCRE", "type": "File Formats", "text": ["A compiled regular expression used to parse section headers. The default matches [section] to the name \"section\". Whitespace is considered part of the section name, thus [\u00a0 larch\u00a0 ] will be read as a section of name \"\u00a0 larch\u00a0 \". Override this attribute if that\u2019s unsuitable. For example:", "Note", "While ConfigParser objects also use an OPTCRE attribute for recognizing option lines, it\u2019s not recommended to override it because that would interfere with constructor options allow_no_value and delimiters."]}, {"name": "configparser.ConfigParser.sections()", "path": "library/configparser#configparser.ConfigParser.sections", "type": "File Formats", "text": ["Return a list of the sections available; the default section is not included in the list."]}, {"name": "configparser.ConfigParser.set()", "path": "library/configparser#configparser.ConfigParser.set", "type": "File Formats", "text": ["If the given section exists, set the given option to the specified value; otherwise raise NoSectionError. option and value must be strings; if not, TypeError is raised."]}, {"name": "configparser.ConfigParser.write()", "path": "library/configparser#configparser.ConfigParser.write", "type": "File Formats", "text": ["Write a representation of the configuration to the specified file object, which must be opened in text mode (accepting strings). This representation can be parsed by a future read() call. If space_around_delimiters is true, delimiters between keys and values are surrounded by spaces."]}, {"name": "configparser.DuplicateOptionError", "path": "library/configparser#configparser.DuplicateOptionError", "type": "File Formats", "text": ["Exception raised by strict parsers if a single option appears twice during reading from a single file, string or dictionary. This catches misspellings and case sensitivity-related errors, e.g. a dictionary may have two keys representing the same case-insensitive configuration key."]}, {"name": "configparser.DuplicateSectionError", "path": "library/configparser#configparser.DuplicateSectionError", "type": "File Formats", "text": ["Exception raised if add_section() is called with the name of a section that is already present or in strict parsers when a section if found more than once in a single input file, string or dictionary.", "New in version 3.2: Optional source and lineno attributes and arguments to __init__() were added."]}, {"name": "configparser.Error", "path": "library/configparser#configparser.Error", "type": "File Formats", "text": ["Base class for all other configparser exceptions."]}, {"name": "configparser.ExtendedInterpolation", "path": "library/configparser#configparser.ExtendedInterpolation", "type": "File Formats", "text": ["An alternative handler for interpolation which implements a more advanced syntax, used for instance in zc.buildout. Extended interpolation is using ${section:option} to denote a value from a foreign section. Interpolation can span multiple levels. For convenience, if the section: part is omitted, interpolation defaults to the current section (and possibly the default values from the special section).", "For example, the configuration specified above with basic interpolation, would look like this with extended interpolation:", "Values from other sections can be fetched as well:"]}, {"name": "configparser.InterpolationDepthError", "path": "library/configparser#configparser.InterpolationDepthError", "type": "File Formats", "text": ["Exception raised when string interpolation cannot be completed because the number of iterations exceeds MAX_INTERPOLATION_DEPTH. Subclass of InterpolationError."]}, {"name": "configparser.InterpolationError", "path": "library/configparser#configparser.InterpolationError", "type": "File Formats", "text": ["Base class for exceptions raised when problems occur performing string interpolation."]}, {"name": "configparser.InterpolationMissingOptionError", "path": "library/configparser#configparser.InterpolationMissingOptionError", "type": "File Formats", "text": ["Exception raised when an option referenced from a value does not exist. Subclass of InterpolationError."]}, {"name": "configparser.InterpolationSyntaxError", "path": "library/configparser#configparser.InterpolationSyntaxError", "type": "File Formats", "text": ["Exception raised when the source text into which substitutions are made does not conform to the required syntax. Subclass of InterpolationError."]}, {"name": "configparser.MAX_INTERPOLATION_DEPTH", "path": "library/configparser#configparser.MAX_INTERPOLATION_DEPTH", "type": "File Formats", "text": ["The maximum depth for recursive interpolation for get() when the raw parameter is false. This is relevant only when the default interpolation is used."]}, {"name": "configparser.MissingSectionHeaderError", "path": "library/configparser#configparser.MissingSectionHeaderError", "type": "File Formats", "text": ["Exception raised when attempting to parse a file which has no section headers."]}, {"name": "configparser.NoOptionError", "path": "library/configparser#configparser.NoOptionError", "type": "File Formats", "text": ["Exception raised when a specified option is not found in the specified section."]}, {"name": "configparser.NoSectionError", "path": "library/configparser#configparser.NoSectionError", "type": "File Formats", "text": ["Exception raised when a specified section is not found."]}, {"name": "configparser.ParsingError", "path": "library/configparser#configparser.ParsingError", "type": "File Formats", "text": ["Exception raised when errors occur attempting to parse a file.", "Changed in version 3.2: The filename attribute and __init__() argument were renamed to source for consistency."]}, {"name": "configparser.RawConfigParser", "path": "library/configparser#configparser.RawConfigParser", "type": "File Formats", "text": ["Legacy variant of the ConfigParser. It has interpolation disabled by default and allows for non-string section names, option names, and values via its unsafe add_section and set methods, as well as the legacy defaults= keyword argument handling.", "Changed in version 3.8: The default dict_type is dict, since it now preserves insertion order.", "Note", "Consider using ConfigParser instead which checks types of the values to be stored internally. If you don\u2019t want interpolation, you can use ConfigParser(interpolation=None).", "Add a section named section to the instance. If a section by the given name already exists, DuplicateSectionError is raised. If the default section name is passed, ValueError is raised.", "Type of section is not checked which lets users create non-string named sections. This behaviour is unsupported and may cause internal errors.", "If the given section exists, set the given option to the specified value; otherwise raise NoSectionError. While it is possible to use RawConfigParser (or ConfigParser with raw parameters set to true) for internal storage of non-string values, full functionality (including interpolation and output to files) can only be achieved using string values.", "This method lets users assign non-string values to keys internally. This behaviour is unsupported and will cause errors when attempting to write to a file or get it in non-raw mode. Use the mapping protocol API which does not allow such assignments to take place."]}, {"name": "configparser.RawConfigParser.add_section()", "path": "library/configparser#configparser.RawConfigParser.add_section", "type": "File Formats", "text": ["Add a section named section to the instance. If a section by the given name already exists, DuplicateSectionError is raised. If the default section name is passed, ValueError is raised.", "Type of section is not checked which lets users create non-string named sections. This behaviour is unsupported and may cause internal errors."]}, {"name": "configparser.RawConfigParser.set()", "path": "library/configparser#configparser.RawConfigParser.set", "type": "File Formats", "text": ["If the given section exists, set the given option to the specified value; otherwise raise NoSectionError. While it is possible to use RawConfigParser (or ConfigParser with raw parameters set to true) for internal storage of non-string values, full functionality (including interpolation and output to files) can only be achieved using string values.", "This method lets users assign non-string values to keys internally. This behaviour is unsupported and will cause errors when attempting to write to a file or get it in non-raw mode. Use the mapping protocol API which does not allow such assignments to take place."]}, {"name": "ConnectionAbortedError", "path": "library/exceptions#ConnectionAbortedError", "type": "Built-in Exceptions", "text": ["A subclass of ConnectionError, raised when a connection attempt is aborted by the peer. Corresponds to errno ECONNABORTED."]}, {"name": "ConnectionError", "path": "library/exceptions#ConnectionError", "type": "Built-in Exceptions", "text": ["A base class for connection-related issues.", "Subclasses are BrokenPipeError, ConnectionAbortedError, ConnectionRefusedError and ConnectionResetError."]}, {"name": "ConnectionRefusedError", "path": "library/exceptions#ConnectionRefusedError", "type": "Built-in Exceptions", "text": ["A subclass of ConnectionError, raised when a connection attempt is refused by the peer. Corresponds to errno ECONNREFUSED."]}, {"name": "ConnectionResetError", "path": "library/exceptions#ConnectionResetError", "type": "Built-in Exceptions", "text": ["A subclass of ConnectionError, raised when a connection is reset by the peer. Corresponds to errno ECONNRESET."]}, {"name": "Constants", "path": "library/constants", "type": "Built-in Constants", "text": ["A small number of constants live in the built-in namespace. They are:", "The false value of the bool type. Assignments to False are illegal and raise a SyntaxError.", "The true value of the bool type. Assignments to True are illegal and raise a SyntaxError.", "The sole value of the type NoneType. None is frequently used to represent the absence of a value, as when default arguments are not passed to a function. Assignments to None are illegal and raise a SyntaxError.", "Special value which should be returned by the binary special methods (e.g. __eq__(), __lt__(), __add__(), __rsub__(), etc.) to indicate that the operation is not implemented with respect to the other type; may be returned by the in-place binary special methods (e.g. __imul__(), __iand__(), etc.) for the same purpose. It should not be evaluated in a boolean context.", "Note", "When a binary (or in-place) method returns NotImplemented the interpreter will try the reflected operation on the other type (or some other fallback, depending on the operator). If all attempts return NotImplemented, the interpreter will raise an appropriate exception. Incorrectly returning NotImplemented will result in a misleading error message or the NotImplemented value being returned to Python code.", "See Implementing the arithmetic operations for examples.", "Note", "NotImplementedError and NotImplemented are not interchangeable, even though they have similar names and purposes. See NotImplementedError for details on when to use it.", "Changed in version 3.9: Evaluating NotImplemented in a boolean context is deprecated. While it currently evaluates as true, it will emit a DeprecationWarning. It will raise a TypeError in a future version of Python.", "The same as the ellipsis literal \u201c...\u201d. Special value used mostly in conjunction with extended slicing syntax for user-defined container data types.", "This constant is true if Python was not started with an -O option. See also the assert statement.", "Note", "The names None, False, True and __debug__ cannot be reassigned (assignments to them, even as an attribute name, raise SyntaxError), so they can be considered \u201ctrue\u201d constants.", "The site module (which is imported automatically during startup, except if the -S command-line option is given) adds several constants to the built-in namespace. They are useful for the interactive interpreter shell and should not be used in programs.", "Objects that when printed, print a message like \u201cUse quit() or Ctrl-D (i.e. EOF) to exit\u201d, and when called, raise SystemExit with the specified exit code.", "Objects that when printed or called, print the text of copyright or credits, respectively.", "Object that when printed, prints the message \u201cType license() to see the full license text\u201d, and when called, displays the full license text in a pager-like fashion (one screen at a time)."]}, {"name": "container.__iter__()", "path": "library/stdtypes#container.__iter__", "type": "Built-in Types", "text": ["Return an iterator object. The object is required to support the iterator protocol described below. If a container supports different types of iteration, additional methods can be provided to specifically request iterators for those iteration types. (An example of an object supporting multiple forms of iteration would be a tree structure which supports both breadth-first and depth-first traversal.) This method corresponds to the tp_iter slot of the type structure for Python objects in the Python/C API."]}, {"name": "contextlib", "path": "library/contextlib", "type": "Runtime", "text": ["Source code: Lib/contextlib.py", "This module provides utilities for common tasks involving the with statement. For more information see also Context Manager Types and With Statement Context Managers.", "Functions and classes provided:", "An abstract base class for classes that implement object.__enter__() and object.__exit__(). A default implementation for object.__enter__() is provided which returns self while object.__exit__() is an abstract method which by default returns None. See also the definition of Context Manager Types.", "New in version 3.6.", "An abstract base class for classes that implement object.__aenter__() and object.__aexit__(). A default implementation for object.__aenter__() is provided which returns self while object.__aexit__() is an abstract method which by default returns None. See also the definition of Asynchronous Context Managers.", "New in version 3.7.", "This function is a decorator that can be used to define a factory function for with statement context managers, without needing to create a class or separate __enter__() and __exit__() methods.", "While many objects natively support use in with statements, sometimes a resource needs to be managed that isn\u2019t a context manager in its own right, and doesn\u2019t implement a close() method for use with contextlib.closing", "An abstract example would be the following to ensure correct resource management:", "The function being decorated must return a generator-iterator when called. This iterator must yield exactly one value, which will be bound to the targets in the with statement\u2019s as clause, if any.", "At the point where the generator yields, the block nested in the with statement is executed. The generator is then resumed after the block is exited. If an unhandled exception occurs in the block, it is reraised inside the generator at the point where the yield occurred. Thus, you can use a try\u2026except\u2026finally statement to trap the error (if any), or ensure that some cleanup takes place. If an exception is trapped merely in order to log it or to perform some action (rather than to suppress it entirely), the generator must reraise that exception. Otherwise the generator context manager will indicate to the with statement that the exception has been handled, and execution will resume with the statement immediately following the with statement.", "contextmanager() uses ContextDecorator so the context managers it creates can be used as decorators as well as in with statements. When used as a decorator, a new generator instance is implicitly created on each function call (this allows the otherwise \u201cone-shot\u201d context managers created by contextmanager() to meet the requirement that context managers support multiple invocations in order to be used as decorators).", "Changed in version 3.2: Use of ContextDecorator.", "Similar to contextmanager(), but creates an asynchronous context manager.", "This function is a decorator that can be used to define a factory function for async with statement asynchronous context managers, without needing to create a class or separate __aenter__() and __aexit__() methods. It must be applied to an asynchronous generator function.", "A simple example:", "New in version 3.7.", "Return a context manager that closes thing upon completion of the block. This is basically equivalent to:", "And lets you write code like this:", "without needing to explicitly close page. Even if an error occurs, page.close() will be called when the with block is exited.", "Return a context manager that returns enter_result from __enter__, but otherwise does nothing. It is intended to be used as a stand-in for an optional context manager, for example:", "An example using enter_result:", "New in version 3.7.", "Return a context manager that suppresses any of the specified exceptions if they occur in the body of a with statement and then resumes execution with the first statement following the end of the with statement.", "As with any other mechanism that completely suppresses exceptions, this context manager should be used only to cover very specific errors where silently continuing with program execution is known to be the right thing to do.", "For example:", "This code is equivalent to:", "This context manager is reentrant.", "New in version 3.4.", "Context manager for temporarily redirecting sys.stdout to another file or file-like object.", "This tool adds flexibility to existing functions or classes whose output is hardwired to stdout.", "For example, the output of help() normally is sent to sys.stdout. You can capture that output in a string by redirecting the output to an io.StringIO object:", "To send the output of help() to a file on disk, redirect the output to a regular file:", "To send the output of help() to sys.stderr:", "Note that the global side effect on sys.stdout means that this context manager is not suitable for use in library code and most threaded applications. It also has no effect on the output of subprocesses. However, it is still a useful approach for many utility scripts.", "This context manager is reentrant.", "New in version 3.4.", "Similar to redirect_stdout() but redirecting sys.stderr to another file or file-like object.", "This context manager is reentrant.", "New in version 3.5.", "A base class that enables a context manager to also be used as a decorator.", "Context managers inheriting from ContextDecorator have to implement __enter__ and __exit__ as normal. __exit__ retains its optional exception handling even when used as a decorator.", "ContextDecorator is used by contextmanager(), so you get this functionality automatically.", "Example of ContextDecorator:", "This change is just syntactic sugar for any construct of the following form:", "ContextDecorator lets you instead write:", "It makes it clear that the cm applies to the whole function, rather than just a piece of it (and saving an indentation level is nice, too).", "Existing context managers that already have a base class can be extended by using ContextDecorator as a mixin class:", "Note", "As the decorated function must be able to be called multiple times, the underlying context manager must support use in multiple with statements. If this is not the case, then the original construct with the explicit with statement inside the function should be used.", "New in version 3.2.", "A context manager that is designed to make it easy to programmatically combine other context managers and cleanup functions, especially those that are optional or otherwise driven by input data.", "For example, a set of files may easily be handled in a single with statement as follows:", "Each instance maintains a stack of registered callbacks that are called in reverse order when the instance is closed (either explicitly or implicitly at the end of a with statement). Note that callbacks are not invoked implicitly when the context stack instance is garbage collected.", "This stack model is used so that context managers that acquire their resources in their __init__ method (such as file objects) can be handled correctly.", "Since registered callbacks are invoked in the reverse order of registration, this ends up behaving as if multiple nested with statements had been used with the registered set of callbacks. This even extends to exception handling - if an inner callback suppresses or replaces an exception, then outer callbacks will be passed arguments based on that updated state.", "This is a relatively low level API that takes care of the details of correctly unwinding the stack of exit callbacks. It provides a suitable foundation for higher level context managers that manipulate the exit stack in application specific ways.", "New in version 3.3.", "Enters a new context manager and adds its __exit__() method to the callback stack. The return value is the result of the context manager\u2019s own __enter__() method.", "These context managers may suppress exceptions just as they normally would if used directly as part of a with statement.", "Adds a context manager\u2019s __exit__() method to the callback stack.", "As __enter__ is not invoked, this method can be used to cover part of an __enter__() implementation with a context manager\u2019s own __exit__() method.", "If passed an object that is not a context manager, this method assumes it is a callback with the same signature as a context manager\u2019s __exit__() method and adds it directly to the callback stack.", "By returning true values, these callbacks can suppress exceptions the same way context manager __exit__() methods can.", "The passed in object is returned from the function, allowing this method to be used as a function decorator.", "Accepts an arbitrary callback function and arguments and adds it to the callback stack.", "Unlike the other methods, callbacks added this way cannot suppress exceptions (as they are never passed the exception details).", "The passed in callback is returned from the function, allowing this method to be used as a function decorator.", "Transfers the callback stack to a fresh ExitStack instance and returns it. No callbacks are invoked by this operation - instead, they will now be invoked when the new stack is closed (either explicitly or implicitly at the end of a with statement).", "For example, a group of files can be opened as an \u201call or nothing\u201d operation as follows:", "Immediately unwinds the callback stack, invoking callbacks in the reverse order of registration. For any context managers and exit callbacks registered, the arguments passed in will indicate that no exception occurred.", "An asynchronous context manager, similar to ExitStack, that supports combining both synchronous and asynchronous context managers, as well as having coroutines for cleanup logic.", "The close() method is not implemented, aclose() must be used instead.", "Similar to enter_context() but expects an asynchronous context manager.", "Similar to push() but expects either an asynchronous context manager or a coroutine function.", "Similar to callback() but expects a coroutine function.", "Similar to close() but properly handles awaitables.", "Continuing the example for asynccontextmanager():", "New in version 3.7.", "This section describes some examples and recipes for making effective use of the tools provided by contextlib.", "The primary use case for ExitStack is the one given in the class documentation: supporting a variable number of context managers and other cleanup operations in a single with statement. The variability may come from the number of context managers needed being driven by user input (such as opening a user specified collection of files), or from some of the context managers being optional:", "As shown, ExitStack also makes it quite easy to use with statements to manage arbitrary resources that don\u2019t natively support the context management protocol.", "It is occasionally desirable to catch exceptions from an __enter__ method implementation, without inadvertently catching exceptions from the with statement body or the context manager\u2019s __exit__ method. By using ExitStack the steps in the context management protocol can be separated slightly in order to allow this:", "Actually needing to do this is likely to indicate that the underlying API should be providing a direct resource management interface for use with try/except/finally statements, but not all APIs are well designed in that regard. When a context manager is the only resource management API provided, then ExitStack can make it easier to handle various situations that can\u2019t be handled directly in a with statement.", "As noted in the documentation of ExitStack.push(), this method can be useful in cleaning up an already allocated resource if later steps in the __enter__() implementation fail.", "Here\u2019s an example of doing this for a context manager that accepts resource acquisition and release functions, along with an optional validation function, and maps them to the context management protocol:", "A pattern you will sometimes see is a try-finally statement with a flag variable to indicate whether or not the body of the finally clause should be executed. In its simplest form (that can\u2019t already be handled just by using an except clause instead), it looks something like this:", "As with any try statement based code, this can cause problems for development and review, because the setup code and the cleanup code can end up being separated by arbitrarily long sections of code.", "ExitStack makes it possible to instead register a callback for execution at the end of a with statement, and then later decide to skip executing that callback:", "This allows the intended cleanup up behaviour to be made explicit up front, rather than requiring a separate flag variable.", "If a particular application uses this pattern a lot, it can be simplified even further by means of a small helper class:", "If the resource cleanup isn\u2019t already neatly bundled into a standalone function, then it is still possible to use the decorator form of ExitStack.callback() to declare the resource cleanup in advance:", "Due to the way the decorator protocol works, a callback function declared this way cannot take any parameters. Instead, any resources to be released must be accessed as closure variables.", "ContextDecorator makes it possible to use a context manager in both an ordinary with statement and also as a function decorator.", "For example, it is sometimes useful to wrap functions or groups of statements with a logger that can track the time of entry and time of exit. Rather than writing both a function decorator and a context manager for the task, inheriting from ContextDecorator provides both capabilities in a single definition:", "Instances of this class can be used as both a context manager:", "And also as a function decorator:", "Note that there is one additional limitation when using context managers as function decorators: there\u2019s no way to access the return value of __enter__(). If that value is needed, then it is still necessary to use an explicit with statement.", "See also", "The specification, background, and examples for the Python with statement.", "Most context managers are written in a way that means they can only be used effectively in a with statement once. These single use context managers must be created afresh each time they\u2019re used - attempting to use them a second time will trigger an exception or otherwise not work correctly.", "This common limitation means that it is generally advisable to create context managers directly in the header of the with statement where they are used (as shown in all of the usage examples above).", "Files are an example of effectively single use context managers, since the first with statement will close the file, preventing any further IO operations using that file object.", "Context managers created using contextmanager() are also single use context managers, and will complain about the underlying generator failing to yield if an attempt is made to use them a second time:", "More sophisticated context managers may be \u201creentrant\u201d. These context managers can not only be used in multiple with statements, but may also be used inside a with statement that is already using the same context manager.", "threading.RLock is an example of a reentrant context manager, as are suppress() and redirect_stdout(). Here\u2019s a very simple example of reentrant use:", "Real world examples of reentrancy are more likely to involve multiple functions calling each other and hence be far more complicated than this example.", "Note also that being reentrant is not the same thing as being thread safe. redirect_stdout(), for example, is definitely not thread safe, as it makes a global modification to the system state by binding sys.stdout to a different stream.", "Distinct from both single use and reentrant context managers are \u201creusable\u201d context managers (or, to be completely explicit, \u201creusable, but not reentrant\u201d context managers, since reentrant context managers are also reusable). These context managers support being used multiple times, but will fail (or otherwise not work correctly) if the specific context manager instance has already been used in a containing with statement.", "threading.Lock is an example of a reusable, but not reentrant, context manager (for a reentrant lock, it is necessary to use threading.RLock instead).", "Another example of a reusable, but not reentrant, context manager is ExitStack, as it invokes all currently registered callbacks when leaving any with statement, regardless of where those callbacks were added:", "As the output from the example shows, reusing a single stack object across multiple with statements works correctly, but attempting to nest them will cause the stack to be cleared at the end of the innermost with statement, which is unlikely to be desirable behaviour.", "Using separate ExitStack instances instead of reusing a single instance avoids that problem:"]}, {"name": "contextlib.AbstractAsyncContextManager", "path": "library/contextlib#contextlib.AbstractAsyncContextManager", "type": "Runtime", "text": ["An abstract base class for classes that implement object.__aenter__() and object.__aexit__(). A default implementation for object.__aenter__() is provided which returns self while object.__aexit__() is an abstract method which by default returns None. See also the definition of Asynchronous Context Managers.", "New in version 3.7."]}, {"name": "contextlib.AbstractContextManager", "path": "library/contextlib#contextlib.AbstractContextManager", "type": "Runtime", "text": ["An abstract base class for classes that implement object.__enter__() and object.__exit__(). A default implementation for object.__enter__() is provided which returns self while object.__exit__() is an abstract method which by default returns None. See also the definition of Context Manager Types.", "New in version 3.6."]}, {"name": "contextlib.asynccontextmanager()", "path": "library/contextlib#contextlib.asynccontextmanager", "type": "Runtime", "text": ["Similar to contextmanager(), but creates an asynchronous context manager.", "This function is a decorator that can be used to define a factory function for async with statement asynchronous context managers, without needing to create a class or separate __aenter__() and __aexit__() methods. It must be applied to an asynchronous generator function.", "A simple example:", "New in version 3.7."]}, {"name": "contextlib.AsyncExitStack", "path": "library/contextlib#contextlib.AsyncExitStack", "type": "Runtime", "text": ["An asynchronous context manager, similar to ExitStack, that supports combining both synchronous and asynchronous context managers, as well as having coroutines for cleanup logic.", "The close() method is not implemented, aclose() must be used instead.", "Similar to enter_context() but expects an asynchronous context manager.", "Similar to push() but expects either an asynchronous context manager or a coroutine function.", "Similar to callback() but expects a coroutine function.", "Similar to close() but properly handles awaitables.", "Continuing the example for asynccontextmanager():", "New in version 3.7."]}, {"name": "contextlib.AsyncExitStack.aclose()", "path": "library/contextlib#contextlib.AsyncExitStack.aclose", "type": "Runtime", "text": ["Similar to close() but properly handles awaitables."]}, {"name": "contextlib.AsyncExitStack.enter_async_context()", "path": "library/contextlib#contextlib.AsyncExitStack.enter_async_context", "type": "Runtime", "text": ["Similar to enter_context() but expects an asynchronous context manager."]}, {"name": "contextlib.AsyncExitStack.push_async_callback()", "path": "library/contextlib#contextlib.AsyncExitStack.push_async_callback", "type": "Runtime", "text": ["Similar to callback() but expects a coroutine function."]}, {"name": "contextlib.AsyncExitStack.push_async_exit()", "path": "library/contextlib#contextlib.AsyncExitStack.push_async_exit", "type": "Runtime", "text": ["Similar to push() but expects either an asynchronous context manager or a coroutine function."]}, {"name": "contextlib.closing()", "path": "library/contextlib#contextlib.closing", "type": "Runtime", "text": ["Return a context manager that closes thing upon completion of the block. This is basically equivalent to:", "And lets you write code like this:", "without needing to explicitly close page. Even if an error occurs, page.close() will be called when the with block is exited."]}, {"name": "contextlib.ContextDecorator", "path": "library/contextlib#contextlib.ContextDecorator", "type": "Runtime", "text": ["A base class that enables a context manager to also be used as a decorator.", "Context managers inheriting from ContextDecorator have to implement __enter__ and __exit__ as normal. __exit__ retains its optional exception handling even when used as a decorator.", "ContextDecorator is used by contextmanager(), so you get this functionality automatically.", "Example of ContextDecorator:", "This change is just syntactic sugar for any construct of the following form:", "ContextDecorator lets you instead write:", "It makes it clear that the cm applies to the whole function, rather than just a piece of it (and saving an indentation level is nice, too).", "Existing context managers that already have a base class can be extended by using ContextDecorator as a mixin class:", "Note", "As the decorated function must be able to be called multiple times, the underlying context manager must support use in multiple with statements. If this is not the case, then the original construct with the explicit with statement inside the function should be used.", "New in version 3.2."]}, {"name": "contextlib.contextmanager()", "path": "library/contextlib#contextlib.contextmanager", "type": "Runtime", "text": ["This function is a decorator that can be used to define a factory function for with statement context managers, without needing to create a class or separate __enter__() and __exit__() methods.", "While many objects natively support use in with statements, sometimes a resource needs to be managed that isn\u2019t a context manager in its own right, and doesn\u2019t implement a close() method for use with contextlib.closing", "An abstract example would be the following to ensure correct resource management:", "The function being decorated must return a generator-iterator when called. This iterator must yield exactly one value, which will be bound to the targets in the with statement\u2019s as clause, if any.", "At the point where the generator yields, the block nested in the with statement is executed. The generator is then resumed after the block is exited. If an unhandled exception occurs in the block, it is reraised inside the generator at the point where the yield occurred. Thus, you can use a try\u2026except\u2026finally statement to trap the error (if any), or ensure that some cleanup takes place. If an exception is trapped merely in order to log it or to perform some action (rather than to suppress it entirely), the generator must reraise that exception. Otherwise the generator context manager will indicate to the with statement that the exception has been handled, and execution will resume with the statement immediately following the with statement.", "contextmanager() uses ContextDecorator so the context managers it creates can be used as decorators as well as in with statements. When used as a decorator, a new generator instance is implicitly created on each function call (this allows the otherwise \u201cone-shot\u201d context managers created by contextmanager() to meet the requirement that context managers support multiple invocations in order to be used as decorators).", "Changed in version 3.2: Use of ContextDecorator."]}, {"name": "contextlib.ExitStack", "path": "library/contextlib#contextlib.ExitStack", "type": "Runtime", "text": ["A context manager that is designed to make it easy to programmatically combine other context managers and cleanup functions, especially those that are optional or otherwise driven by input data.", "For example, a set of files may easily be handled in a single with statement as follows:", "Each instance maintains a stack of registered callbacks that are called in reverse order when the instance is closed (either explicitly or implicitly at the end of a with statement). Note that callbacks are not invoked implicitly when the context stack instance is garbage collected.", "This stack model is used so that context managers that acquire their resources in their __init__ method (such as file objects) can be handled correctly.", "Since registered callbacks are invoked in the reverse order of registration, this ends up behaving as if multiple nested with statements had been used with the registered set of callbacks. This even extends to exception handling - if an inner callback suppresses or replaces an exception, then outer callbacks will be passed arguments based on that updated state.", "This is a relatively low level API that takes care of the details of correctly unwinding the stack of exit callbacks. It provides a suitable foundation for higher level context managers that manipulate the exit stack in application specific ways.", "New in version 3.3.", "Enters a new context manager and adds its __exit__() method to the callback stack. The return value is the result of the context manager\u2019s own __enter__() method.", "These context managers may suppress exceptions just as they normally would if used directly as part of a with statement.", "Adds a context manager\u2019s __exit__() method to the callback stack.", "As __enter__ is not invoked, this method can be used to cover part of an __enter__() implementation with a context manager\u2019s own __exit__() method.", "If passed an object that is not a context manager, this method assumes it is a callback with the same signature as a context manager\u2019s __exit__() method and adds it directly to the callback stack.", "By returning true values, these callbacks can suppress exceptions the same way context manager __exit__() methods can.", "The passed in object is returned from the function, allowing this method to be used as a function decorator.", "Accepts an arbitrary callback function and arguments and adds it to the callback stack.", "Unlike the other methods, callbacks added this way cannot suppress exceptions (as they are never passed the exception details).", "The passed in callback is returned from the function, allowing this method to be used as a function decorator.", "Transfers the callback stack to a fresh ExitStack instance and returns it. No callbacks are invoked by this operation - instead, they will now be invoked when the new stack is closed (either explicitly or implicitly at the end of a with statement).", "For example, a group of files can be opened as an \u201call or nothing\u201d operation as follows:", "Immediately unwinds the callback stack, invoking callbacks in the reverse order of registration. For any context managers and exit callbacks registered, the arguments passed in will indicate that no exception occurred."]}, {"name": "contextlib.ExitStack.callback()", "path": "library/contextlib#contextlib.ExitStack.callback", "type": "Runtime", "text": ["Accepts an arbitrary callback function and arguments and adds it to the callback stack.", "Unlike the other methods, callbacks added this way cannot suppress exceptions (as they are never passed the exception details).", "The passed in callback is returned from the function, allowing this method to be used as a function decorator."]}, {"name": "contextlib.ExitStack.close()", "path": "library/contextlib#contextlib.ExitStack.close", "type": "Runtime", "text": ["Immediately unwinds the callback stack, invoking callbacks in the reverse order of registration. For any context managers and exit callbacks registered, the arguments passed in will indicate that no exception occurred."]}, {"name": "contextlib.ExitStack.enter_context()", "path": "library/contextlib#contextlib.ExitStack.enter_context", "type": "Runtime", "text": ["Enters a new context manager and adds its __exit__() method to the callback stack. The return value is the result of the context manager\u2019s own __enter__() method.", "These context managers may suppress exceptions just as they normally would if used directly as part of a with statement."]}, {"name": "contextlib.ExitStack.pop_all()", "path": "library/contextlib#contextlib.ExitStack.pop_all", "type": "Runtime", "text": ["Transfers the callback stack to a fresh ExitStack instance and returns it. No callbacks are invoked by this operation - instead, they will now be invoked when the new stack is closed (either explicitly or implicitly at the end of a with statement).", "For example, a group of files can be opened as an \u201call or nothing\u201d operation as follows:"]}, {"name": "contextlib.ExitStack.push()", "path": "library/contextlib#contextlib.ExitStack.push", "type": "Runtime", "text": ["Adds a context manager\u2019s __exit__() method to the callback stack.", "As __enter__ is not invoked, this method can be used to cover part of an __enter__() implementation with a context manager\u2019s own __exit__() method.", "If passed an object that is not a context manager, this method assumes it is a callback with the same signature as a context manager\u2019s __exit__() method and adds it directly to the callback stack.", "By returning true values, these callbacks can suppress exceptions the same way context manager __exit__() methods can.", "The passed in object is returned from the function, allowing this method to be used as a function decorator."]}, {"name": "contextlib.nullcontext()", "path": "library/contextlib#contextlib.nullcontext", "type": "Runtime", "text": ["Return a context manager that returns enter_result from __enter__, but otherwise does nothing. It is intended to be used as a stand-in for an optional context manager, for example:", "An example using enter_result:", "New in version 3.7."]}, {"name": "contextlib.redirect_stderr()", "path": "library/contextlib#contextlib.redirect_stderr", "type": "Runtime", "text": ["Similar to redirect_stdout() but redirecting sys.stderr to another file or file-like object.", "This context manager is reentrant.", "New in version 3.5."]}, {"name": "contextlib.redirect_stdout()", "path": "library/contextlib#contextlib.redirect_stdout", "type": "Runtime", "text": ["Context manager for temporarily redirecting sys.stdout to another file or file-like object.", "This tool adds flexibility to existing functions or classes whose output is hardwired to stdout.", "For example, the output of help() normally is sent to sys.stdout. You can capture that output in a string by redirecting the output to an io.StringIO object:", "To send the output of help() to a file on disk, redirect the output to a regular file:", "To send the output of help() to sys.stderr:", "Note that the global side effect on sys.stdout means that this context manager is not suitable for use in library code and most threaded applications. It also has no effect on the output of subprocesses. However, it is still a useful approach for many utility scripts.", "This context manager is reentrant.", "New in version 3.4."]}, {"name": "contextlib.suppress()", "path": "library/contextlib#contextlib.suppress", "type": "Runtime", "text": ["Return a context manager that suppresses any of the specified exceptions if they occur in the body of a with statement and then resumes execution with the first statement following the end of the with statement.", "As with any other mechanism that completely suppresses exceptions, this context manager should be used only to cover very specific errors where silently continuing with program execution is known to be the right thing to do.", "For example:", "This code is equivalent to:", "This context manager is reentrant.", "New in version 3.4."]}, {"name": "contextmanager.__enter__()", "path": "library/stdtypes#contextmanager.__enter__", "type": "Built-in Types", "text": ["Enter the runtime context and return either this object or another object related to the runtime context. The value returned by this method is bound to the identifier in the as clause of with statements using this context manager.", "An example of a context manager that returns itself is a file object. File objects return themselves from __enter__() to allow open() to be used as the context expression in a with statement.", "An example of a context manager that returns a related object is the one returned by decimal.localcontext(). These managers set the active decimal context to a copy of the original decimal context and then return the copy. This allows changes to be made to the current decimal context in the body of the with statement without affecting code outside the with statement."]}, {"name": "contextmanager.__exit__()", "path": "library/stdtypes#contextmanager.__exit__", "type": "Built-in Types", "text": ["Exit the runtime context and return a Boolean flag indicating if any exception that occurred should be suppressed. If an exception occurred while executing the body of the with statement, the arguments contain the exception type, value and traceback information. Otherwise, all three arguments are None.", "Returning a true value from this method will cause the with statement to suppress the exception and continue execution with the statement immediately following the with statement. Otherwise the exception continues propagating after this method has finished executing. Exceptions that occur during execution of this method will replace any exception that occurred in the body of the with statement.", "The exception passed in should never be reraised explicitly - instead, this method should return a false value to indicate that the method completed successfully and does not want to suppress the raised exception. This allows context management code to easily detect whether or not an __exit__() method has actually failed."]}, {"name": "contextvars", "path": "library/contextvars", "type": "Concurrent Execution", "text": ["This module provides APIs to manage, store, and access context-local state. The ContextVar class is used to declare and work with Context Variables. The copy_context() function and the Context class should be used to manage the current context in asynchronous frameworks.", "Context managers that have state should use Context Variables instead of threading.local() to prevent their state from bleeding to other code unexpectedly, when used in concurrent code.", "See also PEP 567 for additional details.", "New in version 3.7.", "This class is used to declare a new Context Variable, e.g.:", "The required name parameter is used for introspection and debug purposes.", "The optional keyword-only default parameter is returned by ContextVar.get() when no value for the variable is found in the current context.", "Important: Context Variables should be created at the top module level and never in closures. Context objects hold strong references to context variables which prevents context variables from being properly garbage collected.", "The name of the variable. This is a read-only property.", "New in version 3.7.1.", "Return a value for the context variable for the current context.", "If there is no value for the variable in the current context, the method will:", "Call to set a new value for the context variable in the current context.", "The required value argument is the new value for the context variable.", "Returns a Token object that can be used to restore the variable to its previous value via the ContextVar.reset() method.", "Reset the context variable to the value it had before the ContextVar.set() that created the token was used.", "For example:", "Token objects are returned by the ContextVar.set() method. They can be passed to the ContextVar.reset() method to revert the value of the variable to what it was before the corresponding set.", "A read-only property. Points to the ContextVar object that created the token.", "A read-only property. Set to the value the variable had before the ContextVar.set() method call that created the token. It points to Token.MISSING is the variable was not set before the call.", "A marker object used by Token.old_value.", "Returns a copy of the current Context object.", "The following snippet gets a copy of the current context and prints all variables and their values that are set in it:", "The function has an O(1) complexity, i.e. works equally fast for contexts with a few context variables and for contexts that have a lot of them.", "A mapping of ContextVars to their values.", "Context() creates an empty context with no values in it. To get a copy of the current context use the copy_context() function.", "Context implements the collections.abc.Mapping interface.", "Execute callable(*args, **kwargs) code in the context object the run method is called on. Return the result of the execution or propagate an exception if one occurred.", "Any changes to any context variables that callable makes will be contained in the context object:", "The method raises a RuntimeError when called on the same context object from more than one OS thread, or when called recursively.", "Return a shallow copy of the context object.", "Return True if the context has a value for var set; return False otherwise.", "Return the value of the var ContextVar variable. If the variable is not set in the context object, a KeyError is raised.", "Return the value for var if var has the value in the context object. Return default otherwise. If default is not given, return None.", "Return an iterator over the variables stored in the context object.", "Return the number of variables set in the context object.", "Return a list of all variables in the context object.", "Return a list of all variables\u2019 values in the context object.", "Return a list of 2-tuples containing all variables and their values in the context object.", "Context variables are natively supported in asyncio and are ready to be used without any extra configuration. For example, here is a simple echo server, that uses a context variable to make the address of a remote client available in the Task that handles that client:"]}, {"name": "contextvars.Context", "path": "library/contextvars#contextvars.Context", "type": "Concurrent Execution", "text": ["A mapping of ContextVars to their values.", "Context() creates an empty context with no values in it. To get a copy of the current context use the copy_context() function.", "Context implements the collections.abc.Mapping interface.", "Execute callable(*args, **kwargs) code in the context object the run method is called on. Return the result of the execution or propagate an exception if one occurred.", "Any changes to any context variables that callable makes will be contained in the context object:", "The method raises a RuntimeError when called on the same context object from more than one OS thread, or when called recursively.", "Return a shallow copy of the context object.", "Return True if the context has a value for var set; return False otherwise.", "Return the value of the var ContextVar variable. If the variable is not set in the context object, a KeyError is raised.", "Return the value for var if var has the value in the context object. Return default otherwise. If default is not given, return None.", "Return an iterator over the variables stored in the context object.", "Return the number of variables set in the context object.", "Return a list of all variables in the context object.", "Return a list of all variables\u2019 values in the context object.", "Return a list of 2-tuples containing all variables and their values in the context object."]}, {"name": "contextvars.Context.copy()", "path": "library/contextvars#contextvars.Context.copy", "type": "Concurrent Execution", "text": ["Return a shallow copy of the context object."]}, {"name": "contextvars.Context.get()", "path": "library/contextvars#contextvars.Context.get", "type": "Concurrent Execution", "text": ["Return the value for var if var has the value in the context object. Return default otherwise. If default is not given, return None."]}, {"name": "contextvars.Context.items()", "path": "library/contextvars#contextvars.Context.items", "type": "Concurrent Execution", "text": ["Return a list of 2-tuples containing all variables and their values in the context object."]}, {"name": "contextvars.Context.keys()", "path": "library/contextvars#contextvars.Context.keys", "type": "Concurrent Execution", "text": ["Return a list of all variables in the context object."]}, {"name": "contextvars.Context.run()", "path": "library/contextvars#contextvars.Context.run", "type": "Concurrent Execution", "text": ["Execute callable(*args, **kwargs) code in the context object the run method is called on. Return the result of the execution or propagate an exception if one occurred.", "Any changes to any context variables that callable makes will be contained in the context object:", "The method raises a RuntimeError when called on the same context object from more than one OS thread, or when called recursively."]}, {"name": "contextvars.Context.values()", "path": "library/contextvars#contextvars.Context.values", "type": "Concurrent Execution", "text": ["Return a list of all variables\u2019 values in the context object."]}, {"name": "contextvars.ContextVar", "path": "library/contextvars#contextvars.ContextVar", "type": "Concurrent Execution", "text": ["This class is used to declare a new Context Variable, e.g.:", "The required name parameter is used for introspection and debug purposes.", "The optional keyword-only default parameter is returned by ContextVar.get() when no value for the variable is found in the current context.", "Important: Context Variables should be created at the top module level and never in closures. Context objects hold strong references to context variables which prevents context variables from being properly garbage collected.", "The name of the variable. This is a read-only property.", "New in version 3.7.1.", "Return a value for the context variable for the current context.", "If there is no value for the variable in the current context, the method will:", "Call to set a new value for the context variable in the current context.", "The required value argument is the new value for the context variable.", "Returns a Token object that can be used to restore the variable to its previous value via the ContextVar.reset() method.", "Reset the context variable to the value it had before the ContextVar.set() that created the token was used.", "For example:"]}, {"name": "contextvars.ContextVar.get()", "path": "library/contextvars#contextvars.ContextVar.get", "type": "Concurrent Execution", "text": ["Return a value for the context variable for the current context.", "If there is no value for the variable in the current context, the method will:"]}, {"name": "contextvars.ContextVar.name", "path": "library/contextvars#contextvars.ContextVar.name", "type": "Concurrent Execution", "text": ["The name of the variable. This is a read-only property.", "New in version 3.7.1."]}, {"name": "contextvars.ContextVar.reset()", "path": "library/contextvars#contextvars.ContextVar.reset", "type": "Concurrent Execution", "text": ["Reset the context variable to the value it had before the ContextVar.set() that created the token was used.", "For example:"]}, {"name": "contextvars.ContextVar.set()", "path": "library/contextvars#contextvars.ContextVar.set", "type": "Concurrent Execution", "text": ["Call to set a new value for the context variable in the current context.", "The required value argument is the new value for the context variable.", "Returns a Token object that can be used to restore the variable to its previous value via the ContextVar.reset() method."]}, {"name": "contextvars.contextvars.Token", "path": "library/contextvars#contextvars.contextvars.Token", "type": "Concurrent Execution", "text": ["Token objects are returned by the ContextVar.set() method. They can be passed to the ContextVar.reset() method to revert the value of the variable to what it was before the corresponding set.", "A read-only property. Points to the ContextVar object that created the token.", "A read-only property. Set to the value the variable had before the ContextVar.set() method call that created the token. It points to Token.MISSING is the variable was not set before the call.", "A marker object used by Token.old_value."]}, {"name": "contextvars.contextvars.Token.Token.MISSING", "path": "library/contextvars#contextvars.contextvars.Token.Token.MISSING", "type": "Concurrent Execution", "text": ["A marker object used by Token.old_value."]}, {"name": "contextvars.contextvars.Token.Token.old_value", "path": "library/contextvars#contextvars.contextvars.Token.Token.old_value", "type": "Concurrent Execution", "text": ["A read-only property. Set to the value the variable had before the ContextVar.set() method call that created the token. It points to Token.MISSING is the variable was not set before the call."]}, {"name": "contextvars.contextvars.Token.Token.var", "path": "library/contextvars#contextvars.contextvars.Token.Token.var", "type": "Concurrent Execution", "text": ["A read-only property. Points to the ContextVar object that created the token."]}, {"name": "contextvars.copy_context()", "path": "library/contextvars#contextvars.copy_context", "type": "Concurrent Execution", "text": ["Returns a copy of the current Context object.", "The following snippet gets a copy of the current context and prints all variables and their values that are set in it:", "The function has an O(1) complexity, i.e. works equally fast for contexts with a few context variables and for contexts that have a lot of them."]}, {"name": "copy", "path": "library/copy", "type": "Data Types", "text": ["Source code: Lib/copy.py", "Assignment statements in Python do not copy objects, they create bindings between a target and an object. For collections that are mutable or contain mutable items, a copy is sometimes needed so one can change one copy without changing the other. This module provides generic shallow and deep copy operations (explained below).", "Interface summary:", "Return a shallow copy of x.", "Return a deep copy of x.", "Raised for module specific errors.", "The difference between shallow and deep copying is only relevant for compound objects (objects that contain other objects, like lists or class instances):", "Two problems often exist with deep copy operations that don\u2019t exist with shallow copy operations:", "The deepcopy() function avoids these problems by:", "This module does not copy types like module, method, stack trace, stack frame, file, socket, window, array, or any similar types. It does \u201ccopy\u201d functions and classes (shallow and deeply), by returning the original object unchanged; this is compatible with the way these are treated by the pickle module.", "Shallow copies of dictionaries can be made using dict.copy(), and of lists by assigning a slice of the entire list, for example, copied_list = original_list[:].", "Classes can use the same interfaces to control copying that they use to control pickling. See the description of module pickle for information on these methods. In fact, the copy module uses the registered pickle functions from the copyreg module.", "In order for a class to define its own copy implementation, it can define special methods __copy__() and __deepcopy__(). The former is called to implement the shallow copy operation; no additional arguments are passed. The latter is called to implement the deep copy operation; it is passed one argument, the memo dictionary. If the __deepcopy__() implementation needs to make a deep copy of a component, it should call the deepcopy() function with the component as first argument and the memo dictionary as second argument.", "See also", "Discussion of the special methods used to support object state retrieval and restoration."]}, {"name": "copy.copy()", "path": "library/copy#copy.copy", "type": "Data Types", "text": ["Return a shallow copy of x."]}, {"name": "copy.deepcopy()", "path": "library/copy#copy.deepcopy", "type": "Data Types", "text": ["Return a deep copy of x."]}, {"name": "copy.Error", "path": "library/copy#copy.Error", "type": "Data Types", "text": ["Raised for module specific errors."]}, {"name": "copyreg", "path": "library/copyreg", "type": "Data Persistence", "text": ["Source code: Lib/copyreg.py", "The copyreg module offers a way to define functions used while pickling specific objects. The pickle and copy modules use those functions when pickling/copying those objects. The module provides configuration information about object constructors which are not classes. Such constructors may be factory functions or class instances.", "Declares object to be a valid constructor. If object is not callable (and hence not valid as a constructor), raises TypeError.", "Declares that function should be used as a \u201creduction\u201d function for objects of type type. function should return either a string or a tuple containing two or three elements.", "The optional constructor parameter, if provided, is a callable object which can be used to reconstruct the object when called with the tuple of arguments returned by function at pickling time. TypeError will be raised if object is a class or constructor is not callable.", "See the pickle module for more details on the interface expected of function and constructor. Note that the dispatch_table attribute of a pickler object or subclass of pickle.Pickler can also be used for declaring reduction functions.", "The example below would like to show how to register a pickle function and how it will be used:"]}, {"name": "copyreg.constructor()", "path": "library/copyreg#copyreg.constructor", "type": "Data Persistence", "text": ["Declares object to be a valid constructor. If object is not callable (and hence not valid as a constructor), raises TypeError."]}, {"name": "copyreg.pickle()", "path": "library/copyreg#copyreg.pickle", "type": "Data Persistence", "text": ["Declares that function should be used as a \u201creduction\u201d function for objects of type type. function should return either a string or a tuple containing two or three elements.", "The optional constructor parameter, if provided, is a callable object which can be used to reconstruct the object when called with the tuple of arguments returned by function at pickling time. TypeError will be raised if object is a class or constructor is not callable.", "See the pickle module for more details on the interface expected of function and constructor. Note that the dispatch_table attribute of a pickler object or subclass of pickle.Pickler can also be used for declaring reduction functions."]}, {"name": "copyright", "path": "library/constants#copyright", "type": "Built-in Constants", "text": ["Objects that when printed or called, print the text of copyright or credits, respectively."]}, {"name": "Coroutines and Tasks", "path": "library/asyncio-task", "type": "Asynchronous I/O", "text": ["This section outlines high-level asyncio APIs to work with coroutines and Tasks.", "Coroutines declared with the async/await syntax is the preferred way of writing asyncio applications. For example, the following snippet of code (requires Python 3.7+) prints \u201chello\u201d, waits 1 second, and then prints \u201cworld\u201d:", "Note that simply calling a coroutine will not schedule it to be executed:", "To actually run a coroutine, asyncio provides three main mechanisms:", "Awaiting on a coroutine. The following snippet of code will print \u201chello\u201d after waiting for 1 second, and then print \u201cworld\u201d after waiting for another 2 seconds:", "Expected output:", "The asyncio.create_task() function to run coroutines concurrently as asyncio Tasks.", "Let\u2019s modify the above example and run two say_after coroutines concurrently:", "Note that expected output now shows that the snippet runs 1 second faster than before:", "We say that an object is an awaitable object if it can be used in an await expression. Many asyncio APIs are designed to accept awaitables.", "There are three main types of awaitable objects: coroutines, Tasks, and Futures.", "Python coroutines are awaitables and therefore can be awaited from other coroutines:", "Important", "In this documentation the term \u201ccoroutine\u201d can be used for two closely related concepts:", "asyncio also supports legacy generator-based coroutines.", "Tasks are used to schedule coroutines concurrently.", "When a coroutine is wrapped into a Task with functions like asyncio.create_task() the coroutine is automatically scheduled to run soon:", "A Future is a special low-level awaitable object that represents an eventual result of an asynchronous operation.", "When a Future object is awaited it means that the coroutine will wait until the Future is resolved in some other place.", "Future objects in asyncio are needed to allow callback-based code to be used with async/await.", "Normally there is no need to create Future objects at the application level code.", "Future objects, sometimes exposed by libraries and some asyncio APIs, can be awaited:", "A good example of a low-level function that returns a Future object is loop.run_in_executor().", "Execute the coroutine coro and return the result.", "This function runs the passed coroutine, taking care of managing the asyncio event loop, finalizing asynchronous generators, and closing the threadpool.", "This function cannot be called when another asyncio event loop is running in the same thread.", "If debug is True, the event loop will be run in debug mode.", "This function always creates a new event loop and closes it at the end. It should be used as a main entry point for asyncio programs, and should ideally only be called once.", "Example:", "New in version 3.7.", "Changed in version 3.9: Updated to use loop.shutdown_default_executor().", "Note", "The source code for asyncio.run() can be found in Lib/asyncio/runners.py.", "Wrap the coro coroutine into a Task and schedule its execution. Return the Task object.", "If name is not None, it is set as the name of the task using Task.set_name().", "The task is executed in the loop returned by get_running_loop(), RuntimeError is raised if there is no running loop in current thread.", "This function has been added in Python 3.7. Prior to Python 3.7, the low-level asyncio.ensure_future() function can be used instead:", "New in version 3.7.", "Changed in version 3.8: Added the name parameter.", "Block for delay seconds.", "If result is provided, it is returned to the caller when the coroutine completes.", "sleep() always suspends the current task, allowing other tasks to run.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example of coroutine displaying the current date every second for 5 seconds:", "Run awaitable objects in the aws sequence concurrently.", "If any awaitable in aws is a coroutine, it is automatically scheduled as a Task.", "If all awaitables are completed successfully, the result is an aggregate list of returned values. The order of result values corresponds to the order of awaitables in aws.", "If return_exceptions is False (default), the first raised exception is immediately propagated to the task that awaits on gather(). Other awaitables in the aws sequence won\u2019t be cancelled and will continue to run.", "If return_exceptions is True, exceptions are treated the same as successful results, and aggregated in the result list.", "If gather() is cancelled, all submitted awaitables (that have not completed yet) are also cancelled.", "If any Task or Future from the aws sequence is cancelled, it is treated as if it raised CancelledError \u2013 the gather() call is not cancelled in this case. This is to prevent the cancellation of one submitted Task/Future to cause other Tasks/Futures to be cancelled.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example:", "Note", "If return_exceptions is False, cancelling gather() after it has been marked done won\u2019t cancel any submitted awaitables. For instance, gather can be marked done after propagating an exception to the caller, therefore, calling gather.cancel() after catching an exception (raised by one of the awaitables) from gather won\u2019t cancel any other awaitables.", "Changed in version 3.7: If the gather itself is cancelled, the cancellation is propagated regardless of return_exceptions.", "Protect an awaitable object from being cancelled.", "If aw is a coroutine it is automatically scheduled as a Task.", "The statement:", "is equivalent to:", "except that if the coroutine containing it is cancelled, the Task running in something() is not cancelled. From the point of view of something(), the cancellation did not happen. Although its caller is still cancelled, so the \u201cawait\u201d expression still raises a CancelledError.", "If something() is cancelled by other means (i.e. from within itself) that would also cancel shield().", "If it is desired to completely ignore cancellation (not recommended) the shield() function should be combined with a try/except clause, as follows:", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Wait for the aw awaitable to complete with a timeout.", "If aw is a coroutine it is automatically scheduled as a Task.", "timeout can either be None or a float or int number of seconds to wait for. If timeout is None, block until the future completes.", "If a timeout occurs, it cancels the task and raises asyncio.TimeoutError.", "To avoid the task cancellation, wrap it in shield().", "The function will wait until the future is actually cancelled, so the total wait time may exceed the timeout. If an exception happens during cancellation, it is propagated.", "If the wait is cancelled, the future aw is also cancelled.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example:", "Changed in version 3.7: When aw is cancelled due to a timeout, wait_for waits for aw to be cancelled. Previously, it raised asyncio.TimeoutError immediately.", "Run awaitable objects in the aws iterable concurrently and block until the condition specified by return_when.", "The aws iterable must not be empty.", "Returns two sets of Tasks/Futures: (done, pending).", "Usage:", "timeout (a float or int), if specified, can be used to control the maximum number of seconds to wait before returning.", "Note that this function does not raise asyncio.TimeoutError. Futures or Tasks that aren\u2019t done when the timeout occurs are simply returned in the second set.", "return_when indicates when this function should return. It must be one of the following constants:", "Constant", "Description", "FIRST_COMPLETED", "The function will return when any future finishes or is cancelled.", "FIRST_EXCEPTION", "The function will return when any future finishes by raising an exception. If no future raises an exception then it is equivalent to ALL_COMPLETED.", "ALL_COMPLETED", "The function will return when all futures finish or are cancelled.", "Unlike wait_for(), wait() does not cancel the futures when a timeout occurs.", "Deprecated since version 3.8: If any awaitable in aws is a coroutine, it is automatically scheduled as a Task. Passing coroutines objects to wait() directly is deprecated as it leads to confusing behavior.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Note", "wait() schedules coroutines as Tasks automatically and later returns those implicitly created Task objects in (done, pending) sets. Therefore the following code won\u2019t work as expected:", "Here is how the above snippet can be fixed:", "Deprecated since version 3.8, will be removed in version 3.11: Passing coroutine objects to wait() directly is deprecated.", "Run awaitable objects in the aws iterable concurrently. Return an iterator of coroutines. Each coroutine returned can be awaited to get the earliest next result from the iterable of the remaining awaitables.", "Raises asyncio.TimeoutError if the timeout occurs before all Futures are done.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Example:", "Asynchronously run function func in a separate thread.", "Any *args and **kwargs supplied for this function are directly passed to func. Also, the current contextvars.Context is propagated, allowing context variables from the event loop thread to be accessed in the separate thread.", "Return a coroutine that can be awaited to get the eventual result of func.", "This coroutine function is primarily intended to be used for executing IO-bound functions/methods that would otherwise block the event loop if they were ran in the main thread. For example:", "Directly calling blocking_io() in any coroutine would block the event loop for its duration, resulting in an additional 1 second of run time. Instead, by using asyncio.to_thread(), we can run it in a separate thread without blocking the event loop.", "Note", "Due to the GIL, asyncio.to_thread() can typically only be used to make IO-bound functions non-blocking. However, for extension modules that release the GIL or alternative Python implementations that don\u2019t have one, asyncio.to_thread() can also be used for CPU-bound functions.", "New in version 3.9.", "Submit a coroutine to the given event loop. Thread-safe.", "Return a concurrent.futures.Future to wait for the result from another OS thread.", "This function is meant to be called from a different OS thread than the one where the event loop is running. Example:", "If an exception is raised in the coroutine, the returned Future will be notified. It can also be used to cancel the task in the event loop:", "See the concurrency and multithreading section of the documentation.", "Unlike other asyncio functions this function requires the loop argument to be passed explicitly.", "New in version 3.5.1.", "Return the currently running Task instance, or None if no task is running.", "If loop is None get_running_loop() is used to get the current loop.", "New in version 3.7.", "Return a set of not yet finished Task objects run by the loop.", "If loop is None, get_running_loop() is used for getting current loop.", "New in version 3.7.", "A Future-like object that runs a Python coroutine. Not thread-safe.", "Tasks are used to run coroutines in event loops. If a coroutine awaits on a Future, the Task suspends the execution of the coroutine and waits for the completion of the Future. When the Future is done, the execution of the wrapped coroutine resumes.", "Event loops use cooperative scheduling: an event loop runs one Task at a time. While a Task awaits for the completion of a Future, the event loop runs other Tasks, callbacks, or performs IO operations.", "Use the high-level asyncio.create_task() function to create Tasks, or the low-level loop.create_task() or ensure_future() functions. Manual instantiation of Tasks is discouraged.", "To cancel a running Task use the cancel() method. Calling it will cause the Task to throw a CancelledError exception into the wrapped coroutine. If a coroutine is awaiting on a Future object during cancellation, the Future object will be cancelled.", "cancelled() can be used to check if the Task was cancelled. The method returns True if the wrapped coroutine did not suppress the CancelledError exception and was actually cancelled.", "asyncio.Task inherits from Future all of its APIs except Future.set_result() and Future.set_exception().", "Tasks support the contextvars module. When a Task is created it copies the current context and later runs its coroutine in the copied context.", "Changed in version 3.7: Added support for the contextvars module.", "Changed in version 3.8: Added the name parameter.", "Deprecated since version 3.8, will be removed in version 3.10: The loop parameter.", "Request the Task to be cancelled.", "This arranges for a CancelledError exception to be thrown into the wrapped coroutine on the next cycle of the event loop.", "The coroutine then has a chance to clean up or even deny the request by suppressing the exception with a try \u2026 \u2026 except CancelledError \u2026 finally block. Therefore, unlike Future.cancel(), Task.cancel() does not guarantee that the Task will be cancelled, although suppressing cancellation completely is not common and is actively discouraged.", "Changed in version 3.9: Added the msg parameter.", "The following example illustrates how coroutines can intercept the cancellation request:", "Return True if the Task is cancelled.", "The Task is cancelled when the cancellation was requested with cancel() and the wrapped coroutine propagated the CancelledError exception thrown into it.", "Return True if the Task is done.", "A Task is done when the wrapped coroutine either returned a value, raised an exception, or the Task was cancelled.", "Return the result of the Task.", "If the Task is done, the result of the wrapped coroutine is returned (or if the coroutine raised an exception, that exception is re-raised.)", "If the Task has been cancelled, this method raises a CancelledError exception.", "If the Task\u2019s result isn\u2019t yet available, this method raises a InvalidStateError exception.", "Return the exception of the Task.", "If the wrapped coroutine raised an exception that exception is returned. If the wrapped coroutine returned normally this method returns None.", "If the Task has been cancelled, this method raises a CancelledError exception.", "If the Task isn\u2019t done yet, this method raises an InvalidStateError exception.", "Add a callback to be run when the Task is done.", "This method should only be used in low-level callback-based code.", "See the documentation of Future.add_done_callback() for more details.", "Remove callback from the callbacks list.", "This method should only be used in low-level callback-based code.", "See the documentation of Future.remove_done_callback() for more details.", "Return the list of stack frames for this Task.", "If the wrapped coroutine is not done, this returns the stack where it is suspended. If the coroutine has completed successfully or was cancelled, this returns an empty list. If the coroutine was terminated by an exception, this returns the list of traceback frames.", "The frames are always ordered from oldest to newest.", "Only one stack frame is returned for a suspended coroutine.", "The optional limit argument sets the maximum number of frames to return; by default all available frames are returned. The ordering of the returned list differs depending on whether a stack or a traceback is returned: the newest frames of a stack are returned, but the oldest frames of a traceback are returned. (This matches the behavior of the traceback module.)", "Print the stack or traceback for this Task.", "This produces output similar to that of the traceback module for the frames retrieved by get_stack().", "The limit argument is passed to get_stack() directly.", "The file argument is an I/O stream to which the output is written; by default output is written to sys.stderr.", "Return the coroutine object wrapped by the Task.", "New in version 3.8.", "Return the name of the Task.", "If no name has been explicitly assigned to the Task, the default asyncio Task implementation generates a default name during instantiation.", "New in version 3.8.", "Set the name of the Task.", "The value argument can be any object, which is then converted to a string.", "In the default Task implementation, the name will be visible in the repr() output of a task object.", "New in version 3.8.", "Note", "Support for generator-based coroutines is deprecated and is scheduled for removal in Python 3.10.", "Generator-based coroutines predate async/await syntax. They are Python generators that use yield from expressions to await on Futures and other coroutines.", "Generator-based coroutines should be decorated with @asyncio.coroutine, although this is not enforced.", "Decorator to mark generator-based coroutines.", "This decorator enables legacy generator-based coroutines to be compatible with async/await code:", "This decorator should not be used for async def coroutines.", "Deprecated since version 3.8, will be removed in version 3.10: Use async def instead.", "Return True if obj is a coroutine object.", "This method is different from inspect.iscoroutine() because it returns True for generator-based coroutines.", "Return True if func is a coroutine function.", "This method is different from inspect.iscoroutinefunction() because it returns True for generator-based coroutine functions decorated with @coroutine."]}, {"name": "credits", "path": "library/constants#credits", "type": "Built-in Constants", "text": ["Objects that when printed or called, print the text of copyright or credits, respectively."]}, {"name": "crypt", "path": "library/crypt", "type": "Unix", "text": ["Source code: Lib/crypt.py", "This module implements an interface to the crypt(3) routine, which is a one-way hash function based upon a modified DES algorithm; see the Unix man page for further details. Possible uses include storing hashed passwords so you can check passwords without storing the actual password, or attempting to crack Unix passwords with a dictionary.", "Notice that the behavior of this module depends on the actual implementation of the crypt(3) routine in the running system. Therefore, any extensions available on the current implementation will also be available on this module.", "Availability: Unix. Not available on VxWorks.", "New in version 3.3.", "The crypt module defines the list of hashing methods (not all methods are available on all platforms):", "A Modular Crypt Format method with 16 character salt and 86 character hash based on the SHA-512 hash function. This is the strongest method.", "Another Modular Crypt Format method with 16 character salt and 43 character hash based on the SHA-256 hash function.", "Another Modular Crypt Format method with 22 character salt and 31 character hash based on the Blowfish cipher.", "New in version 3.7.", "Another Modular Crypt Format method with 8 character salt and 22 character hash based on the MD5 hash function.", "The traditional method with a 2 character salt and 13 characters of hash. This is the weakest method.", "New in version 3.3.", "A list of available password hashing algorithms, as crypt.METHOD_* objects. This list is sorted from strongest to weakest.", "The crypt module defines the following functions:", "word will usually be a user\u2019s password as typed at a prompt or in a graphical interface. The optional salt is either a string as returned from mksalt(), one of the crypt.METHOD_* values (though not all may be available on all platforms), or a full encrypted password including salt, as returned by this function. If salt is not provided, the strongest method will be used (as returned by methods()).", "Checking a password is usually done by passing the plain-text password as word and the full results of a previous crypt() call, which should be the same as the results of this call.", "salt (either a random 2 or 16 character string, possibly prefixed with $digit$ to indicate the method) which will be used to perturb the encryption algorithm. The characters in salt must be in the set [./a-zA-Z0-9], with the exception of Modular Crypt Format which prefixes a $digit$.", "Returns the hashed password as a string, which will be composed of characters from the same alphabet as the salt.", "Since a few crypt(3) extensions allow different values, with different sizes in the salt, it is recommended to use the full crypted password as salt when checking for a password.", "Changed in version 3.3: Accept crypt.METHOD_* values in addition to strings for salt.", "Return a randomly generated salt of the specified method. If no method is given, the strongest method available as returned by methods() is used.", "The return value is a string suitable for passing as the salt argument to crypt().", "rounds specifies the number of rounds for METHOD_SHA256, METHOD_SHA512 and METHOD_BLOWFISH. For METHOD_SHA256 and METHOD_SHA512 it must be an integer between 1000 and 999_999_999, the default is 5000. For METHOD_BLOWFISH it must be a power of two between 16 (24) and 2_147_483_648 (231), the default is 4096 (212).", "New in version 3.3.", "Changed in version 3.7: Added the rounds parameter.", "A simple example illustrating typical use (a constant-time comparison operation is needed to limit exposure to timing attacks. hmac.compare_digest() is suitable for this purpose):", "To generate a hash of a password using the strongest available method and check it against the original:"]}, {"name": "crypt.crypt()", "path": "library/crypt#crypt.crypt", "type": "Unix", "text": ["word will usually be a user\u2019s password as typed at a prompt or in a graphical interface. The optional salt is either a string as returned from mksalt(), one of the crypt.METHOD_* values (though not all may be available on all platforms), or a full encrypted password including salt, as returned by this function. If salt is not provided, the strongest method will be used (as returned by methods()).", "Checking a password is usually done by passing the plain-text password as word and the full results of a previous crypt() call, which should be the same as the results of this call.", "salt (either a random 2 or 16 character string, possibly prefixed with $digit$ to indicate the method) which will be used to perturb the encryption algorithm. The characters in salt must be in the set [./a-zA-Z0-9], with the exception of Modular Crypt Format which prefixes a $digit$.", "Returns the hashed password as a string, which will be composed of characters from the same alphabet as the salt.", "Since a few crypt(3) extensions allow different values, with different sizes in the salt, it is recommended to use the full crypted password as salt when checking for a password.", "Changed in version 3.3: Accept crypt.METHOD_* values in addition to strings for salt."]}, {"name": "crypt.methods", "path": "library/crypt#crypt.methods", "type": "Unix", "text": ["A list of available password hashing algorithms, as crypt.METHOD_* objects. This list is sorted from strongest to weakest."]}, {"name": "crypt.METHOD_BLOWFISH", "path": "library/crypt#crypt.METHOD_BLOWFISH", "type": "Unix", "text": ["Another Modular Crypt Format method with 22 character salt and 31 character hash based on the Blowfish cipher.", "New in version 3.7."]}, {"name": "crypt.METHOD_CRYPT", "path": "library/crypt#crypt.METHOD_CRYPT", "type": "Unix", "text": ["The traditional method with a 2 character salt and 13 characters of hash. This is the weakest method."]}, {"name": "crypt.METHOD_MD5", "path": "library/crypt#crypt.METHOD_MD5", "type": "Unix", "text": ["Another Modular Crypt Format method with 8 character salt and 22 character hash based on the MD5 hash function."]}, {"name": "crypt.METHOD_SHA256", "path": "library/crypt#crypt.METHOD_SHA256", "type": "Unix", "text": ["Another Modular Crypt Format method with 16 character salt and 43 character hash based on the SHA-256 hash function."]}, {"name": "crypt.METHOD_SHA512", "path": "library/crypt#crypt.METHOD_SHA512", "type": "Unix", "text": ["A Modular Crypt Format method with 16 character salt and 86 character hash based on the SHA-512 hash function. This is the strongest method."]}, {"name": "crypt.mksalt()", "path": "library/crypt#crypt.mksalt", "type": "Unix", "text": ["Return a randomly generated salt of the specified method. If no method is given, the strongest method available as returned by methods() is used.", "The return value is a string suitable for passing as the salt argument to crypt().", "rounds specifies the number of rounds for METHOD_SHA256, METHOD_SHA512 and METHOD_BLOWFISH. For METHOD_SHA256 and METHOD_SHA512 it must be an integer between 1000 and 999_999_999, the default is 5000. For METHOD_BLOWFISH it must be a power of two between 16 (24) and 2_147_483_648 (231), the default is 4096 (212).", "New in version 3.3.", "Changed in version 3.7: Added the rounds parameter."]}, {"name": "csv", "path": "library/csv", "type": "File Formats", "text": ["Source code: Lib/csv.py", "The so-called CSV (Comma Separated Values) format is the most common import and export format for spreadsheets and databases. CSV format was used for many years prior to attempts to describe the format in a standardized way in RFC 4180. The lack of a well-defined standard means that subtle differences often exist in the data produced and consumed by different applications. These differences can make it annoying to process CSV files from multiple sources. Still, while the delimiters and quoting characters vary, the overall format is similar enough that it is possible to write a single module which can efficiently manipulate such data, hiding the details of reading and writing the data from the programmer.", "The csv module implements classes to read and write tabular data in CSV format. It allows programmers to say, \u201cwrite this data in the format preferred by Excel,\u201d or \u201cread data from this file which was generated by Excel,\u201d without knowing the precise details of the CSV format used by Excel. Programmers can also describe the CSV formats understood by other applications or define their own special-purpose CSV formats.", "The csv module\u2019s reader and writer objects read and write sequences. Programmers can also read and write data in dictionary form using the DictReader and DictWriter classes.", "See also", "The Python Enhancement Proposal which proposed this addition to Python.", "The csv module defines the following functions:", "Return a reader object which will iterate over lines in the given csvfile. csvfile can be any object which supports the iterator protocol and returns a string each time its __next__() method is called \u2014 file objects and list objects are both suitable. If csvfile is a file object, it should be opened with newline=''. 1 An optional dialect parameter can be given which is used to define a set of parameters specific to a particular CSV dialect. It may be an instance of a subclass of the Dialect class or one of the strings returned by the list_dialects() function. The other optional fmtparams keyword arguments can be given to override individual formatting parameters in the current dialect. For full details about the dialect and formatting parameters, see section Dialects and Formatting Parameters.", "Each row read from the csv file is returned as a list of strings. No automatic data type conversion is performed unless the QUOTE_NONNUMERIC format option is specified (in which case unquoted fields are transformed into floats).", "A short usage example:", "Return a writer object responsible for converting the user\u2019s data into delimited strings on the given file-like object. csvfile can be any object with a write() method. If csvfile is a file object, it should be opened with newline='' 1. An optional dialect parameter can be given which is used to define a set of parameters specific to a particular CSV dialect. It may be an instance of a subclass of the Dialect class or one of the strings returned by the list_dialects() function. The other optional fmtparams keyword arguments can be given to override individual formatting parameters in the current dialect. For full details about the dialect and formatting parameters, see section Dialects and Formatting Parameters. To make it as easy as possible to interface with modules which implement the DB API, the value None is written as the empty string. While this isn\u2019t a reversible transformation, it makes it easier to dump SQL NULL data values to CSV files without preprocessing the data returned from a cursor.fetch* call. All other non-string data are stringified with str() before being written.", "A short usage example:", "Associate dialect with name. name must be a string. The dialect can be specified either by passing a sub-class of Dialect, or by fmtparams keyword arguments, or both, with keyword arguments overriding parameters of the dialect. For full details about the dialect and formatting parameters, see section Dialects and Formatting Parameters.", "Delete the dialect associated with name from the dialect registry. An Error is raised if name is not a registered dialect name.", "Return the dialect associated with name. An Error is raised if name is not a registered dialect name. This function returns an immutable Dialect.", "Return the names of all registered dialects.", "Returns the current maximum field size allowed by the parser. If new_limit is given, this becomes the new limit.", "The csv module defines the following classes:", "Create an object that operates like a regular reader but maps the information in each row to a dict whose keys are given by the optional fieldnames parameter.", "The fieldnames parameter is a sequence. If fieldnames is omitted, the values in the first row of file f will be used as the fieldnames. Regardless of how the fieldnames are determined, the dictionary preserves their original ordering.", "If a row has more fields than fieldnames, the remaining data is put in a list and stored with the fieldname specified by restkey (which defaults to None). If a non-blank row has fewer fields than fieldnames, the missing values are filled-in with the value of restval (which defaults to None).", "All other optional or keyword arguments are passed to the underlying reader instance.", "Changed in version 3.6: Returned rows are now of type OrderedDict.", "Changed in version 3.8: Returned rows are now of type dict.", "A short usage example:", "Create an object which operates like a regular writer but maps dictionaries onto output rows. The fieldnames parameter is a sequence of keys that identify the order in which values in the dictionary passed to the writerow() method are written to file f. The optional restval parameter specifies the value to be written if the dictionary is missing a key in fieldnames. If the dictionary passed to the writerow() method contains a key not found in fieldnames, the optional extrasaction parameter indicates what action to take. If it is set to 'raise', the default value, a ValueError is raised. If it is set to 'ignore', extra values in the dictionary are ignored. Any other optional or keyword arguments are passed to the underlying writer instance.", "Note that unlike the DictReader class, the fieldnames parameter of the DictWriter class is not optional.", "A short usage example:", "The Dialect class is a container class relied on primarily for its attributes, which are used to define the parameters for a specific reader or writer instance.", "The excel class defines the usual properties of an Excel-generated CSV file. It is registered with the dialect name 'excel'.", "The excel_tab class defines the usual properties of an Excel-generated TAB-delimited file. It is registered with the dialect name 'excel-tab'.", "The unix_dialect class defines the usual properties of a CSV file generated on UNIX systems, i.e. using '\\n' as line terminator and quoting all fields. It is registered with the dialect name 'unix'.", "New in version 3.2.", "The Sniffer class is used to deduce the format of a CSV file.", "The Sniffer class provides two methods:", "Analyze the given sample and return a Dialect subclass reflecting the parameters found. If the optional delimiters parameter is given, it is interpreted as a string containing possible valid delimiter characters.", "Analyze the sample text (presumed to be in CSV format) and return True if the first row appears to be a series of column headers.", "An example for Sniffer use:", "The csv module defines the following constants:", "Instructs writer objects to quote all fields.", "Instructs writer objects to only quote those fields which contain special characters such as delimiter, quotechar or any of the characters in lineterminator.", "Instructs writer objects to quote all non-numeric fields.", "Instructs the reader to convert all non-quoted fields to type float.", "Instructs writer objects to never quote fields. When the current delimiter occurs in output data it is preceded by the current escapechar character. If escapechar is not set, the writer will raise Error if any characters that require escaping are encountered.", "Instructs reader to perform no special processing of quote characters.", "The csv module defines the following exception:", "Raised by any of the functions when an error is detected.", "To make it easier to specify the format of input and output records, specific formatting parameters are grouped together into dialects. A dialect is a subclass of the Dialect class having a set of specific methods and a single validate() method. When creating reader or writer objects, the programmer can specify a string or a subclass of the Dialect class as the dialect parameter. In addition to, or instead of, the dialect parameter, the programmer can also specify individual formatting parameters, which have the same names as the attributes defined below for the Dialect class.", "Dialects support the following attributes:", "A one-character string used to separate fields. It defaults to ','.", "Controls how instances of quotechar appearing inside a field should themselves be quoted. When True, the character is doubled. When False, the escapechar is used as a prefix to the quotechar. It defaults to True.", "On output, if doublequote is False and no escapechar is set, Error is raised if a quotechar is found in a field.", "A one-character string used by the writer to escape the delimiter if quoting is set to QUOTE_NONE and the quotechar if doublequote is False. On reading, the escapechar removes any special meaning from the following character. It defaults to None, which disables escaping.", "The string used to terminate lines produced by the writer. It defaults to '\\r\\n'.", "Note", "The reader is hard-coded to recognise either '\\r' or '\\n' as end-of-line, and ignores lineterminator. This behavior may change in the future.", "A one-character string used to quote fields containing special characters, such as the delimiter or quotechar, or which contain new-line characters. It defaults to '\"'.", "Controls when quotes should be generated by the writer and recognised by the reader. It can take on any of the QUOTE_* constants (see section Module Contents) and defaults to QUOTE_MINIMAL.", "When True, whitespace immediately following the delimiter is ignored. The default is False.", "When True, raise exception Error on bad CSV input. The default is False.", "Reader objects (DictReader instances and objects returned by the reader() function) have the following public methods:", "Return the next row of the reader\u2019s iterable object as a list (if the object was returned from reader()) or a dict (if it is a DictReader instance), parsed according to the current dialect. Usually you should call this as next(reader).", "Reader objects have the following public attributes:", "A read-only description of the dialect in use by the parser.", "The number of lines read from the source iterator. This is not the same as the number of records returned, as records can span multiple lines.", "DictReader objects have the following public attribute:", "If not passed as a parameter when creating the object, this attribute is initialized upon first access or when the first record is read from the file.", "Writer objects (DictWriter instances and objects returned by the writer() function) have the following public methods. A row must be an iterable of strings or numbers for Writer objects and a dictionary mapping fieldnames to strings or numbers (by passing them through str() first) for DictWriter objects. Note that complex numbers are written out surrounded by parens. This may cause some problems for other programs which read CSV files (assuming they support complex numbers at all).", "Write the row parameter to the writer\u2019s file object, formatted according to the current dialect. Return the return value of the call to the write method of the underlying file object.", "Changed in version 3.5: Added support of arbitrary iterables.", "Write all elements in rows (an iterable of row objects as described above) to the writer\u2019s file object, formatted according to the current dialect.", "Writer objects have the following public attribute:", "A read-only description of the dialect in use by the writer.", "DictWriter objects have the following public method:", "Write a row with the field names (as specified in the constructor) to the writer\u2019s file object, formatted according to the current dialect. Return the return value of the csvwriter.writerow() call used internally.", "New in version 3.2.", "Changed in version 3.8: writeheader() now also returns the value returned by the csvwriter.writerow() method it uses internally.", "The simplest example of reading a CSV file:", "Reading a file with an alternate format:", "The corresponding simplest possible writing example is:", "Since open() is used to open a CSV file for reading, the file will by default be decoded into unicode using the system default encoding (see locale.getpreferredencoding()). To decode a file using a different encoding, use the encoding argument of open:", "The same applies to writing in something other than the system default encoding: specify the encoding argument when opening the output file.", "Registering a new dialect:", "A slightly more advanced use of the reader \u2014 catching and reporting errors:", "And while the module doesn\u2019t directly support parsing strings, it can easily be done:", "If newline='' is not specified, newlines embedded inside quoted fields will not be interpreted correctly, and on platforms that use \\r\\n linendings on write an extra \\r will be added. It should always be safe to specify newline='', since the csv module does its own (universal) newline handling."]}, {"name": "csv.csvreader.dialect", "path": "library/csv#csv.csvreader.dialect", "type": "File Formats", "text": ["A read-only description of the dialect in use by the parser."]}, {"name": "csv.csvreader.fieldnames", "path": "library/csv#csv.csvreader.fieldnames", "type": "File Formats", "text": ["If not passed as a parameter when creating the object, this attribute is initialized upon first access or when the first record is read from the file."]}, {"name": "csv.csvreader.line_num", "path": "library/csv#csv.csvreader.line_num", "type": "File Formats", "text": ["The number of lines read from the source iterator. This is not the same as the number of records returned, as records can span multiple lines."]}, {"name": "csv.csvreader.__next__()", "path": "library/csv#csv.csvreader.__next__", "type": "File Formats", "text": ["Return the next row of the reader\u2019s iterable object as a list (if the object was returned from reader()) or a dict (if it is a DictReader instance), parsed according to the current dialect. Usually you should call this as next(reader)."]}, {"name": "csv.csvwriter.dialect", "path": "library/csv#csv.csvwriter.dialect", "type": "File Formats", "text": ["A read-only description of the dialect in use by the writer."]}, {"name": "csv.csvwriter.writerow()", "path": "library/csv#csv.csvwriter.writerow", "type": "File Formats", "text": ["Write the row parameter to the writer\u2019s file object, formatted according to the current dialect. Return the return value of the call to the write method of the underlying file object.", "Changed in version 3.5: Added support of arbitrary iterables."]}, {"name": "csv.csvwriter.writerows()", "path": "library/csv#csv.csvwriter.writerows", "type": "File Formats", "text": ["Write all elements in rows (an iterable of row objects as described above) to the writer\u2019s file object, formatted according to the current dialect."]}, {"name": "csv.Dialect", "path": "library/csv#csv.Dialect", "type": "File Formats", "text": ["The Dialect class is a container class relied on primarily for its attributes, which are used to define the parameters for a specific reader or writer instance."]}, {"name": "csv.Dialect.delimiter", "path": "library/csv#csv.Dialect.delimiter", "type": "File Formats", "text": ["A one-character string used to separate fields. It defaults to ','."]}, {"name": "csv.Dialect.doublequote", "path": "library/csv#csv.Dialect.doublequote", "type": "File Formats", "text": ["Controls how instances of quotechar appearing inside a field should themselves be quoted. When True, the character is doubled. When False, the escapechar is used as a prefix to the quotechar. It defaults to True.", "On output, if doublequote is False and no escapechar is set, Error is raised if a quotechar is found in a field."]}, {"name": "csv.Dialect.escapechar", "path": "library/csv#csv.Dialect.escapechar", "type": "File Formats", "text": ["A one-character string used by the writer to escape the delimiter if quoting is set to QUOTE_NONE and the quotechar if doublequote is False. On reading, the escapechar removes any special meaning from the following character. It defaults to None, which disables escaping."]}, {"name": "csv.Dialect.lineterminator", "path": "library/csv#csv.Dialect.lineterminator", "type": "File Formats", "text": ["The string used to terminate lines produced by the writer. It defaults to '\\r\\n'.", "Note", "The reader is hard-coded to recognise either '\\r' or '\\n' as end-of-line, and ignores lineterminator. This behavior may change in the future."]}, {"name": "csv.Dialect.quotechar", "path": "library/csv#csv.Dialect.quotechar", "type": "File Formats", "text": ["A one-character string used to quote fields containing special characters, such as the delimiter or quotechar, or which contain new-line characters. It defaults to '\"'."]}, {"name": "csv.Dialect.quoting", "path": "library/csv#csv.Dialect.quoting", "type": "File Formats", "text": ["Controls when quotes should be generated by the writer and recognised by the reader. It can take on any of the QUOTE_* constants (see section Module Contents) and defaults to QUOTE_MINIMAL."]}, {"name": "csv.Dialect.skipinitialspace", "path": "library/csv#csv.Dialect.skipinitialspace", "type": "File Formats", "text": ["When True, whitespace immediately following the delimiter is ignored. The default is False."]}, {"name": "csv.Dialect.strict", "path": "library/csv#csv.Dialect.strict", "type": "File Formats", "text": ["When True, raise exception Error on bad CSV input. The default is False."]}, {"name": "csv.DictReader", "path": "library/csv#csv.DictReader", "type": "File Formats", "text": ["Create an object that operates like a regular reader but maps the information in each row to a dict whose keys are given by the optional fieldnames parameter.", "The fieldnames parameter is a sequence. If fieldnames is omitted, the values in the first row of file f will be used as the fieldnames. Regardless of how the fieldnames are determined, the dictionary preserves their original ordering.", "If a row has more fields than fieldnames, the remaining data is put in a list and stored with the fieldname specified by restkey (which defaults to None). If a non-blank row has fewer fields than fieldnames, the missing values are filled-in with the value of restval (which defaults to None).", "All other optional or keyword arguments are passed to the underlying reader instance.", "Changed in version 3.6: Returned rows are now of type OrderedDict.", "Changed in version 3.8: Returned rows are now of type dict.", "A short usage example:"]}, {"name": "csv.DictWriter", "path": "library/csv#csv.DictWriter", "type": "File Formats", "text": ["Create an object which operates like a regular writer but maps dictionaries onto output rows. The fieldnames parameter is a sequence of keys that identify the order in which values in the dictionary passed to the writerow() method are written to file f. The optional restval parameter specifies the value to be written if the dictionary is missing a key in fieldnames. If the dictionary passed to the writerow() method contains a key not found in fieldnames, the optional extrasaction parameter indicates what action to take. If it is set to 'raise', the default value, a ValueError is raised. If it is set to 'ignore', extra values in the dictionary are ignored. Any other optional or keyword arguments are passed to the underlying writer instance.", "Note that unlike the DictReader class, the fieldnames parameter of the DictWriter class is not optional.", "A short usage example:"]}, {"name": "csv.DictWriter.writeheader()", "path": "library/csv#csv.DictWriter.writeheader", "type": "File Formats", "text": ["Write a row with the field names (as specified in the constructor) to the writer\u2019s file object, formatted according to the current dialect. Return the return value of the csvwriter.writerow() call used internally.", "New in version 3.2.", "Changed in version 3.8: writeheader() now also returns the value returned by the csvwriter.writerow() method it uses internally."]}, {"name": "csv.Error", "path": "library/csv#csv.Error", "type": "File Formats", "text": ["Raised by any of the functions when an error is detected."]}, {"name": "csv.excel", "path": "library/csv#csv.excel", "type": "File Formats", "text": ["The excel class defines the usual properties of an Excel-generated CSV file. It is registered with the dialect name 'excel'."]}, {"name": "csv.excel_tab", "path": "library/csv#csv.excel_tab", "type": "File Formats", "text": ["The excel_tab class defines the usual properties of an Excel-generated TAB-delimited file. It is registered with the dialect name 'excel-tab'."]}, {"name": "csv.field_size_limit()", "path": "library/csv#csv.field_size_limit", "type": "File Formats", "text": ["Returns the current maximum field size allowed by the parser. If new_limit is given, this becomes the new limit."]}, {"name": "csv.get_dialect()", "path": "library/csv#csv.get_dialect", "type": "File Formats", "text": ["Return the dialect associated with name. An Error is raised if name is not a registered dialect name. This function returns an immutable Dialect."]}, {"name": "csv.list_dialects()", "path": "library/csv#csv.list_dialects", "type": "File Formats", "text": ["Return the names of all registered dialects."]}, {"name": "csv.QUOTE_ALL", "path": "library/csv#csv.QUOTE_ALL", "type": "File Formats", "text": ["Instructs writer objects to quote all fields."]}, {"name": "csv.QUOTE_MINIMAL", "path": "library/csv#csv.QUOTE_MINIMAL", "type": "File Formats", "text": ["Instructs writer objects to only quote those fields which contain special characters such as delimiter, quotechar or any of the characters in lineterminator."]}, {"name": "csv.QUOTE_NONE", "path": "library/csv#csv.QUOTE_NONE", "type": "File Formats", "text": ["Instructs writer objects to never quote fields. When the current delimiter occurs in output data it is preceded by the current escapechar character. If escapechar is not set, the writer will raise Error if any characters that require escaping are encountered.", "Instructs reader to perform no special processing of quote characters."]}, {"name": "csv.QUOTE_NONNUMERIC", "path": "library/csv#csv.QUOTE_NONNUMERIC", "type": "File Formats", "text": ["Instructs writer objects to quote all non-numeric fields.", "Instructs the reader to convert all non-quoted fields to type float."]}, {"name": "csv.reader()", "path": "library/csv#csv.reader", "type": "File Formats", "text": ["Return a reader object which will iterate over lines in the given csvfile. csvfile can be any object which supports the iterator protocol and returns a string each time its __next__() method is called \u2014 file objects and list objects are both suitable. If csvfile is a file object, it should be opened with newline=''. 1 An optional dialect parameter can be given which is used to define a set of parameters specific to a particular CSV dialect. It may be an instance of a subclass of the Dialect class or one of the strings returned by the list_dialects() function. The other optional fmtparams keyword arguments can be given to override individual formatting parameters in the current dialect. For full details about the dialect and formatting parameters, see section Dialects and Formatting Parameters.", "Each row read from the csv file is returned as a list of strings. No automatic data type conversion is performed unless the QUOTE_NONNUMERIC format option is specified (in which case unquoted fields are transformed into floats).", "A short usage example:"]}, {"name": "csv.register_dialect()", "path": "library/csv#csv.register_dialect", "type": "File Formats", "text": ["Associate dialect with name. name must be a string. The dialect can be specified either by passing a sub-class of Dialect, or by fmtparams keyword arguments, or both, with keyword arguments overriding parameters of the dialect. For full details about the dialect and formatting parameters, see section Dialects and Formatting Parameters."]}, {"name": "csv.Sniffer", "path": "library/csv#csv.Sniffer", "type": "File Formats", "text": ["The Sniffer class is used to deduce the format of a CSV file.", "The Sniffer class provides two methods:", "Analyze the given sample and return a Dialect subclass reflecting the parameters found. If the optional delimiters parameter is given, it is interpreted as a string containing possible valid delimiter characters.", "Analyze the sample text (presumed to be in CSV format) and return True if the first row appears to be a series of column headers."]}, {"name": "csv.Sniffer.has_header()", "path": "library/csv#csv.Sniffer.has_header", "type": "File Formats", "text": ["Analyze the sample text (presumed to be in CSV format) and return True if the first row appears to be a series of column headers."]}, {"name": "csv.Sniffer.sniff()", "path": "library/csv#csv.Sniffer.sniff", "type": "File Formats", "text": ["Analyze the given sample and return a Dialect subclass reflecting the parameters found. If the optional delimiters parameter is given, it is interpreted as a string containing possible valid delimiter characters."]}, {"name": "csv.unix_dialect", "path": "library/csv#csv.unix_dialect", "type": "File Formats", "text": ["The unix_dialect class defines the usual properties of a CSV file generated on UNIX systems, i.e. using '\\n' as line terminator and quoting all fields. It is registered with the dialect name 'unix'.", "New in version 3.2."]}, {"name": "csv.unregister_dialect()", "path": "library/csv#csv.unregister_dialect", "type": "File Formats", "text": ["Delete the dialect associated with name from the dialect registry. An Error is raised if name is not a registered dialect name."]}, {"name": "csv.writer()", "path": "library/csv#csv.writer", "type": "File Formats", "text": ["Return a writer object responsible for converting the user\u2019s data into delimited strings on the given file-like object. csvfile can be any object with a write() method. If csvfile is a file object, it should be opened with newline='' 1. An optional dialect parameter can be given which is used to define a set of parameters specific to a particular CSV dialect. It may be an instance of a subclass of the Dialect class or one of the strings returned by the list_dialects() function. The other optional fmtparams keyword arguments can be given to override individual formatting parameters in the current dialect. For full details about the dialect and formatting parameters, see section Dialects and Formatting Parameters. To make it as easy as possible to interface with modules which implement the DB API, the value None is written as the empty string. While this isn\u2019t a reversible transformation, it makes it easier to dump SQL NULL data values to CSV files without preprocessing the data returned from a cursor.fetch* call. All other non-string data are stringified with str() before being written.", "A short usage example:"]}, {"name": "ctypes", "path": "library/ctypes", "type": "Operating System", "text": ["ctypes is a foreign function library for Python. It provides C compatible data types, and allows calling functions in DLLs or shared libraries. It can be used to wrap these libraries in pure Python.", "Note: The code samples in this tutorial use doctest to make sure that they actually work. Since some code samples behave differently under Linux, Windows, or Mac OS X, they contain doctest directives in comments.", "Note: Some code samples reference the ctypes c_int type. On platforms where sizeof(long) == sizeof(int) it is an alias to c_long. So, you should not be confused if c_long is printed if you would expect c_int \u2014 they are actually the same type.", "ctypes exports the cdll, and on Windows windll and oledll objects, for loading dynamic link libraries.", "You load libraries by accessing them as attributes of these objects. cdll loads libraries which export functions using the standard cdecl calling convention, while windll libraries call functions using the stdcall calling convention. oledll also uses the stdcall calling convention, and assumes the functions return a Windows HRESULT error code. The error code is used to automatically raise an OSError exception when the function call fails.", "Changed in version 3.3: Windows errors used to raise WindowsError, which is now an alias of OSError.", "Here are some examples for Windows. Note that msvcrt is the MS standard C library containing most standard C functions, and uses the cdecl calling convention:", "Windows appends the usual .dll file suffix automatically.", "Note", "Accessing the standard C library through cdll.msvcrt will use an outdated version of the library that may be incompatible with the one being used by Python. Where possible, use native Python functionality, or else import and use the msvcrt module.", "On Linux, it is required to specify the filename including the extension to load a library, so attribute access can not be used to load libraries. Either the LoadLibrary() method of the dll loaders should be used, or you should load the library by creating an instance of CDLL by calling the constructor:", "Functions are accessed as attributes of dll objects:", "Note that win32 system dlls like kernel32 and user32 often export ANSI as well as UNICODE versions of a function. The UNICODE version is exported with an W appended to the name, while the ANSI version is exported with an A appended to the name. The win32 GetModuleHandle function, which returns a module handle for a given module name, has the following C prototype, and a macro is used to expose one of them as GetModuleHandle depending on whether UNICODE is defined or not:", "windll does not try to select one of them by magic, you must access the version you need by specifying GetModuleHandleA or GetModuleHandleW explicitly, and then call it with bytes or string objects respectively.", "Sometimes, dlls export functions with names which aren\u2019t valid Python identifiers, like \"??2@YAPAXI@Z\". In this case you have to use getattr() to retrieve the function:", "On Windows, some dlls export functions not by name but by ordinal. These functions can be accessed by indexing the dll object with the ordinal number:", "You can call these functions like any other Python callable. This example uses the time() function, which returns system time in seconds since the Unix epoch, and the GetModuleHandleA() function, which returns a win32 module handle.", "This example calls both functions with a NULL pointer (None should be used as the NULL pointer):", "ValueError is raised when you call an stdcall function with the cdecl calling convention, or vice versa:", "To find out the correct calling convention you have to look into the C header file or the documentation for the function you want to call.", "On Windows, ctypes uses win32 structured exception handling to prevent crashes from general protection faults when functions are called with invalid argument values:", "There are, however, enough ways to crash Python with ctypes, so you should be careful anyway. The faulthandler module can be helpful in debugging crashes (e.g. from segmentation faults produced by erroneous C library calls).", "None, integers, bytes objects and (unicode) strings are the only native Python objects that can directly be used as parameters in these function calls. None is passed as a C NULL pointer, bytes objects and strings are passed as pointer to the memory block that contains their data (char * or wchar_t *). Python integers are passed as the platforms default C int type, their value is masked to fit into the C type.", "Before we move on calling functions with other parameter types, we have to learn more about ctypes data types.", "ctypes defines a number of primitive C compatible data types:", "ctypes type", "C type", "Python type", "c_bool", "_Bool", "bool (1)", "c_char", "char", "1-character bytes object", "c_wchar", "wchar_t", "1-character string", "c_byte", "char", "int", "c_ubyte", "unsigned char", "int", "c_short", "short", "int", "c_ushort", "unsigned short", "int", "c_int", "int", "int", "c_uint", "unsigned int", "int", "c_long", "long", "int", "c_ulong", "unsigned long", "int", "c_longlong", "__int64 or long long", "int", "c_ulonglong", "unsigned __int64 or unsigned long long", "int", "c_size_t", "size_t", "int", "c_ssize_t", "ssize_t or Py_ssize_t", "int", "c_float", "float", "float", "c_double", "double", "float", "c_longdouble", "long double", "float", "c_char_p", "char * (NUL terminated)", "bytes object or None", "c_wchar_p", "wchar_t * (NUL terminated)", "string or None", "c_void_p", "void *", "int or None", "All these types can be created by calling them with an optional initializer of the correct type and value:", "Since these types are mutable, their value can also be changed afterwards:", "Assigning a new value to instances of the pointer types c_char_p, c_wchar_p, and c_void_p changes the memory location they point to, not the contents of the memory block (of course not, because Python bytes objects are immutable):", "You should be careful, however, not to pass them to functions expecting pointers to mutable memory. If you need mutable memory blocks, ctypes has a create_string_buffer() function which creates these in various ways. The current memory block contents can be accessed (or changed) with the raw property; if you want to access it as NUL terminated string, use the value property:", "The create_string_buffer() function replaces the c_buffer() function (which is still available as an alias), as well as the c_string() function from earlier ctypes releases. To create a mutable memory block containing unicode characters of the C type wchar_t use the create_unicode_buffer() function.", "Note that printf prints to the real standard output channel, not to sys.stdout, so these examples will only work at the console prompt, not from within IDLE or PythonWin:", "As has been mentioned before, all Python types except integers, strings, and bytes objects have to be wrapped in their corresponding ctypes type, so that they can be converted to the required C data type:", "You can also customize ctypes argument conversion to allow instances of your own classes be used as function arguments. ctypes looks for an _as_parameter_ attribute and uses this as the function argument. Of course, it must be one of integer, string, or bytes:", "If you don\u2019t want to store the instance\u2019s data in the _as_parameter_ instance variable, you could define a property which makes the attribute available on request.", "It is possible to specify the required argument types of functions exported from DLLs by setting the argtypes attribute.", "argtypes must be a sequence of C data types (the printf function is probably not a good example here, because it takes a variable number and different types of parameters depending on the format string, on the other hand this is quite handy to experiment with this feature):", "Specifying a format protects against incompatible argument types (just as a prototype for a C function), and tries to convert the arguments to valid types:", "If you have defined your own classes which you pass to function calls, you have to implement a from_param() class method for them to be able to use them in the argtypes sequence. The from_param() class method receives the Python object passed to the function call, it should do a typecheck or whatever is needed to make sure this object is acceptable, and then return the object itself, its _as_parameter_ attribute, or whatever you want to pass as the C function argument in this case. Again, the result should be an integer, string, bytes, a ctypes instance, or an object with an _as_parameter_ attribute.", "By default functions are assumed to return the C int type. Other return types can be specified by setting the restype attribute of the function object.", "Here is a more advanced example, it uses the strchr function, which expects a string pointer and a char, and returns a pointer to a string:", "If you want to avoid the ord(\"x\") calls above, you can set the argtypes attribute, and the second argument will be converted from a single character Python bytes object into a C char:", "You can also use a callable Python object (a function or a class for example) as the restype attribute, if the foreign function returns an integer. The callable will be called with the integer the C function returns, and the result of this call will be used as the result of your function call. This is useful to check for error return values and automatically raise an exception:", "WinError is a function which will call Windows FormatMessage() api to get the string representation of an error code, and returns an exception. WinError takes an optional error code parameter, if no one is used, it calls GetLastError() to retrieve it.", "Please note that a much more powerful error checking mechanism is available through the errcheck attribute; see the reference manual for details.", "Sometimes a C api function expects a pointer to a data type as parameter, probably to write into the corresponding location, or if the data is too large to be passed by value. This is also known as passing parameters by reference.", "ctypes exports the byref() function which is used to pass parameters by reference. The same effect can be achieved with the pointer() function, although pointer() does a lot more work since it constructs a real pointer object, so it is faster to use byref() if you don\u2019t need the pointer object in Python itself:", "Structures and unions must derive from the Structure and Union base classes which are defined in the ctypes module. Each subclass must define a _fields_ attribute. _fields_ must be a list of 2-tuples, containing a field name and a field type.", "The field type must be a ctypes type like c_int, or any other derived ctypes type: structure, union, array, pointer.", "Here is a simple example of a POINT structure, which contains two integers named x and y, and also shows how to initialize a structure in the constructor:", "You can, however, build much more complicated structures. A structure can itself contain other structures by using a structure as a field type.", "Here is a RECT structure which contains two POINTs named upperleft and lowerright:", "Nested structures can also be initialized in the constructor in several ways:", "Field descriptors can be retrieved from the class, they are useful for debugging because they can provide useful information:", "Warning", "ctypes does not support passing unions or structures with bit-fields to functions by value. While this may work on 32-bit x86, it\u2019s not guaranteed by the library to work in the general case. Unions and structures with bit-fields should always be passed to functions by pointer.", "By default, Structure and Union fields are aligned in the same way the C compiler does it. It is possible to override this behavior by specifying a _pack_ class attribute in the subclass definition. This must be set to a positive integer and specifies the maximum alignment for the fields. This is what #pragma pack(n) also does in MSVC.", "ctypes uses the native byte order for Structures and Unions. To build structures with non-native byte order, you can use one of the BigEndianStructure, LittleEndianStructure, BigEndianUnion, and LittleEndianUnion base classes. These classes cannot contain pointer fields.", "It is possible to create structures and unions containing bit fields. Bit fields are only possible for integer fields, the bit width is specified as the third item in the _fields_ tuples:", "Arrays are sequences, containing a fixed number of instances of the same type.", "The recommended way to create array types is by multiplying a data type with a positive integer:", "Here is an example of a somewhat artificial data type, a structure containing 4 POINTs among other stuff:", "Instances are created in the usual way, by calling the class:", "The above code print a series of 0 0 lines, because the array contents is initialized to zeros.", "Initializers of the correct type can also be specified:", "Pointer instances are created by calling the pointer() function on a ctypes type:", "Pointer instances have a contents attribute which returns the object to which the pointer points, the i object above:", "Note that ctypes does not have OOR (original object return), it constructs a new, equivalent object each time you retrieve an attribute:", "Assigning another c_int instance to the pointer\u2019s contents attribute would cause the pointer to point to the memory location where this is stored:", "Pointer instances can also be indexed with integers:", "Assigning to an integer index changes the pointed to value:", "It is also possible to use indexes different from 0, but you must know what you\u2019re doing, just as in C: You can access or change arbitrary memory locations. Generally you only use this feature if you receive a pointer from a C function, and you know that the pointer actually points to an array instead of a single item.", "Behind the scenes, the pointer() function does more than simply create pointer instances, it has to create pointer types first. This is done with the POINTER() function, which accepts any ctypes type, and returns a new type:", "Calling the pointer type without an argument creates a NULL pointer. NULL pointers have a False boolean value:", "ctypes checks for NULL when dereferencing pointers (but dereferencing invalid non-NULL pointers would crash Python):", "Usually, ctypes does strict type checking. This means, if you have POINTER(c_int) in the argtypes list of a function or as the type of a member field in a structure definition, only instances of exactly the same type are accepted. There are some exceptions to this rule, where ctypes accepts other objects. For example, you can pass compatible array instances instead of pointer types. So, for POINTER(c_int), ctypes accepts an array of c_int:", "In addition, if a function argument is explicitly declared to be a pointer type (such as POINTER(c_int)) in argtypes, an object of the pointed type (c_int in this case) can be passed to the function. ctypes will apply the required byref() conversion in this case automatically.", "To set a POINTER type field to NULL, you can assign None:", "Sometimes you have instances of incompatible types. In C, you can cast one type into another type. ctypes provides a cast() function which can be used in the same way. The Bar structure defined above accepts POINTER(c_int) pointers or c_int arrays for its values field, but not instances of other types:", "For these cases, the cast() function is handy.", "The cast() function can be used to cast a ctypes instance into a pointer to a different ctypes data type. cast() takes two parameters, a ctypes object that is or can be converted to a pointer of some kind, and a ctypes pointer type. It returns an instance of the second argument, which references the same memory block as the first argument:", "So, cast() can be used to assign to the values field of Bar the structure:", "Incomplete Types are structures, unions or arrays whose members are not yet specified. In C, they are specified by forward declarations, which are defined later:", "The straightforward translation into ctypes code would be this, but it does not work:", "because the new class cell is not available in the class statement itself. In ctypes, we can define the cell class and set the _fields_ attribute later, after the class statement:", "Let\u2019s try it. We create two instances of cell, and let them point to each other, and finally follow the pointer chain a few times:", "ctypes allows creating C callable function pointers from Python callables. These are sometimes called callback functions.", "First, you must create a class for the callback function. The class knows the calling convention, the return type, and the number and types of arguments this function will receive.", "The CFUNCTYPE() factory function creates types for callback functions using the cdecl calling convention. On Windows, the WINFUNCTYPE() factory function creates types for callback functions using the stdcall calling convention.", "Both of these factory functions are called with the result type as first argument, and the callback functions expected argument types as the remaining arguments.", "I will present an example here which uses the standard C library\u2019s qsort() function, that is used to sort items with the help of a callback function. qsort() will be used to sort an array of integers:", "qsort() must be called with a pointer to the data to sort, the number of items in the data array, the size of one item, and a pointer to the comparison function, the callback. The callback will then be called with two pointers to items, and it must return a negative integer if the first item is smaller than the second, a zero if they are equal, and a positive integer otherwise.", "So our callback function receives pointers to integers, and must return an integer. First we create the type for the callback function:", "To get started, here is a simple callback that shows the values it gets passed:", "The result:", "Now we can actually compare the two items and return a useful result:", "As we can easily check, our array is sorted now:", "The function factories can be used as decorator factories, so we may as well write:", "Note", "Make sure you keep references to CFUNCTYPE() objects as long as they are used from C code. ctypes doesn\u2019t, and if you don\u2019t, they may be garbage collected, crashing your program when a callback is made.", "Also, note that if the callback function is called in a thread created outside of Python\u2019s control (e.g. by the foreign code that calls the callback), ctypes creates a new dummy Python thread on every invocation. This behavior is correct for most purposes, but it means that values stored with threading.local will not survive across different callbacks, even when those calls are made from the same C thread.", "Some shared libraries not only export functions, they also export variables. An example in the Python library itself is the Py_OptimizeFlag, an integer set to 0, 1, or 2, depending on the -O or -OO flag given on startup.", "ctypes can access values like this with the in_dll() class methods of the type. pythonapi is a predefined symbol giving access to the Python C api:", "If the interpreter would have been started with -O, the sample would have printed c_long(1), or c_long(2) if -OO would have been specified.", "An extended example which also demonstrates the use of pointers accesses the PyImport_FrozenModules pointer exported by Python.", "Quoting the docs for that value:", "This pointer is initialized to point to an array of struct _frozen records, terminated by one whose members are all NULL or zero. When a frozen module is imported, it is searched in this table. Third-party code could play tricks with this to provide a dynamically created collection of frozen modules.", "So manipulating this pointer could even prove useful. To restrict the example size, we show only how this table can be read with ctypes:", "We have defined the struct _frozen data type, so we can get the pointer to the table:", "Since table is a pointer to the array of struct_frozen records, we can iterate over it, but we just have to make sure that our loop terminates, because pointers have no size. Sooner or later it would probably crash with an access violation or whatever, so it\u2019s better to break out of the loop when we hit the NULL entry:", "The fact that standard Python has a frozen module and a frozen package (indicated by the negative size member) is not well known, it is only used for testing. Try it out with import __hello__ for example.", "There are some edges in ctypes where you might expect something other than what actually happens.", "Consider the following example:", "Hm. We certainly expected the last statement to print 3 4 1 2. What happened? Here are the steps of the rc.a, rc.b = rc.b, rc.a line above:", "Note that temp0 and temp1 are objects still using the internal buffer of the rc object above. So executing rc.a = temp0 copies the buffer contents of temp0 into rc \u2018s buffer. This, in turn, changes the contents of temp1. So, the last assignment rc.b = temp1, doesn\u2019t have the expected effect.", "Keep in mind that retrieving sub-objects from Structure, Unions, and Arrays doesn\u2019t copy the sub-object, instead it retrieves a wrapper object accessing the root-object\u2019s underlying buffer.", "Another example that may behave differently from what one would expect is this:", "Note", "Objects instantiated from c_char_p can only have their value set to bytes or integers.", "Why is it printing False? ctypes instances are objects containing a memory block plus some descriptors accessing the contents of the memory. Storing a Python object in the memory block does not store the object itself, instead the contents of the object is stored. Accessing the contents again constructs a new Python object each time!", "ctypes provides some support for variable-sized arrays and structures.", "The resize() function can be used to resize the memory buffer of an existing ctypes object. The function takes the object as first argument, and the requested size in bytes as the second argument. The memory block cannot be made smaller than the natural memory block specified by the objects type, a ValueError is raised if this is tried:", "This is nice and fine, but how would one access the additional elements contained in this array? Since the type still only knows about 4 elements, we get errors accessing other elements:", "Another way to use variable-sized data types with ctypes is to use the dynamic nature of Python, and (re-)define the data type after the required size is already known, on a case by case basis.", "When programming in a compiled language, shared libraries are accessed when compiling/linking a program, and when the program is run.", "The purpose of the find_library() function is to locate a library in a way similar to what the compiler or runtime loader does (on platforms with several versions of a shared library the most recent should be loaded), while the ctypes library loaders act like when a program is run, and call the runtime loader directly.", "The ctypes.util module provides a function which can help to determine the library to load.", "Try to find a library and return a pathname. name is the library name without any prefix like lib, suffix like .so, .dylib or version number (this is the form used for the posix linker option -l). If no library can be found, returns None.", "The exact functionality is system dependent.", "On Linux, find_library() tries to run external programs (/sbin/ldconfig, gcc, objdump and ld) to find the library file. It returns the filename of the library file.", "Changed in version 3.6: On Linux, the value of the environment variable LD_LIBRARY_PATH is used when searching for libraries, if a library cannot be found by any other means.", "Here are some examples:", "On OS X, find_library() tries several predefined naming schemes and paths to locate the library, and returns a full pathname if successful:", "On Windows, find_library() searches along the system search path, and returns the full pathname, but since there is no predefined naming scheme a call like find_library(\"c\") will fail and return None.", "If wrapping a shared library with ctypes, it may be better to determine the shared library name at development time, and hardcode that into the wrapper module instead of using find_library() to locate the library at runtime.", "There are several ways to load shared libraries into the Python process. One way is to instantiate one of the following classes:", "Instances of this class represent loaded shared libraries. Functions in these libraries use the standard C calling convention, and are assumed to return int.", "On Windows creating a CDLL instance may fail even if the DLL name exists. When a dependent DLL of the loaded DLL is not found, a OSError error is raised with the message \u201c[WinError 126] The specified module could not be found\u201d. This error message does not contain the name of the missing DLL because the Windows API does not return this information making this error hard to diagnose. To resolve this error and determine which DLL is not found, you need to find the list of dependent DLLs and determine which one is not found using Windows debugging and tracing tools.", "See also", "Microsoft DUMPBIN tool \u2013 A tool to find DLL dependents.", "Windows only: Instances of this class represent loaded shared libraries, functions in these libraries use the stdcall calling convention, and are assumed to return the windows specific HRESULT code. HRESULT values contain information specifying whether the function call failed or succeeded, together with additional error code. If the return value signals a failure, an OSError is automatically raised.", "Changed in version 3.3: WindowsError used to be raised.", "Windows only: Instances of this class represent loaded shared libraries, functions in these libraries use the stdcall calling convention, and are assumed to return int by default.", "On Windows CE only the standard calling convention is used, for convenience the WinDLL and OleDLL use the standard calling convention on this platform.", "The Python global interpreter lock is released before calling any function exported by these libraries, and reacquired afterwards.", "Instances of this class behave like CDLL instances, except that the Python GIL is not released during the function call, and after the function execution the Python error flag is checked. If the error flag is set, a Python exception is raised.", "Thus, this is only useful to call Python C api functions directly.", "All these classes can be instantiated by calling them with at least one argument, the pathname of the shared library. If you have an existing handle to an already loaded shared library, it can be passed as the handle named parameter, otherwise the underlying platforms dlopen or LoadLibrary function is used to load the library into the process, and to get a handle to it.", "The mode parameter can be used to specify how the library is loaded. For details, consult the dlopen(3) manpage. On Windows, mode is ignored. On posix systems, RTLD_NOW is always added, and is not configurable.", "The use_errno parameter, when set to true, enables a ctypes mechanism that allows accessing the system errno error number in a safe way. ctypes maintains a thread-local copy of the systems errno variable; if you call foreign functions created with use_errno=True then the errno value before the function call is swapped with the ctypes private copy, the same happens immediately after the function call.", "The function ctypes.get_errno() returns the value of the ctypes private copy, and the function ctypes.set_errno() changes the ctypes private copy to a new value and returns the former value.", "The use_last_error parameter, when set to true, enables the same mechanism for the Windows error code which is managed by the GetLastError() and SetLastError() Windows API functions; ctypes.get_last_error() and ctypes.set_last_error() are used to request and change the ctypes private copy of the windows error code.", "The winmode parameter is used on Windows to specify how the library is loaded (since mode is ignored). It takes any value that is valid for the Win32 API LoadLibraryEx flags parameter. When omitted, the default is to use the flags that result in the most secure DLL load to avoiding issues such as DLL hijacking. Passing the full path to the DLL is the safest way to ensure the correct library and dependencies are loaded.", "Changed in version 3.8: Added winmode parameter.", "Flag to use as mode parameter. On platforms where this flag is not available, it is defined as the integer zero.", "Flag to use as mode parameter. On platforms where this is not available, it is the same as RTLD_GLOBAL.", "The default mode which is used to load shared libraries. On OSX 10.3, this is RTLD_GLOBAL, otherwise it is the same as RTLD_LOCAL.", "Instances of these classes have no public methods. Functions exported by the shared library can be accessed as attributes or by index. Please note that accessing the function through an attribute caches the result and therefore accessing it repeatedly returns the same object each time. On the other hand, accessing it through an index returns a new object each time:", "The following public attributes are available, their name starts with an underscore to not clash with exported function names:", "The system handle used to access the library.", "The name of the library passed in the constructor.", "Shared libraries can also be loaded by using one of the prefabricated objects, which are instances of the LibraryLoader class, either by calling the LoadLibrary() method, or by retrieving the library as attribute of the loader instance.", "Class which loads shared libraries. dlltype should be one of the CDLL, PyDLL, WinDLL, or OleDLL types.", "__getattr__() has special behavior: It allows loading a shared library by accessing it as attribute of a library loader instance. The result is cached, so repeated attribute accesses return the same library each time.", "Load a shared library into the process and return it. This method always returns a new instance of the library.", "These prefabricated library loaders are available:", "Creates CDLL instances.", "Windows only: Creates WinDLL instances.", "Windows only: Creates OleDLL instances.", "Creates PyDLL instances.", "For accessing the C Python api directly, a ready-to-use Python shared library object is available:", "An instance of PyDLL that exposes Python C API functions as attributes. Note that all these functions are assumed to return C int, which is of course not always the truth, so you have to assign the correct restype attribute to use these functions.", "Loading a library through any of these objects raises an auditing event ctypes.dlopen with string argument name, the name used to load the library.", "Accessing a function on a loaded library raises an auditing event ctypes.dlsym with arguments library (the library object) and name (the symbol\u2019s name as a string or integer).", "In cases when only the library handle is available rather than the object, accessing a function raises an auditing event ctypes.dlsym/handle with arguments handle (the raw library handle) and name.", "As explained in the previous section, foreign functions can be accessed as attributes of loaded shared libraries. The function objects created in this way by default accept any number of arguments, accept any ctypes data instances as arguments, and return the default result type specified by the library loader. They are instances of a private class:", "Base class for C callable foreign functions.", "Instances of foreign functions are also C compatible data types; they represent C function pointers.", "This behavior can be customized by assigning to special attributes of the foreign function object.", "Assign a ctypes type to specify the result type of the foreign function. Use None for void, a function not returning anything.", "It is possible to assign a callable Python object that is not a ctypes type, in this case the function is assumed to return a C int, and the callable will be called with this integer, allowing further processing or error checking. Using this is deprecated, for more flexible post processing or error checking use a ctypes data type as restype and assign a callable to the errcheck attribute.", "Assign a tuple of ctypes types to specify the argument types that the function accepts. Functions using the stdcall calling convention can only be called with the same number of arguments as the length of this tuple; functions using the C calling convention accept additional, unspecified arguments as well.", "When a foreign function is called, each actual argument is passed to the from_param() class method of the items in the argtypes tuple, this method allows adapting the actual argument to an object that the foreign function accepts. For example, a c_char_p item in the argtypes tuple will convert a string passed as argument into a bytes object using ctypes conversion rules.", "New: It is now possible to put items in argtypes which are not ctypes types, but each item must have a from_param() method which returns a value usable as argument (integer, string, ctypes instance). This allows defining adapters that can adapt custom objects as function parameters.", "Assign a Python function or another callable to this attribute. The callable will be called with three or more arguments:", "result is what the foreign function returns, as specified by the restype attribute.", "func is the foreign function object itself, this allows reusing the same callable object to check or post process the results of several functions.", "arguments is a tuple containing the parameters originally passed to the function call, this allows specializing the behavior on the arguments used.", "The object that this function returns will be returned from the foreign function call, but it can also check the result value and raise an exception if the foreign function call failed.", "This exception is raised when a foreign function call cannot convert one of the passed arguments.", "On Windows, when a foreign function call raises a system exception (for example, due to an access violation), it will be captured and replaced with a suitable Python exception. Further, an auditing event ctypes.seh_exception with argument code will be raised, allowing an audit hook to replace the exception with its own.", "Some ways to invoke foreign function calls may raise an auditing event ctypes.call_function with arguments function pointer and arguments.", "Foreign functions can also be created by instantiating function prototypes. Function prototypes are similar to function prototypes in C; they describe a function (return type, argument types, calling convention) without defining an implementation. The factory functions must be called with the desired result type and the argument types of the function, and can be used as decorator factories, and as such, be applied to functions through the @wrapper syntax. See Callback functions for examples.", "The returned function prototype creates functions that use the standard C calling convention. The function will release the GIL during the call. If use_errno is set to true, the ctypes private copy of the system errno variable is exchanged with the real errno value before and after the call; use_last_error does the same for the Windows error code.", "Windows only: The returned function prototype creates functions that use the stdcall calling convention, except on Windows CE where WINFUNCTYPE() is the same as CFUNCTYPE(). The function will release the GIL during the call. use_errno and use_last_error have the same meaning as above.", "The returned function prototype creates functions that use the Python calling convention. The function will not release the GIL during the call.", "Function prototypes created by these factory functions can be instantiated in different ways, depending on the type and number of the parameters in the call:", "Returns a foreign function at the specified address which must be an integer.", "Create a C callable function (a callback function) from a Python callable.", "Returns a foreign function exported by a shared library. func_spec must be a 2-tuple (name_or_ordinal, library). The first item is the name of the exported function as string, or the ordinal of the exported function as small integer. The second item is the shared library instance.", "Returns a foreign function that will call a COM method. vtbl_index is the index into the virtual function table, a small non-negative integer. name is name of the COM method. iid is an optional pointer to the interface identifier which is used in extended error reporting.", "COM methods use a special calling convention: They require a pointer to the COM interface as first argument, in addition to those parameters that are specified in the argtypes tuple.", "The optional paramflags parameter creates foreign function wrappers with much more functionality than the features described above.", "paramflags must be a tuple of the same length as argtypes.", "Each item in this tuple contains further information about a parameter, it must be a tuple containing one, two, or three items.", "The first item is an integer containing a combination of direction flags for the parameter:", "Specifies an input parameter to the function.", "Output parameter. The foreign function fills in a value.", "Input parameter which defaults to the integer zero.", "The optional second item is the parameter name as string. If this is specified, the foreign function can be called with named parameters.", "The optional third item is the default value for this parameter.", "This example demonstrates how to wrap the Windows MessageBoxW function so that it supports default parameters and named arguments. The C declaration from the windows header file is this:", "Here is the wrapping with ctypes:", "The MessageBox foreign function can now be called in these ways:", "A second example demonstrates output parameters. The win32 GetWindowRect function retrieves the dimensions of a specified window by copying them into RECT structure that the caller has to supply. Here is the C declaration:", "Here is the wrapping with ctypes:", "Functions with output parameters will automatically return the output parameter value if there is a single one, or a tuple containing the output parameter values when there are more than one, so the GetWindowRect function now returns a RECT instance, when called.", "Output parameters can be combined with the errcheck protocol to do further output processing and error checking. The win32 GetWindowRect api function returns a BOOL to signal success or failure, so this function could do the error checking, and raises an exception when the api call failed:", "If the errcheck function returns the argument tuple it receives unchanged, ctypes continues the normal processing it does on the output parameters. If you want to return a tuple of window coordinates instead of a RECT instance, you can retrieve the fields in the function and return them instead, the normal processing will no longer take place:", "Returns the address of the memory buffer as integer. obj must be an instance of a ctypes type.", "Raises an auditing event ctypes.addressof with argument obj.", "Returns the alignment requirements of a ctypes type. obj_or_type must be a ctypes type or instance.", "Returns a light-weight pointer to obj, which must be an instance of a ctypes type. offset defaults to zero, and must be an integer that will be added to the internal pointer value.", "byref(obj, offset) corresponds to this C code:", "The returned object can only be used as a foreign function call parameter. It behaves similar to pointer(obj), but the construction is a lot faster.", "This function is similar to the cast operator in C. It returns a new instance of type which points to the same memory block as obj. type must be a pointer type, and obj must be an object that can be interpreted as a pointer.", "This function creates a mutable character buffer. The returned object is a ctypes array of c_char.", "init_or_size must be an integer which specifies the size of the array, or a bytes object which will be used to initialize the array items.", "If a bytes object is specified as first argument, the buffer is made one item larger than its length so that the last element in the array is a NUL termination character. An integer can be passed as second argument which allows specifying the size of the array if the length of the bytes should not be used.", "Raises an auditing event ctypes.create_string_buffer with arguments init, size.", "This function creates a mutable unicode character buffer. The returned object is a ctypes array of c_wchar.", "init_or_size must be an integer which specifies the size of the array, or a string which will be used to initialize the array items.", "If a string is specified as first argument, the buffer is made one item larger than the length of the string so that the last element in the array is a NUL termination character. An integer can be passed as second argument which allows specifying the size of the array if the length of the string should not be used.", "Raises an auditing event ctypes.create_unicode_buffer with arguments init, size.", "Windows only: This function is a hook which allows implementing in-process COM servers with ctypes. It is called from the DllCanUnloadNow function that the _ctypes extension dll exports.", "Windows only: This function is a hook which allows implementing in-process COM servers with ctypes. It is called from the DllGetClassObject function that the _ctypes extension dll exports.", "Try to find a library and return a pathname. name is the library name without any prefix like lib, suffix like .so, .dylib or version number (this is the form used for the posix linker option -l). If no library can be found, returns None.", "The exact functionality is system dependent.", "Windows only: return the filename of the VC runtime library used by Python, and by the extension modules. If the name of the library cannot be determined, None is returned.", "If you need to free memory, for example, allocated by an extension module with a call to the free(void *), it is important that you use the function in the same library that allocated the memory.", "Windows only: Returns a textual description of the error code code. If no error code is specified, the last error code is used by calling the Windows api function GetLastError.", "Windows only: Returns the last error code set by Windows in the calling thread. This function calls the Windows GetLastError() function directly, it does not return the ctypes-private copy of the error code.", "Returns the current value of the ctypes-private copy of the system errno variable in the calling thread.", "Raises an auditing event ctypes.get_errno with no arguments.", "Windows only: returns the current value of the ctypes-private copy of the system LastError variable in the calling thread.", "Raises an auditing event ctypes.get_last_error with no arguments.", "Same as the standard C memmove library function: copies count bytes from src to dst. dst and src must be integers or ctypes instances that can be converted to pointers.", "Same as the standard C memset library function: fills the memory block at address dst with count bytes of value c. dst must be an integer specifying an address, or a ctypes instance.", "This factory function creates and returns a new ctypes pointer type. Pointer types are cached and reused internally, so calling this function repeatedly is cheap. type must be a ctypes type.", "This function creates a new pointer instance, pointing to obj. The returned object is of the type POINTER(type(obj)).", "Note: If you just want to pass a pointer to an object to a foreign function call, you should use byref(obj) which is much faster.", "This function resizes the internal memory buffer of obj, which must be an instance of a ctypes type. It is not possible to make the buffer smaller than the native size of the objects type, as given by sizeof(type(obj)), but it is possible to enlarge the buffer.", "Set the current value of the ctypes-private copy of the system errno variable in the calling thread to value and return the previous value.", "Raises an auditing event ctypes.set_errno with argument errno.", "Windows only: set the current value of the ctypes-private copy of the system LastError variable in the calling thread to value and return the previous value.", "Raises an auditing event ctypes.set_last_error with argument error.", "Returns the size in bytes of a ctypes type or instance memory buffer. Does the same as the C sizeof operator.", "This function returns the C string starting at memory address address as a bytes object. If size is specified, it is used as size, otherwise the string is assumed to be zero-terminated.", "Raises an auditing event ctypes.string_at with arguments address, size.", "Windows only: this function is probably the worst-named thing in ctypes. It creates an instance of OSError. If code is not specified, GetLastError is called to determine the error code. If descr is not specified, FormatError() is called to get a textual description of the error.", "Changed in version 3.3: An instance of WindowsError used to be created.", "This function returns the wide character string starting at memory address address as a string. If size is specified, it is used as the number of characters of the string, otherwise the string is assumed to be zero-terminated.", "Raises an auditing event ctypes.wstring_at with arguments address, size.", "This non-public class is the common base class of all ctypes data types. Among other things, all ctypes type instances contain a memory block that hold C compatible data; the address of the memory block is returned by the addressof() helper function. Another instance variable is exposed as _objects; this contains other Python objects that need to be kept alive in case the memory block contains pointers.", "Common methods of ctypes data types, these are all class methods (to be exact, they are methods of the metaclass):", "This method returns a ctypes instance that shares the buffer of the source object. The source object must support the writeable buffer interface. The optional offset parameter specifies an offset into the source buffer in bytes; the default is zero. If the source buffer is not large enough a ValueError is raised.", "Raises an auditing event ctypes.cdata/buffer with arguments pointer, size, offset.", "This method creates a ctypes instance, copying the buffer from the source object buffer which must be readable. The optional offset parameter specifies an offset into the source buffer in bytes; the default is zero. If the source buffer is not large enough a ValueError is raised.", "Raises an auditing event ctypes.cdata/buffer with arguments pointer, size, offset.", "This method returns a ctypes type instance using the memory specified by address which must be an integer.", "This method, and others that indirectly call this method, raises an auditing event ctypes.cdata with argument address.", "This method adapts obj to a ctypes type. It is called with the actual object used in a foreign function call when the type is present in the foreign function\u2019s argtypes tuple; it must return an object that can be used as a function call parameter.", "All ctypes data types have a default implementation of this classmethod that normally returns obj if that is an instance of the type. Some types accept other objects as well.", "This method returns a ctypes type instance exported by a shared library. name is the name of the symbol that exports the data, library is the loaded shared library.", "Common instance variables of ctypes data types:", "Sometimes ctypes data instances do not own the memory block they contain, instead they share part of the memory block of a base object. The _b_base_ read-only member is the root ctypes object that owns the memory block.", "This read-only variable is true when the ctypes data instance has allocated the memory block itself, false otherwise.", "This member is either None or a dictionary containing Python objects that need to be kept alive so that the memory block contents is kept valid. This object is only exposed for debugging; never modify the contents of this dictionary.", "This non-public class is the base class of all fundamental ctypes data types. It is mentioned here because it contains the common attributes of the fundamental ctypes data types. _SimpleCData is a subclass of _CData, so it inherits their methods and attributes. ctypes data types that are not and do not contain pointers can now be pickled.", "Instances have a single attribute:", "This attribute contains the actual value of the instance. For integer and pointer types, it is an integer, for character types, it is a single character bytes object or string, for character pointer types it is a Python bytes object or string.", "When the value attribute is retrieved from a ctypes instance, usually a new object is returned each time. ctypes does not implement original object return, always a new object is constructed. The same is true for all other ctypes object instances.", "Fundamental data types, when returned as foreign function call results, or, for example, by retrieving structure field members or array items, are transparently converted to native Python types. In other words, if a foreign function has a restype of c_char_p, you will always receive a Python bytes object, not a c_char_p instance.", "Subclasses of fundamental data types do not inherit this behavior. So, if a foreign functions restype is a subclass of c_void_p, you will receive an instance of this subclass from the function call. Of course, you can get the value of the pointer by accessing the value attribute.", "These are the fundamental ctypes data types:", "Represents the C signed char datatype, and interprets the value as small integer. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C char datatype, and interprets the value as a single character. The constructor accepts an optional string initializer, the length of the string must be exactly one character.", "Represents the C char * datatype when it points to a zero-terminated string. For a general character pointer that may also point to binary data, POINTER(c_char) must be used. The constructor accepts an integer address, or a bytes object.", "Represents the C double datatype. The constructor accepts an optional float initializer.", "Represents the C long double datatype. The constructor accepts an optional float initializer. On platforms where sizeof(long double) ==\nsizeof(double) it is an alias to c_double.", "Represents the C float datatype. The constructor accepts an optional float initializer.", "Represents the C signed int datatype. The constructor accepts an optional integer initializer; no overflow checking is done. On platforms where sizeof(int) == sizeof(long) it is an alias to c_long.", "Represents the C 8-bit signed int datatype. Usually an alias for c_byte.", "Represents the C 16-bit signed int datatype. Usually an alias for c_short.", "Represents the C 32-bit signed int datatype. Usually an alias for c_int.", "Represents the C 64-bit signed int datatype. Usually an alias for c_longlong.", "Represents the C signed long datatype. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C signed long long datatype. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C signed short datatype. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C size_t datatype.", "Represents the C ssize_t datatype.", "New in version 3.2.", "Represents the C unsigned char datatype, it interprets the value as small integer. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C unsigned int datatype. The constructor accepts an optional integer initializer; no overflow checking is done. On platforms where sizeof(int) == sizeof(long) it is an alias for c_ulong.", "Represents the C 8-bit unsigned int datatype. Usually an alias for c_ubyte.", "Represents the C 16-bit unsigned int datatype. Usually an alias for c_ushort.", "Represents the C 32-bit unsigned int datatype. Usually an alias for c_uint.", "Represents the C 64-bit unsigned int datatype. Usually an alias for c_ulonglong.", "Represents the C unsigned long datatype. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C unsigned long long datatype. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C unsigned short datatype. The constructor accepts an optional integer initializer; no overflow checking is done.", "Represents the C void * type. The value is represented as integer. The constructor accepts an optional integer initializer.", "Represents the C wchar_t datatype, and interprets the value as a single character unicode string. The constructor accepts an optional string initializer, the length of the string must be exactly one character.", "Represents the C wchar_t * datatype, which must be a pointer to a zero-terminated wide character string. The constructor accepts an integer address, or a string.", "Represent the C bool datatype (more accurately, _Bool from C99). Its value can be True or False, and the constructor accepts any object that has a truth value.", "Windows only: Represents a HRESULT value, which contains success or error information for a function or method call.", "Represents the C PyObject * datatype. Calling this without an argument creates a NULL PyObject * pointer.", "The ctypes.wintypes module provides quite some other Windows specific data types, for example HWND, WPARAM, or DWORD. Some useful structures like MSG or RECT are also defined.", "Abstract base class for unions in native byte order.", "Abstract base class for structures in big endian byte order.", "Abstract base class for structures in little endian byte order.", "Structures with non-native byte order cannot contain pointer type fields, or any other data types containing pointer type fields.", "Abstract base class for structures in native byte order.", "Concrete structure and union types must be created by subclassing one of these types, and at least define a _fields_ class variable. ctypes will create descriptors which allow reading and writing the fields by direct attribute accesses. These are the", "A sequence defining the structure fields. The items must be 2-tuples or 3-tuples. The first item is the name of the field, the second item specifies the type of the field; it can be any ctypes data type.", "For integer type fields like c_int, a third optional item can be given. It must be a small positive integer defining the bit width of the field.", "Field names must be unique within one structure or union. This is not checked, only one field can be accessed when names are repeated.", "It is possible to define the _fields_ class variable after the class statement that defines the Structure subclass, this allows creating data types that directly or indirectly reference themselves:", "The _fields_ class variable must, however, be defined before the type is first used (an instance is created, sizeof() is called on it, and so on). Later assignments to the _fields_ class variable will raise an AttributeError.", "It is possible to define sub-subclasses of structure types, they inherit the fields of the base class plus the _fields_ defined in the sub-subclass, if any.", "An optional small integer that allows overriding the alignment of structure fields in the instance. _pack_ must already be defined when _fields_ is assigned, otherwise it will have no effect.", "An optional sequence that lists the names of unnamed (anonymous) fields. _anonymous_ must be already defined when _fields_ is assigned, otherwise it will have no effect.", "The fields listed in this variable must be structure or union type fields. ctypes will create descriptors in the structure type that allows accessing the nested fields directly, without the need to create the structure or union field.", "Here is an example type (Windows):", "The TYPEDESC structure describes a COM data type, the vt field specifies which one of the union fields is valid. Since the u field is defined as anonymous field, it is now possible to access the members directly off the TYPEDESC instance. td.lptdesc and td.u.lptdesc are equivalent, but the former is faster since it does not need to create a temporary union instance:", "It is possible to define sub-subclasses of structures, they inherit the fields of the base class. If the subclass definition has a separate _fields_ variable, the fields specified in this are appended to the fields of the base class.", "Structure and union constructors accept both positional and keyword arguments. Positional arguments are used to initialize member fields in the same order as they are appear in _fields_. Keyword arguments in the constructor are interpreted as attribute assignments, so they will initialize _fields_ with the same name, or create new attributes for names not present in _fields_.", "Abstract base class for arrays.", "The recommended way to create concrete array types is by multiplying any ctypes data type with a positive integer. Alternatively, you can subclass this type and define _length_ and _type_ class variables. Array elements can be read and written using standard subscript and slice accesses; for slice reads, the resulting object is not itself an Array.", "A positive integer specifying the number of elements in the array. Out-of-range subscripts result in an IndexError. Will be returned by len().", "Specifies the type of each element in the array.", "Array subclass constructors accept positional arguments, used to initialize the elements in order.", "Private, abstract base class for pointers.", "Concrete pointer types are created by calling POINTER() with the type that will be pointed to; this is done automatically by pointer().", "If a pointer points to an array, its elements can be read and written using standard subscript and slice accesses. Pointer objects have no size, so len() will raise TypeError. Negative subscripts will read from the memory before the pointer (as in C), and out-of-range subscripts will probably crash with an access violation (if you\u2019re lucky).", "Specifies the type pointed to.", "Returns the object to which to pointer points. Assigning to this attribute changes the pointer to point to the assigned object."]}, {"name": "ctypes.addressof()", "path": "library/ctypes#ctypes.addressof", "type": "Operating System", "text": ["Returns the address of the memory buffer as integer. obj must be an instance of a ctypes type.", "Raises an auditing event ctypes.addressof with argument obj."]}, {"name": "ctypes.alignment()", "path": "library/ctypes#ctypes.alignment", "type": "Operating System", "text": ["Returns the alignment requirements of a ctypes type. obj_or_type must be a ctypes type or instance."]}, {"name": "ctypes.ArgumentError", "path": "library/ctypes#ctypes.ArgumentError", "type": "Operating System", "text": ["This exception is raised when a foreign function call cannot convert one of the passed arguments."]}, {"name": "ctypes.Array", "path": "library/ctypes#ctypes.Array", "type": "Operating System", "text": ["Abstract base class for arrays.", "The recommended way to create concrete array types is by multiplying any ctypes data type with a positive integer. Alternatively, you can subclass this type and define _length_ and _type_ class variables. Array elements can be read and written using standard subscript and slice accesses; for slice reads, the resulting object is not itself an Array.", "A positive integer specifying the number of elements in the array. Out-of-range subscripts result in an IndexError. Will be returned by len().", "Specifies the type of each element in the array.", "Array subclass constructors accept positional arguments, used to initialize the elements in order."]}, {"name": "ctypes.Array._length_", "path": "library/ctypes#ctypes.Array._length_", "type": "Operating System", "text": ["A positive integer specifying the number of elements in the array. Out-of-range subscripts result in an IndexError. Will be returned by len()."]}, {"name": "ctypes.Array._type_", "path": "library/ctypes#ctypes.Array._type_", "type": "Operating System", "text": ["Specifies the type of each element in the array."]}, {"name": "ctypes.BigEndianStructure", "path": "library/ctypes#ctypes.BigEndianStructure", "type": "Operating System", "text": ["Abstract base class for structures in big endian byte order."]}, {"name": "ctypes.byref()", "path": "library/ctypes#ctypes.byref", "type": "Operating System", "text": ["Returns a light-weight pointer to obj, which must be an instance of a ctypes type. offset defaults to zero, and must be an integer that will be added to the internal pointer value.", "byref(obj, offset) corresponds to this C code:", "The returned object can only be used as a foreign function call parameter. It behaves similar to pointer(obj), but the construction is a lot faster."]}, {"name": "ctypes.cast()", "path": "library/ctypes#ctypes.cast", "type": "Operating System", "text": ["This function is similar to the cast operator in C. It returns a new instance of type which points to the same memory block as obj. type must be a pointer type, and obj must be an object that can be interpreted as a pointer."]}, {"name": "ctypes.CDLL", "path": "library/ctypes#ctypes.CDLL", "type": "Operating System", "text": ["Instances of this class represent loaded shared libraries. Functions in these libraries use the standard C calling convention, and are assumed to return int.", "On Windows creating a CDLL instance may fail even if the DLL name exists. When a dependent DLL of the loaded DLL is not found, a OSError error is raised with the message \u201c[WinError 126] The specified module could not be found\u201d. This error message does not contain the name of the missing DLL because the Windows API does not return this information making this error hard to diagnose. To resolve this error and determine which DLL is not found, you need to find the list of dependent DLLs and determine which one is not found using Windows debugging and tracing tools."]}, {"name": "ctypes.CFUNCTYPE()", "path": "library/ctypes#ctypes.CFUNCTYPE", "type": "Operating System", "text": ["The returned function prototype creates functions that use the standard C calling convention. The function will release the GIL during the call. If use_errno is set to true, the ctypes private copy of the system errno variable is exchanged with the real errno value before and after the call; use_last_error does the same for the Windows error code."]}, {"name": "ctypes.create_string_buffer()", "path": "library/ctypes#ctypes.create_string_buffer", "type": "Operating System", "text": ["This function creates a mutable character buffer. The returned object is a ctypes array of c_char.", "init_or_size must be an integer which specifies the size of the array, or a bytes object which will be used to initialize the array items.", "If a bytes object is specified as first argument, the buffer is made one item larger than its length so that the last element in the array is a NUL termination character. An integer can be passed as second argument which allows specifying the size of the array if the length of the bytes should not be used.", "Raises an auditing event ctypes.create_string_buffer with arguments init, size."]}, {"name": "ctypes.create_unicode_buffer()", "path": "library/ctypes#ctypes.create_unicode_buffer", "type": "Operating System", "text": ["This function creates a mutable unicode character buffer. The returned object is a ctypes array of c_wchar.", "init_or_size must be an integer which specifies the size of the array, or a string which will be used to initialize the array items.", "If a string is specified as first argument, the buffer is made one item larger than the length of the string so that the last element in the array is a NUL termination character. An integer can be passed as second argument which allows specifying the size of the array if the length of the string should not be used.", "Raises an auditing event ctypes.create_unicode_buffer with arguments init, size."]}, {"name": "ctypes.c_bool", "path": "library/ctypes#ctypes.c_bool", "type": "Operating System", "text": ["Represent the C bool datatype (more accurately, _Bool from C99). Its value can be True or False, and the constructor accepts any object that has a truth value."]}, {"name": "ctypes.c_byte", "path": "library/ctypes#ctypes.c_byte", "type": "Operating System", "text": ["Represents the C signed char datatype, and interprets the value as small integer. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_char", "path": "library/ctypes#ctypes.c_char", "type": "Operating System", "text": ["Represents the C char datatype, and interprets the value as a single character. The constructor accepts an optional string initializer, the length of the string must be exactly one character."]}, {"name": "ctypes.c_char_p", "path": "library/ctypes#ctypes.c_char_p", "type": "Operating System", "text": ["Represents the C char * datatype when it points to a zero-terminated string. For a general character pointer that may also point to binary data, POINTER(c_char) must be used. The constructor accepts an integer address, or a bytes object."]}, {"name": "ctypes.c_double", "path": "library/ctypes#ctypes.c_double", "type": "Operating System", "text": ["Represents the C double datatype. The constructor accepts an optional float initializer."]}, {"name": "ctypes.c_float", "path": "library/ctypes#ctypes.c_float", "type": "Operating System", "text": ["Represents the C float datatype. The constructor accepts an optional float initializer."]}, {"name": "ctypes.c_int", "path": "library/ctypes#ctypes.c_int", "type": "Operating System", "text": ["Represents the C signed int datatype. The constructor accepts an optional integer initializer; no overflow checking is done. On platforms where sizeof(int) == sizeof(long) it is an alias to c_long."]}, {"name": "ctypes.c_int16", "path": "library/ctypes#ctypes.c_int16", "type": "Operating System", "text": ["Represents the C 16-bit signed int datatype. Usually an alias for c_short."]}, {"name": "ctypes.c_int32", "path": "library/ctypes#ctypes.c_int32", "type": "Operating System", "text": ["Represents the C 32-bit signed int datatype. Usually an alias for c_int."]}, {"name": "ctypes.c_int64", "path": "library/ctypes#ctypes.c_int64", "type": "Operating System", "text": ["Represents the C 64-bit signed int datatype. Usually an alias for c_longlong."]}, {"name": "ctypes.c_int8", "path": "library/ctypes#ctypes.c_int8", "type": "Operating System", "text": ["Represents the C 8-bit signed int datatype. Usually an alias for c_byte."]}, {"name": "ctypes.c_long", "path": "library/ctypes#ctypes.c_long", "type": "Operating System", "text": ["Represents the C signed long datatype. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_longdouble", "path": "library/ctypes#ctypes.c_longdouble", "type": "Operating System", "text": ["Represents the C long double datatype. The constructor accepts an optional float initializer. On platforms where sizeof(long double) ==\nsizeof(double) it is an alias to c_double."]}, {"name": "ctypes.c_longlong", "path": "library/ctypes#ctypes.c_longlong", "type": "Operating System", "text": ["Represents the C signed long long datatype. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_short", "path": "library/ctypes#ctypes.c_short", "type": "Operating System", "text": ["Represents the C signed short datatype. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_size_t", "path": "library/ctypes#ctypes.c_size_t", "type": "Operating System", "text": ["Represents the C size_t datatype."]}, {"name": "ctypes.c_ssize_t", "path": "library/ctypes#ctypes.c_ssize_t", "type": "Operating System", "text": ["Represents the C ssize_t datatype.", "New in version 3.2."]}, {"name": "ctypes.c_ubyte", "path": "library/ctypes#ctypes.c_ubyte", "type": "Operating System", "text": ["Represents the C unsigned char datatype, it interprets the value as small integer. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_uint", "path": "library/ctypes#ctypes.c_uint", "type": "Operating System", "text": ["Represents the C unsigned int datatype. The constructor accepts an optional integer initializer; no overflow checking is done. On platforms where sizeof(int) == sizeof(long) it is an alias for c_ulong."]}, {"name": "ctypes.c_uint16", "path": "library/ctypes#ctypes.c_uint16", "type": "Operating System", "text": ["Represents the C 16-bit unsigned int datatype. Usually an alias for c_ushort."]}, {"name": "ctypes.c_uint32", "path": "library/ctypes#ctypes.c_uint32", "type": "Operating System", "text": ["Represents the C 32-bit unsigned int datatype. Usually an alias for c_uint."]}, {"name": "ctypes.c_uint64", "path": "library/ctypes#ctypes.c_uint64", "type": "Operating System", "text": ["Represents the C 64-bit unsigned int datatype. Usually an alias for c_ulonglong."]}, {"name": "ctypes.c_uint8", "path": "library/ctypes#ctypes.c_uint8", "type": "Operating System", "text": ["Represents the C 8-bit unsigned int datatype. Usually an alias for c_ubyte."]}, {"name": "ctypes.c_ulong", "path": "library/ctypes#ctypes.c_ulong", "type": "Operating System", "text": ["Represents the C unsigned long datatype. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_ulonglong", "path": "library/ctypes#ctypes.c_ulonglong", "type": "Operating System", "text": ["Represents the C unsigned long long datatype. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_ushort", "path": "library/ctypes#ctypes.c_ushort", "type": "Operating System", "text": ["Represents the C unsigned short datatype. The constructor accepts an optional integer initializer; no overflow checking is done."]}, {"name": "ctypes.c_void_p", "path": "library/ctypes#ctypes.c_void_p", "type": "Operating System", "text": ["Represents the C void * type. The value is represented as integer. The constructor accepts an optional integer initializer."]}, {"name": "ctypes.c_wchar", "path": "library/ctypes#ctypes.c_wchar", "type": "Operating System", "text": ["Represents the C wchar_t datatype, and interprets the value as a single character unicode string. The constructor accepts an optional string initializer, the length of the string must be exactly one character."]}, {"name": "ctypes.c_wchar_p", "path": "library/ctypes#ctypes.c_wchar_p", "type": "Operating System", "text": ["Represents the C wchar_t * datatype, which must be a pointer to a zero-terminated wide character string. The constructor accepts an integer address, or a string."]}, {"name": "ctypes.DllCanUnloadNow()", "path": "library/ctypes#ctypes.DllCanUnloadNow", "type": "Operating System", "text": ["Windows only: This function is a hook which allows implementing in-process COM servers with ctypes. It is called from the DllCanUnloadNow function that the _ctypes extension dll exports."]}, {"name": "ctypes.DllGetClassObject()", "path": "library/ctypes#ctypes.DllGetClassObject", "type": "Operating System", "text": ["Windows only: This function is a hook which allows implementing in-process COM servers with ctypes. It is called from the DllGetClassObject function that the _ctypes extension dll exports."]}, {"name": "ctypes.FormatError()", "path": "library/ctypes#ctypes.FormatError", "type": "Operating System", "text": ["Windows only: Returns a textual description of the error code code. If no error code is specified, the last error code is used by calling the Windows api function GetLastError."]}, {"name": "ctypes.GetLastError()", "path": "library/ctypes#ctypes.GetLastError", "type": "Operating System", "text": ["Windows only: Returns the last error code set by Windows in the calling thread. This function calls the Windows GetLastError() function directly, it does not return the ctypes-private copy of the error code."]}, {"name": "ctypes.get_errno()", "path": "library/ctypes#ctypes.get_errno", "type": "Operating System", "text": ["Returns the current value of the ctypes-private copy of the system errno variable in the calling thread.", "Raises an auditing event ctypes.get_errno with no arguments."]}, {"name": "ctypes.get_last_error()", "path": "library/ctypes#ctypes.get_last_error", "type": "Operating System", "text": ["Windows only: returns the current value of the ctypes-private copy of the system LastError variable in the calling thread.", "Raises an auditing event ctypes.get_last_error with no arguments."]}, {"name": "ctypes.HRESULT", "path": "library/ctypes#ctypes.HRESULT", "type": "Operating System"