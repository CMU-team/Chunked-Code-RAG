[{"name": "()", "path": "glossary", "type": "Glossary", "text": "\nA parenthesized number followed by a comma denotes a tuple with one element.\nThe trailing comma distinguishes a one-element tuple from a parenthesized `n`.\n\nIn a dimension entry, instructs NumPy to choose the length that will keep the\ntotal number of array elements the same.\n\nAn `Ellipsis`.\n\nWhen indexing an array, shorthand that the missing axes, if they exist, are\nfull slices.\n\nIt can be used at most once; `a[...,0,...]` raises an `IndexError`.\n\nThe Python slice operator. In ndarrays, slicing can be applied to every axis:\n\nTrailing slices can be omitted:\n\nIn contrast to Python, where slicing creates a copy, in NumPy slicing creates\na view.\n\nFor details, see Combining advanced and basic indexing.\n\nIn a dtype declaration, indicates that the data is little-endian (the bracket\nis big on the right).\n\nIn a dtype declaration, indicates that the data is big-endian (the bracket is\nbig on the left).\n\nRather than using a scalar or slice as an index, an axis can be indexed with\nan array, providing fine-grained selection. This is known as advanced indexing\nor \u201cfancy indexing\u201d.\n\nAn operation `along axis n` of array `a` behaves as if its argument were an\narray of slices of `a` where each slice has a successive index of axis `n`.\n\nFor example, if `a` is a 3 x `N` array, an operation along axis 0 behaves as\nif its argument were an array containing slices of each row:\n\nTo make it concrete, we can pick the operation to be the array-reversal\nfunction `numpy.flip`, which accepts an `axis` argument. We construct a 3 x 4\narray `a`:\n\nReversing along axis 0 (the row axis) yields\n\nRecalling the definition of `along an axis`, `flip` along axis 0 is treating\nits argument as if it were\n\nand the result of `np.flip(a,axis=0)` is to reverse the slices:\n\nUsed synonymously in the NumPy docs with ndarray.\n\nAny scalar or sequence that can be interpreted as an ndarray. In addition to\nndarrays and scalars this category includes lists (possibly nested and with\ndifferent element types) and tuples. Any argument accepted by numpy.array is\narray_like.\n\nAn array scalar is an instance of the types/classes float32, float64, etc..\nFor uniformity in handling operands, NumPy treats a scalar as an array of zero\ndimension. In contrast, a 0-dimensional array is an ndarray instance\ncontaining precisely one value.\n\nAnother term for an array dimension. Axes are numbered left to right; axis 0\nis the first element in the shape tuple.\n\nIn a two-dimensional vector, the elements of axis 0 are rows and the elements\nof axis 1 are columns.\n\nIn higher dimensions, the picture changes. NumPy prints higher-dimensional\nvectors as replications of row-by-column building blocks, as in this three-\ndimensional vector:\n\n`a` is depicted as a two-element array whose elements are 2x3 vectors. From\nthis point of view, rows and columns are the final two axes, respectively, in\nany shape.\n\nThis rule helps you anticipate how a vector will be printed, and conversely\nhow to find the index of any of the printed elements. For instance, in the\nexample, the last two values of 8\u2019s index must be 0 and 2. Since 8 appears in\nthe second of the two 2x3\u2019s, the first index must be 1:\n\nA convenient way to count dimensions in a printed vector is to count `[`\nsymbols after the open-parenthesis. This is useful in distinguishing, say, a\n(1,2,3) shape from a (2,3) shape:\n\nIf an array does not own its memory, then its base attribute returns the\nobject whose memory the array is referencing. That object may be referencing\nthe memory from still another object, so the owning object may be\n`a.base.base.base...`. Some writers erroneously claim that testing `base`\ndetermines if arrays are views. For the correct way, see\n`numpy.shares_memory`.\n\nSee Endianness.\n\nBasic Linear Algebra Subprograms\n\nbroadcasting is NumPy\u2019s ability to process ndarrays of different sizes as if\nall were the same size.\n\nIt permits an elegant do-what-I-mean behavior where, for instance, adding a\nscalar to a vector adds the scalar value to every element.\n\nOrdinarly, vector operands must all be the same size, because NumPy works\nelement by element \u2013 for instance, `c = a * b` is\n\nBut in certain useful cases, NumPy can duplicate data along \u201cmissing\u201d axes or\n\u201ctoo-short\u201d dimensions so shapes will match. The duplication costs no memory\nor time. For details, see Broadcasting.\n\nSame as row-major.\n\nSee Row- and column-major order.\n\nSee view.\n\nSee axis.\n\nThe datatype describing the (identically typed) elements in an ndarray. It can\nbe changed to reinterpret the array contents. For details, see Data type\nobjects (dtype).\n\nAnother term for advanced indexing.\n\nIn a structured data type, each subtype is called a `field`. The `field` has a\nname (a string), a type (any valid dtype), and an optional `title`. See Data\ntype objects (dtype).\n\nSame as column-major.\n\nSee ravel.\n\nAll elements of a homogeneous array have the same type. ndarrays, in contrast\nto Python lists, are homogeneous. The type can be complicated, as in a\nstructured array, but all elements have that type.\n\nNumPy object arrays, which contain references to Python objects, fill the role\nof heterogeneous arrays.\n\nThe size of the dtype element in bytes.\n\nSee Endianness.\n\nA boolean array used to select only certain elements for an operation:\n\nBad or missing data can be cleanly ignored by putting it in a masked array,\nwhich has an internal boolean array indicating invalid entries. Operations\nwith masked arrays ignore these entries.\n\nFor details, see Masked arrays.\n\nNumPy\u2019s two-dimensional matrix class should no longer be used; use regular\nndarrays.\n\nNumPy\u2019s basic structure.\n\nAn array whose dtype is `object`; that is, it contains references to Python\nobjects. Indexing the array dereferences the Python objects, so unlike other\nndarrays, an object array has the ability to hold heterogeneous objects.\n\nnumpy.ravel  and numpy.flatten  both flatten an ndarray. `ravel` will return a\nview if possible; `flatten` always returns a copy.\n\nFlattening collapses a multimdimensional array to a single dimension; details\nof how this is done (for instance, whether `a[n+1]` should be the next row or\nnext column) are parameters.\n\nA structured array with allowing access in an attribute style (`a.field`) in\naddition to `a['field']`. For details, see numpy.recarray.\n\nSee Row- and column-major order. NumPy creates arrays in row-major order by\ndefault.\n\nIn NumPy, usually a synonym for array scalar.\n\nA tuple showing the length of each dimension of an ndarray. The length of the\ntuple itself is the number of dimensions (numpy.ndim). The product of the\ntuple elements is the number of elements in the array. For details, see\nnumpy.ndarray.shape.\n\nPhysical memory is one-dimensional; strides provide a mechanism to map a given\nindex to an address in memory. For an N-dimensional array, its `strides`\nattribute is an N-element tuple; advancing from index `i` to index `i+1` on\naxis `n` means adding `a.strides[n]` bytes to the address.\n\nStrides are computed automatically from an array\u2019s dtype and shape, but can be\ndirectly specified using as_strided.\n\nFor details, see numpy.ndarray.strides.\n\nTo see how striding underlies the power of NumPy views, see The NumPy array: a\nstructure for efficient numerical computation.\n\nArray whose dtype is a structured data type.\n\nUsers can create arbitrarily complex dtypes that can include other arrays and\ndtypes. These composite dtypes are called structured data types.\n\nAn array nested in a structured data type, as `b` is here:\n\nAn element of a structured datatype that behaves like an ndarray.\n\nAn alias for a field name in a structured datatype.\n\nIn NumPy, usually a synonym for dtype. For the more general Python meaning,\nsee here.\n\nNumPy\u2019s fast element-by-element computation (vectorization) gives a choice\nwhich function gets applied. The general term for the function is `ufunc`,\nshort for `universal function`. NumPy routines have built-in ufuncs, but users\ncan also write their own.\n\nNumPy hands off array processing to C, where looping and computation are much\nfaster than in Python. To exploit this, programmers using NumPy eliminate\nPython loops in favor of array-to-array operations. vectorization can refer\nboth to the C offloading and to structuring NumPy code to leverage it.\n\nWithout touching underlying data, NumPy can make one array appear to change\nits datatype and shape.\n\nAn array created this way is a `view`, and NumPy often exploits the\nperformance gain of using a view versus making a new array.\n\nA potential drawback is that writing to a view can alter the original as well.\nIf this is a problem, NumPy instead needs to create a physically distinct\narray \u2013 a `copy`.\n\nSome NumPy routines always return views, some always return copies, some may\nreturn one or the other, and for some the choice can be specified.\nResponsibility for managing views and copies falls to the programmer.\n`numpy.shares_memory` will check whether `b` is a view of `a`, but an exact\nanswer isn\u2019t always feasible, as the documentation page explains.\n\n"}, {"name": "--overwrite-signature", "path": "f2py/usage", "type": "Using F2PY", "text": "\nF2PY can be used either as a command line tool `f2py` or as a Python module\n`numpy.f2py`. While we try to provide the command line tool as part of the\nnumpy setup, some platforms like Windows make it difficult to reliably put the\nexecutables on the `PATH`. We will refer to `f2py` in this document but you\nmay have to run it as a module:\n\nIf you run `f2py` with no arguments, and the line `numpy Version` at the end\nmatches the NumPy version printed from `python -m numpy.f2py`, then you can\nuse the shorter version. If not, or if you cannot run `f2py`, you should\nreplace all calls to `f2py` here with the longer version.\n\nWhen used as a command line tool, `f2py` has three major modes, distinguished\nby the usage of `-c` and `-h` switches:\n\nTo scan Fortran sources and generate a signature file, use\n\nNote\n\nA Fortran source file can contain many routines, and it is often not necessary\nto allow all routines be usable from Python. In such cases, either specify\nwhich routines should be wrapped (in the `only: .. :` part) or which routines\nF2PY should ignored (in the `skip: .. :` part).\n\nIf `<filename.pyf>` is specified as `stdout` then signatures are written to\nstandard output instead of a file.\n\nAmong other options (see below), the following can be used in this mode:\n\nOverwrites an existing signature file.\n\nTo construct an extension module, use\n\nThe constructed extension module is saved as `<modulename>module.c` to the\ncurrent directory.\n\nHere `<fortran files>` may also contain signature files. Among other options\n(see below), the following options can be used in this mode:\n\nAdds debugging hooks to the extension module. When using this extension\nmodule, various diagnostic information about the wrapper is written to the\nstandard output, for example, the values of variables, the steps taken, etc.\n\nAdd a CPP `#include` statement to the extension module source. `<includefile>`\nshould be given in one of the following forms\n\nThe include statement is inserted just before the wrapper functions. This\nfeature enables using arbitrary C functions (defined in `<includefile>`) in\nF2PY generated wrappers.\n\nNote\n\nThis option is deprecated. Use `usercode` statement to specify C code snippets\ndirectly in signature files.\n\nCreate Fortran subroutine wrappers to Fortran functions. `--wrap-functions` is\ndefault because it ensures maximum portability and compiler independence.\n\nSearch include files from given directories.\n\nList system resources found by `numpy_distutils/system_info.py`. For example,\ntry `f2py --help-link lapack_opt`.\n\nTo build an extension module, use\n\nIf `<fortran files>` contains a signature file, then the source for an\nextension module is constructed, all Fortran and C sources are compiled, and\nfinally all object and library files are linked to the extension module\n`<modulename>.so` which is saved into the current directory.\n\nIf `<fortran files>` does not contain a signature file, then an extension\nmodule is constructed by scanning all Fortran source codes for routine\nsignatures, before proceeding to build the extension module.\n\nAmong other options (see below) and options described for previous modes, the\nfollowing options can be used in this mode:\n\nList the available Fortran compilers.\n\nList the available Fortran compilers.\n\nSpecify a Fortran compiler type by vendor.\n\nSpecify the path to a F77 compiler\n\nSpecify the path to a F77 compiler\n\nSpecify the path to a F90 compiler\n\nSpecify the path to a F90 compiler\n\nSpecify F77 compiler flags\n\nSpecify F90 compiler flags\n\nSpecify optimization flags\n\nSpecify architecture specific optimization flags\n\nCompile without optimization flags\n\nCompile without arch-dependent optimization flags\n\nCompile with debugging information\n\nUse the library `<libname>` when linking.\n\nDefine macro `<macro>` as `<defn>`.\n\nDefine macro `<macro>`\n\nAppend directory `<dir>` to the list of directories searched for include\nfiles.\n\nAdd directory `<dir>` to the list of directories to be searched for `-l`.\n\nLink the extension module with <resource> as defined by\n`numpy_distutils/system_info.py`. E.g. to link with optimized LAPACK libraries\n(vecLib on MacOSX, ATLAS elsewhere), use `--link-lapack_opt`. See also\n`--help-link` switch.\n\nNote\n\nThe `f2py -c` option must be applied either to an existing `.pyf` file (plus\nthe source/object/library files) or one must specify the `-m <modulename>`\noption (plus the sources/object/library files). Use one of the following\noptions:\n\nor\n\nFor more information, see the Building C and C++ Extensions Python\ndocumentation for details.\n\nWhen building an extension module, a combination of the following macros may\nbe required for non-gcc Fortran compilers:\n\nTo test the performance of F2PY generated interfaces, use\n`-DF2PY_REPORT_ATEXIT`. Then a report of various timings is printed out at the\nexit of Python. This feature may not work on all platforms, currently only\nLinux platform is supported.\n\nTo see whether F2PY generated interface performs copies of array arguments,\nuse `-DF2PY_REPORT_ON_ARRAY_COPY=<int>`. When the size of an array argument is\nlarger than `<int>`, a message about the coping is sent to `stderr`.\n\nName of an extension module. Default is `untitled`.\n\nWarning\n\nDon\u2019t use this option if a signature file (*.pyf) is used.\n\nDo [not] lower the cases in `<fortran files>`. By default, `--lower` is\nassumed with `-h` switch, and `--no-lower` without the `-h` switch.\n\nAll F2PY generated files are created in `<dirname>`. Default is\n`tempfile.mkdtemp()`.\n\nRun quietly.\n\nRun with extra verbosity.\n\nPrint the F2PY version and exit.\n\nExecute `f2py` without any options to get an up-to-date list of available\noptions.\n\nWarning\n\nThe current Python interface to the `f2py` module is not mature and may change\nin the future.\n\nFortran to Python Interface Generator.\n\nBuild extension module from a Fortran 77 source string with f2py.\n\nFortran source of module / subroutine to compile\n\nChanged in version 1.16.0: Accept str as well as bytes\n\nThe name of the compiled python module\n\nAdditional parameters passed to f2py\n\nChanged in version 1.16.0: A list of args may also be provided.\n\nPrint f2py output to screen\n\nName of the file where the fortran source is written. The default is to use a\ntemporary file with the extension provided by the `extension` parameter\n\nFilename extension if `source_fn` is not provided. The extension tells which\nfortran standard is used. The default is `f`, which implies F77 standard.\n\nNew in version 1.11.0.\n\nIf True, return a `subprocess.CompletedProcess` containing the stdout and\nstderr of the compile process, instead of just the status code.\n\nNew in version 1.20.0.\n\n0 on success, or a `subprocess.CompletedProcess` if `full_output=True`\n\nReturn the directory that contains the fortranobject.c and .h files.\n\nNote\n\nThis function is not needed when building an extension with `numpy.distutils`\ndirectly from `.f` and/or `.pyf` files in one go.\n\nPython extension modules built with f2py-generated code need to use\n`fortranobject.c` as a source file, and include the `fortranobject.h` header.\nThis function can be used to obtain the directory containing both of these\nfiles.\n\nAbsolute path to the directory containing `fortranobject.c` and\n`fortranobject.h`.\n\nSee also\n\nfunction that returns the numpy include directory\n\nNew in version 1.22.0.\n\nUnless the build system you are using has specific support for f2py, building\na Python extension using a `.pyf` signature file is a two-step process. For a\nmodule `mymod`:\n\nStep 2: build your Python extension module. This requires the following source\nfiles:\n\nEquivalent to running:\n\nwhere `<args>=string.join(<list>,' ')`, but in Python. Unless `-h` is used,\nthis function returns a dictionary containing information on generated modules\nand their dependencies on source files. For example, the command `f2py -m\nscalar scalar.f` can be executed from Python as follows\n\nYou cannot build extension modules with this function, that is, using `-c` is\nnot allowed. Use `compile` command instead\n\n"}, {"name": "1", "path": "reference/arrays.scalars", "type": "Scalars", "text": "\nPython defines only one type of a particular data class (there is only one\ninteger type, one floating-point type, etc.). This can be convenient in\napplications that don\u2019t need to be concerned with all the ways data can be\nrepresented in a computer. For scientific computing, however, more control is\noften needed.\n\nIn NumPy, there are 24 new fundamental Python types to describe different\ntypes of scalars. These type descriptors are mostly based on the types\navailable in the C language that CPython is written in, with several\nadditional types compatible with Python\u2019s types.\n\nArray scalars have the same attributes and methods as `ndarrays`. 1 This\nallows one to treat items of an array partly on the same footing as arrays,\nsmoothing out rough edges that result when mixing scalar and array operations.\n\nArray scalars live in a hierarchy (see the Figure below) of data types. They\ncan be detected using the hierarchy: For example, `isinstance(val,\nnp.generic)` will return `True` if val is an array scalar object.\nAlternatively, what kind of array scalar is present can be determined using\nother members of the data type hierarchy. Thus, for example `isinstance(val,\nnp.complexfloating)` will return `True` if val is a complex valued type, while\n`isinstance(val, np.flexible)` will return true if val is one of the flexible\nitemsize array types (`str_`, `bytes_`, `void`).\n\nFigure: Hierarchy of type objects representing the array data types. Not shown\nare the two integer types `intp` and `uintp` which just point to the integer\ntype that holds a pointer for the platform. All the number types can be\nobtained using bit-width names as well.\n\nHowever, array scalars are immutable, so none of the array scalar attributes\nare settable.\n\nThe built-in scalar types are shown below. The C-like names are associated\nwith character codes, which are shown in their descriptions. Use of the\ncharacter codes, however, is discouraged.\n\nSome of the scalar types are essentially equivalent to fundamental Python\ntypes and therefore inherit from them as well as from the generic array scalar\ntype:\n\nArray scalar type\n\nRelated Python type\n\nInherits?\n\n`int_`\n\n`int`\n\nPython 2 only\n\n`float_`\n\n`float`\n\nyes\n\n`complex_`\n\n`complex`\n\nyes\n\n`bytes_`\n\n`bytes`\n\nyes\n\n`str_`\n\n`str`\n\nyes\n\n`bool_`\n\n`bool`\n\nno\n\n`datetime64`\n\n`datetime.datetime`\n\nno\n\n`timedelta64`\n\n`datetime.timedelta`\n\nno\n\nThe `bool_` data type is very similar to the Python `bool` but does not\ninherit from it because Python\u2019s `bool` does not allow itself to be inherited\nfrom, and on the C-level the size of the actual bool data is not the same as a\nPython Boolean scalar.\n\nWarning\n\nThe `int_` type does not inherit from the `int` built-in under Python 3,\nbecause type `int` is no longer a fixed-width integer type.\n\nTip\n\nThe default data type in NumPy is `float_`.\n\nBase class for numpy scalar types.\n\nClass from which most (all?) numpy scalar types are derived. For consistency,\nexposes the same API as `ndarray`, despite many consequent attributes being\neither \u201cget-only,\u201d or completely irrelevant. This is the class from which it\nis strongly suggested users should derive custom scalar types.\n\nAbstract base class of all numeric scalar types.\n\nAbstract base class of all integer scalar types.\n\nNote\n\nThe numpy integer types mirror the behavior of C integers, and can therefore\nbe subject to Overflow Errors.\n\nAbstract base class of all signed integer scalar types.\n\nSigned integer type, compatible with C `char`.\n\n`'b'`\n\n`numpy.int8`: 8-bit signed integer (`-128` to `127`).\n\nSigned integer type, compatible with C `short`.\n\n`'h'`\n\n`numpy.int16`: 16-bit signed integer (`-32_768` to `32_767`).\n\nSigned integer type, compatible with C `int`.\n\n`'i'`\n\n`numpy.int32`: 32-bit signed integer (`-2_147_483_648` to `2_147_483_647`).\n\nSigned integer type, compatible with Python `int` and C `long`.\n\n`'l'`\n\n`numpy.int64`: 64-bit signed integer (`-9_223_372_036_854_775_808` to\n`9_223_372_036_854_775_807`).\n\n`numpy.intp`: Signed integer large enough to fit pointer, compatible with C\n`intptr_t`.\n\nSigned integer type, compatible with C `long long`.\n\n`'q'`\n\nAbstract base class of all unsigned integer scalar types.\n\nUnsigned integer type, compatible with C `unsigned char`.\n\n`'B'`\n\n`numpy.uint8`: 8-bit unsigned integer (`0` to `255`).\n\nUnsigned integer type, compatible with C `unsigned short`.\n\n`'H'`\n\n`numpy.uint16`: 16-bit unsigned integer (`0` to `65_535`).\n\nUnsigned integer type, compatible with C `unsigned int`.\n\n`'I'`\n\n`numpy.uint32`: 32-bit unsigned integer (`0` to `4_294_967_295`).\n\nUnsigned integer type, compatible with C `unsigned long`.\n\n`'L'`\n\n`numpy.uint64`: 64-bit unsigned integer (`0` to `18_446_744_073_709_551_615`).\n\n`numpy.uintp`: Unsigned integer large enough to fit pointer, compatible with C\n`uintptr_t`.\n\nSigned integer type, compatible with C `unsigned long long`.\n\n`'Q'`\n\nAbstract base class of all numeric scalar types with a (potentially) inexact\nrepresentation of the values in its range, such as floating-point numbers.\n\nNote\n\nInexact scalars are printed using the fewest decimal digits needed to\ndistinguish their value from other values of the same datatype, by judicious\nrounding. See the `unique` parameter of `format_float_positional` and\n`format_float_scientific`.\n\nThis means that variables with equal binary values but whose datatypes are of\ndifferent precisions may display differently:\n\nNote that none of these floats hold the exact value \\\\(\\frac{1}{10}\\\\); `f16`\nprints as `0.1` because it is as close to that value as possible, whereas the\nother types do not as they have more precision and therefore have closer\nvalues.\n\nConversely, floating-point scalars of different precisions which approximate\nthe same decimal value may compare unequal despite printing identically:\n\nAbstract base class of all floating-point scalar types.\n\nHalf-precision floating-point number type.\n\n`'e'`\n\n`numpy.float16`: 16-bit-precision floating-point number type: sign bit, 5 bits\nexponent, 10 bits mantissa.\n\nSingle-precision floating-point number type, compatible with C `float`.\n\n`'f'`\n\n`numpy.float32`: 32-bit-precision floating-point number type: sign bit, 8 bits\nexponent, 23 bits mantissa.\n\nDouble-precision floating-point number type, compatible with Python `float`\nand C `double`.\n\n`'d'`\n\n`numpy.float_`\n\n`numpy.float64`: 64-bit precision floating-point number type: sign bit, 11\nbits exponent, 52 bits mantissa.\n\nExtended-precision floating-point number type, compatible with C `long double`\nbut not necessarily with IEEE 754 quadruple-precision.\n\n`'g'`\n\n`numpy.longfloat`\n\n`numpy.float128`: 128-bit extended-precision floating-point number type.\n\nAbstract base class of all complex number scalar types that are made up of\nfloating-point numbers.\n\nComplex number type composed of two single-precision floating-point numbers.\n\n`'F'`\n\n`numpy.singlecomplex`\n\n`numpy.complex64`: Complex number type composed of 2 32-bit-precision\nfloating-point numbers.\n\nComplex number type composed of two double-precision floating-point numbers,\ncompatible with Python `complex`.\n\n`'D'`\n\n`numpy.cfloat`\n\n`numpy.complex_`\n\n`numpy.complex128`: Complex number type composed of 2 64-bit-precision\nfloating-point numbers.\n\nComplex number type composed of two extended-precision floating-point numbers.\n\n`'G'`\n\n`numpy.clongfloat`\n\n`numpy.longcomplex`\n\n`numpy.complex256`: Complex number type composed of 2 128-bit extended-\nprecision floating-point numbers.\n\nBoolean type (True or False), stored as a byte.\n\nWarning\n\nThe `bool_` type is not a subclass of the `int_` type (the `bool_` is not even\na number type). This is different than Python\u2019s default implementation of\n`bool` as a sub-class of `int`.\n\n`'?'`\n\n`numpy.bool8`\n\nIf created from a 64-bit integer, it represents an offset from\n`1970-01-01T00:00:00`. If created from string, the string can be in ISO 8601\ndate or datetime format.\n\nSee Datetimes and Timedeltas for more information.\n\n`'M'`\n\nA timedelta stored as a 64-bit integer.\n\nSee Datetimes and Timedeltas for more information.\n\n`'m'`\n\nAny Python object.\n\n`'O'`\n\nNote\n\nThe data actually stored in object arrays (i.e., arrays having dtype\n`object_`) are references to Python objects, not the objects themselves.\nHence, object arrays behave more like usual Python `lists`, in the sense that\ntheir contents need not be of the same Python type.\n\nThe object type is also special because an array containing `object_` items\ndoes not return an `object_` object on item access, but instead returns the\nactual object that the array item refers to.\n\nThe following data types are flexible: they have no predefined size and the\ndata they describe can be of different length in different arrays. (In the\ncharacter codes `#` is an integer denoting how many elements the data type\nconsists of.)\n\nAbstract base class of all scalar types without predefined length. The actual\nsize of these types depends on the specific `np.dtype` instantiation.\n\nA byte string.\n\nWhen used in arrays, this type strips trailing null bytes.\n\n`'S'`\n\n`numpy.string_`\n\nA unicode string.\n\nWhen used in arrays, this type strips trailing null codepoints.\n\nUnlike the builtin `str`, this supports the Buffer Protocol, exposing its\ncontents as UCS4:\n\n`'U'`\n\n`numpy.unicode_`\n\nEither an opaque sequence of bytes, or a structure.\n\nStructured `void` scalars can only be constructed via extraction from\nStructured arrays:\n\n`'V'`\n\nWarning\n\nSee Note on string types.\n\nNumeric Compatibility: If you used old typecode characters in your Numeric\ncode (which was never recommended), you will need to change some of them to\nthe new characters. In particular, the needed changes are `c -> S1`, `b -> B`,\n`1 -> b`, `s -> h`, `w -> H`, and `u -> I`. These changes make the type\ncharacter convention more consistent with other Python modules such as the\n`struct` module.\n\nAlong with their (mostly) C-derived names, the integer, float, and complex\ndata-types are also available using a bit-width convention so that an array of\nthe right size can always be ensured. Two aliases (`numpy.intp` and\n`numpy.uintp`) pointing to the integer type that is sufficiently large to hold\na C pointer are also provided.\n\nalias of `numpy.bool_`\n\nAliases for the signed integer types (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `numpy.longlong`) with the specified number of\nbits.\n\nCompatible with the C99 `int8_t`, `int16_t`, `int32_t`, and `int64_t`,\nrespectively.\n\nAlias for the unsigned integer types (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `numpy.ulonglong`) with the specified number\nof bits.\n\nCompatible with the C99 `uint8_t`, `uint16_t`, `uint32_t`, and `uint64_t`,\nrespectively.\n\nAlias for the signed integer type (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `np.longlong`) that is the same size as a\npointer.\n\nCompatible with the C `intptr_t`.\n\n`'p'`\n\nAlias for the unsigned integer type (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `np.ulonglong`) that is the same size as a\npointer.\n\nCompatible with the C `uintptr_t`.\n\n`'P'`\n\nalias of `numpy.half`\n\nalias of `numpy.single`\n\nalias of `numpy.double`\n\nAlias for `numpy.longdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\nalias of `numpy.csingle`\n\nalias of `numpy.cdouble`\n\nAlias for `numpy.clongdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\nThe first two of these are conveniences which resemble the names of the\nbuiltin types, in the same style as `bool_`, `int_`, `str_`, `bytes_`, and\n`object_`:\n\nalias of `numpy.double`\n\nalias of `numpy.cdouble`\n\nSome more use alternate naming conventions for extended-precision floats and\ncomplex numbers:\n\nalias of `numpy.longdouble`\n\nalias of `numpy.csingle`\n\nalias of `numpy.cdouble`\n\nalias of `numpy.clongdouble`\n\nalias of `numpy.clongdouble`\n\nThe following aliases originate from Python 2, and it is recommended that they\nnot be used in new code.\n\nalias of `numpy.bytes_`\n\nalias of `numpy.str_`\n\nThe array scalar objects have an `array priority` of `NPY_SCALAR_PRIORITY`\n(-1,000,000.0). They also do not (yet) have a `ctypes` attribute. Otherwise,\nthey share the same attributes as arrays:\n\n`generic.flags`\n\nThe integer value of flags.\n\n`generic.shape`\n\nTuple of array dimensions.\n\n`generic.strides`\n\nTuple of bytes steps in each dimension.\n\n`generic.ndim`\n\nThe number of array dimensions.\n\n`generic.data`\n\nPointer to start of data.\n\n`generic.size`\n\nThe number of elements in the gentype.\n\n`generic.itemsize`\n\nThe length of one element in bytes.\n\n`generic.base`\n\nScalar attribute identical to the corresponding array attribute.\n\n`generic.dtype`\n\nGet array data-descriptor.\n\n`generic.real`\n\nThe real part of the scalar.\n\n`generic.imag`\n\nThe imaginary part of the scalar.\n\n`generic.flat`\n\nA 1-D view of the scalar.\n\n`generic.T`\n\nScalar attribute identical to the corresponding array attribute.\n\n`generic.__array_interface__`\n\nArray protocol: Python side\n\n`generic.__array_struct__`\n\nArray protocol: struct\n\n`generic.__array_priority__`\n\nArray priority.\n\n`generic.__array_wrap__`\n\nsc.__array_wrap__(obj) return scalar from array\n\nSee also\n\nIndexing routines, Data type objects (dtype)\n\nArray scalars can be indexed like 0-dimensional arrays: if x is an array\nscalar,\n\nArray scalars have exactly the same methods as arrays. The default behavior of\nthese methods is to internally convert the scalar to an equivalent\n0-dimensional array and to call the corresponding array method. In addition,\nmath operations on array scalars are defined so that the same hardware flags\nare set and used to interpret the results as for ufunc, so that the error\nstate used for ufuncs also carries over to the math on array scalars.\n\nThe exceptions to the above rules are given below:\n\n`generic.__array__`\n\nsc.__array__(dtype) return 0-dim array from scalar with specified dtype\n\n`generic.__array_wrap__`\n\nsc.__array_wrap__(obj) return scalar from array\n\n`generic.squeeze`\n\nScalar method identical to the corresponding array attribute.\n\n`generic.byteswap`\n\nScalar method identical to the corresponding array attribute.\n\n`generic.__reduce__`\n\nHelper for pickle.\n\n`generic.__setstate__`\n\n`generic.setflags`\n\nScalar method identical to the corresponding array attribute.\n\nUtility method for typing:\n\n`number.__class_getitem__`(item, /)\n\nReturn a parametrized wrapper around the `number` type.\n\nThere are two ways to effectively define a new array scalar type (apart from\ncomposing structured types dtypes from the built-in scalar types): One way is\nto simply subclass the `ndarray` and overwrite the methods of interest. This\nwill work to a degree, but internally certain behaviors are fixed by the data\ntype of the array. To fully customize the data type of an array you need to\ndefine a new data-type, and register it with NumPy. Such new types can only be\ndefined in C, using the NumPy C-API.\n\n"}, {"name": "1", "path": "reference/random/parallel", "type": "Parallel Applications", "text": "\nThere are three strategies implemented that can be used to produce repeatable\npseudo-random numbers across multiple processes (local or distributed).\n\n`SeedSequence` implements an algorithm to process a user-provided seed,\ntypically as an integer of some size, and to convert it into an initial state\nfor a `BitGenerator`. It uses hashing techniques to ensure that low-quality\nseeds are turned into high quality initial states (at least, with very high\nprobability).\n\nFor example, `MT19937` has a state consisting of 624 `uint32` integers. A\nnaive way to take a 32-bit integer seed would be to just set the last element\nof the state to the 32-bit seed and leave the rest 0s. This is a valid state\nfor `MT19937`, but not a good one. The Mersenne Twister algorithm suffers if\nthere are too many 0s. Similarly, two adjacent 32-bit integer seeds (i.e.\n`12345` and `12346`) would produce very similar streams.\n\n`SeedSequence` avoids these problems by using successions of integer hashes\nwith good avalanche properties to ensure that flipping any bit in the input\ninput has about a 50% chance of flipping any bit in the output. Two input\nseeds that are very close to each other will produce initial states that are\nvery far from each other (with very high probability). It is also constructed\nin such a way that you can provide arbitrary-sized integers or lists of\nintegers. `SeedSequence` will take all of the bits that you provide and mix\nthem together to produce however many bits the consuming `BitGenerator` needs\nto initialize itself.\n\nThese properties together mean that we can safely mix together the usual user-\nprovided seed with simple incrementing counters to get `BitGenerator` states\nthat are (to very high probability) independent of each other. We can wrap\nthis together into an API that is easy to use and difficult to misuse.\n\nChild `SeedSequence` objects can also spawn to make grandchildren, and so on.\nEach `SeedSequence` has its position in the tree of spawned `SeedSequence`\nobjects mixed in with the user-provided seed to generate independent (with\nvery high probability) streams.\n\nThis feature lets you make local decisions about when and how to split up\nstreams without coordination between processes. You do not have to preallocate\nspace to avoid overlapping or request streams from a common global service.\nThis general \u201ctree-hashing\u201d scheme is not unique to numpy but not yet\nwidespread. Python has increasingly-flexible mechanisms for parallelization\navailable, and this scheme fits in very well with that kind of use.\n\nUsing this scheme, an upper bound on the probability of a collision can be\nestimated if one knows the number of streams that you derive. `SeedSequence`\nhashes its inputs, both the seed and the spawn-tree-path, down to a 128-bit\npool by default. The probability that there is a collision in that pool,\npessimistically-estimated (1), will be about \\\\(n^2*2^{-128}\\\\) where `n` is\nthe number of streams spawned. If a program uses an aggressive million\nstreams, about \\\\(2^{20}\\\\), then the probability that at least one pair of\nthem are identical is about \\\\(2^{-88}\\\\), which is in solidly-ignorable\nterritory (2).\n\nThe algorithm is carefully designed to eliminate a number of possible ways to\ncollide. For example, if one only does one level of spawning, it is guaranteed\nthat all states will be unique. But it\u2019s easier to estimate the naive upper\nbound on a napkin and take comfort knowing that the probability is actually\nlower.\n\nIn this calculation, we can mostly ignore the amount of numbers drawn from\neach stream. See Upgrading PCG64 with PCG64DXSM for the technical details\nabout `PCG64`. The other PRNGs we provide have some extra protection built in\nthat avoids overlaps if the `SeedSequence` pools differ in the slightest bit.\n`PCG64DXSM` has \\\\(2^{127}\\\\) separate cycles determined by the seed in\naddition to the position in the \\\\(2^{128}\\\\) long period for each cycle, so\none has to both get on or near the same cycle and seed a nearby position in\nthe cycle. `Philox` has completely independent cycles determined by the seed.\n`SFC64` incorporates a 64-bit counter so every unique seed is at least\n\\\\(2^{64}\\\\) iterations away from any other seed. And finally, `MT19937` has\njust an unimaginably huge period. Getting a collision internal to\n`SeedSequence` is the way a failure would be observed.\n\n`Philox` is a counter-based RNG based which generates values by encrypting an\nincrementing counter using weak cryptographic primitives. The seed determines\nthe key that is used for the encryption. Unique keys create unique,\nindependent streams. `Philox` lets you bypass the seeding algorithm to\ndirectly set the 128-bit key. Similar, but different, keys will still create\nindependent streams.\n\nThis scheme does require that you avoid reusing stream IDs. This may require\ncoordination between the parallel processes.\n\n`jumped` advances the state of the BitGenerator as-if a large number of random\nnumbers have been drawn, and returns a new instance with this state. The\nspecific number of draws varies by BitGenerator, and ranges from \\\\(2^{64}\\\\)\nto \\\\(2^{128}\\\\). Additionally, the as-if draws also depend on the size of the\ndefault random number produced by the specific BitGenerator. The BitGenerators\nthat support `jumped`, along with the period of the BitGenerator, the size of\nthe jump and the bits in the default unsigned random are listed below.\n\nBitGenerator\n\nPeriod\n\nJump Size\n\nBits per Draw\n\nMT19937\n\n\\\\(2^{19937}-1\\\\)\n\n\\\\(2^{128}\\\\)\n\n32\n\nPCG64\n\n\\\\(2^{128}\\\\)\n\n\\\\(~2^{127}\\\\) (3)\n\n64\n\nPCG64DXSM\n\n\\\\(2^{128}\\\\)\n\n\\\\(~2^{127}\\\\) (3)\n\n64\n\nPhilox\n\n\\\\(2^{256}\\\\)\n\n\\\\(2^{128}\\\\)\n\n64\n\nThe jump size is \\\\((\\phi-1)*2^{128}\\\\) where \\\\(\\phi\\\\) is the golden ratio.\nAs the jumps wrap around the period, the actual distances between neighboring\nstreams will slowly grow smaller than the jump size, but using the golden\nratio this way is a classic method of constructing a low-discrepancy sequence\nthat spreads out the states around the period optimally. You will not be able\nto jump enough to make those distances small enough to overlap in your\nlifetime.\n\n`jumped` can be used to produce long blocks which should be long enough to not\noverlap.\n\nWhen using `jumped`, one does have to take care not to jump to a stream that\nwas already used. In the above example, one could not later use\n`blocked_rng[0].jumped()` as it would overlap with `blocked_rng[1]`. Like with\nthe independent streams, if the main process here wants to split off 10 more\nstreams by jumping, then it needs to start with `range(10, 20)`, otherwise it\nwould recreate the same streams. On the other hand, if you carefully construct\nthe streams, then you are guaranteed to have streams that do not overlap.\n\n"}, {"name": "1", "path": "user/basics.broadcasting", "type": "User Guide", "text": "\nSee also\n\n`numpy.broadcast`\n\nThe term broadcasting describes how NumPy treats arrays with different shapes\nduring arithmetic operations. Subject to certain constraints, the smaller\narray is \u201cbroadcast\u201d across the larger array so that they have compatible\nshapes. Broadcasting provides a means of vectorizing array operations so that\nlooping occurs in C instead of Python. It does this without making needless\ncopies of data and usually leads to efficient algorithm implementations. There\nare, however, cases where broadcasting is a bad idea because it leads to\ninefficient use of memory that slows computation.\n\nNumPy operations are usually done on pairs of arrays on an element-by-element\nbasis. In the simplest case, the two arrays must have exactly the same shape,\nas in the following example:\n\nNumPy\u2019s broadcasting rule relaxes this constraint when the arrays\u2019 shapes meet\ncertain constraints. The simplest broadcasting example occurs when an array\nand a scalar value are combined in an operation:\n\nThe result is equivalent to the previous example where `b` was an array. We\ncan think of the scalar `b` being stretched during the arithmetic operation\ninto an array with the same shape as `a`. The new elements in `b`, as shown in\nFigure 1, are simply copies of the original scalar. The stretching analogy is\nonly conceptual. NumPy is smart enough to use the original scalar value\nwithout actually making copies so that broadcasting operations are as memory\nand computationally efficient as possible.\n\nFigure 1\n\nIn the simplest example of broadcasting, the scalar `b` is stretched to become\nan array of same shape as `a` so the shapes are compatible for element-by-\nelement multiplication.\n\nThe code in the second example is more efficient than that in the first\nbecause broadcasting moves less memory around during the multiplication (`b`\nis a scalar rather than an array).\n\nWhen operating on two arrays, NumPy compares their shapes element-wise. It\nstarts with the trailing (i.e. rightmost) dimensions and works its way left.\nTwo dimensions are compatible when\n\nIf these conditions are not met, a `ValueError: operands could not be\nbroadcast together` exception is thrown, indicating that the arrays have\nincompatible shapes. The size of the resulting array is the size that is not 1\nalong each axis of the inputs.\n\nArrays do not need to have the same number of dimensions. For example, if you\nhave a `256x256x3` array of RGB values, and you want to scale each color in\nthe image by a different value, you can multiply the image by a one-\ndimensional array with 3 values. Lining up the sizes of the trailing axes of\nthese arrays according to the broadcast rules, shows that they are compatible:\n\nWhen either of the dimensions compared is one, the other is used. In other\nwords, dimensions with size 1 are stretched or \u201ccopied\u201d to match the other.\n\nIn the following example, both the `A` and `B` arrays have axes with length\none that are expanded to a larger size during the broadcast operation:\n\nA set of arrays is called \u201cbroadcastable\u201d to the same shape if the above rules\nproduce a valid result.\n\nFor example, if `a.shape` is (5,1), `b.shape` is (1,6), `c.shape` is (6,) and\n`d.shape` is () so that d is a scalar, then a, b, c, and d are all\nbroadcastable to dimension (5,6); and\n\nHere are some more examples:\n\nHere are examples of shapes that do not broadcast:\n\nAn example of broadcasting when a 1-d array is added to a 2-d array:\n\nAs shown in Figure 2, `b` is added to each row of `a`. In Figure 3, an\nexception is raised because of the incompatible shapes.\n\nFigure 2\n\nA one dimensional array added to a two dimensional array results in\nbroadcasting if number of 1-d array elements matches the number of 2-d array\ncolumns.\n\nFigure 3\n\nWhen the trailing dimensions of the arrays are unequal, broadcasting fails\nbecause it is impossible to align the values in the rows of the 1st array with\nthe elements of the 2nd arrays for element-by-element addition.\n\nBroadcasting provides a convenient way of taking the outer product (or any\nother outer operation) of two arrays. The following example shows an outer\naddition operation of two 1-d arrays:\n\nFigure 4\n\nIn some cases, broadcasting stretches both arrays to form an output array\nlarger than either of the initial arrays.\n\nHere the `newaxis` index operator inserts a new axis into `a`, making it a\ntwo-dimensional `4x1` array. Combining the `4x1` array with `b`, which has\nshape `(3,)`, yields a `4x3` array.\n\nBroadcasting comes up quite often in real world problems. A typical example\noccurs in the vector quantization (VQ) algorithm used in information theory,\nclassification, and other related areas. The basic operation in VQ finds the\nclosest point in a set of points, called `codes` in VQ jargon, to a given\npoint, called the `observation`. In the very simple, two-dimensional case\nshown below, the values in `observation` describe the weight and height of an\nathlete to be classified. The `codes` represent different classes of athletes.\n1 Finding the closest point requires calculating the distance between\nobservation and each of the codes. The shortest distance provides the best\nmatch. In this example, `codes[0]` is the closest class indicating that the\nathlete is likely a basketball player.\n\nIn this example, the `observation` array is stretched to match the shape of\nthe `codes` array:\n\nFigure 5\n\nThe basic operation of vector quantization calculates the distance between an\nobject to be classified, the dark square, and multiple known codes, the gray\ncircles. In this simple case, the codes represent individual classes. More\ncomplex cases use multiple codes per class.\n\nTypically, a large number of `observations`, perhaps read from a database, are\ncompared to a set of `codes`. Consider this scenario:\n\nThe three-dimensional array, `diff`, is a consequence of broadcasting, not a\nnecessity for the calculation. Large data sets will generate a large\nintermediate array that is computationally inefficient. Instead, if each\nobservation is calculated individually using a Python loop around the code in\nthe two-dimensional example above, a much smaller array is used.\n\nBroadcasting is a powerful tool for writing short and usually intuitive code\nthat does its computations very efficiently in C. However, there are cases\nwhen broadcasting uses unnecessarily large amounts of memory for a particular\nalgorithm. In these cases, it is better to write the algorithm\u2019s outer loop in\nPython. This may also produce more readable code, as algorithms that use\nbroadcasting tend to become more difficult to interpret as the number of\ndimensions in the broadcast increases.\n\nIn this example, weight has more impact on the distance calculation than\nheight because of the larger values. In practice, it is important to normalize\nthe height and weight, often by their standard deviation across the data set,\nso that both have equal influence on the distance calculation.\n\n"}, {"name": "1", "path": "reference/routines.polynomials", "type": "Polynomials", "text": "\nPolynomials in NumPy can be created, manipulated, and even fitted using the\nconvenience classes of the `numpy.polynomial` package, introduced in NumPy\n1.4.\n\nPrior to NumPy 1.4, `numpy.poly1d` was the class of choice and it is still\navailable in order to maintain backward compatibility. However, the newer\n`polynomial package` is more complete and its `convenience classes` provide a\nmore consistent, better-behaved interface for working with polynomial\nexpressions. Therefore `numpy.polynomial` is recommended for new coding.\n\nNote\n\nTerminology\n\nThe term polynomial module refers to the old API defined in\n`numpy.lib.polynomial`, which includes the `numpy.poly1d` class and the\npolynomial functions prefixed with poly accessible from the `numpy` namespace\n(e.g. `numpy.polyadd`, `numpy.polyval`, `numpy.polyfit`, etc.).\n\nThe term polynomial package refers to the new API defined in\n`numpy.polynomial`, which includes the convenience classes for the different\nkinds of polynomials (`numpy.polynomial.Polynomial`,\n`numpy.polynomial.Chebyshev`, etc.).\n\nAs noted above, the `poly1d class` and associated functions defined in\n`numpy.lib.polynomial`, such as `numpy.polyfit` and `numpy.poly`, are\nconsidered legacy and should not be used in new code. Since NumPy version 1.4,\nthe `numpy.polynomial` package is preferred for working with polynomials.\n\nThe following table highlights some of the main differences between the legacy\npolynomial module and the polynomial package for common tasks. The\n`Polynomial` class is imported for brevity:\n\nHow to\u2026\n\nLegacy (`numpy.poly1d`)\n\n`numpy.polynomial`\n\nCreate a polynomial object from coefficients 1\n\n`p = np.poly1d([1, 2, 3])`\n\n`p = Polynomial([3, 2, 1])`\n\nCreate a polynomial object from roots\n\n`r = np.poly([-1, 1])` `p = np.poly1d(r)`\n\n`p = Polynomial.fromroots([-1, 1])`\n\nFit a polynomial of degree `deg` to data\n\n`np.polyfit(x, y, deg)`\n\n`Polynomial.fit(x, y, deg)`\n\nNote the reversed ordering of the coefficients\n\nThere are significant differences between `numpy.lib.polynomial` and\n`numpy.polynomial`. The most significant difference is the ordering of the\ncoefficients for the polynomial expressions. The various routines in\n`numpy.polynomial` all deal with series whose coefficients go from degree zero\nupward, which is the reverse order of the poly1d convention. The easy way to\nremember this is that indices correspond to degree, i.e., `coef[i]` is the\ncoefficient of the term of degree i.\n\nThough the difference in convention may be confusing, it is straightforward to\nconvert from the legacy polynomial API to the new. For example, the following\ndemonstrates how you would convert a `numpy.poly1d` instance representing the\nexpression \\\\(x^{2} + 2x + 3\\\\) to a `Polynomial` instance representing the\nsame expression:\n\nIn addition to the `coef` attribute, polynomials from the polynomial package\nalso have `domain` and `window` attributes. These attributes are most relevant\nwhen fitting polynomials to data, though it should be noted that polynomials\nwith different `domain` and `window` attributes are not considered equal, and\ncan\u2019t be mixed in arithmetic:\n\nSee the documentation for the convenience classes for further details on the\n`domain` and `window` attributes.\n\nAnother major difference between the legacy polynomial module and the\npolynomial package is polynomial fitting. In the old module, fitting was done\nvia the `polyfit` function. In the polynomial package, the `fit` class method\nis preferred. For example, consider a simple linear fit to the following data:\n\nWith the legacy polynomial module, a linear fit (i.e. polynomial of degree 1)\ncould be applied to these data with `polyfit`:\n\nWith the new polynomial API, the `fit` class method is preferred:\n\nNote that the coefficients are given in the scaled domain defined by the\nlinear mapping between the `window` and `domain`. `convert` can be used to get\nthe coefficients in the unscaled data domain.\n\nIn addition to standard power series polynomials, the polynomial package\nprovides several additional kinds of polynomials including Chebyshev, Hermite\n(two subtypes), Laguerre, and Legendre polynomials. Each of these has an\nassociated `convenience class` available from the `numpy.polynomial` namespace\nthat provides a consistent interface for working with polynomials regardless\nof their type.\n\nDocumentation pertaining to specific functions defined for each kind of\npolynomial individually can be found in the corresponding module\ndocumentation:\n\n"}, {"name": "1", "path": "reference/routines.polynomials.chebyshev", "type": "Chebyshev Series ( \n        \n         numpy.polynomial.chebyshev\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Chebyshev series, including a `Chebyshev` class that encapsulates the\nusual arithmetic operations. (General information on how this module\nrepresents and works with such polynomials is in the docstring for its\n\u201cparent\u201d sub-package, `numpy.polynomial`).\n\n`Chebyshev`(coef[, domain, window])\n\nA Chebyshev series class.\n\n`chebdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebadd`(c1, c2)\n\nAdd one Chebyshev series to another.\n\n`chebsub`(c1, c2)\n\nSubtract one Chebyshev series from another.\n\n`chebmulx`(c)\n\nMultiply a Chebyshev series by x.\n\n`chebmul`(c1, c2)\n\nMultiply one Chebyshev series by another.\n\n`chebdiv`(c1, c2)\n\nDivide one Chebyshev series by another.\n\n`chebpow`(c, pow[, maxpower])\n\nRaise a Chebyshev series to a power.\n\n`chebval`(x, c[, tensor])\n\nEvaluate a Chebyshev series at points x.\n\n`chebval2d`(x, y, c)\n\nEvaluate a 2-D Chebyshev series at points (x, y).\n\n`chebval3d`(x, y, z, c)\n\nEvaluate a 3-D Chebyshev series at points (x, y, z).\n\n`chebgrid2d`(x, y, c)\n\nEvaluate a 2-D Chebyshev series on the Cartesian product of x and y.\n\n`chebgrid3d`(x, y, z, c)\n\nEvaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.\n\n`chebder`(c[, m, scl, axis])\n\nDifferentiate a Chebyshev series.\n\n`chebint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Chebyshev series.\n\n`chebfromroots`(roots)\n\nGenerate a Chebyshev series with given roots.\n\n`chebroots`(c)\n\nCompute the roots of a Chebyshev series.\n\n`chebvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`chebvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`chebvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`chebgauss`(deg)\n\nGauss-Chebyshev quadrature.\n\n`chebweight`(x)\n\nThe weight function of the Chebyshev polynomials.\n\n`chebcompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`chebfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Chebyshev series to data.\n\n`chebpts1`(npts)\n\nChebyshev points of the first kind.\n\n`chebpts2`(npts)\n\nChebyshev points of the second kind.\n\n`chebtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`chebline`(off, scl)\n\nChebyshev series whose graph is a straight line.\n\n`cheb2poly`(c)\n\nConvert a Chebyshev series to a polynomial.\n\n`poly2cheb`(pol)\n\nConvert a polynomial to a Chebyshev series.\n\n`chebinterpolate`(func, deg[, args])\n\nInterpolate a function at the Chebyshev points of the first kind.\n\n`numpy.polynomial`\n\nThe implementations of multiplication, division, integration, and\ndifferentiation use the algebraic identities [1]:\n\nwhere\n\nThese identities allow a Chebyshev series to be expressed as a finite,\nsymmetric Laurent series. In this module, this sort of Laurent series is\nreferred to as a \u201cz-series.\u201d\n\nA. T. Benjamin, et al., \u201cCombinatorial Trigonometry with Chebyshev\nPolynomials,\u201d Journal of Statistical Planning and Inference 14, 2008\n(https://web.archive.org/web/20080221202153/https://www.math.hmc.edu/~benjamin/papers/CombTrig.pdf,\npg. 4)\n\n"}, {"name": "add_data_dir()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_data_dir", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nRecursively add files under data_path to data_files list.\n\nRecursively add files under data_path to the list of data_files to be\ninstalled (and distributed). The data_path can be either a relative path-name,\nor an absolute path-name, or a 2-tuple where the first argument shows where in\nthe install directory the data directory should be installed to.\n\nArgument can be either\n\nRules for installation paths:\n\nFor example suppose the source directory contains fun/foo.dat and\nfun/bar/car.dat:\n\nWill install data-files to the locations:\n\n"}, {"name": "add_data_files()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_data_files", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd data files to configuration data_files.\n\nArgument(s) can be either\n\nThe form of each element of the files sequence is very flexible allowing many\ncombinations of where to get the files from the package and where they should\nultimately be installed on the system. The most basic usage is for an element\nof the files argument sequence to be a simple filename. This will cause that\nfile from the local path to be installed to the installation path of the\nself.name package (package path). The file argument can also be a relative\npath in which case the entire relative path will be installed into the package\ndirectory. Finally, the file can be an absolute path name in which case the\nfile will be found at the absolute path name but installed to the package\npath.\n\nThis basic behavior can be augmented by passing a 2-tuple in as the file\nargument. The first element of the tuple should specify the relative path\n(under the package install directory) where the remaining sequence of files\nshould be installed to (it has nothing to do with the file-names in the source\ndistribution). The second element of the tuple is the sequence of files that\nshould be installed. The files in this sequence can be filenames, relative\npaths, or absolute paths. For absolute paths the file will be installed in the\ntop-level package installation directory (regardless of the first argument).\nFilenames and relative path names will be installed in the package install\ndirectory under the path name given as the first element of the tuple.\n\nRules for installation paths:\n\nAn additional feature is that the path to a data-file can actually be a\nfunction that takes no arguments and returns the actual path(s) to the data-\nfiles. This is useful when the data files are generated while building the\npackage.\n\nAdd files to the list of data_files to be included with the package.\n\nwill install these data files to:\n\nwhere <package install directory> is the package (or sub-package) directory\nsuch as \u2018/usr/lib/python2.4/site-packages/mypackage\u2019 (\u2018C: Python2.4 Lib site-\npackages mypackage\u2019) or \u2018/usr/lib/python2.4/site-\npackages/mypackage/mysubpackage\u2019 (\u2018C: Python2.4 Lib site-packages mypackage\nmysubpackage\u2019).\n\n"}, {"name": "add_extension()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_extension", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd extension to configuration.\n\nCreate and add an Extension instance to the ext_modules list. This method also\ntakes the following optional keyword arguments that are passed on to the\nExtension constructor.\n\nname of the extension\n\nlist of the sources. The list of sources may contain functions (called source\ngenerators) which must take an extension instance and a build directory as\ninputs and return a source file or list of source files or None. If None is\nreturned then no sources are generated. If the Extension instance has no\nsources after processing all source generators, then no extension module is\nbuilt.\n\nThe depends list contains paths to files or directories that the sources of\nthe extension module depend on. If any path in the depends list is newer than\nthe extension module, then the module will be rebuilt.\n\ndict or list of dict of keywords to be appended to keywords.\n\nThe self.paths(\u2026) method is applied to all lists that may contain paths.\n\n"}, {"name": "add_headers()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_headers", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd installable headers to configuration.\n\nAdd the given sequence of files to the beginning of the headers list. By\ndefault, headers will be installed under <python-\ninclude>/<self.name.replace(\u2018.\u2019,\u2019/\u2019)>/ directory. If an item of files is a\ntuple, then its first argument specifies the actual installation location\nrelative to the <python-include> path.\n\nArgument(s) can be either:\n\n"}, {"name": "add_include_dirs()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_include_dirs", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd paths to configuration include directories.\n\nAdd the given sequence of paths to the beginning of the include_dirs list.\nThis list will be visible to all extension modules of the current package.\n\n"}, {"name": "add_installed_library()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_installed_library", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nSimilar to add_library, but the specified library is installed.\n\nMost C libraries used with `distutils` are only used to build python\nextensions, but libraries built through this method will be installed so that\nthey can be reused by third-party packages.\n\nName of the installed library.\n\nList of the library\u2019s source files. See `add_library` for details.\n\nPath to install the library, relative to the current sub-package.\n\nThe following keys are allowed:\n\nSee also\n\nThe best way to encode the options required to link against the specified C\nlibraries is to use a \u201clibname.ini\u201d file, and use `get_info` to retrieve the\nrequired options (see `add_npy_pkg_config` for more information).\n\n"}, {"name": "add_library()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_library", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd library to configuration.\n\nName of the extension.\n\nList of the sources. The list of sources may contain functions (called source\ngenerators) which must take an extension instance and a build directory as\ninputs and return a source file or list of source files or None. If None is\nreturned then no sources are generated. If the Extension instance has no\nsources after processing all source generators, then no extension module is\nbuilt.\n\nThe following keys are allowed:\n\n"}, {"name": "add_npy_pkg_config()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_npy_pkg_config", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nGenerate and install a npy-pkg config file from a template.\n\nThe config file generated from `template` is installed in the given install\ndirectory, using `subst_dict` for variable substitution.\n\nThe path of the template, relatively to the current package path.\n\nWhere to install the npy-pkg config file, relatively to the current package\npath.\n\nIf given, any string of the form `@key@` will be replaced by `subst_dict[key]`\nin the template file when installed. The install prefix is always available\nthrough the variable `@prefix@`, since the install prefix is not easy to get\nreliably from setup.py.\n\nSee also\n\nThis works for both standard installs and in-place builds, i.e. the `@prefix@`\nrefer to the source directory for in-place builds.\n\nAssuming the foo.ini.in file has the following content:\n\nThe generated file will have the following content:\n\nand will be installed as foo.ini in the \u2018lib\u2019 subpath.\n\nWhen cross-compiling with numpy distutils, it might be necessary to use\nmodified npy-pkg-config files. Using the default/generated files will link\nwith the host libraries (i.e. libnpymath.a). For cross-compilation you of-\ncourse need to link with target libraries, while using the host Python\ninstallation.\n\nYou can copy out the numpy/core/lib/npy-pkg-config directory, add a pkgdir\nvalue to the .ini files and set NPY_PKG_CONFIG_PATH environment variable to\npoint to the directory with the modified npy-pkg-config files.\n\nExample npymath.ini modified for cross-compilation:\n\n"}, {"name": "add_scripts()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_scripts", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd scripts to configuration.\n\nAdd the sequence of files to the beginning of the scripts list. Scripts will\nbe installed under the <prefix>/bin/ directory.\n\n"}, {"name": "add_subpackage()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_subpackage", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd a sub-package to the current Configuration instance.\n\nThis is useful in a setup.py script for adding sub-packages to a package.\n\nname of the subpackage\n\nif given, the subpackage path such as the subpackage is in subpackage_path /\nsubpackage_name. If None,the subpackage is assumed to be located in the local\npath / subpackage_name.\n\n"}, {"name": "Additional Git Resources", "path": "dev/gitwash/git_resources", "type": "Development", "text": "\nThere are many ways of working with git; here are some posts on the rules of\nthumb that other projects have come up with:\n\nYou can get these on your own machine with (e.g) `git help push` or (same\nthing) `git push --help`, but, for convenience, here are the online manual\npages for some common commands:\n\n"}, {"name": "Advanced debugging tools", "path": "dev/development_advanced_debugging", "type": "Development", "text": "\nIf you reached here, you want to dive into, or use, more advanced tooling.\nThis is usually not necessary for first time contributors and most day-to-day\ndevelopment. These are used more rarely, for example close to a new NumPy\nrelease, or when a large or particular complex change was made.\n\nSince not all of these tools are used on a regular bases and only available on\nsome systems, please expect differences, issues, or quirks; we will be happy\nto help if you get stuck and appreciate any improvements or suggestions to\nthese workflows.\n\nMost development will not require more than a typical debugging toolchain as\nshown in Debugging. But for example memory leaks can be particularly subtle or\ndifficult to narrow down.\n\nWe do not expect any of these tools to be run by most contributors. However,\nyou can ensure that we can track down such issues more easily easier:\n\nThis will help us catch any oversights before your change is released and\nmeans you do not have to worry about making reference counting errors, which\ncan be intimidating.\n\nDebug builds of Python are easily available for example on `debian` systems,\nand can be used on all platforms. Running a test or terminal is usually as\neasy as:\n\nand were already mentioned in Debugging.\n\nA Python debug build will help:\n\nPython debug builds allows to check correct reference counting. This works\nusing the additional commands:\n\nRunning the test suite only with a debug python build will not find many\nerrors on its own. An additional advantage of a debug build of Python is that\nit allows detecting memory leaks.\n\nA tool to make this easier is pytest-leaks, which can be installed using\n`pip`. Unfortunately, `pytest` itself may leak memory, but good results can\nusually (currently) be achieved by removing:\n\nfrom `numpy/conftest.py` (This may change with new `pytest-leaks` versions or\n`pytest` updates).\n\nThis allows to run the test suite, or part of it, conveniently:\n\nwhere `-R2:3` is the `pytest-leaks` command (see its documentation), the `-s`\ncauses output to print and may be necessary (in some versions captured output\nwas detected as a leak).\n\nNote that some tests are known (or even designed) to leak references, we try\nto mark them, but expect some false positives.\n\nValgrind is a powerful tool to find certain memory access problems and should\nbe run on complicated C code. Basic use of `valgrind` usually requires no more\nthan:\n\nwhere `PYTHONMALLOC=malloc` is necessary to avoid false positives from python\nitself. Depending on the system and valgrind version, you may see more false\npositives. `valgrind` supports \u201csuppressions\u201d to ignore some of these, and\nPython does have a suppression file (and even a compile time option) which may\nhelp if you find it necessary.\n\nValgrind helps:\n\nFind many memory leaks. Note that for most leaks the python debug build\napproach (and `pytest-leaks`) is much more sensitive. The reason is that\n`valgrind` can only detect if memory is definitely lost. If:\n\nHas incorrect reference counting for `dtype`, this is a bug, but valgrind\ncannot see it because `np.dtype(np.int64)` always returns the same object.\nHowever, not all dtypes are singletons, so this might leak memory for\ndifferent input. In rare cases NumPy uses `malloc` and not the Python memory\nallocators which are invisible to the Python debug build. `malloc` should\nnormally be avoided, but there are some exceptions (e.g. the `PyArray_Dims`\nstructure is public API and cannot use the Python allocators.)\n\nEven though using valgrind for memory leak detection is slow and less\nsensitive it can be a convenient: you can run most programs with valgrind\nwithout modification.\n\nThings to be aware of:\n\nA big advantage of valgrind is that it has no requirements aside from valgrind\nitself (although you probably want to use debug builds for better tracebacks).\n\nYou can run the test suite with valgrind which may be sufficient when you are\nonly interested in a few tests:\n\nNote the `--continue-on-collection-errors`, which is currently necessary due\nto missing `longdouble` support causing failures (this will usually not be\nnecessary if you do not run the full test suite).\n\nIf you wish to detect memory leaks you will also require `--show-leak-\nkinds=definite` and possibly more valgrind options. Just as for `pytest-leaks`\ncertain tests are known to leak cause errors in valgrind and may or may not be\nmarked as such.\n\nWe have developed pytest-valgrind which:\n\nPlease refer to its `README` for more information (it includes an example\ncommand for NumPy).\n\n"}, {"name": "Advanced F2PY use cases", "path": "f2py/advanced", "type": "Advanced F2PY use cases", "text": "\nUser-defined Python C/API functions can be defined inside signature files\nusing `usercode` and `pymethoddef` statements (they must be used inside the\n`python module` block). For example, the following signature file `spam.pyf`\n\nwraps the C library function `system()`:\n\nIn Python this can then be used as:\n\nThe following example illustrates how to add user-defined variables to a F2PY\ngenerated extension module by modifying the dictionary of a F2PY generated\nmodule. Consider the following signature file (compiled with `f2py -c\nvar.pyf`):\n\nNotice that the second `usercode` statement must be defined inside an\n`interface` block and the module dictionary is available through the variable\n`d` (see `varmodule.c` generated by `f2py var.pyf` for additional details).\n\nUsage in Python:\n\nCurrently, F2PY can handle only `<type spec>(kind=<kindselector>)`\ndeclarations where `<kindselector>` is a numeric integer (e.g. 1, 2, 4,\u2026), but\nnot a function call `KIND(..)` or any other expression. F2PY needs to know\nwhat would be the corresponding C type and a general solution for that would\nbe too complicated to implement.\n\nHowever, F2PY provides a hook to overcome this difficulty, namely, users can\ndefine their own <Fortran type> to <C type> maps. For example, if Fortran 90\ncode contains:\n\nthen create a mapping file containing a Python dictionary:\n\nfor instance.\n\nUse the `--f2cmap` command-line option to pass the file name to F2PY. By\ndefault, F2PY assumes file name is `.f2py_f2cmap` in the current working\ndirectory.\n\nMore generally, the f2cmap file must contain a dictionary with items:\n\nthat defines mapping between Fortran type:\n\nand the corresponding <C type>. The <C type> can be one of the following:\n\nFor more information, see the F2Py source code `numpy/f2py/capi_maps.py`.\n\n"}, {"name": "Array creation", "path": "user/basics.creation", "type": "User Guide", "text": "\nSee also\n\nArray creation routines\n\nThere are 6 general mechanisms for creating arrays:\n\nYou can use these methods to create ndarrays or Structured arrays. This\ndocument will cover general methods for ndarray creation.\n\nNumPy arrays can be defined using Python sequences such as lists and tuples.\nLists and tuples are defined using `[...]` and `(...)`, respectively. Lists\nand tuples can define ndarray creation:\n\nWhen you use `numpy.array` to define a new array, you should consider the\ndtype of the elements in the array, which can be specified explicitly. This\nfeature gives you more control over the underlying data structures and how the\nelements are handled in C/C++ functions. If you are not careful with `dtype`\nassignments, you can get unwanted overflow, as such\n\nAn 8-bit signed integer represents integers from -128 to 127. Assigning the\n`int8` array to integers outside of this range results in overflow. This\nfeature can often be misunderstood. If you perform calculations with\nmismatching `dtypes`, you can get unwanted results, for example:\n\nNotice when you perform operations with two arrays of the same `dtype`:\n`uint32`, the resulting array is the same type. When you perform operations\nwith different `dtype`, NumPy will assign a new type that satisfies all of the\narray elements involved in the computation, here `uint32` and `int32` can both\nbe represented in as `int64`.\n\nThe default NumPy behavior is to create arrays in either 64-bit signed\nintegers or double precision floating point numbers, `int64` and `float`,\nrespectively. If you expect your arrays to be a certain type, then you need to\nspecify the `dtype` while you create the array.\n\nNumPy has over 40 built-in functions for creating arrays as laid out in the\nArray creation routines. These functions can be split into roughly three\ncategories, based on the dimension of the array they create:\n\nThe 1D array creation functions e.g. `numpy.linspace` and `numpy.arange`\ngenerally need at least two inputs, `start` and `stop`.\n\n`numpy.arange` creates arrays with regularly incrementing values. Check the\ndocumentation for complete information and examples. A few examples are shown:\n\nNote: best practice for `numpy.arange` is to use integer start, end, and step\nvalues. There are some subtleties regarding `dtype`. In the second example,\nthe `dtype` is defined. In the third example, the array is `dtype=float` to\naccommodate the step size of `0.1`. Due to roundoff error, the `stop` value is\nsometimes included.\n\n`numpy.linspace` will create arrays with a specified number of elements, and\nspaced equally between the specified beginning and end values. For example:\n\nThe advantage of this creation function is that you guarantee the number of\nelements and the starting and end point. The previous `arange(start, stop,\nstep)` will not include the value `stop`.\n\nThe 2D array creation functions e.g. `numpy.eye`, `numpy.diag`, and\n`numpy.vander` define properties of special matrices represented as 2D arrays.\n\n`np.eye(n, m)` defines a 2D identity matrix. The elements where i=j (row index\nand column index are equal) are 1 and the rest are 0, as such:\n\n`numpy.diag` can define either a square 2D array with given values along the\ndiagonal or if given a 2D array returns a 1D array that is only the diagonal\nelements. The two array creation functions can be helpful while doing linear\nalgebra, as such:\n\n`vander(x, n)` defines a Vandermonde matrix as a 2D NumPy array. Each column\nof the Vandermonde matrix is a decreasing power of the input 1D array or list\nor tuple, `x` where the highest polynomial order is `n-1`. This array creation\nroutine is helpful in generating linear least squares models, as such:\n\nThe ndarray creation functions e.g. `numpy.ones`, `numpy.zeros`, and `random`\ndefine arrays based upon the desired shape. The ndarray creation functions can\ncreate arrays with any dimension by specifying how many dimensions and length\nalong that dimension in a tuple or list.\n\n`numpy.zeros` will create an array filled with 0 values with the specified\nshape. The default dtype is `float64`:\n\n`numpy.ones` will create an array filled with 1 values. It is identical to\n`zeros` in all other respects as such:\n\nThe `random` method of the result of `default_rng` will create an array filled\nwith random values between 0 and 1. It is included with the `numpy.random`\nlibrary. Below, two arrays are created with shapes (2,3) and (2,3,2),\nrespectively. The seed is set to 42 so you can reproduce these pseudorandom\nnumbers:\n\n`numpy.indices` will create a set of arrays (stacked as a one-higher\ndimensioned array), one per dimension with each representing variation in that\ndimension:\n\nThis is particularly useful for evaluating functions of multiple dimensions on\na regular grid.\n\nOnce you have created arrays, you can replicate, join, or mutate those\nexisting arrays to create new arrays. When you assign an array or its elements\nto a new variable, you have to explicitly `numpy.copy` the array, otherwise\nthe variable is a view into the original array. Consider the following\nexample:\n\nIn this example, you did not create a new array. You created a variable, `b`\nthat viewed the first 2 elements of `a`. When you added 1 to `b` you would get\nthe same result by adding 1 to `a[:2]`. If you want to create a new array, use\nthe `numpy.copy` array creation routine as such:\n\nFor more information and examples look at Copies and Views.\n\nThere are a number of routines to join existing arrays e.g. `numpy.vstack`,\n`numpy.hstack`, and `numpy.block`. Here is an example of joining four 2-by-2\narrays into a 4-by-4 array using `block`:\n\nOther routines use similar syntax to join ndarrays. Check the routine\u2019s\ndocumentation for further examples and syntax.\n\nThis is the most common case of large array creation. The details depend\ngreatly on the format of data on disk. This section gives general pointers on\nhow to handle various formats. For more detailed examples of IO look at How to\nRead and Write files.\n\nVarious fields have standard formats for array data. The following lists the\nones with known Python libraries to read them and return NumPy arrays (there\nmay be others for which it is possible to read and convert to NumPy arrays so\ncheck the last section as well)\n\nExamples of formats that cannot be read directly but for which it is not hard\nto convert are those formats supported by libraries like PIL (able to read and\nwrite many image formats such as jpg, png, etc).\n\nDelimited files such as comma separated value (csv) and tab separated value\n(tsv) files are used for programs like Excel and LabView. Python functions can\nread and parse these files line-by-line. NumPy has two standard routines for\nimporting a file with delimited data `numpy.loadtxt` and `numpy.genfromtxt`.\nThese functions have more involved use cases in Reading and writing files. A\nsimple example given a `simple.csv`:\n\nImporting `simple.csv` is accomplished using `loadtxt`:\n\nMore generic ASCII files can be read using `scipy.io` and Pandas.\n\nThere are a variety of approaches one can use. If the file has a relatively\nsimple format then one can write a simple I/O library and use the NumPy\n`fromfile()` function and `.tofile()` method to read and write NumPy arrays\ndirectly (mind your byteorder though!) If a good C or C++ library exists that\nread the data, one can wrap that library with a variety of techniques though\nthat certainly is much more work and requires significantly more advanced\nknowledge to interface with C or C++.\n\nNumPy is the fundamental library for array containers in the Python Scientific\nComputing stack. Many Python libraries, including SciPy, Pandas, and OpenCV,\nuse NumPy ndarrays as the common format for data exchange, These libraries can\ncreate, operate on, and work with NumPy arrays.\n\n"}, {"name": "Array creation routines", "path": "reference/routines.array-creation", "type": "Array creation routines", "text": "\nSee also\n\nArray creation\n\n`empty`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, without initializing entries.\n\n`empty_like`(prototype[, dtype, order, subok, ...])\n\nReturn a new array with the same shape and type as a given array.\n\n`eye`(N[, M, k, dtype, order, like])\n\nReturn a 2-D array with ones on the diagonal and zeros elsewhere.\n\n`identity`(n[, dtype, like])\n\nReturn the identity array.\n\n`ones`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with ones.\n\n`ones_like`(a[, dtype, order, subok, shape])\n\nReturn an array of ones with the same shape and type as a given array.\n\n`zeros`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with zeros.\n\n`zeros_like`(a[, dtype, order, subok, shape])\n\nReturn an array of zeros with the same shape and type as a given array.\n\n`full`(shape, fill_value[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with `fill_value`.\n\n`full_like`(a, fill_value[, dtype, order, ...])\n\nReturn a full array with the same shape and type as a given array.\n\n`array`(object[, dtype, copy, order, subok, ...])\n\nCreate an array.\n\n`asarray`(a[, dtype, order, like])\n\nConvert the input to an array.\n\n`asanyarray`(a[, dtype, order, like])\n\nConvert the input to an ndarray, but pass ndarray subclasses through.\n\n`ascontiguousarray`(a[, dtype, like])\n\nReturn a contiguous array (ndim >= 1) in memory (C order).\n\n`asmatrix`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`copy`(a[, order, subok])\n\nReturn an array copy of the given object.\n\n`frombuffer`(buffer[, dtype, count, offset, like])\n\nInterpret a buffer as a 1-dimensional array.\n\n`fromfile`(file[, dtype, count, sep, offset, like])\n\nConstruct an array from data in a text or binary file.\n\n`fromfunction`(function, shape, *[, dtype, like])\n\nConstruct an array by executing a function over each coordinate.\n\n`fromiter`(iter, dtype[, count, like])\n\nCreate a new 1-dimensional array from an iterable object.\n\n`fromstring`(string[, dtype, count, like])\n\nA new 1-D array initialized from text data in a string.\n\n`loadtxt`(fname[, dtype, comments, delimiter, ...])\n\nLoad data from a text file.\n\nNote\n\n`numpy.rec` is the preferred alias for `numpy.core.records`.\n\n`core.records.array`(obj[, dtype, shape, ...])\n\nConstruct a record array from a wide-variety of objects.\n\n`core.records.fromarrays`(arrayList[, dtype, ...])\n\nCreate a record array from a (flat) list of arrays\n\n`core.records.fromrecords`(recList[, dtype, ...])\n\nCreate a recarray from a list of records in text form.\n\n`core.records.fromstring`(datastring[, dtype, ...])\n\nCreate a record array from binary data\n\n`core.records.fromfile`(fd[, dtype, shape, ...])\n\nCreate an array from binary file data\n\nNote\n\n`numpy.char` is the preferred alias for `numpy.core.defchararray`.\n\n`core.defchararray.array`(obj[, itemsize, ...])\n\nCreate a `chararray`.\n\n`core.defchararray.asarray`(obj[, itemsize, ...])\n\nConvert the input to a `chararray`, copying the data only if necessary.\n\n`arange`([start,] stop[, step,][, dtype, like])\n\nReturn evenly spaced values within a given interval.\n\n`linspace`(start, stop[, num, endpoint, ...])\n\nReturn evenly spaced numbers over a specified interval.\n\n`logspace`(start, stop[, num, endpoint, base, ...])\n\nReturn numbers spaced evenly on a log scale.\n\n`geomspace`(start, stop[, num, endpoint, ...])\n\nReturn numbers spaced evenly on a log scale (a geometric progression).\n\n`meshgrid`(*xi[, copy, sparse, indexing])\n\nReturn coordinate matrices from coordinate vectors.\n\n`mgrid`\n\n`nd_grid` instance which returns a dense multi-dimensional \"meshgrid\".\n\n`ogrid`\n\n`nd_grid` instance which returns an open multi-dimensional \"meshgrid\".\n\n`diag`(v[, k])\n\nExtract a diagonal or construct a diagonal array.\n\n`diagflat`(v[, k])\n\nCreate a two-dimensional array with the flattened input as a diagonal.\n\n`tri`(N[, M, k, dtype, like])\n\nAn array with ones at and below the given diagonal and zeros elsewhere.\n\n`tril`(m[, k])\n\nLower triangle of an array.\n\n`triu`(m[, k])\n\nUpper triangle of an array.\n\n`vander`(x[, N, increasing])\n\nGenerate a Vandermonde matrix.\n\n`mat`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`bmat`(obj[, ldict, gdict])\n\nBuild a matrix object from a string, nested sequence, or array.\n\n"}, {"name": "Array manipulation routines", "path": "reference/routines.array-manipulation", "type": "Array manipulation routines", "text": "\n`copyto`(dst, src[, casting, where])\n\nCopies values from one array to another, broadcasting as necessary.\n\n`shape`(a)\n\nReturn the shape of an array.\n\n`reshape`(a, newshape[, order])\n\nGives a new shape to an array without changing its data.\n\n`ravel`(a[, order])\n\nReturn a contiguous flattened array.\n\n`ndarray.flat`\n\nA 1-D iterator over the array.\n\n`ndarray.flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`moveaxis`(a, source, destination)\n\nMove axes of an array to new positions.\n\n`rollaxis`(a, axis[, start])\n\nRoll the specified axis backwards, until it lies in a given position.\n\n`swapaxes`(a, axis1, axis2)\n\nInterchange two axes of an array.\n\n`ndarray.T`\n\nThe transposed array.\n\n`transpose`(a[, axes])\n\nReverse or permute the axes of an array; returns the modified array.\n\n`atleast_1d`(*arys)\n\nConvert inputs to arrays with at least one dimension.\n\n`atleast_2d`(*arys)\n\nView inputs as arrays with at least two dimensions.\n\n`atleast_3d`(*arys)\n\nView inputs as arrays with at least three dimensions.\n\n`broadcast`\n\nProduce an object that mimics broadcasting.\n\n`broadcast_to`(array, shape[, subok])\n\nBroadcast an array to a new shape.\n\n`broadcast_arrays`(*args[, subok])\n\nBroadcast any number of arrays against each other.\n\n`expand_dims`(a, axis)\n\nExpand the shape of an array.\n\n`squeeze`(a[, axis])\n\nRemove axes of length one from `a`.\n\n`asarray`(a[, dtype, order, like])\n\nConvert the input to an array.\n\n`asanyarray`(a[, dtype, order, like])\n\nConvert the input to an ndarray, but pass ndarray subclasses through.\n\n`asmatrix`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`asfarray`(a[, dtype])\n\nReturn an array converted to a float type.\n\n`asfortranarray`(a[, dtype, like])\n\nReturn an array (ndim >= 1) laid out in Fortran order in memory.\n\n`ascontiguousarray`(a[, dtype, like])\n\nReturn a contiguous array (ndim >= 1) in memory (C order).\n\n`asarray_chkfinite`(a[, dtype, order])\n\nConvert the input to an array, checking for NaNs or Infs.\n\n`asscalar`(a)\n\nConvert an array of size 1 to its scalar equivalent.\n\n`require`(a[, dtype, requirements, like])\n\nReturn an ndarray of the provided type that satisfies requirements.\n\n`concatenate`([axis, out, dtype, casting])\n\nJoin a sequence of arrays along an existing axis.\n\n`stack`(arrays[, axis, out])\n\nJoin a sequence of arrays along a new axis.\n\n`block`(arrays)\n\nAssemble an nd-array from nested lists of blocks.\n\n`vstack`(tup)\n\nStack arrays in sequence vertically (row wise).\n\n`hstack`(tup)\n\nStack arrays in sequence horizontally (column wise).\n\n`dstack`(tup)\n\nStack arrays in sequence depth wise (along third axis).\n\n`column_stack`(tup)\n\nStack 1-D arrays as columns into a 2-D array.\n\n`row_stack`(tup)\n\nStack arrays in sequence vertically (row wise).\n\n`split`(ary, indices_or_sections[, axis])\n\nSplit an array into multiple sub-arrays as views into `ary`.\n\n`array_split`(ary, indices_or_sections[, axis])\n\nSplit an array into multiple sub-arrays.\n\n`dsplit`(ary, indices_or_sections)\n\nSplit array into multiple sub-arrays along the 3rd axis (depth).\n\n`hsplit`(ary, indices_or_sections)\n\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\n`vsplit`(ary, indices_or_sections)\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\n`tile`(A, reps)\n\nConstruct an array by repeating A the number of times given by reps.\n\n`repeat`(a, repeats[, axis])\n\nRepeat elements of an array.\n\n`delete`(arr, obj[, axis])\n\nReturn a new array with sub-arrays along an axis deleted.\n\n`insert`(arr, obj, values[, axis])\n\nInsert values along the given axis before the given indices.\n\n`append`(arr, values[, axis])\n\nAppend values to the end of an array.\n\n`resize`(a, new_shape)\n\nReturn a new array with the specified shape.\n\n`trim_zeros`(filt[, trim])\n\nTrim the leading and/or trailing zeros from a 1-D array or sequence.\n\n`unique`(ar[, return_index, return_inverse, ...])\n\nFind the unique elements of an array.\n\n`flip`(m[, axis])\n\nReverse the order of elements in an array along the given axis.\n\n`fliplr`(m)\n\nReverse the order of elements along axis 1 (left/right).\n\n`flipud`(m)\n\nReverse the order of elements along axis 0 (up/down).\n\n`reshape`(a, newshape[, order])\n\nGives a new shape to an array without changing its data.\n\n`roll`(a, shift[, axis])\n\nRoll array elements along a given axis.\n\n`rot90`(m[, k, axes])\n\nRotate an array by 90 degrees in the plane specified by axes.\n\n"}, {"name": "Array objects", "path": "reference/arrays", "type": "Array objects", "text": "\nNumPy provides an N-dimensional array type, the ndarray, which describes a\ncollection of \u201citems\u201d of the same type. The items can be indexed using for\nexample N integers.\n\nAll ndarrays are homogeneous: every item takes up the same size block of\nmemory, and all blocks are interpreted in exactly the same way. How each item\nin the array is to be interpreted is specified by a separate data-type object,\none of which is associated with every array. In addition to basic types\n(integers, floats, etc.), the data type objects can also represent data\nstructures.\n\nAn item extracted from an array, e.g., by indexing, is represented by a Python\nobject whose type is one of the array scalar types built in NumPy. The array\nscalars allow easy manipulation of also more complicated arrangements of data.\n\nFigure Conceptual diagram showing the relationship between the three\nfundamental objects used to describe the data in an array: 1) the ndarray\nitself, 2) the data-type object that describes the layout of a single fixed-\nsize element of the array, 3) the array-scalar Python object that is returned\nwhen a single element of the array is accessed.\n\n"}, {"name": "Binary operations", "path": "reference/routines.bitwise", "type": "Binary operations", "text": "\n`bitwise_and`(x1, x2, /[, out, where, ...])\n\nCompute the bit-wise AND of two arrays element-wise.\n\n`bitwise_or`(x1, x2, /[, out, where, casting, ...])\n\nCompute the bit-wise OR of two arrays element-wise.\n\n`bitwise_xor`(x1, x2, /[, out, where, ...])\n\nCompute the bit-wise XOR of two arrays element-wise.\n\n`invert`(x, /[, out, where, casting, order, ...])\n\nCompute bit-wise inversion, or bit-wise NOT, element-wise.\n\n`left_shift`(x1, x2, /[, out, where, casting, ...])\n\nShift the bits of an integer to the left.\n\n`right_shift`(x1, x2, /[, out, where, ...])\n\nShift the bits of an integer to the right.\n\n`packbits`(a, /[, axis, bitorder])\n\nPacks the elements of a binary-valued array into bits in a uint8 array.\n\n`unpackbits`(a, /[, axis, count, bitorder])\n\nUnpacks elements of a uint8 array into a binary-valued output array.\n\n`binary_repr`(num[, width])\n\nReturn the binary representation of the input number as a string.\n\n"}, {"name": "Bit Generators", "path": "reference/random/bit_generators/index", "type": "Bit Generators", "text": "\nThe random values produced by `Generator` originate in a BitGenerator. The\nBitGenerators do not directly provide random numbers and only contains methods\nused for seeding, getting or setting the state, jumping or advancing the\nstate, and for accessing low-level wrappers for consumption by code that can\nefficiently access the functions provided, e.g., numba.\n\nThe included BitGenerators are:\n\n`BitGenerator`([seed])\n\nBase Class for generic BitGenerators, which provide a stream of random bits\nbased on different algorithms.\n\n"}, {"name": "broadcast.index", "path": "reference/generated/numpy.broadcast.index", "type": "Standard array subclasses", "text": "\nattribute\n\ncurrent index in broadcasted result\n\n"}, {"name": "broadcast.iters", "path": "reference/generated/numpy.broadcast.iters", "type": "Standard array subclasses", "text": "\nattribute\n\ntuple of iterators along `self`\u2019s \u201ccomponents.\u201d\n\nReturns a tuple of `numpy.flatiter` objects, one for each \u201ccomponent\u201d of\n`self`.\n\nSee also\n\n"}, {"name": "broadcast.nd", "path": "reference/generated/numpy.broadcast.nd", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of dimensions of broadcasted result. For code intended for NumPy 1.12.0\nand later the more consistent `ndim` is preferred.\n\n"}, {"name": "broadcast.ndim", "path": "reference/generated/numpy.broadcast.ndim", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of dimensions of broadcasted result. Alias for `nd`.\n\nNew in version 1.12.0.\n\n"}, {"name": "broadcast.numiter", "path": "reference/generated/numpy.broadcast.numiter", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of iterators possessed by the broadcasted result.\n\n"}, {"name": "broadcast.reset()", "path": "reference/generated/numpy.broadcast.reset", "type": "numpy.broadcast.reset", "text": "\nmethod\n\nReset the broadcasted result\u2019s iterator(s).\n\n"}, {"name": "broadcast.size", "path": "reference/generated/numpy.broadcast.size", "type": "Standard array subclasses", "text": "\nattribute\n\nTotal size of broadcasted result.\n\n"}, {"name": "build_src", "path": "f2py/buildtools/distutils", "type": "Using via \n        \n         numpy.distutils", "text": "\n`numpy.distutils` is part of NumPy, and extends the standard Python\n`distutils` module to deal with Fortran sources and F2PY signature files, e.g.\ncompile Fortran sources, call F2PY to construct extension modules, etc.\n\nExample\n\nConsider the following `setup_file.py` for the `fib` and `scalar` examples\nfrom Three ways to wrap - getting started section:\n\nRunning\n\nwill build two extension modules `scalar` and `fib2` to the build directory.\n\n`numpy.distutils` extends `distutils` with the following features:\n\n`Extension` class argument `sources` may contain Fortran source files. In\naddition, the list `sources` may contain at most one F2PY signature file, and\nin this case, the name of an Extension module must match with the\n`<modulename>` used in signature file. It is assumed that an F2PY signature\nfile contains exactly one `python module` block.\n\nIf `sources` do not contain a signature file, then F2PY is used to scan\nFortran source files to construct wrappers to the Fortran codes.\n\nAdditional options to the F2PY executable can be given using the `Extension`\nclass argument `f2py_options`.\n\nThe following new `distutils` commands are defined:\n\nto construct Fortran wrapper extension modules, among many other things.\n\nto change Fortran compiler options.\n\nAdditionally, the `build_ext` and `build_clib` commands are also enhanced to\nsupport Fortran sources.\n\nRun\n\nto see available options for these commands.\n\nWhen building Python packages containing Fortran sources, one can choose\ndifferent Fortran compilers by using the `build_ext` command option\n`--fcompiler=<Vendor>`. Here `<Vendor>` can be one of the following names (on\n`linux` systems):\n\nSee `numpy_distutils/fcompiler.py` for an up-to-date list of supported\ncompilers for different platforms, or run\n\n"}, {"name": "Building from source", "path": "user/building", "type": "User Guide", "text": "\nThere are two options for building NumPy- building with Gitpod or locally from\nsource. Your choice depends on your operating system and familiarity with the\ncommand line.\n\nGitpod is an open-source platform that automatically creates the correct\ndevelopment environment right in your browser, reducing the need to install\nlocal development environments and deal with incompatible dependencies.\n\nIf you are a Windows user, unfamiliar with using the command line or building\nNumPy for the first time, it is often faster to build with Gitpod. Here are\nthe in-depth instructions for building NumPy with building NumPy with Gitpod.\n\nBuilding locally on your machine gives you more granular control. If you are a\nMacOS or Linux user familiar with using the command line, you can continue\nwith building NumPy locally by following the instructions below.\n\nBuilding NumPy requires the following software installed:\n\nPython 3.6.x or newer\n\nPlease note that the Python development headers also need to be installed,\ne.g., on Debian/Ubuntu one needs to install both `python3` and `python3-dev`.\nOn Windows and macOS this is normally not an issue.\n\nCompilers\n\nMuch of NumPy is written in C. You will need a C compiler that complies with\nthe C99 standard.\n\nWhile a FORTRAN 77 compiler is not necessary for building NumPy, it is needed\nto run the `numpy.f2py` tests. These tests are skipped if the compiler is not\nauto-detected.\n\nNote that NumPy is developed mainly using GNU compilers and tested on MSVC and\nClang compilers. Compilers from other vendors such as Intel, Absoft, Sun, NAG,\nCompaq, Vast, Portland, Lahey, HP, IBM are only supported in the form of\ncommunity feedback, and may not work out of the box. GCC 4.x (and later)\ncompilers are recommended. On ARM64 (aarch64) GCC 8.x (and later) are\nrecommended.\n\nLinear Algebra libraries\n\nNumPy does not require any external linear algebra libraries to be installed.\nHowever, if these are available, NumPy\u2019s setup script can detect them and use\nthem for building. A number of different LAPACK library setups can be used,\nincluding optimized LAPACK libraries such as OpenBLAS or MKL. The choice and\nlocation of these libraries as well as include paths and other such build\noptions can be specified in a `site.cfg` file located in the NumPy root\nrepository or a `.numpy-site.cfg` file in your home directory. See the\n`site.cfg.example` example file included in the NumPy repository or sdist for\ndocumentation, and below for specifying search priority from environmental\nvariables.\n\nCython\n\nFor building NumPy, you\u2019ll need a recent version of Cython.\n\nTo install NumPy, run:\n\nTo perform an in-place build that can be run from the source folder run:\n\nNote: for build instructions to do development work on NumPy itself, see\nSetting up and using your development environment.\n\nMake sure to test your builds. To ensure everything stays in shape, see if all\ntests pass:\n\nFor detailed info on testing, see Testing builds.\n\nIt\u2019s possible to do a parallel build with:\n\nThis will compile numpy on 4 CPUs and install it into the specified prefix. to\nperform a parallel in-place build, run:\n\nThe number of build jobs can also be specified via the environment variable\n`NPY_NUM_BUILD_JOBS`.\n\nCompilers are auto-detected; building with a particular compiler can be done\nwith `--fcompiler`. E.g. to select gfortran:\n\nFor more information see:\n\nOne relatively simple and reliable way to check for the compiler used to build\na library is to use ldd on the library. If libg2c.so is a dependency, this\nmeans that g77 has been used (note: g77 is no longer supported for building\nNumPy). If libgfortran.so is a dependency, gfortran has been used. If both are\ndependencies, this means both have been used, which is almost always a very\nbad idea.\n\nNumPy searches for optimized linear algebra libraries such as BLAS and LAPACK.\nThere are specific orders for searching these libraries, as described below\nand in the `site.cfg.example` file.\n\nNote that both BLAS and CBLAS interfaces are needed for a properly optimized\nbuild of NumPy.\n\nThe default order for the libraries are:\n\nThe detection of BLAS libraries may be bypassed by defining the environment\nvariable `NPY_BLAS_LIBS` , which should contain the exact linker flags you\nwant to use (interface is assumed to be Fortran 77). Also define\n`NPY_CBLAS_LIBS` (even empty if CBLAS is contained in your BLAS library) to\ntrigger use of CBLAS and avoid slow fallback code for matrix calculations.\n\nIf you wish to build against OpenBLAS but you also have BLIS available one may\npredefine the order of searching via the environment variable `NPY_BLAS_ORDER`\nwhich is a comma-separated list of the above names which is used to determine\nwhat to search for, for instance:\n\nwill prefer to use ATLAS, then BLIS, then OpenBLAS and as a last resort MKL.\nIf neither of these exists the build will fail (names are compared lower\ncase).\n\nAlternatively one may use `!` or `^` to negate all items:\n\nwill allow using anything but NetLIB BLAS and ATLAS libraries, the order of\nthe above list is retained.\n\nOne cannot mix negation and positives, nor have multiple negations, such cases\nwill raise an error.\n\nThe default order for the libraries are:\n\nThe detection of LAPACK libraries may be bypassed by defining the environment\nvariable `NPY_LAPACK_LIBS`, which should contain the exact linker flags you\nwant to use (language is assumed to be Fortran 77).\n\nIf you wish to build against OpenBLAS but you also have MKL available one may\npredefine the order of searching via the environment variable\n`NPY_LAPACK_ORDER` which is a comma-separated list of the above names, for\ninstance:\n\nwill prefer to use ATLAS, then OpenBLAS and as a last resort MKL. If neither\nof these exists the build will fail (names are compared lower case).\n\nAlternatively one may use `!` or `^` to negate all items:\n\nwill allow using anything but the NetLIB LAPACK library, the order of the\nabove list is retained.\n\nOne cannot mix negation and positives, nor have multiple negations, such cases\nwill raise an error.\n\nDeprecated since version 1.20: The native libraries on macOS, provided by\nAccelerate, are not fit for use in NumPy since they have bugs that cause wrong\noutput under easily reproducible conditions. If the vendor fixes those bugs,\nthe library could be reinstated, but until then users compiling for themselves\nshould use another linear algebra library or use the built-in (but slower)\ndefault, see the next section.\n\nUsage of ATLAS and other accelerated libraries in NumPy can be disabled via:\n\nor:\n\nYou can tell Numpy to use 64-bit BLAS/LAPACK libraries by setting the\nenvironment variable:\n\nwhen building Numpy. The following 64-bit BLAS/LAPACK libraries are supported:\n\nThe order in which they are preferred is determined by `NPY_BLAS_ILP64_ORDER`\nand `NPY_LAPACK_ILP64_ORDER` environment variables. The default value is\n`openblas64_,openblas_ilp64`.\n\nNote\n\nUsing non-symbol-suffixed 64-bit BLAS/LAPACK in a program that also uses\n32-bit BLAS/LAPACK can cause crashes under certain conditions (e.g. with\nembedded Python interpreters on Linux).\n\nThe 64-bit OpenBLAS with `64_` symbol suffix is obtained by compiling OpenBLAS\nwith settings:\n\nThe symbol suffix avoids the symbol name clashes between 32-bit and 64-bit\nBLAS/LAPACK libraries.\n\nAdditional compiler flags can be supplied by setting the `OPT`, `FOPT` (for\nFortran), and `CC` environment variables. When providing options that should\nimprove the performance of the code ensure that you also set `-DNDEBUG` so\nthat debugging code is not executed.\n\n"}, {"name": "Building the NumPy API and reference docs", "path": "dev/howto_build_docs", "type": "Development", "text": "\nIf you only want to get the documentation, note that pre-built versions can be\nfound at\n\nhttps://numpy.org/doc/\n\nin several different formats.\n\nBefore proceeding further it should be noted that the documentation is built\nwith the `make` tool, which is not natively available on Windows. MacOS or\nLinux users can jump to Prerequisites. It is recommended for Windows users to\nset up their development environment on Gitpod or Windows Subsystem for Linux\n(WSL). WSL is a good option for a persistent local set-up.\n\nGitpod is an open-source platform that automatically creates the correct\ndevelopment environment right in your browser, reducing the need to install\nlocal development environments and deal with incompatible dependencies.\n\nIf you have good internet connectivity and want a temporary set-up, it is\noften faster to build with Gitpod. Here are the in-depth instructions for\nbuilding NumPy with Gitpod.\n\nBuilding the NumPy documentation and API reference requires the following:\n\nSince large parts of the main documentation are obtained from NumPy via\n`import numpy` and examining the docstrings, you will need to first build and\ninstall it so that the correct version is imported. NumPy has to be re-built\nand re-installed every time you fetch the latest version of the repository,\nbefore generating the documentation. This ensures that the NumPy version and\nthe git repository version are in sync.\n\nNote that you can e.g. install NumPy to a temporary location and set the\nPYTHONPATH environment variable appropriately. Alternatively, if using Python\nvirtual environments (via e.g. `conda`, `virtualenv` or the `venv` module),\ninstalling NumPy into a new virtual environment is recommended.\n\nAll of the necessary dependencies for building the NumPy docs except for\nDoxygen can be installed with:\n\nWe currently use Sphinx along with Doxygen for generating the API and\nreference documentation for NumPy. In addition, building the documentation\nrequires the Sphinx extension `plot_directive`, which is shipped with\nMatplotlib. We also use numpydoc to render docstrings in the generated API\ndocumentation. SciPy is installed since some parts of the documentation\nrequire SciPy functions.\n\nFor installing Doxygen, please check the official download and installation\npages, or if you are using Linux then you can install it through your\ndistribution package manager.\n\nNote\n\nTry to install a newer version of Doxygen > 1.8.10 otherwise you may get some\nwarnings during the build.\n\nIf you obtained NumPy via git, also get the git submodules that contain\nadditional parts required for building the documentation:\n\nNow you are ready to generate the docs, so write:\n\nIf all goes well, this will generate a `build/html` subdirectory in the `/doc`\ndirectory, containing the built documentation. If you get a message about\n`installed numpy != current repo git version`, you must either override the\ncheck by setting `GITVER` or re-install NumPy.\n\nIf you have built NumPy into a virtual environment and get an error that says\n`numpy not found, cannot build documentation without...`, you need to override\nthe makefile `PYTHON` variable at the command line, so instead of writing\n`make html` write:\n\nTo build the PDF documentation, do instead:\n\nYou will need to have LaTeX installed for this, inclusive of support for Greek\nletters. For example, on Ubuntu xenial `texlive-lang-greek` and `cm-super` are\nneeded. Also, `latexmk` is needed on non-Windows systems.\n\nInstead of the above, you can also do:\n\nwhich will rebuild NumPy, install it to a temporary location, and build the\ndocumentation in all formats. This will most likely again only work on Unix\nplatforms.\n\nThe documentation for NumPy distributed at https://numpy.org/doc in html and\npdf format is also built with `make dist`. See HOWTO RELEASE for details on\nhow to update https://numpy.org/doc.\n\n"}, {"name": "busdaycalendar.holidays", "path": "reference/generated/numpy.busdaycalendar.holidays", "type": "Datetime support functions", "text": "\nattribute\n\nA copy of the holiday array indicating additional invalid days.\n\n"}, {"name": "busdaycalendar.weekmask", "path": "reference/generated/numpy.busdaycalendar.weekmask", "type": "Datetime support functions", "text": "\nattribute\n\nA copy of the seven-element boolean mask indicating valid days.\n\n"}, {"name": "Byte-swapping", "path": "user/basics.byteswapping", "type": "User Guide", "text": "\nThe `ndarray` is an object that provide a python array interface to data in\nmemory.\n\nIt often happens that the memory that you want to view with an array is not of\nthe same byte ordering as the computer on which you are running Python.\n\nFor example, I might be working on a computer with a little-endian CPU - such\nas an Intel Pentium, but I have loaded some data from a file written by a\ncomputer that is big-endian. Let\u2019s say I have loaded 4 bytes from a file\nwritten by a Sun (big-endian) computer. I know that these 4 bytes represent\ntwo 16-bit integers. On a big-endian machine, a two-byte integer is stored\nwith the Most Significant Byte (MSB) first, and then the Least Significant\nByte (LSB). Thus the bytes are, in memory order:\n\nLet\u2019s say the two integers were in fact 1 and 770. Because 770 = 256 * 3 + 2,\nthe 4 bytes in memory would contain respectively: 0, 1, 3, 2. The bytes I have\nloaded from the file would have these contents:\n\nWe might want to use an `ndarray` to access these integers. In that case, we\ncan create an array around this memory, and tell numpy that there are two\nintegers, and that they are 16 bit and big-endian:\n\nNote the array `dtype` above of `>i2`. The `>` means \u2018big-endian\u2019 (`<` is\nlittle-endian) and `i2` means \u2018signed 2-byte integer\u2019. For example, if our\ndata represented a single unsigned 4-byte little-endian integer, the dtype\nstring would be `<u4`.\n\nIn fact, why don\u2019t we try that?\n\nReturning to our `big_end_arr` \\- in this case our underlying data is big-\nendian (data endianness) and we\u2019ve set the dtype to match (the dtype is also\nbig-endian). However, sometimes you need to flip these around.\n\nWarning\n\nScalars currently do not include byte order information, so extracting a\nscalar from an array will return an integer in native byte order. Hence:\n\nAs you can imagine from the introduction, there are two ways you can affect\nthe relationship between the byte ordering of the array and the underlying\nmemory it is looking at:\n\nThe common situations in which you need to change byte ordering are:\n\nWe make something where they don\u2019t match:\n\nThe obvious fix for this situation is to change the dtype so it gives the\ncorrect endianness:\n\nNote the array has not changed in memory:\n\nYou might want to do this if you need the data in memory to be a certain\nordering. For example you might be writing the memory out to a file that needs\na certain byte ordering.\n\nNow the array has changed in memory:\n\nYou may have a correctly specified array dtype, but you need the array to have\nthe opposite byte order in memory, and you want the dtype to match so the\narray values make sense. In this case you just do both of the previous\noperations:\n\nAn easier way of casting the data to a specific dtype and byte ordering can be\nachieved with the ndarray astype method:\n\n"}, {"name": "C API Deprecations", "path": "reference/c-api/deprecations", "type": "C API Deprecations", "text": "\nThe API exposed by NumPy for third-party extensions has grown over years of\nreleases, and has allowed programmers to directly access NumPy functionality\nfrom C. This API can be best described as \u201corganic\u201d. It has emerged from\nmultiple competing desires and from multiple points of view over the years,\nstrongly influenced by the desire to make it easy for users to move to NumPy\nfrom Numeric and Numarray. The core API originated with Numeric in 1995 and\nthere are patterns such as the heavy use of macros written to mimic Python\u2019s\nC-API as well as account for compiler technology of the late 90\u2019s. There is\nalso only a small group of volunteers who have had very little time to spend\non improving this API.\n\nThere is an ongoing effort to improve the API. It is important in this effort\nto ensure that code that compiles for NumPy 1.X continues to compile for NumPy\n1.X. At the same time, certain API\u2019s will be marked as deprecated so that\nfuture-looking code can avoid these API\u2019s and follow better practices.\n\nAnother important role played by deprecation markings in the C API is to move\ntowards hiding internal details of the NumPy implementation. For those needing\ndirect, easy, access to the data of ndarrays, this will not remove this\nability. Rather, there are many potential performance optimizations which\nrequire changing the implementation details, and NumPy developers have been\nunable to try them because of the high value of preserving ABI compatibility.\nBy deprecating this direct access, we will in the future be able to improve\nNumPy\u2019s performance in ways we cannot presently.\n\nIn C, there is no equivalent to the deprecation warnings that Python supports.\nOne way to do deprecations is to flag them in the documentation and release\nnotes, then remove or change the deprecated features in a future major version\n(NumPy 2.0 and beyond). Minor versions of NumPy should not have major C-API\nchanges, however, that prevent code that worked on a previous minor release.\nFor example, we will do our best to ensure that code that compiled and worked\non NumPy 1.4 should continue to work on NumPy 1.7 (but perhaps with compiler\nwarnings).\n\nTo use the NPY_NO_DEPRECATED_API mechanism, you need to #define it to the\ntarget API version of NumPy before #including any NumPy headers. If you want\nto confirm that your code is clean against 1.7, use:\n\nOn compilers which support a #warning mechanism, NumPy issues a compiler\nwarning if you do not define the symbol NPY_NO_DEPRECATED_API. This way, the\nfact that there are deprecations will be flagged for third-party developers\nwho may not have read the release notes closely.\n\n"}, {"name": "char **NpyIter_GetDataPtrArray()", "path": "reference/c-api/iterator#c.NpyIter_GetDataPtrArray", "type": "Array Iterator API", "text": "\nThis gives back a pointer to the `nop` data pointers. If\n`NPY_ITER_EXTERNAL_LOOP` was not specified, each data pointer points to the\ncurrent data item of the iterator. If no inner iteration was specified, it\npoints to the first data item of the inner loop.\n\nThis pointer may be cached before the iteration loop, calling `iternext` will\nnot change it. This function may be safely called without holding the Python\nGIL.\n\n"}, {"name": "char **NpyIter_GetInitialDataPtrArray()", "path": "reference/c-api/iterator#c.NpyIter_GetInitialDataPtrArray", "type": "Array Iterator API", "text": "\nGets the array of data pointers directly into the arrays (never into the\nbuffers), corresponding to iteration index 0.\n\nThese pointers are different from the pointers accepted by\n`NpyIter_ResetBasePointers`, because the direction along some axes may have\nbeen reversed.\n\nThis function may be safely called without holding the Python GIL.\n\n"}, {"name": "char *core_signature", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_signature", "type": "Python Types and C-Structures", "text": "\nCore signature string\n\n"}, {"name": "char *data", "path": "reference/c-api/types-and-structures#c.NPY_AO.data", "type": "Python Types and C-Structures", "text": "\nAccessible via `PyArray_DATA`, this data member is a pointer to the first\nelement of the array. This pointer can (and normally should) be recast to the\ndata type of the array.\n\n"}, {"name": "char *dataptr", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.dataptr", "type": "Python Types and C-Structures", "text": "\nThis member points to an element in the ndarray indicated by the index.\n\n"}, {"name": "char *doc", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.doc", "type": "Python Types and C-Structures", "text": "\nDocumentation for the ufunc. Should not contain the function signature as this\nis generated dynamically when __doc__ is retrieved.\n\n"}, {"name": "char *name", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.name", "type": "Python Types and C-Structures", "text": "\nA string name for the ufunc. This is used dynamically to build the __doc__\nattribute of ufuncs.\n\n"}, {"name": "char *PyArray_BYTES()", "path": "reference/c-api/array#c.PyArray_BYTES", "type": "Array API", "text": "\nThese two macros are similar and obtain the pointer to the data-buffer for the\narray. The first macro can (and should be) assigned to a particular pointer\nwhere the second is for generic processing. If you have not guaranteed a\ncontiguous and/or aligned array then be sure you understand how to access the\ndata in the array to avoid memory and/or alignment problems.\n\n"}, {"name": "char *PyArray_One()", "path": "reference/c-api/array#c.PyArray_One", "type": "Array API", "text": "\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 1 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\n"}, {"name": "char *PyArray_Zero()", "path": "reference/c-api/array#c.PyArray_Zero", "type": "Array API", "text": "\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 0 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\n"}, {"name": "char *PyDataMem_RENEW()", "path": "reference/c-api/array#c.PyDataMem_RENEW", "type": "Array API", "text": "\nMacros to allocate, free, and reallocate memory. These macros are used\ninternally to create arrays.\n\n"}, {"name": "char *types", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.types", "type": "Python Types and C-Structures", "text": "\nAn array of \\\\(nargs \\times ntypes\\\\) 8-bit type_numbers which contains the\ntype signature for the function for each of the supported (builtin) data\ntypes. For each of the ntypes functions, the corresponding set of type numbers\nin this array shows how the args argument should be interpreted in the 1-d\nvector loop. These type numbers do not have to be the same type and mixed-type\nufuncs are supported.\n\n"}, {"name": "char byteorder", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.byteorder", "type": "Python Types and C-Structures", "text": "\nA character indicating the byte-order: \u2018>\u2019 (big-endian), \u2018<\u2019 (little- endian),\n\u2018=\u2019 (native), \u2018|\u2019 (irrelevant, ignore). All builtin data- types have byteorder\n\u2018=\u2019.\n\n"}, {"name": "char flags", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.flags", "type": "Python Types and C-Structures", "text": "\nA data-type bit-flag that determines if the data-type exhibits object- array\nlike behavior. Each bit in this member is a flag which are named as:\n\n"}, {"name": "char kind", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.kind", "type": "Python Types and C-Structures", "text": "\nA character code indicating the kind of array (using the array interface\ntypestring notation). A \u2018b\u2019 represents Boolean, a \u2018i\u2019 represents signed\ninteger, a \u2018u\u2019 represents unsigned integer, \u2018f\u2019 represents floating point, \u2018c\u2019\nrepresents complex floating point, \u2018S\u2019 represents 8-bit zero-terminated bytes,\n\u2018U\u2019 represents 32-bit/character unicode string, and \u2018V\u2019 represents arbitrary.\n\n"}, {"name": "char type", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.type", "type": "Python Types and C-Structures", "text": "\nA traditional character code indicating the data type.\n\n"}, {"name": "char typekind", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.typekind", "type": "Python Types and C-Structures", "text": "\nA character indicating what kind of array is present according to the\ntypestring convention with \u2018t\u2019 -> bitfield, \u2018b\u2019 -> Boolean, \u2018i\u2019 -> signed\ninteger, \u2018u\u2019 -> unsigned integer, \u2018f\u2019 -> floating point, \u2018c\u2019 -> complex\nfloating point, \u2018O\u2019 -> object, \u2018S\u2019 -> (byte-)string, \u2018U\u2019 -> unicode, \u2018V\u2019 ->\nvoid.\n\n"}, {"name": "char.add()", "path": "reference/generated/numpy.char.add", "type": "numpy.char.add", "text": "\nReturn element-wise string concatenation for two arrays of str or unicode.\n\nArrays `x1` and `x2` must have the same shape.\n\nInput array.\n\nInput array.\n\nOutput array of `string_` or `unicode_`, depending on input types of the same\nshape as `x1` and `x2`.\n\n"}, {"name": "char.array()", "path": "reference/generated/numpy.char.array", "type": "numpy.char.array", "text": "\nCreate a `chararray`.\n\nNote\n\nThis class is provided for numarray backward-compatibility. New code (not\nconcerned with numarray compatibility) should use arrays of type `string_` or\n`unicode_` and use the free functions in `numpy.char` for fast vectorized\nstring operations instead.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nIf true (default), then the object is copied. Otherwise, a copy will only be\nmade if __array__ returns a copy, if obj is a nested sequence, or if a copy is\nneeded to satisfy any of the other requirements (`itemsize`, unicode, `order`,\netc.).\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest). If order is \u2018A\u2019, then the returned array may be in any\norder (either C-, Fortran-contiguous, or even discontiguous).\n\n"}, {"name": "char.asarray()", "path": "reference/generated/numpy.char.asarray", "type": "numpy.char.asarray", "text": "\nConvert the input to a `chararray`, copying the data only if necessary.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest).\n\n"}, {"name": "char.capitalize()", "path": "reference/generated/numpy.char.capitalize", "type": "numpy.char.capitalize", "text": "\nReturn a copy of `a` with only the first character of each element\ncapitalized.\n\nCalls `str.capitalize` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array of strings to capitalize.\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.center()", "path": "reference/generated/numpy.char.center", "type": "numpy.char.center", "text": "\nReturn a copy of `a` with its elements centered in a string of length `width`.\n\nCalls `str.center` element-wise.\n\nThe length of the resulting strings\n\nThe padding character to use (default is space).\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.chararray.argsort()", "path": "reference/generated/numpy.char.chararray.argsort", "type": "numpy.char.chararray.argsort", "text": "\nmethod\n\nReturns the indices that would sort this array.\n\nRefer to `numpy.argsort` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.astype()", "path": "reference/generated/numpy.char.chararray.astype", "type": "numpy.char.chararray.astype", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "char.chararray.base", "path": "reference/generated/numpy.char.chararray.base", "type": "String operations", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "char.chararray.copy()", "path": "reference/generated/numpy.char.chararray.copy", "type": "numpy.char.chararray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "char.chararray.count()", "path": "reference/generated/numpy.char.chararray.count", "type": "numpy.char.chararray.count", "text": "\nmethod\n\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\nSee also\n\n"}, {"name": "char.chararray.ctypes", "path": "reference/generated/numpy.char.chararray.ctypes", "type": "String operations", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "char.chararray.data", "path": "reference/generated/numpy.char.chararray.data", "type": "String operations", "text": "\nattribute\n\nPython buffer object pointing to the start of the array\u2019s data.\n\n"}, {"name": "char.chararray.decode()", "path": "reference/generated/numpy.char.chararray.decode", "type": "numpy.char.chararray.decode", "text": "\nmethod\n\nCalls `str.decode` element-wise.\n\nSee also\n\n"}, {"name": "char.chararray.dtype", "path": "reference/generated/numpy.char.chararray.dtype", "type": "String operations", "text": "\nattribute\n\nData-type of the array\u2019s elements.\n\nSee also\n\n"}, {"name": "char.chararray.dump()", "path": "reference/generated/numpy.char.chararray.dump", "type": "numpy.char.chararray.dump", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "char.chararray.dumps()", "path": "reference/generated/numpy.char.chararray.dumps", "type": "numpy.char.chararray.dumps", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "char.chararray.encode()", "path": "reference/generated/numpy.char.chararray.encode", "type": "numpy.char.chararray.encode", "text": "\nmethod\n\nCalls `str.encode` element-wise.\n\nSee also\n\n"}, {"name": "char.chararray.endswith()", "path": "reference/generated/numpy.char.chararray.endswith", "type": "numpy.char.chararray.endswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nends with `suffix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "char.chararray.expandtabs()", "path": "reference/generated/numpy.char.chararray.expandtabs", "type": "numpy.char.chararray.expandtabs", "text": "\nmethod\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\nSee also\n\n"}, {"name": "char.chararray.fill()", "path": "reference/generated/numpy.char.chararray.fill", "type": "numpy.char.chararray.fill", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "char.chararray.find()", "path": "reference/generated/numpy.char.chararray.find", "type": "numpy.char.chararray.find", "text": "\nmethod\n\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\nSee also\n\n"}, {"name": "char.chararray.flags", "path": "reference/generated/numpy.char.chararray.flags", "type": "String operations", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "char.chararray.flat", "path": "reference/generated/numpy.char.chararray.flat", "type": "String operations", "text": "\nattribute\n\nA 1-D iterator over the array.\n\nThis is a `numpy.flatiter` instance, which acts similarly to, but is not a\nsubclass of, Python\u2019s built-in iterator object.\n\nSee also\n\nReturn a copy of the array collapsed into one dimension.\n\nAn assignment example:\n\n"}, {"name": "char.chararray.flatten()", "path": "reference/generated/numpy.char.chararray.flatten", "type": "numpy.char.chararray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "char.chararray.getfield()", "path": "reference/generated/numpy.char.chararray.getfield", "type": "numpy.char.chararray.getfield", "text": "\nmethod\n\nReturns a field of the given array as a certain type.\n\nA field is a view of the array data with a given data-type. The values in the\nview are determined by the given type and the offset into the current array in\nbytes. The offset needs to be such that the view dtype fits in the array\ndtype; for example an array of dtype complex128 has 16-byte elements. If\ntaking a view with a 32-bit integer (4 bytes), the offset needs to be between\n0 and 12 bytes.\n\nThe data type of the view. The dtype size of the view can not be larger than\nthat of the array itself.\n\nNumber of bytes to skip before beginning the element view.\n\nBy choosing an offset of 8 bytes we can select the complex part of the array\nfor our view:\n\n"}, {"name": "char.chararray.imag", "path": "reference/generated/numpy.char.chararray.imag", "type": "String operations", "text": "\nattribute\n\nThe imaginary part of the array.\n\n"}, {"name": "char.chararray.index()", "path": "reference/generated/numpy.char.chararray.index", "type": "numpy.char.chararray.index", "text": "\nmethod\n\nLike `find`, but raises `ValueError` when the substring is not found.\n\nSee also\n\n"}, {"name": "char.chararray.isalnum()", "path": "reference/generated/numpy.char.chararray.isalnum", "type": "numpy.char.chararray.isalnum", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isalpha()", "path": "reference/generated/numpy.char.chararray.isalpha", "type": "numpy.char.chararray.isalpha", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isdecimal()", "path": "reference/generated/numpy.char.chararray.isdecimal", "type": "numpy.char.chararray.isdecimal", "text": "\nmethod\n\nFor each element in `self`, return True if there are only decimal characters\nin the element.\n\nSee also\n\n"}, {"name": "char.chararray.isdigit()", "path": "reference/generated/numpy.char.chararray.isdigit", "type": "numpy.char.chararray.isdigit", "text": "\nmethod\n\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.islower()", "path": "reference/generated/numpy.char.chararray.islower", "type": "numpy.char.chararray.islower", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isnumeric()", "path": "reference/generated/numpy.char.chararray.isnumeric", "type": "numpy.char.chararray.isnumeric", "text": "\nmethod\n\nFor each element in `self`, return True if there are only numeric characters\nin the element.\n\nSee also\n\n"}, {"name": "char.chararray.isspace()", "path": "reference/generated/numpy.char.chararray.isspace", "type": "numpy.char.chararray.isspace", "text": "\nmethod\n\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.istitle()", "path": "reference/generated/numpy.char.chararray.istitle", "type": "numpy.char.chararray.istitle", "text": "\nmethod\n\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isupper()", "path": "reference/generated/numpy.char.chararray.isupper", "type": "numpy.char.chararray.isupper", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.item()", "path": "reference/generated/numpy.char.chararray.item", "type": "numpy.char.chararray.item", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "char.chararray.itemsize", "path": "reference/generated/numpy.char.chararray.itemsize", "type": "String operations", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "char.chararray.join()", "path": "reference/generated/numpy.char.chararray.join", "type": "numpy.char.chararray.join", "text": "\nmethod\n\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\nSee also\n\n"}, {"name": "char.chararray.ljust()", "path": "reference/generated/numpy.char.chararray.ljust", "type": "numpy.char.chararray.ljust", "text": "\nmethod\n\nReturn an array with the elements of `self` left-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "char.chararray.lower()", "path": "reference/generated/numpy.char.chararray.lower", "type": "numpy.char.chararray.lower", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to lowercase.\n\nSee also\n\n"}, {"name": "char.chararray.lstrip()", "path": "reference/generated/numpy.char.chararray.lstrip", "type": "numpy.char.chararray.lstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading characters removed.\n\nSee also\n\n"}, {"name": "char.chararray.nbytes", "path": "reference/generated/numpy.char.chararray.nbytes", "type": "String operations", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "char.chararray.ndim", "path": "reference/generated/numpy.char.chararray.ndim", "type": "String operations", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "char.chararray.nonzero()", "path": "reference/generated/numpy.char.chararray.nonzero", "type": "numpy.char.chararray.nonzero", "text": "\nmethod\n\nReturn the indices of the elements that are non-zero.\n\nRefer to `numpy.nonzero` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.put()", "path": "reference/generated/numpy.char.chararray.put", "type": "numpy.char.chararray.put", "text": "\nmethod\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\nRefer to `numpy.put` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.ravel()", "path": "reference/generated/numpy.char.chararray.ravel", "type": "numpy.char.chararray.ravel", "text": "\nmethod\n\nReturn a flattened array.\n\nRefer to `numpy.ravel` for full documentation.\n\nSee also\n\nequivalent function\n\na flat iterator on the array.\n\n"}, {"name": "char.chararray.real", "path": "reference/generated/numpy.char.chararray.real", "type": "String operations", "text": "\nattribute\n\nThe real part of the array.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.repeat()", "path": "reference/generated/numpy.char.chararray.repeat", "type": "numpy.char.chararray.repeat", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.replace()", "path": "reference/generated/numpy.char.chararray.replace", "type": "numpy.char.chararray.replace", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with all occurrences\nof substring `old` replaced by `new`.\n\nSee also\n\n"}, {"name": "char.chararray.reshape()", "path": "reference/generated/numpy.char.chararray.reshape", "type": "numpy.char.chararray.reshape", "text": "\nmethod\n\nReturns an array containing the same data with a new shape.\n\nRefer to `numpy.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\nUnlike the free function `numpy.reshape`, this method on `ndarray` allows the\nelements of the shape parameter to be passed in as separate arguments. For\nexample, `a.reshape(10, 11)` is equivalent to `a.reshape((10, 11))`.\n\n"}, {"name": "char.chararray.resize()", "path": "reference/generated/numpy.char.chararray.resize", "type": "numpy.char.chararray.resize", "text": "\nmethod\n\nChange shape and size of array in-place.\n\nShape of resized array.\n\nIf False, reference count will not be checked. Default is True.\n\nIf `a` does not own its own data or references or views to it exist, and the\ndata memory must be changed. PyPy only: will always raise if the data memory\nmust be changed, since there is no reliable way to determine if references or\nviews to it exist.\n\nIf the `order` keyword argument is specified. This behaviour is a bug in\nNumPy.\n\nSee also\n\nReturn a new array with the specified shape.\n\nThis reallocates space for the data area if necessary.\n\nOnly contiguous arrays (data elements consecutive in memory) can be resized.\n\nThe purpose of the reference count check is to make sure you do not use this\narray as a buffer for another Python object and then reallocate the memory.\nHowever, reference counts can increase in other ways so if you are sure that\nyou have not shared the memory for this array with another Python object, then\nyou may safely set `refcheck` to False.\n\nShrinking an array: array is flattened (in the order that the data are stored\nin memory), resized, and reshaped:\n\nEnlarging an array: as above, but missing entries are filled with zeros:\n\nReferencing an array prevents resizing\u2026\n\nUnless `refcheck` is False:\n\n"}, {"name": "char.chararray.rfind()", "path": "reference/generated/numpy.char.chararray.rfind", "type": "numpy.char.chararray.rfind", "text": "\nmethod\n\nFor each element in `self`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\nSee also\n\n"}, {"name": "char.chararray.rindex()", "path": "reference/generated/numpy.char.chararray.rindex", "type": "numpy.char.chararray.rindex", "text": "\nmethod\n\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\nSee also\n\n"}, {"name": "char.chararray.rjust()", "path": "reference/generated/numpy.char.chararray.rjust", "type": "numpy.char.chararray.rjust", "text": "\nmethod\n\nReturn an array with the elements of `self` right-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "char.chararray.rsplit()", "path": "reference/generated/numpy.char.chararray.rsplit", "type": "numpy.char.chararray.rsplit", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "char.chararray.rstrip()", "path": "reference/generated/numpy.char.chararray.rstrip", "type": "numpy.char.chararray.rstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the trailing characters\nremoved.\n\nSee also\n\n"}, {"name": "char.chararray.searchsorted()", "path": "reference/generated/numpy.char.chararray.searchsorted", "type": "numpy.char.chararray.searchsorted", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.setfield()", "path": "reference/generated/numpy.char.chararray.setfield", "type": "numpy.char.chararray.setfield", "text": "\nmethod\n\nPut a value into a specified place in a field defined by a data-type.\n\nPlace `val` into `a`\u2019s field defined by `dtype` and beginning `offset` bytes\ninto the field.\n\nValue to be placed in field.\n\nData-type of the field in which to place `val`.\n\nThe number of bytes into the field at which to place `val`.\n\nSee also\n\n"}, {"name": "char.chararray.setflags()", "path": "reference/generated/numpy.char.chararray.setflags", "type": "numpy.char.chararray.setflags", "text": "\nmethod\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\nThese Boolean-valued flags affect how numpy interprets the memory area used by\n`a` (see Notes below). The ALIGNED flag can only be set to True if the data is\nactually aligned according to the type. The WRITEBACKIFCOPY and (deprecated)\nUPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be\nset to True if the array owns its own memory, or the ultimate owner of the\nmemory exposes a writeable buffer interface, or is a string. (The exception\nfor string is made so that unpickling can be done without copying memory.)\n\nDescribes whether or not `a` can be written to.\n\nDescribes whether or not `a` is aligned properly for its type.\n\nDescribes whether or not `a` is a copy of another \u201cbase\u201d array.\n\nArray flags provide information about how the memory area used for the array\nis to be interpreted. There are 7 Boolean flags in use, only four of which can\nbe changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n\nWRITEABLE (W) the data area can be written to;\n\nALIGNED (A) the data and strides are aligned appropriately for the hardware\n(as determined by the compiler);\n\nUPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n\nWRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by\n.base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the\nbase array will be updated with the contents of this array.\n\nAll flags can be accessed using the single (upper case) letter as well as the\nfull name.\n\n"}, {"name": "char.chararray.shape", "path": "reference/generated/numpy.char.chararray.shape", "type": "String operations", "text": "\nattribute\n\nTuple of array dimensions.\n\nThe shape property is usually used to get the current shape of an array, but\nmay also be used to reshape the array in-place by assigning a tuple of array\ndimensions to it. As with `numpy.reshape`, one of the new shape dimensions can\nbe -1, in which case its value is inferred from the size of the array and the\nremaining dimensions. Reshaping an array in-place will fail if a copy is\nrequired.\n\nSee also\n\nsimilar function\n\nsimilar method\n\n"}, {"name": "char.chararray.size", "path": "reference/generated/numpy.char.chararray.size", "type": "String operations", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "char.chararray.sort()", "path": "reference/generated/numpy.char.chararray.sort", "type": "numpy.char.chararray.sort", "text": "\nmethod\n\nSort an array in-place. Refer to `numpy.sort` for full documentation.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with datatype. The \u2018mergesort\u2019 option is retained for\nbackwards compatibility.\n\nChanged in version 1.15.0: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a sorted copy of an array.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in sorted array.\n\nPartial sort.\n\nSee `numpy.sort` for notes on the different sorting algorithms.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\n"}, {"name": "char.chararray.split()", "path": "reference/generated/numpy.char.chararray.split", "type": "numpy.char.chararray.split", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "char.chararray.splitlines()", "path": "reference/generated/numpy.char.chararray.splitlines", "type": "numpy.char.chararray.splitlines", "text": "\nmethod\n\nFor each element in `self`, return a list of the lines in the element,\nbreaking at line boundaries.\n\nSee also\n\n"}, {"name": "char.chararray.squeeze()", "path": "reference/generated/numpy.char.chararray.squeeze", "type": "numpy.char.chararray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.startswith()", "path": "reference/generated/numpy.char.chararray.startswith", "type": "numpy.char.chararray.startswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nstarts with `prefix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "char.chararray.strides", "path": "reference/generated/numpy.char.chararray.strides", "type": "String operations", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "char.chararray.strip()", "path": "reference/generated/numpy.char.chararray.strip", "type": "numpy.char.chararray.strip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading and trailing\ncharacters removed.\n\nSee also\n\n"}, {"name": "char.chararray.swapaxes()", "path": "reference/generated/numpy.char.chararray.swapaxes", "type": "numpy.char.chararray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.swapcase()", "path": "reference/generated/numpy.char.chararray.swapcase", "type": "numpy.char.chararray.swapcase", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with uppercase\ncharacters converted to lowercase and vice versa.\n\nSee also\n\n"}, {"name": "char.chararray.T", "path": "reference/generated/numpy.char.chararray.t", "type": "String operations", "text": "\nattribute\n\nThe transposed array.\n\nSame as `self.transpose()`.\n\nSee also\n\n"}, {"name": "char.chararray.take()", "path": "reference/generated/numpy.char.chararray.take", "type": "numpy.char.chararray.take", "text": "\nmethod\n\nReturn an array formed from the elements of `a` at the given indices.\n\nRefer to `numpy.take` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.title()", "path": "reference/generated/numpy.char.chararray.title", "type": "numpy.char.chararray.title", "text": "\nmethod\n\nFor each element in `self`, return a titlecased version of the string: words\nstart with uppercase characters, all remaining cased characters are lowercase.\n\nSee also\n\n"}, {"name": "char.chararray.tobytes()", "path": "reference/generated/numpy.char.chararray.tobytes", "type": "String operations", "text": "\nmethod\n\nConstruct Python bytes containing the raw data bytes in the array.\n\nConstructs Python bytes showing a copy of the raw contents of data memory. The\nbytes object is produced in C-order by default. This behavior is controlled by\nthe `order` parameter.\n\nNew in version 1.9.0.\n\nControls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019\notherwise. Default is \u2018C\u2019.\n\nPython bytes exhibiting a copy of `a`\u2019s raw data.\n\n"}, {"name": "char.chararray.tofile()", "path": "reference/generated/numpy.char.chararray.tofile", "type": "numpy.char.chararray.tofile", "text": "\nmethod\n\nWrite array to a file as text or binary (default).\n\nData is always written in \u2018C\u2019 order, independent of the order of `a`. The data\nproduced by this method can be recovered using the function fromfile().\n\nAn open file object, or a string containing a filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nSeparator between array items for text output. If \u201c\u201d (empty), a binary file is\nwritten, equivalent to `file.write(a.tobytes())`.\n\nFormat string for text file output. Each entry in the array is formatted to\ntext by first converting it to the closest Python type, and then using\n\u201cformat\u201d % item.\n\nThis is a convenience function for quick storage of array data. Information on\nendianness and precision is lost, so this method is not a good choice for\nfiles intended to archive data or transport data between machines with\ndifferent endianness. Some of these problems can be overcome by outputting the\ndata as text files, at the expense of speed and file size.\n\nWhen fid is a file object, array contents are directly written to the file,\nbypassing the file object\u2019s `write` method. As a result, tofile cannot be used\nwith files objects supporting compression (e.g., GzipFile) or file-like\nobjects that do not support `fileno()` (e.g., BytesIO).\n\n"}, {"name": "char.chararray.tolist()", "path": "reference/generated/numpy.char.chararray.tolist", "type": "numpy.char.chararray.tolist", "text": "\nmethod\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\nReturn a copy of the array data as a (nested) Python list. Data items are\nconverted to the nearest compatible builtin Python type, via the `item`\nfunction.\n\nIf `a.ndim` is 0, then since the depth of the nested list is 0, it will not be\na list at all, but a simple Python scalar.\n\nThe possibly nested list of array elements.\n\nThe array may be recreated via `a = np.array(a.tolist())`, although this may\nsometimes lose precision.\n\nFor a 1D array, `a.tolist()` is almost the same as `list(a)`, except that\n`tolist` changes numpy scalars to Python scalars:\n\nAdditionally, for a 2D array, `tolist` applies recursively:\n\nThe base case for this recursion is a 0D array:\n\n"}, {"name": "char.chararray.tostring()", "path": "reference/generated/numpy.char.chararray.tostring", "type": "numpy.char.chararray.tostring", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "char.chararray.translate()", "path": "reference/generated/numpy.char.chararray.translate", "type": "numpy.char.chararray.translate", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\nSee also\n\n"}, {"name": "char.chararray.transpose()", "path": "reference/generated/numpy.char.chararray.transpose", "type": "numpy.char.chararray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "char.chararray.upper()", "path": "reference/generated/numpy.char.chararray.upper", "type": "numpy.char.chararray.upper", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to uppercase.\n\nSee also\n\n"}, {"name": "char.chararray.view()", "path": "reference/generated/numpy.char.chararray.view", "type": "numpy.char.chararray.view", "text": "\nmethod\n\nNew view of array with the same data.\n\nNote\n\nPassing None for `dtype` is different from omitting the parameter, since the\nformer invokes `dtype(None)` which is an alias for `dtype('float_')`.\n\nData-type descriptor of the returned view, e.g., float32 or int16. Omitting it\nresults in the view having the same data-type as `a`. This argument can also\nbe specified as an ndarray sub-class, which then specifies the type of the\nreturned object (this is equivalent to setting the `type` parameter).\n\nType of the returned view, e.g., ndarray or matrix. Again, omission of the\nparameter results in type preservation.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\nViewing array data using a different type and dtype:\n\nCreating a view on a structured array so it can be used in calculations\n\nMaking changes to the view changes the underlying array\n\nUsing a view to convert an array to a recarray:\n\nViews share data:\n\nViews that change the dtype size (bytes per entry) should normally be avoided\non arrays defined by slices, transposes, fortran-ordering, etc.:\n\n"}, {"name": "char.chararray.zfill()", "path": "reference/generated/numpy.char.chararray.zfill", "type": "numpy.char.chararray.zfill", "text": "\nmethod\n\nReturn the numeric string left-filled with zeros in a string of length\n`width`.\n\nSee also\n\n"}, {"name": "char.compare_chararrays()", "path": "reference/generated/numpy.char.compare_chararrays", "type": "numpy.char.compare_chararrays", "text": "\nPerforms element-wise comparison of two string arrays using the comparison\noperator specified by `cmp_op`.\n\nArrays to be compared.\n\nType of comparison.\n\nIf True, the spaces at the end of Strings are removed before the comparison.\n\nThe output array of type Boolean with the same shape as a and b.\n\nIf `cmp_op` is not valid.\n\nIf at least one of `a` or `b` is a non-string array\n\n"}, {"name": "char.count()", "path": "reference/generated/numpy.char.count", "type": "numpy.char.count", "text": "\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\nCalls `str.count` element-wise.\n\nThe substring to search for.\n\nOptional arguments `start` and `end` are interpreted as slice notation to\nspecify the range in which to count.\n\nOutput array of ints.\n\nSee also\n\n"}, {"name": "char.decode()", "path": "reference/generated/numpy.char.decode", "type": "numpy.char.decode", "text": "\nCalls `str.decode` element-wise.\n\nThe set of available codecs comes from the Python standard library, and may be\nextended at runtime. For more information, see the `codecs` module.\n\nThe name of an encoding\n\nSpecifies how to handle encoding errors\n\nSee also\n\nThe type of the result will depend on the encoding specified.\n\n"}, {"name": "char.encode()", "path": "reference/generated/numpy.char.encode", "type": "numpy.char.encode", "text": "\nCalls `str.encode` element-wise.\n\nThe set of available codecs comes from the Python standard library, and may be\nextended at runtime. For more information, see the codecs module.\n\nThe name of an encoding\n\nSpecifies how to handle encoding errors\n\nSee also\n\nThe type of the result will depend on the encoding specified.\n\n"}, {"name": "char.endswith()", "path": "reference/generated/numpy.char.endswith", "type": "numpy.char.endswith", "text": "\nReturns a boolean array which is `True` where the string element in `a` ends\nwith `suffix`, otherwise `False`.\n\nCalls `str.endswith` element-wise.\n\nWith optional `start`, test beginning at that position. With optional `end`,\nstop comparing at that position.\n\nOutputs an array of bools.\n\nSee also\n\n"}, {"name": "char.equal()", "path": "reference/generated/numpy.char.equal", "type": "numpy.char.equal", "text": "\nReturn (x1 == x2) element-wise.\n\nUnlike `numpy.equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.expandtabs()", "path": "reference/generated/numpy.char.expandtabs", "type": "numpy.char.expandtabs", "text": "\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\nCalls `str.expandtabs` element-wise.\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces, depending on the current column and the given `tabsize`.\nThe column number is reset to zero after each newline occurring in the string.\nThis doesn\u2019t understand other non-printing characters or escape sequences.\n\nInput array\n\nReplace tabs with `tabsize` number of spaces. If not given defaults to 8\nspaces.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.find()", "path": "reference/generated/numpy.char.find", "type": "numpy.char.find", "text": "\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\nCalls `str.find` element-wise.\n\nFor each element, return the lowest index in the string where substring `sub`\nis found, such that `sub` is contained in the range [`start`, `end`].\n\nOptional arguments `start` and `end` are interpreted as in slice notation.\n\nOutput array of ints. Returns -1 if `sub` is not found.\n\nSee also\n\n"}, {"name": "char.greater()", "path": "reference/generated/numpy.char.greater", "type": "numpy.char.greater", "text": "\nReturn (x1 > x2) element-wise.\n\nUnlike `numpy.greater`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.greater_equal()", "path": "reference/generated/numpy.char.greater_equal", "type": "numpy.char.greater_equal", "text": "\nReturn (x1 >= x2) element-wise.\n\nUnlike `numpy.greater_equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.index()", "path": "reference/generated/numpy.char.index", "type": "numpy.char.index", "text": "\nLike `find`, but raises `ValueError` when the substring is not found.\n\nCalls `str.index` element-wise.\n\nOutput array of ints. Returns -1 if `sub` is not found.\n\nSee also\n\n"}, {"name": "char.isalnum()", "path": "reference/generated/numpy.char.isalnum", "type": "numpy.char.isalnum", "text": "\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\nCalls `str.isalnum` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.isalpha()", "path": "reference/generated/numpy.char.isalpha", "type": "numpy.char.isalpha", "text": "\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\nCalls `str.isalpha` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.isdecimal()", "path": "reference/generated/numpy.char.isdecimal", "type": "numpy.char.isdecimal", "text": "\nFor each element, return True if there are only decimal characters in the\nelement.\n\nCalls `unicode.isdecimal` element-wise.\n\nDecimal characters include digit characters, and all characters that can be\nused to form decimal-radix numbers, e.g. `U+0660, ARABIC-INDIC DIGIT ZERO`.\n\nInput array.\n\nArray of booleans identical in shape to `a`.\n\nSee also\n\n"}, {"name": "char.isdigit()", "path": "reference/generated/numpy.char.isdigit", "type": "numpy.char.isdigit", "text": "\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\nCalls `str.isdigit` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.islower()", "path": "reference/generated/numpy.char.islower", "type": "numpy.char.islower", "text": "\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\nCalls `str.islower` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.isnumeric()", "path": "reference/generated/numpy.char.isnumeric", "type": "numpy.char.isnumeric", "text": "\nFor each element, return True if there are only numeric characters in the\nelement.\n\nCalls `unicode.isnumeric` element-wise.\n\nNumeric characters include digit characters, and all characters that have the\nUnicode numeric value property, e.g. `U+2155, VULGAR FRACTION ONE FIFTH`.\n\nInput array.\n\nArray of booleans of same shape as `a`.\n\nSee also\n\n"}, {"name": "char.isspace()", "path": "reference/generated/numpy.char.isspace", "type": "numpy.char.isspace", "text": "\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\nCalls `str.isspace` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.istitle()", "path": "reference/generated/numpy.char.istitle", "type": "numpy.char.istitle", "text": "\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\nCall `str.istitle` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.isupper()", "path": "reference/generated/numpy.char.isupper", "type": "numpy.char.isupper", "text": "\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\nCall `str.isupper` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.join()", "path": "reference/generated/numpy.char.join", "type": "numpy.char.join", "text": "\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\nCalls `str.join` element-wise.\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.less()", "path": "reference/generated/numpy.char.less", "type": "numpy.char.less", "text": "\nReturn (x1 < x2) element-wise.\n\nUnlike `numpy.greater`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.less_equal()", "path": "reference/generated/numpy.char.less_equal", "type": "numpy.char.less_equal", "text": "\nReturn (x1 <= x2) element-wise.\n\nUnlike `numpy.less_equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.ljust()", "path": "reference/generated/numpy.char.ljust", "type": "numpy.char.ljust", "text": "\nReturn an array with the elements of `a` left-justified in a string of length\n`width`.\n\nCalls `str.ljust` element-wise.\n\nThe length of the resulting strings\n\nThe character to use for padding\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.lower()", "path": "reference/generated/numpy.char.lower", "type": "numpy.char.lower", "text": "\nReturn an array with the elements converted to lowercase.\n\nCall `str.lower` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.lstrip()", "path": "reference/generated/numpy.char.lstrip", "type": "numpy.char.lstrip", "text": "\nFor each element in `a`, return a copy with the leading characters removed.\n\nCalls `str.lstrip` element-wise.\n\nInput array.\n\nThe `chars` argument is a string specifying the set of characters to be\nremoved. If omitted or None, the `chars` argument defaults to removing\nwhitespace. The `chars` argument is not a prefix; rather, all combinations of\nits values are stripped.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\nThe \u2018a\u2019 variable is unstripped from c[1] because whitespace leading.\n\n"}, {"name": "char.mod()", "path": "reference/generated/numpy.char.mod", "type": "numpy.char.mod", "text": "\nReturn (a % i), that is pre-Python 2.6 string formatting (interpolation),\nelement-wise for a pair of array_likes of str or unicode.\n\nThese values will be element-wise interpolated into the string.\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.multiply()", "path": "reference/generated/numpy.char.multiply", "type": "numpy.char.multiply", "text": "\nReturn (a * i), that is string multiple concatenation, element-wise.\n\nValues in `i` of less than 0 are treated as 0 (which yields an empty string).\n\nOutput array of str or unicode, depending on input types\n\n"}, {"name": "char.not_equal()", "path": "reference/generated/numpy.char.not_equal", "type": "numpy.char.not_equal", "text": "\nReturn (x1 != x2) element-wise.\n\nUnlike `numpy.not_equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.partition()", "path": "reference/generated/numpy.char.partition", "type": "numpy.char.partition", "text": "\nPartition each element in `a` around `sep`.\n\nCalls `str.partition` element-wise.\n\nFor each element in `a`, split the element as the first occurrence of `sep`,\nand return 3 strings containing the part before the separator, the separator\nitself, and the part after the separator. If the separator is not found,\nreturn 3 strings containing the string itself, followed by two empty strings.\n\nInput array\n\nSeparator to split each string element in `a`.\n\nOutput array of str or unicode, depending on input type. The output array will\nhave an extra dimension with 3 elements per input element.\n\nSee also\n\n"}, {"name": "char.replace()", "path": "reference/generated/numpy.char.replace", "type": "numpy.char.replace", "text": "\nFor each element in `a`, return a copy of the string with all occurrences of\nsubstring `old` replaced by `new`.\n\nCalls `str.replace` element-wise.\n\nIf the optional argument `count` is given, only the first `count` occurrences\nare replaced.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.rfind()", "path": "reference/generated/numpy.char.rfind", "type": "numpy.char.rfind", "text": "\nFor each element in `a`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\nCalls `str.rfind` element-wise.\n\nOptional arguments `start` and `end` are interpreted as in slice notation.\n\nOutput array of ints. Return -1 on failure.\n\nSee also\n\n"}, {"name": "char.rindex()", "path": "reference/generated/numpy.char.rindex", "type": "numpy.char.rindex", "text": "\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\nCalls `str.rindex` element-wise.\n\nOutput array of ints.\n\nSee also\n\n"}, {"name": "char.rjust()", "path": "reference/generated/numpy.char.rjust", "type": "numpy.char.rjust", "text": "\nReturn an array with the elements of `a` right-justified in a string of length\n`width`.\n\nCalls `str.rjust` element-wise.\n\nThe length of the resulting strings\n\nThe character to use for padding\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.rpartition()", "path": "reference/generated/numpy.char.rpartition", "type": "numpy.char.rpartition", "text": "\nPartition (split) each element around the right-most separator.\n\nCalls `str.rpartition` element-wise.\n\nFor each element in `a`, split the element as the last occurrence of `sep`,\nand return 3 strings containing the part before the separator, the separator\nitself, and the part after the separator. If the separator is not found,\nreturn 3 strings containing the string itself, followed by two empty strings.\n\nInput array\n\nRight-most separator to split each element in array.\n\nOutput array of string or unicode, depending on input type. The output array\nwill have an extra dimension with 3 elements per input element.\n\nSee also\n\n"}, {"name": "char.rsplit()", "path": "reference/generated/numpy.char.rsplit", "type": "numpy.char.rsplit", "text": "\nFor each element in `a`, return a list of the words in the string, using `sep`\nas the delimiter string.\n\nCalls `str.rsplit` element-wise.\n\nExcept for splitting from the right, `rsplit` behaves like `split`.\n\nIf `sep` is not specified or None, any whitespace string is a separator.\n\nIf `maxsplit` is given, at most `maxsplit` splits are done, the rightmost\nones.\n\nArray of list objects\n\nSee also\n\n"}, {"name": "char.rstrip()", "path": "reference/generated/numpy.char.rstrip", "type": "numpy.char.rstrip", "text": "\nFor each element in `a`, return a copy with the trailing characters removed.\n\nCalls `str.rstrip` element-wise.\n\nThe `chars` argument is a string specifying the set of characters to be\nremoved. If omitted or None, the `chars` argument defaults to removing\nwhitespace. The `chars` argument is not a suffix; rather, all combinations of\nits values are stripped.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.split()", "path": "reference/generated/numpy.char.split", "type": "numpy.char.split", "text": "\nFor each element in `a`, return a list of the words in the string, using `sep`\nas the delimiter string.\n\nCalls `str.split` element-wise.\n\nIf `sep` is not specified or None, any whitespace string is a separator.\n\nIf `maxsplit` is given, at most `maxsplit` splits are done.\n\nArray of list objects\n\nSee also\n\n"}, {"name": "char.splitlines()", "path": "reference/generated/numpy.char.splitlines", "type": "numpy.char.splitlines", "text": "\nFor each element in `a`, return a list of the lines in the element, breaking\nat line boundaries.\n\nCalls `str.splitlines` element-wise.\n\nLine breaks are not included in the resulting list unless keepends is given\nand true.\n\nArray of list objects\n\nSee also\n\n"}, {"name": "char.startswith()", "path": "reference/generated/numpy.char.startswith", "type": "numpy.char.startswith", "text": "\nReturns a boolean array which is `True` where the string element in `a` starts\nwith `prefix`, otherwise `False`.\n\nCalls `str.startswith` element-wise.\n\nWith optional `start`, test beginning at that position. With optional `end`,\nstop comparing at that position.\n\nArray of booleans\n\nSee also\n\n"}, {"name": "char.str_len()", "path": "reference/generated/numpy.char.str_len", "type": "numpy.char.str_len", "text": "\nReturn len(a) element-wise.\n\nOutput array of integers\n\nSee also\n\n"}, {"name": "char.strip()", "path": "reference/generated/numpy.char.strip", "type": "numpy.char.strip", "text": "\nFor each element in `a`, return a copy with the leading and trailing\ncharacters removed.\n\nCalls `str.strip` element-wise.\n\nThe `chars` argument is a string specifying the set of characters to be\nremoved. If omitted or None, the `chars` argument defaults to removing\nwhitespace. The `chars` argument is not a prefix or suffix; rather, all\ncombinations of its values are stripped.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.swapcase()", "path": "reference/generated/numpy.char.swapcase", "type": "numpy.char.swapcase", "text": "\nReturn element-wise a copy of the string with uppercase characters converted\nto lowercase and vice versa.\n\nCalls `str.swapcase` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.title()", "path": "reference/generated/numpy.char.title", "type": "numpy.char.title", "text": "\nReturn element-wise title cased version of string or unicode.\n\nTitle case words start with uppercase characters, all remaining cased\ncharacters are lowercase.\n\nCalls `str.title` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.translate()", "path": "reference/generated/numpy.char.translate", "type": "numpy.char.translate", "text": "\nFor each element in `a`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\nCalls `str.translate` element-wise.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.upper()", "path": "reference/generated/numpy.char.upper", "type": "numpy.char.upper", "text": "\nReturn an array with the elements converted to uppercase.\n\nCalls `str.upper` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.zfill()", "path": "reference/generated/numpy.char.zfill", "type": "numpy.char.zfill", "text": "\nReturn the numeric string left-filled with zeros\n\nCalls `str.zfill` element-wise.\n\nInput array.\n\nWidth of string to left-fill elements in `a`.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "chararray.argsort()", "path": "reference/generated/numpy.chararray.argsort", "type": "numpy.chararray.argsort", "text": "\nmethod\n\nReturns the indices that would sort this array.\n\nRefer to `numpy.argsort` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.astype()", "path": "reference/generated/numpy.chararray.astype", "type": "numpy.chararray.astype", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "chararray.base", "path": "reference/generated/numpy.chararray.base", "type": "String operations", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "chararray.copy()", "path": "reference/generated/numpy.chararray.copy", "type": "numpy.chararray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "chararray.count()", "path": "reference/generated/numpy.chararray.count", "type": "numpy.chararray.count", "text": "\nmethod\n\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\nSee also\n\n"}, {"name": "chararray.ctypes", "path": "reference/generated/numpy.chararray.ctypes", "type": "String operations", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "chararray.data", "path": "reference/generated/numpy.chararray.data", "type": "String operations", "text": "\nattribute\n\nPython buffer object pointing to the start of the array\u2019s data.\n\n"}, {"name": "chararray.decode()", "path": "reference/generated/numpy.chararray.decode", "type": "numpy.chararray.decode", "text": "\nmethod\n\nCalls `str.decode` element-wise.\n\nSee also\n\n"}, {"name": "chararray.dump()", "path": "reference/generated/numpy.chararray.dump", "type": "numpy.chararray.dump", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "chararray.dumps()", "path": "reference/generated/numpy.chararray.dumps", "type": "numpy.chararray.dumps", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "chararray.encode()", "path": "reference/generated/numpy.chararray.encode", "type": "numpy.chararray.encode", "text": "\nmethod\n\nCalls `str.encode` element-wise.\n\nSee also\n\n"}, {"name": "chararray.endswith()", "path": "reference/generated/numpy.chararray.endswith", "type": "numpy.chararray.endswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nends with `suffix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "chararray.expandtabs()", "path": "reference/generated/numpy.chararray.expandtabs", "type": "numpy.chararray.expandtabs", "text": "\nmethod\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\nSee also\n\n"}, {"name": "chararray.fill()", "path": "reference/generated/numpy.chararray.fill", "type": "numpy.chararray.fill", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "chararray.find()", "path": "reference/generated/numpy.chararray.find", "type": "numpy.chararray.find", "text": "\nmethod\n\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\nSee also\n\n"}, {"name": "chararray.flags", "path": "reference/generated/numpy.chararray.flags", "type": "String operations", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "chararray.flat", "path": "reference/generated/numpy.chararray.flat", "type": "String operations", "text": "\nattribute\n\nA 1-D iterator over the array.\n\nThis is a `numpy.flatiter` instance, which acts similarly to, but is not a\nsubclass of, Python\u2019s built-in iterator object.\n\nSee also\n\nReturn a copy of the array collapsed into one dimension.\n\nAn assignment example:\n\n"}, {"name": "chararray.flatten()", "path": "reference/generated/numpy.chararray.flatten", "type": "numpy.chararray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "chararray.getfield()", "path": "reference/generated/numpy.chararray.getfield", "type": "numpy.chararray.getfield", "text": "\nmethod\n\nReturns a field of the given array as a certain type.\n\nA field is a view of the array data with a given data-type. The values in the\nview are determined by the given type and the offset into the current array in\nbytes. The offset needs to be such that the view dtype fits in the array\ndtype; for example an array of dtype complex128 has 16-byte elements. If\ntaking a view with a 32-bit integer (4 bytes), the offset needs to be between\n0 and 12 bytes.\n\nThe data type of the view. The dtype size of the view can not be larger than\nthat of the array itself.\n\nNumber of bytes to skip before beginning the element view.\n\nBy choosing an offset of 8 bytes we can select the complex part of the array\nfor our view:\n\n"}, {"name": "chararray.index()", "path": "reference/generated/numpy.chararray.index", "type": "numpy.chararray.index", "text": "\nmethod\n\nLike `find`, but raises `ValueError` when the substring is not found.\n\nSee also\n\n"}, {"name": "chararray.isalnum()", "path": "reference/generated/numpy.chararray.isalnum", "type": "numpy.chararray.isalnum", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isalpha()", "path": "reference/generated/numpy.chararray.isalpha", "type": "numpy.chararray.isalpha", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isdecimal()", "path": "reference/generated/numpy.chararray.isdecimal", "type": "numpy.chararray.isdecimal", "text": "\nmethod\n\nFor each element in `self`, return True if there are only decimal characters\nin the element.\n\nSee also\n\n"}, {"name": "chararray.isdigit()", "path": "reference/generated/numpy.chararray.isdigit", "type": "numpy.chararray.isdigit", "text": "\nmethod\n\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.islower()", "path": "reference/generated/numpy.chararray.islower", "type": "numpy.chararray.islower", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isnumeric()", "path": "reference/generated/numpy.chararray.isnumeric", "type": "numpy.chararray.isnumeric", "text": "\nmethod\n\nFor each element in `self`, return True if there are only numeric characters\nin the element.\n\nSee also\n\n"}, {"name": "chararray.isspace()", "path": "reference/generated/numpy.chararray.isspace", "type": "numpy.chararray.isspace", "text": "\nmethod\n\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.istitle()", "path": "reference/generated/numpy.chararray.istitle", "type": "numpy.chararray.istitle", "text": "\nmethod\n\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isupper()", "path": "reference/generated/numpy.chararray.isupper", "type": "numpy.chararray.isupper", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.item()", "path": "reference/generated/numpy.chararray.item", "type": "numpy.chararray.item", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "chararray.itemsize", "path": "reference/generated/numpy.chararray.itemsize", "type": "String operations", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "chararray.join()", "path": "reference/generated/numpy.chararray.join", "type": "numpy.chararray.join", "text": "\nmethod\n\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\nSee also\n\n"}, {"name": "chararray.ljust()", "path": "reference/generated/numpy.chararray.ljust", "type": "numpy.chararray.ljust", "text": "\nmethod\n\nReturn an array with the elements of `self` left-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "chararray.lower()", "path": "reference/generated/numpy.chararray.lower", "type": "numpy.chararray.lower", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to lowercase.\n\nSee also\n\n"}, {"name": "chararray.lstrip()", "path": "reference/generated/numpy.chararray.lstrip", "type": "numpy.chararray.lstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading characters removed.\n\nSee also\n\n"}, {"name": "chararray.nbytes", "path": "reference/generated/numpy.chararray.nbytes", "type": "String operations", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "chararray.ndim", "path": "reference/generated/numpy.chararray.ndim", "type": "String operations", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "chararray.nonzero()", "path": "reference/generated/numpy.chararray.nonzero", "type": "numpy.chararray.nonzero", "text": "\nmethod\n\nReturn the indices of the elements that are non-zero.\n\nRefer to `numpy.nonzero` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.put()", "path": "reference/generated/numpy.chararray.put", "type": "numpy.chararray.put", "text": "\nmethod\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\nRefer to `numpy.put` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.ravel()", "path": "reference/generated/numpy.chararray.ravel", "type": "numpy.chararray.ravel", "text": "\nmethod\n\nReturn a flattened array.\n\nRefer to `numpy.ravel` for full documentation.\n\nSee also\n\nequivalent function\n\na flat iterator on the array.\n\n"}, {"name": "chararray.repeat()", "path": "reference/generated/numpy.chararray.repeat", "type": "numpy.chararray.repeat", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.replace()", "path": "reference/generated/numpy.chararray.replace", "type": "numpy.chararray.replace", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with all occurrences\nof substring `old` replaced by `new`.\n\nSee also\n\n"}, {"name": "chararray.reshape()", "path": "reference/generated/numpy.chararray.reshape", "type": "numpy.chararray.reshape", "text": "\nmethod\n\nReturns an array containing the same data with a new shape.\n\nRefer to `numpy.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\nUnlike the free function `numpy.reshape`, this method on `ndarray` allows the\nelements of the shape parameter to be passed in as separate arguments. For\nexample, `a.reshape(10, 11)` is equivalent to `a.reshape((10, 11))`.\n\n"}, {"name": "chararray.resize()", "path": "reference/generated/numpy.chararray.resize", "type": "numpy.chararray.resize", "text": "\nmethod\n\nChange shape and size of array in-place.\n\nShape of resized array.\n\nIf False, reference count will not be checked. Default is True.\n\nIf `a` does not own its own data or references or views to it exist, and the\ndata memory must be changed. PyPy only: will always raise if the data memory\nmust be changed, since there is no reliable way to determine if references or\nviews to it exist.\n\nIf the `order` keyword argument is specified. This behaviour is a bug in\nNumPy.\n\nSee also\n\nReturn a new array with the specified shape.\n\nThis reallocates space for the data area if necessary.\n\nOnly contiguous arrays (data elements consecutive in memory) can be resized.\n\nThe purpose of the reference count check is to make sure you do not use this\narray as a buffer for another Python object and then reallocate the memory.\nHowever, reference counts can increase in other ways so if you are sure that\nyou have not shared the memory for this array with another Python object, then\nyou may safely set `refcheck` to False.\n\nShrinking an array: array is flattened (in the order that the data are stored\nin memory), resized, and reshaped:\n\nEnlarging an array: as above, but missing entries are filled with zeros:\n\nReferencing an array prevents resizing\u2026\n\nUnless `refcheck` is False:\n\n"}, {"name": "chararray.rfind()", "path": "reference/generated/numpy.chararray.rfind", "type": "numpy.chararray.rfind", "text": "\nmethod\n\nFor each element in `self`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\nSee also\n\n"}, {"name": "chararray.rindex()", "path": "reference/generated/numpy.chararray.rindex", "type": "numpy.chararray.rindex", "text": "\nmethod\n\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\nSee also\n\n"}, {"name": "chararray.rjust()", "path": "reference/generated/numpy.chararray.rjust", "type": "numpy.chararray.rjust", "text": "\nmethod\n\nReturn an array with the elements of `self` right-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "chararray.rsplit()", "path": "reference/generated/numpy.chararray.rsplit", "type": "numpy.chararray.rsplit", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "chararray.rstrip()", "path": "reference/generated/numpy.chararray.rstrip", "type": "numpy.chararray.rstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the trailing characters\nremoved.\n\nSee also\n\n"}, {"name": "chararray.searchsorted()", "path": "reference/generated/numpy.chararray.searchsorted", "type": "numpy.chararray.searchsorted", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.setfield()", "path": "reference/generated/numpy.chararray.setfield", "type": "numpy.chararray.setfield", "text": "\nmethod\n\nPut a value into a specified place in a field defined by a data-type.\n\nPlace `val` into `a`\u2019s field defined by `dtype` and beginning `offset` bytes\ninto the field.\n\nValue to be placed in field.\n\nData-type of the field in which to place `val`.\n\nThe number of bytes into the field at which to place `val`.\n\nSee also\n\n"}, {"name": "chararray.setflags()", "path": "reference/generated/numpy.chararray.setflags", "type": "numpy.chararray.setflags", "text": "\nmethod\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\nThese Boolean-valued flags affect how numpy interprets the memory area used by\n`a` (see Notes below). The ALIGNED flag can only be set to True if the data is\nactually aligned according to the type. The WRITEBACKIFCOPY and (deprecated)\nUPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be\nset to True if the array owns its own memory, or the ultimate owner of the\nmemory exposes a writeable buffer interface, or is a string. (The exception\nfor string is made so that unpickling can be done without copying memory.)\n\nDescribes whether or not `a` can be written to.\n\nDescribes whether or not `a` is aligned properly for its type.\n\nDescribes whether or not `a` is a copy of another \u201cbase\u201d array.\n\nArray flags provide information about how the memory area used for the array\nis to be interpreted. There are 7 Boolean flags in use, only four of which can\nbe changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n\nWRITEABLE (W) the data area can be written to;\n\nALIGNED (A) the data and strides are aligned appropriately for the hardware\n(as determined by the compiler);\n\nUPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n\nWRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by\n.base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the\nbase array will be updated with the contents of this array.\n\nAll flags can be accessed using the single (upper case) letter as well as the\nfull name.\n\n"}, {"name": "chararray.size", "path": "reference/generated/numpy.chararray.size", "type": "String operations", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "chararray.sort()", "path": "reference/generated/numpy.chararray.sort", "type": "numpy.chararray.sort", "text": "\nmethod\n\nSort an array in-place. Refer to `numpy.sort` for full documentation.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with datatype. The \u2018mergesort\u2019 option is retained for\nbackwards compatibility.\n\nChanged in version 1.15.0: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a sorted copy of an array.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in sorted array.\n\nPartial sort.\n\nSee `numpy.sort` for notes on the different sorting algorithms.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\n"}, {"name": "chararray.split()", "path": "reference/generated/numpy.chararray.split", "type": "numpy.chararray.split", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "chararray.splitlines()", "path": "reference/generated/numpy.chararray.splitlines", "type": "numpy.chararray.splitlines", "text": "\nmethod\n\nFor each element in `self`, return a list of the lines in the element,\nbreaking at line boundaries.\n\nSee also\n\n"}, {"name": "chararray.squeeze()", "path": "reference/generated/numpy.chararray.squeeze", "type": "numpy.chararray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.startswith()", "path": "reference/generated/numpy.chararray.startswith", "type": "numpy.chararray.startswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nstarts with `prefix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "chararray.strides", "path": "reference/generated/numpy.chararray.strides", "type": "String operations", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "chararray.strip()", "path": "reference/generated/numpy.chararray.strip", "type": "numpy.chararray.strip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading and trailing\ncharacters removed.\n\nSee also\n\n"}, {"name": "chararray.swapaxes()", "path": "reference/generated/numpy.chararray.swapaxes", "type": "numpy.chararray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.swapcase()", "path": "reference/generated/numpy.chararray.swapcase", "type": "numpy.chararray.swapcase", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with uppercase\ncharacters converted to lowercase and vice versa.\n\nSee also\n\n"}, {"name": "chararray.T", "path": "reference/generated/numpy.chararray.t", "type": "String operations", "text": "\nattribute\n\nThe transposed array.\n\nSame as `self.transpose()`.\n\nSee also\n\n"}, {"name": "chararray.take()", "path": "reference/generated/numpy.chararray.take", "type": "numpy.chararray.take", "text": "\nmethod\n\nReturn an array formed from the elements of `a` at the given indices.\n\nRefer to `numpy.take` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.title()", "path": "reference/generated/numpy.chararray.title", "type": "numpy.chararray.title", "text": "\nmethod\n\nFor each element in `self`, return a titlecased version of the string: words\nstart with uppercase characters, all remaining cased characters are lowercase.\n\nSee also\n\n"}, {"name": "chararray.tobytes()", "path": "reference/generated/numpy.chararray.tobytes", "type": "String operations", "text": "\nmethod\n\nConstruct Python bytes containing the raw data bytes in the array.\n\nConstructs Python bytes showing a copy of the raw contents of data memory. The\nbytes object is produced in C-order by default. This behavior is controlled by\nthe `order` parameter.\n\nNew in version 1.9.0.\n\nControls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019\notherwise. Default is \u2018C\u2019.\n\nPython bytes exhibiting a copy of `a`\u2019s raw data.\n\n"}, {"name": "chararray.tofile()", "path": "reference/generated/numpy.chararray.tofile", "type": "numpy.chararray.tofile", "text": "\nmethod\n\nWrite array to a file as text or binary (default).\n\nData is always written in \u2018C\u2019 order, independent of the order of `a`. The data\nproduced by this method can be recovered using the function fromfile().\n\nAn open file object, or a string containing a filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nSeparator between array items for text output. If \u201c\u201d (empty), a binary file is\nwritten, equivalent to `file.write(a.tobytes())`.\n\nFormat string for text file output. Each entry in the array is formatted to\ntext by first converting it to the closest Python type, and then using\n\u201cformat\u201d % item.\n\nThis is a convenience function for quick storage of array data. Information on\nendianness and precision is lost, so this method is not a good choice for\nfiles intended to archive data or transport data between machines with\ndifferent endianness. Some of these problems can be overcome by outputting the\ndata as text files, at the expense of speed and file size.\n\nWhen fid is a file object, array contents are directly written to the file,\nbypassing the file object\u2019s `write` method. As a result, tofile cannot be used\nwith files objects supporting compression (e.g., GzipFile) or file-like\nobjects that do not support `fileno()` (e.g., BytesIO).\n\n"}, {"name": "chararray.tolist()", "path": "reference/generated/numpy.chararray.tolist", "type": "numpy.chararray.tolist", "text": "\nmethod\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\nReturn a copy of the array data as a (nested) Python list. Data items are\nconverted to the nearest compatible builtin Python type, via the `item`\nfunction.\n\nIf `a.ndim` is 0, then since the depth of the nested list is 0, it will not be\na list at all, but a simple Python scalar.\n\nThe possibly nested list of array elements.\n\nThe array may be recreated via `a = np.array(a.tolist())`, although this may\nsometimes lose precision.\n\nFor a 1D array, `a.tolist()` is almost the same as `list(a)`, except that\n`tolist` changes numpy scalars to Python scalars:\n\nAdditionally, for a 2D array, `tolist` applies recursively:\n\nThe base case for this recursion is a 0D array:\n\n"}, {"name": "chararray.tostring()", "path": "reference/generated/numpy.chararray.tostring", "type": "numpy.chararray.tostring", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "chararray.translate()", "path": "reference/generated/numpy.chararray.translate", "type": "numpy.chararray.translate", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\nSee also\n\n"}, {"name": "chararray.transpose()", "path": "reference/generated/numpy.chararray.transpose", "type": "numpy.chararray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "chararray.upper()", "path": "reference/generated/numpy.chararray.upper", "type": "numpy.chararray.upper", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to uppercase.\n\nSee also\n\n"}, {"name": "chararray.view()", "path": "reference/generated/numpy.chararray.view", "type": "numpy.chararray.view", "text": "\nmethod\n\nNew view of array with the same data.\n\nNote\n\nPassing None for `dtype` is different from omitting the parameter, since the\nformer invokes `dtype(None)` which is an alias for `dtype('float_')`.\n\nData-type descriptor of the returned view, e.g., float32 or int16. Omitting it\nresults in the view having the same data-type as `a`. This argument can also\nbe specified as an ndarray sub-class, which then specifies the type of the\nreturned object (this is equivalent to setting the `type` parameter).\n\nType of the returned view, e.g., ndarray or matrix. Again, omission of the\nparameter results in type preservation.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\nViewing array data using a different type and dtype:\n\nCreating a view on a structured array so it can be used in calculations\n\nMaking changes to the view changes the underlying array\n\nUsing a view to convert an array to a recarray:\n\nViews share data:\n\nViews that change the dtype size (bytes per entry) should normally be avoided\non arrays defined by slices, transposes, fortran-ordering, etc.:\n\n"}, {"name": "chararray.zfill()", "path": "reference/generated/numpy.chararray.zfill", "type": "numpy.chararray.zfill", "text": "\nmethod\n\nReturn the numeric string left-filled with zeros in a string of length\n`width`.\n\nSee also\n\n"}, {"name": "class.__array__()", "path": "reference/arrays.classes#numpy.class.__array__", "type": "Standard array subclasses", "text": "\nIf a class (ndarray subclass or not) having the `__array__` method is used as\nthe output object of an ufunc, results will not be written to the object\nreturned by `__array__`. This practice will return `TypeError`.\n\n"}, {"name": "class.__array_finalize__()", "path": "reference/arrays.classes#numpy.class.__array_finalize__", "type": "Standard array subclasses", "text": "\nThis method is called whenever the system internally allocates a new array\nfrom obj, where obj is a subclass (subtype) of the `ndarray`. It can be used\nto change attributes of self after construction (so as to ensure a 2-d matrix\nfor example), or to update meta-information from the \u201cparent.\u201d Subclasses\ninherit a default implementation of this method that does nothing.\n\n"}, {"name": "class.__array_function__()", "path": "reference/arrays.classes#numpy.class.__array_function__", "type": "Standard array subclasses", "text": "\nNew in version 1.16.\n\nNote\n\nAs a convenience for `__array_function__` implementors, `types` provides all\nargument types with an `'__array_function__'` attribute. This allows\nimplementors to quickly identify cases where they should defer to\n`__array_function__` implementations on other arguments. Implementations\nshould not rely on the iteration order of `types`.\n\nMost implementations of `__array_function__` will start with two checks:\n\nIf these conditions hold, `__array_function__` should return the result from\ncalling its implementation for `func(*args, **kwargs)`. Otherwise, it should\nreturn the sentinel value `NotImplemented`, indicating that the function is\nnot implemented by these types.\n\nThere are no general requirements on the return value from\n`__array_function__`, although most sensible implementations should probably\nreturn array(s) with the same type as one of the function\u2019s arguments.\n\nIt may also be convenient to define a custom decorators (`implements` below)\nfor registering `__array_function__` implementations.\n\nNote that it is not required for `__array_function__` implementations to\ninclude all of the corresponding NumPy function\u2019s optional arguments (e.g.,\n`broadcast_to` above omits the irrelevant `subok` argument). Optional\narguments are only passed in to `__array_function__` if they were explicitly\nused in the NumPy function call.\n\nJust like the case for builtin special methods like `__add__`, properly\nwritten `__array_function__` methods should always return `NotImplemented`\nwhen an unknown type is encountered. Otherwise, it will be impossible to\ncorrectly override NumPy functions from another object if the operation also\nincludes one of your objects.\n\nFor the most part, the rules for dispatch with `__array_function__` match\nthose for `__array_ufunc__`. In particular:\n\nIf no `__array_function__` methods exists, NumPy will default to calling its\nown implementation, intended for use on NumPy arrays. This case arises, for\nexample, when all array-like arguments are Python numbers or lists. (NumPy\narrays do have a `__array_function__` method, given below, but it always\nreturns `NotImplemented` if any argument other than a NumPy array subclass\nimplements `__array_function__`.)\n\nOne deviation from the current behavior of `__array_ufunc__` is that NumPy\nwill only call `__array_function__` on the first argument of each unique type.\nThis matches Python\u2019s rule for calling reflected methods, and this ensures\nthat checking overloads has acceptable performance even when there are a large\nnumber of overloaded arguments.\n\n"}, {"name": "class.__array_prepare__()", "path": "reference/arrays.classes#numpy.class.__array_prepare__", "type": "Standard array subclasses", "text": "\nAt the beginning of every ufunc, this method is called on the input object\nwith the highest array priority, or the output object if one was specified.\nThe output array is passed in and whatever is returned is passed to the ufunc.\nSubclasses inherit a default implementation of this method which simply\nreturns the output array unmodified. Subclasses may opt to use this method to\ntransform the output array into an instance of the subclass and update\nmetadata before returning the array to the ufunc for computation.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\n"}, {"name": "class.__array_priority__", "path": "reference/arrays.classes#numpy.class.__array_priority__", "type": "Standard array subclasses", "text": "\nThe value of this attribute is used to determine what type of object to return\nin situations where there is more than one possibility for the Python type of\nthe returned object. Subclasses inherit a default value of 0.0 for this\nattribute.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\n"}, {"name": "class.__array_ufunc__()", "path": "reference/arrays.classes", "type": "Standard array subclasses", "text": "\nNote\n\nSubclassing a `numpy.ndarray` is possible but if your goal is to create an\narray with modified behavior, as do dask arrays for distributed computation\nand cupy arrays for GPU-based computation, subclassing is discouraged.\nInstead, using numpy\u2019s dispatch mechanism is recommended.\n\nThe `ndarray` can be inherited from (in Python or in C) if desired. Therefore,\nit can form a foundation for many useful classes. Often whether to sub-class\nthe array object or to simply use the core array component as an internal part\nof a new class is a difficult decision, and can be simply a matter of choice.\nNumPy has several tools for simplifying how your new object interacts with\nother array objects, and so the choice may not be significant in the end. One\nway to simplify the question is by asking yourself if the object you are\ninterested in can be replaced as a single array or does it really require two\nor more arrays at its core.\n\nNote that `asarray` always returns the base-class ndarray. If you are\nconfident that your use of the array object can handle any subclass of an\nndarray, then `asanyarray` can be used to allow subclasses to propagate more\ncleanly through your subroutine. In principal a subclass could redefine any\naspect of the array and therefore, under strict guidelines, `asanyarray` would\nrarely be useful. However, most subclasses of the array object will not\nredefine certain aspects of the array object such as the buffer interface, or\nthe attributes of the array. One important example, however, of why your\nsubroutine may not be able to handle an arbitrary subclass of an array is that\nmatrices redefine the \u201c*\u201d operator to be matrix-multiplication, rather than\nelement-by-element multiplication.\n\nSee also\n\nSubclassing ndarray\n\nNumPy provides several hooks that classes can customize:\n\nNew in version 1.13.\n\nAny class, ndarray subclass or not, can define this method or set it to None\nin order to override the behavior of NumPy\u2019s ufuncs. This works quite\nsimilarly to Python\u2019s `__mul__` and other binary operation routines.\n\nThe method should return either the result of the operation, or\n`NotImplemented` if the operation requested is not implemented.\n\nIf one of the input or output arguments has a `__array_ufunc__` method, it is\nexecuted instead of the ufunc. If more than one of the arguments implements\n`__array_ufunc__`, they are tried in the order: subclasses before\nsuperclasses, inputs before outputs, otherwise left to right. The first\nroutine returning something other than `NotImplemented` determines the result.\nIf all of the `__array_ufunc__` operations return `NotImplemented`, a\n`TypeError` is raised.\n\nNote\n\nWe intend to re-implement numpy functions as (generalized) Ufunc, in which\ncase it will become possible for them to be overridden by the\n`__array_ufunc__` method. A prime candidate is `matmul`, which currently is\nnot a Ufunc, but could be relatively easily be rewritten as a (set of)\ngeneralized Ufuncs. The same may happen with functions such as `median`,\n`amin`, and `argsort`.\n\nLike with some other special methods in python, such as `__hash__` and\n`__iter__`, it is possible to indicate that your class does not support ufuncs\nby setting `__array_ufunc__ = None`. Ufuncs always raise `TypeError` when\ncalled on an object that sets `__array_ufunc__ = None`.\n\nThe presence of `__array_ufunc__` also influences how `ndarray` handles binary\noperations like `arr + obj` and `arr < obj` when `arr` is an `ndarray` and\n`obj` is an instance of a custom class. There are two possibilities. If\n`obj.__array_ufunc__` is present and not None, then `ndarray.__add__` and\nfriends will delegate to the ufunc machinery, meaning that `arr + obj` becomes\n`np.add(arr, obj)`, and then `add` invokes `obj.__array_ufunc__`. This is\nuseful if you want to define an object that acts like an array.\n\nAlternatively, if `obj.__array_ufunc__` is set to None, then as a special\ncase, special methods like `ndarray.__add__` will notice this and\nunconditionally raise `TypeError`. This is useful if you want to create\nobjects that interact with arrays via binary operations, but are not\nthemselves arrays. For example, a units handling system might have an object\n`m` representing the \u201cmeters\u201d unit, and want to support the syntax `arr * m`\nto represent that the array has units of \u201cmeters\u201d, but not want to otherwise\ninteract with arrays via ufuncs or otherwise. This can be done by setting\n`__array_ufunc__ = None` and defining `__mul__` and `__rmul__` methods. (Note\nthat this means that writing an `__array_ufunc__` that always returns\n`NotImplemented` is not quite the same as setting `__array_ufunc__ = None`: in\nthe former case, `arr + obj` will raise `TypeError`, while in the latter case\nit is possible to define a `__radd__` method to prevent this.)\n\nThe above does not hold for in-place operators, for which `ndarray` never\nreturns `NotImplemented`. Hence, `arr += obj` would always lead to a\n`TypeError`. This is because for arrays in-place operations cannot generically\nbe replaced by a simple reverse operation. (For instance, by default, `arr +=\nobj` would be translated to `arr = arr + obj`, i.e., `arr` would be replaced,\ncontrary to what is expected for in-place array operations.)\n\nNote\n\nIf you define `__array_ufunc__`:\n\nNote\n\nIf a class defines the `__array_ufunc__` method, this disables the\n`__array_wrap__`, `__array_prepare__`, `__array_priority__` mechanism\ndescribed below for ufuncs (which may eventually be deprecated).\n\nNew in version 1.16.\n\nNote\n\nAs a convenience for `__array_function__` implementors, `types` provides all\nargument types with an `'__array_function__'` attribute. This allows\nimplementors to quickly identify cases where they should defer to\n`__array_function__` implementations on other arguments. Implementations\nshould not rely on the iteration order of `types`.\n\nMost implementations of `__array_function__` will start with two checks:\n\nIf these conditions hold, `__array_function__` should return the result from\ncalling its implementation for `func(*args, **kwargs)`. Otherwise, it should\nreturn the sentinel value `NotImplemented`, indicating that the function is\nnot implemented by these types.\n\nThere are no general requirements on the return value from\n`__array_function__`, although most sensible implementations should probably\nreturn array(s) with the same type as one of the function\u2019s arguments.\n\nIt may also be convenient to define a custom decorators (`implements` below)\nfor registering `__array_function__` implementations.\n\nNote that it is not required for `__array_function__` implementations to\ninclude all of the corresponding NumPy function\u2019s optional arguments (e.g.,\n`broadcast_to` above omits the irrelevant `subok` argument). Optional\narguments are only passed in to `__array_function__` if they were explicitly\nused in the NumPy function call.\n\nJust like the case for builtin special methods like `__add__`, properly\nwritten `__array_function__` methods should always return `NotImplemented`\nwhen an unknown type is encountered. Otherwise, it will be impossible to\ncorrectly override NumPy functions from another object if the operation also\nincludes one of your objects.\n\nFor the most part, the rules for dispatch with `__array_function__` match\nthose for `__array_ufunc__`. In particular:\n\nIf no `__array_function__` methods exists, NumPy will default to calling its\nown implementation, intended for use on NumPy arrays. This case arises, for\nexample, when all array-like arguments are Python numbers or lists. (NumPy\narrays do have a `__array_function__` method, given below, but it always\nreturns `NotImplemented` if any argument other than a NumPy array subclass\nimplements `__array_function__`.)\n\nOne deviation from the current behavior of `__array_ufunc__` is that NumPy\nwill only call `__array_function__` on the first argument of each unique type.\nThis matches Python\u2019s rule for calling reflected methods, and this ensures\nthat checking overloads has acceptable performance even when there are a large\nnumber of overloaded arguments.\n\nThis method is called whenever the system internally allocates a new array\nfrom obj, where obj is a subclass (subtype) of the `ndarray`. It can be used\nto change attributes of self after construction (so as to ensure a 2-d matrix\nfor example), or to update meta-information from the \u201cparent.\u201d Subclasses\ninherit a default implementation of this method that does nothing.\n\nAt the beginning of every ufunc, this method is called on the input object\nwith the highest array priority, or the output object if one was specified.\nThe output array is passed in and whatever is returned is passed to the ufunc.\nSubclasses inherit a default implementation of this method which simply\nreturns the output array unmodified. Subclasses may opt to use this method to\ntransform the output array into an instance of the subclass and update\nmetadata before returning the array to the ufunc for computation.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\nAt the end of every ufunc, this method is called on the input object with the\nhighest array priority, or the output object if one was specified. The ufunc-\ncomputed array is passed in and whatever is returned is passed to the user.\nSubclasses inherit a default implementation of this method, which transforms\nthe array into a new instance of the object\u2019s class. Subclasses may opt to use\nthis method to transform the output array into an instance of the subclass and\nupdate metadata before returning the array to the user.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\nThe value of this attribute is used to determine what type of object to return\nin situations where there is more than one possibility for the Python type of\nthe returned object. Subclasses inherit a default value of 0.0 for this\nattribute.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\nIf a class (ndarray subclass or not) having the `__array__` method is used as\nthe output object of an ufunc, results will not be written to the object\nreturned by `__array__`. This practice will return `TypeError`.\n\nNote\n\nIt is strongly advised not to use the matrix subclass. As described below, it\nmakes writing functions that deal consistently with matrices and regular\narrays very difficult. Currently, they are mainly used for interacting with\n`scipy.sparse`. We hope to provide an alternative for this use, however, and\neventually remove the `matrix` subclass.\n\n`matrix` objects inherit from the ndarray and therefore, they have the same\nattributes and methods of ndarrays. There are six important differences of\nmatrix objects, however, that may lead to unexpected results when you use\nmatrices but expect them to act like arrays:\n\nMatrices have special attributes which make calculations easier. These are\n\n`matrix.T`\n\nReturns the transpose of the matrix.\n\n`matrix.H`\n\nReturns the (complex) conjugate transpose of `self`.\n\n`matrix.I`\n\nReturns the (multiplicative) inverse of invertible `self`.\n\n`matrix.A`\n\nReturn `self` as an `ndarray` object.\n\nWarning\n\nMatrix objects over-ride multiplication, \u2018*\u2019, and power, \u2018**\u2019, to be matrix-\nmultiplication and matrix power, respectively. If your subroutine can accept\nsub-classes and you do not convert to base- class arrays, then you must use\nthe ufuncs multiply and power to be sure that you are performing the correct\noperation for all inputs.\n\nThe matrix class is a Python subclass of the ndarray and can be used as a\nreference for how to construct your own subclass of the ndarray. Matrices can\nbe created from other matrices, strings, and anything else that can be\nconverted to an `ndarray` . The name \u201cmat \u201cis an alias for \u201cmatrix \u201cin NumPy.\n\n`matrix`(data[, dtype, copy])\n\nNote\n\nIt is no longer recommended to use this class, even for linear\n\n`asmatrix`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`bmat`(obj[, ldict, gdict])\n\nBuild a matrix object from a string, nested sequence, or array.\n\nExample 1: Matrix creation from a string\n\nExample 2: Matrix creation from nested sequence\n\nExample 3: Matrix creation from an array\n\nMemory-mapped files are useful for reading and/or modifying small segments of\na large file with regular layout, without reading the entire file into memory.\nA simple subclass of the ndarray uses a memory-mapped file for the data buffer\nof the array. For small files, the over-head of reading the entire file into\nmemory is typically not significant, however for large files using memory\nmapping can save considerable resources.\n\nMemory-mapped-file arrays have one additional method (besides those they\ninherit from the ndarray): `.flush()` which must be called manually by the\nuser to ensure that any changes to the array actually get written to disk.\n\n`memmap`(filename[, dtype, mode, offset, ...])\n\nCreate a memory-map to an array stored in a binary file on disk.\n\n`memmap.flush`()\n\nWrite any changes in the array to the file on disk.\n\nExample:\n\nSee also\n\nCreating character arrays (numpy.char)\n\nNote\n\nThe `chararray` class exists for backwards compatibility with Numarray, it is\nnot recommended for new development. Starting from numpy 1.4, if one needs\narrays of strings, it is recommended to use arrays of `dtype` `object_`,\n`bytes_` or `str_`, and use the free functions in the `numpy.char` module for\nfast vectorized string operations.\n\nThese are enhanced arrays of either `str_` type or `bytes_` type. These arrays\ninherit from the `ndarray`, but specially-define the operations `+`, `*`, and\n`%` on a (broadcasting) element-by-element basis. These operations are not\navailable on the standard `ndarray` of character type. In addition, the\n`chararray` has all of the standard `str` (and `bytes`) methods, executing\nthem on an element-by-element basis. Perhaps the easiest way to create a\nchararray is to use `self.view(chararray)` where self is an ndarray of str or\nunicode data-type. However, a chararray can also be created using the\n`numpy.chararray` constructor, or via the `numpy.char.array` function:\n\n`chararray`(shape[, itemsize, unicode, ...])\n\nProvides a convenient view on arrays of string and unicode values.\n\n`core.defchararray.array`(obj[, itemsize, ...])\n\nCreate a `chararray`.\n\nAnother difference with the standard ndarray of str data-type is that the\nchararray inherits the feature introduced by Numarray that white-space at the\nend of any element in the array will be ignored on item retrieval and\ncomparison operations.\n\nSee also\n\nCreating record arrays (numpy.rec), Data type routines, Data type objects\n(dtype).\n\nNumPy provides the `recarray` class which allows accessing the fields of a\nstructured array as attributes, and a corresponding scalar data type object\n`record`.\n\n`recarray`(shape[, dtype, buf, offset, ...])\n\nConstruct an ndarray that allows field access using attributes.\n\n`record`\n\nA data-type scalar that allows field access as attribute lookup.\n\nSee also\n\nMasked arrays\n\nFor backward compatibility and as a standard \u201ccontainer \u201cclass, the UserArray\nfrom Numeric has been brought over to NumPy and named\n`numpy.lib.user_array.container` The container class is a Python class whose\nself.array attribute is an ndarray. Multiple inheritance is probably easier\nwith numpy.lib.user_array.container than with the ndarray itself and so it is\nincluded by default. It is not documented here beyond mentioning its existence\nbecause you are encouraged to use the ndarray class directly if you can.\n\n`numpy.lib.user_array.container`(data[, ...])\n\nStandard container-class for easy multiple-inheritance.\n\nIterators are a powerful concept for array processing. Essentially, iterators\nimplement a generalized for-loop. If myiter is an iterator object, then the\nPython code:\n\ncalls `val = next(myiter)` repeatedly until `StopIteration` is raised by the\niterator. There are several ways to iterate over an array that may be useful:\ndefault iteration, flat iteration, and \\\\(N\\\\)-dimensional enumeration.\n\nThe default iterator of an ndarray object is the default Python iterator of a\nsequence type. Thus, when the array object itself is used as an iterator. The\ndefault behavior is equivalent to:\n\nThis default iterator selects a sub-array of dimension \\\\(N-1\\\\) from the\narray. This can be a useful construct for defining recursive algorithms. To\nloop over the entire array requires \\\\(N\\\\) for-loops.\n\n`ndarray.flat`\n\nA 1-D iterator over the array.\n\nAs mentioned previously, the flat attribute of ndarray objects returns an\niterator that will cycle over the entire array in C-style contiguous order.\n\nHere, I\u2019ve used the built-in enumerate iterator to return the iterator index\nas well as the value.\n\n`ndenumerate`(arr)\n\nMultidimensional index iterator.\n\nSometimes it may be useful to get the N-dimensional index while iterating. The\nndenumerate iterator can achieve this.\n\n`broadcast`\n\nProduce an object that mimics broadcasting.\n\nThe general concept of broadcasting is also available from Python using the\n`broadcast` iterator. This object takes \\\\(N\\\\) objects as inputs and returns\nan iterator that returns tuples providing each of the input sequence elements\nin the broadcasted result.\n\n"}, {"name": "class.__array_wrap__()", "path": "reference/arrays.classes#numpy.class.__array_wrap__", "type": "Standard array subclasses", "text": "\nAt the end of every ufunc, this method is called on the input object with the\nhighest array priority, or the output object if one was specified. The ufunc-\ncomputed array is passed in and whatever is returned is passed to the user.\nSubclasses inherit a default implementation of this method, which transforms\nthe array into a new instance of the object\u2019s class. Subclasses may opt to use\nthis method to transform the output array into an instance of the subclass and\nupdate metadata before returning the array to the user.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\n"}, {"name": "config.add_library()", "path": "reference/distutils_guide", "type": "NumPy Distutils - Users Guide", "text": "\nCurrently SciPy project consists of two packages:\n\nNumPy \u2014 it provides packages like:\n\nThe aim of this document is to describe how to add new tools to SciPy.\n\nSciPy consists of Python packages, called SciPy packages, that are available\nto Python users via the `scipy` namespace. Each SciPy package may contain\nother SciPy packages. And so on. Therefore, the SciPy directory tree is a tree\nof packages with arbitrary depth and width. Any SciPy package may depend on\nNumPy packages but the dependence on other SciPy packages should be kept\nminimal or zero.\n\nA SciPy package contains, in addition to its sources, the following files and\ndirectories:\n\nTheir contents are described below.\n\nIn order to add a Python package to SciPy, its build script (`setup.py`) must\nmeet certain requirements. The most important requirement is that the package\ndefine a `configuration(parent_package='',top_path=None)` function which\nreturns a dictionary suitable for passing to `numpy.distutils.core.setup(..)`.\nTo simplify the construction of this dictionary, `numpy.distutils.misc_util`\nprovides the `Configuration` class, described below.\n\nBelow is an example of a minimal `setup.py` file for a pure SciPy package:\n\nThe arguments of the `configuration` function specify the name of parent SciPy\npackage (`parent_package`) and the directory location of the main `setup.py`\nscript (`top_path`). These arguments, along with the name of the current\npackage, should be passed to the `Configuration` constructor.\n\nThe `Configuration` constructor has a fourth optional argument,\n`package_path`, that can be used when package files are located in a different\nlocation than the directory of the `setup.py` file.\n\nRemaining `Configuration` arguments are all keyword arguments that will be\nused to initialize attributes of `Configuration` instance. Usually, these\nkeywords are the same as the ones that `setup(..)` function would expect, for\nexample, `packages`, `ext_modules`, `data_files`, `include_dirs`, `libraries`,\n`headers`, `scripts`, `package_dir`, etc. However, the direct specification of\nthese keywords is not recommended as the content of these keyword arguments\nwill not be processed or checked for the consistency of SciPy building system.\n\nFinally, `Configuration` has `.todict()` method that returns all the\nconfiguration data as a dictionary suitable for passing on to the `setup(..)`\nfunction.\n\nIn addition to attributes that can be specified via keyword arguments to\n`Configuration` constructor, `Configuration` instance (let us denote as\n`config`) has the following attributes that can be useful in writing setup\nscripts:\n\n`config.add_data_files(*files)` \u2014 prepend `files` to `data_files` list. If\n`files` item is a tuple then its first element defines the suffix of where\ndata files are copied relative to package installation directory and the\nsecond element specifies the path to data files. By default data files are\ncopied under package installation directory. For example,\n\nwill install data files to the following locations\n\nPath to data files can be a function taking no arguments and returning path(s)\nto data files \u2013 this is a useful when data files are generated while building\nthe package. (XXX: explain the step when this function are called exactly)\n\n`config.add_data_dir(data_path)` \u2014 add directory `data_path` recursively to\n`data_files`. The whole directory tree starting at `data_path` will be copied\nunder package installation directory. If `data_path` is a tuple then its first\nelement defines the suffix of where data files are copied relative to package\ninstallation directory and the second element specifies the path to data\ndirectory. By default, data directory are copied under package installation\ndirectory under the basename of `data_path`. For example,\n\nwill install data files to the following locations\n\n`config.add_extension(name,sources,**kw)` \u2014 create and add an `Extension`\ninstance to `ext_modules` list. The first argument `name` defines the name of\nthe extension module that will be installed under `config.name` package. The\nsecond argument is a list of sources. `add_extension` method takes also\nkeyword arguments that are passed on to the `Extension` constructor. The list\nof allowed keywords is the following: `include_dirs`, `define_macros`,\n`undef_macros`, `library_dirs`, `libraries`, `runtime_library_dirs`,\n`extra_objects`, `extra_compile_args`, `extra_link_args`, `export_symbols`,\n`swig_opts`, `depends`, `language`, `f2py_options`, `module_dirs`,\n`extra_info`, `extra_f77_compile_args`, `extra_f90_compile_args`.\n\nNote that `config.paths` method is applied to all lists that may contain\npaths. `extra_info` is a dictionary or a list of dictionaries that content\nwill be appended to keyword arguments. The list `depends` contains paths to\nfiles or directories that the sources of the extension module depend on. If\nany path in the `depends` list is newer than the extension module, then the\nmodule will be rebuilt.\n\nThe list of sources may contain functions (\u2018source generators\u2019) with a pattern\n`def <funcname>(ext, build_dir): return <source(s) or None>`. If `funcname`\nreturns `None`, no sources are generated. And if the `Extension` instance has\nno sources after processing all source generators, no extension module will be\nbuilt. This is the recommended way to conditionally define extension modules.\nSource generator functions are called by the `build_src` sub-command of\n`numpy.distutils`.\n\nFor example, here is a typical source generator function:\n\nThe first argument contains the Extension instance that can be useful to\naccess its attributes like `depends`, `sources`, etc. lists and modify them\nduring the building process. The second argument gives a path to a build\ndirectory that must be used when creating files to a disk.\n\nNumPy distutils supports automatic conversion of source files named\n<somefile>.src. This facility can be used to maintain very similar code blocks\nrequiring only simple changes between blocks. During the build phase of setup,\nif a template file named <somefile>.src is encountered, a new file named\n<somefile> is constructed from the template and placed in the build directory\nto be used instead. Two forms of template conversion are supported. The first\nform occurs for files named <file>.ext.src where ext is a recognized Fortran\nextension (f, f90, f95, f77, for, ftn, pyf). The second form is used for all\nother cases.\n\nThis template converter will replicate all function and subroutine blocks in\nthe file with names that contain \u2018<\u2026>\u2019 according to the rules in \u2018<\u2026>\u2019. The\nnumber of comma-separated words in \u2018<\u2026>\u2019 determines the number of times the\nblock is repeated. What these words are indicates what that repeat rule,\n\u2018<\u2026>\u2019, should be replaced with in each block. All of the repeat rules in a\nblock must contain the same number of comma-separated words indicating the\nnumber of times that block should be repeated. If the word in the repeat rule\nneeds a comma, leftarrow, or rightarrow, then prepend it with a backslash \u2018 '.\nIf a word in the repeat rule matches \u2018 \\<index>\u2019 then it will be replaced with\nthe <index>-th word in the same repeat specification. There are two forms for\nthe repeat rule: named and short.\n\nA named repeat rule is useful when the same set of repeats must be used\nseveral times in a block. It is specified using <rule1=item1, item2, item3,\u2026,\nitemN>, where N is the number of times the block should be repeated. On each\nrepeat of the block, the entire expression, \u2018<\u2026>\u2019 will be replaced first with\nitem1, and then with item2, and so forth until N repeats are accomplished.\nOnce a named repeat specification has been introduced, the same repeat rule\nmay be used in the current block by referring only to the name (i.e. <rule1>).\n\nA short repeat rule looks like <item1, item2, item3, \u2026, itemN>. The rule\nspecifies that the entire expression, \u2018<\u2026>\u2019 should be replaced first with\nitem1, and then with item2, and so forth until N repeats are accomplished.\n\nThe following predefined named repeat rules are available:\n\nNon-Fortran files use a separate syntax for defining template blocks that\nshould be repeated using a variable expansion similar to the named repeat\nrules of the Fortran-specific repeats.\n\nNumPy Distutils preprocesses C source files (extension: `.c.src`) written in a\ncustom templating language to generate C code. The `@` symbol is used to wrap\nmacro-style variables to empower a string substitution mechanism that might\ndescribe (for instance) a set of data types.\n\nThe template language blocks are delimited by `/**begin repeat` and `/**end\nrepeat**/` lines, which may also be nested using consecutively numbered\ndelimiting lines such as `/**begin repeat1` and `/**end repeat1**/`:\n\nThe above rules may be clearer in the following template source example:\n\nThe preprocessing of generically-typed C source files (whether in NumPy proper\nor in any third party package using NumPy Distutils) is performed by\nconv_template.py. The type-specific C files generated (extension: `.c`) by\nthese modules during the build process are ready to be compiled. This form of\ngeneric typing is also supported for C header files (preprocessed to produce\n`.h` files).\n\nThe header of a typical SciPy `__init__.py` is:\n\nIt is possible to specify config_fc options in setup.py scripts. For example,\nusing\n\nsources=[\u2026], config_fc={\u2018noopt\u2019:(__file__,1)})\n\nwill compile the `library` sources without optimization flags.\n\nIt\u2019s recommended to specify only those config_fc options in such a way that\nare compiler independent.\n\nSome old Fortran codes need special compiler options in order to work\ncorrectly. In order to specify compiler options per source file,\n`numpy.distutils` Fortran compiler looks for the following pattern:\n\nin the first 20 lines of the source and use the `f77flags` for specified type\nof the fcompiler (the first character `C` is optional).\n\nTODO: This feature can be easily extended for Fortran 90 codes as well. Let us\nknow if you would need such a feature.\n\n"}, {"name": "const Tp *data()", "path": "dev/howto-docs#_CPPv4N9DoxyLimbo4dataEv", "type": "Development", "text": "\nReturns the raw data for the limbo.\n\n"}, {"name": "Contributing to NumPy", "path": "dev/index", "type": "Development", "text": "\nNot a coder? Not a problem! NumPy is multi-faceted, and we can use a lot of\nhelp. These are all activities we\u2019d like to get help with (they\u2019re all\nimportant, so we list them in alphabetical order):\n\nThe rest of this document discusses working on the NumPy code base and\ndocumentation. We\u2019re in the process of updating our descriptions of other\nactivities and roles. If you are interested in these other activities, please\ncontact us! You can do this via the numpy-discussion mailing list, or on\nGitHub (open an issue or comment on a relevant issue). These are our preferred\ncommunication channels (open source is open by nature!), however if you prefer\nto discuss in private first, please reach out to our community coordinators at\n`numpy-team@googlegroups.com` or `numpy-team.slack.com` (send an email to\n`numpy-team@googlegroups.com` for an invite the first time).\n\nHere\u2019s the short summary, complete TOC links are below:\n\nIf you are a first-time contributor:\n\nClone the project to your local computer:\n\nChange the directory:\n\nAdd the upstream repository:\n\nNow, `git remote -v` will show two remote repositories named:\n\nDevelop your contribution:\n\nPull the latest changes from upstream:\n\nCreate a branch for the feature you want to work on. Since the branch name\nwill appear in the merge message, use a sensible name such as \u2018linspace-\nspeedups\u2019:\n\nTo submit your contribution:\n\nPush your changes back to your fork on GitHub:\n\nReview process:\n\nDocument changes\n\nBeyond changes to a functions docstring and possible description in the\ngeneral documentation, if your change introduces any user-facing modifications\nthey may need to be mentioned in the release notes. To add your change to the\nrelease notes, you need to create a short file with a summary and place it in\n`doc/release/upcoming_changes`. The file\n`doc/release/upcoming_changes/README.rst` details the format and filename\nconventions.\n\nIf your change introduces a deprecation, make sure to discuss this first on\nGitHub or the mailing list first. If agreement on the deprecation is reached,\nfollow NEP 23 deprecation policy to add the deprecation.\n\nCross referencing issues\n\nIf the PR relates to any issues, you can add the text `xref gh-xxxx` where\n`xxxx` is the number of the issue to github comments. Likewise, if the PR\nsolves an issue, replace the `xref` with `closes`, `fixes` or any of the other\nflavors github accepts.\n\nIn the source code, be sure to preface any issue or PR reference with `gh-\nxxxx`.\n\nFor a more detailed discussion, read on and follow the links at the bottom of\nthis page.\n\nIf GitHub indicates that the branch of your Pull Request can no longer be\nmerged automatically, you have to incorporate changes that have been made\nsince you started into your branch. Our recommended way to do this is to\nrebase on main.\n\nUse the following import conventions:\n\nPull requests (PRs) that modify code should either have new tests, or modify\nexisting tests to fail before the PR and pass afterwards. You should run the\ntests before pushing a PR.\n\nRunning NumPy\u2019s test suite locally requires some additional packages, such as\n`pytest` and `hypothesis`. The additional testing dependencies are listed in\n`test_requirements.txt` in the top-level directory, and can conveniently be\ninstalled with:\n\nTests for a module should ideally cover all code in that module, i.e.,\nstatement coverage should be at 100%.\n\nTo measure the test coverage, install pytest-cov and then run:\n\nThis will create a report in `build/coverage`, which can be viewed with:\n\nTo build docs, run `make` from the `doc` directory. `make help` lists all\ntargets. For example, to build the HTML documentation, you can run:\n\nTo get the appropriate dependencies and other requirements, see Building the\nNumPy API and reference docs.\n\nThe rest of the story\n\nNumPy-specific workflow is in numpy-development-workflow.\n\n"}, {"name": "Convenience Classes", "path": "reference/routines.polynomials.package", "type": "Convenience classes", "text": "\nThe following lists the various constants and methods common to all of the\nclasses representing the various kinds of polynomials. In the following, the\nterm `Poly` represents any one of the convenience classes (e.g. `Polynomial`,\n`Chebyshev`, `Hermite`, etc.) while the lowercase `p` represents an instance\nof a polynomial class.\n\nMethods for creating polynomial instances.\n\nMethods for converting a polynomial instance of one kind to another.\n\n"}, {"name": "Copies and views", "path": "user/basics.copies", "type": "User Guide", "text": "\nWhen operating on NumPy arrays, it is possible to access the internal data\nbuffer directly using a view without copying data around. This ensures good\nperformance but can also cause unwanted problems if the user is not aware of\nhow this works. Hence, it is important to know the difference between these\ntwo terms and to know which operations return copies and which return views.\n\nThe NumPy array is a data structure consisting of two parts: the contiguous\ndata buffer with the actual data elements and the metadata that contains\ninformation about the data buffer. The metadata includes data type, strides,\nand other important information that helps manipulate the `ndarray` easily.\nSee the Internal organization of NumPy arrays section for a detailed look.\n\nIt is possible to access the array differently by just changing certain\nmetadata like stride and dtype without changing the data buffer. This creates\na new way of looking at the data and these new arrays are called views. The\ndata buffer remains the same, so any changes made to a view reflects in the\noriginal copy. A view can be forced through the `ndarray.view` method.\n\nWhen a new array is created by duplicating the data buffer as well as the\nmetadata, it is called a copy. Changes made to the copy do not reflect on the\noriginal array. Making a copy is slower and memory-consuming but sometimes\nnecessary. A copy can be forced by using `ndarray.copy`.\n\nSee also\n\nIndexing on ndarrays\n\nViews are created when elements can be addressed with offsets and strides in\nthe original array. Hence, basic indexing always creates views. For example:\n\nHere, `y` gets changed when `x` is changed because it is a view.\n\nAdvanced indexing, on the other hand, always creates copies. For example:\n\nHere, `y` is a copy, as signified by the `base` attribute. We can also confirm\nthis by assigning new values to `x[[1, 2]]` which in turn will not affect `y`\nat all:\n\nIt must be noted here that during the assignment of `x[[1, 2]]` no view or\ncopy is created as the assignment happens in-place.\n\nThe `numpy.reshape` function creates a view where possible or a copy\notherwise. In most cases, the strides can be modified to reshape the array\nwith a view. However, in some cases where the array becomes non-contiguous\n(perhaps after a `ndarray.transpose` operation), the reshaping cannot be done\nby modifying strides and requires a copy. In these cases, we can raise an\nerror by assigning the new shape to the shape attribute of the array. For\nexample:\n\nTaking the example of another operation, `ravel` returns a contiguous\nflattened view of the array wherever possible. On the other hand,\n`ndarray.flatten` always returns a flattened copy of the array. However, to\nguarantee a view in most cases, `x.reshape(-1)` may be preferable.\n\nThe `base` attribute of the ndarray makes it easy to tell if an array is a\nview or a copy. The base attribute of a view returns the original array while\nit returns `None` for a copy.\n\nNote that the `base` attribute should not be used to determine if an ndarray\nobject is new; only if it is a view or a copy of another ndarray.\n\n"}, {"name": "core.defchararray.array()", "path": "reference/generated/numpy.core.defchararray.array", "type": "numpy.core.defchararray.array", "text": "\nCreate a `chararray`.\n\nNote\n\nThis class is provided for numarray backward-compatibility. New code (not\nconcerned with numarray compatibility) should use arrays of type `string_` or\n`unicode_` and use the free functions in `numpy.char` for fast vectorized\nstring operations instead.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nIf true (default), then the object is copied. Otherwise, a copy will only be\nmade if __array__ returns a copy, if obj is a nested sequence, or if a copy is\nneeded to satisfy any of the other requirements (`itemsize`, unicode, `order`,\netc.).\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest). If order is \u2018A\u2019, then the returned array may be in any\norder (either C-, Fortran-contiguous, or even discontiguous).\n\n"}, {"name": "core.defchararray.asarray()", "path": "reference/generated/numpy.core.defchararray.asarray", "type": "numpy.core.defchararray.asarray", "text": "\nConvert the input to a `chararray`, copying the data only if necessary.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest).\n\n"}, {"name": "core.records.array()", "path": "reference/generated/numpy.core.records.array", "type": "numpy.core.records.array", "text": "\nConstruct a record array from a wide-variety of objects.\n\nA general-purpose record array constructor that dispatches to the appropriate\n`recarray` creation function based on the inputs (see Notes).\n\nInput object. See Notes for details on how various input types are treated.\n\nValid dtype for array.\n\nShape of each array.\n\nPosition in the file or buffer to start reading from.\n\nBuffer (`buf`) is interpreted according to these strides (strides define how\nmany bytes each array element, row, column, etc. occupy in memory).\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nWhether to copy the input object (True), or to use a reference instead. This\noption only applies when the input is an ndarray or recarray. Defaults to\nTrue.\n\nRecord array created from the specified object.\n\nIf `obj` is `None`, then call the `recarray` constructor. If `obj` is a\nstring, then call the `fromstring` constructor. If `obj` is a list or a tuple,\nthen if the first object is an `ndarray`, call `fromarrays`, otherwise call\n`fromrecords`. If `obj` is a `recarray`, then make a copy of the data in the\nrecarray (if `copy=True`) and use the new formats, names, and titles. If `obj`\nis a file, then call `fromfile`. Finally, if obj is an `ndarray`, then return\n`obj.view(recarray)`, making a copy of the data if `copy=True`.\n\n"}, {"name": "core.records.fromarrays()", "path": "reference/generated/numpy.core.records.fromarrays", "type": "numpy.core.records.fromarrays", "text": "\nCreate a record array from a (flat) list of arrays\n\nList of array-like objects (such as lists, tuples, and ndarrays).\n\nvalid dtype for all arrays\n\nShape of the resulting array. If not provided, inferred from `arrayList[0]`.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nRecord array consisting of given arrayList columns.\n\n"}, {"name": "core.records.fromfile()", "path": "reference/generated/numpy.core.records.fromfile", "type": "numpy.core.records.fromfile", "text": "\nCreate an array from binary file data\n\nIf file is a string or a path-like object then that file is opened, else it is\nassumed to be a file object. The file object must support random access (i.e.\nit must have tell and seek methods).\n\nvalid dtype for all arrays\n\nshape of each array.\n\nPosition in the file to start reading from.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation\n\nrecord array consisting of data enclosed in file.\n\n"}, {"name": "core.records.fromrecords()", "path": "reference/generated/numpy.core.records.fromrecords", "type": "numpy.core.records.fromrecords", "text": "\nCreate a recarray from a list of records in text form.\n\ndata in the same field may be heterogeneous - they will be promoted to the\nhighest data type.\n\nvalid dtype for all arrays\n\nshape of each array.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nIf both `formats` and `dtype` are None, then this will auto-detect formats.\nUse list of tuples rather than list of lists for faster processing.\n\nrecord array consisting of given recList rows.\n\n"}, {"name": "core.records.fromstring()", "path": "reference/generated/numpy.core.records.fromstring", "type": "numpy.core.records.fromstring", "text": "\nCreate a record array from binary data\n\nNote that despite the name of this function it does not accept `str`\ninstances.\n\nBuffer of binary data\n\nValid dtype for all arrays\n\nShape of each array.\n\nPosition in the buffer to start reading from.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nRecord array view into the data in datastring. This will be readonly if\n`datastring` is readonly.\n\nSee also\n\n"}, {"name": "CT", "path": "reference/routines.fft", "type": "Discrete Fourier Transform ( \n      \n       numpy.fft\n      \n      )", "text": "\nThe SciPy module `scipy.fft` is a more comprehensive superset of `numpy.fft`,\nwhich includes only a basic set of routines.\n\n`fft`(a[, n, axis, norm])\n\nCompute the one-dimensional discrete Fourier Transform.\n\n`ifft`(a[, n, axis, norm])\n\nCompute the one-dimensional inverse discrete Fourier Transform.\n\n`fft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional discrete Fourier Transform.\n\n`ifft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional inverse discrete Fourier Transform.\n\n`fftn`(a[, s, axes, norm])\n\nCompute the N-dimensional discrete Fourier Transform.\n\n`ifftn`(a[, s, axes, norm])\n\nCompute the N-dimensional inverse discrete Fourier Transform.\n\n`rfft`(a[, n, axis, norm])\n\nCompute the one-dimensional discrete Fourier Transform for real input.\n\n`irfft`(a[, n, axis, norm])\n\nComputes the inverse of `rfft`.\n\n`rfft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional FFT of a real array.\n\n`irfft2`(a[, s, axes, norm])\n\nComputes the inverse of `rfft2`.\n\n`rfftn`(a[, s, axes, norm])\n\nCompute the N-dimensional discrete Fourier Transform for real input.\n\n`irfftn`(a[, s, axes, norm])\n\nComputes the inverse of `rfftn`.\n\n`hfft`(a[, n, axis, norm])\n\nCompute the FFT of a signal that has Hermitian symmetry, i.e., a real\nspectrum.\n\n`ihfft`(a[, n, axis, norm])\n\nCompute the inverse FFT of a signal that has Hermitian symmetry.\n\n`fftfreq`(n[, d])\n\nReturn the Discrete Fourier Transform sample frequencies.\n\n`rfftfreq`(n[, d])\n\nReturn the Discrete Fourier Transform sample frequencies (for usage with rfft,\nirfft).\n\n`fftshift`(x[, axes])\n\nShift the zero-frequency component to the center of the spectrum.\n\n`ifftshift`(x[, axes])\n\nThe inverse of `fftshift`.\n\nFourier analysis is fundamentally a method for expressing a function as a sum\nof periodic components, and for recovering the function from those components.\nWhen both the function and its Fourier transform are replaced with discretized\ncounterparts, it is called the discrete Fourier transform (DFT). The DFT has\nbecome a mainstay of numerical computing in part because of a very fast\nalgorithm for computing it, called the Fast Fourier Transform (FFT), which was\nknown to Gauss (1805) and was brought to light in its current form by Cooley\nand Tukey [CT]. Press et al. [NR] provide an accessible introduction to\nFourier analysis and its applications.\n\nBecause the discrete Fourier transform separates its input into components\nthat contribute at discrete frequencies, it has a great number of applications\nin digital signal processing, e.g., for filtering, and in this context the\ndiscretized input to the transform is customarily referred to as a signal,\nwhich exists in the time domain. The output is called a spectrum or transform\nand exists in the frequency domain.\n\nThere are many ways to define the DFT, varying in the sign of the exponent,\nnormalization, etc. In this implementation, the DFT is defined as\n\nThe DFT is in general defined for complex inputs and outputs, and a single-\nfrequency component at linear frequency \\\\(f\\\\) is represented by a complex\nexponential \\\\(a_m = \\exp\\\\{2\\pi i\\,f m\\Delta t\\\\}\\\\), where \\\\(\\Delta t\\\\) is\nthe sampling interval.\n\nThe values in the result follow so-called \u201cstandard\u201d order: If `A = fft(a,\nn)`, then `A[0]` contains the zero-frequency term (the sum of the signal),\nwhich is always purely real for real inputs. Then `A[1:n/2]` contains the\npositive-frequency terms, and `A[n/2+1:]` contains the negative-frequency\nterms, in order of decreasingly negative frequency. For an even number of\ninput points, `A[n/2]` represents both positive and negative Nyquist\nfrequency, and is also purely real for real input. For an odd number of input\npoints, `A[(n-1)/2]` contains the largest positive frequency, while\n`A[(n+1)/2]` contains the largest negative frequency. The routine\n`np.fft.fftfreq(n)` returns an array giving the frequencies of corresponding\nelements in the output. The routine `np.fft.fftshift(A)` shifts transforms and\ntheir frequencies to put the zero-frequency components in the middle, and\n`np.fft.ifftshift(A)` undoes that shift.\n\nWhen the input `a` is a time-domain signal and `A = fft(a)`, `np.abs(A)` is\nits amplitude spectrum and `np.abs(A)**2` is its power spectrum. The phase\nspectrum is obtained by `np.angle(A)`.\n\nThe inverse DFT is defined as\n\nIt differs from the forward transform by the sign of the exponential argument\nand the default normalization by \\\\(1/n\\\\).\n\n`numpy.fft` promotes `float32` and `complex64` arrays to `float64` and\n`complex128` arrays respectively. For an FFT implementation that does not\npromote input arrays, see `scipy.fftpack`.\n\nThe argument `norm` indicates which direction of the pair of direct/inverse\ntransforms is scaled and with what normalization factor. The default\nnormalization (`\"backward\"`) has the direct (forward) transforms unscaled and\nthe inverse (backward) transforms scaled by \\\\(1/n\\\\). It is possible to\nobtain unitary transforms by setting the keyword argument `norm` to `\"ortho\"`\nso that both direct and inverse transforms are scaled by \\\\(1/\\sqrt{n}\\\\).\nFinally, setting the keyword argument `norm` to `\"forward\"` has the direct\ntransforms scaled by \\\\(1/n\\\\) and the inverse transforms unscaled (i.e.\nexactly opposite to the default `\"backward\"`). `None` is an alias of the\ndefault option `\"backward\"` for backward compatibility.\n\nWhen the input is purely real, its transform is Hermitian, i.e., the component\nat frequency \\\\(f_k\\\\) is the complex conjugate of the component at frequency\n\\\\(-f_k\\\\), which means that for real inputs there is no information in the\nnegative frequency components that is not already available from the positive\nfrequency components. The family of `rfft` functions is designed to operate on\nreal inputs, and exploits this symmetry by computing only the positive\nfrequency components, up to and including the Nyquist frequency. Thus, `n`\ninput points produce `n/2+1` complex output points. The inverses of this\nfamily assumes the same symmetry of its input, and for an output of `n` points\nuses `n/2+1` input points.\n\nCorrespondingly, when the spectrum is purely real, the signal is Hermitian.\nThe `hfft` family of functions exploits this symmetry by using `n/2+1` complex\npoints in the input (time) domain for `n` real points in the frequency domain.\n\nIn higher dimensions, FFTs are used, e.g., for image analysis and filtering.\nThe computational efficiency of the FFT means that it can also be a faster way\nto compute large convolutions, using the property that a convolution in the\ntime domain is equivalent to a point-by-point multiplication in the frequency\ndomain.\n\nIn two dimensions, the DFT is defined as\n\nwhich extends in the obvious way to higher dimensions, and the inverses in\nhigher dimensions also extend in the same way.\n\nCooley, James W., and John W. Tukey, 1965, \u201cAn algorithm for the machine\ncalculation of complex Fourier series,\u201d Math. Comput. 19: 297-301.\n\nPress, W., Teukolsky, S., Vetterline, W.T., and Flannery, B.P., 2007,\nNumerical Recipes: The Art of Scientific Computing, ch. 12-13. Cambridge Univ.\nPress, Cambridge, UK.\n\nFor examples, see the various functions.\n\n"}, {"name": "Data type routines", "path": "reference/routines.dtype", "type": "Data type routines", "text": "\n`can_cast`(from_, to[, casting])\n\nReturns True if cast between data types can occur according to the casting\nrule.\n\n`promote_types`(type1, type2)\n\nReturns the data type with the smallest size and smallest scalar kind to which\nboth `type1` and `type2` may be safely cast.\n\n`min_scalar_type`(a, /)\n\nFor scalar `a`, returns the data type with the smallest size and smallest\nscalar kind which can hold its value.\n\n`result_type`(*arrays_and_dtypes)\n\nReturns the type that results from applying the NumPy type promotion rules to\nthe arguments.\n\n`common_type`(*arrays)\n\nReturn a scalar type which is common to the input arrays.\n\n`obj2sctype`(rep[, default])\n\nReturn the scalar dtype or NumPy equivalent of Python type of an object.\n\n`dtype`(dtype[, align, copy])\n\nCreate a data type object.\n\n`format_parser`(formats, names, titles[, ...])\n\nClass to convert formats, names, titles description to a dtype.\n\n`finfo`(dtype)\n\nMachine limits for floating point types.\n\n`iinfo`(type)\n\nMachine limits for integer types.\n\n`MachAr`([float_conv, int_conv, ...])\n\nDiagnosing machine parameters.\n\n`issctype`(rep)\n\nDetermines whether the given object represents a scalar data-type.\n\n`issubdtype`(arg1, arg2)\n\nReturns True if first argument is a typecode lower/equal in type hierarchy.\n\n`issubsctype`(arg1, arg2)\n\nDetermine if the first argument is a subclass of the second argument.\n\n`issubclass_`(arg1, arg2)\n\nDetermine if a class is a subclass of a second class.\n\n`find_common_type`(array_types, scalar_types)\n\nDetermine common type following standard coercion rules.\n\n`typename`(char)\n\nReturn a description for the given data type code.\n\n`sctype2char`(sctype)\n\nReturn the string representation of a scalar dtype.\n\n`mintypecode`(typechars[, typeset, default])\n\nReturn the character for the minimum-size type to which given types can be\nsafely cast.\n\n`maximum_sctype`(t)\n\nReturn the scalar type of highest precision of the same kind as the input.\n\n"}, {"name": "Data types", "path": "user/basics.types", "type": "User Guide", "text": "\nSee also\n\nData type objects\n\nNumPy supports a much greater variety of numerical types than Python does.\nThis section shows which are available, and how to modify an array\u2019s data-\ntype.\n\nThe primitive types supported are tied closely to those in C:\n\nNumpy type\n\nC type\n\nDescription\n\n`numpy.bool_`\n\n`bool`\n\nBoolean (True or False) stored as a byte\n\n`numpy.byte`\n\n`signed char`\n\nPlatform-defined\n\n`numpy.ubyte`\n\n`unsigned char`\n\nPlatform-defined\n\n`numpy.short`\n\n`short`\n\nPlatform-defined\n\n`numpy.ushort`\n\n`unsigned short`\n\nPlatform-defined\n\n`numpy.intc`\n\n`int`\n\nPlatform-defined\n\n`numpy.uintc`\n\n`unsigned int`\n\nPlatform-defined\n\n`numpy.int_`\n\n`long`\n\nPlatform-defined\n\n`numpy.uint`\n\n`unsigned long`\n\nPlatform-defined\n\n`numpy.longlong`\n\n`long long`\n\nPlatform-defined\n\n`numpy.ulonglong`\n\n`unsigned long long`\n\nPlatform-defined\n\n`numpy.half` / `numpy.float16`\n\nHalf precision float: sign bit, 5 bits exponent, 10 bits mantissa\n\n`numpy.single`\n\n`float`\n\nPlatform-defined single precision float: typically sign bit, 8 bits exponent,\n23 bits mantissa\n\n`numpy.double`\n\n`double`\n\nPlatform-defined double precision float: typically sign bit, 11 bits exponent,\n52 bits mantissa.\n\n`numpy.longdouble`\n\n`long double`\n\nPlatform-defined extended-precision float\n\n`numpy.csingle`\n\n`float complex`\n\nComplex number, represented by two single-precision floats (real and imaginary\ncomponents)\n\n`numpy.cdouble`\n\n`double complex`\n\nComplex number, represented by two double-precision floats (real and imaginary\ncomponents).\n\n`numpy.clongdouble`\n\n`long double complex`\n\nComplex number, represented by two extended-precision floats (real and\nimaginary components).\n\nSince many of these have platform-dependent definitions, a set of fixed-size\naliases are provided (See Sized aliases).\n\nNumPy numerical types are instances of `dtype` (data-type) objects, each\nhaving unique characteristics. Once you have imported NumPy using\n\nthe dtypes are available as `np.bool_`, `np.float32`, etc.\n\nAdvanced types, not listed above, are explored in section Structured arrays.\n\nThere are 5 basic numerical types representing booleans (bool), integers\n(int), unsigned integers (uint) floating point (float) and complex. Those with\nnumbers in their name indicate the bitsize of the type (i.e. how many bits are\nneeded to represent a single value in memory). Some types, such as `int` and\n`intp`, have differing bitsizes, dependent on the platforms (e.g. 32-bit vs.\n64-bit machines). This should be taken into account when interfacing with low-\nlevel code (such as C or Fortran) where the raw memory is addressed.\n\nData-types can be used as functions to convert python numbers to array scalars\n(see the array scalar section for an explanation), python sequences of numbers\nto arrays of that type, or as arguments to the dtype keyword that many numpy\nfunctions or methods accept. Some examples:\n\nArray types can also be referred to by character codes, mostly to retain\nbackward compatibility with older packages such as Numeric. Some documentation\nmay still refer to these, for example:\n\nWe recommend using dtype objects instead.\n\nTo convert the type of an array, use the .astype() method (preferred) or the\ntype itself as a function. For example:\n\nNote that, above, we use the Python float object as a dtype. NumPy knows that\n`int` refers to `np.int_`, `bool` means `np.bool_`, that `float` is\n`np.float_` and `complex` is `np.complex_`. The other data-types do not have\nPython equivalents.\n\nTo determine the type of an array, look at the dtype attribute:\n\ndtype objects also contain information about the type, such as its bit-width\nand its byte-order. The data type can also be used indirectly to query\nproperties of the type, such as whether it is an integer:\n\nNumPy generally returns elements of arrays as array scalars (a scalar with an\nassociated dtype). Array scalars differ from Python scalars, but for the most\npart they can be used interchangeably (the primary exception is for versions\nof Python older than v2.x, where integer array scalars cannot act as indices\nfor lists and tuples). There are some exceptions, such as when code requires\nvery specific attributes of a scalar or when it checks specifically whether a\nvalue is a Python scalar. Generally, problems are easily fixed by explicitly\nconverting array scalars to Python scalars, using the corresponding Python\ntype function (e.g., `int`, `float`, `complex`, `str`, `unicode`).\n\nThe primary advantage of using array scalars is that they preserve the array\ntype (Python may not have a matching scalar type available, e.g. `int16`).\nTherefore, the use of array scalars ensures identical behaviour between arrays\nand scalars, irrespective of whether the value is inside an array or not.\nNumPy scalars also have many of the same methods arrays do.\n\nThe fixed size of NumPy numeric types may cause overflow errors when a value\nrequires more memory than available in the data type. For example,\n`numpy.power` evaluates `100 ** 8` correctly for 64-bit integers, but gives\n1874919424 (incorrect) for a 32-bit integer.\n\nThe behaviour of NumPy and Python integer types differs significantly for\ninteger overflows and may confuse users expecting NumPy integers to behave\nsimilar to Python\u2019s `int`. Unlike NumPy, the size of Python\u2019s `int` is\nflexible. This means Python integers may expand to accommodate any integer and\nwill not overflow.\n\nNumPy provides `numpy.iinfo` and `numpy.finfo` to verify the minimum or\nmaximum values of NumPy integer and floating point values respectively\n\nIf 64-bit integers are still too small the result may be cast to a floating\npoint number. Floating point numbers offer a larger, but inexact, range of\npossible values.\n\nPython\u2019s floating-point numbers are usually 64-bit floating-point numbers,\nnearly equivalent to `np.float64`. In some unusual situations it may be useful\nto use floating-point numbers with more precision. Whether this is possible in\nnumpy depends on the hardware and on the development environment:\nspecifically, x86 machines provide hardware floating-point with 80-bit\nprecision, and while most C compilers provide this as their `long double`\ntype, MSVC (standard for Windows builds) makes `long double` identical to\n`double` (64 bits). NumPy makes the compiler\u2019s `long double` available as\n`np.longdouble` (and `np.clongdouble` for the complex numbers). You can find\nout what your numpy provides with `np.finfo(np.longdouble)`.\n\nNumPy does not provide a dtype with more precision than C\u2019s `long double`\\; in\nparticular, the 128-bit IEEE quad precision data type (FORTRAN\u2019s `REAL*16`\\\\)\nis not available.\n\nFor efficient memory alignment, `np.longdouble` is usually stored padded with\nzero bits, either to 96 or 128 bits. Which is more efficient depends on\nhardware and development environment; typically on 32-bit systems they are\npadded to 96 bits, while on 64-bit systems they are typically padded to 128\nbits. `np.longdouble` is padded to the system default; `np.float96` and\n`np.float128` are provided for users who want specific padding. In spite of\nthe names, `np.float96` and `np.float128` provide only as much precision as\n`np.longdouble`, that is, 80 bits on most x86 machines and 64 bits in standard\nWindows builds.\n\nBe warned that even if `np.longdouble` offers more precision than python\n`float`, it is easy to lose that extra precision, since python often forces\nvalues to pass through `float`. For example, the `%` formatting operator\nrequires its arguments to be converted to standard python types, and it is\ntherefore impossible to preserve extended precision even if many decimal\nplaces are requested. It can be useful to test your code with the value `1 +\nnp.finfo(np.longdouble).eps`.\n\n"}, {"name": "DataSource.abspath()", "path": "reference/generated/numpy.datasource.abspath", "type": "numpy.DataSource.abspath", "text": "\nmethod\n\nReturn absolute path of file in the DataSource directory.\n\nIf `path` is an URL, then `abspath` will return either the location the file\nexists locally or the location it would exist when opened using the `open`\nmethod.\n\nCan be a local file or a remote URL.\n\nComplete path, including the `DataSource` destination directory.\n\nThe functionality is based on `os.path.abspath`.\n\n"}, {"name": "DataSource.exists()", "path": "reference/generated/numpy.datasource.exists", "type": "numpy.DataSource.exists", "text": "\nmethod\n\nTest if path exists.\n\nTest if `path` exists as (and in this order):\n\nCan be a local file or a remote URL.\n\nTrue if `path` exists.\n\nWhen `path` is an URL, `exists` will return True if it\u2019s either stored locally\nin the `DataSource` directory, or is a valid remote URL. `DataSource` does not\ndiscriminate between the two, the file is accessible if it exists in either\nlocation.\n\n"}, {"name": "DataSource.open()", "path": "reference/generated/numpy.datasource.open", "type": "numpy.DataSource.open", "text": "\nmethod\n\nOpen and return file-like object.\n\nIf `path` is an URL, it will be downloaded, stored in the `DataSource`\ndirectory and opened from there.\n\nLocal file path or URL to open.\n\nMode to open `path`. Mode \u2018r\u2019 for reading, \u2018w\u2019 for writing, \u2018a\u2019 to append.\nAvailable modes depend on the type of object specified by `path`. Default is\n\u2018r\u2019.\n\nOpen text file with given encoding. The default encoding will be what\n`io.open` uses.\n\nNewline to use when reading text file.\n\nFile object.\n\n"}, {"name": "Datetime Support Functions", "path": "reference/routines.datetime", "type": "Datetime Support Functions", "text": "\n`datetime_as_string`(arr[, unit, timezone, ...])\n\nConvert an array of datetimes into an array of strings.\n\n`datetime_data`(dtype, /)\n\nGet information about the step size of a date or time type.\n\n`busdaycalendar`([weekmask, holidays])\n\nA business day calendar object that efficiently stores information defining\nvalid days for the busday family of functions.\n\n`is_busday`(dates[, weekmask, holidays, ...])\n\nCalculates which of the given dates are valid days, and which are not.\n\n`busday_offset`(dates, offsets[, roll, ...])\n\nFirst adjusts the date to fall on a valid day according to the `roll` rule,\nthen applies offsets to the given dates counted in valid days.\n\n`busday_count`(begindates, enddates[, ...])\n\nCounts the number of valid days between `begindates` and `enddates`, not\nincluding the day of `enddates`.\n\n"}, {"name": "Datetimes and Timedeltas", "path": "reference/arrays.datetime", "type": "Datetimes and Timedeltas", "text": "\nNew in version 1.7.0.\n\nStarting in NumPy 1.7, there are core array data types which natively support\ndatetime functionality. The data type is called \u201cdatetime64\u201d, so named because\n\u201cdatetime\u201d is already taken by the datetime library included in Python.\n\nThe most basic way to create datetimes is from strings in ISO 8601 date or\ndatetime format. It is also possible to create datetimes from an integer by\noffset relative to the Unix epoch (00:00:00 UTC on 1 January 1970). The unit\nfor internal storage is automatically selected from the form of the string,\nand can be either a date unit or a time unit. The date units are years (\u2018Y\u2019),\nmonths (\u2018M\u2019), weeks (\u2018W\u2019), and days (\u2018D\u2019), while the time units are hours\n(\u2018h\u2019), minutes (\u2018m\u2019), seconds (\u2018s\u2019), milliseconds (\u2018ms\u2019), and some additional\nSI-prefix seconds-based units. The datetime64 data type also accepts the\nstring \u201cNAT\u201d, in any combination of lowercase/uppercase letters, for a \u201cNot A\nTime\u201d value.\n\nA simple ISO date:\n\nFrom an integer and a date unit, 1 year since the UNIX epoch:\n\nUsing months for the unit:\n\nSpecifying just the month, but forcing a \u2018days\u2019 unit:\n\nFrom a date and time:\n\nNAT (not a time):\n\nWhen creating an array of datetimes from a string, it is still possible to\nautomatically select the unit from the inputs, by using the datetime type with\ngeneric units.\n\nAn array of datetimes can be constructed from integers representing POSIX\ntimestamps with the given unit.\n\nThe datetime type works with many common NumPy functions, for example `arange`\ncan be used to generate ranges of dates.\n\nAll the dates for one month:\n\nThe datetime object represents a single moment in time. If two datetimes have\ndifferent units, they may still be representing the same moment of time, and\nconverting from a bigger unit like months to a smaller unit like days is\nconsidered a \u2018safe\u2019 cast because the moment of time is still being represented\nexactly.\n\nDeprecated since version 1.11.0: NumPy does not store timezone information.\nFor backwards compatibility, datetime64 still parses timezone offsets, which\nit handles by converting to UTC. This behaviour is deprecated and will raise\nan error in the future.\n\nNumPy allows the subtraction of two Datetime values, an operation which\nproduces a number with a time unit. Because NumPy doesn\u2019t have a physical\nquantities system in its core, the timedelta64 data type was created to\ncomplement datetime64. The arguments for timedelta64 are a number, to\nrepresent the number of units, and a date/time unit, such as (D)ay, (M)onth,\n(Y)ear, (h)ours, (m)inutes, or (s)econds. The timedelta64 data type also\naccepts the string \u201cNAT\u201d in place of the number for a \u201cNot A Time\u201d value.\n\nDatetimes and Timedeltas work together to provide ways for simple datetime\ncalculations.\n\nThere are two Timedelta units (\u2018Y\u2019, years and \u2018M\u2019, months) which are treated\nspecially, because how much time they represent changes depending on when they\nare used. While a timedelta day unit is equivalent to 24 hours, there is no\nway to convert a month unit into days, because different months have different\nnumbers of days.\n\nThe Datetime and Timedelta data types support a large number of time units, as\nwell as generic units which can be coerced into any of the other units based\non input data.\n\nDatetimes are always stored based on POSIX time (though having a TAI mode\nwhich allows for accounting of leap-seconds is proposed), with an epoch of\n1970-01-01T00:00Z. This means the supported dates are always a symmetric\ninterval around the epoch, called \u201ctime span\u201d in the table below.\n\nThe length of the span is the range of a 64-bit integer times the length of\nthe date or unit. For example, the time span for \u2018W\u2019 (week) is exactly 7 times\nlonger than the time span for \u2018D\u2019 (day), and the time span for \u2018D\u2019 (day) is\nexactly 24 times longer than the time span for \u2018h\u2019 (hour).\n\nHere are the date units:\n\nCode\n\nMeaning\n\nTime span (relative)\n\nTime span (absolute)\n\nY\n\nyear\n\n+/- 9.2e18 years\n\n[9.2e18 BC, 9.2e18 AD]\n\nM\n\nmonth\n\n+/- 7.6e17 years\n\n[7.6e17 BC, 7.6e17 AD]\n\nW\n\nweek\n\n+/- 1.7e17 years\n\n[1.7e17 BC, 1.7e17 AD]\n\nD\n\nday\n\n+/- 2.5e16 years\n\n[2.5e16 BC, 2.5e16 AD]\n\nAnd here are the time units:\n\nCode\n\nMeaning\n\nTime span (relative)\n\nTime span (absolute)\n\nh\n\nhour\n\n+/- 1.0e15 years\n\n[1.0e15 BC, 1.0e15 AD]\n\nm\n\nminute\n\n+/- 1.7e13 years\n\n[1.7e13 BC, 1.7e13 AD]\n\ns\n\nsecond\n\n+/- 2.9e11 years\n\n[2.9e11 BC, 2.9e11 AD]\n\nms\n\nmillisecond\n\n+/- 2.9e8 years\n\n[ 2.9e8 BC, 2.9e8 AD]\n\nus / \u03bcs\n\nmicrosecond\n\n+/- 2.9e5 years\n\n[290301 BC, 294241 AD]\n\nns\n\nnanosecond\n\n+/- 292 years\n\n[ 1678 AD, 2262 AD]\n\nps\n\npicosecond\n\n+/- 106 days\n\n[ 1969 AD, 1970 AD]\n\nfs\n\nfemtosecond\n\n+/- 2.6 hours\n\n[ 1969 AD, 1970 AD]\n\nas\n\nattosecond\n\n+/- 9.2 seconds\n\n[ 1969 AD, 1970 AD]\n\nTo allow the datetime to be used in contexts where only certain days of the\nweek are valid, NumPy includes a set of \u201cbusday\u201d (business day) functions.\n\nThe default for busday functions is that the only valid days are Monday\nthrough Friday (the usual business days). The implementation is based on a\n\u201cweekmask\u201d containing 7 Boolean flags to indicate valid days; custom weekmasks\nare possible that specify other sets of valid days.\n\nThe \u201cbusday\u201d functions can additionally check a list of \u201choliday\u201d dates,\nspecific dates that are not valid days.\n\nThe function `busday_offset` allows you to apply offsets specified in business\ndays to datetimes with a unit of \u2018D\u2019 (day).\n\nWhen an input date falls on the weekend or a holiday, `busday_offset` first\napplies a rule to roll the date to a valid business day, then applies the\noffset. The default rule is \u2018raise\u2019, which simply raises an exception. The\nrules most typically used are \u2018forward\u2019 and \u2018backward\u2019.\n\nIn some cases, an appropriate use of the roll and the offset is necessary to\nget a desired answer.\n\nThe first business day on or after a date:\n\nThe first business day strictly after a date:\n\nThe function is also useful for computing some kinds of days like holidays. In\nCanada and the U.S., Mother\u2019s day is on the second Sunday in May, which can be\ncomputed with a custom weekmask.\n\nWhen performance is important for manipulating many business dates with one\nparticular choice of weekmask and holidays, there is an object\n`busdaycalendar` which stores the data necessary in an optimized form.\n\nTo test a datetime64 value to see if it is a valid day, use `is_busday`.\n\nTo find how many valid days there are in a specified range of datetime64\ndates, use `busday_count`:\n\nIf you have an array of datetime64 day values, and you want a count of how\nmany of them are valid dates, you can do this:\n\nHere are several examples of custom weekmask values. These examples specify\nthe \u201cbusday\u201d default of Monday through Friday being valid days.\n\nSome examples:\n\n"}, {"name": "deletechars", "path": "user/basics.io.genfromtxt", "type": "User Guide", "text": "\nNumPy provides several functions to create arrays from tabular data. We focus\nhere on the `genfromtxt` function.\n\nIn a nutshell, `genfromtxt` runs two main loops. The first loop converts each\nline of the file in a sequence of strings. The second loop converts each\nstring to the appropriate data type. This mechanism is slower than a single\nloop, but gives more flexibility. In particular, `genfromtxt` is able to take\nmissing data into account, when other faster and simpler functions like\n`loadtxt` cannot.\n\nNote\n\nWhen giving examples, we will use the following conventions:\n\nThe only mandatory argument of `genfromtxt` is the source of the data. It can\nbe a string, a list of strings, a generator or an open file-like object with a\n`read` method, for example, a file or `io.StringIO` object. If a single string\nis provided, it is assumed to be the name of a local or remote file. If a list\nof strings or a generator returning strings is provided, each string is\ntreated as one line in a file. When the URL of a remote file is passed, the\nfile is automatically downloaded to the current directory and opened.\n\nRecognized file types are text files and archives. Currently, the function\nrecognizes `gzip` and `bz2` (`bzip2`) archives. The type of the archive is\ndetermined from the extension of the file: if the filename ends with `'.gz'`,\na `gzip` archive is expected; if it ends with `'bz2'`, a `bzip2` archive is\nassumed.\n\nOnce the file is defined and open for reading, `genfromtxt` splits each non-\nempty line into a sequence of strings. Empty or commented lines are just\nskipped. The `delimiter` keyword is used to define how the splitting should\ntake place.\n\nQuite often, a single character marks the separation between columns. For\nexample, comma-separated files (CSV) use a comma (`,`) or a semicolon (`;`) as\ndelimiter:\n\nAnother common separator is `\"\\t\"`, the tabulation character. However, we are\nnot limited to a single character, any string will do. By default,\n`genfromtxt` assumes `delimiter=None`, meaning that the line is split along\nwhite spaces (including tabs) and that consecutive white spaces are considered\nas a single white space.\n\nAlternatively, we may be dealing with a fixed-width file, where columns are\ndefined as a given number of characters. In that case, we need to set\n`delimiter` to a single integer (if all the columns have the same size) or to\na sequence of integers (if columns can have different sizes):\n\nBy default, when a line is decomposed into a series of strings, the individual\nentries are not stripped of leading nor trailing white spaces. This behavior\ncan be overwritten by setting the optional argument `autostrip` to a value of\n`True`:\n\nThe optional argument `comments` is used to define a character string that\nmarks the beginning of a comment. By default, `genfromtxt` assumes\n`comments='#'`. The comment marker may occur anywhere on the line. Any\ncharacter present after the comment marker(s) is simply ignored:\n\nNew in version 1.7.0: When `comments` is set to `None`, no lines are treated\nas comments.\n\nNote\n\nThere is one notable exception to this behavior: if the optional argument\n`names=True`, the first commented line will be examined for names.\n\nThe presence of a header in the file can hinder data processing. In that case,\nwe need to use the `skip_header` optional argument. The values of this\nargument must be an integer which corresponds to the number of lines to skip\nat the beginning of the file, before any other action is performed. Similarly,\nwe can skip the last `n` lines of the file by using the `skip_footer`\nattribute and giving it a value of `n`:\n\nBy default, `skip_header=0` and `skip_footer=0`, meaning that no lines are\nskipped.\n\nIn some cases, we are not interested in all the columns of the data but only a\nfew of them. We can select which columns to import with the `usecols`\nargument. This argument accepts a single integer or a sequence of integers\ncorresponding to the indices of the columns to import. Remember that by\nconvention, the first column has an index of 0. Negative integers behave the\nsame as regular Python negative indexes.\n\nFor example, if we want to import only the first and the last columns, we can\nuse `usecols=(0, -1)`:\n\nIf the columns have names, we can also select which columns to import by\ngiving their name to the `usecols` argument, either as a sequence of strings\nor a comma-separated string:\n\nThe main way to control how the sequences of strings we have read from the\nfile are converted to other types is to set the `dtype` argument. Acceptable\nvalues for this argument are:\n\nIn all the cases but the first one, the output will be a 1D array with a\nstructured dtype. This dtype has as many fields as items in the sequence. The\nfield names are defined with the `names` keyword.\n\nWhen `dtype=None`, the type of each column is determined iteratively from its\ndata. We start by checking whether a string can be converted to a boolean\n(that is, if the string matches `true` or `false` in lower cases); then\nwhether it can be converted to an integer, then to a float, then to a complex\nand eventually to a string. This behavior may be changed by modifying the\ndefault mapper of the `StringConverter` class.\n\nThe option `dtype=None` is provided for convenience. However, it is\nsignificantly slower than setting the dtype explicitly.\n\nA natural approach when dealing with tabular data is to allocate a name to\neach column. A first possibility is to use an explicit structured dtype, as\nmentioned previously:\n\nAnother simpler possibility is to use the `names` keyword with a sequence of\nstrings or a comma-separated string:\n\nIn the example above, we used the fact that by default, `dtype=float`. By\ngiving a sequence of names, we are forcing the output to a structured dtype.\n\nWe may sometimes need to define the column names from the data itself. In that\ncase, we must use the `names` keyword with a value of `True`. The names will\nthen be read from the first line (after the `skip_header` ones), even if the\nline is commented out:\n\nThe default value of `names` is `None`. If we give any other value to the\nkeyword, the new names will overwrite the field names we may have defined with\nthe dtype:\n\nIf `names=None` but a structured dtype is expected, names are defined with the\nstandard NumPy default of `\"f%i\"`, yielding names like `f0`, `f1` and so\nforth:\n\nIn the same way, if we don\u2019t give enough names to match the length of the\ndtype, the missing names will be defined with this default template:\n\nWe can overwrite this default with the `defaultfmt` argument, that takes any\nformat string:\n\nNote\n\nWe need to keep in mind that `defaultfmt` is used only if some names are\nexpected but not defined.\n\nNumPy arrays with a structured dtype can also be viewed as `recarray`, where a\nfield can be accessed as if it were an attribute. For that reason, we may need\nto make sure that the field name doesn\u2019t contain any space or invalid\ncharacter, or that it does not correspond to the name of a standard attribute\n(like `size` or `shape`), which would confuse the interpreter. `genfromtxt`\naccepts three optional arguments that provide a finer control on the names:\n\nGives a string combining all the characters that must be deleted from the\nname. By default, invalid characters are `~!@#$%^&*()-=+~\\|]}[{';: /?.>,<`.\n\nGives a list of the names to exclude, such as `return`, `file`, `print`\u2026 If\none of the input name is part of this list, an underscore character (`'_'`)\nwill be appended to it.\n\nWhether the names should be case-sensitive (`case_sensitive=True`), converted\nto upper case (`case_sensitive=False` or `case_sensitive='upper'`) or to lower\ncase (`case_sensitive='lower'`).\n\nUsually, defining a dtype is sufficient to define how the sequence of strings\nmust be converted. However, some additional control may sometimes be required.\nFor example, we may want to make sure that a date in a format `YYYY/MM/DD` is\nconverted to a `datetime` object, or that a string like `xx%` is properly\nconverted to a float between 0 and 1. In such cases, we should define\nconversion functions with the `converters` arguments.\n\nThe value of this argument is typically a dictionary with column indices or\ncolumn names as keys and a conversion functions as values. These conversion\nfunctions can either be actual functions or lambda functions. In any case,\nthey should accept only a string as input and output only a single element of\nthe wanted type.\n\nIn the following example, the second column is converted from as string\nrepresenting a percentage to a float between 0 and 1:\n\nWe need to keep in mind that by default, `dtype=float`. A float is therefore\nexpected for the second column. However, the strings `' 2.3%'` and `' 78.9%'`\ncannot be converted to float and we end up having `np.nan` instead. Let\u2019s now\nuse a converter:\n\nThe same results can be obtained by using the name of the second column\n(`\"p\"`) as key instead of its index (1):\n\nConverters can also be used to provide a default for missing entries. In the\nfollowing example, the converter `convert` transforms a stripped string into\nthe corresponding float or into -999 if the string is empty. We need to\nexplicitly strip the string from white spaces as it is not done by default:\n\nSome entries may be missing in the dataset we are trying to import. In a\nprevious example, we used a converter to transform an empty string into a\nfloat. However, user-defined converters may rapidly become cumbersome to\nmanage.\n\nThe `genfromtxt` function provides two other complementary mechanisms: the\n`missing_values` argument is used to recognize missing data and a second\nargument, `filling_values`, is used to process these missing data.\n\nBy default, any empty string is marked as missing. We can also consider more\ncomplex strings, such as `\"N/A\"` or `\"???\"` to represent missing or invalid\ndata. The `missing_values` argument accepts three kinds of values:\n\nThis string will be used as the marker for missing data for all the columns\n\nIn that case, each item is associated to a column, in order.\n\nValues of the dictionary are strings or sequence of strings. The corresponding\nkeys can be column indices (integers) or column names (strings). In addition,\nthe special key `None` can be used to define a default applicable to all\ncolumns.\n\nWe know how to recognize missing data, but we still need to provide a value\nfor these missing entries. By default, this value is determined from the\nexpected dtype according to this table:\n\nExpected type\n\nDefault\n\n`bool`\n\n`False`\n\n`int`\n\n`-1`\n\n`float`\n\n`np.nan`\n\n`complex`\n\n`np.nan+0j`\n\n`string`\n\n`'???'`\n\nWe can get a finer control on the conversion of missing values with the\n`filling_values` optional argument. Like `missing_values`, this argument\naccepts different kind of values:\n\nThis will be the default for all columns\n\nEach entry will be the default for the corresponding column\n\nEach key can be a column index or a column name, and the corresponding value\nshould be a single object. We can use the special key `None` to define a\ndefault for all columns.\n\nIn the following example, we suppose that the missing values are flagged with\n`\"N/A\"` in the first column and by `\"???\"` in the third column. We wish to\ntransform these missing values to 0 if they occur in the first and second\ncolumn, and to -999 if they occur in the last column:\n\nWe may also want to keep track of the occurrence of missing data by\nconstructing a boolean mask, with `True` entries where data was missing and\n`False` otherwise. To do that, we just have to set the optional argument\n`usemask` to `True` (the default is `False`). The output array will then be a\n`MaskedArray`.\n\nIn addition to `genfromtxt`, the `numpy.lib.npyio` module provides several\nconvenience functions derived from `genfromtxt`. These functions work the same\nway as the original, but they have different default values.\n\nReturns a standard `numpy.recarray` (if `usemask=False`) or a `MaskedRecords`\narray (if `usemaske=True`). The default dtype is `dtype=None`, meaning that\nthe types of each column will be automatically determined.\n\nLike `recfromtxt`, but with a default `delimiter=\",\"`.\n\n"}, {"name": "Development workflow", "path": "dev/development_workflow", "type": "Development", "text": "\nYou already have your own forked copy of the NumPy repository, by following\nCreate a NumPy fork, Make the local copy, you have configured git by following\nGit configuration, and have linked the upstream repository as explained in\nLinking your repository to the upstream repo.\n\nWhat is described below is a recommended workflow with Git.\n\nIn short:\n\nWhen finished:\n\nThis way of working helps to keep work well organized and the history as clear\nas possible.\n\nSee also\n\nThere are many online tutorials to help you learn git. For discussions of\nspecific git workflows, see these discussions on linux git workflow, and\nipython git workflow.\n\nFirst, fetch new commits from the `upstream` repository:\n\nThen, create a new branch based on the main branch of the upstream repository:\n\nOptional: Check which files have changed with `git status` (see git status).\nYou\u2019ll see a listing like this one:\n\nTo commit the staged files into the local copy of your repo, do `git commit`.\nAt this point, a text editor will open up to allow you to write a commit\nmessage. Read the commit message section to be sure that you are writing a\nproperly formatted and sufficiently detailed commit message. After saving your\nmessage and closing the editor, your commit will be saved. For trivial\ncommits, a short commit message can be passed in through the command line\nusing the `-m` flag. For example, `git commit -am \"ENH: Some message\"`.\n\nIn some cases, you will see this form of the commit command: `git commit -a`.\nThe extra `-a` flag automatically commits all modified files and removes all\ndeleted files. This can save you some typing of numerous `git add` commands;\nhowever, it can add unwanted changes to a commit if you\u2019re not careful. For\nmore information, see why the -a flag? \\- and the helpful use-case description\nin the tangled working copy problem.\n\nPush the changes to your forked repo on github:\n\nFor more information, see git push.\n\nNote\n\nAssuming you have followed the instructions in these pages, git will create a\ndefault link to your github repo called `origin`. In git >= 1.7 you can ensure\nthat the link to origin is permanently set by using the `--set-upstream`\noption:\n\nFrom now on git will know that `my-new-feature` is related to the `my-new-\nfeature` branch in your own github repo. Subsequent push calls are then\nsimplified to the following:\n\nYou have to use `--set-upstream` for each new branch that you create.\n\nIt may be the case that while you were working on your edits, new commits have\nbeen added to `upstream` that affect your work. In this case, follow the\nRebasing on main section of this document to apply those changes to your\nbranch.\n\nCommit messages should be clear and follow a few basic rules. Example:\n\nDescribing the motivation for a change, the nature of a bug for bug fixes or\nsome details on what an enhancement does are also good to include in a commit\nmessage. Messages should be understandable without looking at the code\nchanges. A commit message like `MAINT: fixed another one` is an example of\nwhat not to do; the reader has to go look for context elsewhere.\n\nStandard acronyms to start the commit message with are:\n\nIf you plan a new feature or API change, it\u2019s wisest to first email the NumPy\nmailing list asking for comment. If you haven\u2019t heard back in a week, it\u2019s OK\nto ping the list again.\n\nWhen you feel your work is finished, you can create a pull request (PR).\nGithub has a nice help page that outlines the process for filing pull\nrequests.\n\nIf your changes involve modifications to the API or addition/modification of a\nfunction, add a release note to the `doc/release/upcoming_changes/` directory,\nfollowing the instructions and format in the\n`doc/release/upcoming_changes/README.rst` file.\n\nWe review pull requests as soon as we can, typically within a week. If you get\nno review comments within two weeks, feel free to ask for feedback by adding a\ncomment on your PR (this will notify maintainers).\n\nIf your PR is large or complicated, asking for input on the numpy-discussion\nmailing list may also be useful.\n\nThis updates your feature branch with changes from the upstream NumPy github\nrepo. If you do not absolutely need to do this, try to avoid doing it, except\nperhaps when you are finished. The first step will be to update the remote\nrepository with new commits from upstream:\n\nNext, you need to update the feature branch:\n\nIf you have made changes to files that have changed also upstream, this may\ngenerate merge conflicts that you need to resolve. See below for help in this\ncase.\n\nFinally, remove the backup branch upon a successful rebase:\n\nNote\n\nRebasing on main is preferred over merging upstream back to your branch. Using\n`git merge` and `git pull` is discouraged when working on feature branches.\n\nSometimes, you mess up merges or rebases. Luckily, in Git it is relatively\nstraightforward to recover from such mistakes.\n\nIf you mess up during a rebase:\n\nIf you notice you messed up after the rebase:\n\nIf you forgot to make a backup branch:\n\nIf you didn\u2019t actually mess up but there are merge conflicts, you need to\nresolve those. This can be one of the trickier things to get right. For a good\ndescription of how to do this, see this article on merging conflicts.\n\nNote\n\nDo this only for your own feature branches.\n\nThere\u2019s an embarrassing typo in a commit you made? Or perhaps you made several\nfalse starts you would like the posterity not to see.\n\nThis can be done via interactive rebasing.\n\nSuppose that the commit history looks like this:\n\nand `6ad92e5` is the last commit in the `main` branch. Suppose we want to make\nthe following changes:\n\nWe do as follows:\n\nThis will open an editor with the following text in it:\n\nTo achieve what we want, we will make the following changes to it:\n\nThis means that (i) we want to edit the commit message for `13d7934`, and (ii)\ncollapse the last three commits into one. Now we save and quit the editor.\n\nGit will then immediately bring up an editor for editing the commit message.\nAfter revising it, we get the output:\n\nand the history looks now like this:\n\nIf it went wrong, recovery is again possible as explained above.\n\nSee also: https://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-\nbranch-locally-and-remotely\n\nIf you want to work on some stuff with other people, where you are all\ncommitting into the same repository, or even the same branch, then just share\nit via github.\n\nFirst fork NumPy into your account, as from Create a NumPy fork.\n\nThen, go to your forked repository github page, say `https://github.com/your-\nuser-name/numpy`\n\nClick on the \u2018Admin\u2019 button, and add anyone else to the repo as a\ncollaborator:\n\nNow all those people can do:\n\nRemember that links starting with `git@` use the ssh protocol and are read-\nwrite; links starting with `git://` are read-only.\n\nYour collaborators can then commit directly into that repo with the usual:\n\nTo see a graphical representation of the repository branches and commits:\n\nTo see a linear list of commits for this branch:\n\nYou can also look at the network graph visualizer for your github repo.\n\nBackporting is the process of copying new feature/fixes committed in\nnumpy/main back to stable release branches. To do this you make a branch off\nthe branch you are backporting to, cherry pick the commits you want from\n`numpy/main`, and then submit a pull request for the branch containing the\nbackport.\n\nFirst, you need to make the branch you will work on. This needs to be based on\nthe older version of NumPy (not main):\n\nNow you need to apply the changes from main to this branch using git cherry-\npick:\n\nPush the new branch to your Github repository:\n\nRequires commit rights to the main NumPy repo.\n\nWhen you have a set of \u201cready\u201d changes in a feature branch ready for NumPy\u2019s\n`main` or `maintenance` branches, you can push them to `upstream` as follows:\n\nFirst, merge or rebase on the target branch.\n\nOnly a few, unrelated commits then prefer rebasing:\n\nSee Rebasing on main.\n\nIf all of the commits are related, create a merge commit:\n\nCheck that what you are going to push looks sensible:\n\nPush to upstream:\n\nNote\n\nIt\u2019s usually a good idea to use the `-n` flag to `git push` to check first\nthat you\u2019re about to push the changes you want to the place you want.\n\n"}, {"name": "distutils.ccompiler.CCompiler_compile()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_compile", "type": "numpy.distutils.ccompiler.CCompiler_compile", "text": "\nCompile one or more source files.\n\nPlease refer to the Python distutils API reference for more details.\n\nA list of filenames\n\nPath to the output directory.\n\nA list of macro definitions.\n\nThe directories to add to the default include file search path for this\ncompilation only.\n\nWhether or not to output debug symbols in or alongside the object file(s).\n\nExtra pre- and post-arguments.\n\nA list of file names that all targets depend on.\n\nA list of object file names, one per source file `sources`.\n\nIf compilation fails.\n\n"}, {"name": "distutils.ccompiler.CCompiler_customize()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_customize", "type": "numpy.distutils.ccompiler.CCompiler_customize", "text": "\nDo any platform-specific customization of a compiler instance.\n\nThis method calls `distutils.sysconfig.customize_compiler` for platform-\nspecific customization, as well as optionally remove a flag to suppress\nspurious warnings in case C++ code is being compiled.\n\nThis parameter is not used for anything.\n\nWhether or not C++ has to be compiled. If so (True), the `\"-Wstrict-\nprototypes\"` option is removed to prevent spurious warnings. Default is False.\n\nAll the default options used by distutils can be extracted with:\n\n"}, {"name": "distutils.ccompiler.CCompiler_customize_cmd()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_customize_cmd", "type": "numpy.distutils.ccompiler.CCompiler_customize_cmd", "text": "\nCustomize compiler using distutils command.\n\nAn instance inheriting from `distutils.cmd.Command`.\n\nList of `CCompiler` commands (without `'set_'`) that should not be altered.\nStrings that are checked for are: `('include_dirs', 'define', 'undef',\n'libraries', 'library_dirs', 'rpath', 'link_objects')`.\n\n"}, {"name": "distutils.ccompiler.CCompiler_cxx_compiler()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_cxx_compiler", "type": "numpy.distutils.ccompiler.CCompiler_cxx_compiler", "text": "\nReturn the C++ compiler.\n\nThe C++ compiler, as a `CCompiler` instance.\n\n"}, {"name": "distutils.ccompiler.CCompiler_find_executables()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_find_executables", "type": "numpy.distutils.ccompiler.CCompiler_find_executables", "text": "\nDoes nothing here, but is called by the get_version method and can be\noverridden by subclasses. In particular it is redefined in the `FCompiler`\nclass where more documentation can be found.\n\n"}, {"name": "distutils.ccompiler.CCompiler_get_version()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_get_version", "type": "numpy.distutils.ccompiler.CCompiler_get_version", "text": "\nReturn compiler version, or None if compiler is not available.\n\nIf True, force a new determination of the version, even if the compiler\nalready has a version attribute. Default is False.\n\nThe list of status values returned by the version look-up process for which a\nversion string is returned. If the status value is not in `ok_status`, None is\nreturned. Default is `[0]`.\n\nVersion string, in the format of `distutils.version.LooseVersion`.\n\n"}, {"name": "distutils.ccompiler.CCompiler_object_filenames()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_object_filenames", "type": "numpy.distutils.ccompiler.CCompiler_object_filenames", "text": "\nReturn the name of the object files for the given source files.\n\nThe list of paths to source files. Paths can be either relative or absolute,\nthis is handled transparently.\n\nWhether to strip the directory from the returned paths. If True, the file name\nprepended by `output_dir` is returned. Default is False.\n\nIf given, this path is prepended to the returned paths to the object files.\n\nThe list of paths to the object files corresponding to the source files in\n`source_filenames`.\n\n"}, {"name": "distutils.ccompiler.CCompiler_show_customization()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_show_customization", "type": "numpy.distutils.ccompiler.CCompiler_show_customization", "text": "\nPrint the compiler customizations to stdout.\n\nPrinting is only done if the distutils log threshold is < 2.\n\n"}, {"name": "distutils.ccompiler.CCompiler_spawn()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_spawn", "type": "numpy.distutils.ccompiler.CCompiler_spawn", "text": "\nExecute a command in a sub-process.\n\nThe command to execute.\n\nThe text to add to the log file kept by `numpy.distutils`. If not given,\n`display` is equal to `cmd`.\n\nIf the command failed, i.e. the exit status was not 0.\n\n"}, {"name": "distutils.ccompiler.gen_lib_options()", "path": "reference/generated/numpy.distutils.ccompiler.gen_lib_options", "type": "numpy.distutils.ccompiler.gen_lib_options", "text": "\n\n"}, {"name": "distutils.ccompiler.new_compiler()", "path": "reference/generated/numpy.distutils.ccompiler.new_compiler", "type": "numpy.distutils.ccompiler.new_compiler", "text": "\n\n"}, {"name": "distutils.ccompiler.replace_method()", "path": "reference/generated/numpy.distutils.ccompiler.replace_method", "type": "numpy.distutils.ccompiler.replace_method", "text": "\n\n"}, {"name": "distutils.ccompiler.simple_version_match()", "path": "reference/generated/numpy.distutils.ccompiler.simple_version_match", "type": "numpy.distutils.ccompiler.simple_version_match", "text": "\nSimple matching of version numbers, for use in CCompiler and FCompiler.\n\nA regular expression matching version numbers. Default is `r'[-.\\d]+'`.\n\nA regular expression matching patterns to skip. Default is `''`, in which case\nnothing is skipped.\n\nA regular expression matching the start of where to start looking for version\nnumbers. Default is `''`, in which case searching is started at the beginning\nof the version string given to `matcher`.\n\nA function that is appropriate to use as the `.version_match` attribute of a\n`CCompiler` class. `matcher` takes a single parameter, a version string.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cache_flush()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cache_flush", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cache_flush", "text": "\nmethod\n\nForce update the cache.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cc_normalize_flags", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags", "text": "\nmethod\n\nRemove the conflicts that caused due gathering implied features flags.\n\nflags should be sorted from the lowest to the highest interest.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.conf_features", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.conf_features", "type": "NumPy.distutils.ccompiler_opt.ccompileropt.conf_features", "text": "\nattribute\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.conf_features_partial()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.conf_features_partial", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.conf_features_partial", "text": "\nmethod\n\nReturn a dictionary of supported CPU features by the platform, and accumulate\nthe rest of undefined options in `conf_features`, the returned dict has same\nrules and notes in class attribute `conf_features`, also its override any\noptions that been set in \u2018conf_features\u2019.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_flags()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_baseline_flags", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_flags", "text": "\nmethod\n\nReturns a list of final CPU baseline compiler flags\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_baseline_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names", "text": "\nmethod\n\nreturn a list of final CPU baseline feature names\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_dispatch_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_dispatch_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_dispatch_names", "text": "\nmethod\n\nreturn a list of final CPU dispatch feature names\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_compile()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_compile", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_compile", "text": "\nmethod\n\nWrap CCompiler.compile()\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_info()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_info", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_info", "text": "\nmethod\n\nReturn a tuple containing info about (platform, compiler, extra_args),\nrequired by the abstract class \u2018_CCompiler\u2019 for discovering the platform\nenvironment. This is also used as a cache factor in order to detect any\nchanges happening from outside.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_test()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_test", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_test", "text": "\nmethod\n\nReturn True if \u2018CCompiler.compile()\u2019 able to compile a source file with\ncertain flags.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_ahead()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_ahead", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_ahead", "text": "\nmethod\n\nReturn list of features in \u2018names\u2019 after remove any implied features and keep\nthe origins.\n\nsequence of CPU feature names in uppercase.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_c_preprocessor()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_c_preprocessor", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_c_preprocessor", "text": "\nmethod\n\nGenerate C preprocessor definitions and include headers of a CPU feature.\n\nCPU feature name in uppercase.\n\nif > 0, align the generated strings to the right depend on number of tabs.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_detect()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_detect", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_detect", "text": "\nmethod\n\nReturn a list of CPU features that required to be detected sorted from the\nlowest to highest interest.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_get_til()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_get_til", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_get_til", "text": "\nmethod\n\nsame as `feature_implies_c()` but stop collecting implied features when\nfeature\u2019s option that provided through parameter \u2018keyisfalse\u2019 is False, also\nsorting the returned features.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_implies()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_implies", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_implies", "text": "\nmethod\n\nReturn a set of CPU features that implied by \u2018names\u2019\n\nCPU feature name(s) in uppercase.\n\nif False(default) then the returned set will not contain any features from\n\u2018names\u2019. This case happens only when two features imply each other.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_implies_c()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_implies_c", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_implies_c", "text": "\nmethod\n\nsame as feature_implies() but combining \u2018names\u2019\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_is_exist()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_is_exist", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_is_exist", "text": "\nmethod\n\nReturns True if a certain feature is exist and covered within\n`_Config.conf_features`.\n\nfeature name in uppercase.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_names", "text": "\nmethod\n\nReturns a set of CPU feature names that supported by platform and the C\ncompiler.\n\nSpecify certain CPU features to test it against the C compiler. if\nNone(default), it will test all current supported features. Note: feature\nnames must be in upper-case.\n\nIf None(default), default compiler flags for every CPU feature will be used\nduring the test.\n\nA list of C macro definitions.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_sorted()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_sorted", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_sorted", "text": "\nmethod\n\nSort a list of CPU features ordered by the lowest interest.\n\nsequence of supported feature names in uppercase.\n\nIf true, the sorted features is reversed. (highest interest)\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_untied()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_untied", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_untied", "text": "\nmethod\n\nsame as \u2018feature_ahead()\u2019 but if both features implied each other and keep the\nhighest interest.\n\nsequence of CPU feature names in uppercase.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.generate_dispatch_header()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.generate_dispatch_header", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.generate_dispatch_header", "text": "\nmethod\n\nGenerate the dispatch header which contains the #definitions and headers for\nplatform-specific instruction-sets for the enabled CPU baseline and dispatch-\nable features.\n\nIts highly recommended to take a look at the generated header also the\ngenerated source files via `try_dispatch()` in order to get the full picture.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.is_cached()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.is_cached", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.is_cached", "text": "\nmethod\n\nReturns True if the class loaded from the cache file\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.parse_targets()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.parse_targets", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.parse_targets", "text": "\nmethod\n\nFetch and parse configuration statements that required for defining the\ntargeted CPU features, statements should be declared in the top of source in\nbetween C comment and start with a special mark @targets.\n\nConfiguration statements are sort of keywords representing CPU features names,\ngroup of statements and policies, combined together to determine the required\noptimization.\n\nthe path of C source file.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.try_dispatch()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.try_dispatch", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.try_dispatch", "text": "\nmethod\n\nCompile one or more dispatch-able sources and generates object files, also\ngenerates abstract C config headers and macros that used later for the final\nruntime dispatching process.\n\nThe mechanism behind it is to takes each source file that specified in\n\u2018sources\u2019 and branching it into several files depend on special configuration\nstatements that must be declared in the top of each source which contains\ntargeted CPU features, then it compiles every branched source with the proper\ncompiler flags.\n\nMust be a list of dispatch-able sources file paths, and configuration\nstatements must be declared inside each file.\n\nPath of parent directory for the generated headers and wrapped sources. If\nNone(default) the files will generated in-place.\n\nDistutils `CCompiler` instance to be used for compilation. If None (default),\nthe provided instance during the initialization will be used instead.\n\nArguments to pass on to the `CCompiler.compile()`\n\nRaises by `CCompiler.compile()` on compiling failure.\n\nSome errors during checking the sanity of configuration statements.\n\nSee also\n\nParsing the configuration statements of dispatch-able sources.\n\n"}, {"name": "distutils.ccompiler_opt.new_ccompiler_opt()", "path": "reference/generated/numpy.distutils.ccompiler_opt.new_ccompiler_opt", "type": "numpy.distutils.ccompiler_opt.new_ccompiler_opt", "text": "\nCreate a new instance of \u2018CCompilerOpt\u2019 and generate the dispatch header which\ncontains the #definitions and headers of platform-specific instruction-sets\nfor the enabled CPU baseline and dispatch-able features.\n\npath of the dispatch header\n\n"}, {"name": "distutils.cpuinfo.cpu", "path": "reference/generated/numpy.distutils.cpuinfo.cpu", "type": "numpy.distutils.cpuinfo.cpu", "text": "\n\n"}, {"name": "distutils.exec_command.exec_command()", "path": "reference/generated/numpy.distutils.exec_command.exec_command", "type": "numpy.distutils.exec_command.exec_command", "text": "\nReturn (status,output) of executed command.\n\nDeprecated since version 1.17: Use subprocess.Popen instead\n\nA concatenated string of executable and arguments.\n\nBefore running command `cd execute_in` and after `cd -`.\n\nIf True, execute `sh -c command`. Default None (True)\n\nIf True use tee. Default None (True)\n\nBoth stdout and stderr messages.\n\nOn NT, DOS systems the returned status is correct for external commands. Wild\ncards will not work for non-posix systems or when use_shell=0.\n\n"}, {"name": "distutils.exec_command.filepath_from_subprocess_output()", "path": "reference/generated/numpy.distutils.exec_command.filepath_from_subprocess_output", "type": "numpy.distutils.exec_command.filepath_from_subprocess_output", "text": "\nConvert `bytes` in the encoding used by a subprocess into a filesystem-\nappropriate `str`.\n\nInherited from `exec_command`, and possibly incorrect.\n\n"}, {"name": "distutils.exec_command.find_executable()", "path": "reference/generated/numpy.distutils.exec_command.find_executable", "type": "numpy.distutils.exec_command.find_executable", "text": "\nReturn full path of a executable or None.\n\nSymbolic links are not followed.\n\n"}, {"name": "distutils.exec_command.forward_bytes_to_stdout()", "path": "reference/generated/numpy.distutils.exec_command.forward_bytes_to_stdout", "type": "numpy.distutils.exec_command.forward_bytes_to_stdout", "text": "\nForward bytes from a subprocess call to the console, without attempting to\ndecode them.\n\nThe assumption is that the subprocess call already returned bytes in a\nsuitable encoding.\n\n"}, {"name": "distutils.exec_command.get_pythonexe()", "path": "reference/generated/numpy.distutils.exec_command.get_pythonexe", "type": "numpy.distutils.exec_command.get_pythonexe", "text": "\n\n"}, {"name": "distutils.exec_command.temp_file_name()", "path": "reference/generated/numpy.distutils.exec_command.temp_file_name", "type": "numpy.distutils.exec_command.temp_file_name", "text": "\n\n"}, {"name": "distutils.log.set_verbosity()", "path": "reference/generated/numpy.distutils.log.set_verbosity", "type": "numpy.distutils.log.set_verbosity", "text": "\n\n"}, {"name": "distutils.system_info.get_info()", "path": "reference/generated/numpy.distutils.system_info.get_info", "type": "numpy.distutils.system_info.get_info", "text": "\n0 - do nothing 1 - display warning message 2 - raise error\n\n"}, {"name": "distutils.system_info.get_standard_file()", "path": "reference/generated/numpy.distutils.system_info.get_standard_file", "type": "numpy.distutils.system_info.get_standard_file", "text": "\nReturns a list of files named \u2018fname\u2019 from 1) System-wide directory\n(directory-location of this module) 2) Users HOME directory\n(os.environ[\u2018HOME\u2019]) 3) Local directory\n\n"}, {"name": "double npy_half_to_double()", "path": "reference/c-api/coremath#c.npy_half_to_double", "type": "NumPy core libraries", "text": "\nConverts a half-precision float to a double-precision float.\n\n"}, {"name": "double npy_spacing()", "path": "reference/c-api/coremath#c.npy_spacing", "type": "NumPy core libraries", "text": "\nThis is a function equivalent to Fortran intrinsic. Return distance between x\nand next representable floating point value from x, e.g. spacing(1) == eps.\nspacing of nan and +/- inf return nan. Single and extended precisions are\navailable with suffix f and l.\n\nNew in version 1.4.0.\n\n"}, {"name": "double PyArray_GetPriority()", "path": "reference/c-api/array#c.PyArray_GetPriority", "type": "Array API", "text": "\nReturn the `__array_priority__` attribute (converted to a double) of obj or\ndef if no attribute of that name exists. Fast returns that avoid the attribute\nlookup are provided for objects of type `PyArray_Type`.\n\n"}, {"name": "double random_beta()", "path": "reference/random/c-api#c.random_beta", "type": "C API for random", "text": "\n\n"}, {"name": "double random_chisquare()", "path": "reference/random/c-api#c.random_chisquare", "type": "C API for random", "text": "\n\n"}, {"name": "double random_exponential()", "path": "reference/random/c-api#c.random_exponential", "type": "C API for random", "text": "\n\n"}, {"name": "double random_f()", "path": "reference/random/c-api#c.random_f", "type": "C API for random", "text": "\n\n"}, {"name": "double random_gamma()", "path": "reference/random/c-api#c.random_gamma", "type": "C API for random", "text": "\n\n"}, {"name": "double random_gumbel()", "path": "reference/random/c-api#c.random_gumbel", "type": "C API for random", "text": "\n\n"}, {"name": "double random_laplace()", "path": "reference/random/c-api#c.random_laplace", "type": "C API for random", "text": "\n\n"}, {"name": "double random_logistic()", "path": "reference/random/c-api#c.random_logistic", "type": "C API for random", "text": "\n\n"}, {"name": "double random_lognormal()", "path": "reference/random/c-api#c.random_lognormal", "type": "C API for random", "text": "\n\n"}, {"name": "double random_noncentral_chisquare()", "path": "reference/random/c-api#c.random_noncentral_chisquare", "type": "C API for random", "text": "\n\n"}, {"name": "double random_noncentral_f()", "path": "reference/random/c-api#c.random_noncentral_f", "type": "C API for random", "text": "\n\n"}, {"name": "double random_normal()", "path": "reference/random/c-api#c.random_normal", "type": "C API for random", "text": "\n\n"}, {"name": "double random_pareto()", "path": "reference/random/c-api#c.random_pareto", "type": "C API for random", "text": "\n\n"}, {"name": "double random_power()", "path": "reference/random/c-api#c.random_power", "type": "C API for random", "text": "\n\n"}, {"name": "double random_rayleigh()", "path": "reference/random/c-api#c.random_rayleigh", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_cauchy()", "path": "reference/random/c-api#c.random_standard_cauchy", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_exponential()", "path": "reference/random/c-api#c.random_standard_exponential", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_gamma()", "path": "reference/random/c-api#c.random_standard_gamma", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_normal()", "path": "reference/random/c-api#c.random_standard_normal", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_t()", "path": "reference/random/c-api#c.random_standard_t", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_uniform()", "path": "reference/random/c-api#c.random_standard_uniform", "type": "C API for random", "text": "\n\n"}, {"name": "double random_triangular()", "path": "reference/random/c-api#c.random_triangular", "type": "C API for random", "text": "\n\n"}, {"name": "double random_uniform()", "path": "reference/random/c-api#c.random_uniform", "type": "C API for random", "text": "\n\n"}, {"name": "double random_vonmises()", "path": "reference/random/c-api#c.random_vonmises", "type": "C API for random", "text": "\n\n"}, {"name": "double random_wald()", "path": "reference/random/c-api#c.random_wald", "type": "C API for random", "text": "\n\n"}, {"name": "double random_weibull()", "path": "reference/random/c-api#c.random_weibull", "type": "C API for random", "text": "\n\n"}, {"name": "DoxyLimbo()", "path": "dev/howto-docs#_CPPv4N9DoxyLimbo9DoxyLimboERK9DoxyLimboI2Tp1NE", "type": "Development", "text": "\nSet Default behavior for copy the limbo.\n\n"}, {"name": "dtype object", "path": "reference/arrays.dtypes", "type": "Data type objects ( \n      \n       dtype\n      \n      )", "text": "\nA data type object (an instance of `numpy.dtype` class) describes how the\nbytes in the fixed-size block of memory corresponding to an array item should\nbe interpreted. It describes the following aspects of the data:\n\nIf the data type is structured data type, an aggregate of other data types,\n(e.g., describing an array item consisting of an integer and a float),\n\nTo describe the type of scalar data, there are several built-in scalar types\nin NumPy for various precision of integers, floating-point numbers, etc. An\nitem extracted from an array, e.g., by indexing, will be a Python object whose\ntype is the scalar type associated with the data type of the array.\n\nNote that the scalar types are not `dtype` objects, even though they can be\nused in place of one whenever a data type specification is needed in NumPy.\n\nStructured data types are formed by creating a data type whose field contain\nother data types. Each field has a name by which it can be accessed. The\nparent data type should be of sufficient size to contain all its fields; the\nparent is nearly always based on the `void` type which allows an arbitrary\nitem size. Structured data types may also contain nested structured sub-array\ndata types in their fields.\n\nFinally, a data type can describe items that are themselves arrays of items of\nanother data type. These sub-arrays must, however, be of a fixed size.\n\nIf an array is created using a data-type describing a sub-array, the\ndimensions of the sub-array are appended to the shape of the array when the\narray is created. Sub-arrays in a field of a structured type behave\ndifferently, see Field access.\n\nSub-arrays always have a C-contiguous memory layout.\n\nA simple data type containing a 32-bit big-endian integer: (see Specifying and\nconstructing data types for details on construction)\n\nThe corresponding array scalar type is `int32`.\n\nA structured data type containing a 16-character string (in field \u2018name\u2019) and\na sub-array of two 64-bit floating-point number (in field \u2018grades\u2019):\n\nItems of an array of this data type are wrapped in an array scalar type that\nalso has two fields:\n\nWhenever a data-type is required in a NumPy function or method, either a\n`dtype` object or something that can be converted to one can be supplied. Such\nconversions are done by the `dtype` constructor:\n\n`dtype`(dtype[, align, copy])\n\nCreate a data type object.\n\nWhat can be converted to a data-type object is described below:\n\nUsed as-is.\n\nThe default data type: `float_`.\n\nThe 24 built-in array scalar type objects all convert to an associated data-\ntype object. This is true for their sub-classes as well.\n\nNote that not all data-type information can be supplied with a type-object:\nfor example, `flexible` data-types have a default itemsize of 0, and require\nan explicitly given size to be useful.\n\nThe generic hierarchical type objects convert to corresponding type objects\naccording to the associations:\n\n`number`, `inexact`, `floating`\n\n`float`\n\n`complexfloating`\n\n`cfloat`\n\n`integer`, `signedinteger`\n\n`int_`\n\n`unsignedinteger`\n\n`uint`\n\n`character`\n\n`string`\n\n`generic`, `flexible`\n\n`void`\n\nDeprecated since version 1.19: This conversion of generic scalar types is\ndeprecated. This is because it can be unexpected in a context such as\n`arr.astype(dtype=np.floating)`, which casts an array of `float32` to an array\nof `float64`, even though `float32` is a subdtype of `np.floating`.\n\nSeveral python types are equivalent to a corresponding array scalar when used\nto generate a `dtype` object:\n\n`int`\n\n`int_`\n\n`bool`\n\n`bool_`\n\n`float`\n\n`float_`\n\n`complex`\n\n`cfloat`\n\n`bytes`\n\n`bytes_`\n\n`str`\n\n`str_`\n\n`buffer`\n\n`void`\n\n(all others)\n\n`object_`\n\nNote that `str` refers to either null terminated bytes or unicode strings\ndepending on the Python version. In code targeting both Python 2 and 3\n`np.unicode_` should be used as a dtype for strings. See Note on string types.\n\nNote\n\nAll other types map to `object_` for convenience. Code should expect that such\ntypes may map to a specific (new) dtype in the future.\n\nAny type object with a `dtype` attribute: The attribute will be accessed and\nused directly. The attribute must return something that is convertible into a\ndtype object.\n\nSeveral kinds of strings can be converted. Recognized strings can be prepended\nwith `'>'` (big-endian), `'<'` (little-endian), or `'='` (hardware-native, the\ndefault), to specify the byte order.\n\nEach built-in data-type has a character code (the updated Numeric typecodes),\nthat uniquely identifies it.\n\nThe first character specifies the kind of data and the remaining characters\nspecify the number of bytes per item, except for Unicode, where it is\ninterpreted as the number of characters. The item size must correspond to an\nexisting type, or an error will be raised. The supported kinds are\n\n`'?'`\n\nboolean\n\n`'b'`\n\n(signed) byte\n\n`'B'`\n\nunsigned byte\n\n`'i'`\n\n(signed) integer\n\n`'u'`\n\nunsigned integer\n\n`'f'`\n\nfloating-point\n\n`'c'`\n\ncomplex-floating point\n\n`'m'`\n\ntimedelta\n\n`'M'`\n\ndatetime\n\n`'O'`\n\n(Python) objects\n\n`'S'`, `'a'`\n\nzero-terminated bytes (not recommended)\n\n`'U'`\n\nUnicode string\n\n`'V'`\n\nraw data (`void`)\n\nNote on string types\n\nFor backward compatibility with Python 2 the `S` and `a` typestrings remain\nzero-terminated bytes and `numpy.string_` continues to alias `numpy.bytes_`.\nTo use actual strings in Python 3 use `U` or `numpy.str_`. For signed bytes\nthat do not need zero-termination `b` or `i1` can be used.\n\nA short-hand notation for specifying the format of a structured data type is a\ncomma-separated string of basic formats.\n\nA basic format in this context is an optional shape specifier followed by an\narray-protocol type string. Parenthesis are required on the shape if it has\nmore than one dimension. NumPy allows a modification on the format in that any\nstring that can uniquely identify the type can be used to specify the data-\ntype in a field. The generated data-type fields are named `'f0'`, `'f1'`, \u2026,\n`'f<N-1>'` where N (>1) is the number of comma-separated basic formats in the\nstring. If the optional shape specifier is provided, then the data-type for\nthe corresponding field describes a sub-array.\n\nAny string in `numpy.sctypeDict`.keys():\n\nThe first argument must be an object that is converted to a zero-sized\nflexible data-type object, the second argument is an integer providing the\ndesired itemsize.\n\nThe first argument is any object that can be converted into a fixed-size data-\ntype object. The second argument is the desired shape of this type. If the\nshape parameter is 1, then the data-type object used to be equivalent to fixed\ndtype. This behaviour is deprecated since NumPy 1.17 and will raise an error\nin the future. If shape is a tuple, then the new dtype defines a sub-array of\nthe given shape.\n\nobj should be a list of fields where each field is described by a tuple of\nlength 2 or 3. (Equivalent to the `descr` item in the `__array_interface__`\nattribute.)\n\nThe first element, field_name, is the field name (if this is `''` then a\nstandard field name, `'f#'`, is assigned). The field name may also be a\n2-tuple of strings where the first string is either a \u201ctitle\u201d (which may be\nany string or unicode string) or meta-data for the field which can be any\nobject, and the second string is the \u201cname\u201d which must be a valid Python\nidentifier.\n\nThe second element, field_dtype, can be anything that can be interpreted as a\ndata-type.\n\nThe optional third element field_shape contains the shape if this field\nrepresents an array of the data-type in the second element. Note that a\n3-tuple with a third argument equal to 1 is equivalent to a 2-tuple.\n\nThis style does not accept align in the `dtype` constructor as it is assumed\nthat all of the memory is accounted for by the array interface description.\n\nData-type with fields `big` (big-endian 32-bit integer) and `little` (little-\nendian 32-bit integer):\n\nData-type with fields `R`, `G`, `B`, `A`, each being an unsigned 8-bit\ninteger:\n\nThis style has two required and three optional keys. The names and formats\nkeys are required. Their respective values are equal-length lists with the\nfield names and the field formats. The field names must be strings and the\nfield formats can be any object accepted by `dtype` constructor.\n\nWhen the optional keys offsets and titles are provided, their values must each\nbe lists of the same length as the names and formats lists. The offsets value\nis a list of byte offsets (limited to `ctypes.c_int`) for each field, while\nthe titles value is a list of titles for each field (`None` can be used if no\ntitle is desired for that field). The titles can be any object, but when a\n`str` object will add another entry to the fields dictionary keyed by the\ntitle and referencing the same field tuple which will contain the title as an\nadditional tuple member.\n\nThe itemsize key allows the total size of the dtype to be set, and must be an\ninteger large enough so all the fields are within the dtype. If the dtype\nbeing constructed is aligned, the itemsize must also be divisible by the\nstruct alignment. Total dtype itemsize is limited to `ctypes.c_int`.\n\nData type with fields `r`, `g`, `b`, `a`, each being an 8-bit unsigned\ninteger:\n\nData type with fields `r` and `b` (with the given titles), both being 8-bit\nunsigned integers, the first at byte position 0 from the start of the field\nand the second at position 2:\n\nThis usage is discouraged, because it is ambiguous with the other dict-based\nconstruction method. If you have a field called \u2018names\u2019 and a field called\n\u2018formats\u2019 there will be a conflict.\n\nThis style allows passing in the `fields` attribute of a data-type object.\n\nobj should contain string or unicode keys that refer to `(data-type, offset)`\nor `(data-type, offset, title)` tuples.\n\nData type containing field `col1` (10-character string at byte position 0),\n`col2` (32-bit float at byte position 10), and `col3` (integers at byte\nposition 14):\n\nIn NumPy 1.7 and later, this form allows `base_dtype` to be interpreted as a\nstructured dtype. Arrays created with this dtype will have underlying dtype\n`base_dtype` but will have fields and flags taken from `new_dtype`. This is\nuseful for creating custom structured dtypes, as done in record arrays.\n\nThis form also makes it possible to specify struct dtypes with overlapping\nfields, functioning like the \u2018union\u2019 type in C. This usage is discouraged,\nhowever, and the union mechanism is preferred.\n\nBoth arguments must be convertible to data-type objects with the same total\nsize.\n\n32-bit integer, whose first two bytes are interpreted as an integer via field\n`real`, and the following two bytes via field `imag`.\n\n32-bit integer, which is interpreted as consisting of a sub-array of shape\n`(4,)` containing 8-bit integers:\n\n32-bit integer, containing fields `r`, `g`, `b`, `a` that interpret the 4\nbytes in the integer as four unsigned integers:\n\nNumPy data type descriptions are instances of the `dtype` class.\n\nThe type of the data is described by the following `dtype` attributes:\n\n`dtype.type`\n\n`dtype.kind`\n\nA character code (one of 'biufcmMOSUV') identifying the general kind of data.\n\n`dtype.char`\n\nA unique character code for each of the 21 different built-in types.\n\n`dtype.num`\n\nA unique number for each of the 21 different built-in types.\n\n`dtype.str`\n\nThe array-protocol typestring of this data-type object.\n\nSize of the data is in turn described by:\n\n`dtype.name`\n\nA bit-width name for this data-type.\n\n`dtype.itemsize`\n\nThe element size of this data-type object.\n\nEndianness of this data:\n\n`dtype.byteorder`\n\nA character indicating the byte-order of this data-type object.\n\nInformation about sub-data-types in a structured data type:\n\n`dtype.fields`\n\nDictionary of named fields defined for this data type, or `None`.\n\n`dtype.names`\n\nOrdered list of field names, or `None` if there are no fields.\n\nFor data types that describe sub-arrays:\n\n`dtype.subdtype`\n\nTuple `(item_dtype, shape)` if this `dtype` describes a sub-array, and None\notherwise.\n\n`dtype.shape`\n\nShape tuple of the sub-array if this data type describes a sub-array, and `()`\notherwise.\n\nAttributes providing additional information:\n\n`dtype.hasobject`\n\nBoolean indicating whether this dtype contains any reference-counted objects\nin any fields or sub-dtypes.\n\n`dtype.flags`\n\nBit-flags describing how this data type is to be interpreted.\n\n`dtype.isbuiltin`\n\nInteger indicating how this dtype relates to the built-in dtypes.\n\n`dtype.isnative`\n\nBoolean indicating whether the byte order of this dtype is native to the\nplatform.\n\n`dtype.descr`\n\n`__array_interface__` description of the data-type.\n\n`dtype.alignment`\n\nThe required alignment (bytes) of this data-type according to the compiler.\n\n`dtype.base`\n\nReturns dtype for the base element of the subarrays, regardless of their\ndimension or shape.\n\nMetadata attached by the user:\n\n`dtype.metadata`\n\nEither `None` or a readonly dictionary of metadata (mappingproxy).\n\nData types have the following method for changing the byte order:\n\n`dtype.newbyteorder`([new_order])\n\nReturn a new dtype with a different byte order.\n\nThe following methods implement the pickle protocol:\n\n`dtype.__reduce__`\n\nHelper for pickle.\n\n`dtype.__setstate__`\n\nUtility method for typing:\n\n`dtype.__class_getitem__`(item, /)\n\nReturn a parametrized wrapper around the `dtype` type.\n\nComparison operations:\n\n`dtype.__ge__`(value, /)\n\nReturn self>=value.\n\n`dtype.__gt__`(value, /)\n\nReturn self>value.\n\n`dtype.__le__`(value, /)\n\nReturn self<=value.\n\n`dtype.__lt__`(value, /)\n\nReturn self<value.\n\n"}, {"name": "dtype.__class_getitem__()", "path": "reference/generated/numpy.dtype.__class_getitem__", "type": "numpy.dtype.__class_getitem__", "text": "\nmethod\n\nReturn a parametrized wrapper around the `dtype` type.\n\nNew in version 1.22.\n\nA parametrized `dtype` type.\n\nSee also\n\nType hinting generics in standard collections.\n\nThis method is only available for python 3.9 and later.\n\n"}, {"name": "dtype.__ge__()", "path": "reference/generated/numpy.dtype.__ge__", "type": "numpy.dtype.__ge__", "text": "\nmethod\n\nReturn self>=value.\n\n"}, {"name": "dtype.__gt__()", "path": "reference/generated/numpy.dtype.__gt__", "type": "numpy.dtype.__gt__", "text": "\nmethod\n\nReturn self>value.\n\n"}, {"name": "dtype.__le__()", "path": "reference/generated/numpy.dtype.__le__", "type": "numpy.dtype.__le__", "text": "\nmethod\n\nReturn self<=value.\n\n"}, {"name": "dtype.__lt__()", "path": "reference/generated/numpy.dtype.__lt__", "type": "numpy.dtype.__lt__", "text": "\nmethod\n\nReturn self<value.\n\n"}, {"name": "dtype.__reduce__()", "path": "reference/generated/numpy.dtype.__reduce__", "type": "numpy.dtype.__reduce__", "text": "\nmethod\n\nHelper for pickle.\n\n"}, {"name": "dtype.__setstate__()", "path": "reference/generated/numpy.dtype.__setstate__", "type": "numpy.dtype.__setstate__", "text": "\nmethod\n\n"}, {"name": "dtype.alignment", "path": "reference/generated/numpy.dtype.alignment", "type": "numpy.dtype.alignment", "text": "\nattribute\n\nThe required alignment (bytes) of this data-type according to the compiler.\n\nMore information is available in the C-API section of the manual.\n\n"}, {"name": "dtype.base", "path": "reference/generated/numpy.dtype.base", "type": "numpy.dtype.base", "text": "\nattribute\n\nReturns dtype for the base element of the subarrays, regardless of their\ndimension or shape.\n\nSee also\n\n"}, {"name": "dtype.byteorder", "path": "reference/generated/numpy.dtype.byteorder", "type": "numpy.dtype.byteorder", "text": "\nattribute\n\nA character indicating the byte-order of this data-type object.\n\nOne of:\n\n\u2018=\u2019\n\nnative\n\n\u2018<\u2019\n\nlittle-endian\n\n\u2018>\u2019\n\nbig-endian\n\n\u2018|\u2019\n\nnot applicable\n\nAll built-in data-type objects have byteorder either \u2018=\u2019 or \u2018|\u2019.\n\n"}, {"name": "dtype.char", "path": "reference/generated/numpy.dtype.char", "type": "numpy.dtype.char", "text": "\nattribute\n\nA unique character code for each of the 21 different built-in types.\n\n"}, {"name": "dtype.descr", "path": "reference/generated/numpy.dtype.descr", "type": "numpy.dtype.descr", "text": "\nattribute\n\n`__array_interface__` description of the data-type.\n\nThe format is that required by the \u2018descr\u2019 key in the `__array_interface__`\nattribute.\n\nWarning: This attribute exists specifically for `__array_interface__`, and\npassing it directly to `np.dtype` will not accurately reconstruct some dtypes\n(e.g., scalar and subarray dtypes).\n\n"}, {"name": "dtype.fields", "path": "reference/generated/numpy.dtype.fields", "type": "numpy.dtype.fields", "text": "\nattribute\n\nDictionary of named fields defined for this data type, or `None`.\n\nThe dictionary is indexed by keys that are the names of the fields. Each entry\nin the dictionary is a tuple fully describing the field:\n\nOffset is limited to C int, which is signed and usually 32 bits. If present,\nthe optional title can be any object (if it is a string or unicode then it\nwill also be a key in the fields dictionary, otherwise it\u2019s meta-data). Notice\nalso that the first two elements of the tuple can be passed directly as\narguments to the `ndarray.getfield` and `ndarray.setfield` methods.\n\nSee also\n\n"}, {"name": "dtype.flags", "path": "reference/generated/numpy.dtype.flags", "type": "numpy.dtype.flags", "text": "\nattribute\n\nBit-flags describing how this data type is to be interpreted.\n\nBit-masks are in `numpy.core.multiarray` as the constants `ITEM_HASOBJECT`,\n`LIST_PICKLE`, `ITEM_IS_POINTER`, `NEEDS_INIT`, `NEEDS_PYAPI`, `USE_GETITEM`,\n`USE_SETITEM`. A full explanation of these flags is in C-API documentation;\nthey are largely useful for user-defined data-types.\n\nThe following example demonstrates that operations on this particular dtype\nrequires Python C-API.\n\n"}, {"name": "dtype.hasobject", "path": "reference/generated/numpy.dtype.hasobject", "type": "numpy.dtype.hasobject", "text": "\nattribute\n\nBoolean indicating whether this dtype contains any reference-counted objects\nin any fields or sub-dtypes.\n\nRecall that what is actually in the ndarray memory representing the Python\nobject is the memory address of that object (a pointer). Special handling may\nbe required, and this attribute is useful for distinguishing data types that\nmay contain arbitrary Python objects and data-types that won\u2019t.\n\n"}, {"name": "dtype.isalignedstruct", "path": "reference/generated/numpy.dtype.isalignedstruct", "type": "Data type objects", "text": "\nattribute\n\nBoolean indicating whether the dtype is a struct which maintains field\nalignment. This flag is sticky, so when combining multiple structs together,\nit is preserved and produces new dtypes which are also aligned.\n\n"}, {"name": "dtype.isbuiltin", "path": "reference/generated/numpy.dtype.isbuiltin", "type": "numpy.dtype.isbuiltin", "text": "\nattribute\n\nInteger indicating how this dtype relates to the built-in dtypes.\n\nRead-only.\n\n0\n\nif this is a structured array type, with fields\n\n1\n\nif this is a dtype compiled into numpy (such as ints, floats etc)\n\n2\n\nif the dtype is for a user-defined numpy type A user-defined type uses the\nnumpy C-API machinery to extend numpy to handle a new array type. See User-\ndefined data-types in the NumPy manual.\n\n"}, {"name": "dtype.isnative", "path": "reference/generated/numpy.dtype.isnative", "type": "numpy.dtype.isnative", "text": "\nattribute\n\nBoolean indicating whether the byte order of this dtype is native to the\nplatform.\n\n"}, {"name": "dtype.itemsize", "path": "reference/generated/numpy.dtype.itemsize", "type": "numpy.dtype.itemsize", "text": "\nattribute\n\nThe element size of this data-type object.\n\nFor 18 of the 21 types this number is fixed by the data-type. For the flexible\ndata-types, this number can be anything.\n\n"}, {"name": "dtype.kind", "path": "reference/generated/numpy.dtype.kind", "type": "numpy.dtype.kind", "text": "\nattribute\n\nA character code (one of \u2018biufcmMOSUV\u2019) identifying the general kind of data.\n\nb\n\nboolean\n\ni\n\nsigned integer\n\nu\n\nunsigned integer\n\nf\n\nfloating-point\n\nc\n\ncomplex floating-point\n\nm\n\ntimedelta\n\nM\n\ndatetime\n\nO\n\nobject\n\nS\n\n(byte-)string\n\nU\n\nUnicode\n\nV\n\nvoid\n\n"}, {"name": "dtype.metadata", "path": "reference/generated/numpy.dtype.metadata", "type": "numpy.dtype.metadata", "text": "\nattribute\n\nEither `None` or a readonly dictionary of metadata (mappingproxy).\n\nThe metadata field can be set using any dictionary at data-type creation.\nNumPy currently has no uniform approach to propagating metadata; although some\narray operations preserve it, there is no guarantee that others will.\n\nWarning\n\nAlthough used in certain projects, this feature was long undocumented and is\nnot well supported. Some aspects of metadata propagation are expected to\nchange in the future.\n\nAdding arrays with identical datatypes currently preserves the metadata:\n\nBut if the arrays have different dtype metadata, the metadata may be dropped:\n\n"}, {"name": "dtype.name", "path": "reference/generated/numpy.dtype.name", "type": "numpy.dtype.name", "text": "\nattribute\n\nA bit-width name for this data-type.\n\nUn-sized flexible data-type objects do not have this attribute.\n\n"}, {"name": "dtype.names", "path": "reference/generated/numpy.dtype.names", "type": "numpy.dtype.names", "text": "\nattribute\n\nOrdered list of field names, or `None` if there are no fields.\n\nThe names are ordered according to increasing byte offset. This can be used,\nfor example, to walk through all of the named fields in offset order.\n\n"}, {"name": "dtype.ndim", "path": "reference/generated/numpy.dtype.ndim", "type": "Data type objects", "text": "\nattribute\n\nNumber of dimensions of the sub-array if this data type describes a sub-array,\nand `0` otherwise.\n\nNew in version 1.13.0.\n\n"}, {"name": "dtype.newbyteorder()", "path": "reference/generated/numpy.dtype.newbyteorder", "type": "numpy.dtype.newbyteorder", "text": "\nmethod\n\nReturn a new dtype with a different byte order.\n\nChanges are also made in all fields and sub-arrays of the data type.\n\nByte order to force; a value from the byte order specifications below. The\ndefault value (\u2018S\u2019) results in swapping the current byte order. `new_order`\ncodes can be any of:\n\nNew dtype object with the given change to the byte order.\n\nChanges are also made in all fields and sub-arrays of the data type.\n\n"}, {"name": "dtype.num", "path": "reference/generated/numpy.dtype.num", "type": "numpy.dtype.num", "text": "\nattribute\n\nA unique number for each of the 21 different built-in types.\n\nThese are roughly ordered from least-to-most precision.\n\n"}, {"name": "dtype.shape", "path": "reference/generated/numpy.dtype.shape", "type": "numpy.dtype.shape", "text": "\nattribute\n\nShape tuple of the sub-array if this data type describes a sub-array, and `()`\notherwise.\n\n"}, {"name": "dtype.str", "path": "reference/generated/numpy.dtype.str", "type": "numpy.dtype.str", "text": "\nattribute\n\nThe array-protocol typestring of this data-type object.\n\n"}, {"name": "dtype.subdtype", "path": "reference/generated/numpy.dtype.subdtype", "type": "numpy.dtype.subdtype", "text": "\nattribute\n\nTuple `(item_dtype, shape)` if this `dtype` describes a sub-array, and None\notherwise.\n\nThe shape is the fixed shape of the sub-array described by this data type, and\nitem_dtype the data type of the array.\n\nIf a field whose dtype object has this attribute is retrieved, then the extra\ndimensions implied by shape are tacked on to the end of the retrieved array.\n\nSee also\n\n"}, {"name": "dtype.type", "path": "reference/generated/numpy.dtype.type", "type": "numpy.dtype.type", "text": "\nattribute\n\n"}, {"name": "Elementary Function", "path": "reference/c-api/generalized-ufuncs", "type": "Generalized Universal Function API", "text": "\nThere is a general need for looping over not only functions on scalars but\nalso over functions on vectors (or arrays). This concept is realized in NumPy\nby generalizing the universal functions (ufuncs). In regular ufuncs, the\nelementary function is limited to element-by-element operations, whereas the\ngeneralized version (gufuncs) supports \u201csub-array\u201d by \u201csub-array\u201d operations.\nThe Perl vector library PDL provides a similar functionality and its terms are\nre-used in the following.\n\nEach generalized ufunc has information associated with it that states what the\n\u201ccore\u201d dimensionality of the inputs is, as well as the corresponding\ndimensionality of the outputs (the element-wise ufuncs have zero core\ndimensions). The list of the core dimensions for all arguments is called the\n\u201csignature\u201d of a ufunc. For example, the ufunc numpy.add has signature\n`(),()->()` defining two scalar inputs and one scalar output.\n\nAnother example is the function `inner1d(a, b)` with a signature of\n`(i),(i)->()`. This applies the inner product along the last axis of each\ninput, but keeps the remaining indices intact. For example, where `a` is of\nshape `(3, 5, N)` and `b` is of shape `(5, N)`, this will return an output of\nshape `(3,5)`. The underlying elementary function is called `3 * 5` times. In\nthe signature, we specify one core dimension `(i)` for each input and zero\ncore dimensions `()` for the output, since it takes two 1-d arrays and returns\na scalar. By using the same name `i`, we specify that the two corresponding\ndimensions should be of the same size.\n\nThe dimensions beyond the core dimensions are called \u201cloop\u201d dimensions. In the\nabove example, this corresponds to `(3, 5)`.\n\nThe signature determines how the dimensions of each input/output array are\nsplit into core and loop dimensions:\n\nTypically, the size of all core dimensions in an output will be determined by\nthe size of a core dimension with the same label in an input array. This is\nnot a requirement, and it is possible to define a signature where a label\ncomes up for the first time in an output, although some precautions must be\ntaken when calling such a function. An example would be the function\n`euclidean_pdist(a)`, with signature `(n,d)->(p)`, that given an array of `n`\n`d`-dimensional vectors, computes all unique pairwise Euclidean distances\namong them. The output dimension `p` must therefore be equal to `n * (n - 1) /\n2`, but it is the caller\u2019s responsibility to pass in an output array of the\nright size. If the size of a core dimension of an output cannot be determined\nfrom a passed in input or output array, an error will be raised.\n\nNote: Prior to NumPy 1.10.0, less strict checks were in place: missing core\ndimensions were created by prepending 1\u2019s to the shape as necessary, core\ndimensions with the same label were broadcast together, and undetermined\ndimensions were created with size 1.\n\nEach ufunc consists of an elementary function that performs the most basic\noperation on the smallest portion of array arguments (e.g. adding two numbers\nis the most basic operation in adding two arrays). The ufunc applies the\nelementary function multiple times on different parts of the arrays. The\ninput/output of elementary functions can be vectors; e.g., the elementary\nfunction of inner1d takes two vectors as input.\n\nA signature is a string describing the input/output dimensions of the\nelementary function of a ufunc. See section below for more details.\n\nThe dimensionality of each input/output of an elementary function is defined\nby its core dimensions (zero core dimensions correspond to a scalar\ninput/output). The core dimensions are mapped to the last dimensions of the\ninput/output arrays.\n\nA dimension name represents a core dimension in the signature. Different\ndimensions may share a name, indicating that they are of the same size.\n\nA dimension index is an integer representing a dimension name. It enumerates\nthe dimension names according to the order of the first occurrence of each\nname in the signature.\n\nThe signature defines \u201ccore\u201d dimensionality of input and output variables, and\nthereby also defines the contraction of the dimensions. The signature is\nrepresented by a string of the following format:\n\nThe formal syntax of signatures is as follows:\n\nNotes:\n\nHere are some examples of signatures:\n\nname\n\nsignature\n\ncommon usage\n\nadd\n\n`(),()->()`\n\nbinary ufunc\n\nsum1d\n\n`(i)->()`\n\nreduction\n\ninner1d\n\n`(i),(i)->()`\n\nvector-vector multiplication\n\nmatmat\n\n`(m,n),(n,p)->(m,p)`\n\nmatrix multiplication\n\nvecmat\n\n`(n),(n,p)->(p)`\n\nvector-matrix multiplication\n\nmatvec\n\n`(m,n),(n)->(m)`\n\nmatrix-vector multiplication\n\nmatmul\n\n`(m?,n),(n,p?)->(m?,p?)`\n\ncombination of the four above\n\nouter_inner\n\n`(i,t),(j,t)->(i,j)`\n\ninner over the last dimension, outer over the second to last, and\nloop/broadcast over the rest.\n\ncross1d\n\n`(3),(3)->(3)`\n\ncross product where the last dimension is frozen and must be 3\n\nThe last is an instance of freezing a core dimension and can be used to\nimprove ufunc performance\n\nThe current interface remains unchanged, and `PyUFunc_FromFuncAndData` can\nstill be used to implement (specialized) ufuncs, consisting of scalar\nelementary functions.\n\nOne can use `PyUFunc_FromFuncAndDataAndSignature` to declare a more general\nufunc. The argument list is the same as `PyUFunc_FromFuncAndData`, with an\nadditional argument specifying the signature as C string.\n\nFurthermore, the callback function is of the same type as before, `void\n(*foo)(char **args, intp *dimensions, intp *steps, void *func)`. When invoked,\n`args` is a list of length `nargs` containing the data of all input/output\narguments. For a scalar elementary function, `steps` is also of length\n`nargs`, denoting the strides used for the arguments. `dimensions` is a\npointer to a single integer defining the size of the axis to be looped over.\n\nFor a non-trivial signature, `dimensions` will also contain the sizes of the\ncore dimensions as well, starting at the second entry. Only one size is\nprovided for each unique dimension name and the sizes are given according to\nthe first occurrence of a dimension name in the signature.\n\nThe first `nargs` elements of `steps` remain the same as for scalar ufuncs.\nThe following elements contain the strides of all core dimensions for all\narguments in order.\n\nFor example, consider a ufunc with signature `(i,j),(i)->()`. In this case,\n`args` will contain three pointers to the data of the input/output arrays `a`,\n`b`, `c`. Furthermore, `dimensions` will be `[N, I, J]` to define the size of\n`N` of the loop and the sizes `I` and `J` for the core dimensions `i` and `j`.\nFinally, `steps` will be `[a_N, b_N, c_N, a_i, a_j, b_i]`, containing all\nnecessary strides.\n\n"}, {"name": "enum NPY_CASTING", "path": "reference/c-api/array#c.NPY_CASTING", "type": "Array API", "text": "\nNew in version 1.6.\n\nAn enumeration type indicating how permissive data conversions should be. This\nis used by the iterator added in NumPy 1.6, and is intended to be used more\nbroadly in a future version.\n\nOnly allow identical types.\n\nAllow identical and casts involving byte swapping.\n\nOnly allow casts which will not cause values to be rounded, truncated, or\notherwise changed.\n\nAllow any safe casts, and casts between types of the same kind. For example,\nfloat64 -> float32 is permitted with this rule.\n\nAllow any cast, no matter what kind of data loss may occur.\n\n"}, {"name": "enum NPY_CLIPMODE", "path": "reference/c-api/array#c.NPY_CLIPMODE", "type": "Array API", "text": "\nA variable type indicating the kind of clipping that should be applied in\ncertain functions.\n\nThe default for most operations, raises an exception if an index is out of\nbounds.\n\nClips an index to the valid range if it is out of bounds.\n\nWraps an index to the valid range if it is out of bounds.\n\n"}, {"name": "enum NPY_ORDER", "path": "reference/c-api/array#c.NPY_ORDER", "type": "Array API", "text": "\nAn enumeration type indicating the element order that an array should be\ninterpreted in. When a brand new array is created, generally only NPY_CORDER\nand NPY_FORTRANORDER are used, whereas when one or more inputs are provided,\nthe order can be based on them.\n\nFortran order if all the inputs are Fortran, C otherwise.\n\nC order.\n\nFortran order.\n\nAn order as close to the order of the inputs as possible, even if the input is\nin neither C nor Fortran order.\n\n"}, {"name": "enum NPY_SCALARKIND", "path": "reference/c-api/array#c.NPY_SCALARKIND", "type": "Array API", "text": "\nA special variable type indicating the number of \u201ckinds\u201d of scalars\ndistinguished in determining scalar-coercion rules. This variable can take on\nthe values:\n\nDefined to be the number of scalar kinds (not including `NPY_NOSCALAR`).\n\n"}, {"name": "enum NPY_SEARCHSIDE", "path": "reference/c-api/array#c.NPY_SEARCHSIDE", "type": "Array API", "text": "\nA variable type indicating whether the index returned should be that of the\nfirst suitable location (if `NPY_SEARCHLEFT`) or of the last (if\n`NPY_SEARCHRIGHT`).\n\n"}, {"name": "enum NPY_SELECTKIND", "path": "reference/c-api/array#c.NPY_SELECTKIND", "type": "Array API", "text": "\nA variable type indicating the selection algorithm being used.\n\n"}, {"name": "enumerator NPY_BOOL", "path": "reference/c-api/dtype#c.NPY_BOOL", "type": "Data Type API", "text": "\nThe enumeration value for the boolean type, stored as one byte. It may only be\nset to the values 0 and 1.\n\n"}, {"name": "enumerator NPY_BOOL_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_BOOL_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_BYTE", "path": "reference/c-api/dtype#c.NPY_BYTE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_CDOUBLE", "path": "reference/c-api/dtype#c.NPY_CDOUBLE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_CFLOAT", "path": "reference/c-api/dtype#c.NPY_CFLOAT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_CLIP", "path": "reference/c-api/array#c.NPY_CLIPMODE.NPY_CLIP", "type": "Array API", "text": "\nClips an index to the valid range if it is out of bounds.\n\n"}, {"name": "enumerator NPY_CLONGDOUBLE", "path": "reference/c-api/dtype#c.NPY_CLONGDOUBLE", "type": "Data Type API", "text": "\nThe enumeration value for a platform-specific complex floating point type\nwhich is made up of two NPY_LONGDOUBLE values.\n\n"}, {"name": "enumerator NPY_COMPLEX128", "path": "reference/c-api/dtype#c.NPY_COMPLEX128", "type": "Data Type API", "text": "\nThe enumeration value for a 128-bit/16-byte complex type made up of two\nNPY_DOUBLE values.\n\n"}, {"name": "enumerator NPY_COMPLEX64", "path": "reference/c-api/dtype#c.NPY_COMPLEX64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte complex type made up of two\nNPY_FLOAT values.\n\n"}, {"name": "enumerator NPY_COMPLEX_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_COMPLEX_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_CORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_CORDER", "type": "Array API", "text": "\nC order.\n\n"}, {"name": "enumerator NPY_DATETIME", "path": "reference/c-api/dtype#c.NPY_DATETIME", "type": "Data Type API", "text": "\nThe enumeration value for a data type which holds dates or datetimes with a\nprecision based on selectable date or time units.\n\n"}, {"name": "enumerator NPY_DEFAULT_TYPE", "path": "reference/c-api/dtype#c.NPY_DEFAULT_TYPE", "type": "Data Type API", "text": "\nThe default type to use when no dtype is explicitly specified, for example\nwhen calling np.zero(shape). This is equivalent to `NPY_DOUBLE`.\n\n"}, {"name": "enumerator NPY_DOUBLE", "path": "reference/c-api/dtype#c.NPY_DOUBLE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_EQUIV_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_EQUIV_CASTING", "type": "Array API", "text": "\nAllow identical and casts involving byte swapping.\n\n"}, {"name": "enumerator NPY_FLOAT", "path": "reference/c-api/dtype#c.NPY_FLOAT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_FLOAT16", "path": "reference/c-api/dtype#c.NPY_FLOAT16", "type": "Data Type API", "text": "\nThe enumeration value for a 16-bit/2-byte IEEE 754-2008 compatible floating\npoint type.\n\n"}, {"name": "enumerator NPY_FLOAT32", "path": "reference/c-api/dtype#c.NPY_FLOAT32", "type": "Data Type API", "text": "\nThe enumeration value for a 32-bit/4-byte IEEE 754 compatible floating point\ntype.\n\n"}, {"name": "enumerator NPY_FLOAT64", "path": "reference/c-api/dtype#c.NPY_FLOAT64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte IEEE 754 compatible floating point\ntype.\n\n"}, {"name": "enumerator NPY_FLOAT_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_FLOAT_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_FORTRANORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_FORTRANORDER", "type": "Array API", "text": "\nFortran order.\n\n"}, {"name": "enumerator NPY_HALF", "path": "reference/c-api/dtype#c.NPY_HALF", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_HEAPSORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_HEAPSORT", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_INT", "path": "reference/c-api/dtype#c.NPY_INT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_INT16", "path": "reference/c-api/dtype#c.NPY_INT16", "type": "Data Type API", "text": "\nThe enumeration value for a 16-bit/2-byte signed integer.\n\n"}, {"name": "enumerator NPY_INT32", "path": "reference/c-api/dtype#c.NPY_INT32", "type": "Data Type API", "text": "\nThe enumeration value for a 32-bit/4-byte signed integer.\n\n"}, {"name": "enumerator NPY_INT64", "path": "reference/c-api/dtype#c.NPY_INT64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte signed integer.\n\n"}, {"name": "enumerator NPY_INT8", "path": "reference/c-api/dtype#c.NPY_INT8", "type": "Data Type API", "text": "\nThe enumeration value for an 8-bit/1-byte signed integer.\n\n"}, {"name": "enumerator NPY_INTNEG_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_INTNEG_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_INTP", "path": "reference/c-api/dtype#c.NPY_INTP", "type": "Data Type API", "text": "\nThe enumeration value for a signed integer type which is the same size as a\n(void *) pointer. This is the type used by all arrays of indices.\n\n"}, {"name": "enumerator NPY_INTPOS_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_INTPOS_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_KEEPORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_KEEPORDER", "type": "Array API", "text": "\nAn order as close to the order of the inputs as possible, even if the input is\nin neither C nor Fortran order.\n\n"}, {"name": "enumerator NPY_LONG", "path": "reference/c-api/dtype#c.NPY_LONG", "type": "Data Type API", "text": "\nEquivalent to either NPY_INT or NPY_LONGLONG, depending on the platform.\n\n"}, {"name": "enumerator NPY_LONGDOUBLE", "path": "reference/c-api/dtype#c.NPY_LONGDOUBLE", "type": "Data Type API", "text": "\nThe enumeration value for a platform-specific floating point type which is at\nleast as large as NPY_DOUBLE, but larger on many platforms.\n\n"}, {"name": "enumerator NPY_LONGLONG", "path": "reference/c-api/dtype#c.NPY_LONGLONG", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_MASK", "path": "reference/c-api/dtype#c.NPY_MASK", "type": "Data Type API", "text": "\nThe enumeration value of the type used for masks, such as with the\n`NPY_ITER_ARRAYMASK` iterator flag. This is equivalent to `NPY_UINT8`.\n\n"}, {"name": "enumerator NPY_MERGESORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_MERGESORT", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_NSCALARKINDS", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_NSCALARKINDS", "type": "Array API", "text": "\nDefined to be the number of scalar kinds (not including `NPY_NOSCALAR`).\n\n"}, {"name": "enumerator NPY_NSORTS", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_NSORTS", "type": "Array API", "text": "\nDefined to be the number of sorts. It is fixed at three by the need for\nbackwards compatibility, and consequently `NPY_MERGESORT` and `NPY_STABLESORT`\nare aliased to each other and may refer to one of several stable sorting\nalgorithms depending on the data type.\n\n"}, {"name": "enumerator NPY_OBJECT", "path": "reference/c-api/dtype#c.NPY_OBJECT", "type": "Data Type API", "text": "\nThe enumeration value for references to arbitrary Python objects.\n\n"}, {"name": "enumerator NPY_OBJECT_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_OBJECT_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_SAFE_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_SAFE_CASTING", "type": "Array API", "text": "\nOnly allow casts which will not cause values to be rounded, truncated, or\notherwise changed.\n\n"}, {"name": "enumerator NPY_SAME_KIND_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_SAME_KIND_CASTING", "type": "Array API", "text": "\nAllow any safe casts, and casts between types of the same kind. For example,\nfloat64 -> float32 is permitted with this rule.\n\n"}, {"name": "enumerator NPY_SEARCHRIGHT", "path": "reference/c-api/array#c.NPY_SEARCHSIDE.NPY_SEARCHRIGHT", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_SHORT", "path": "reference/c-api/dtype#c.NPY_SHORT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_STABLESORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_STABLESORT", "type": "Array API", "text": "\nUsed as an alias of `NPY_MERGESORT` and vica versa.\n\n"}, {"name": "enumerator NPY_STRING", "path": "reference/c-api/dtype#c.NPY_STRING", "type": "Data Type API", "text": "\nThe enumeration value for ASCII strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\n"}, {"name": "enumerator NPY_TIMEDELTA", "path": "reference/c-api/dtype#c.NPY_TIMEDELTA", "type": "Data Type API", "text": "\nThe enumeration value for a data type which holds lengths of times in integers\nof selectable date or time units.\n\n"}, {"name": "enumerator NPY_TYPES", "path": "reference/c-api/dtype", "type": "Data Type API", "text": "\nThe standard array can have 24 different data types (and has some support for\nadding your own types). These data types all have an enumerated type, an\nenumerated type-character, and a corresponding array scalar Python type object\n(placed in a hierarchy). There are also standard C typedefs to make it easier\nto manipulate elements of the given data type. For the numeric types, there\nare also bit-width equivalent C typedefs and named typenumbers that make it\neasier to select the precision desired.\n\nWarning\n\nThe names for the types in c code follows c naming conventions more closely.\nThe Python names for these types follow Python conventions. Thus, `NPY_FLOAT`\npicks up a 32-bit float in C, but `numpy.float_` in Python corresponds to a\n64-bit double. The bit-width names can be used in both Python and C for\nclarity.\n\nThere is a list of enumerated types defined providing the basic 24 data types\nplus some useful generic names. Whenever the code requires a type number, one\nof these enumerated types is requested. The types are all called `NPY_{NAME}`:\n\nThe enumeration value for the boolean type, stored as one byte. It may only be\nset to the values 0 and 1.\n\nThe enumeration value for an 8-bit/1-byte signed integer.\n\nThe enumeration value for a 16-bit/2-byte signed integer.\n\nThe enumeration value for a 32-bit/4-byte signed integer.\n\nEquivalent to either NPY_INT or NPY_LONGLONG, depending on the platform.\n\nThe enumeration value for a 64-bit/8-byte signed integer.\n\nThe enumeration value for an 8-bit/1-byte unsigned integer.\n\nThe enumeration value for a 16-bit/2-byte unsigned integer.\n\nThe enumeration value for a 32-bit/4-byte unsigned integer.\n\nEquivalent to either NPY_UINT or NPY_ULONGLONG, depending on the platform.\n\nThe enumeration value for a 64-bit/8-byte unsigned integer.\n\nThe enumeration value for a 16-bit/2-byte IEEE 754-2008 compatible floating\npoint type.\n\nThe enumeration value for a 32-bit/4-byte IEEE 754 compatible floating point\ntype.\n\nThe enumeration value for a 64-bit/8-byte IEEE 754 compatible floating point\ntype.\n\nThe enumeration value for a platform-specific floating point type which is at\nleast as large as NPY_DOUBLE, but larger on many platforms.\n\nThe enumeration value for a 64-bit/8-byte complex type made up of two\nNPY_FLOAT values.\n\nThe enumeration value for a 128-bit/16-byte complex type made up of two\nNPY_DOUBLE values.\n\nThe enumeration value for a platform-specific complex floating point type\nwhich is made up of two NPY_LONGDOUBLE values.\n\nThe enumeration value for a data type which holds dates or datetimes with a\nprecision based on selectable date or time units.\n\nThe enumeration value for a data type which holds lengths of times in integers\nof selectable date or time units.\n\nThe enumeration value for ASCII strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\nThe enumeration value for UCS4 strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\nThe enumeration value for references to arbitrary Python objects.\n\nPrimarily used to hold struct dtypes, but can contain arbitrary binary data.\n\nSome useful aliases of the above types are\n\nThe enumeration value for a signed integer type which is the same size as a\n(void *) pointer. This is the type used by all arrays of indices.\n\nThe enumeration value for an unsigned integer type which is the same size as a\n(void *) pointer.\n\nThe enumeration value of the type used for masks, such as with the\n`NPY_ITER_ARRAYMASK` iterator flag. This is equivalent to `NPY_UINT8`.\n\nThe default type to use when no dtype is explicitly specified, for example\nwhen calling np.zero(shape). This is equivalent to `NPY_DOUBLE`.\n\nOther useful related constants are\n\nThe total number of built-in NumPy types. The enumeration covers the range\nfrom 0 to NPY_NTYPES-1.\n\nA signal value guaranteed not to be a valid type enumeration number.\n\nThe start of type numbers used for Custom Data types.\n\nThe various character codes indicating certain types are also part of an\nenumerated list. References to type characters (should they be needed at all)\nshould always use these enumerations. The form of them is `NPY_{NAME}LTR`\nwhere `{NAME}` can be\n\nBOOL, BYTE, UBYTE, SHORT, USHORT, INT, UINT, LONG, ULONG, LONGLONG, ULONGLONG,\nHALF, FLOAT, DOUBLE, LONGDOUBLE, CFLOAT, CDOUBLE, CLONGDOUBLE, DATETIME,\nTIMEDELTA, OBJECT, STRING, VOID\n\nINTP, UINTP\n\nGENBOOL, SIGNED, UNSIGNED, FLOATING, COMPLEX\n\nThe latter group of `{NAME}s` corresponds to letters used in the array\ninterface typestring specification.\n\nThese are defined for `{bits}` = 8, 16, 32, 64, 128, and 256 and provide the\nmaximum (minimum) value of the corresponding (unsigned) integer type. Note:\nthe actual integer type may not be available on all platforms (i.e. 128-bit\nand 256-bit integers are rare).\n\nThis is defined for `{type}` = BYTE, SHORT, INT, LONG, LONGLONG, INTP\n\nThis is defined for all defined for `{type}` = BYTE, UBYTE, SHORT, USHORT,\nINT, UINT, LONG, ULONG, LONGLONG, ULONGLONG, INTP, UINTP\n\nAll `NPY_SIZEOF_{CTYPE}` constants have corresponding `NPY_BITSOF_{CTYPE}`\nconstants defined. The `NPY_BITSOF_{CTYPE}` constants provide the number of\nbits in the data type. Specifically, the available `{CTYPE}s` are\n\nBOOL, CHAR, SHORT, INT, LONG, LONGLONG, FLOAT, DOUBLE, LONGDOUBLE\n\nAll of the numeric data types (integer, floating point, and complex) have\nconstants that are defined to be a specific enumerated type number. Exactly\nwhich enumerated type a bit-width type refers to is platform dependent. In\nparticular, the constants available are `PyArray_{NAME}{BITS}` where `{NAME}`\nis INT, UINT, FLOAT, COMPLEX and `{BITS}` can be 8, 16, 32, 64, 80, 96, 128,\n160, 192, 256, and 512. Obviously not all bit-widths are available on all\nplatforms for all the kinds of numeric types. Commonly 8-, 16-, 32-, 64-bit\nintegers; 32-, 64-bit floats; and 64-, 128-bit complex types are available.\n\nThe constants NPY_INTP and NPY_UINTP refer to an enumerated integer type that\nis large enough to hold a pointer on the platform. Index arrays should always\nbe converted to NPY_INTP , because the dimension of the array is of type\nnpy_intp.\n\nThere are standard variable types for each of the numeric data types and the\nbool data type. Some of these are already available in the C-specification.\nYou can create variables in extension code with these types.\n\nunsigned char; The constants `NPY_FALSE` and `NPY_TRUE` are also defined.\n\nUnsigned versions of the integers can be defined by pre-pending a \u2018u\u2019 to the\nfront of the integer name.\n\nchar\n\nunsigned char\n\nshort\n\nunsigned short\n\nint\n\nunsigned int\n\n16-bit integer\n\n16-bit unsigned integer\n\n32-bit integer\n\n32-bit unsigned integer\n\n64-bit integer\n\n64-bit unsigned integer\n\nlong int\n\nunsigned long int\n\nlong long int\n\nunsigned long long int\n\nPy_intptr_t (an integer that is the size of a pointer on the platform).\n\nunsigned Py_intptr_t (an integer that is the size of a pointer on the\nplatform).\n\n16-bit float\n\n32-bit float\n\n32-bit complex float\n\n64-bit double\n\n64-bit complex double\n\nlong double\n\nlong complex double\n\ncomplex types are structures with .real and .imag members (in that order).\n\nThere are also typedefs for signed integers, unsigned integers, floating\npoint, and complex floating point types of specific bit- widths. The available\ntype names are\n\n`npy_int{bits}`, `npy_uint{bits}`, `npy_float{bits}`, and `npy_complex{bits}`\n\nwhere `{bits}` is the number of bits in the type and can be 8, 16, 32, 64,\n128, and 256 for integer types; 16, 32 , 64, 80, 96, 128, and 256 for\nfloating-point types; and 32, 64, 128, 160, 192, and 512 for complex-valued\ntypes. Which bit-widths are available is platform dependent. The bolded bit-\nwidths are usually available on all platforms.\n\nFor help in printing, the following strings are defined as the correct format\nspecifier in printf and related commands.\n\n"}, {"name": "enumerator NPY_UBYTE", "path": "reference/c-api/dtype#c.NPY_UBYTE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_UINT", "path": "reference/c-api/dtype#c.NPY_UINT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_UINT16", "path": "reference/c-api/dtype#c.NPY_UINT16", "type": "Data Type API", "text": "\nThe enumeration value for a 16-bit/2-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINT32", "path": "reference/c-api/dtype#c.NPY_UINT32", "type": "Data Type API", "text": "\nThe enumeration value for a 32-bit/4-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINT64", "path": "reference/c-api/dtype#c.NPY_UINT64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINT8", "path": "reference/c-api/dtype#c.NPY_UINT8", "type": "Data Type API", "text": "\nThe enumeration value for an 8-bit/1-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINTP", "path": "reference/c-api/dtype#c.NPY_UINTP", "type": "Data Type API", "text": "\nThe enumeration value for an unsigned integer type which is the same size as a\n(void *) pointer.\n\n"}, {"name": "enumerator NPY_ULONG", "path": "reference/c-api/dtype#c.NPY_ULONG", "type": "Data Type API", "text": "\nEquivalent to either NPY_UINT or NPY_ULONGLONG, depending on the platform.\n\n"}, {"name": "enumerator NPY_ULONGLONG", "path": "reference/c-api/dtype#c.NPY_ULONGLONG", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_UNICODE", "path": "reference/c-api/dtype#c.NPY_UNICODE", "type": "Data Type API", "text": "\nThe enumeration value for UCS4 strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\n"}, {"name": "enumerator NPY_UNSAFE_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_UNSAFE_CASTING", "type": "Array API", "text": "\nAllow any cast, no matter what kind of data loss may occur.\n\n"}, {"name": "enumerator NPY_USHORT", "path": "reference/c-api/dtype#c.NPY_USHORT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_VOID", "path": "reference/c-api/dtype#c.NPY_VOID", "type": "Data Type API", "text": "\nPrimarily used to hold struct dtypes, but can contain arbitrary binary data.\n\n"}, {"name": "enumerator NPY_WRAP", "path": "reference/c-api/array#c.NPY_CLIPMODE.NPY_WRAP", "type": "Array API", "text": "\nWraps an index to the valid range if it is out of bounds.\n\n"}, {"name": "errstate.__call__()", "path": "reference/generated/numpy.errstate.__call__", "type": "numpy.errstate.__call__", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "exec_command", "path": "reference/generated/numpy.distutils.exec_command", "type": "numpy.distutils.exec_command", "text": "\nexec_command\n\nImplements exec_command function that is (almost) equivalent to\ncommands.getstatusoutput function but on NT, DOS systems the returned status\nis actually correct (though, the returned status values may be different by a\nfactor). In addition, exec_command takes keyword arguments for (re-)defining\nenvironment variables.\n\nProvides functions:\n\nin the modified environment.\n\nvariable PATH. Equivalent to posix `which` command.\n\nAuthor: Pearu Peterson <pearu@cens.ioc.ee> Created: 11 January 2003\n\nRequires: Python 2.x\n\nSuccessfully tested on:\n\nos.name\n\nsys.platform\n\ncomments\n\nposix\n\nlinux2\n\nDebian (sid) Linux, Python 2.1.3+, 2.2.3+, 2.3.3 PyCrust 0.9.3, Idle 1.0.2\n\nposix\n\nlinux2\n\nRed Hat 9 Linux, Python 2.1.3, 2.2.2, 2.3.2\n\nposix\n\nsunos5\n\nSunOS 5.9, Python 2.2, 2.3.2\n\nposix\n\ndarwin\n\nDarwin 7.2.0, Python 2.3\n\nnt\n\nwin32\n\nWindows Me Python 2.3(EE), Idle 1.0, PyCrust 0.7.2 Python 2.1.1 Idle 0.8\n\nnt\n\nwin32\n\nWindows 98, Python 2.1.1. Idle 0.8\n\nnt\n\nwin32\n\nCygwin 98-4.10, Python 2.1.1(MSC) - echo tests fail i.e. redefining\nenvironment variables may not work. FIXED: don\u2019t use cygwin echo! Comment:\nalso `cmd /c echo` will not work but redefining environment variables do work.\n\nposix\n\ncygwin\n\nCygwin 98-4.10, Python 2.3.3(cygming special)\n\nnt\n\nwin32\n\nWindows XP, Python 2.3.3\n\nKnown bugs:\n\n`exec_command`(command[, execute_in, ...])\n\nReturn (status,output) of executed command.\n\n`filepath_from_subprocess_output`(output)\n\nConvert `bytes` in the encoding used by a subprocess into a filesystem-\nappropriate `str`.\n\n`find_executable`(exe[, path, _cache])\n\nReturn full path of a executable or None.\n\n`forward_bytes_to_stdout`(val)\n\nForward bytes from a subprocess call to the console, without attempting to\ndecode them.\n\n`get_pythonexe`()\n\n`temp_file_name`()\n\n"}, {"name": "Extending", "path": "reference/random/extending", "type": "Examples of using Numba, Cython, CFFI", "text": "\nThe BitGenerators have been designed to be extendable using standard tools for\nhigh-performance Python \u2013 numba and Cython. The `Generator` object can also be\nused with user-provided BitGenerators as long as these export a small set of\nrequired functions.\n\nNumba can be used with either CTypes or CFFI. The current iteration of the\nBitGenerators all export a small set of functions through both interfaces.\n\nThis example shows how numba can be used to produce gaussian samples using a\npure Python implementation which is then compiled. The random numbers are\nprovided by `ctypes.next_double`.\n\nBoth CTypes and CFFI allow the more complicated distributions to be used\ndirectly in Numba after compiling the file distributions.c into a `DLL` or\n`so`. An example showing the use of a more complicated distribution is in the\n`examples` section below.\n\nCython can be used to unpack the `PyCapsule` provided by a BitGenerator. This\nexample uses `PCG64` and the example from above. The usual caveats for writing\nhigh-performance code using Cython \u2013 removing bounds checks and wrap around,\nproviding array alignment information \u2013 still apply.\n\nThe BitGenerator can also be directly accessed using the members of the\n`bitgen_t` struct.\n\nCython can be used to directly access the functions in\n`numpy/random/c_distributions.pxd`. This requires linking with the `npyrandom`\nlibrary located in `numpy/random/lib`.\n\nSee Extending numpy.random via Cython for the complete listings of these\nexamples and a minimal `setup.py` to build the c-extension modules.\n\nCFFI can be used to directly access the functions in\n`include/numpy/random/distributions.h`. Some \u201cmassaging\u201d of the header file is\nrequired:\n\nOnce the header is parsed by `ffi.cdef`, the functions can be accessed\ndirectly from the `_generator` shared object, using the `BitGenerator.cffi`\ninterface.\n\n`Generator` can be used with user-provided `BitGenerator`s. The simplest way\nto write a new BitGenerator is to examine the pyx file of one of the existing\nBitGenerators. The key structure that must be provided is the `capsule` which\ncontains a `PyCapsule` to a struct pointer of type `bitgen_t`,\n\nwhich provides 5 pointers. The first is an opaque pointer to the data\nstructure used by the BitGenerators. The next three are function pointers\nwhich return the next 64- and 32-bit unsigned integers, the next random double\nand the next raw value. This final function is used for testing and so can be\nset to the next 64-bit unsigned integer function if not needed. Functions\ninside `Generator` use this structure as in\n\n"}, {"name": "Extending numpy.random via Cython", "path": "reference/random/examples/cython/index", "type": "Cython", "text": "\n\n"}, {"name": "Extending via CFFI", "path": "reference/random/examples/cffi", "type": "CFFI", "text": "\n\n"}, {"name": "Extending via Numba", "path": "reference/random/examples/numba", "type": "Numba", "text": "\n\n"}, {"name": "Extending via Numba and CFFI", "path": "reference/random/examples/numba_cffi", "type": "CFFI + Numba", "text": "\n\n"}, {"name": "extending.pyx", "path": "reference/random/examples/cython/extending.pyx", "type": "Cython", "text": "\n\n"}, {"name": "extending_distributions.pyx", "path": "reference/random/examples/cython/extending_distributions.pyx", "type": "Cython", "text": "\n\n"}, {"name": "F2PY user guide and reference manual", "path": "f2py/index", "type": "F2PY user guide and reference manual", "text": "\nThe purpose of the `F2PY` \u2013Fortran to Python interface generator\u2013 utility is\nto provide a connection between Python and Fortran languages. F2PY is a part\nof NumPy (`numpy.f2py`) and also available as a standalone command line tool\n`f2py` when `numpy` is installed that facilitates creating/building Python\nC/API extension modules that make it possible\n\nfrom Python.\n\n"}, {"name": "fft.fft()", "path": "reference/generated/numpy.fft.fft", "type": "numpy.fft.fft", "text": "\nCompute the one-dimensional discrete Fourier Transform.\n\nThis function computes the one-dimensional n-point discrete Fourier Transform\n(DFT) with the efficient Fast Fourier Transform (FFT) algorithm [CT].\n\nInput array, can be complex.\n\nLength of the transformed axis of the output. If `n` is smaller than the\nlength of the input, the input is cropped. If it is larger, the input is\npadded with zeros. If `n` is not given, the length of the input along the axis\nspecified by `axis` is used.\n\nAxis over which to compute the FFT. If not given, the last axis is used.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nfor definition of the DFT and conventions used.\n\nThe inverse of `fft`.\n\nThe two-dimensional FFT.\n\nThe n-dimensional FFT.\n\nThe n-dimensional FFT of real input.\n\nFrequency bins for given FFT parameters.\n\nFFT (Fast Fourier Transform) refers to a way the discrete Fourier Transform\n(DFT) can be calculated efficiently, by using symmetries in the calculated\nterms. The symmetry is highest when `n` is a power of 2, and the transform is\ntherefore most efficient for these sizes.\n\nThe DFT is defined, with the conventions used in this implementation, in the\ndocumentation for the `numpy.fft` module.\n\nCooley, James W., and John W. Tukey, 1965, \u201cAn algorithm for the machine\ncalculation of complex Fourier series,\u201d Math. Comput. 19: 297-301.\n\nIn this example, real input has an FFT which is Hermitian, i.e., symmetric in\nthe real part and anti-symmetric in the imaginary part, as described in the\n`numpy.fft` documentation:\n\n"}, {"name": "fft.fft2()", "path": "reference/generated/numpy.fft.fft2", "type": "numpy.fft.fft2", "text": "\nCompute the 2-dimensional discrete Fourier Transform.\n\nThis function computes the n-dimensional discrete Fourier Transform over any\naxes in an M-dimensional array by means of the Fast Fourier Transform (FFT).\nBy default, the transform is computed over the last two axes of the input\narray, i.e., a 2-dimensional FFT.\n\nInput array, can be complex\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). This corresponds to `n` for `fft(x, n)`. Along\neach axis, if the given shape is smaller than that of the input, the input is\ncropped. If it is larger, the input is padded with zeros. if `s` is not given,\nthe shape of the input along the axes specified by `axes` is used.\n\nAxes over which to compute the FFT. If not given, the last two axes are used.\nA repeated index in `axes` means the transform over that axis is performed\nmultiple times. A one-element sequence means that a one-dimensional FFT is\nperformed.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or the last two axes if `axes` is not given.\n\nIf `s` and `axes` have different length, or `axes` not given and `len(s) !=\n2`.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe inverse two-dimensional FFT.\n\nThe one-dimensional FFT.\n\nThe n-dimensional FFT.\n\nShifts zero-frequency terms to the center of the array. For two-dimensional\ninput, swaps first and third quadrants, and second and fourth quadrants.\n\n`fft2` is just `fftn` with a different default for `axes`.\n\nThe output, analogously to `fft`, contains the term for zero frequency in the\nlow-order corner of the transformed axes, the positive frequency terms in the\nfirst half of these axes, the term for the Nyquist frequency in the middle of\nthe axes and the negative frequency terms in the second half of the axes, in\norder of decreasingly negative frequency.\n\nSee `fftn` for details and a plotting example, and `numpy.fft` for definitions\nand conventions used.\n\n"}, {"name": "fft.fftfreq()", "path": "reference/generated/numpy.fft.fftfreq", "type": "numpy.fft.fftfreq", "text": "\nReturn the Discrete Fourier Transform sample frequencies.\n\nThe returned float array `f` contains the frequency bin centers in cycles per\nunit of the sample spacing (with zero at the start). For instance, if the\nsample spacing is in seconds, then the frequency unit is cycles/second.\n\nGiven a window length `n` and a sample spacing `d`:\n\nWindow length.\n\nSample spacing (inverse of the sampling rate). Defaults to 1.\n\nArray of length `n` containing the sample frequencies.\n\n"}, {"name": "fft.fftn()", "path": "reference/generated/numpy.fft.fftn", "type": "numpy.fft.fftn", "text": "\nCompute the N-dimensional discrete Fourier Transform.\n\nThis function computes the N-dimensional discrete Fourier Transform over any\nnumber of axes in an M-dimensional array by means of the Fast Fourier\nTransform (FFT).\n\nInput array, can be complex.\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). This corresponds to `n` for `fft(x, n)`. Along any\naxis, if the given shape is smaller than that of the input, the input is\ncropped. If it is larger, the input is padded with zeros. if `s` is not given,\nthe shape of the input along the axes specified by `axes` is used.\n\nAxes over which to compute the FFT. If not given, the last `len(s)` axes are\nused, or all axes if `s` is also not specified. Repeated indices in `axes`\nmeans that the transform over that axis is performed multiple times.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` and `a`, as explained in the parameters\nsection above.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe inverse of `fftn`, the inverse n-dimensional FFT.\n\nThe one-dimensional FFT, with definitions and conventions used.\n\nThe n-dimensional FFT of real input.\n\nThe two-dimensional FFT.\n\nShifts zero-frequency terms to centre of array\n\nThe output, analogously to `fft`, contains the term for zero frequency in the\nlow-order corner of all axes, the positive frequency terms in the first half\nof all axes, the term for the Nyquist frequency in the middle of all axes and\nthe negative frequency terms in the second half of all axes, in order of\ndecreasingly negative frequency.\n\nSee `numpy.fft` for details, definitions and conventions used.\n\n"}, {"name": "fft.fftshift()", "path": "reference/generated/numpy.fft.fftshift", "type": "numpy.fft.fftshift", "text": "\nShift the zero-frequency component to the center of the spectrum.\n\nThis function swaps half-spaces for all axes listed (defaults to all). Note\nthat `y[0]` is the Nyquist component only if `len(x)` is even.\n\nInput array.\n\nAxes over which to shift. Default is None, which shifts all axes.\n\nThe shifted array.\n\nSee also\n\nThe inverse of `fftshift`.\n\nShift the zero-frequency component only along the second axis:\n\n"}, {"name": "fft.hfft()", "path": "reference/generated/numpy.fft.hfft", "type": "numpy.fft.hfft", "text": "\nCompute the FFT of a signal that has Hermitian symmetry, i.e., a real\nspectrum.\n\nThe input array.\n\nLength of the transformed axis of the output. For `n` output points, `n//2 +\n1` input points are necessary. If the input is longer than this, it is\ncropped. If it is shorter than this, it is padded with zeros. If `n` is not\ngiven, it is taken to be `2*(m-1)` where `m` is the length of the input along\nthe axis specified by `axis`.\n\nAxis over which to compute the FFT. If not given, the last axis is used.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. The length of the\ntransformed axis is `n`, or, if `n` is not given, `2*m - 2` where `m` is the\nlength of the transformed axis of the input. To get an odd number of output\npoints, `n` must be specified, for instance as `2*m - 1` in the typical case,\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nCompute the one-dimensional FFT for real input.\n\nThe inverse of `hfft`.\n\n`hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the opposite\ncase: here the signal has Hermitian symmetry in the time domain and is real in\nthe frequency domain. So here it\u2019s `hfft` for which you must supply the length\nof the result if it is to be odd.\n\nThe correct interpretation of the hermitian input depends on the length of the\noriginal data, as given by `n`. This is because each input shape could\ncorrespond to either an odd or even length signal. By default, `hfft` assumes\nan even output length which puts the last entry at the Nyquist frequency;\naliasing with its symmetric counterpart. By Hermitian symmetry, the value is\nthus treated as purely real. To avoid losing information, the shape of the\nfull signal must be given.\n\n"}, {"name": "fft.ifft()", "path": "reference/generated/numpy.fft.ifft", "type": "numpy.fft.ifft", "text": "\nCompute the one-dimensional inverse discrete Fourier Transform.\n\nThis function computes the inverse of the one-dimensional n-point discrete\nFourier transform computed by `fft`. In other words, `ifft(fft(a)) == a` to\nwithin numerical accuracy. For a general description of the algorithm and\ndefinitions, see `numpy.fft`.\n\nThe input should be ordered in the same way as is returned by `fft`, i.e.,\n\nFor an even number of input points, `A[n//2]` represents the sum of the values\nat the positive and negative Nyquist frequencies, as the two are aliased\ntogether. See `numpy.fft` for details.\n\nInput array, can be complex.\n\nLength of the transformed axis of the output. If `n` is smaller than the\nlength of the input, the input is cropped. If it is larger, the input is\npadded with zeros. If `n` is not given, the length of the input along the axis\nspecified by `axis` is used. See notes about padding issues.\n\nAxis over which to compute the inverse DFT. If not given, the last axis is\nused.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nAn introduction, with definitions and general explanations.\n\nThe one-dimensional (forward) FFT, of which `ifft` is the inverse\n\nThe two-dimensional inverse FFT.\n\nThe n-dimensional inverse FFT.\n\nIf the input parameter `n` is larger than the size of the input, the input is\npadded by appending zeros at the end. Even though this is the common approach,\nit might lead to surprising results. If a different padding is desired, it\nmust be performed before calling `ifft`.\n\nCreate and plot a band-limited signal with random phases:\n\n"}, {"name": "fft.ifft2()", "path": "reference/generated/numpy.fft.ifft2", "type": "numpy.fft.ifft2", "text": "\nCompute the 2-dimensional inverse discrete Fourier Transform.\n\nThis function computes the inverse of the 2-dimensional discrete Fourier\nTransform over any number of axes in an M-dimensional array by means of the\nFast Fourier Transform (FFT). In other words, `ifft2(fft2(a)) == a` to within\nnumerical accuracy. By default, the inverse transform is computed over the\nlast two axes of the input array.\n\nThe input, analogously to `ifft`, should be ordered in the same way as is\nreturned by `fft2`, i.e. it should have the term for zero frequency in the\nlow-order corner of the two axes, the positive frequency terms in the first\nhalf of these axes, the term for the Nyquist frequency in the middle of the\naxes and the negative frequency terms in the second half of both axes, in\norder of decreasingly negative frequency.\n\nInput array, can be complex.\n\nShape (length of each axis) of the output (`s[0]` refers to axis 0, `s[1]` to\naxis 1, etc.). This corresponds to `n` for `ifft(x, n)`. Along each axis, if\nthe given shape is smaller than that of the input, the input is cropped. If it\nis larger, the input is padded with zeros. if `s` is not given, the shape of\nthe input along the axes specified by `axes` is used. See notes for issue on\n`ifft` zero padding.\n\nAxes over which to compute the FFT. If not given, the last two axes are used.\nA repeated index in `axes` means the transform over that axis is performed\nmultiple times. A one-element sequence means that a one-dimensional FFT is\nperformed.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or the last two axes if `axes` is not given.\n\nIf `s` and `axes` have different length, or `axes` not given and `len(s) !=\n2`.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe forward 2-dimensional FFT, of which `ifft2` is the inverse.\n\nThe inverse of the n-dimensional FFT.\n\nThe one-dimensional FFT.\n\nThe one-dimensional inverse FFT.\n\n`ifft2` is just `ifftn` with a different default for `axes`.\n\nSee `ifftn` for details and a plotting example, and `numpy.fft` for definition\nand conventions used.\n\nZero-padding, analogously with `ifft`, is performed by appending zeros to the\ninput along the specified dimension. Although this is the common approach, it\nmight lead to surprising results. If another form of zero padding is desired,\nit must be performed before `ifft2` is called.\n\n"}, {"name": "fft.ifftn()", "path": "reference/generated/numpy.fft.ifftn", "type": "numpy.fft.ifftn", "text": "\nCompute the N-dimensional inverse discrete Fourier Transform.\n\nThis function computes the inverse of the N-dimensional discrete Fourier\nTransform over any number of axes in an M-dimensional array by means of the\nFast Fourier Transform (FFT). In other words, `ifftn(fftn(a)) == a` to within\nnumerical accuracy. For a description of the definitions and conventions used,\nsee `numpy.fft`.\n\nThe input, analogously to `ifft`, should be ordered in the same way as is\nreturned by `fftn`, i.e. it should have the term for zero frequency in all\naxes in the low-order corner, the positive frequency terms in the first half\nof all axes, the term for the Nyquist frequency in the middle of all axes and\nthe negative frequency terms in the second half of all axes, in order of\ndecreasingly negative frequency.\n\nInput array, can be complex.\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). This corresponds to `n` for `ifft(x, n)`. Along\nany axis, if the given shape is smaller than that of the input, the input is\ncropped. If it is larger, the input is padded with zeros. if `s` is not given,\nthe shape of the input along the axes specified by `axes` is used. See notes\nfor issue on `ifft` zero padding.\n\nAxes over which to compute the IFFT. If not given, the last `len(s)` axes are\nused, or all axes if `s` is also not specified. Repeated indices in `axes`\nmeans that the inverse transform over that axis is performed multiple times.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` or `a`, as explained in the parameters\nsection above.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe forward n-dimensional FFT, of which `ifftn` is the inverse.\n\nThe one-dimensional inverse FFT.\n\nThe two-dimensional inverse FFT.\n\nUndoes `fftshift`, shifts zero-frequency terms to beginning of array.\n\nSee `numpy.fft` for definitions and conventions used.\n\nZero-padding, analogously with `ifft`, is performed by appending zeros to the\ninput along the specified dimension. Although this is the common approach, it\nmight lead to surprising results. If another form of zero padding is desired,\nit must be performed before `ifftn` is called.\n\nCreate and plot an image with band-limited frequency content:\n\n"}, {"name": "fft.ifftshift()", "path": "reference/generated/numpy.fft.ifftshift", "type": "numpy.fft.ifftshift", "text": "\nThe inverse of `fftshift`. Although identical for even-length `x`, the\nfunctions differ by one sample for odd-length `x`.\n\nInput array.\n\nAxes over which to calculate. Defaults to None, which shifts all axes.\n\nThe shifted array.\n\nSee also\n\nShift zero-frequency component to the center of the spectrum.\n\n"}, {"name": "fft.ihfft()", "path": "reference/generated/numpy.fft.ihfft", "type": "numpy.fft.ihfft", "text": "\nCompute the inverse FFT of a signal that has Hermitian symmetry.\n\nInput array.\n\nLength of the inverse FFT, the number of points along transformation axis in\nthe input to use. If `n` is smaller than the length of the input, the input is\ncropped. If it is larger, the input is padded with zeros. If `n` is not given,\nthe length of the input along the axis specified by `axis` is used.\n\nAxis over which to compute the inverse FFT. If not given, the last axis is\nused.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. The length of the\ntransformed axis is `n//2 + 1`.\n\nSee also\n\n`hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the opposite\ncase: here the signal has Hermitian symmetry in the time domain and is real in\nthe frequency domain. So here it\u2019s `hfft` for which you must supply the length\nof the result if it is to be odd:\n\n"}, {"name": "fft.irfft()", "path": "reference/generated/numpy.fft.irfft", "type": "numpy.fft.irfft", "text": "\nComputes the inverse of `rfft`.\n\nThis function computes the inverse of the one-dimensional n-point discrete\nFourier Transform of real input computed by `rfft`. In other words,\n`irfft(rfft(a), len(a)) == a` to within numerical accuracy. (See Notes below\nfor why `len(a)` is necessary here.)\n\nThe input is expected to be in the form returned by `rfft`, i.e. the real\nzero-frequency term followed by the complex positive frequency terms in order\nof increasing frequency. Since the discrete Fourier Transform of real input is\nHermitian-symmetric, the negative frequency terms are taken to be the complex\nconjugates of the corresponding positive frequency terms.\n\nThe input array.\n\nLength of the transformed axis of the output. For `n` output points, `n//2+1`\ninput points are necessary. If the input is longer than this, it is cropped.\nIf it is shorter than this, it is padded with zeros. If `n` is not given, it\nis taken to be `2*(m-1)` where `m` is the length of the input along the axis\nspecified by `axis`.\n\nAxis over which to compute the inverse FFT. If not given, the last axis is\nused.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. The length of the\ntransformed axis is `n`, or, if `n` is not given, `2*(m-1)` where `m` is the\nlength of the transformed axis of the input. To get an odd number of output\npoints, `n` must be specified.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nFor definition of the DFT and conventions used.\n\nThe one-dimensional FFT of real input, of which `irfft` is inverse.\n\nThe one-dimensional FFT.\n\nThe inverse of the two-dimensional FFT of real input.\n\nThe inverse of the n-dimensional FFT of real input.\n\nReturns the real valued `n`-point inverse discrete Fourier transform of `a`,\nwhere `a` contains the non-negative frequency terms of a Hermitian-symmetric\nsequence. `n` is the length of the result, not the input.\n\nIf you specify an `n` such that `a` must be zero-padded or truncated, the\nextra/removed values will be added/removed at high frequencies. One can thus\nresample a series to `m` points via Fourier interpolation by: `a_resamp =\nirfft(rfft(a), m)`.\n\nThe correct interpretation of the hermitian input depends on the length of the\noriginal data, as given by `n`. This is because each input shape could\ncorrespond to either an odd or even length signal. By default, `irfft` assumes\nan even output length which puts the last entry at the Nyquist frequency;\naliasing with its symmetric counterpart. By Hermitian symmetry, the value is\nthus treated as purely real. To avoid losing information, the correct length\nof the real input must be given.\n\nNotice how the last term in the input to the ordinary `ifft` is the complex\nconjugate of the second term, and the output has zero imaginary part\neverywhere. When calling `irfft`, the negative frequencies are not specified,\nand the output array is purely real.\n\n"}, {"name": "fft.irfft2()", "path": "reference/generated/numpy.fft.irfft2", "type": "numpy.fft.irfft2", "text": "\nComputes the inverse of `rfft2`.\n\nThe input array\n\nShape of the real output to the inverse FFT.\n\nThe axes over which to compute the inverse fft. Default is the last two axes.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe result of the inverse real 2-D FFT.\n\nSee also\n\nThe forward two-dimensional FFT of real input, of which `irfft2` is the\ninverse.\n\nThe one-dimensional FFT for real input.\n\nThe inverse of the one-dimensional FFT of real input.\n\nCompute the inverse of the N-dimensional FFT of real input.\n\nThis is really `irfftn` with different defaults. For more details see\n`irfftn`.\n\n"}, {"name": "fft.irfftn()", "path": "reference/generated/numpy.fft.irfftn", "type": "numpy.fft.irfftn", "text": "\nComputes the inverse of `rfftn`.\n\nThis function computes the inverse of the N-dimensional discrete Fourier\nTransform for real input over any number of axes in an M-dimensional array by\nmeans of the Fast Fourier Transform (FFT). In other words, `irfftn(rfftn(a),\na.shape) == a` to within numerical accuracy. (The `a.shape` is necessary like\n`len(a)` is for `irfft`, and for the same reason.)\n\nThe input should be ordered in the same way as is returned by `rfftn`, i.e. as\nfor `irfft` for the final transformation axis, and as for `ifftn` along all\nthe other axes.\n\nInput array.\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). `s` is also the number of input points used along\nthis axis, except for the last axis, where `s[-1]//2+1` points of the input\nare used. Along any axis, if the shape indicated by `s` is smaller than that\nof the input, the input is cropped. If it is larger, the input is padded with\nzeros. If `s` is not given, the shape of the input along the axes specified by\naxes is used. Except for the last axis which is taken to be `2*(m-1)` where\n`m` is the length of the input along that axis.\n\nAxes over which to compute the inverse FFT. If not given, the last `len(s)`\naxes are used, or all axes if `s` is also not specified. Repeated indices in\n`axes` means that the inverse transform over that axis is performed multiple\ntimes.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` or `a`, as explained in the parameters\nsection above. The length of each transformed axis is as given by the\ncorresponding element of `s`, or the length of the input in every axis except\nfor the last one if `s` is not given. In the final transformed axis the length\nof the output when `s` is not given is `2*(m-1)` where `m` is the length of\nthe final transformed axis of the input. To get an odd number of output points\nin the final axis, `s` must be specified.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nThe forward n-dimensional FFT of real input, of which `ifftn` is the inverse.\n\nThe one-dimensional FFT, with definitions and conventions used.\n\nThe inverse of the one-dimensional FFT of real input.\n\nThe inverse of the two-dimensional FFT of real input.\n\nSee `fft` for definitions and conventions used.\n\nSee `rfft` for definitions and conventions used for real input.\n\nThe correct interpretation of the hermitian input depends on the shape of the\noriginal data, as given by `s`. This is because each input shape could\ncorrespond to either an odd or even length signal. By default, `irfftn`\nassumes an even output length which puts the last entry at the Nyquist\nfrequency; aliasing with its symmetric counterpart. When performing the final\ncomplex to real transform, the last value is thus treated as purely real. To\navoid losing information, the correct shape of the real input must be given.\n\n"}, {"name": "fft.rfft()", "path": "reference/generated/numpy.fft.rfft", "type": "numpy.fft.rfft", "text": "\nCompute the one-dimensional discrete Fourier Transform for real input.\n\nThis function computes the one-dimensional n-point discrete Fourier Transform\n(DFT) of a real-valued array by means of an efficient algorithm called the\nFast Fourier Transform (FFT).\n\nInput array\n\nNumber of points along transformation axis in the input to use. If `n` is\nsmaller than the length of the input, the input is cropped. If it is larger,\nthe input is padded with zeros. If `n` is not given, the length of the input\nalong the axis specified by `axis` is used.\n\nAxis over which to compute the FFT. If not given, the last axis is used.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. If `n` is even, the length\nof the transformed axis is `(n/2)+1`. If `n` is odd, the length is `(n+1)/2`.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nFor definition of the DFT and conventions used.\n\nThe inverse of `rfft`.\n\nThe one-dimensional FFT of general (complex) input.\n\nThe n-dimensional FFT.\n\nThe n-dimensional FFT of real input.\n\nWhen the DFT is computed for purely real input, the output is Hermitian-\nsymmetric, i.e. the negative frequency terms are just the complex conjugates\nof the corresponding positive-frequency terms, and the negative-frequency\nterms are therefore redundant. This function does not compute the negative\nfrequency terms, and the length of the transformed axis of the output is\ntherefore `n//2 + 1`.\n\nWhen `A = rfft(a)` and fs is the sampling frequency, `A[0]` contains the zero-\nfrequency term 0*fs, which is real due to Hermitian symmetry.\n\nIf `n` is even, `A[-1]` contains the term representing both positive and\nnegative Nyquist frequency (+fs/2 and -fs/2), and must also be purely real. If\n`n` is odd, there is no term at fs/2; `A[-1]` contains the largest positive\nfrequency (fs/2*(n-1)/n), and is complex in the general case.\n\nIf the input `a` contains an imaginary part, it is silently discarded.\n\nNotice how the final element of the `fft` output is the complex conjugate of\nthe second element, for real input. For `rfft`, this symmetry is exploited to\ncompute only the non-negative frequency terms.\n\n"}, {"name": "fft.rfft2()", "path": "reference/generated/numpy.fft.rfft2", "type": "numpy.fft.rfft2", "text": "\nCompute the 2-dimensional FFT of a real array.\n\nInput array, taken to be real.\n\nShape of the FFT.\n\nAxes over which to compute the FFT.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe result of the real 2-D FFT.\n\nSee also\n\nCompute the N-dimensional discrete Fourier Transform for real input.\n\nThis is really just `rfftn` with different default behavior. For more details\nsee `rfftn`.\n\n"}, {"name": "fft.rfftfreq()", "path": "reference/generated/numpy.fft.rfftfreq", "type": "numpy.fft.rfftfreq", "text": "\nReturn the Discrete Fourier Transform sample frequencies (for usage with rfft,\nirfft).\n\nThe returned float array `f` contains the frequency bin centers in cycles per\nunit of the sample spacing (with zero at the start). For instance, if the\nsample spacing is in seconds, then the frequency unit is cycles/second.\n\nGiven a window length `n` and a sample spacing `d`:\n\nUnlike `fftfreq` (but like `scipy.fftpack.rfftfreq`) the Nyquist frequency\ncomponent is considered to be positive.\n\nWindow length.\n\nSample spacing (inverse of the sampling rate). Defaults to 1.\n\nArray of length `n//2 + 1` containing the sample frequencies.\n\n"}, {"name": "fft.rfftn()", "path": "reference/generated/numpy.fft.rfftn", "type": "numpy.fft.rfftn", "text": "\nCompute the N-dimensional discrete Fourier Transform for real input.\n\nThis function computes the N-dimensional discrete Fourier Transform over any\nnumber of axes in an M-dimensional real array by means of the Fast Fourier\nTransform (FFT). By default, all axes are transformed, with the real transform\nperformed over the last axis, while the remaining transforms are complex.\n\nInput array, taken to be real.\n\nShape (length along each transformed axis) to use from the input. (`s[0]`\nrefers to axis 0, `s[1]` to axis 1, etc.). The final element of `s`\ncorresponds to `n` for `rfft(x, n)`, while for the remaining axes, it\ncorresponds to `n` for `fft(x, n)`. Along any axis, if the given shape is\nsmaller than that of the input, the input is cropped. If it is larger, the\ninput is padded with zeros. if `s` is not given, the shape of the input along\nthe axes specified by `axes` is used.\n\nAxes over which to compute the FFT. If not given, the last `len(s)` axes are\nused, or all axes if `s` is also not specified.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` and `a`, as explained in the parameters\nsection above. The length of the last axis transformed will be `s[-1]//2+1`,\nwhile the remaining transformed axes will have lengths according to `s`, or\nunchanged from the input.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nThe inverse of `rfftn`, i.e. the inverse of the n-dimensional FFT of real\ninput.\n\nThe one-dimensional FFT, with definitions and conventions used.\n\nThe one-dimensional FFT of real input.\n\nThe n-dimensional FFT.\n\nThe two-dimensional FFT of real input.\n\nThe transform for real input is performed over the last transformation axis,\nas by `rfft`, then the transform over the remaining axes is performed as by\n`fftn`. The order of the output is as for `rfft` for the final transformation\naxis, and as for `fftn` for the remaining transformation axes.\n\nSee `fft` for details, definitions and conventions used.\n\n"}, {"name": "final class numpy.typing.NBitBase", "path": "reference/typing#numpy.typing.NBitBase", "type": "Typing ( \n    \n     numpy.typing\n    \n    )", "text": "\nA type representing `numpy.number` precision during static type checking.\n\nUsed exclusively for the purpose static type checking, `NBitBase` represents\nthe base of a hierarchical set of subclasses. Each subsequent subclass is\nherein used for representing a lower level of precision, e.g. `64Bit > 32Bit >\n16Bit`.\n\nNew in version 1.20.\n\nBelow is a typical usage example: `NBitBase` is herein used for annotating a\nfunction that takes a float and integer of arbitrary precision as arguments\nand returns a new float of whichever precision is largest (e.g. `np.float16 +\nnp.int64 -> np.float64`).\n\n"}, {"name": "flatiter.base", "path": "reference/generated/numpy.flatiter.base", "type": "Indexing routines", "text": "\nattribute\n\nA reference to the array that is iterated over.\n\n"}, {"name": "flatiter.coords", "path": "reference/generated/numpy.flatiter.coords", "type": "Indexing routines", "text": "\nattribute\n\nAn N-dimensional tuple of current coordinates.\n\n"}, {"name": "flatiter.copy()", "path": "reference/generated/numpy.flatiter.copy", "type": "numpy.flatiter.copy", "text": "\nmethod\n\nGet a copy of the iterator as a 1-D array.\n\n"}, {"name": "flatiter.index", "path": "reference/generated/numpy.flatiter.index", "type": "Indexing routines", "text": "\nattribute\n\nCurrent flat index into the array.\n\n"}, {"name": "float npy_half_to_float()", "path": "reference/c-api/coremath#c.npy_half_to_float", "type": "NumPy core libraries", "text": "\nConverts a half-precision float to a single-precision float.\n\n"}, {"name": "float random_gamma_f()", "path": "reference/random/c-api#c.random_gamma_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_exponential_f()", "path": "reference/random/c-api#c.random_standard_exponential_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_gamma_f()", "path": "reference/random/c-api#c.random_standard_gamma_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_normal_f()", "path": "reference/random/c-api#c.random_standard_normal_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_uniform_f()", "path": "reference/random/c-api#c.random_standard_uniform_f", "type": "C API for random", "text": "\n\n"}, {"name": "Floating point error handling", "path": "reference/routines.err", "type": "Floating point error handling", "text": "\n`seterr`([all, divide, over, under, invalid])\n\nSet how floating-point errors are handled.\n\n`geterr`()\n\nGet the current way of handling floating-point errors.\n\n`seterrcall`(func)\n\nSet the floating-point error callback function or log object.\n\n`geterrcall`()\n\nReturn the current callback function used on floating-point errors.\n\n`errstate`(**kwargs)\n\nContext manager for floating-point error handling.\n\n`seterrobj`(errobj, /)\n\nSet the object that defines floating-point error handling.\n\n`geterrobj`()\n\nReturn the current object that defines floating-point error handling.\n\n"}, {"name": "For downstream package authors", "path": "user/depending_on_numpy", "type": "User Guide", "text": "\nThis document aims to explain some best practices for authoring a package that\ndepends on NumPy.\n\nNumPy uses a standard, PEP 440 compliant, versioning scheme:\n`major.minor.bugfix`. A major release is highly unusual (NumPy is still at\nversion `1.xx`) and if it happens it will likely indicate an ABI break. Minor\nversions are released regularly, typically every 6 months. Minor versions\ncontain new features, deprecations, and removals of previously deprecated\ncode. Bugfix releases are made even more frequently; they do not contain any\nnew features or deprecations.\n\nIt is important to know that NumPy, like Python itself and most other well\nknown scientific Python projects, does not use semantic versioning. Instead,\nbackwards incompatible API changes require deprecation warnings for at least\ntwo releases. For more details, see NEP 23 \u2014 Backwards compatibility and\ndeprecation policy.\n\nNumPy has both a Python API and a C API. The C API can be used directly or via\nCython, f2py, or other such tools. If your package uses the C API, then ABI\n(application binary interface) stability of NumPy is important. NumPy\u2019s ABI is\nforward but not backward compatible. This means: binaries compiled against a\ngiven version of NumPy will still run correctly with newer NumPy versions, but\nnot with older versions.\n\nFor large, actively maintained packages that depend on NumPy, we recommend\ntesting against the development version of NumPy in CI. To make this easy,\nnightly builds are provided as wheels at https://anaconda.org/scipy-wheels-\nnightly/. This helps detect regressions in NumPy that need fixing before the\nnext NumPy release. Furthermore, we recommend to raise errors on warnings in\nCI for this job, either all warnings or otherwise at least\n`DeprecationWarning` and `FutureWarning`. This gives you an early warning\nabout changes in NumPy to adapt your code.\n\nIf a package either uses the NumPy C API directly or it uses some other tool\nthat depends on it like Cython or Pythran, NumPy is a build-time dependency of\nthe package. Because the NumPy ABI is only forward compatible, you must build\nyour own binaries (wheels or other package formats) against the lowest NumPy\nversion that you support (or an even older version).\n\nPicking the correct NumPy version to build against for each Python version and\nplatform can get complicated. There are a couple of ways to do this. Build-\ntime dependencies are specified in `pyproject.toml` (see PEP 517), which is\nthe file used to build wheels by PEP 517 compliant tools (e.g., when using\n`pip wheel`).\n\nYou can specify everything manually in `pyproject.toml`, or you can instead\nrely on the oldest-supported-numpy metapackage. `oldest-supported-numpy` will\nspecify the correct NumPy version at build time for wheels, taking into\naccount Python version, Python implementation (CPython or PyPy), operating\nsystem and hardware platform. It will specify the oldest NumPy version that\nsupports that combination of characteristics. Note: for platforms for which\nNumPy provides wheels on PyPI, it will be the first version with wheels (even\nif some older NumPy version happens to build).\n\nFor conda-forge it\u2019s a little less complicated: there\u2019s dedicated handling for\nNumPy in build-time and runtime dependencies, so typically this is enough (see\nhere for docs):\n\nNote\n\n`pip` has `--no-use-pep517` and `--no-build-isolation` flags that may ignore\n`pyproject.toml` or treat it differently - if users use those flags, they are\nresponsible for installing the correct build dependencies themselves.\n\n`conda` will always use `-no-build-isolation`; dependencies for conda builds\nare given in the conda recipe (`meta.yaml`), the ones in `pyproject.toml` have\nno effect.\n\nPlease do not use `setup_requires` (it is deprecated and may invoke\n`easy_install`).\n\nBecause for NumPy you have to care about ABI compatibility, you specify the\nversion with `==` to the lowest supported version. For your other build\ndependencies you can probably be looser, however it\u2019s still important to set\nlower and upper bounds for each dependency. It\u2019s fine to specify either a\nrange or a specific version for a dependency like `wheel` or `setuptools`.\nIt\u2019s recommended to set the upper bound of the range to the latest already\nreleased version of `wheel` and `setuptools` \\- this prevents future releases\nfrom breaking your packages on PyPI.\n\nNumPy itself and many core scientific Python packages have agreed on a\nschedule for dropping support for old Python and NumPy versions: NEP 29 \u2014\nRecommend Python and NumPy version support as a community policy standard. We\nrecommend all packages depending on NumPy to follow the recommendations in NEP\n29.\n\nFor run-time dependencies, you specify the range of versions in\n`install_requires` in `setup.py` (assuming you use `numpy.distutils` or\n`setuptools` to build). Getting the upper bound right for NumPy is slightly\ntricky. If we don\u2019t set any bound, a too-new version will be pulled in a few\nyears down the line, and NumPy may have deprecated and removed some API that\nyour package depended on by then. On the other hand if you set the upper bound\nto the newest already-released version, then as soon as a new NumPy version is\nreleased there will be no matching version of your package that works with it.\n\nWhat to do here depends on your release frequency. Given that NumPy releases\ncome in a 6-monthly cadence and that features that get deprecated in NumPy\nshould stay around for another two releases, a good upper bound is\n`<1.(xx+3).0` \\- where `xx` is the minor version of the latest already-\nreleased NumPy. This is safe to do if you release at least once a year. If\nyour own releases are much less frequent, you may set the upper bound a little\nfurther into the future - this is a trade-off between a future NumPy version\n_maybe_ removing something you rely on, and the upper bound being exceeded\nwhich _may_ lead to your package being hard to install in combination with\nother packages relying on the latest NumPy.\n\nNote\n\nSciPy has more documentation on how it builds wheels and deals with its build-\ntime and runtime dependencies here.\n\nNumPy and SciPy wheel build CI may also be useful as a reference, it can be\nfound here for NumPy and here for SciPy.\n\n"}, {"name": "Fortran 77 programs", "path": "f2py/buildtools/index", "type": "F2PY and Build Systems", "text": "\nIn this section we will cover the various popular build systems and their\nusage with `f2py`.\n\nNote\n\nAs of November 2021\n\nThe default build system for `F2PY` has traditionally been the through the\nenhanced `numpy.distutils` module. This module is based on `distutils` which\nwill be removed in `Python 3.12.0` in October 2023; `setuptools` does not have\nsupport for Fortran or `F2PY` and it is unclear if it will be supported in the\nfuture. Alternative methods are thus increasingly more important.\n\nBuilding an extension module which includes Python and Fortran consists of:\n\nOne or more generated files from `f2py`\n\n`fortranobject.{c,h}`\n\nNumPy headers\n\nBroadly speaking there are three cases which arise when considering the\noutputs of `f2py`:\n\nGenerates\n\nWhen no `COMMON` blocks are present only a `C` wrapper file is generated.\nWrappers are also generated to rewrite assumed shape arrays as automatic\narrays.\n\nGenerates:\n\nThe secondary wrapper is used to handle code which is subdivided into modules.\nIt rewrites assumed shape arrays as automatic arrays.\n\nGenerates:\n\nSignature files `.pyf` do not signal their language standard via the file\nextension, they may generate the F90 and F77 specific wrappers depending on\ntheir contents; which shifts the burden of checking for generated files onto\nthe build system.\n\nNote\n\nThe signature file output situation is being reconsidered in issue 20385 .\n\nIn theory keeping the above requirements in hand, any build system can be\nadapted to generate `f2py` extension modules. Here we will cover a subset of\nthe more popular systems.\n\nNote\n\n`make` has no place in a modern multi-language setup, and so is not discussed\nfurther.\n\n"}, {"name": "Functional programming", "path": "reference/routines.functional", "type": "Functional programming", "text": "\n`apply_along_axis`(func1d, axis, arr, *args, ...)\n\nApply a function to 1-D slices along the given axis.\n\n`apply_over_axes`(func, a, axes)\n\nApply a function repeatedly over multiple axes.\n\n`vectorize`(pyfunc[, otypes, doc, excluded, ...])\n\nGeneralized function class.\n\n`frompyfunc`(func, /, nin, nout, *[, identity])\n\nTakes an arbitrary Python function and returns a NumPy ufunc.\n\n`piecewise`(x, condlist, funclist, *args, **kw)\n\nEvaluate a piecewise-defined function.\n\n"}, {"name": "generic.__array__()", "path": "reference/generated/numpy.generic.__array__", "type": "numpy.generic.__array__", "text": "\nmethod\n\nsc.__array__(dtype) return 0-dim array from scalar with specified dtype\n\n"}, {"name": "generic.__array_interface__", "path": "reference/generated/numpy.generic.__array_interface__", "type": "numpy.generic.__array_interface__", "text": "\nattribute\n\nArray protocol: Python side\n\n"}, {"name": "generic.__array_priority__", "path": "reference/generated/numpy.generic.__array_priority__", "type": "numpy.generic.__array_priority__", "text": "\nattribute\n\nArray priority.\n\n"}, {"name": "generic.__array_struct__", "path": "reference/generated/numpy.generic.__array_struct__", "type": "numpy.generic.__array_struct__", "text": "\nattribute\n\nArray protocol: struct\n\n"}, {"name": "generic.__array_wrap__()", "path": "reference/generated/numpy.generic.__array_wrap__", "type": "numpy.generic.__array_wrap__", "text": "\nmethod\n\nsc.__array_wrap__(obj) return scalar from array\n\n"}, {"name": "generic.__reduce__()", "path": "reference/generated/numpy.generic.__reduce__", "type": "numpy.generic.__reduce__", "text": "\nmethod\n\nHelper for pickle.\n\n"}, {"name": "generic.__setstate__()", "path": "reference/generated/numpy.generic.__setstate__", "type": "numpy.generic.__setstate__", "text": "\nmethod\n\n"}, {"name": "generic.base", "path": "reference/generated/numpy.generic.base", "type": "numpy.generic.base", "text": "\nattribute\n\nScalar attribute identical to the corresponding array attribute.\n\nPlease see `ndarray.base`.\n\n"}, {"name": "generic.byteswap()", "path": "reference/generated/numpy.generic.byteswap", "type": "numpy.generic.byteswap", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.byteswap`.\n\n"}, {"name": "generic.data", "path": "reference/generated/numpy.generic.data", "type": "numpy.generic.data", "text": "\nattribute\n\nPointer to start of data.\n\n"}, {"name": "generic.dtype", "path": "reference/generated/numpy.generic.dtype", "type": "numpy.generic.dtype", "text": "\nattribute\n\nGet array data-descriptor.\n\n"}, {"name": "generic.flags", "path": "reference/generated/numpy.generic.flags", "type": "numpy.generic.flags", "text": "\nattribute\n\nThe integer value of flags.\n\n"}, {"name": "generic.flat", "path": "reference/generated/numpy.generic.flat", "type": "numpy.generic.flat", "text": "\nattribute\n\nA 1-D view of the scalar.\n\n"}, {"name": "generic.imag", "path": "reference/generated/numpy.generic.imag", "type": "numpy.generic.imag", "text": "\nattribute\n\nThe imaginary part of the scalar.\n\n"}, {"name": "generic.itemsize", "path": "reference/generated/numpy.generic.itemsize", "type": "numpy.generic.itemsize", "text": "\nattribute\n\nThe length of one element in bytes.\n\n"}, {"name": "generic.ndim", "path": "reference/generated/numpy.generic.ndim", "type": "numpy.generic.ndim", "text": "\nattribute\n\nThe number of array dimensions.\n\n"}, {"name": "generic.real", "path": "reference/generated/numpy.generic.real", "type": "numpy.generic.real", "text": "\nattribute\n\nThe real part of the scalar.\n\n"}, {"name": "generic.setflags()", "path": "reference/generated/numpy.generic.setflags", "type": "numpy.generic.setflags", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.setflags`.\n\n"}, {"name": "generic.shape", "path": "reference/generated/numpy.generic.shape", "type": "numpy.generic.shape", "text": "\nattribute\n\nTuple of array dimensions.\n\n"}, {"name": "generic.size", "path": "reference/generated/numpy.generic.size", "type": "numpy.generic.size", "text": "\nattribute\n\nThe number of elements in the gentype.\n\n"}, {"name": "generic.squeeze()", "path": "reference/generated/numpy.generic.squeeze", "type": "numpy.generic.squeeze", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.squeeze`.\n\n"}, {"name": "generic.strides", "path": "reference/generated/numpy.generic.strides", "type": "numpy.generic.strides", "text": "\nattribute\n\nTuple of bytes steps in each dimension.\n\n"}, {"name": "generic.T", "path": "reference/generated/numpy.generic.t", "type": "numpy.generic.T", "text": "\nattribute\n\nScalar attribute identical to the corresponding array attribute.\n\nPlease see `ndarray.T`.\n\n"}, {"name": "Get the local copy of the code", "path": "dev/gitwash/following_latest", "type": "Development", "text": "\nFrom the command line:\n\nYou now have a copy of the code tree in the new `numpy` directory. If this\ndoesn\u2019t work you can try the alternative read-only url:\n\n"}, {"name": "get_build_temp_dir()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_build_temp_dir", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturn a path to a temporary directory where temporary files should be placed.\n\n"}, {"name": "get_config_cmd()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_config_cmd", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturns the numpy.distutils config command instance.\n\n"}, {"name": "get_distribution()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_distribution", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturn the distutils distribution object for self.\n\n"}, {"name": "get_info()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_info", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nGet resources information.\n\nReturn information (from system_info.get_info) for all of the names in the\nargument list in a single dictionary.\n\n"}, {"name": "get_subpackage()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_subpackage", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturn list of subpackage configurations.\n\nName of the subpackage to get the configuration. \u2018*\u2019 in subpackage_name is\nhandled as a wildcard.\n\nIf None, then the path is assumed to be the local path plus the\nsubpackage_name. If a setup.py file is not found in the subpackage_path, then\na default configuration is used.\n\nParent name.\n\n"}, {"name": "get_version()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_version", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nTry to get version string of a package.\n\nReturn a version string of the current package or None if the version\ninformation could not be detected.\n\nThis method scans files named __version__.py, <packagename>_version.py,\nversion.py, and __svn_version__.py for string variables version, __version__,\nand <packagename>_version, until a version number is found.\n\n"}, {"name": "Git configuration", "path": "dev/gitwash/configure_git", "type": "Development", "text": "\nYour personal git configurations are saved in the `.gitconfig` file in your\nhome directory. Here is an example `.gitconfig` file:\n\nYou can edit this file directly or you can use the `git config --global`\ncommand:\n\nTo set up on another computer, you can copy your `~/.gitconfig` file, or run\nthe commands above.\n\nIt is good practice to tell git who you are, for labeling any changes you make\nto the code. The simplest way to do this is from the command line:\n\nThis will write the settings into your git configuration file, which should\nnow contain a user section with your name and email:\n\nOf course you\u2019ll need to replace `Your Name` and `you@yourdomain.example.com`\nwith your actual name and email address.\n\nYou might well benefit from some aliases to common commands.\n\nFor example, you might well want to be able to shorten `git checkout` to `git\nco`. Or you may want to alias `git diff --color-words` (which gives a nicely\nformatted output of the diff) to `git wdiff`\n\nThe following `git config --global` commands:\n\nwill create an `alias` section in your `.gitconfig` file with contents like\nthis:\n\nYou may also want to make sure that your editor of choice is used\n\nTo enforce summaries when doing merges (`~/.gitconfig` file again):\n\nOr from the command line:\n\n"}, {"name": "Git for development", "path": "dev/gitwash/index", "type": "Development", "text": "\nThese pages describe a general git and github workflow.\n\nThis is not a comprehensive git reference. It\u2019s tailored to the github hosting\nservice. You may well find better or quicker ways of getting stuff done with\ngit, but these should get you started.\n\nFor general resources for learning git see Additional Git Resources.\n\nHave a look at the github install help pages available from github help\n\nContents:\n\n"}, {"name": "Global State", "path": "reference/global_state", "type": "Global State", "text": "\nNumPy has a few import-time, compile-time, or runtime options which change the\nglobal behaviour. Most of these are related to performance or for debugging\npurposes and will not be interesting to the vast majority of users.\n\nNumPy itself is normally intentionally limited to a single thread during\nfunction calls, however it does support multiple Python threads running at the\nsame time. Note that for performant linear algebra NumPy uses a BLAS backend\nsuch as OpenBLAS or MKL, which may use multiple threads that may be controlled\nby environment variables such as `OMP_NUM_THREADS` depending on what is used.\nOne way to control the number of threads is the package threadpoolctl\n\nWhen working with very large arrays on modern Linux kernels, you can\nexperience a significant speedup when transparent hugepage is used. The\ncurrent system policy for transparent hugepages can be seen by:\n\nWhen set to `madvise` NumPy will typically use hugepages for a performance\nboost. This behaviour can be modified by setting the environment variable:\n\nor setting it to `1` to always enable it. When not set, the default is to use\nmadvise on Kernels 4.6 and newer. These kernels presumably experience a large\nspeedup with hugepage support. This flag is checked at import time.\n\nThe array function protocol which allows array-like objects to hook into the\nNumPy API is currently enabled by default. This option exists since NumPy 1.16\nand is enabled by default since NumPy 1.17. It can be disabled using:\n\nSee also `numpy.class.__array_function__` for more information. This flag is\nchecked at import time.\n\nThe compile-time environment variables:\n\ncontrol how NumPy reports contiguity for arrays. The default that it is\nenabled and the debug mode is disabled. This setting should always be enabled.\nSetting the debug option can be interesting for testing code written in C\nwhich iterates through arrays that may or may not be contiguous in memory.\nMost users will have no reason to change these; for details see the memory\nlayout documentation.\n\nSome users might pass ownership of the data pointer to the `ndarray` by\nsetting the `OWNDATA` flag. If they do this without setting (manually) a\nmemory allocation policy, the default will be to call `free`. If\n`NUMPY_WARN_IF_NO_MEM_POLICY` is set to `\"1\"`, a `RuntimeWarning` will be\nemitted. A better alternative is to use a `PyCapsule` with a deallocator and\nset the `ndarray.base`.\n\n"}, {"name": "have_f77c()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.have_f77c", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nCheck for availability of Fortran 77 compiler.\n\nUse it inside source generating function to ensure that setup distribution\ninstance has been initialized.\n\nTrue if a Fortran 77 compiler is available (because a simple Fortran 77 code\nwas able to be compiled successfully).\n\n"}, {"name": "have_f90c()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.have_f90c", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nCheck for availability of Fortran 90 compiler.\n\nUse it inside source generating function to ensure that setup distribution\ninstance has been initialized.\n\nTrue if a Fortran 90 compiler is available (because a simple Fortran 90 code\nwas able to be compiled successfully)\n\n"}, {"name": "Hermite Series, \u201cPhysicists\u201d (numpy.polynomial.hermite)", "path": "reference/routines.polynomials.hermite", "type": "Hermite Series, \u201cPhysicists\u201d ( \n        \n         numpy.polynomial.hermite\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Hermite series, including a `Hermite` class that encapsulates the usual\narithmetic operations. (General information on how this module represents and\nworks with such polynomials is in the docstring for its \u201cparent\u201d sub-package,\n`numpy.polynomial`).\n\n`Hermite`(coef[, domain, window])\n\nAn Hermite series class.\n\n`hermdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermadd`(c1, c2)\n\nAdd one Hermite series to another.\n\n`hermsub`(c1, c2)\n\nSubtract one Hermite series from another.\n\n`hermmulx`(c)\n\nMultiply a Hermite series by x.\n\n`hermmul`(c1, c2)\n\nMultiply one Hermite series by another.\n\n`hermdiv`(c1, c2)\n\nDivide one Hermite series by another.\n\n`hermpow`(c, pow[, maxpower])\n\nRaise a Hermite series to a power.\n\n`hermval`(x, c[, tensor])\n\nEvaluate an Hermite series at points x.\n\n`hermval2d`(x, y, c)\n\nEvaluate a 2-D Hermite series at points (x, y).\n\n`hermval3d`(x, y, z, c)\n\nEvaluate a 3-D Hermite series at points (x, y, z).\n\n`hermgrid2d`(x, y, c)\n\nEvaluate a 2-D Hermite series on the Cartesian product of x and y.\n\n`hermgrid3d`(x, y, z, c)\n\nEvaluate a 3-D Hermite series on the Cartesian product of x, y, and z.\n\n`hermder`(c[, m, scl, axis])\n\nDifferentiate a Hermite series.\n\n`hermint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Hermite series.\n\n`hermfromroots`(roots)\n\nGenerate a Hermite series with given roots.\n\n`hermroots`(c)\n\nCompute the roots of a Hermite series.\n\n`hermvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`hermvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermgauss`(deg)\n\nGauss-Hermite quadrature.\n\n`hermweight`(x)\n\nWeight function of the Hermite polynomials.\n\n`hermcompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`hermfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Hermite series to data.\n\n`hermtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`hermline`(off, scl)\n\nHermite series whose graph is a straight line.\n\n`herm2poly`(c)\n\nConvert a Hermite series to a polynomial.\n\n`poly2herm`(pol)\n\nConvert a polynomial to a Hermite series.\n\n`numpy.polynomial`\n\n"}, {"name": "HermiteE Series, \u201cProbabilists\u201d (numpy.polynomial.hermite_e)", "path": "reference/routines.polynomials.hermite_e", "type": "HermiteE Series, \u201cProbabilists\u201d ( \n        \n         numpy.polynomial.hermite_e\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Hermite_e series, including a `HermiteE` class that encapsulates the\nusual arithmetic operations. (General information on how this module\nrepresents and works with such polynomials is in the docstring for its\n\u201cparent\u201d sub-package, `numpy.polynomial`).\n\n`HermiteE`(coef[, domain, window])\n\nAn HermiteE series class.\n\n`hermedomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermezero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermeone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermex`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermeadd`(c1, c2)\n\nAdd one Hermite series to another.\n\n`hermesub`(c1, c2)\n\nSubtract one Hermite series from another.\n\n`hermemulx`(c)\n\nMultiply a Hermite series by x.\n\n`hermemul`(c1, c2)\n\nMultiply one Hermite series by another.\n\n`hermediv`(c1, c2)\n\nDivide one Hermite series by another.\n\n`hermepow`(c, pow[, maxpower])\n\nRaise a Hermite series to a power.\n\n`hermeval`(x, c[, tensor])\n\nEvaluate an HermiteE series at points x.\n\n`hermeval2d`(x, y, c)\n\nEvaluate a 2-D HermiteE series at points (x, y).\n\n`hermeval3d`(x, y, z, c)\n\nEvaluate a 3-D Hermite_e series at points (x, y, z).\n\n`hermegrid2d`(x, y, c)\n\nEvaluate a 2-D HermiteE series on the Cartesian product of x and y.\n\n`hermegrid3d`(x, y, z, c)\n\nEvaluate a 3-D HermiteE series on the Cartesian product of x, y, and z.\n\n`hermeder`(c[, m, scl, axis])\n\nDifferentiate a Hermite_e series.\n\n`hermeint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Hermite_e series.\n\n`hermefromroots`(roots)\n\nGenerate a HermiteE series with given roots.\n\n`hermeroots`(c)\n\nCompute the roots of a HermiteE series.\n\n`hermevander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`hermevander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermevander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermegauss`(deg)\n\nGauss-HermiteE quadrature.\n\n`hermeweight`(x)\n\nWeight function of the Hermite_e polynomials.\n\n`hermecompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`hermefit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Hermite series to data.\n\n`hermetrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`hermeline`(off, scl)\n\nHermite series whose graph is a straight line.\n\n`herme2poly`(c)\n\nConvert a Hermite series to a polynomial.\n\n`poly2herme`(pol)\n\nConvert a polynomial to a Hermite series.\n\n`numpy.polynomial`\n\n"}, {"name": "How to write a NumPy how-to", "path": "user/how-to-how-to", "type": "User Guide", "text": "\nHow-tos get straight to the point \u2013 they\n\n\u201cI need to refuel my car.\u201d\n\nAdd helpful details for newcomers (\u201cHayseed Road\u201d, even though it\u2019s the only\nturnoff at three km/mi). But not irrelevant ones:\n\nIf there\u2019s related background (tutorial, explanation, reference, alternative\napproach), bring it to the user\u2019s attention with a link (\u201cDirections from\nRoute 7,\u201d \u201cWhy so few filling stations?\u201d).\n\nIf the information is already documented and succinct enough for a how-to,\njust link to it, possibly after an introduction (\u201cThree km/mi, take a right\u201d).\n\n\u201cI want to see the sights.\u201d\n\nThe `See the sights` how-to should link to a set of narrower how-tos:\n\nand these might in turn link to still narrower how-tos \u2013 so the town center\npage might link to\n\nBy organizing how-tos this way, you not only display the options for people\nwho need to narrow their question, you also have provided answers for users\nwho start with narrower questions (\u201cI want to see historic buildings,\u201d \u201cWhich\nway to city hall?\u201d).\n\nIf a how-to has many steps:\n\nPeople use the terms \u201chow-to\u201d and \u201ctutorial\u201d interchangeably, but we draw a\ndistinction, following Daniele Procida\u2019s taxonomy of documentation.\n\nDocumentation needs to meet users where they are. `How-tos` offer get-it-done\ninformation; the user wants steps to copy and doesn\u2019t necessarily want to\nunderstand NumPy. `Tutorials` are warm-fuzzy information; the user wants a\nfeel for some aspect of NumPy (and again, may or may not care about deeper\nknowledge).\n\nWe distinguish both tutorials and how-tos from `Explanations`, which are deep\ndives intended to give understanding rather than immediate assistance, and\n`References`, which give complete, authoritative data on some concrete part of\nNumPy (like its API) but aren\u2019t obligated to paint a broader picture.\n\nFor more on tutorials, see Learn to write a NumPy tutorial\n\nYes \u2013 until the sections with question-mark headings; they explain rather than\ngiving directions. In a how-to, those would be links.\n\n"}, {"name": "I/O with NumPy", "path": "user/basics.io", "type": "User Guide", "text": "\n\n"}, {"name": "include statements", "path": "f2py/signature-file", "type": "Signature file", "text": "\nThe syntax specification for signature files (.pyf files) is modeled on the\nFortran 90/95 language specification. Almost all Fortran 90/95 standard\nconstructs are understood, both in free and fixed format (recall that Fortran\n77 is a subset of Fortran 90/95). F2PY introduces some extensions to the\nFortran 90/95 language specification that help in the design of the Fortran to\nPython interface, making it more \u201cPythonic\u201d.\n\nSignature files may contain arbitrary Fortran code so that any Fortran 90/95\ncodes can be treated as signature files. F2PY silently ignores Fortran\nconstructs that are irrelevant for creating the interface. However, this also\nmeans that syntax errors are not caught by F2PY and will only be caught when\nthe library is built.\n\nIn general, the contents of the signature files are case-sensitive. When\nscanning Fortran codes to generate a signature file, F2PY lowers all cases\nautomatically except in multi-line blocks or when the `--no-lower` option is\nused.\n\nThe syntax of signature files is presented below.\n\nA signature file may contain one (recommended) or more `python module` blocks.\nThe `python module` block describes the contents of a Python/C extension\nmodule `<modulename>module.c` that F2PY generates.\n\nWarning\n\nException: if `<modulename>` contains a substring `__user__`, then the\ncorresponding `python module` block describes the signatures of call-back\nfunctions (see Call-back arguments).\n\nA `python module` block has the following structure:\n\nHere brackets `[]` indicate an optional section, dots `...` indicate one or\nmore of a previous section. So, `[]...` is to be read as zero or more of a\nprevious section.\n\nThe signature of a Fortran routine has the following structure:\n\nFrom a Fortran routine signature F2PY generates a Python/C extension function\nthat has the following signature:\n\nThe signature of a Fortran block data has the following structure:\n\nThe definition of the `<argument/variable type declaration>` part is\n\nwhere\n\nand\n\nIf an argument has no `<argument type declaration>`, its type is determined by\napplying `implicit` rules to its name.\n\nThe definition of the `<use statement>` part is\n\nwhere\n\nThe definition of the `<common block statement>` part is\n\nwhere\n\nThe `<other statement>` part refers to any other Fortran language constructs\nthat are not described above. F2PY ignores most of them except the following:\n\nIf a file `<filename>` does not exist, the `include` statement is ignored.\nOtherwise, the file `<filename>` is included to a signature file. `include`\nstatements can be used in any part of a signature file, also outside the\nFortran/C routine signature blocks.\n\nwhere\n\nImplicit rules are used to determine the type specification of a variable\n(from the first-letter of its name) if the variable is not defined using\n`<variable type declaration>`. Default implicit rules are given by:\n\nF2PY generates wrappers for all entry names using the signature of the routine\nblock.\n\nNote\n\nThe `entry` statement can be used to describe the signature of an arbitrary\nsubroutine or function allowing F2PY to generate a number of wrappers from\nonly one routine block signature. There are few restrictions while doing this:\n`fortranname` cannot be used, `callstatement` and `callprotoargument` can be\nused only if they are valid for all entry routines, etc.\n\nIn addition, F2PY introduces the following statements:\n\nUses a `Py_BEGIN_ALLOW_THREADS .. Py_END_ALLOW_THREADS` block around the call\nto Fortran/C function.\n\nReplaces the F2PY generated call statement to Fortran/C function with\n`<C-expr|multi-line block>`. The wrapped Fortran/C function is available as\n`(*f2py_func)`.\n\nTo raise an exception, set `f2py_success = 0` in `<C-expr|multi-line block>`.\n\nWhen the `callstatement` statement is used then F2PY may not generate proper\nprototypes for Fortran/C functions (because `<C-expr>` may contain any\nfunction calls and F2PY has no way to determine what should be the proper\nprototype).\n\nWith this statement you can explicitly specify the arguments of the\ncorresponding prototype:\n\nF2PY allows for the use of an arbitrary `<routine name>` for a given Fortran/C\nfunction. Then this statement is used for the `<actual Fortran/C routine\nname>`.\n\nIf `fortranname` statement is used without `<actual Fortran/C routine name>`\nthen a dummy wrapper is generated.\n\nWhen this is used inside a `python module` block, the given C code will be\ninserted to generated C/API source just before wrapper function definitions.\n\nHere you can define arbitrary C functions to be used for the initialization of\noptional arguments.\n\nFor example, if `usercode` is used twice inside `python module` block then the\nsecond multi-line block is inserted after the definition of the external\nroutines.\n\nWhen used inside `<routine signature>`, then the given C code will be inserted\ninto the corresponding wrapper function just after the declaration of\nvariables but before any C statements. So, the `usercode` follow-up can\ncontain both declarations and C statements.\n\nWhen used inside the first `interface` block, then the given C code will be\ninserted at the end of the initialization function of the extension module.\nThis is how the extension modules dictionary can be modified and has many use-\ncases; for example, to define additional variables.\n\nThis is a multi-line block which will be inserted into the definition of a\nmodule methods `PyMethodDef`-array. It must be a comma-separated list of C\narrays (see Extending and Embedding Python documentation for details).\n`pymethoddef` statement can be used only inside `python module` block.\n\nThe following attributes are used by F2PY:\n\nThe corresponding argument is moved to the end of `<optional arguments>` list.\nA default value for an optional argument can be specified via `<init_expr>`,\nsee the `entitydecl` definition.\n\nNote\n\nThe corresponding argument with this attribute considered mandatory. This is\nthe default. `required` should only be specified if there is a need to disable\nthe automatic `optional` setting when `<init_expr>` is used.\n\nIf a Python `None` object is used as a required argument, the argument is\ntreated as optional. That is, in the case of array argument, the memory is\nallocated. If `<init_expr>` is given, then the corresponding initialization is\ncarried out.\n\nThe corresponding variable is considered as an array with dimensions given in\n`<arrayspec>`.\n\nThis specifies the \u201cintention\u201d of the corresponding argument. `<intentspec>`\nis a comma separated list of the following keys:\n\nThe corresponding argument is considered to be input-only. This means that the\nvalue of the argument is passed to a Fortran/C function and that the function\nis expected to not change the value of this argument.\n\nThe corresponding argument is marked for input/output or as an in situ output\nargument. `intent(inout)` arguments can be only \u201ccontiguous\u201d NumPy arrays with\nproper type and size. Here \u201ccontiguous\u201d can be either in the Fortran or C\nsense. The latter coincides with the default contiguous concept used in NumPy\nand is effective only if `intent(c)` is used. F2PY assumes Fortran contiguous\narguments by default.\n\nNote\n\nUsing `intent(inout)` is generally not recommended, use `intent(in,out)`\ninstead.\n\nSee also the `intent(inplace)` attribute.\n\nThe corresponding argument is considered to be an input/output or in situ\noutput argument. `intent(inplace)` arguments must be NumPy arrays of a proper\nsize. If the type of an array is not \u201cproper\u201d or the array is non-contiguous\nthen the array will be modified in-place to fix the type and make it\ncontiguous.\n\nNote\n\nUsing `intent(inplace)` is generally not recommended either.\n\nFor example, when slices have been taken from an `intent(inplace)` argument\nthen after in-place changes, the data pointers for the slices may point to an\nunallocated memory area.\n\nThe corresponding argument is considered to be a return variable. It is\nappended to the `<returned variables>` list. Using `intent(out)` sets\n`intent(hide)` automatically, unless `intent(in)` or `intent(inout)` are\nspecified as well.\n\nBy default, returned multidimensional arrays are Fortran-contiguous. If\n`intent(c)` attribute is used, then the returned multidimensional arrays are\nC-contiguous.\n\nThe corresponding argument is removed from the list of required or optional\narguments. Typically `intent(hide)` is used with `intent(out)` or when\n`<init_expr>` completely determines the value of the argument like in the\nfollowing example:\n\nThe corresponding argument is treated as a C scalar or C array argument. For\nthe case of a scalar argument, its value is passed to a C function as a C\nscalar argument (recall that Fortran scalar arguments are actually C pointer\narguments). For array arguments, the wrapper function is assumed to treat\nmultidimensional arrays as C-contiguous arrays.\n\nThere is no need to use `intent(c)` for one-dimensional arrays, irrespective\nof whether the wrapped function is in Fortran or C. This is because the\nconcepts of Fortran- and C contiguity overlap in one-dimensional cases.\n\nIf `intent(c)` is used as a statement but without an entity declaration list,\nthen F2PY adds the `intent(c)` attribute to all arguments.\n\nAlso, when wrapping C functions, one must use `intent(c)` attribute for\n`<routine name>` in order to disable Fortran specific `F_FUNC(..,..)` macros.\n\nThe corresponding argument is treated as junk memory. No Fortran nor C\ncontiguity checks are carried out. Using `intent(cache)` makes sense only for\narray arguments, also in conjunction with `intent(hide)` or `optional`\nattributes.\n\nEnsures that the original contents of `intent(in)` argument is preserved.\nTypically used with the `intent(in,out)` attribute. F2PY creates an optional\nargument `overwrite_<argument name>` with the default value `0`.\n\nThis indicates that the original contents of the `intent(in)` argument may be\naltered by the Fortran/C function. F2PY creates an optional argument\n`overwrite_<argument name>` with the default value `1`.\n\nReplaces the returned name with `<new name>` in the `__doc__` string of the\nwrapper function.\n\nConstructs an external function suitable for calling Python functions from\nFortran. `intent(callback)` must be specified before the corresponding\n`external` statement. If the \u2018argument\u2019 is not in the argument list then it\nwill be added to Python wrapper but only by initializing an external function.\n\nNote\n\nUse `intent(callback)` in situations where the Fortran/C code assumes that the\nuser implemented a function with a given prototype and linked it to an\nexecutable. Don\u2019t use `intent(callback)` if the function appears in the\nargument list of a Fortran routine.\n\nWith `intent(hide)` or `optional` attributes specified and using a wrapper\nfunction without specifying the callback argument in the argument list; then\nthe call-back function is assumed to be found in the namespace of the F2PY\ngenerated extension module where it can be set as a module attribute by a\nuser.\n\nDefines an auxiliary C variable in the F2PY generated wrapper function. Useful\nto save parameter values so that they can be accessed in initialization\nexpressions for other variables.\n\nNote\n\n`intent(aux)` silently implies `intent(c)`.\n\nThe following rules apply:\n\nIf none of `intent(in | inout | out | hide)` are specified, `intent(in)` is\nassumed.\n\nIf `intent(copy)` or `intent(overwrite)` is used, then an additional optional\nargument is introduced with a name `overwrite_<argument name>` and a default\nvalue 0 or 1, respectively.\n\nPerforms a consistency check on the arguments by evaluating `<C-booleanexpr>`;\nif `<C-booleanexpr>` returns 0, an exception is raised.\n\nNote\n\nIf `check(..)` is not used then F2PY automatically generates a few standard\nchecks (e.g. in a case of an array argument, it checks for the proper shape\nand size). Use `check()` to disable checks generated by F2PY.\n\nThis declares that the corresponding argument depends on the values of\nvariables in the `<names>` list. For example, `<init_expr>` may use the values\nof other arguments. Using information given by `depend(..)` attributes, F2PY\nensures that arguments are initialized in a proper order. If the `depend(..)`\nattribute is not used then F2PY determines dependence relations automatically.\nUse `depend()` to disable the dependence relations generated by F2PY.\n\nWhen you edit dependence relations that were initially generated by F2PY, be\ncareful not to break the dependence relations of other relevant variables.\nAnother thing to watch out for is cyclic dependencies. F2PY is able to detect\ncyclic dependencies when constructing wrappers and it complains if any are\nfound.\n\nThe corresponding variable is a Fortran 90 allocatable array defined as\nFortran 90 module data.\n\nThe corresponding argument is a function provided by user. The signature of\nthis call-back function can be defined\n\nFor example, F2PY generates from:\n\nthe following call-back signatures:\n\nThe corresponding user-provided Python function are then:\n\nSee also the `intent(callback)` attribute.\n\nThis indicates that the corresponding variable is a parameter and it must have\na fixed value. F2PY replaces all parameter occurrences by their corresponding\nvalues.\n\nThe F2PY directives allow using F2PY signature file constructs in Fortran\n77/90 source codes. With this feature one can (almost) completely skip the\nintermediate signature file generation and apply F2PY directly to Fortran\nsource codes.\n\nF2PY directives have the following form:\n\nwhere allowed comment characters for fixed and free format Fortran codes are\n`cC*!#` and `!`, respectively. Everything that follows `<comment char>f2py` is\nignored by a compiler but read by F2PY as a normal non-comment Fortran line:\n\nNote\n\nWhen F2PY finds a line with F2PY directive, the directive is first replaced by\n5 spaces and then the line is reread.\n\nFor fixed format Fortran codes, `<comment char>` must be at the first column\nof a file, of course. For free format Fortran codes, the F2PY directives can\nappear anywhere in a file.\n\nC expressions are used in the following parts of signature files:\n\nA C expression may contain:\n\nthe following CPP macros:\n\nFor initializing an array `<array name>`, F2PY generates a loop over all\nindices and dimensions that executes the following pseudo-statement:\n\nwhere `_i[<i>]` refers to the `<i>`-th index value and that runs from `0` to\n`shape(<array name>,<i>)-1`.\n\nFor example, a function `myrange(n)` generated from the following signature\n\nis equivalent to `numpy.arange(n,dtype=float)`.\n\nWarning\n\nF2PY may lower cases also in C expressions when scanning Fortran codes (see\n`--[no]-lower` option).\n\nA multi-line block starts with `'''` (triple single-quotes) and ends with\n`'''` in some strictly subsequent line. Multi-line blocks can be used only\nwithin .pyf files. The contents of a multi-line block can be arbitrary (except\nthat it cannot contain `'''`) and no transformations (e.g. lowering cases) are\napplied to it.\n\nCurrently, multi-line blocks can be used in the following constructs:\n\n"}, {"name": "Indexing on ndarrays", "path": "user/basics.indexing", "type": "User Guide", "text": "\nSee also\n\nIndexing routines\n\n`ndarrays` can be indexed using the standard Python `x[obj]` syntax, where x\nis the array and obj the selection. There are different kinds of indexing\navailable depending on obj: basic indexing, advanced indexing and field\naccess.\n\nMost of the following examples show the use of indexing when referencing data\nin an array. The examples work just as well when assigning to an array. See\nAssigning values to indexed arrays for specific examples and explanations on\nhow assignments work.\n\nNote that in Python, `x[(exp1, exp2, ..., expN)]` is equivalent to `x[exp1,\nexp2, ..., expN]`; the latter is just syntactic sugar for the former.\n\nSingle element indexing works exactly like that for other standard Python\nsequences. It is 0-based, and accepts negative indices for indexing from the\nend of the array.\n\nIt is not necessary to separate each dimension\u2019s index into its own set of\nsquare brackets.\n\nNote that if one indexes a multidimensional array with fewer indices than\ndimensions, one gets a subdimensional array. For example:\n\nThat is, each index specified selects the array corresponding to the rest of\nthe dimensions selected. In the above example, choosing 0 means that the\nremaining dimension of length 5 is being left unspecified, and that what is\nreturned is an array of that dimensionality and size. It must be noted that\nthe returned array is a view, i.e., it is not a copy of the original, but\npoints to the same values in memory as does the original array. In this case,\nthe 1-D array at the first position (0) is returned. So using a single index\non the returned array, results in a single element being returned. That is:\n\nSo note that `x[0, 2] == x[0][2]` though the second case is more inefficient\nas a new temporary array is created after the first index that is subsequently\nindexed by 2.\n\nNote\n\nNumPy uses C-order indexing. That means that the last index usually represents\nthe most rapidly changing memory location, unlike Fortran or IDL, where the\nfirst index represents the most rapidly changing location in memory. This\ndifference represents a great potential for confusion.\n\nBasic slicing extends Python\u2019s basic concept of slicing to N dimensions. Basic\nslicing occurs when obj is a `slice` object (constructed by `start:stop:step`\nnotation inside of brackets), an integer, or a tuple of slice objects and\nintegers. `Ellipsis` and `newaxis` objects can be interspersed with these as\nwell.\n\nDeprecated since version 1.15.0: In order to remain backward compatible with a\ncommon usage in Numeric, basic slicing is also initiated if the selection\nobject is any non-ndarray and non-tuple sequence (such as a `list`) containing\n`slice` objects, the `Ellipsis` object, or the `newaxis` object, but not for\ninteger arrays or other embedded sequences.\n\nThe simplest case of indexing with N integers returns an array scalar\nrepresenting the corresponding item. As in Python, all indices are zero-based:\nfor the i-th index \\\\(n_i\\\\), the valid range is \\\\(0 \\le n_i < d_i\\\\) where\n\\\\(d_i\\\\) is the i-th element of the shape of the array. Negative indices are\ninterpreted as counting from the end of the array (i.e., if \\\\(n_i < 0\\\\), it\nmeans \\\\(n_i + d_i\\\\)).\n\nAll arrays generated by basic slicing are always views of the original array.\n\nNote\n\nNumPy slicing creates a view instead of a copy as in the case of built-in\nPython sequences such as string, tuple and list. Care must be taken when\nextracting a small portion from a large array which becomes useless after the\nextraction, because the small portion extracted contains a reference to the\nlarge original array whose memory will not be released until all arrays\nderived from it are garbage-collected. In such cases an explicit `copy()` is\nrecommended.\n\nThe standard rules of sequence slicing apply to basic slicing on a per-\ndimension basis (including using a step index). Some useful concepts to\nremember include:\n\nThe basic slice syntax is `i:j:k` where i is the starting index, j is the\nstopping index, and k is the step (\\\\(k\\neq0\\\\)). This selects the m elements\n(in the corresponding dimension) with index values i, i + k, \u2026, i + (m - 1) k\nwhere \\\\(m = q + (r\\neq0)\\\\) and q and r are the quotient and remainder\nobtained by dividing j - i by k: j - i = q k + r, so that i + (m - 1) k < j.\nFor example:\n\nNegative i and j are interpreted as n + i and n + j where n is the number of\nelements in the corresponding dimension. Negative k makes stepping go towards\nsmaller indices. From the above example:\n\nAssume n is the number of elements in the dimension being sliced. Then, if i\nis not given it defaults to 0 for k > 0 and n - 1 for k < 0 . If j is not\ngiven it defaults to n for k > 0 and -n-1 for k < 0 . If k is not given it\ndefaults to 1. Note that `::` is the same as `:` and means select all indices\nalong this axis. From the above example:\n\nIf the number of objects in the selection tuple is less than N, then `:` is\nassumed for any subsequent dimensions. For example:\n\nBasic slicing with more than one non-`:` entry in the slicing tuple, acts like\nrepeated application of slicing using a single non-`:` entry, where the\nnon-`:` entries are successively taken (with all other non-`:` entries\nreplaced by `:`). Thus, `x[ind1, ..., ind2,:]` acts like `x[ind1][..., ind2,\n:]` under basic slicing.\n\nWarning\n\nThe above is not true for advanced indexing.\n\nThere are some tools to facilitate the easy matching of array shapes with\nexpressions and in assignments.\n\n`Ellipsis` expands to the number of `:` objects needed for the selection tuple\nto index all dimensions. In most cases, this means that the length of the\nexpanded selection tuple is `x.ndim`. There may only be a single ellipsis\npresent. From the above example:\n\nThis is equivalent to:\n\nEach `newaxis` object in the selection tuple serves to expand the dimensions\nof the resulting selection by one unit-length dimension. The added dimension\nis the position of the `newaxis` object in the selection tuple. `newaxis` is\nan alias for `None`, and `None` can be used in place of this with the same\nresult. From the above example:\n\nThis can be handy to combine two arrays in a way that otherwise would require\nexplicit reshaping operations. For example:\n\nAdvanced indexing is triggered when the selection object, obj, is a non-tuple\nsequence object, an `ndarray` (of data type integer or bool), or a tuple with\nat least one sequence object or ndarray (of data type integer or bool). There\nare two types of advanced indexing: integer and Boolean.\n\nAdvanced indexing always returns a copy of the data (contrast with basic\nslicing that returns a view).\n\nWarning\n\nThe definition of advanced indexing means that `x[(1, 2, 3),]` is\nfundamentally different than `x[(1, 2, 3)]`. The latter is equivalent to `x[1,\n2, 3]` which will trigger basic selection while the former will trigger\nadvanced indexing. Be sure to understand why this occurs.\n\nAlso recognize that `x[[1, 2, 3]]` will trigger advanced indexing, whereas due\nto the deprecated Numeric compatibility mentioned above, `x[[1, 2,\nslice(None)]]` will trigger basic slicing.\n\nInteger array indexing allows selection of arbitrary items in the array based\non their N-dimensional index. Each integer array represents a number of\nindices into that dimension.\n\nNegative values are permitted in the index arrays and work as they do with\nsingle indices or slices:\n\nIf the index values are out of bounds then an `IndexError` is thrown:\n\nWhen the index consists of as many integer arrays as dimensions of the array\nbeing indexed, the indexing is straightforward, but different from slicing.\n\nAdvanced indices always are broadcast and iterated as one:\n\nNote that the resulting shape is identical to the (broadcast) indexing array\nshapes `ind_1, ..., ind_N`. If the indices cannot be broadcast to the same\nshape, an exception `IndexError: shape mismatch: indexing arrays could not be\nbroadcast together with shapes...` is raised.\n\nIndexing with multidimensional index arrays tend to be more unusual uses, but\nthey are permitted, and they are useful for some problems. We\u2019ll start with\nthe simplest multidimensional case:\n\nIn this case, if the index arrays have a matching shape, and there is an index\narray for each dimension of the array being indexed, the resultant array has\nthe same shape as the index arrays, and the values correspond to the index set\nfor each position in the index arrays. In this example, the first index value\nis 0 for both index arrays, and thus the first value of the resultant array is\n`y[0, 0]`. The next value is `y[2, 1]`, and the last is `y[4, 2]`.\n\nIf the index arrays do not have the same shape, there is an attempt to\nbroadcast them to the same shape. If they cannot be broadcast to the same\nshape, an exception is raised:\n\nThe broadcasting mechanism permits index arrays to be combined with scalars\nfor other indices. The effect is that the scalar value is used for all the\ncorresponding values of the index arrays:\n\nJumping to the next level of complexity, it is possible to only partially\nindex an array with index arrays. It takes a bit of thought to understand what\nhappens in such cases. For example if we just use one index array with y:\n\nIt results in the construction of a new array where each value of the index\narray selects one row from the array being indexed and the resultant array has\nthe resulting shape (number of index elements, size of row).\n\nIn general, the shape of the resultant array will be the concatenation of the\nshape of the index array (or the shape that all the index arrays were\nbroadcast to) with the shape of any unused dimensions (those not indexed) in\nthe array being indexed.\n\nFrom each row, a specific element should be selected. The row index is just\n`[0, 1, 2]` and the column index specifies the element to choose for the\ncorresponding row, here `[0, 1, 0]`. Using both together the task can be\nsolved using advanced indexing:\n\nTo achieve a behaviour similar to the basic slicing above, broadcasting can be\nused. The function `ix_` can help with this broadcasting. This is best\nunderstood with an example.\n\nFrom a 4x3 array the corner elements should be selected using advanced\nindexing. Thus all elements for which the column is one of `[0, 2]` and the\nrow is one of `[0, 3]` need to be selected. To use advanced indexing one needs\nto select all elements explicitly. Using the method explained previously one\ncould write:\n\nHowever, since the indexing arrays above just repeat themselves, broadcasting\ncan be used (compare operations such as `rows[:, np.newaxis] + columns`) to\nsimplify this:\n\nThis broadcasting can also be achieved using the function `ix_`:\n\nNote that without the `np.ix_` call, only the diagonal elements would be\nselected:\n\nThis difference is the most important thing to remember about indexing with\nmultiple advanced indices.\n\nA real-life example of where advanced indexing may be useful is for a color\nlookup table where we want to map the values of an image into RGB triples for\ndisplay. The lookup table could have a shape (nlookup, 3). Indexing such an\narray with an image with shape (ny, nx) with dtype=np.uint8 (or any integer\ntype so long as values are with the bounds of the lookup table) will result in\nan array of shape (ny, nx, 3) where a triple of RGB values is associated with\neach pixel location.\n\nThis advanced indexing occurs when obj is an array object of Boolean type,\nsuch as may be returned from comparison operators. A single boolean index\narray is practically identical to `x[obj.nonzero()]` where, as described\nabove, `obj.nonzero()` returns a tuple (of length `obj.ndim`) of integer index\narrays showing the `True` elements of obj. However, it is faster when\n`obj.shape == x.shape`.\n\nIf `obj.ndim == x.ndim`, `x[obj]` returns a 1-dimensional array filled with\nthe elements of x corresponding to the `True` values of obj. The search order\nwill be row-major, C-style. If obj has `True` values at entries that are\noutside of the bounds of x, then an index error will be raised. If obj is\nsmaller than x it is identical to filling it with `False`.\n\nA common use case for this is filtering for desired element values. For\nexample, one may wish to select all entries from an array which are not `NaN`:\n\nOr wish to add a constant to all negative elements:\n\nIn general if an index includes a Boolean array, the result will be identical\nto inserting `obj.nonzero()` into the same position and using the integer\narray indexing mechanism described above. `x[ind_1, boolean_array, ind_2]` is\nequivalent to `x[(ind_1,) + boolean_array.nonzero() + (ind_2,)]`.\n\nIf there is only one Boolean array and no integer indexing array present, this\nis straightforward. Care must only be taken to make sure that the boolean\nindex has exactly as many dimensions as it is supposed to work with.\n\nIn general, when the boolean array has fewer dimensions than the array being\nindexed, this is equivalent to `x[b, ...]`, which means x is indexed by b\nfollowed by as many `:` as are needed to fill out the rank of x. Thus the\nshape of the result is one dimension containing the number of True elements of\nthe boolean array, followed by the remaining dimensions of the array being\nindexed:\n\nHere the 4th and 5th rows are selected from the indexed array and combined to\nmake a 2-D array.\n\nFrom an array, select all rows which sum up to less or equal two:\n\nCombining multiple Boolean indexing arrays or a Boolean with an integer\nindexing array can best be understood with the `obj.nonzero()` analogy. The\nfunction `ix_` also supports boolean arrays and will work without any\nsurprises.\n\nUse boolean indexing to select all rows adding up to an even number. At the\nsame time columns 0 and 2 should be selected with an advanced integer index.\nUsing the `ix_` function this can be done with:\n\nWithout the `np.ix_` call, only the diagonal elements would be selected.\n\nOr without `np.ix_` (compare the integer array examples):\n\nUse a 2-D boolean array of shape (2, 3) with four True elements to select rows\nfrom a 3-D array of shape (2, 3, 5) results in a 2-D result of shape (4, 5):\n\nWhen there is at least one slice (`:`), ellipsis (`...`) or `newaxis` in the\nindex (or the array has more dimensions than there are advanced indices), then\nthe behaviour can be more complicated. It is like concatenating the indexing\nresult for each advanced index element.\n\nIn the simplest case, there is only a single advanced index combined with a\nslice. For example:\n\nIn effect, the slice and index array operation are independent. The slice\noperation extracts columns with index 1 and 2, (i.e. the 2nd and 3rd columns),\nfollowed by the index array operation which extracts rows with index 0, 2 and\n4 (i.e the first, third and fifth rows). This is equivalent to:\n\nA single advanced index can, for example, replace a slice and the result array\nwill be the same. However, it is a copy and may have a different memory\nlayout. A slice is preferable when it is possible. For example:\n\nThe easiest way to understand a combination of multiple advanced indices may\nbe to think in terms of the resulting shape. There are two parts to the\nindexing operation, the subspace defined by the basic indexing (excluding\nintegers) and the subspace from the advanced indexing part. Two cases of index\ncombination need to be distinguished:\n\nIn the first case, the dimensions resulting from the advanced indexing\noperation come first in the result array, and the subspace dimensions after\nthat. In the second case, the dimensions from the advanced indexing operations\nare inserted into the result array at the same spot as they were in the\ninitial array (the latter logic is what makes simple advanced indexing behave\njust like slicing).\n\nSuppose `x.shape` is (10, 20, 30) and `ind` is a (2, 3, 4)-shaped indexing\n`intp` array, then `result = x[..., ind, :]` has shape (10, 2, 3, 4, 30)\nbecause the (20,)-shaped subspace has been replaced with a (2, 3, 4)-shaped\nbroadcasted indexing subspace. If we let i, j, k loop over the (2, 3,\n4)-shaped subspace then `result[..., i, j, k, :] = x[..., ind[i, j, k], :]`.\nThis example produces the same result as `x.take(ind, axis=-2)`.\n\nLet `x.shape` be (10, 20, 30, 40, 50) and suppose `ind_1` and `ind_2` can be\nbroadcast to the shape (2, 3, 4). Then `x[:, ind_1, ind_2]` has shape (10, 2,\n3, 4, 40, 50) because the (20, 30)-shaped subspace from X has been replaced\nwith the (2, 3, 4) subspace from the indices. However, `x[:, ind_1, :, ind_2]`\nhas shape (2, 3, 4, 10, 30, 50) because there is no unambiguous place to drop\nin the indexing subspace, thus it is tacked-on to the beginning. It is always\npossible to use `.transpose()` to move the subspace anywhere desired. Note\nthat this example cannot be replicated using `take`.\n\nSlicing can be combined with broadcasted boolean indices:\n\nSee also\n\nStructured arrays\n\nIf the `ndarray` object is a structured array the fields of the array can be\naccessed by indexing the array with strings, dictionary-like.\n\nIndexing `x['field-name']` returns a new view to the array, which is of the\nsame shape as x (except when the field is a sub-array) but of data type\n`x.dtype['field-name']` and contains only the part of the data in the\nspecified field. Also, record array scalars can be \u201cindexed\u201d this way.\n\nIndexing into a structured array can also be done with a list of field names,\ne.g. `x[['field-name1', 'field-name2']]`. As of NumPy 1.16, this returns a\nview containing only those fields. In older versions of NumPy, it returned a\ncopy. See the user guide section on Structured arrays for more information on\nmultifield indexing.\n\nIf the accessed field is a sub-array, the dimensions of the sub-array are\nappended to the shape of the result. For example:\n\n`x.flat` returns an iterator that will iterate over the entire array (in\nC-contiguous style with the last index varying the fastest). This iterator\nobject can also be indexed using basic slicing or advanced indexing as long as\nthe selection object is not a tuple. This should be clear from the fact that\n`x.flat` is a 1-dimensional view. It can be used for integer indexing with\n1-dimensional C-style-flat indices. The shape of any returned array is\ntherefore the shape of the integer indexing object.\n\nAs mentioned, one can select a subset of an array to assign to using a single\nindex, slices, and index and mask arrays. The value being assigned to the\nindexed array must be shape consistent (the same shape or broadcastable to the\nshape the index produces). For example, it is permitted to assign a constant\nto a slice:\n\nor an array of the right size:\n\nNote that assignments may result in changes if assigning higher types to lower\ntypes (like floats to ints) or even exceptions (assigning complex to floats or\nints):\n\nUnlike some of the references (such as array and mask indices) assignments are\nalways made to the original data in the array (indeed, nothing else would make\nsense!). Note though, that some actions may not work as one may naively\nexpect. This particular example is often surprising to people:\n\nWhere people expect that the 1st location will be incremented by 3. In fact,\nit will only be incremented by 1. The reason is that a new array is extracted\nfrom the original (as a temporary) containing the values at 1, 1, 3, 1, then\nthe value 1 is added to the temporary, and then the temporary is assigned back\nto the original array. Thus the value of the array at `x[1] + 1` is assigned\nto `x[1]` three times, rather than being incremented 3 times.\n\nThe indexing syntax is very powerful but limiting when dealing with a variable\nnumber of indices. For example, if you want to write a function that can\nhandle arguments with various numbers of dimensions without having to write\nspecial case code for each number of possible dimensions, how can that be\ndone? If one supplies to the index a tuple, the tuple will be interpreted as a\nlist of indices. For example:\n\nSo one can use code to construct tuples of any number of indices and then use\nthese within an index.\n\nSlices can be specified within programs by using the slice() function in\nPython. For example:\n\nLikewise, ellipsis can be specified by code by using the Ellipsis object:\n\nFor this reason, it is possible to use the output from the `np.nonzero()`\nfunction directly as an index since it always returns a tuple of index arrays.\n\nBecause the special treatment of tuples, they are not automatically converted\nto an array as a list would be. As an example:\n\nThese are some detailed notes, which are not of importance for day to day\nindexing (in no particular order):\n\n"}, {"name": "Indexing routines", "path": "reference/arrays.indexing", "type": "Indexing routines", "text": "\nSee also\n\nIndexing on ndarrays\n\n`c_`\n\nTranslates slice objects to concatenation along the second axis.\n\n`r_`\n\nTranslates slice objects to concatenation along the first axis.\n\n`s_`\n\nA nicer way to build up index tuples for arrays.\n\n`nonzero`(a)\n\nReturn the indices of the elements that are non-zero.\n\n`where`(condition, [x, y], /)\n\nReturn elements chosen from `x` or `y` depending on `condition`.\n\n`indices`(dimensions[, dtype, sparse])\n\nReturn an array representing the indices of a grid.\n\n`ix_`(*args)\n\nConstruct an open mesh from multiple sequences.\n\n`ogrid`\n\n`nd_grid` instance which returns an open multi-dimensional \"meshgrid\".\n\n`ravel_multi_index`(multi_index, dims[, mode, ...])\n\nConverts a tuple of index arrays into an array of flat indices, applying\nboundary modes to the multi-index.\n\n`unravel_index`(indices, shape[, order])\n\nConverts a flat index or array of flat indices into a tuple of coordinate\narrays.\n\n`diag_indices`(n[, ndim])\n\nReturn the indices to access the main diagonal of an array.\n\n`diag_indices_from`(arr)\n\nReturn the indices to access the main diagonal of an n-dimensional array.\n\n`mask_indices`(n, mask_func[, k])\n\nReturn the indices to access (n, n) arrays, given a masking function.\n\n`tril_indices`(n[, k, m])\n\nReturn the indices for the lower-triangle of an (n, m) array.\n\n`tril_indices_from`(arr[, k])\n\nReturn the indices for the lower-triangle of arr.\n\n`triu_indices`(n[, k, m])\n\nReturn the indices for the upper-triangle of an (n, m) array.\n\n`triu_indices_from`(arr[, k])\n\nReturn the indices for the upper-triangle of arr.\n\n`take`(a, indices[, axis, out, mode])\n\nTake elements from an array along an axis.\n\n`take_along_axis`(arr, indices, axis)\n\nTake values from the input array by matching 1d index and data slices.\n\n`choose`(a, choices[, out, mode])\n\nConstruct an array from an index array and a list of arrays to choose from.\n\n`compress`(condition, a[, axis, out])\n\nReturn selected slices of an array along given axis.\n\n`diag`(v[, k])\n\nExtract a diagonal or construct a diagonal array.\n\n`diagonal`(a[, offset, axis1, axis2])\n\nReturn specified diagonals.\n\n`select`(condlist, choicelist[, default])\n\nReturn an array drawn from elements in choicelist, depending on conditions.\n\n`lib.stride_tricks.sliding_window_view`(x, ...)\n\nCreate a sliding window view into the array with the given window shape.\n\n`lib.stride_tricks.as_strided`(x[, shape, ...])\n\nCreate a view into the array with the given shape and strides.\n\n`place`(arr, mask, vals)\n\nChange elements of an array based on conditional and input values.\n\n`put`(a, ind, v[, mode])\n\nReplaces specified elements of an array with given values.\n\n`put_along_axis`(arr, indices, values, axis)\n\nPut values into the destination array by matching 1d index and data slices.\n\n`putmask`(a, mask, values)\n\nChanges elements of an array based on conditional and input values.\n\n`fill_diagonal`(a, val[, wrap])\n\nFill the main diagonal of the given array of any dimensionality.\n\n`nditer`(op[, flags, op_flags, op_dtypes, ...])\n\nEfficient multi-dimensional iterator object to iterate over arrays.\n\n`ndenumerate`(arr)\n\nMultidimensional index iterator.\n\n`ndindex`(*shape)\n\nAn N-dimensional iterator object to index arrays.\n\n`nested_iters`(op, axes[, flags, op_flags, ...])\n\nCreate nditers for use in nested loops\n\n`flatiter`()\n\nFlat iterator object to iterate over arrays.\n\n`lib.Arrayterator`(var[, buf_size])\n\nBuffered iterator for big arrays.\n\n"}, {"name": "Input and output", "path": "reference/routines.io", "type": "Input and output", "text": "\n`load`(file[, mmap_mode, allow_pickle, ...])\n\nLoad arrays or pickled objects from `.npy`, `.npz` or pickled files.\n\n`save`(file, arr[, allow_pickle, fix_imports])\n\nSave an array to a binary file in NumPy `.npy` format.\n\n`savez`(file, *args, **kwds)\n\nSave several arrays into a single file in uncompressed `.npz` format.\n\n`savez_compressed`(file, *args, **kwds)\n\nSave several arrays into a single file in compressed `.npz` format.\n\nThe format of these binary file types is documented in `numpy.lib.format`\n\n`loadtxt`(fname[, dtype, comments, delimiter, ...])\n\nLoad data from a text file.\n\n`savetxt`(fname, X[, fmt, delimiter, newline, ...])\n\nSave an array to a text file.\n\n`genfromtxt`(fname[, dtype, comments, ...])\n\nLoad data from a text file, with missing values handled as specified.\n\n`fromregex`(file, regexp, dtype[, encoding])\n\nConstruct an array from a text file, using regular expression parsing.\n\n`fromstring`(string[, dtype, count, like])\n\nA new 1-D array initialized from text data in a string.\n\n`ndarray.tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`ndarray.tolist`()\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\n`fromfile`(file[, dtype, count, sep, offset, like])\n\nConstruct an array from data in a text or binary file.\n\n`ndarray.tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`array2string`(a[, max_line_width, precision, ...])\n\nReturn a string representation of an array.\n\n`array_repr`(arr[, max_line_width, precision, ...])\n\nReturn the string representation of an array.\n\n`array_str`(a[, max_line_width, precision, ...])\n\nReturn a string representation of the data in an array.\n\n`format_float_positional`(x[, precision, ...])\n\nFormat a floating-point scalar as a decimal string in positional notation.\n\n`format_float_scientific`(x[, precision, ...])\n\nFormat a floating-point scalar as a decimal string in scientific notation.\n\n`memmap`(filename[, dtype, mode, offset, ...])\n\nCreate a memory-map to an array stored in a binary file on disk.\n\n`lib.format.open_memmap`(filename[, mode, ...])\n\nOpen a .npy file as a memory-mapped array.\n\n`set_printoptions`([precision, threshold, ...])\n\nSet printing options.\n\n`get_printoptions`()\n\nReturn the current print options.\n\n`set_string_function`(f[, repr])\n\nSet a Python function to be used when pretty printing arrays.\n\n`printoptions`(*args, **kwargs)\n\nContext manager for setting print options.\n\n`binary_repr`(num[, width])\n\nReturn the binary representation of the input number as a string.\n\n`base_repr`(number[, base, padding])\n\nReturn a string representation of a number in the given base system.\n\n`DataSource`([destpath])\n\nA generic data source file (file, http, ftp, ...).\n\n`lib.format`\n\nBinary serialization\n\n"}, {"name": "Install git", "path": "dev/gitwash/git_intro", "type": "Development", "text": "\nDeveloping with git can be done entirely without github. Git is a distributed\nversion control system. In order to use git on your machine you must install\nit.\n\n"}, {"name": "int **cancastscalarkindto", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.cancastscalarkindto", "type": "Python Types and C-Structures", "text": "\nEither `NULL` or an array of `NPY_NSCALARKINDS` pointers. These pointers\nshould each be either `NULL` or a pointer to an array of integers (terminated\nby `NPY_NOTYPE`) indicating data-types that a scalar of this data-type of the\nspecified kind can be cast to safely (this usually means without losing\nprecision).\n\n"}, {"name": "int *cancastto", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.cancastto", "type": "Python Types and C-Structures", "text": "\nEither `NULL` or an array of integers (terminated by `NPY_NOTYPE` ) indicated\ndata-types that this data-type can be cast to safely (this usually means\nwithout losing precision).\n\n"}, {"name": "int *core_dim_ixs", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_dim_ixs", "type": "Python Types and C-Structures", "text": "\nDimension indices in a flattened form; indices of argument `k` are stored in\n`core_dim_ixs[core_offsets[k] : core_offsets[k] + core_numdims[k]]`\n\n"}, {"name": "int *core_num_dims", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_num_dims", "type": "Python Types and C-Structures", "text": "\nNumber of core dimensions of each argument\n\n"}, {"name": "int *core_offsets", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_offsets", "type": "Python Types and C-Structures", "text": "\nPosition of 1st core dimension of each argument in `core_dim_ixs`, equivalent\nto cumsum(`core_num_dims`)\n\n"}, {"name": "int alignment", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.alignment", "type": "Python Types and C-Structures", "text": "\nA number providing alignment information for this data type. Specifically, it\nshows how far from the start of a 2-element structure (whose first element is\na `char` ), the compiler places an item of this type: `offsetof(struct {char\nc; type v;}, v)`\n\n"}, {"name": "int argmax()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argmax", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that retrieves the index of the largest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the largest element is returned in `max_ind`.\n\n"}, {"name": "int argmin()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argmin", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that retrieves the index of the smallest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the smallest element is returned in `min_ind`.\n\n"}, {"name": "int argsort()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argsort", "type": "Python Types and C-Structures", "text": "\nAn array of function pointers to sorting algorithms for this data type. The\nsame sorting algorithms as for sort are available. The indices producing the\nsort are returned in `result` (which must be initialized with indices 0 to\n`length-1` inclusive).\n\n"}, {"name": "int compare()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.compare", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that compares two elements of the array, `arr`,\npointed to by `d1` and `d2`. This function requires behaved (aligned and not\nswapped) arrays. The return value is 1 if * `d1` > * `d2`, 0 if * `d1` == *\n`d2`, and -1 if * `d1` < * `d2`. The array object `arr` is used to retrieve\nitemsize and field information for flexible arrays.\n\n"}, {"name": "int core_enabled", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_enabled", "type": "Python Types and C-Structures", "text": "\n0 for scalar ufuncs; 1 for generalized ufuncs\n\n"}, {"name": "int core_num_dim_ix", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_num_dim_ix", "type": "Python Types and C-Structures", "text": "\nNumber of distinct core dimension names in the signature\n\n"}, {"name": "int doxy_javadoc_example()", "path": "dev/howto-docs", "type": "Development", "text": "\nThis guide will help you decide what to contribute and how to submit it to the\nofficial NumPy documentation.\n\nThe NumPy community has set a firm goal of improving its documentation. We\nhold regular documentation meetings on Zoom (dates are announced on the numpy-\ndiscussion mailing list), and everyone is welcome. Reach out if you have\nquestions or need someone to guide you through your first steps \u2013 we\u2019re happy\nto help. Minutes are taken on hackmd.io and stored in the NumPy Archive\nrepository.\n\nThe NumPy Documentation has the details covered. API reference documentation\nis generated directly from docstrings in the code when the documentation is\nbuilt. Although we have mostly complete reference documentation for each\nfunction and class exposed to users, there is a lack of usage examples for\nsome of them.\n\nWhat we lack are docs with broader scope \u2013 tutorials, how-tos, and\nexplanations. Reporting defects is another way to contribute. We discuss both.\n\nWe\u2019re eager to hear about and fix doc defects. But to attack the biggest\nproblems we end up having to defer or overlook some bug reports. Here are the\nbest defects to go after.\n\nTop priority goes to technical inaccuracies \u2013 a docstring missing a parameter,\na faulty description of a function/parameter/method, and so on. Other\n\u201cstructural\u201d defects like broken links also get priority. All these fixes are\neasy to confirm and put in place. You can submit a pull request (PR) with the\nfix, if you know how to do that; otherwise please open an issue.\n\nTypos and misspellings fall on a lower rung; we welcome hearing about them but\nmay not be able to fix them promptly. These too can be handled as pull\nrequests or issues.\n\nObvious wording mistakes (like leaving out a \u201cnot\u201d) fall into the typo\ncategory, but other rewordings \u2013 even for grammar \u2013 require a judgment call,\nwhich raises the bar. Test the waters by first presenting the fix as an issue.\n\nSome functions/objects like numpy.ndarray.transpose, numpy.array etc. defined\nin C-extension modules have their docstrings defined separately in\n_add_newdocs.py\n\nYour frustrations using our documents are our best guide to what needs fixing.\n\nIf you write a missing doc you join the front line of open source, but it\u2019s a\nmeaningful contribution just to let us know what\u2019s missing. If you want to\ncompose a doc, run your thoughts by the mailing list for further ideas and\nfeedback. If you want to alert us to a gap, open an issue. See this issue for\nan example.\n\nIf you\u2019re looking for subjects, our formal roadmap for documentation is a\nNumPy Enhancement Proposal (NEP), NEP 44 - Restructuring the NumPy\nDocumentation. It identifies areas where our docs need help and lists several\nadditions we\u2019d like to see, including Jupyter notebooks.\n\nThere are formulas for writing useful documents, and four formulas cover\nnearly everything. There are four formulas because there are four categories\nof document \u2013 `tutorial`, `how-to guide`, `explanation`, and `reference`. The\ninsight that docs divide up this way belongs to Daniele Procida and his\nDi\u00e1taxis Framework. When you begin a document or propose one, have in mind\nwhich of these types it will be.\n\nIn addition to the documentation that is part of the NumPy source tree, you\ncan submit content in Jupyter Notebook format to the NumPy Tutorials page.\nThis set of tutorials and educational materials is meant to provide high-\nquality resources by the NumPy project, both for self-learning and for\nteaching classes with. These resources are developed in a separate GitHub\nrepository, numpy-tutorials, where you can check out existing notebooks, open\nissues to suggest new topics or submit your own tutorials as pull requests.\n\nDon\u2019t worry if English is not your first language, or if you can only come up\nwith a rough draft. Open source is a community effort. Do your best \u2013 we\u2019ll\nhelp fix issues.\n\nImages and real-life data make text more engaging and powerful, but be sure\nwhat you use is appropriately licensed and available. Here again, even a rough\nidea for artwork can be polished by others.\n\nFor now, the only data formats accepted by NumPy are those also used by other\nPython scientific libraries like pandas, SciPy, or Matplotlib. We\u2019re\ndeveloping a package to accept more formats; contact us for details.\n\nNumPy documentation is kept in the source code tree. To get your document into\nthe docbase you must download the tree, build it, and submit a pull request.\nIf GitHub and pull requests are new to you, check our Contributor Guide.\n\nOur markup language is reStructuredText (rST), which is more elaborate than\nMarkdown. Sphinx, the tool many Python projects use to build and link project\ndocumentation, converts the rST into HTML and other formats. For more on rST,\nsee the Quick reStructuredText Guide or the reStructuredText Primer\n\nIf you run across outside material that would be a useful addition to the\nNumPy docs, let us know by opening an issue.\n\nYou don\u2019t have to contribute here to contribute to NumPy. You\u2019ve contributed\nif you write a tutorial on your blog, create a YouTube video, or answer\nquestions on Stack Overflow and other sites.\n\nNumPy style governs cases where:\n\nOur current rules:\n\nWhen using Sphinx in combination with the NumPy conventions, you should use\nthe `numpydoc` extension so that your docstrings will be handled correctly.\nFor example, Sphinx will extract the `Parameters` section from your docstring\nand convert it into a field list. Using `numpydoc` will also avoid the\nreStructuredText errors produced by plain Sphinx when it encounters NumPy\ndocstring conventions like section headers (e.g. `-------------`) that sphinx\ndoes not expect to find in docstrings.\n\nIt is available from:\n\nNote that for documentation within NumPy, it is not necessary to do `import\nnumpy as np` at the beginning of an example.\n\nPlease use the `numpydoc` formatting standard as shown in their example.\n\nNumPy uses Doxygen to parse specially-formatted C/C++ comment blocks. This\ngenerates XML files, which are converted by Breathe into RST, which is used by\nSphinx.\n\nIt takes three steps to complete the documentation process:\n\nAlthough there is still no commenting style set to follow, the Javadoc is more\npreferable than the others due to the similarities with the current existing\nnon-indexed comment blocks.\n\nNote\n\nPlease see \u201cDocumenting the code\u201d.\n\nThis is what Javadoc style looks like:\n\nAnd here is how it is rendered:\n\nThis a simple brief.\n\nAnd the details goes here. Multi lines are welcome.\n\nleave a comment for the returned value.\n\nFor line comment, you can use a triple forward slash. For example:\n\nAnd here is how it is rendered:\n\nTemplate to represent limbo numbers.\n\nSpecializations for integer types that are part of nowhere. It doesn\u2019t support\nwith any real types.\n\nType of the integer. Required to be an integer type.\n\nNumber of elements.\n\nDefault constructor. Initialize nothing.\n\nSet Default behavior for copy the limbo.\n\nReturns the raw data for the limbo.\n\nExample for inline comment.\n\nNote\n\nFor more tags/commands, please take a look at\nhttps://www.doxygen.nl/manual/commands.html\n\n`@brief`\n\nStarts a paragraph that serves as a brief description. By default the first\nsentence of the documentation block is automatically treated as a brief\ndescription, since option JAVADOC_AUTOBRIEF is enabled within doxygen\nconfigurations.\n\n`@details`\n\nJust like `@brief` starts a brief description, `@details` starts the detailed\ndescription. You can also start a new paragraph (blank line) then the\n`@details` command is not needed.\n\n`@param`\n\nStarts a parameter description for a function parameter with name <parameter-\nname>, followed by a description of the parameter. The existence of the\nparameter is checked and a warning is given if the documentation of this (or\nany other) parameter is missing or not present in the function declaration or\ndefinition.\n\n`@return`\n\nStarts a return value description for a function. Multiple adjacent `@return`\ncommands will be joined into a single paragraph. The `@return` description\nends when a blank line or some other sectioning command is encountered.\n\n`@code/@endcode`\n\nStarts/Ends a block of code. A code block is treated differently from ordinary\ntext. It is interpreted as source code.\n\n`@rst/@endrst`\n\nStarts/Ends a block of reST markup.\n\nTake a look at the following example:\n\nAnd here is how it is rendered:\n\nA comment block contains reST markup.\n\nSome code example:\n\nNote\n\nThanks to Breathe, we were able to bring it to Doxygen\n\nNot all headers files are collected automatically. You have to add the desired\nC/C++ header paths within the sub-config files of Doxygen.\n\nSub-config files have the unique name `.doxyfile`, which you can usually find\nnear directories that contain documented headers. You need to create a new\nconfig file if there\u2019s not one located in a path close(2-depth) to the headers\nyou want to add.\n\nSub-config files can accept any of Doxygen configuration options, but do not\noverride or re-initialize any configuration option, rather only use the\nconcatenation operator \u201c+=\u201d. For example:\n\nNote\n\n@CUR_DIR is a template constant returns the current dir path of the sub-config\nfile.\n\nBreathe provides a wide range of custom directives to allow converting the\ndocuments generated by Doxygen into reST files.\n\nNote\n\nFor more information, please check out \u201cDirectives & Config Variables\u201d\n\n`doxygenfunction`\n\nThis directive generates the appropriate output for a single function. The\nfunction name is required to be unique in the project.\n\nCheckout the example to see it in action.\n\n`doxygenclass`\n\nThis directive generates the appropriate output for a single class. It takes\nthe standard project, path, outline and no-link options and additionally the\nmembers, protected-members, private-members, undoc-members, membergroups and\nmembers-only options:\n\nCheckout the `doxygenclass documentation\n<https://breathe.readthedocs.io/en/latest/class.html#class-example>_` for more\ndetails and to see it in action.\n\n`doxygennamespace`\n\nThis directive generates the appropriate output for the contents of a\nnamespace. It takes the standard project, path, outline and no-link options\nand additionally the content-only, members, protected-members, private-members\nand undoc-members options. To reference a nested namespace, the full\nnamespaced path must be provided, e.g. foo::bar for the bar namespace inside\nthe foo namespace.\n\nCheckout the doxygennamespace documentation for more details and to see it in\naction.\n\n`doxygengroup`\n\nThis directive generates the appropriate output for the contents of a doxygen\ngroup. A doxygen group can be declared with specific doxygen markup in the\nsource comments as covered in the doxygen grouping documentation.\n\nIt takes the standard project, path, outline and no-link options and\nadditionally the content-only, members, protected-members, private-members and\nundoc-members options.\n\nCheckout the doxygengroup documentation for more details and to see it in\naction.\n\n"}, {"name": "int elsize", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.elsize", "type": "Python Types and C-Structures", "text": "\nFor data types that are always the same size (such as long), this holds the\nsize of the data type. For flexible data types where different arrays can have\na different elementsize, this should be 0.\n\n"}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.PyArray_Chunk.flags", "type": "Python Types and C-Structures", "text": "\nAny data flags (e.g. `NPY_ARRAY_WRITEABLE` ) that should be used to interpret\nthe memory.\n\n"}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.NPY_AO.flags", "type": "Python Types and C-Structures", "text": "\nPointed to by the macro `PyArray_FLAGS`, this data member represents the flags\nindicating how the memory pointed to by data is to be interpreted. Possible\nflags are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_OWNDATA`, `NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`,\n`NPY_ARRAY_WRITEBACKIFCOPY`, and `NPY_ARRAY_UPDATEIFCOPY`.\n\n"}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.flags", "type": "Python Types and C-Structures", "text": "\nAny of the bits `NPY_ARRAY_C_CONTIGUOUS` (1), `NPY_ARRAY_F_CONTIGUOUS` (2),\n`NPY_ARRAY_ALIGNED` (0x100), `NPY_ARRAY_NOTSWAPPED` (0x200), or\n`NPY_ARRAY_WRITEABLE` (0x400) to indicate something about the data. The\n`NPY_ARRAY_ALIGNED`, `NPY_ARRAY_C_CONTIGUOUS`, and `NPY_ARRAY_F_CONTIGUOUS`\nflags can actually be determined from the other parameters. The flag\n`NPY_ARR_HAS_DESCR` (0x800) can also be set to indicate to objects consuming\nthe version 3 array interface that the descr member of the structure is\npresent (it will be ignored by objects consuming version 2 of the array\ninterface).\n\n"}, {"name": "int fromstr()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fromstr", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that converts the string pointed to by `str` to one\nelement of the corresponding type and places it in the memory location pointed\nto by `ip`. After the conversion is completed, `*endptr` points to the rest of\nthe string. The last argument `arr` is the array into which ip points (needed\nfor variable-size data- types). Returns 0 on success or -1 on failure.\nRequires a behaved array. This function should be called without holding the\nPython GIL, and has to grab it for error reporting.\n\n"}, {"name": "int identity", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.identity", "type": "Python Types and C-Structures", "text": "\nEither `PyUFunc_One`, `PyUFunc_Zero`, `PyUFunc_MinusOne`, `PyUFunc_None`,\n`PyUFunc_ReorderableNone`, or `PyUFunc_IdentityValue` to indicate the identity\nfor this operation. It is only used for a reduce-like call on an empty array.\n\n"}, {"name": "int itemsize", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.itemsize", "type": "Python Types and C-Structures", "text": "\nThe number of bytes each item in the array requires.\n\n"}, {"name": "int len", "path": "reference/c-api/types-and-structures#c.PyArray_Dims.len", "type": "Python Types and C-Structures", "text": "\nThe length of the list of integers. It is assumed safe to access ptr [0] to\nptr [len-1].\n\n"}, {"name": "int nargs", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.nargs", "type": "Python Types and C-Structures", "text": "\nThe total number of arguments (nin \\+ nout). This must be less than\n`NPY_MAXARGS`.\n\n"}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.NPY_AO.nd", "type": "Python Types and C-Structures", "text": "\nAn integer providing the number of dimensions for this array. When nd is 0,\nthe array is sometimes called a rank-0 array. Such arrays have undefined\ndimensions and strides and cannot be accessed. Macro `PyArray_NDIM` defined in\n`ndarraytypes.h` points to this data member. `NPY_MAXDIMS` is the largest\nnumber of dimensions for any array.\n\n"}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject.nd", "type": "Python Types and C-Structures", "text": "\nThe number of dimensions in the broadcasted result.\n\n"}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.nd", "type": "Python Types and C-Structures", "text": "\nthe number of dimensions in the array.\n\n"}, {"name": "int nout", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.nout", "type": "Python Types and C-Structures", "text": "\nThe number of output arguments.\n\n"}, {"name": "int npy_clear_floatstatus()", "path": "reference/c-api/coremath#c.npy_clear_floatstatus", "type": "NumPy core libraries", "text": "\nClears the floating point status. Returns the previous status mask.\n\nNote that `npy_clear_floatstatus_barrier` is preferable as it prevents\naggressive compiler optimizations reordering the call relative to the code\nsetting the status, which could lead to incorrect results.\n\nNew in version 1.9.0.\n\n"}, {"name": "int npy_clear_floatstatus_barrier()", "path": "reference/c-api/coremath#c.npy_clear_floatstatus_barrier", "type": "NumPy core libraries", "text": "\nClears the floating point status. A pointer to a local variable is passed in\nto prevent aggressive compiler optimizations from reordering this function\ncall. Returns the previous status mask.\n\nNew in version 1.15.0.\n\n"}, {"name": "int npy_get_floatstatus()", "path": "reference/c-api/coremath#c.npy_get_floatstatus", "type": "NumPy core libraries", "text": "\nGet floating point status. Returns a bitmask with following possible flags:\n\nNote that `npy_get_floatstatus_barrier` is preferable as it prevents\naggressive compiler optimizations reordering the call relative to the code\nsetting the status, which could lead to incorrect results.\n\nNew in version 1.9.0.\n\n"}, {"name": "int npy_get_floatstatus_barrier()", "path": "reference/c-api/coremath#c.npy_get_floatstatus_barrier", "type": "NumPy core libraries", "text": "\nGet floating point status. A pointer to a local variable is passed in to\nprevent aggressive compiler optimizations from reordering this function call\nrelative to the code setting the status, which could lead to incorrect\nresults.\n\nReturns a bitmask with following possible flags:\n\nNew in version 1.15.0.\n\n"}, {"name": "int npy_half_eq()", "path": "reference/c-api/coremath#c.npy_half_eq", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 == h2).\n\n"}, {"name": "int npy_half_eq_nonan()", "path": "reference/c-api/coremath#c.npy_half_eq_nonan", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats that are known to not be NaN (h1 == h2). If\na value is NaN, the result is undefined.\n\n"}, {"name": "int npy_half_ge()", "path": "reference/c-api/coremath#c.npy_half_ge", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 >= h2).\n\n"}, {"name": "int npy_half_gt()", "path": "reference/c-api/coremath#c.npy_half_gt", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 > h2).\n\n"}, {"name": "int npy_half_isfinite()", "path": "reference/c-api/coremath#c.npy_half_isfinite", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float is finite (not NaN or Inf).\n\n"}, {"name": "int npy_half_isinf()", "path": "reference/c-api/coremath#c.npy_half_isinf", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float is plus or minus Inf.\n\n"}, {"name": "int npy_half_isnan()", "path": "reference/c-api/coremath#c.npy_half_isnan", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float is a NaN.\n\n"}, {"name": "int npy_half_iszero()", "path": "reference/c-api/coremath#c.npy_half_iszero", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float has a value equal to zero. This may be\nslightly faster than calling npy_half_eq(h, NPY_ZERO).\n\n"}, {"name": "int npy_half_le()", "path": "reference/c-api/coremath#c.npy_half_le", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 <= h2).\n\n"}, {"name": "int npy_half_le_nonan()", "path": "reference/c-api/coremath#c.npy_half_le_nonan", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats that are known to not be NaN (h1 <= h2). If\na value is NaN, the result is undefined.\n\n"}, {"name": "int npy_half_lt()", "path": "reference/c-api/coremath#c.npy_half_lt", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 < h2).\n\n"}, {"name": "int npy_half_lt_nonan()", "path": "reference/c-api/coremath#c.npy_half_lt_nonan", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats that are known to not be NaN (h1 < h2). If\na value is NaN, the result is undefined.\n\n"}, {"name": "int npy_half_ne()", "path": "reference/c-api/coremath#c.npy_half_ne", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 != h2).\n\n"}, {"name": "int npy_half_signbit()", "path": "reference/c-api/coremath#c.npy_half_signbit", "type": "NumPy core libraries", "text": "\nReturns 1 is h is negative, 0 otherwise.\n\n"}, {"name": "int NpyIter_CreateCompatibleStrides()", "path": "reference/c-api/iterator#c.NpyIter_CreateCompatibleStrides", "type": "Array Iterator API", "text": "\nBuilds a set of strides which are the same as the strides of an output array\ncreated using the `NPY_ITER_ALLOCATE` flag, where NULL was passed for op_axes.\nThis is for data packed contiguously, but not necessarily in C or Fortran\norder. This should be used together with `NpyIter_GetShape` and\n`NpyIter_GetNDim` with the flag `NPY_ITER_MULTI_INDEX` passed into the\nconstructor.\n\nA use case for this function is to match the shape and layout of the iterator\nand tack on one or more dimensions. For example, in order to generate a vector\nper input value for a numerical gradient, you pass in ndim*itemsize for\nitemsize, then add another dimension to the end with size ndim and stride\nitemsize. To do the Hessian matrix, you do the same thing but add two\ndimensions, or take advantage of the symmetry and pack it into 1 dimension\nwith a particular encoding.\n\nThis function may only be called if the iterator is tracking a multi-index and\nif `NPY_ITER_DONT_NEGATE_STRIDES` was used to prevent an axis from being\niterated in reverse order.\n\nIf an array is created with this method, simply adding \u2018itemsize\u2019 for each\niteration will traverse the new array matching the iterator.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_Deallocate()", "path": "reference/c-api/iterator#c.NpyIter_Deallocate", "type": "Array Iterator API", "text": "\nDeallocates the iterator object and resolves any needed writebacks.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_EnableExternalLoop()", "path": "reference/c-api/iterator#c.NpyIter_EnableExternalLoop", "type": "Array Iterator API", "text": "\nIf `NpyIter_RemoveMultiIndex` was called, you may want to enable the flag\n`NPY_ITER_EXTERNAL_LOOP`. This flag is not permitted together with\n`NPY_ITER_MULTI_INDEX`, so this function is provided to enable the feature\nafter `NpyIter_RemoveMultiIndex` is called. This function also resets the\niterator to its initial state.\n\nWARNING: This function changes the internal logic of the iterator. Any cached\nfunctions or pointers from the iterator must be retrieved again!\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GetNDim()", "path": "reference/c-api/iterator#c.NpyIter_GetNDim", "type": "Array Iterator API", "text": "\nReturns the number of dimensions being iterated. If a multi-index was not\nrequested in the iterator constructor, this value may be smaller than the\nnumber of dimensions in the original objects.\n\n"}, {"name": "int NpyIter_GetNOp()", "path": "reference/c-api/iterator#c.NpyIter_GetNOp", "type": "Array Iterator API", "text": "\nReturns the number of operands in the iterator.\n\n"}, {"name": "int NpyIter_GetShape()", "path": "reference/c-api/iterator#c.NpyIter_GetShape", "type": "Array Iterator API", "text": "\nReturns the broadcast shape of the iterator in `outshape`. This can only be\ncalled on an iterator which is tracking a multi-index.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GotoIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoIndex", "type": "Array Iterator API", "text": "\nAdjusts the iterator to point to the `index` specified. If the iterator was\nconstructed with the flag `NPY_ITER_C_INDEX`, `index` is the C-order index,\nand if the iterator was constructed with the flag `NPY_ITER_F_INDEX`, `index`\nis the Fortran-order index. Returns an error if there is no index being\ntracked, the index is out of bounds, or inner loop iteration is disabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GotoIterIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoIterIndex", "type": "Array Iterator API", "text": "\nAdjusts the iterator to point to the `iterindex` specified. The IterIndex is\nan index matching the iteration order of the iterator. Returns an error if the\n`iterindex` is out of bounds, buffering is enabled, or inner loop iteration is\ndisabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GotoMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoMultiIndex", "type": "Array Iterator API", "text": "\nAdjusts the iterator to point to the `ndim` indices pointed to by\n`multi_index`. Returns an error if a multi-index is not being tracked, the\nindices are out of bounds, or inner loop iteration is disabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_RemoveAxis()", "path": "reference/c-api/iterator#c.NpyIter_RemoveAxis", "type": "Array Iterator API", "text": "\nRemoves an axis from iteration. This requires that `NPY_ITER_MULTI_INDEX` was\nset for iterator creation, and does not work if buffering is enabled or an\nindex is being tracked. This function also resets the iterator to its initial\nstate.\n\nThis is useful for setting up an accumulation loop, for example. The iterator\ncan first be created with all the dimensions, including the accumulation axis,\nso that the output gets created correctly. Then, the accumulation axis can be\nremoved, and the calculation done in a nested fashion.\n\nWARNING: This function may change the internal memory layout of the iterator.\nAny cached functions or pointers from the iterator must be retrieved again!\nThe iterator range will be reset as well.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_RemoveMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_RemoveMultiIndex", "type": "Array Iterator API", "text": "\nIf the iterator is tracking a multi-index, this strips support for them, and\ndoes further iterator optimizations that are possible if multi-indices are not\nneeded. This function also resets the iterator to its initial state.\n\nWARNING: This function may change the internal memory layout of the iterator.\nAny cached functions or pointers from the iterator must be retrieved again!\n\nAfter calling this function, NpyIter_HasMultiIndex(iter) will return false.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_Reset()", "path": "reference/c-api/iterator#c.NpyIter_Reset", "type": "Array Iterator API", "text": "\nResets the iterator back to its initial state, at the beginning of the\niteration range.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\n"}, {"name": "int NpyIter_ResetBasePointers()", "path": "reference/c-api/iterator#c.NpyIter_ResetBasePointers", "type": "Array Iterator API", "text": "\nResets the iterator back to its initial state, but using the values in\n`baseptrs` for the data instead of the pointers from the arrays being\niterated. This functions is intended to be used, together with the `op_axes`\nparameter, by nested iteration code with two or more iterators.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\nTODO: Move the following into a special section on nested iterators.\n\nCreating iterators for nested iteration requires some care. All the iterator\noperands must match exactly, or the calls to `NpyIter_ResetBasePointers` will\nbe invalid. This means that automatic copies and output allocation should not\nbe used haphazardly. It is possible to still use the automatic data conversion\nand casting features of the iterator by creating one of the iterators with all\nthe conversion parameters enabled, then grabbing the allocated operands with\nthe `NpyIter_GetOperandArray` function and passing them into the constructors\nfor the rest of the iterators.\n\nWARNING: When creating iterators for nested iteration, the code must not use a\ndimension more than once in the different iterators. If this is done, nested\niteration will produce out-of-bounds pointers during iteration.\n\nWARNING: When creating iterators for nested iteration, buffering can only be\napplied to the innermost iterator. If a buffered iterator is used as the\nsource for `baseptrs`, it will point into a small buffer instead of the array\nand the inner iteration will be invalid.\n\nThe pattern for using nested iterators is as follows.\n\n"}, {"name": "int NpyIter_ResetToIterIndexRange()", "path": "reference/c-api/iterator#c.NpyIter_ResetToIterIndexRange", "type": "Array Iterator API", "text": "\nResets the iterator and restricts it to the `iterindex` range `[istart,\niend)`. See `NpyIter_Copy` for an explanation of how to use this for multi-\nthreaded iteration. This requires that the flag `NPY_ITER_RANGED` was passed\nto the iterator constructor.\n\nIf you want to reset both the `iterindex` range and the base pointers at the\nsame time, you can do the following to avoid extra buffer copying (be sure to\nadd the return code error checks when you copy this code).\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\n"}, {"name": "int ntypes", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.ntypes", "type": "Python Types and C-Structures", "text": "\nThe number of supported data types for the ufunc. This number specifies how\nmany different 1-d loops (of the builtin data types) are available.\n\n"}, {"name": "int PyArray_AxisConverter()", "path": "reference/c-api/array#c.PyArray_AxisConverter", "type": "Array API", "text": "\nConvert a Python object, obj, representing an axis argument to the proper\nvalue for passing to the functions that take an integer axis. Specifically, if\nobj is None, axis is set to `NPY_MAXDIMS` which is interpreted correctly by\nthe C-API functions that take axis arguments.\n\n"}, {"name": "int PyArray_BoolConverter()", "path": "reference/c-api/array#c.PyArray_BoolConverter", "type": "Array API", "text": "\nConvert any Python object, obj, to `NPY_TRUE` or `NPY_FALSE`, and place the\nresult in value.\n\n"}, {"name": "int PyArray_Broadcast()", "path": "reference/c-api/array#c.PyArray_Broadcast", "type": "Array API", "text": "\nThis function encapsulates the broadcasting rules. The mit container should\nalready contain iterators for all the arrays that need to be broadcast. On\nreturn, these iterators will be adjusted so that iteration over each\nsimultaneously will accomplish the broadcasting. A negative number is returned\nif an error occurs.\n\n"}, {"name": "int PyArray_BufferConverter()", "path": "reference/c-api/array#c.PyArray_BufferConverter", "type": "Array API", "text": "\nConvert any Python object, obj, with a (single-segment) buffer interface to a\nvariable with members that detail the object\u2019s use of its chunk of memory. The\nbuf variable is a pointer to a structure with base, ptr, len, and flags\nmembers. The `PyArray_Chunk` structure is binary compatible with the Python\u2019s\nbuffer object (through its len member on 32-bit platforms and its ptr member\non 64-bit platforms or in Python 2.5). On return, the base member is set to\nobj (or its base if obj is already a buffer object pointing to another\nobject). If you need to hold on to the memory be sure to INCREF the base\nmember. The chunk of memory is pointed to by buf ->ptr member and has length\nbuf ->len. The flags member of buf is `NPY_ARRAY_ALIGNED` with the\n`NPY_ARRAY_WRITEABLE` flag set if obj has a writeable buffer interface.\n\n"}, {"name": "int PyArray_ByteorderConverter()", "path": "reference/c-api/array#c.PyArray_ByteorderConverter", "type": "Array API", "text": "\nConvert Python strings into the corresponding byte-order character: \u2018>\u2019, \u2018<\u2019,\n\u2018s\u2019, \u2018=\u2019, or \u2018|\u2019.\n\n"}, {"name": "int PyArray_CanCastArrayTo()", "path": "reference/c-api/array#c.PyArray_CanCastArrayTo", "type": "Array API", "text": "\nNew in version 1.6.\n\nReturns non-zero if arr can be cast to totype according to the casting rule\ngiven in casting. If arr is an array scalar, its value is taken into account,\nand non-zero is also returned when the value will not overflow or be truncated\nto an integer when converting to a smaller type.\n\nThis is almost the same as the result of\nPyArray_CanCastTypeTo(PyArray_MinScalarType(arr), totype, casting), but it\nalso handles a special case arising because the set of uint values is not a\nsubset of the int values for types with the same number of bits.\n\n"}, {"name": "int PyArray_CanCastSafely()", "path": "reference/c-api/array#c.PyArray_CanCastSafely", "type": "Array API", "text": "\nReturns non-zero if an array of data type fromtype can be cast to an array of\ndata type totype without losing information. An exception is that 64-bit\nintegers are allowed to be cast to 64-bit floating point values even though\nthis can lose precision on large integers so as not to proliferate the use of\nlong doubles without explicit requests. Flexible array types are not checked\naccording to their lengths with this function.\n\n"}, {"name": "int PyArray_CanCastTo()", "path": "reference/c-api/array#c.PyArray_CanCastTo", "type": "Array API", "text": "\n`PyArray_CanCastTypeTo` supersedes this function in NumPy 1.6 and later.\n\nEquivalent to PyArray_CanCastTypeTo(fromtype, totype, NPY_SAFE_CASTING).\n\n"}, {"name": "int PyArray_CanCastTypeTo()", "path": "reference/c-api/array#c.PyArray_CanCastTypeTo", "type": "Array API", "text": "\nNew in version 1.6.\n\nReturns non-zero if an array of data type fromtype (which can include flexible\ntypes) can be cast safely to an array of data type totype (which can include\nflexible types) according to the casting rule casting. For simple types with\n`NPY_SAFE_CASTING`, this is basically a wrapper around\n`PyArray_CanCastSafely`, but for flexible types such as strings or unicode, it\nproduces results taking into account their sizes. Integer and float types can\nonly be cast to a string or unicode type using `NPY_SAFE_CASTING` if the\nstring or unicode type is big enough to hold the max value of the\ninteger/float type being cast from.\n\n"}, {"name": "int PyArray_CanCoerceScalar()", "path": "reference/c-api/array#c.PyArray_CanCoerceScalar", "type": "Array API", "text": "\nSee the function `PyArray_ResultType` for details of NumPy type promotion,\nupdated in NumPy 1.6.0.\n\nImplements the rules for scalar coercion. Scalars are only silently coerced\nfrom thistype to neededtype if this function returns nonzero. If scalar is\n`NPY_NOSCALAR`, then this function is equivalent to `PyArray_CanCastSafely`.\nThe rule is that scalars of the same KIND can be coerced into arrays of the\nsame KIND. This rule means that high-precision scalars will never cause low-\nprecision arrays of the same KIND to be upcast.\n\n"}, {"name": "int PyArray_CastingConverter()", "path": "reference/c-api/array#c.PyArray_CastingConverter", "type": "Array API", "text": "\nConvert the Python strings \u2018no\u2019, \u2018equiv\u2019, \u2018safe\u2019, \u2018same_kind\u2019, and \u2018unsafe\u2019\ninto the `NPY_CASTING` enumeration `NPY_NO_CASTING`, `NPY_EQUIV_CASTING`,\n`NPY_SAFE_CASTING`, `NPY_SAME_KIND_CASTING`, and `NPY_UNSAFE_CASTING`.\n\n"}, {"name": "int PyArray_CastTo()", "path": "reference/c-api/array#c.PyArray_CastTo", "type": "Array API", "text": "\nAs of 1.6, this function simply calls `PyArray_CopyInto`, which handles the\ncasting.\n\nCast the elements of the array in into the array out. The output array should\nbe writeable, have an integer-multiple of the number of elements in the input\narray (more than one copy can be placed in out), and have a data type that is\none of the builtin types. Returns 0 on success and -1 if an error occurs.\n\n"}, {"name": "int PyArray_CheckAnyScalar()", "path": "reference/c-api/array#c.PyArray_CheckAnyScalar", "type": "Array API", "text": "\nEvaluates true if op is a Python scalar object (see `PyArray_IsPythonScalar`),\nan array scalar (an instance of a sub-type of `PyGenericArr_Type`) or an\ninstance of a sub-type of `PyArray_Type` whose dimensionality is 0.\n\n"}, {"name": "int PyArray_CheckExact()", "path": "reference/c-api/array#c.PyArray_CheckExact", "type": "Array API", "text": "\nEvaluates true if op is a Python object with type `PyArray_Type`.\n\n"}, {"name": "int PyArray_CheckScalar()", "path": "reference/c-api/array#c.PyArray_CheckScalar", "type": "Array API", "text": "\nEvaluates true if op is either an array scalar (an instance of a sub-type of\n`PyGenericArr_Type` ), or an instance of (a sub-class of) `PyArray_Type` whose\ndimensionality is 0.\n\n"}, {"name": "int PyArray_ClipmodeConverter()", "path": "reference/c-api/array#c.PyArray_ClipmodeConverter", "type": "Array API", "text": "\nConvert the Python strings \u2018clip\u2019, \u2018wrap\u2019, and \u2018raise\u2019 into the `NPY_CLIPMODE`\nenumeration `NPY_CLIP`, `NPY_WRAP`, and `NPY_RAISE`.\n\n"}, {"name": "int PyArray_CompareLists()", "path": "reference/c-api/array#c.PyArray_CompareLists", "type": "Array API", "text": "\nGiven two n -length arrays of integers, l1, and l2, return 1 if the lists are\nidentical; otherwise, return 0.\n\n"}, {"name": "int PyArray_ConvertClipmodeSequence()", "path": "reference/c-api/array#c.PyArray_ConvertClipmodeSequence", "type": "Array API", "text": "\nConverts either a sequence of clipmodes or a single clipmode into a C array of\n`NPY_CLIPMODE` values. The number of clipmodes n must be known before calling\nthis function. This function is provided to help functions allow a different\nclipmode for each dimension.\n\n"}, {"name": "int PyArray_CopyInto()", "path": "reference/c-api/array#c.PyArray_CopyInto", "type": "Array API", "text": "\nCopy from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src must not overlap.\n\n"}, {"name": "int PyArray_CopyObject()", "path": "reference/c-api/array#c.PyArray_CopyObject", "type": "Array API", "text": "\nAssign an object `src` to a NumPy array `dest` according to array-coercion\nrules. This is basically identical to `PyArray_FromAny`, but assigns directly\nto the output array. Returns 0 on success and -1 on failures.\n\n"}, {"name": "int Pyarray_DescrAlignConverter()", "path": "reference/c-api/array#c.Pyarray_DescrAlignConverter", "type": "Array API", "text": "\nLike `PyArray_DescrConverter` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\n"}, {"name": "int Pyarray_DescrAlignConverter2()", "path": "reference/c-api/array#c.Pyarray_DescrAlignConverter2", "type": "Array API", "text": "\nLike `PyArray_DescrConverter2` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\n"}, {"name": "int PyArray_DescrConverter()", "path": "reference/c-api/array#c.PyArray_DescrConverter", "type": "Array API", "text": "\nConvert any compatible Python object, obj, to a data-type object in dtype. A\nlarge number of Python objects can be converted to data-type objects. See Data\ntype objects (dtype) for a complete description. This version of the converter\nconverts None objects to a `NPY_DEFAULT_TYPE` data-type object. This function\ncan be used with the \u201cO&\u201d character code in `PyArg_ParseTuple` processing.\n\n"}, {"name": "int PyArray_DescrConverter2()", "path": "reference/c-api/array#c.PyArray_DescrConverter2", "type": "Array API", "text": "\nConvert any compatible Python object, obj, to a data-type object in dtype.\nThis version of the converter converts None objects so that the returned data-\ntype is `NULL`. This function can also be used with the \u201cO&\u201d character in\nPyArg_ParseTuple processing.\n\n"}, {"name": "int PyArray_Dump()", "path": "reference/c-api/array#c.PyArray_Dump", "type": "Array API", "text": "\nPickle the object in self to the given file (either a string or a Python file\nobject). If file is a Python string it is considered to be the name of a file\nwhich is then opened in binary mode. The given protocol is used (if protocol\nis negative, or the highest available is used). This is a simple wrapper\naround cPickle.dump(self, file, protocol).\n\n"}, {"name": "int PyArray_EquivByteorders()", "path": "reference/c-api/array#c.PyArray_EquivByteorders", "type": "Array API", "text": "\nTrue if byteorder characters b1 and b2 ( `NPY_LITTLE`, `NPY_BIG`,\n`NPY_NATIVE`, `NPY_IGNORE` ) are either equal or equivalent as to their\nspecification of a native byte order. Thus, on a little-endian machine\n`NPY_LITTLE` and `NPY_NATIVE` are equivalent where they are not equivalent on\na big-endian machine.\n\n"}, {"name": "int PyArray_FillWithScalar()", "path": "reference/c-api/array#c.PyArray_FillWithScalar", "type": "Array API", "text": "\nFill the array, arr, with the given scalar object, obj. The object is first\nconverted to the data type of arr, and then copied into every location. A -1\nis returned if an error occurs, otherwise 0 is returned.\n\n"}, {"name": "int PyArray_FinalizeFunc()", "path": "reference/c-api/array#c.PyArray_FinalizeFunc", "type": "Array API", "text": "\nThe function pointed to by the CObject `__array_finalize__`. The first\nargument is the newly created sub-type. The second argument (if not NULL) is\nthe \u201cparent\u201d array (if the array was created using slicing or some other\noperation where a clearly-distinguishable parent is present). This routine can\ndo anything it wants to. It should return a -1 on error and 0 otherwise.\n\n"}, {"name": "int PyArray_FLAGS()", "path": "reference/c-api/array#c.PyArray_FLAGS", "type": "Array API", "text": "\nReturns an integer representing the array-flags.\n\n"}, {"name": "int PyArray_Free()", "path": "reference/c-api/array#c.PyArray_Free", "type": "Array API", "text": "\nMust be called with the same objects and memory locations returned from\n`PyArray_AsCArray` (\u2026). This function cleans up memory that otherwise would\nget leaked.\n\n"}, {"name": "int PyArray_GetArrayParamsFromObject()", "path": "reference/c-api/array#c.PyArray_GetArrayParamsFromObject", "type": "Array API", "text": "\nDeprecated since version NumPy: 1.19\n\nUnless NumPy is made aware of an issue with this, this function is scheduled\nfor rapid removal without replacement.\n\nChanged in version NumPy: 1.19\n\n`context` is never used. Its use results in an error.\n\nNew in version 1.6.\n\n"}, {"name": "int PyArray_GetEndianness()", "path": "reference/c-api/config#c.PyArray_GetEndianness", "type": "System configuration", "text": "\nNew in version 1.3.0.\n\nReturns the endianness of the current platform. One of `NPY_CPU_BIG`,\n`NPY_CPU_LITTLE`, or `NPY_CPU_UNKNOWN_ENDIAN`.\n\n"}, {"name": "int PyArray_HasArrayInterface()", "path": "reference/c-api/array#c.PyArray_HasArrayInterface", "type": "Array API", "text": "\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to `Py_NotImplemented` and no error condition is\nset.\n\n"}, {"name": "int PyArray_HasArrayInterfaceType()", "path": "reference/c-api/array#c.PyArray_HasArrayInterfaceType", "type": "Array API", "text": "\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to Py_NotImplemented and no error condition is\nset. This version allows setting of the dtype in the part of the array\ninterface that looks for the `__array__` attribute. `context` is unused.\n\n"}, {"name": "int PyArray_HASFIELDS()", "path": "reference/c-api/array#c.PyArray_HASFIELDS", "type": "Array API", "text": "\nType has fields associated with it.\n\n"}, {"name": "int PyArray_IntpConverter()", "path": "reference/c-api/array#c.PyArray_IntpConverter", "type": "Array API", "text": "\nConvert any Python sequence, obj, smaller than `NPY_MAXDIMS` to a C-array of\n`npy_intp`. The Python object could also be a single number. The seq variable\nis a pointer to a structure with members ptr and len. On successful return,\nseq ->ptr contains a pointer to memory that must be freed, by calling\n`PyDimMem_FREE`, to avoid a memory leak. The restriction on memory size allows\nthis converter to be conveniently used for sequences intended to be\ninterpreted as array shapes.\n\n"}, {"name": "int PyArray_IntpFromSequence()", "path": "reference/c-api/array#c.PyArray_IntpFromSequence", "type": "Array API", "text": "\nConvert any Python sequence (or single Python number) passed in as seq to (up\nto) maxvals pointer-sized integers and place them in the vals array. The\nsequence can be smaller then maxvals as the number of converted objects is\nreturned.\n\n"}, {"name": "int PyArray_IS_C_CONTIGUOUS()", "path": "reference/c-api/array#c.PyArray_IS_C_CONTIGUOUS", "type": "Array API", "text": "\nEvaluates true if arr is C-style contiguous.\n\n"}, {"name": "int PyArray_IS_F_CONTIGUOUS()", "path": "reference/c-api/array#c.PyArray_IS_F_CONTIGUOUS", "type": "Array API", "text": "\nEvaluates true if arr is Fortran-style contiguous.\n\n"}, {"name": "int PyArray_ISALIGNED()", "path": "reference/c-api/array#c.PyArray_ISALIGNED", "type": "Array API", "text": "\nEvaluates true if the data area of arr is properly aligned on the machine.\n\n"}, {"name": "int PyArray_IsAnyScalar()", "path": "reference/c-api/array#c.PyArray_IsAnyScalar", "type": "Array API", "text": "\nEvaluates true if op is either a Python scalar object (see\n`PyArray_IsPythonScalar`) or an array scalar (an instance of a sub- type of\n`PyGenericArr_Type` ).\n\n"}, {"name": "int PyArray_ISBEHAVED()", "path": "reference/c-api/array#c.PyArray_ISBEHAVED", "type": "Array API", "text": "\nEvaluates true if the data area of arr is aligned and writeable and in machine\nbyte-order according to its descriptor.\n\n"}, {"name": "int PyArray_ISBEHAVED_RO()", "path": "reference/c-api/array#c.PyArray_ISBEHAVED_RO", "type": "Array API", "text": "\nEvaluates true if the data area of arr is aligned and in machine byte-order.\n\n"}, {"name": "int PyArray_ISBOOL()", "path": "reference/c-api/array#c.PyArray_ISBOOL", "type": "Array API", "text": "\nType represents Boolean data type.\n\n"}, {"name": "int PyArray_ISBYTESWAPPED()", "path": "reference/c-api/array#c.PyArray_ISBYTESWAPPED", "type": "Array API", "text": "\nEvaluates true if the data area of the ndarray m is not in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\n"}, {"name": "int PyArray_ISCARRAY()", "path": "reference/c-api/array#c.PyArray_ISCARRAY", "type": "Array API", "text": "\nEvaluates true if the data area of arr is C-style contiguous, and\n`PyArray_ISBEHAVED` (arr) is true.\n\n"}, {"name": "int PyArray_ISCARRAY_RO()", "path": "reference/c-api/array#c.PyArray_ISCARRAY_RO", "type": "Array API", "text": "\nEvaluates true if the data area of arr is C-style contiguous, aligned, and in\nmachine byte-order.\n\n"}, {"name": "int PyArray_ISCOMPLEX()", "path": "reference/c-api/array#c.PyArray_ISCOMPLEX", "type": "Array API", "text": "\nType represents any complex floating point number.\n\n"}, {"name": "int PyArray_ISEXTENDED()", "path": "reference/c-api/array#c.PyArray_ISEXTENDED", "type": "Array API", "text": "\nType is either flexible or user-defined.\n\n"}, {"name": "int PyArray_ISFARRAY()", "path": "reference/c-api/array#c.PyArray_ISFARRAY", "type": "Array API", "text": "\nEvaluates true if the data area of arr is Fortran-style contiguous and\n`PyArray_ISBEHAVED` (arr) is true.\n\n"}, {"name": "int PyArray_ISFARRAY_RO()", "path": "reference/c-api/array#c.PyArray_ISFARRAY_RO", "type": "Array API", "text": "\nEvaluates true if the data area of arr is Fortran-style contiguous, aligned,\nand in machine byte-order .\n\n"}, {"name": "int PyArray_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyArray_ISFLEXIBLE", "type": "Array API", "text": "\nType represents one of the flexible array types ( `NPY_STRING`, `NPY_UNICODE`,\nor `NPY_VOID` ).\n\n"}, {"name": "int PyArray_ISFLOAT()", "path": "reference/c-api/array#c.PyArray_ISFLOAT", "type": "Array API", "text": "\nType represents any floating point number.\n\n"}, {"name": "int PyArray_ISFORTRAN()", "path": "reference/c-api/array#c.PyArray_ISFORTRAN", "type": "Array API", "text": "\nEvaluates true if arr is Fortran-style contiguous and not C-style contiguous.\n`PyArray_IS_F_CONTIGUOUS` is the correct way to test for Fortran-style\ncontiguity.\n\n"}, {"name": "int PyArray_ISINTEGER()", "path": "reference/c-api/array#c.PyArray_ISINTEGER", "type": "Array API", "text": "\nType represents any integer.\n\n"}, {"name": "int PyArray_ISNOTSWAPPED()", "path": "reference/c-api/array#c.PyArray_ISNOTSWAPPED", "type": "Array API", "text": "\nEvaluates true if the data area of the ndarray m is in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\n"}, {"name": "int PyArray_ISNUMBER()", "path": "reference/c-api/array#c.PyArray_ISNUMBER", "type": "Array API", "text": "\nType represents any integer, floating point, or complex floating point number.\n\n"}, {"name": "int PyArray_ISOBJECT()", "path": "reference/c-api/array#c.PyArray_ISOBJECT", "type": "Array API", "text": "\nType represents object data type.\n\n"}, {"name": "int PyArray_ISONESEGMENT()", "path": "reference/c-api/array#c.PyArray_ISONESEGMENT", "type": "Array API", "text": "\nEvaluates true if the data area of arr consists of a single (C-style or\nFortran-style) contiguous segment.\n\n"}, {"name": "int PyArray_ISPYTHON()", "path": "reference/c-api/array#c.PyArray_ISPYTHON", "type": "Array API", "text": "\nType represents an enumerated type corresponding to one of the standard Python\nscalar (bool, int, float, or complex).\n\n"}, {"name": "int PyArray_IsPythonNumber()", "path": "reference/c-api/array#c.PyArray_IsPythonNumber", "type": "Array API", "text": "\nEvaluates true if op is an instance of a builtin numeric type (int, float,\ncomplex, long, bool)\n\n"}, {"name": "int PyArray_IsPythonScalar()", "path": "reference/c-api/array#c.PyArray_IsPythonScalar", "type": "Array API", "text": "\nEvaluates true if op is a builtin Python scalar object (int, float, complex,\nbytes, str, long, bool).\n\n"}, {"name": "int PyArray_ISSIGNED()", "path": "reference/c-api/array#c.PyArray_ISSIGNED", "type": "Array API", "text": "\nType represents a signed integer.\n\n"}, {"name": "int PyArray_ISSTRING()", "path": "reference/c-api/array#c.PyArray_ISSTRING", "type": "Array API", "text": "\nType represents a string data type.\n\n"}, {"name": "int PyArray_ISUNSIGNED()", "path": "reference/c-api/array#c.PyArray_ISUNSIGNED", "type": "Array API", "text": "\nType represents an unsigned integer.\n\n"}, {"name": "int PyArray_ISUSERDEF()", "path": "reference/c-api/array#c.PyArray_ISUSERDEF", "type": "Array API", "text": "\nType represents a user-defined type.\n\n"}, {"name": "int PyArray_ISWRITEABLE()", "path": "reference/c-api/array#c.PyArray_ISWRITEABLE", "type": "Array API", "text": "\nEvaluates true if the data area of arr can be written to\n\n"}, {"name": "int PyArray_IsZeroDim()", "path": "reference/c-api/array#c.PyArray_IsZeroDim", "type": "Array API", "text": "\nEvaluates true if op is an instance of (a subclass of) `PyArray_Type` and has\n0 dimensions.\n\n"}, {"name": "int PyArray_ITER_NOTDONE()", "path": "reference/c-api/array#c.PyArray_ITER_NOTDONE", "type": "Array API", "text": "\nEvaluates TRUE as long as the iterator has not looped through all of the\nelements, otherwise it evaluates FALSE.\n\n"}, {"name": "int PyArray_MoveInto()", "path": "reference/c-api/array#c.PyArray_MoveInto", "type": "Array API", "text": "\nMove data from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src may overlap.\n\n"}, {"name": "int PyArray_MultiIter_NOTDONE()", "path": "reference/c-api/array#c.PyArray_MultiIter_NOTDONE", "type": "Array API", "text": "\nEvaluates TRUE as long as the multi-iterator has not looped through all of the\nelements (of the broadcasted result), otherwise it evaluates FALSE.\n\n"}, {"name": "int PyArray_MultiplyIntList()", "path": "reference/c-api/array#c.PyArray_MultiplyIntList", "type": "Array API", "text": "\nBoth of these routines multiply an n -length array, seq, of integers and\nreturn the result. No overflow checking is performed.\n\n"}, {"name": "int PyArray_NDIM()", "path": "reference/c-api/array", "type": "Array API", "text": "\nThese macros access the `PyArrayObject` structure members and are defined in\n`ndarraytypes.h`. The input argument, arr, can be any PyObject* that is\ndirectly interpretable as a PyArrayObject* (any instance of the `PyArray_Type`\nand its sub-types).\n\nThe number of dimensions in the array.\n\nReturns an integer representing the array-flags.\n\nReturn the (builtin) typenumber for the elements of this array.\n\nConvert obj and place it in the ndarray, arr, at the place pointed to by\nitemptr. Return -1 if an error occurs or 0 on success.\n\nNew in version 1.7.\n\nEnables the specified array flags. This function does no validation, and\nassumes that you know what you\u2019re doing.\n\nNew in version 1.7.\n\nClears the specified array flags. This function does no validation, and\nassumes that you know what you\u2019re doing.\n\nThese two macros are similar and obtain the pointer to the data-buffer for the\narray. The first macro can (and should be) assigned to a particular pointer\nwhere the second is for generic processing. If you have not guaranteed a\ncontiguous and/or aligned array then be sure you understand how to access the\ndata in the array to avoid memory and/or alignment problems.\n\nReturns a pointer to the dimensions/shape of the array. The number of elements\nmatches the number of dimensions of the array. Can return `NULL` for\n0-dimensional arrays.\n\nNew in version 1.7.\n\nA synonym for `PyArray_DIMS`, named to be consistent with the `shape` usage\nwithin Python.\n\nReturns a pointer to the strides of the array. The number of elements matches\nthe number of dimensions of the array.\n\nReturn the shape in the n \\\\(^{\\textrm{th}}\\\\) dimension.\n\nReturn the stride in the n \\\\(^{\\textrm{th}}\\\\) dimension.\n\nReturn the itemsize for the elements of this array.\n\nNote that, in the old API that was deprecated in version 1.7, this function\nhad the return type `int`.\n\nReturns the total size (in number of elements) of the array.\n\nReturns 0 if obj is not a sub-class of ndarray. Otherwise, returns the total\nnumber of elements in the array. Safer version of `PyArray_SIZE` (obj).\n\nReturns the total number of bytes consumed by the array.\n\nThis returns the base object of the array. In most cases, this means the\nobject which owns the memory the array is pointing at.\n\nIf you are constructing an array using the C API, and specifying your own\nmemory, you should use the function `PyArray_SetBaseObject` to set the base to\nan object which owns the memory.\n\nIf the (deprecated) `NPY_ARRAY_UPDATEIFCOPY` or the\n`NPY_ARRAY_WRITEBACKIFCOPY` flags are set, it has a different meaning, namely\nbase is the array into which the current array will be copied upon copy\nresolution. This overloading of the base property for two functions is likely\nto change in a future version of NumPy.\n\nReturns a borrowed reference to the dtype property of the array.\n\nNew in version 1.7.\n\nA synonym for PyArray_DESCR, named to be consistent with the \u2018dtype\u2019 usage\nwithin Python.\n\nGet a Python object of a builtin type from the ndarray, arr, at the location\npointed to by itemptr. Return `NULL` on failure.\n\n`numpy.ndarray.item` is identical to PyArray_GETITEM.\n\nThe function pointed to by the CObject `__array_finalize__`. The first\nargument is the newly created sub-type. The second argument (if not NULL) is\nthe \u201cparent\u201d array (if the array was created using slicing or some other\noperation where a clearly-distinguishable parent is present). This routine can\ndo anything it wants to. It should return a -1 on error and 0 otherwise.\n\nThese functions and macros provide easy access to elements of the ndarray from\nC. These work for all arrays. You may need to take care when accessing the\ndata in the array, however, if it is not in machine byte-order, misaligned, or\nnot writeable. In other words, be sure to respect the state of the flags\nunless you know what you are doing, or have previously guaranteed an array\nthat is writeable, aligned, and in machine byte-order using `PyArray_FromAny`.\nIf you wish to handle all types of arrays, the copyswap function for each type\nis useful for handling misbehaved arrays. Some platforms (e.g. Solaris) do not\nlike misaligned data and will crash if you de-reference a misaligned pointer.\nOther platforms (e.g. x86 Linux) will just work more slowly with misaligned\ndata.\n\nReturn a pointer to the data of the ndarray, aobj, at the N-dimensional index\ngiven by the c-array, ind, (which must be at least aobj ->nd in size). You may\nwant to typecast the returned pointer to the data type of the ndarray.\n\nQuick, inline access to the element at the given coordinates in the ndarray,\nobj, which must have respectively 1, 2, 3, or 4 dimensions (this is not\nchecked). The corresponding i, j, k, and l coordinates can be any integer but\nwill be interpreted as `npy_intp`. You may want to typecast the returned\npointer to the data type of the ndarray.\n\nThis function steals a reference to descr. The easiest way to get one is using\n`PyArray_DescrFromType`.\n\nThis is the main array creation function. Most new arrays are created with\nthis flexible function.\n\nThe returned object is an object of Python-type subtype, which must be a\nsubtype of `PyArray_Type`. The array has nd dimensions, described by dims. The\ndata-type descriptor of the new array is descr.\n\nIf subtype is of an array subclass instead of the base `&PyArray_Type`, then\nobj is the object to pass to the `__array_finalize__` method of the subclass.\n\nIf data is `NULL`, then new unitinialized memory will be allocated and flags\ncan be non-zero to indicate a Fortran-style contiguous array. Use\n`PyArray_FILLWBYTE` to initialize the memory.\n\nIf data is not `NULL`, then it is assumed to point to the memory to be used\nfor the array and the flags argument is used as the new flags for the array\n(except the state of `NPY_ARRAY_OWNDATA`, `NPY_ARRAY_WRITEBACKIFCOPY` and\n`NPY_ARRAY_UPDATEIFCOPY` flags of the new array will be reset).\n\nIn addition, if data is non-NULL, then strides can also be provided. If\nstrides is `NULL`, then the array strides are computed as C-style contiguous\n(default) or Fortran-style contiguous (flags is nonzero for data = `NULL` or\nflags & `NPY_ARRAY_F_CONTIGUOUS` is nonzero non-NULL data). Any provided dims\nand strides are copied into newly allocated dimension and strides arrays for\nthe new array object.\n\n`PyArray_CheckStrides` can help verify non- `NULL` stride information.\n\nIf `data` is provided, it must stay alive for the life of the array. One way\nto manage this is through `PyArray_SetBaseObject`\n\nNew in version 1.6.\n\nThis function steals a reference to descr if it is not NULL. This array\ncreation routine allows for the convenient creation of a new array matching an\nexisting array\u2019s shapes and memory layout, possibly changing the layout and/or\ndata type.\n\nWhen order is `NPY_ANYORDER`, the result order is `NPY_FORTRANORDER` if\nprototype is a fortran array, `NPY_CORDER` otherwise. When order is\n`NPY_KEEPORDER`, the result order matches that of prototype, even when the\naxes of prototype aren\u2019t in C or Fortran order.\n\nIf descr is NULL, the data type of prototype is used.\n\nIf subok is 1, the newly created array will use the sub-type of prototype to\ncreate the new array, otherwise it will create a base-class array.\n\nThis is similar to `PyArray_NewFromDescr` (\u2026) except you specify the data-type\ndescriptor with type_num and itemsize, where type_num corresponds to a builtin\n(or user-defined) type. If the type always has the same number of bytes, then\nitemsize is ignored. Otherwise, itemsize specifies the particular size of this\narray.\n\nWarning\n\nIf data is passed to `PyArray_NewFromDescr` or `PyArray_New`, this memory must\nnot be deallocated until the new array is deleted. If this data came from\nanother Python object, this can be accomplished using `Py_INCREF` on that\nobject and setting the base member of the new array to point to that object.\nIf strides are passed in they must be consistent with the dimensions, the\nitemsize, and the data of the array.\n\nCreate a new uninitialized array of type, typenum, whose size in each of nd\ndimensions is given by the integer array, dims.The memory for the array is\nuninitialized (unless typenum is `NPY_OBJECT` in which case each element in\nthe array is set to NULL). The typenum argument allows specification of any of\nthe builtin data-types such as `NPY_FLOAT` or `NPY_LONG`. The memory for the\narray can be set to zero if desired using `PyArray_FILLWBYTE` (return_object,\n0).This function cannot be used to create a flexible-type array (no itemsize\ngiven).\n\nCreate an array wrapper around data pointed to by the given pointer. The array\nflags will have a default that the data area is well-behaved and C-style\ncontiguous. The shape of the array is given by the dims c-array of length nd.\nThe data-type of the array is indicated by typenum. If data comes from another\nreference-counted Python object, the reference count on this object should be\nincreased after the pointer is passed in, and the base member of the returned\nndarray should point to the Python object that owns the data. This will ensure\nthat the provided memory is not freed while the returned array is in\nexistence.\n\nThis function steals a reference to descr.\n\nCreate a new array with the provided data-type descriptor, descr, of the shape\ndetermined by nd and dims.\n\nFill the array pointed to by obj \u2014which must be a (subclass of) ndarray\u2014with\nthe contents of val (evaluated as a byte). This macro calls memset, so obj\nmust be contiguous.\n\nConstruct a new nd -dimensional array with shape given by dims and data type\ngiven by dtype. If fortran is non-zero, then a Fortran-order array is created,\notherwise a C-order array is created. Fill the memory with zeros (or the 0\nobject if dtype corresponds to `NPY_OBJECT` ).\n\nMacro form of `PyArray_Zeros` which takes a type-number instead of a data-type\nobject.\n\nConstruct a new nd -dimensional array with shape given by dims and data type\ngiven by dtype. If fortran is non-zero, then a Fortran-order array is created,\notherwise a C-order array is created. The array is uninitialized unless the\ndata type corresponds to `NPY_OBJECT` in which case the array is filled with\n`Py_None`.\n\nMacro form of `PyArray_Empty` which takes a type-number, typenum, instead of a\ndata-type object.\n\nConstruct a new 1-dimensional array of data-type, typenum, that ranges from\nstart to stop (exclusive) in increments of step . Equivalent to arange (start,\nstop, step, dtype).\n\nConstruct a new 1-dimensional array of data-type determined by `descr`, that\nranges from `start` to `stop` (exclusive) in increments of `step`. Equivalent\nto arange( `start`, `stop`, `step`, `typenum` ).\n\nNew in version 1.7.\n\nThis function steals a reference to `obj` and sets it as the base property of\n`arr`.\n\nIf you construct an array by passing in your own memory buffer as a parameter,\nyou need to set the array\u2019s `base` property to ensure the lifetime of the\nmemory buffer is appropriate.\n\nThe return value is 0 on success, -1 on failure.\n\nIf the object provided is an array, this function traverses the chain of\n`base` pointers so that each array points to the owner of the memory directly.\nOnce the base is set, it may not be changed to another value.\n\nThis is the main function used to obtain an array from any nested sequence, or\nobject that exposes the array interface, op. The parameters allow\nspecification of the required dtype, the minimum (min_depth) and maximum\n(max_depth) number of dimensions acceptable, and other requirements for the\narray. This function steals a reference to the dtype argument, which needs to\nbe a `PyArray_Descr` structure indicating the desired data-type (including\nrequired byteorder). The dtype argument may be `NULL`, indicating that any\ndata-type (and byteorder) is acceptable. Unless `NPY_ARRAY_FORCECAST` is\npresent in `flags`, this call will generate an error if the data type cannot\nbe safely obtained from the object. If you want to use `NULL` for the dtype\nand ensure the array is notswapped then use `PyArray_CheckFromAny`. A value of\n0 for either of the depth parameters causes the parameter to be ignored. Any\nof the following array flags can be added (e.g. using |) to get the\nrequirements argument. If your code can handle general (e.g. strided, byte-\nswapped, or unaligned arrays) then requirements may be 0. Also, if op is not\nalready an array (or does not expose the array interface), then a new array\nwill be created (and filled from op using the sequence protocol). The new\narray will have `NPY_ARRAY_DEFAULT` as its flags member. The context argument\nis unused.\n\nMake sure the returned array is C-style contiguous\n\nMake sure the returned array is Fortran-style contiguous.\n\nMake sure the returned array is aligned on proper boundaries for its data\ntype. An aligned array has the data pointer and every strides factor as a\nmultiple of the alignment factor for the data-type- descriptor.\n\nMake sure the returned array can be written to.\n\nMake sure a copy is made of op. If this flag is not present, data is not\ncopied if it can be avoided.\n\nMake sure the result is a base-class ndarray. By default, if op is an instance\nof a subclass of ndarray, an instance of that same subclass is returned. If\nthis flag is set, an ndarray object will be returned instead.\n\nForce a cast to the output type even if it cannot be done safely. Without this\nflag, a data cast will occur only if it can be done safely, otherwise an error\nis raised.\n\nIf op is already an array, but does not satisfy the requirements, then a copy\nis made (which will satisfy the requirements). If this flag is present and a\ncopy (of an object that is already an array) must be made, then the\ncorresponding `NPY_ARRAY_WRITEBACKIFCOPY` flag is set in the returned copy and\nop is made to be read-only. You must be sure to call\n`PyArray_ResolveWritebackIfCopy` to copy the contents back into op and the op\narray will be made writeable again. If op is not writeable to begin with, or\nif it is not already an array, then an error is raised.\n\nDeprecated. Use `NPY_ARRAY_WRITEBACKIFCOPY`, which is similar. This flag\n\u201cautomatically\u201d copies the data back when the returned array is deallocated,\nwhich is not supported in all python implementations.\n\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_CARRAY`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED` |\n`NPY_ARRAY_WRITEBACKIFCOPY` | `NPY_ARRAY_UPDATEIFCOPY`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED` |\n`NPY_ARRAY_WRITEBACKIFCOPY` | `NPY_ARRAY_UPDATEIFCOPY`\n\nDeprecated since version NumPy: 1.19\n\nUnless NumPy is made aware of an issue with this, this function is scheduled\nfor rapid removal without replacement.\n\nChanged in version NumPy: 1.19\n\n`context` is never used. Its use results in an error.\n\nNew in version 1.6.\n\nNearly identical to `PyArray_FromAny` (\u2026) except requirements can contain\n`NPY_ARRAY_NOTSWAPPED` (over-riding the specification in dtype) and\n`NPY_ARRAY_ELEMENTSTRIDES` which indicates that the array should be aligned in\nthe sense that the strides are multiples of the element size.\n\nIn versions 1.6 and earlier of NumPy, the following flags did not have the\n_ARRAY_ macro namespace in them. That form of the constant names is deprecated\nin 1.7.\n\nMake sure the returned array has a data-type descriptor that is in machine\nbyte-order, over-riding any specification in the dtype argument. Normally, the\nbyte-order requirement is determined by the dtype argument. If this flag is\nset and the dtype argument does not indicate a machine byte-order descriptor\n(or is NULL and the object is already an array with a data-type descriptor\nthat is not in machine byte- order), then a new data-type descriptor is\ncreated and used with its byte-order field set to native.\n\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_NOTSWAPPED`\n\nMake sure the returned array has strides that are multiples of the element\nsize.\n\nSpecial case of `PyArray_FromAny` for when op is already an array but it needs\nto be of a specific newtype (including byte-order) or has certain\nrequirements.\n\nReturns an ndarray object from a Python object that exposes the\n`__array_struct__` attribute and follows the array interface protocol. If the\nobject does not contain this attribute then a borrowed reference to\n`Py_NotImplemented` is returned.\n\nReturns an ndarray object from a Python object that exposes the\n`__array_interface__` attribute following the array interface protocol. If the\nobject does not contain this attribute then a borrowed reference to\n`Py_NotImplemented` is returned.\n\nReturn an ndarray object from a Python object that exposes the `__array__`\nmethod. The `__array__` method can take 0, or 1 argument `([dtype])`.\n`context` is unused.\n\nThis function returns a (C-style) contiguous and behaved function array from\nany nested sequence or array interface exporting object, op, of (non-flexible)\ntype given by the enumerated typenum, of minimum depth min_depth, and of\nmaximum depth max_depth. Equivalent to a call to `PyArray_FromAny` with\nrequirements set to `NPY_ARRAY_DEFAULT` and the type_num member of the type\nargument set to typenum.\n\nThis function returns a well-behaved C-style contiguous array from any nested\nsequence or array-interface exporting object. The minimum number of dimensions\nthe array can have is given by `min_depth` while the maximum is `max_depth`.\nThis is equivalent to call `PyArray_FromAny` with requirements\n`NPY_ARRAY_DEFAULT` and `NPY_ARRAY_ENSUREARRAY`.\n\nReturn an aligned and in native-byteorder array from any nested sequence or\narray-interface exporting object, op, of a type given by the enumerated\ntypenum. The minimum number of dimensions the array can have is given by\nmin_depth while the maximum is max_depth. This is equivalent to a call to\n`PyArray_FromAny` with requirements set to BEHAVED.\n\nThis function steals a reference to `op` and makes sure that `op` is a base-\nclass ndarray. It special cases array scalars, but otherwise calls\n`PyArray_FromAny` ( `op`, NULL, 0, 0, `NPY_ARRAY_ENSUREARRAY`, NULL).\n\nConstruct a one-dimensional ndarray of a single type from a binary or (ASCII)\ntext `string` of length `slen`. The data-type of the array to-be-created is\ngiven by `dtype`. If num is -1, then copy the entire string and return an\nappropriately sized array, otherwise, `num` is the number of items to copy\nfrom the string. If `sep` is NULL (or \u201c\u201d), then interpret the string as bytes\nof binary data, otherwise convert the sub-strings separated by `sep` to items\nof data-type `dtype`. Some data-types may not be readable in text mode and an\nerror will be raised if that occurs. All errors return NULL.\n\nConstruct a one-dimensional ndarray of a single type from a binary or text\nfile. The open file pointer is `fp`, the data-type of the array to be created\nis given by `dtype`. This must match the data in the file. If `num` is -1,\nthen read until the end of the file and return an appropriately sized array,\notherwise, `num` is the number of items to read. If `sep` is NULL (or \u201c\u201d),\nthen read from the file in binary mode, otherwise read from the file in text\nmode with `sep` providing the item separator. Some array types cannot be read\nin text mode in which case an error is raised.\n\nConstruct a one-dimensional ndarray of a single type from an object, `buf`,\nthat exports the (single-segment) buffer protocol (or has an attribute\n__buffer__ that returns an object that exports the buffer protocol). A\nwriteable buffer will be tried first followed by a read- only buffer. The\n`NPY_ARRAY_WRITEABLE` flag of the returned array will reflect which one was\nsuccessful. The data is assumed to start at `offset` bytes from the start of\nthe memory location for the object. The type of the data in the buffer will be\ninterpreted depending on the data- type descriptor, `dtype.` If `count` is\nnegative then it will be determined from the size of the buffer and the\nrequested itemsize, otherwise, `count` represents how many elements should be\nconverted from the buffer.\n\nCopy from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src must not overlap.\n\nAssign an object `src` to a NumPy array `dest` according to array-coercion\nrules. This is basically identical to `PyArray_FromAny`, but assigns directly\nto the output array. Returns 0 on success and -1 on failures.\n\nMove data from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src may overlap.\n\nIf `op` is already (C-style) contiguous and well-behaved then just return a\nreference, otherwise return a (contiguous and well-behaved) copy of the array.\nThe parameter op must be a (sub-class of an) ndarray and no checking for that\nis done.\n\nConvert `obj` to an ndarray. The argument can be any nested sequence or object\nthat exports the array interface. This is a macro form of `PyArray_FromAny`\nusing `NULL`, 0, 0, 0 for the other arguments. Your code must be able to\nhandle any data-type descriptor and any combination of data-flags to use this\nmacro.\n\nSimilar to `PyArray_FROM_O` except it can take an argument of requirements\nindicating properties the resulting array must have. Available requirements\nthat can be enforced are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`, `NPY_ARRAY_NOTSWAPPED`,\n`NPY_ARRAY_ENSURECOPY`, `NPY_ARRAY_WRITEBACKIFCOPY`, `NPY_ARRAY_UPDATEIFCOPY`,\n`NPY_ARRAY_FORCECAST`, and `NPY_ARRAY_ENSUREARRAY`. Standard combinations of\nflags can also be used:\n\nSimilar to `PyArray_FROM_O` except it can take an argument of typenum\nspecifying the type-number the returned array.\n\nCombination of `PyArray_FROM_OF` and `PyArray_FROM_OT` allowing both a typenum\nand a flags argument to be provided.\n\nSimilar to `PyArray_FromAny` except the data-type is specified using a\ntypenumber. `PyArray_DescrFromType` (typenum) is passed directly to\n`PyArray_FromAny`. This macro also adds `NPY_ARRAY_DEFAULT` to requirements if\n`NPY_ARRAY_ENSURECOPY` is passed in as requirements.\n\nEncapsulate the functionality of functions and methods that take the axis=\nkeyword and work properly with None as the axis argument. The input array is\n`obj`, while `*axis` is a converted integer (so that >=MAXDIMS is the None\nvalue), and `requirements` gives the needed properties of `obj`. The output is\na converted version of the input so that requirements are met and if needed a\nflattening has occurred. On output negative values of `*axis` are converted\nand the new value is checked to ensure consistency with the shape of `obj`.\n\nEvaluates true if op is a Python object whose type is a sub-type of\n`PyArray_Type`.\n\nEvaluates true if op is a Python object with type `PyArray_Type`.\n\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to `Py_NotImplemented` and no error condition is\nset.\n\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to Py_NotImplemented and no error condition is\nset. This version allows setting of the dtype in the part of the array\ninterface that looks for the `__array__` attribute. `context` is unused.\n\nEvaluates true if op is an instance of (a subclass of) `PyArray_Type` and has\n0 dimensions.\n\nEvaluates true if op is an instance of `Py{cls}ArrType_Type`.\n\nEvaluates true if op is either an array scalar (an instance of a sub-type of\n`PyGenericArr_Type` ), or an instance of (a sub-class of) `PyArray_Type` whose\ndimensionality is 0.\n\nEvaluates true if op is an instance of a builtin numeric type (int, float,\ncomplex, long, bool)\n\nEvaluates true if op is a builtin Python scalar object (int, float, complex,\nbytes, str, long, bool).\n\nEvaluates true if op is either a Python scalar object (see\n`PyArray_IsPythonScalar`) or an array scalar (an instance of a sub- type of\n`PyGenericArr_Type` ).\n\nEvaluates true if op is a Python scalar object (see `PyArray_IsPythonScalar`),\nan array scalar (an instance of a sub-type of `PyGenericArr_Type`) or an\ninstance of a sub-type of `PyArray_Type` whose dimensionality is 0.\n\nFor the typenum macros, the argument is an integer representing an enumerated\narray data type. For the array type checking macros the argument must be a\nPyObject* that can be directly interpreted as a PyArrayObject*.\n\nType represents an unsigned integer.\n\nType represents a signed integer.\n\nType represents any integer.\n\nType represents any floating point number.\n\nType represents any complex floating point number.\n\nType represents any integer, floating point, or complex floating point number.\n\nType represents a string data type.\n\nType represents an enumerated type corresponding to one of the standard Python\nscalar (bool, int, float, or complex).\n\nType represents one of the flexible array types ( `NPY_STRING`, `NPY_UNICODE`,\nor `NPY_VOID` ).\n\nType has no size information attached, and can be resized. Should only be\ncalled on flexible dtypes. Types that are attached to an array will always be\nsized, hence the array form of this macro not existing.\n\nChanged in version 1.18.\n\nFor structured datatypes with no fields this function now returns False.\n\nType represents a user-defined type.\n\nType is either flexible or user-defined.\n\nType represents object data type.\n\nType represents Boolean data type.\n\nType has fields associated with it.\n\nEvaluates true if the data area of the ndarray m is in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\nEvaluates true if the data area of the ndarray m is not in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\nReturn `NPY_TRUE` if type1 and type2 actually represent equivalent types for\nthis platform (the fortran member of each type is ignored). For example, on\n32-bit platforms, `NPY_LONG` and `NPY_INT` are equivalent. Otherwise return\n`NPY_FALSE`.\n\nReturn `NPY_TRUE` if a1 and a2 are arrays with equivalent types for this\nplatform.\n\nSpecial case of `PyArray_EquivTypes` (\u2026) that does not accept flexible data\ntypes but may be easier to call.\n\nTrue if byteorder characters b1 and b2 ( `NPY_LITTLE`, `NPY_BIG`,\n`NPY_NATIVE`, `NPY_IGNORE` ) are either equal or equivalent as to their\nspecification of a native byte order. Thus, on a little-endian machine\n`NPY_LITTLE` and `NPY_NATIVE` are equivalent where they are not equivalent on\na big-endian machine.\n\nMainly for backwards compatibility to the Numeric C-API and for simple casts\nto non-flexible types. Return a new array object with the elements of arr cast\nto the data-type typenum which must be one of the enumerated types and not a\nflexible type.\n\nReturn a new array of the type specified, casting the elements of arr as\nappropriate. The fortran argument specifies the ordering of the output array.\n\nAs of 1.6, this function simply calls `PyArray_CopyInto`, which handles the\ncasting.\n\nCast the elements of the array in into the array out. The output array should\nbe writeable, have an integer-multiple of the number of elements in the input\narray (more than one copy can be placed in out), and have a data type that is\none of the builtin types. Returns 0 on success and -1 if an error occurs.\n\nReturn the low-level casting function to cast from the given descriptor to the\nbuiltin type number. If no casting function exists return `NULL` and set an\nerror. Using this function instead of direct access to from ->f->cast will\nallow support of any user-defined casting functions added to a descriptors\ncasting dictionary.\n\nReturns non-zero if an array of data type fromtype can be cast to an array of\ndata type totype without losing information. An exception is that 64-bit\nintegers are allowed to be cast to 64-bit floating point values even though\nthis can lose precision on large integers so as not to proliferate the use of\nlong doubles without explicit requests. Flexible array types are not checked\naccording to their lengths with this function.\n\n`PyArray_CanCastTypeTo` supersedes this function in NumPy 1.6 and later.\n\nEquivalent to PyArray_CanCastTypeTo(fromtype, totype, NPY_SAFE_CASTING).\n\nNew in version 1.6.\n\nReturns non-zero if an array of data type fromtype (which can include flexible\ntypes) can be cast safely to an array of data type totype (which can include\nflexible types) according to the casting rule casting. For simple types with\n`NPY_SAFE_CASTING`, this is basically a wrapper around\n`PyArray_CanCastSafely`, but for flexible types such as strings or unicode, it\nproduces results taking into account their sizes. Integer and float types can\nonly be cast to a string or unicode type using `NPY_SAFE_CASTING` if the\nstring or unicode type is big enough to hold the max value of the\ninteger/float type being cast from.\n\nNew in version 1.6.\n\nReturns non-zero if arr can be cast to totype according to the casting rule\ngiven in casting. If arr is an array scalar, its value is taken into account,\nand non-zero is also returned when the value will not overflow or be truncated\nto an integer when converting to a smaller type.\n\nThis is almost the same as the result of\nPyArray_CanCastTypeTo(PyArray_MinScalarType(arr), totype, casting), but it\nalso handles a special case arising because the set of uint values is not a\nsubset of the int values for types with the same number of bits.\n\nNew in version 1.6.\n\nIf arr is an array, returns its data type descriptor, but if arr is an array\nscalar (has 0 dimensions), it finds the data type of smallest size to which\nthe value may be converted without overflow or truncation to an integer.\n\nThis function will not demote complex to float or anything to boolean, but\nwill demote a signed integer to an unsigned integer when the scalar value is\npositive.\n\nNew in version 1.6.\n\nFinds the data type of smallest size and kind to which type1 and type2 may be\nsafely converted. This function is symmetric and associative. A string or\nunicode result will be the proper size for storing the max value of the input\ntypes converted to a string or unicode.\n\nNew in version 1.6.\n\nThis applies type promotion to all the inputs, using the NumPy rules for\ncombining scalars and arrays, to determine the output type of a set of\noperands. This is the same result type that ufuncs produce. The specific\nalgorithm used is as follows.\n\nCategories are determined by first checking which of boolean, integer\n(int/uint), or floating point (float/complex) the maximum kind of all the\narrays and the scalars are.\n\nIf there are only scalars or the maximum category of the scalars is higher\nthan the maximum category of the arrays, the data types are combined with\n`PyArray_PromoteTypes` to produce the return value.\n\nOtherwise, PyArray_MinScalarType is called on each array, and the resulting\ndata types are all combined with `PyArray_PromoteTypes` to produce the return\nvalue.\n\nThe set of int values is not a subset of the uint values for types with the\nsame number of bits, something not reflected in `PyArray_MinScalarType`, but\nhandled as a special case in PyArray_ResultType.\n\nThis function is superseded by `PyArray_MinScalarType` and/or\n`PyArray_ResultType`.\n\nThis function is useful for determining a common type that two or more arrays\ncan be converted to. It only works for non-flexible array types as no itemsize\ninformation is passed. The mintype argument represents the minimum type\nacceptable, and op represents the object that will be converted to an array.\nThe return value is the enumerated typenumber that represents the data-type\nthat op should have.\n\nThis function is superseded by `PyArray_ResultType`.\n\nThis function works similarly to `PyArray_ObjectType` (\u2026) except it handles\nflexible arrays. The mintype argument can have an itemsize member and the\nouttype argument will have an itemsize member at least as big but perhaps\nbigger depending on the object op.\n\nThe functionality this provides is largely superseded by iterator `NpyIter`\nintroduced in 1.6, with flag `NPY_ITER_COMMON_DTYPE` or with the same dtype\nparameter for all operands.\n\nConvert a sequence of Python objects contained in op to an array of ndarrays\neach having the same data type. The type is selected in the same way as\n`PyArray_ResultType`. The length of the sequence is returned in n, and an n\n-length array of `PyArrayObject` pointers is the return value (or `NULL` if an\nerror occurs). The returned array must be freed by the caller of this routine\n(using `PyDataMem_FREE` ) and all the array objects in it `DECREF` \u2018d or a\nmemory-leak will occur. The example template-code below shows a typically\nusage:\n\nChanged in version 1.18.0: A mix of scalars and zero-dimensional arrays now\nproduces a type capable of holding the scalar value. Previously priority was\ngiven to the dtype of the arrays.\n\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 0 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 1 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\nReturns `NPY_TRUE` if typenum represents a valid type-number (builtin or user-\ndefined or character code). Otherwise, this function returns `NPY_FALSE`.\n\nInitialize all function pointers and members to `NULL`.\n\nRegister a data-type as a new user-defined data type for arrays. The type must\nhave most of its entries filled in. This is not always checked and errors can\nproduce segfaults. In particular, the typeobj member of the `dtype` structure\nmust be filled with a Python type that has a fixed-size element-size that\ncorresponds to the elsize member of dtype. Also the `f` member must have the\nrequired functions: nonzero, copyswap, copyswapn, getitem, setitem, and cast\n(some of the cast functions may be `NULL` if no support is desired). To avoid\nconfusion, you should choose a unique character typecode but this is not\nenforced and not relied on internally.\n\nA user-defined type number is returned that uniquely identifies the type. A\npointer to the new structure can then be obtained from `PyArray_DescrFromType`\nusing the returned type number. A -1 is returned if an error occurs. If this\ndtype has already been registered (checked only by the address of the\npointer), then return the previously-assigned type-number.\n\nRegister a low-level casting function, castfunc, to convert from the data-\ntype, descr, to the given data-type number, totype. Any old casting function\nis over-written. A `0` is returned on success or a `-1` on failure.\n\nRegister the data-type number, totype, as castable from data-type object,\ndescr, of the given scalar kind. Use scalar = `NPY_NOSCALAR` to register that\nan array of data-type descr can be cast safely to a data-type whose\ntype_number is totype. The return value is 0 on success or -1 on failure.\n\nGiven a string return the type-number for the data-type with that string as\nthe type-object name. Returns `NPY_NOTYPE` without setting an error if no type\ncan be found. Only works for user-defined data-types.\n\nUsed for an array, op, that contains any Python objects. It increments the\nreference count of every object in the array according to the data-type of op.\nA -1 is returned if an error occurs, otherwise 0 is returned.\n\nA function to INCREF all the objects at the location ptr according to the\ndata-type dtype. If ptr is the start of a structured type with an object at\nany offset, then this will (recursively) increment the reference count of all\nobject-like items in the structured type.\n\nUsed for an array, op, that contains any Python objects. It decrements the\nreference count of every object in the array according to the data-type of op.\nNormal return value is 0. A -1 is returned if an error occurs.\n\nA function to XDECREF all the object-like items at the location ptr as\nrecorded in the data-type, dtype. This works recursively so that if `dtype`\nitself has fields with data-types that contain object-like items, all the\nobject-like fields will be XDECREF `'d`.\n\nFill a newly created array with a single value obj at all locations in the\nstructure with object data-types. No checking is performed but arr must be of\ndata-type `NPY_OBJECT` and be single-segment and uninitialized (no previous\nobjects in position). Use `PyArray_XDECREF` (arr) if you need to decrement all\nthe items in the object array prior to calling this function.\n\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Set the UPDATEIFCOPY flag and `arr->base` so that\nwhen `arr` is destructed, it will copy any changes back to `base`. DEPRECATED,\nuse `PyArray_SetWritebackIfCopyBase`.\n\nReturns 0 for success, -1 for failure.\n\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Sets the `NPY_ARRAY_WRITEBACKIFCOPY` flag and\n`arr->base`, and set `base` to READONLY. Call `PyArray_ResolveWritebackIfCopy`\nbefore calling `Py_DECREF` in order copy any changes back to `base` and reset\nthe READONLY flag.\n\nReturns 0 for success, -1 for failure.\n\nThe `flags` attribute of the `PyArrayObject` structure contains important\ninformation about the memory used by the array (pointed to by the data member)\nThis flag information must be kept accurate or strange results and even\nsegfaults may result.\n\nThere are 6 (binary) flags that describe the memory area used by the data\nbuffer. These constants are defined in `arrayobject.h` and determine the bit-\nposition of the flag. Python exposes a nice attribute- based interface as well\nas a dictionary-like interface for getting (and, if appropriate, setting)\nthese flags.\n\nMemory areas of all kinds can be pointed to by an ndarray, necessitating these\nflags. If you get an arbitrary `PyArrayObject` in C-code, you need to be aware\nof the flags that are set. If you need to guarantee a certain kind of array\n(like `NPY_ARRAY_C_CONTIGUOUS` and `NPY_ARRAY_BEHAVED`), then pass these\nrequirements into the PyArray_FromAny function.\n\nAn ndarray can have a data segment that is not a simple contiguous chunk of\nwell-behaved memory you can manipulate. It may not be aligned with word\nboundaries (very important on some platforms). It might have its data in a\ndifferent byte-order than the machine recognizes. It might not be writeable.\nIt might be in Fortran-contiguous order. The array flags are used to indicate\nwhat can be said about data associated with an array.\n\nIn versions 1.6 and earlier of NumPy, the following flags did not have the\n_ARRAY_ macro namespace in them. That form of the constant names is deprecated\nin 1.7.\n\nThe data area is in C-style contiguous order (last index varies the fastest).\n\nThe data area is in Fortran-style contiguous order (first index varies the\nfastest).\n\nNote\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true. The correct way to access the `itemsize` of an\narray from the C API is `PyArray_ITEMSIZE(arr)`.\n\nSee also\n\nInternal memory layout of an ndarray\n\nThe data area is owned by this array. Should never be set manually, instead\ncreate a `PyObject` wrapping the data and set the array\u2019s base to that object.\nFor an example, see the test in `test_mem_policy`.\n\nThe data area and all array elements are aligned appropriately.\n\nThe data area can be written to.\n\nNotice that the above 3 flags are defined so that a new, well- behaved array\nhas these flags defined as true.\n\nThe data area represents a (well-behaved) copy whose information should be\ntransferred back to the original when `PyArray_ResolveWritebackIfCopy` is\ncalled.\n\nThis is a special flag that is set if this array represents a copy made\nbecause a user required certain flags in `PyArray_FromAny` and a copy had to\nbe made of some other array (and the user asked for this flag to be set in\nsuch a situation). The base attribute then points to the \u201cmisbehaved\u201d array\n(which is set read_only). :c:func`PyArray_ResolveWritebackIfCopy` will copy\nits contents back to the \u201cmisbehaved\u201d array (casting if necessary) and will\nreset the \u201cmisbehaved\u201d array to `NPY_ARRAY_WRITEABLE`. If the \u201cmisbehaved\u201d\narray was not `NPY_ARRAY_WRITEABLE` to begin with then `PyArray_FromAny` would\nhave returned an error because `NPY_ARRAY_WRITEBACKIFCOPY` would not have been\npossible.\n\nA deprecated version of `NPY_ARRAY_WRITEBACKIFCOPY` which depends upon\n`dealloc` to trigger the writeback. For backwards compatibility,\n`PyArray_ResolveWritebackIfCopy` is called at `dealloc` but relying on that\nbehavior is deprecated and not supported in PyPy.\n\n`PyArray_UpdateFlags` (obj, flags) will update the `obj->flags` for `flags`\nwhich can be any of `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_ALIGNED`, or `NPY_ARRAY_WRITEABLE`.\n\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_CARRAY`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\nThese constants are used in `PyArray_FromAny` (and its macro forms) to specify\ndesired properties of the new array.\n\nCast to the desired type, even if it can\u2019t be done without losing information.\n\nMake sure the resulting array is a copy of the original.\n\nMake sure the resulting object is an actual ndarray, and not a sub-class.\n\nFor all of these macros arr must be an instance of a (subclass of)\n`PyArray_Type`.\n\nThe first parameter, arr, must be an ndarray or subclass. The parameter,\nflags, should be an integer consisting of bitwise combinations of the possible\nflags an array can have: `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_OWNDATA`, `NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`,\n`NPY_ARRAY_WRITEBACKIFCOPY`, `NPY_ARRAY_UPDATEIFCOPY`.\n\nEvaluates true if arr is C-style contiguous.\n\nEvaluates true if arr is Fortran-style contiguous.\n\nEvaluates true if arr is Fortran-style contiguous and not C-style contiguous.\n`PyArray_IS_F_CONTIGUOUS` is the correct way to test for Fortran-style\ncontiguity.\n\nEvaluates true if the data area of arr can be written to\n\nEvaluates true if the data area of arr is properly aligned on the machine.\n\nEvaluates true if the data area of arr is aligned and writeable and in machine\nbyte-order according to its descriptor.\n\nEvaluates true if the data area of arr is aligned and in machine byte-order.\n\nEvaluates true if the data area of arr is C-style contiguous, and\n`PyArray_ISBEHAVED` (arr) is true.\n\nEvaluates true if the data area of arr is Fortran-style contiguous and\n`PyArray_ISBEHAVED` (arr) is true.\n\nEvaluates true if the data area of arr is C-style contiguous, aligned, and in\nmachine byte-order.\n\nEvaluates true if the data area of arr is Fortran-style contiguous, aligned,\nand in machine byte-order .\n\nEvaluates true if the data area of arr consists of a single (C-style or\nFortran-style) contiguous segment.\n\nThe `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_ALIGNED`, and\n`NPY_ARRAY_F_CONTIGUOUS` array flags can be \u201ccalculated\u201d from the array object\nitself. This routine updates one or more of these flags of arr as specified in\nflagmask by performing the required calculation.\n\nWarning\n\nIt is important to keep the flags updated (using `PyArray_UpdateFlags` can\nhelp) whenever a manipulation with an array is performed that might cause them\nto change. Later calculations in NumPy that rely on the state of these flags\ndo not repeat the calculation to update them.\n\nEquivalent to `ndarray.getfield` (self, dtype, offset). This function steals a\nreference to `PyArray_Descr` and returns a new array of the given `dtype`\nusing the data in the current array at a specified `offset` in bytes. The\n`offset` plus the itemsize of the new array type must be less than `self\n->descr->elsize` or an error is raised. The same shape and strides as the\noriginal array are used. Therefore, this function has the effect of returning\na field from a structured array. But, it can also be used to select specific\nbytes or groups of bytes from any array type.\n\nEquivalent to `ndarray.setfield` (self, val, dtype, offset ). Set the field\nstarting at offset in bytes and of the given dtype to val. The offset plus\ndtype ->elsize must be less than self ->descr->elsize or an error is raised.\nOtherwise, the val argument is converted to an array and copied into the field\npointed to. If necessary, the elements of val are repeated to fill the\ndestination array, But, the number of elements in the destination must be an\ninteger multiple of the number of elements in val.\n\nEquivalent to `ndarray.byteswap` (self, inplace). Return an array whose data\narea is byteswapped. If inplace is non-zero, then do the byteswap inplace and\nreturn a reference to self. Otherwise, create a byteswapped copy and leave\nself unchanged.\n\nEquivalent to `ndarray.copy` (self, fortran). Make a copy of the old array.\nThe returned array is always aligned and writeable with data interpreted the\nsame as the old array. If order is `NPY_CORDER`, then a C-style contiguous\narray is returned. If order is `NPY_FORTRANORDER`, then a Fortran-style\ncontiguous array is returned. If order is `NPY_ANYORDER`, then the array\nreturned is Fortran-style contiguous only if the old one is; otherwise, it is\nC-style contiguous.\n\nEquivalent to `ndarray.tolist` (self). Return a nested Python list from self.\n\nEquivalent to `ndarray.tobytes` (self, order). Return the bytes of this array\nin a Python string.\n\nWrite the contents of self to the file pointer fp in C-style contiguous\nfashion. Write the data as binary bytes if sep is the string \u201c\u201dor `NULL`.\nOtherwise, write the contents of self as text using the sep string as the item\nseparator. Each item will be printed to the file. If the format string is not\n`NULL` or \u201c\u201d, then it is a Python print statement format string showing how\nthe items are to be written.\n\nPickle the object in self to the given file (either a string or a Python file\nobject). If file is a Python string it is considered to be the name of a file\nwhich is then opened in binary mode. The given protocol is used (if protocol\nis negative, or the highest available is used). This is a simple wrapper\naround cPickle.dump(self, file, protocol).\n\nPickle the object in self to a Python string and return it. Use the Pickle\nprotocol provided (or the highest available if protocol is negative).\n\nFill the array, arr, with the given scalar object, obj. The object is first\nconverted to the data type of arr, and then copied into every location. A -1\nis returned if an error occurs, otherwise 0 is returned.\n\nEquivalent to `ndarray.view` (self, dtype). Return a new view of the array\nself as possibly a different data-type, dtype, and different array subclass\nptype.\n\nIf dtype is `NULL`, then the returned array will have the same data type as\nself. The new data-type must be consistent with the size of self. Either the\nitemsizes must be identical, or self must be single-segment and the total\nnumber of bytes must be the same. In the latter case the dimensions of the\nreturned array will be altered in the last (or first for Fortran-style\ncontiguous arrays) dimension. The data area of the returned array and self is\nexactly the same.\n\nResult will be a new array (pointing to the same memory location as self if\npossible), but having a shape given by newshape. If the new shape is not\ncompatible with the strides of self, then a copy of the array with the new\nspecified shape will be returned.\n\nEquivalent to `ndarray.reshape` (self, shape) where shape is a sequence.\nConverts shape to a `PyArray_Dims` structure and calls `PyArray_Newshape`\ninternally. For back-ward compatibility \u2013 Not recommended\n\nEquivalent to `ndarray.squeeze` (self). Return a new view of self with all of\nthe dimensions of length 1 removed from the shape.\n\nWarning\n\nmatrix objects are always 2-dimensional. Therefore, `PyArray_Squeeze` has no\neffect on arrays of matrix sub-class.\n\nEquivalent to `ndarray.swapaxes` (self, a1, a2). The returned array is a new\nview of the data in self with the given axes, a1 and a2, swapped.\n\nEquivalent to `ndarray.resize` (self, newshape, refcheck `=` refcheck, order=\nfortran ). This function only works on single-segment arrays. It changes the\nshape of self inplace and will reallocate the memory for self if newshape has\na different total number of elements then the old shape. If reallocation is\nnecessary, then self must own its data, have self \\- `>base==NULL`, have self\n\\- `>weakrefs==NULL`, and (unless refcheck is 0) not be referenced by any\nother array. The fortran argument can be `NPY_ANYORDER`, `NPY_CORDER`, or\n`NPY_FORTRANORDER`. It currently has no effect. Eventually it could be used to\ndetermine how the resize operation should view the data when constructing a\ndifferently-dimensioned array. Returns None on success and NULL on error.\n\nEquivalent to `ndarray.transpose` (self, permute). Permute the axes of the\nndarray object self according to the data structure permute and return the\nresult. If permute is `NULL`, then the resulting array has its axes reversed.\nFor example if self has shape \\\\(10\\times20\\times30\\\\), and permute `.ptr` is\n(0,2,1) the shape of the result is \\\\(10\\times30\\times20.\\\\) If permute is\n`NULL`, the shape of the result is \\\\(30\\times20\\times10.\\\\)\n\nEquivalent to `ndarray.flatten` (self, order). Return a 1-d copy of the array.\nIf order is `NPY_FORTRANORDER` the elements are scanned out in Fortran order\n(first-dimension varies the fastest). If order is `NPY_CORDER`, the elements\nof `self` are scanned in C-order (last dimension varies the fastest). If order\n`NPY_ANYORDER`, then the result of `PyArray_ISFORTRAN` (self) is used to\ndetermine which order to flatten.\n\nEquivalent to self.ravel(order). Same basic functionality as `PyArray_Flatten`\n(self, order) except if order is 0 and self is C-style contiguous, the shape\nis altered but no copy is performed.\n\nEquivalent to `ndarray.take` (self, indices, axis, ret, clipmode) except axis\n=None in Python is obtained by setting axis = `NPY_MAXDIMS` in C. Extract the\nitems from self indicated by the integer-valued indices along the given axis.\nThe clipmode argument can be `NPY_RAISE`, `NPY_WRAP`, or `NPY_CLIP` to\nindicate what to do with out-of-bound indices. The ret argument can specify an\noutput array rather than having one created internally.\n\nEquivalent to self.put(values, indices, clipmode ). Put values into self at\nthe corresponding (flattened) indices. If values is too small it will be\nrepeated as necessary.\n\nPlace the values in self wherever corresponding positions (using a flattened\ncontext) in mask are true. The mask and self arrays must have the same total\nnumber of elements. If values is too small, it will be repeated as necessary.\n\nEquivalent to `ndarray.repeat` (self, op, axis). Copy the elements of self, op\ntimes along the given axis. Either op is a scalar integer or a sequence of\nlength self ->dimensions[ axis ] indicating how many times to repeat each item\nalong the axis.\n\nEquivalent to `ndarray.choose` (self, op, ret, clipmode). Create a new array\nby selecting elements from the sequence of arrays in op based on the integer\nvalues in self. The arrays must all be broadcastable to the same shape and the\nentries in self should be between 0 and len(op). The output is placed in ret\nunless it is `NULL` in which case a new output is created. The clipmode\nargument determines behavior for when entries in self are not between 0 and\nlen(op).\n\nraise a ValueError;\n\nwrap values < 0 by adding len(op) and values >=len(op) by subtracting len(op)\nuntil they are in range;\n\nall values are clipped to the region [0, len(op) ).\n\nEquivalent to `ndarray.sort` (self, axis, kind). Return an array with the\nitems of self sorted along axis. The array is sorted using the algorithm\ndenoted by kind, which is an integer/enum pointing to the type of sorting\nalgorithms used.\n\nEquivalent to `ndarray.argsort` (self, axis). Return an array of indices such\nthat selection of these indices along the given `axis` would return a sorted\nversion of self. If self ->descr is a data-type with fields defined, then\nself->descr->names is used to determine the sort order. A comparison where the\nfirst field is equal will use the second field and so on. To alter the sort\norder of a structured array, create a new data-type with a different order of\nnames and construct a view of the array with that new data-type.\n\nGiven a sequence of arrays (sort_keys) of the same shape, return an array of\nindices (similar to `PyArray_ArgSort` (\u2026)) that would sort the arrays\nlexicographically. A lexicographic sort specifies that when two keys are found\nto be equal, the order is based on comparison of subsequent keys. A merge sort\n(which leaves equal entries unmoved) is required to be defined for the types.\nThe sort is accomplished by sorting the indices first using the first sort_key\nand then using the second sort_key and so forth. This is equivalent to the\nlexsort(sort_keys, axis) Python command. Because of the way the merge-sort\nworks, be sure to understand the order the sort_keys must be in (reversed from\nthe order you would use when comparing two elements).\n\nIf these arrays are all collected in a structured array, then `PyArray_Sort`\n(\u2026) can also be used to sort the array directly.\n\nEquivalent to `ndarray.searchsorted` (self, values, side, perm). Assuming self\nis a 1-d array in ascending order, then the output is an array of indices the\nsame shape as values such that, if the elements in values were inserted before\nthe indices, the order of self would be preserved. No checking is done on\nwhether or not self is in ascending order.\n\nThe side argument indicates whether the index returned should be that of the\nfirst suitable location (if `NPY_SEARCHLEFT`) or of the last (if\n`NPY_SEARCHRIGHT`).\n\nThe sorter argument, if not `NULL`, must be a 1D array of integer indices the\nsame length as self, that sorts it into ascending order. This is typically the\nresult of a call to `PyArray_ArgSort` (\u2026) Binary search is used to find the\nrequired insertion points.\n\nEquivalent to `ndarray.partition` (self, ktharray, axis, kind). Partitions the\narray so that the values of the element indexed by ktharray are in the\npositions they would be if the array is fully sorted and places all elements\nsmaller than the kth before and all elements equal or greater after the kth\nelement. The ordering of all elements within the partitions is undefined. If\nself->descr is a data-type with fields defined, then self->descr->names is\nused to determine the sort order. A comparison where the first field is equal\nwill use the second field and so on. To alter the sort order of a structured\narray, create a new data-type with a different order of names and construct a\nview of the array with that new data-type. Returns zero on success and -1 on\nfailure.\n\nEquivalent to `ndarray.argpartition` (self, ktharray, axis, kind). Return an\narray of indices such that selection of these indices along the given `axis`\nwould return a partitioned version of self.\n\nEquivalent to `ndarray.diagonal` (self, offset, axis1, axis2 ). Return the\noffset diagonals of the 2-d arrays defined by axis1 and axis2.\n\nNew in version 1.6.\n\nCounts the number of non-zero elements in the array object self.\n\nEquivalent to `ndarray.nonzero` (self). Returns a tuple of index arrays that\nselect elements of self that are nonzero. If (nd= `PyArray_NDIM` ( `self`\n))==1, then a single index array is returned. The index arrays have data type\n`NPY_INTP`. If a tuple is returned (nd \\\\(\\neq\\\\) 1), then its length is nd.\n\nEquivalent to `ndarray.compress` (self, condition, axis ). Return the elements\nalong axis corresponding to elements of condition that are true.\n\nTip\n\nPass in `NPY_MAXDIMS` for axis in order to achieve the same effect that is\nobtained by passing in `axis=None` in Python (treating the array as a 1-d\narray).\n\nNote\n\nThe out argument specifies where to place the result. If out is NULL, then the\noutput array is created, otherwise the output is placed in out which must be\nthe correct size and type. A new reference to the output array is always\nreturned even when out is not NULL. The caller of the routine has the\nresponsibility to `Py_DECREF` out if not NULL or a memory-leak will occur.\n\nEquivalent to `ndarray.argmax` (self, axis). Return the index of the largest\nelement of self along axis.\n\nEquivalent to `ndarray.argmin` (self, axis). Return the index of the smallest\nelement of self along axis.\n\nEquivalent to `ndarray.max` (self, axis). Returns the largest element of self\nalong the given axis. When the result is a single element, returns a numpy\nscalar instead of an ndarray.\n\nEquivalent to `ndarray.min` (self, axis). Return the smallest element of self\nalong the given axis. When the result is a single element, returns a numpy\nscalar instead of an ndarray.\n\nEquivalent to `ndarray.ptp` (self, axis). Return the difference between the\nlargest element of self along axis and the smallest element of self along\naxis. When the result is a single element, returns a numpy scalar instead of\nan ndarray.\n\nNote\n\nThe rtype argument specifies the data-type the reduction should take place\nover. This is important if the data-type of the array is not \u201clarge\u201d enough to\nhandle the output. By default, all integer data-types are made at least as\nlarge as `NPY_LONG` for the \u201cadd\u201d and \u201cmultiply\u201d ufuncs (which form the basis\nfor mean, sum, cumsum, prod, and cumprod functions).\n\nEquivalent to `ndarray.mean` (self, axis, rtype). Returns the mean of the\nelements along the given axis, using the enumerated type rtype as the data\ntype to sum in. Default sum behavior is obtained using `NPY_NOTYPE` for rtype.\n\nEquivalent to `ndarray.trace` (self, offset, axis1, axis2, rtype). Return the\nsum (using rtype as the data type of summation) over the offset diagonal\nelements of the 2-d arrays defined by axis1 and axis2 variables. A positive\noffset chooses diagonals above the main diagonal. A negative offset selects\ndiagonals below the main diagonal.\n\nEquivalent to `ndarray.clip` (self, min, max). Clip an array, self, so that\nvalues larger than max are fixed to max and values less than min are fixed to\nmin.\n\nEquivalent to `ndarray.conjugate` (self). Return the complex conjugate of\nself. If self is not of complex data type, then return self with a reference.\n\nEquivalent to `ndarray.round` (self, decimals, out). Returns the array with\nelements rounded to the nearest decimal place. The decimal place is defined as\nthe \\\\(10^{-\\textrm{decimals}}\\\\) digit so that negative decimals cause\nrounding to the nearest 10\u2019s, 100\u2019s, etc. If out is `NULL`, then the output\narray is created, otherwise the output is placed in out which must be the\ncorrect size and type.\n\nEquivalent to `ndarray.std` (self, axis, rtype). Return the standard deviation\nusing data along axis converted to data type rtype.\n\nEquivalent to `ndarray.sum` (self, axis, rtype). Return 1-d vector sums of\nelements in self along axis. Perform the sum after converting data to data\ntype rtype.\n\nEquivalent to `ndarray.cumsum` (self, axis, rtype). Return cumulative 1-d sums\nof elements in self along axis. Perform the sum after converting data to data\ntype rtype.\n\nEquivalent to `ndarray.prod` (self, axis, rtype). Return 1-d products of\nelements in self along axis. Perform the product after converting data to data\ntype rtype.\n\nEquivalent to `ndarray.cumprod` (self, axis, rtype). Return 1-d cumulative\nproducts of elements in `self` along `axis`. Perform the product after\nconverting data to data type `rtype`.\n\nEquivalent to `ndarray.all` (self, axis). Return an array with True elements\nfor every 1-d sub-array of `self` defined by `axis` in which all the elements\nare True.\n\nEquivalent to `ndarray.any` (self, axis). Return an array with True elements\nfor every 1-d sub-array of self defined by axis in which any of the elements\nare True.\n\nSometimes it is useful to access a multidimensional array as a C-style multi-\ndimensional array so that algorithms can be implemented using C\u2019s a[i][j][k]\nsyntax. This routine returns a pointer, ptr, that simulates this kind of\nC-style array, for 1-, 2-, and 3-d ndarrays.\n\nNote\n\nThe simulation of a C-style array is not complete for 2-d and 3-d arrays. For\nexample, the simulated arrays of pointers cannot be passed to subroutines\nexpecting specific, statically-defined 2-d and 3-d arrays. To pass to\nfunctions requiring those kind of inputs, you must statically define the\nrequired array and copy data.\n\nMust be called with the same objects and memory locations returned from\n`PyArray_AsCArray` (\u2026). This function cleans up memory that otherwise would\nget leaked.\n\nJoin the sequence of objects in obj together along axis into a single array.\nIf the dimensions or types are not compatible an error is raised.\n\nCompute a product-sum over the last dimensions of obj1 and obj2. Neither array\nis conjugated.\n\nCompute a product-sum over the last dimension of obj1 and the second-to-last\ndimension of obj2. For 2-d arrays this is a matrix-product. Neither array is\nconjugated.\n\nNew in version 1.6.\n\nSame as PyArray_MatrixProduct, but store the result in out. The output array\nmust have the correct shape, type, and be C-contiguous, or an exception is\nraised.\n\nNew in version 1.6.\n\nApplies the Einstein summation convention to the array operands provided,\nreturning a new array or placing the result in out. The string in subscripts\nis a comma separated list of index letters. The number of operands is in nop,\nand op_in is an array containing those operands. The data type of the output\ncan be forced with dtype, the output order can be forced with order\n(`NPY_KEEPORDER` is recommended), and when dtype is specified, casting\nindicates how permissive the data conversion should be.\n\nSee the `einsum` function for more details.\n\nA specialized copy and transpose function that works only for 2-d arrays. The\nreturned array is a transposed copy of op.\n\nCompute the 1-d correlation of the 1-d arrays op1 and op2 . The correlation is\ncomputed at each output point by multiplying op1 by a shifted version of op2\nand summing the result. As a result of the shift, needed values outside of the\ndefined range of op1 and op2 are interpreted as zero. The mode determines how\nmany shifts to return: 0 - return only shifts that did not need to assume\nzero- values; 1 - return an object that is the same size as op1, 2 - return\nall possible shifts (any overlap at all is accepted).\n\nThis does not compute the usual correlation: if op2 is larger than op1, the\narguments are swapped, and the conjugate is never taken for complex arrays.\nSee PyArray_Correlate2 for the usual signal processing correlation.\n\nUpdated version of PyArray_Correlate, which uses the usual definition of\ncorrelation for 1d arrays. The correlation is computed at each output point by\nmultiplying op1 by a shifted version of op2 and summing the result. As a\nresult of the shift, needed values outside of the defined range of op1 and op2\nare interpreted as zero. The mode determines how many shifts to return: 0 -\nreturn only shifts that did not need to assume zero- values; 1 - return an\nobject that is the same size as op1, 2 - return all possible shifts (any\noverlap at all is accepted).\n\nCompute z as follows:\n\nIf both `x` and `y` are `NULL`, then return `PyArray_Nonzero` (condition).\nOtherwise, both x and y must be given and the object returned is shaped like\ncondition and has elements of x and y where condition is respectively True or\nFalse.\n\nDetermine if newstrides is a strides array consistent with the memory of an nd\n-dimensional array with shape `dims` and element-size, elsize. The newstrides\narray is checked to see if jumping by the provided number of bytes in each\ndirection will ever mean jumping more than numbytes which is the assumed size\nof the available memory segment. If numbytes is 0, then an equivalent numbytes\nis computed assuming nd, dims, and elsize refer to a single-segment array.\nReturn `NPY_TRUE` if newstrides is acceptable, otherwise return `NPY_FALSE`.\n\nBoth of these routines multiply an n -length array, seq, of integers and\nreturn the result. No overflow checking is performed.\n\nGiven two n -length arrays of integers, l1, and l2, return 1 if the lists are\nidentical; otherwise, return 0.\n\nNew in version 1.7.0.\n\nWhen working with more complex dtypes which are composed of other dtypes, such\nas the struct dtype, creating inner loops that manipulate the dtypes requires\ncarrying along additional data. NumPy supports this idea through a struct\n`NpyAuxData`, mandating a few conventions so that it is possible to do this.\n\nDefining an `NpyAuxData` is similar to defining a class in C++, but the object\nsemantics have to be tracked manually since the API is in C. Here\u2019s an example\nfor a function which doubles up an element using an element copier function as\na primitive.\n\nThe function pointer type for NpyAuxData free functions.\n\nThe function pointer type for NpyAuxData clone functions. These functions\nshould never set the Python exception on error, because they may be called\nfrom a multi-threaded context.\n\nA macro which calls the auxdata\u2019s free function appropriately, does nothing if\nauxdata is NULL.\n\nA macro which calls the auxdata\u2019s clone function appropriately, returning a\ndeep copy of the auxiliary data.\n\nAs of NumPy 1.6.0, these array iterators are superseded by the new array\niterator, `NpyIter`.\n\nAn array iterator is a simple way to access the elements of an N-dimensional\narray quickly and efficiently. Section 2 provides more description and\nexamples of this useful approach to looping over an array.\n\nReturn an array iterator object from the array, arr. This is equivalent to\narr. flat. The array iterator object makes it easy to loop over an\nN-dimensional non-contiguous array in C-style contiguous fashion.\n\nReturn an array iterator that will iterate over all axes but the one provided\nin *axis. The returned iterator cannot be used with `PyArray_ITER_GOTO1D`.\nThis iterator could be used to write something similar to what ufuncs do\nwherein the loop over the largest axis is done by a separate sub-routine. If\n*axis is negative then *axis will be set to the axis having the smallest\nstride and that axis will be used.\n\nReturn an array iterator that is broadcast to iterate as an array of the shape\nprovided by dimensions and nd.\n\nEvaluates true if op is an array iterator (or instance of a subclass of the\narray iterator type).\n\nReset an iterator to the beginning of the array.\n\nIncremement the index and the dataptr members of the iterator to point to the\nnext element of the array. If the array is not (C-style) contiguous, also\nincrement the N-dimensional coordinates array.\n\nA pointer to the current element of the array.\n\nSet the iterator index, dataptr, and coordinates members to the location in\nthe array indicated by the N-dimensional c-array, destination, which must have\nsize at least iterator ->nd_m1+1.\n\nSet the iterator index and dataptr to the location in the array indicated by\nthe integer index which points to an element in the C-styled flattened array.\n\nEvaluates TRUE as long as the iterator has not looped through all of the\nelements, otherwise it evaluates FALSE.\n\nA simplified interface to broadcasting. This function takes the number of\narrays to broadcast and then num extra ( `PyObject *` ) arguments. These\narguments are converted to arrays and iterators are created.\n`PyArray_Broadcast` is then called on the resulting multi-iterator object. The\nresulting, broadcasted mult-iterator object is then returned. A broadcasted\noperation can then be performed using a single loop and using\n`PyArray_MultiIter_NEXT` (..)\n\nReset all the iterators to the beginning in a multi-iterator object, multi.\n\nAdvance each iterator in a multi-iterator object, multi, to its next\n(broadcasted) element.\n\nReturn the data-pointer of the i \\\\(^{\\textrm{th}}\\\\) iterator in a multi-\niterator object.\n\nAdvance the pointer of only the i \\\\(^{\\textrm{th}}\\\\) iterator.\n\nAdvance each iterator in a multi-iterator object, multi, to the given \\\\(N\\\\)\n-dimensional destination where \\\\(N\\\\) is the number of dimensions in the\nbroadcasted array.\n\nAdvance each iterator in a multi-iterator object, multi, to the corresponding\nlocation of the index into the flattened broadcasted array.\n\nEvaluates TRUE as long as the multi-iterator has not looped through all of the\nelements (of the broadcasted result), otherwise it evaluates FALSE.\n\nThis function encapsulates the broadcasting rules. The mit container should\nalready contain iterators for all the arrays that need to be broadcast. On\nreturn, these iterators will be adjusted so that iteration over each\nsimultaneously will accomplish the broadcasting. A negative number is returned\nif an error occurs.\n\nThis function takes a multi-iterator object that has been previously\n\u201cbroadcasted,\u201d finds the dimension with the smallest \u201csum of strides\u201d in the\nbroadcasted result and adapts all the iterators so as not to iterate over that\ndimension (by effectively making them of length-1 in that dimension). The\ncorresponding dimension is returned unless mit ->nd is 0, then -1 is returned.\nThis function is useful for constructing ufunc-like routines that broadcast\ntheir inputs correctly and then call a strided 1-d version of the routine as\nthe inner-loop. This 1-d version is usually optimized for speed and for this\nreason the loop should be performed over the axis that won\u2019t require large\nstride jumps.\n\nNew in version 1.4.0.\n\nNeighborhood iterators are subclasses of the iterator object, and can be used\nto iter over a neighborhood of a point. For example, you may want to iterate\nover every voxel of a 3d image, and for every such voxel, iterate over an\nhypercube. Neighborhood iterator automatically handle boundaries, thus making\nthis kind of code much easier to write than manual boundaries handling, at the\ncost of a slight overhead.\n\nThis function creates a new neighborhood iterator from an existing iterator.\nThe neighborhood will be computed relatively to the position currently pointed\nby iter, the bounds define the shape of the neighborhood iterator, and the\nmode argument the boundaries handling mode.\n\nThe bounds argument is expected to be a (2 * iter->ao->nd) arrays, such as the\nrange bound[2*i]->bounds[2*i+1] defines the range where to walk for dimension\ni (both bounds are included in the walked coordinates). The bounds should be\nordered for each dimension (bounds[2*i] <= bounds[2*i+1]).\n\nThe mode should be one of:\n\nZero padding. Outside bounds values will be 0.\n\nOne padding, Outside bounds values will be 1.\n\nConstant padding. Outside bounds values will be the same as the first item in\nfill_value.\n\nMirror padding. Outside bounds values will be as if the array items were\nmirrored. For example, for the array [1, 2, 3, 4], x[-2] will be 2, x[-2] will\nbe 1, x[4] will be 4, x[5] will be 1, etc\u2026\n\nCircular padding. Outside bounds values will be as if the array was repeated.\nFor example, for the array [1, 2, 3, 4], x[-2] will be 3, x[-2] will be 4,\nx[4] will be 1, x[5] will be 2, etc\u2026\n\nIf the mode is constant filling (`NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING`),\nfill_value should point to an array object which holds the filling value (the\nfirst item will be the filling value if the array contains more than one\nitem). For other cases, fill_value may be NULL.\n\nReset the iterator position to the first point of the neighborhood. This\nshould be called whenever the iter argument given at\nPyArray_NeighborhoodIterObject is changed (see example)\n\nAfter this call, iter->dataptr points to the next point of the neighborhood.\nCalling this function after every point of the neighborhood has been visited\nis undefined.\n\nArray mapping is the machinery behind advanced indexing.\n\nUse advanced indexing to iterate an array.\n\nSwap the axes to or from their inserted form. `MapIter` always puts the\nadvanced (array) indices first in the iteration. But if they are consecutive,\nit will insert/transpose them back before returning. This is stored as\n`mit->consec != 0` (the place where they are inserted). For assignments, the\nopposite happens: the values to be assigned are transposed (`getmap=1` instead\nof `getmap=0`). `getmap=0` and `getmap=1` undo the other operation.\n\nThis function needs to update the state of the map iterator and point\n`mit->dataptr` to the memory-location of the next object.\n\nNote that this function never handles an extra operand but provides\ncompatibility for an old (exposed) API.\n\nSimilar to `PyArray_MapIterArray` but with an additional `copy_if_overlap`\nargument. If `copy_if_overlap != 0`, checks if `a` has memory overlap with any\nof the arrays in `index` and with `extra_op`, and make copies as appropriate\nto avoid problems if the input is modified during the iteration. `iter->array`\nmay contain a copied array (UPDATEIFCOPY/WRITEBACKIFCOPY set).\n\nThis function steals a reference to arr.\n\nThis function checks to see if arr is a 0-dimensional array and, if so,\nreturns the appropriate array scalar. It should be used whenever 0-dimensional\narrays could be returned to Python.\n\nReturn an array scalar object of the given dtype by copying from memory\npointed to by data. base is expected to be the array object that is the owner\nof the data. base is required if `dtype` is a `void` scalar, or if the\n`NPY_USE_GETITEM` flag is set and it is known that the `getitem` method uses\nthe `arr` argument without checking if it is `NULL`. Otherwise `base` may be\n`NULL`.\n\nIf the data is not in native byte order (as indicated by `dtype->byteorder`)\nthen this function will byteswap the data, because array scalars are always in\ncorrect machine-byte order.\n\nReturn an array scalar object of the type and itemsize indicated by the array\nobject arr copied from the memory pointed to by data and swapping if the data\nin arr is not in machine byte-order.\n\nReturn a 0-dimensional array of type determined by outcode from scalar which\nshould be an array-scalar object. If outcode is NULL, then the type is\ndetermined from scalar.\n\nReturn in ctypeptr a pointer to the actual value in an array scalar. There is\nno error checking so scalar must be an array-scalar object, and ctypeptr must\nhave enough space to hold the correct type. For flexible-sized types, a\npointer to the data is copied into the memory of ctypeptr, for all other\ntypes, the actual data is copied into the address pointed to by ctypeptr.\n\nReturn the data (cast to the data type indicated by outcode) from the array-\nscalar, scalar, into the memory pointed to by ctypeptr (which must be large\nenough to handle the incoming memory).\n\nReturns a scalar type-object from a type-number, type . Equivalent to\n`PyArray_DescrFromType` (type)->typeobj except for reference counting and\nerror-checking. Returns a new reference to the typeobject on success or `NULL`\non failure.\n\nSee the function `PyArray_MinScalarType` for an alternative mechanism\nintroduced in NumPy 1.6.0.\n\nReturn the kind of scalar represented by typenum and the array in *arr (if arr\nis not `NULL` ). The array is assumed to be rank-0 and only used if typenum\nrepresents a signed integer. If arr is not `NULL` and the first element is\nnegative then `NPY_INTNEG_SCALAR` is returned, otherwise `NPY_INTPOS_SCALAR`\nis returned. The possible return values are the enumerated values in\n`NPY_SCALARKIND`.\n\nSee the function `PyArray_ResultType` for details of NumPy type promotion,\nupdated in NumPy 1.6.0.\n\nImplements the rules for scalar coercion. Scalars are only silently coerced\nfrom thistype to neededtype if this function returns nonzero. If scalar is\n`NPY_NOSCALAR`, then this function is equivalent to `PyArray_CanCastSafely`.\nThe rule is that scalars of the same KIND can be coerced into arrays of the\nsame KIND. This rule means that high-precision scalars will never cause low-\nprecision arrays of the same KIND to be upcast.\n\nWarning\n\nData-type objects must be reference counted so be aware of the action on the\ndata-type reference of different C-API calls. The standard rule is that when a\ndata-type object is returned it is a new reference. Functions that take\nPyArray_Descr* objects and return arrays steal references to the data-type\ntheir inputs unless otherwise noted. Therefore, you must own a reference to\nany data-type object used as input to such a function.\n\nEvaluates as true if obj is a data-type object ( PyArray_Descr* ).\n\nReturn a new data-type object copied from obj (the fields reference is just\nupdated so that the new object points to the same fields dictionary if any).\n\nCreate a new data-type object from the built-in (or user-registered) data-type\nindicated by typenum. All builtin types should not have any of their fields\nchanged. This creates a new copy of the `PyArray_Descr` structure so that you\ncan fill it in as appropriate. This function is especially needed for flexible\ndata-types which need to have a new elsize member in order to be meaningful in\narray construction.\n\nCreate a new data-type object with the byteorder set according to newendian.\nAll referenced data-type objects (in subdescr and fields members of the data-\ntype object) are also changed (recursively).\n\nThe value of newendian is one of these macros:\n\nIf a byteorder of `NPY_IGNORE` is encountered it is left alone. If newendian\nis `NPY_SWAP`, then all byte-orders are swapped. Other valid newendian values\nare `NPY_NATIVE`, `NPY_LITTLE`, and `NPY_BIG` which all cause the returned\ndata-typed descriptor (and all it\u2019s referenced data-type descriptors) to have\nthe corresponding byte- order.\n\nDetermine an appropriate data-type object from the object op (which should be\na \u201cnested\u201d sequence object) and the minimum data-type descriptor mintype\n(which can be `NULL` ). Similar in behavior to array(op).dtype. Don\u2019t confuse\nthis function with `PyArray_DescrConverter`. This function essentially looks\nat all the objects in the (nested) sequence and determines the data-type from\nthe elements it finds.\n\nReturn a data-type object from an array-scalar object. No checking is done to\nbe sure that scalar is an array scalar. If no suitable data-type can be\ndetermined, then a data-type of `NPY_OBJECT` is returned by default.\n\nReturns a data-type object corresponding to typenum. The typenum can be one of\nthe enumerated types, a character code for one of the enumerated types, or a\nuser-defined type. If you want to use a flexible size array, then you need to\n`flexible typenum` and set the results `elsize` parameter to the desired size.\nThe typenum is one of the `NPY_TYPES`.\n\nConvert any compatible Python object, obj, to a data-type object in dtype. A\nlarge number of Python objects can be converted to data-type objects. See Data\ntype objects (dtype) for a complete description. This version of the converter\nconverts None objects to a `NPY_DEFAULT_TYPE` data-type object. This function\ncan be used with the \u201cO&\u201d character code in `PyArg_ParseTuple` processing.\n\nConvert any compatible Python object, obj, to a data-type object in dtype.\nThis version of the converter converts None objects so that the returned data-\ntype is `NULL`. This function can also be used with the \u201cO&\u201d character in\nPyArg_ParseTuple processing.\n\nLike `PyArray_DescrConverter` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\nLike `PyArray_DescrConverter2` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\nTake the fields dictionary, dict, such as the one attached to a data-type\nobject and construct an ordered-list of field names such as is stored in the\nnames field of the `PyArray_Descr` object.\n\nAll of these functions can be used in `PyArg_ParseTuple` (\u2026) with the \u201cO&\u201d\nformat specifier to automatically convert any Python object to the required\nC-object. All of these functions return `NPY_SUCCEED` if successful and\n`NPY_FAIL` if not. The first argument to all of these function is a Python\nobject. The second argument is the address of the C-type to convert the Python\nobject to.\n\nWarning\n\nBe sure to understand what steps you should take to manage the memory when\nusing these conversion functions. These functions can require freeing memory,\nand/or altering the reference counts of specific objects based on your use.\n\nConvert any Python object to a `PyArrayObject`. If `PyArray_Check` (obj) is\nTRUE then its reference count is incremented and a reference placed in\naddress. If obj is not an array, then convert it to an array using\n`PyArray_FromAny` . No matter what is returned, you must DECREF the object\nreturned by this routine in address when you are done with it.\n\nThis is a default converter for output arrays given to functions. If obj is\n`Py_None` or `NULL`, then *address will be `NULL` but the call will succeed.\nIf `PyArray_Check` ( obj) is TRUE then it is returned in *address without\nincrementing its reference count.\n\nConvert any Python sequence, obj, smaller than `NPY_MAXDIMS` to a C-array of\n`npy_intp`. The Python object could also be a single number. The seq variable\nis a pointer to a structure with members ptr and len. On successful return,\nseq ->ptr contains a pointer to memory that must be freed, by calling\n`PyDimMem_FREE`, to avoid a memory leak. The restriction on memory size allows\nthis converter to be conveniently used for sequences intended to be\ninterpreted as array shapes.\n\nConvert any Python object, obj, with a (single-segment) buffer interface to a\nvariable with members that detail the object\u2019s use of its chunk of memory. The\nbuf variable is a pointer to a structure with base, ptr, len, and flags\nmembers. The `PyArray_Chunk` structure is binary compatible with the Python\u2019s\nbuffer object (through its len member on 32-bit platforms and its ptr member\non 64-bit platforms or in Python 2.5). On return, the base member is set to\nobj (or its base if obj is already a buffer object pointing to another\nobject). If you need to hold on to the memory be sure to INCREF the base\nmember. The chunk of memory is pointed to by buf ->ptr member and has length\nbuf ->len. The flags member of buf is `NPY_ARRAY_ALIGNED` with the\n`NPY_ARRAY_WRITEABLE` flag set if obj has a writeable buffer interface.\n\nConvert a Python object, obj, representing an axis argument to the proper\nvalue for passing to the functions that take an integer axis. Specifically, if\nobj is None, axis is set to `NPY_MAXDIMS` which is interpreted correctly by\nthe C-API functions that take axis arguments.\n\nConvert any Python object, obj, to `NPY_TRUE` or `NPY_FALSE`, and place the\nresult in value.\n\nConvert Python strings into the corresponding byte-order character: \u2018>\u2019, \u2018<\u2019,\n\u2018s\u2019, \u2018=\u2019, or \u2018|\u2019.\n\nConvert Python strings into one of `NPY_QUICKSORT` (starts with \u2018q\u2019 or \u2018Q\u2019),\n`NPY_HEAPSORT` (starts with \u2018h\u2019 or \u2018H\u2019), `NPY_MERGESORT` (starts with \u2018m\u2019 or\n\u2018M\u2019) or `NPY_STABLESORT` (starts with \u2018t\u2019 or \u2018T\u2019). `NPY_MERGESORT` and\n`NPY_STABLESORT` are aliased to each other for backwards compatibility and may\nrefer to one of several stable sorting algorithms depending on the data type.\n\nConvert Python strings into one of `NPY_SEARCHLEFT` (starts with \u2018l\u2019 or \u2018L\u2019),\nor `NPY_SEARCHRIGHT` (starts with \u2018r\u2019 or \u2018R\u2019).\n\nConvert the Python strings \u2018C\u2019, \u2018F\u2019, \u2018A\u2019, and \u2018K\u2019 into the `NPY_ORDER`\nenumeration `NPY_CORDER`, `NPY_FORTRANORDER`, `NPY_ANYORDER`, and\n`NPY_KEEPORDER`.\n\nConvert the Python strings \u2018no\u2019, \u2018equiv\u2019, \u2018safe\u2019, \u2018same_kind\u2019, and \u2018unsafe\u2019\ninto the `NPY_CASTING` enumeration `NPY_NO_CASTING`, `NPY_EQUIV_CASTING`,\n`NPY_SAFE_CASTING`, `NPY_SAME_KIND_CASTING`, and `NPY_UNSAFE_CASTING`.\n\nConvert the Python strings \u2018clip\u2019, \u2018wrap\u2019, and \u2018raise\u2019 into the `NPY_CLIPMODE`\nenumeration `NPY_CLIP`, `NPY_WRAP`, and `NPY_RAISE`.\n\nConverts either a sequence of clipmodes or a single clipmode into a C array of\n`NPY_CLIPMODE` values. The number of clipmodes n must be known before calling\nthis function. This function is provided to help functions allow a different\nclipmode for each dimension.\n\nConvert all kinds of Python objects (including arrays and array scalars) to a\nstandard integer. On error, -1 is returned and an exception set. You may find\nuseful the macro:\n\nConvert all kinds of Python objects (including arrays and array scalars) to a\n(platform-pointer-sized) integer. On error, -1 is returned and an exception\nset.\n\nConvert any Python sequence (or single Python number) passed in as seq to (up\nto) maxvals pointer-sized integers and place them in the vals array. The\nsequence can be smaller then maxvals as the number of converted objects is\nreturned.\n\nConvert typestring characters (with itemsize) to basic enumerated data types.\nThe typestring character corresponding to signed and unsigned integers,\nfloating point numbers, and complex-floating point numbers are recognized and\nconverted. Other values of gentype are returned. This function can be used to\nconvert, for example, the string \u2018f4\u2019 to `NPY_FLOAT32`.\n\nIn order to make use of the C-API from another extension module, the\n`import_array` function must be called. If the extension module is self-\ncontained in a single .c file, then that is all that needs to be done. If,\nhowever, the extension module involves multiple files where the C-API is\nneeded then some additional steps must be taken.\n\nThis function must be called in the initialization section of a module that\nwill make use of the C-API. It imports the module where the function-pointer\ntable is stored and points the correct variable to it.\n\nUsing these #defines you can use the C-API in multiple files for a single\nextension module. In each file you must define `PY_ARRAY_UNIQUE_SYMBOL` to\nsome name that will hold the C-API (e.g. myextension_ARRAY_API). This must be\ndone before including the numpy/arrayobject.h file. In the module\ninitialization routine you call `import_array`. In addition, in the files that\ndo not have the module initialization sub_routine define `NO_IMPORT_ARRAY`\nprior to including numpy/arrayobject.h.\n\nSuppose I have two files coolmodule.c and coolhelper.c which need to be\ncompiled and linked into a single extension module. Suppose coolmodule.c\ncontains the required initcool module initialization function (with the\nimport_array() function called). Then, coolmodule.c would have at the top:\n\nOn the other hand, coolhelper.c would contain at the top:\n\nYou can also put the common two last lines into an extension-local header file\nas long as you make sure that NO_IMPORT_ARRAY is #defined before #including\nthat file.\n\nInternally, these #defines work as follows:\n\nBecause python extensions are not used in the same way as usual libraries on\nmost platforms, some errors cannot be automatically detected at build time or\neven runtime. For example, if you build an extension using a function\navailable only for numpy >= 1.3.0, and you import the extension later with\nnumpy 1.2, you will not get an import error (but almost certainly a\nsegmentation fault when calling the function). That\u2019s why several functions\nare provided to check for numpy versions. The macros `NPY_VERSION` and\n`NPY_FEATURE_VERSION` corresponds to the numpy version used to build the\nextension, whereas the versions returned by the functions\n`PyArray_GetNDArrayCVersion` and `PyArray_GetNDArrayCFeatureVersion`\ncorresponds to the runtime numpy\u2019s version.\n\nThe rules for ABI and API compatibilities can be summarized as follows:\n\nABI incompatibility is automatically detected in every numpy\u2019s version. API\nincompatibility detection was added in numpy 1.4.0. If you want to supported\nmany different numpy versions with one extension binary, you have to build\nyour extension with the lowest `NPY_FEATURE_VERSION` as possible.\n\nThe current version of the ndarray object (check to see if this variable is\ndefined to guarantee the `numpy/arrayobject.h` header is being used).\n\nThe current version of the C-API.\n\nThis just returns the value `NPY_VERSION`. `NPY_VERSION` changes whenever a\nbackward incompatible change at the ABI level. Because it is in the C-API,\nhowever, comparing the output of this function from the value defined in the\ncurrent header gives a way to test if the C-API has changed thus requiring a\nre-compilation of extension modules that use the C-API. This is automatically\nchecked in the function `import_array`.\n\nNew in version 1.4.0.\n\nThis just returns the value `NPY_FEATURE_VERSION`. `NPY_FEATURE_VERSION`\nchanges whenever the API changes (e.g. a function is added). A changed value\ndoes not always require a recompile.\n\nNumPy stores an internal table of Python callable objects that are used to\nimplement arithmetic operations for arrays as well as certain array\ncalculation methods. This function allows the user to replace any or all of\nthese Python objects with their own versions. The keys of the dictionary,\ndict, are the named functions to replace and the paired value is the Python\ncallable object to use. Care should be taken that the function used to replace\nan internal array operation does not itself call back to that internal array\noperation (unless you have designed the function to handle that), or an\nunchecked infinite recursion can result (possibly causing program crash). The\nkey names that represent operations that can be replaced are:\n\nadd, subtract, multiply, divide, remainder, power, square, reciprocal,\nones_like, sqrt, negative, positive, absolute, invert, left_shift,\nright_shift, bitwise_and, bitwise_xor, bitwise_or, less, less_equal, equal,\nnot_equal, greater, greater_equal, floor_divide, true_divide, logical_or,\nlogical_and, floor, ceil, maximum, minimum, rint.\n\nThese functions are included here because they are used at least once in the\narray object\u2019s methods. The function returns -1 (without setting a Python\nError) if one of the objects being assigned is not callable.\n\nDeprecated since version 1.16.\n\nReturn a Python dictionary containing the callable Python objects stored in\nthe internal arithmetic operation table. The keys of this dictionary are given\nin the explanation for `PyArray_SetNumericOps`.\n\nDeprecated since version 1.16.\n\nThis function allows you to alter the tp_str and tp_repr methods of the array\nobject to any Python function. Thus you can alter what happens for all arrays\nwhen str(arr) or repr(arr) is called from Python. The function to be called is\npassed in as op. If repr is non-zero, then this function will be called in\nresponse to repr(arr), otherwise the function will be called in response to\nstr(arr). No check on whether or not op is callable is performed. The callable\npassed in to op should expect an array argument and should return a string to\nbe printed.\n\nMacros to allocate, free, and reallocate memory. These macros are used\ninternally to create arrays.\n\nMacros to allocate, free, and reallocate dimension and strides memory.\n\nThese macros use different memory allocators, depending on the constant\n`NPY_USE_PYMEM`. The system malloc is used when `NPY_USE_PYMEM` is 0, if\n`NPY_USE_PYMEM` is 1, then the Python memory allocator is used.\n\nIf `obj.flags` has `NPY_ARRAY_WRITEBACKIFCOPY` or (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY`, this function clears the flags, `DECREF` s\n`obj->base` and makes it writeable, and sets `obj->base` to NULL. It then\ncopies `obj->data` to `obj->base->data`, and returns the error state of the\ncopy operation. This is the opposite of `PyArray_SetWritebackIfCopyBase`.\nUsually this is called once you are finished with `obj`, just before\n`Py_DECREF(obj)`. It may be called multiple times, or with `NULL` input. See\nalso `PyArray_DiscardWritebackIfCopy`.\n\nReturns 0 if nothing was done, -1 on error, and 1 if action was taken.\n\nThese macros are only meaningful if `NPY_ALLOW_THREADS` evaluates True during\ncompilation of the extension module. Otherwise, these macros are equivalent to\nwhitespace. Python uses a single Global Interpreter Lock (GIL) for each Python\nprocess so that only a single thread may execute at a time (even on multi-cpu\nmachines). When calling out to a compiled function that may take time to\ncompute (and does not have side-effects for other threads like updated global\nvariables), the GIL should be released so that other Python threads can run\nwhile the time-consuming calculations are performed. This can be accomplished\nusing two groups of macros. Typically, if one macro in a group is used in a\ncode block, all of them must be used in the same code block. Currently,\n`NPY_ALLOW_THREADS` is defined to the python-defined `WITH_THREADS` constant\nunless the environment variable `NPY_NOSMP` is set in which case\n`NPY_ALLOW_THREADS` is defined to be 0.\n\nThis group is used to call code that may take some time but does not use any\nPython C-API calls. Thus, the GIL should be released during its calculation.\n\nEquivalent to `Py_BEGIN_ALLOW_THREADS` except it uses `NPY_ALLOW_THREADS` to\ndetermine if the macro if replaced with white-space or not.\n\nEquivalent to `Py_END_ALLOW_THREADS` except it uses `NPY_ALLOW_THREADS` to\ndetermine if the macro if replaced with white-space or not.\n\nPlace in the variable declaration area. This macro sets up the variable needed\nfor storing the Python state.\n\nPlace right before code that does not need the Python interpreter (no Python\nC-API calls). This macro saves the Python state and releases the GIL.\n\nPlace right after code that does not need the Python interpreter. This macro\nacquires the GIL and restores the Python state from the saved variable.\n\nUseful to release the GIL only if dtype does not contain arbitrary Python\nobjects which may need the Python interpreter during execution of the loop.\n\nUseful to regain the GIL in situations where it was released using the BEGIN\nform of this macro.\n\nUseful to release the GIL only if loop_size exceeds a minimum threshold,\ncurrently set to 500. Should be matched with a `NPY_END_THREADS` to regain the\nGIL.\n\nThis group is used to re-acquire the Python GIL after it has been released.\nFor example, suppose the GIL has been released (using the previous calls), and\nthen some path in the code (perhaps in a different subroutine) requires use of\nthe Python C-API, then these macros are useful to acquire the GIL. These\nmacros accomplish essentially a reverse of the previous three (acquire the\nLOCK saving what state it had) and then re-release it with the saved state.\n\nPlace in the variable declaration area to set up the necessary variable.\n\nPlace before code that needs to call the Python C-API (when it is known that\nthe GIL has already been released).\n\nPlace after code that needs to call the Python C-API (to re-release the GIL).\n\nTip\n\nNever use semicolons after the threading support macros.\n\nDefault priority for arrays.\n\nDefault subtype priority.\n\nDefault scalar priority (very small)\n\nReturn the `__array_priority__` attribute (converted to a double) of obj or\ndef if no attribute of that name exists. Fast returns that avoid the attribute\nlookup are provided for objects of type `PyArray_Type`.\n\nDefault size of the user-settable internal buffers.\n\nSmallest size of user-settable internal buffers.\n\nLargest size allowed for the user-settable buffers.\n\nThe number of floating-point types\n\nThe maximum number of dimensions allowed in arrays.\n\nThe maximum number of array arguments that can be used in functions.\n\nDefined as 0 for use with Bool.\n\nDefined as 1 for use with Bool.\n\nThe return value of failed converter functions which are called using the \u201cO&\u201d\nsyntax in `PyArg_ParseTuple`-like functions.\n\nThe return value of successful converter functions which are called using the\n\u201cO&\u201d syntax in `PyArg_ParseTuple`-like functions.\n\nEvaluates as True if arrays a1 and a2 have the same shape.\n\nReturns the maximum of a and b. If (a) or (b) are expressions they are\nevaluated twice.\n\nReturns the minimum of a and b. If (a) or (b) are expressions they are\nevaluated twice.\n\nImplements the complex comparisons between two complex numbers (structures\nwith a real and imag member) using NumPy\u2019s definition of the ordering which is\nlexicographic: comparing the real parts first and then the complex parts if\nthe real parts are equal.\n\nReturns the reference count of any Python object.\n\nIf `obj.flags` has `NPY_ARRAY_WRITEBACKIFCOPY` or (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY`, this function clears the flags, `DECREF` s\n`obj->base` and makes it writeable, and sets `obj->base` to NULL. In contrast\nto `PyArray_DiscardWritebackIfCopy` it makes no attempt to copy the data from\n`obj->base` This undoes `PyArray_SetWritebackIfCopyBase`. Usually this is\ncalled after an error when you are finished with `obj`, just before\n`Py_DECREF(obj)`. It may be called multiple times, or with `NULL` input.\n\nDeprecated in 1.14, use `PyArray_DiscardWritebackIfCopy` followed by\n`Py_XDECREF`\n\nDECREF\u2019s an array object which may have the (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY` or `NPY_ARRAY_WRITEBACKIFCOPY` flag set without\ncausing the contents to be copied back into the original array. Resets the\n`NPY_ARRAY_WRITEABLE` flag on the base object. This is useful for recovering\nfrom an error condition when writeback semantics are used, but will lead to\nwrong results.\n\nA special variable-type which can take on different values to indicate the\nsorting algorithm being used.\n\nUsed as an alias of `NPY_MERGESORT` and vica versa.\n\nDefined to be the number of sorts. It is fixed at three by the need for\nbackwards compatibility, and consequently `NPY_MERGESORT` and `NPY_STABLESORT`\nare aliased to each other and may refer to one of several stable sorting\nalgorithms depending on the data type.\n\nA special variable type indicating the number of \u201ckinds\u201d of scalars\ndistinguished in determining scalar-coercion rules. This variable can take on\nthe values:\n\nDefined to be the number of scalar kinds (not including `NPY_NOSCALAR`).\n\nAn enumeration type indicating the element order that an array should be\ninterpreted in. When a brand new array is created, generally only NPY_CORDER\nand NPY_FORTRANORDER are used, whereas when one or more inputs are provided,\nthe order can be based on them.\n\nFortran order if all the inputs are Fortran, C otherwise.\n\nC order.\n\nFortran order.\n\nAn order as close to the order of the inputs as possible, even if the input is\nin neither C nor Fortran order.\n\nA variable type indicating the kind of clipping that should be applied in\ncertain functions.\n\nThe default for most operations, raises an exception if an index is out of\nbounds.\n\nClips an index to the valid range if it is out of bounds.\n\nWraps an index to the valid range if it is out of bounds.\n\nA variable type indicating whether the index returned should be that of the\nfirst suitable location (if `NPY_SEARCHLEFT`) or of the last (if\n`NPY_SEARCHRIGHT`).\n\nA variable type indicating the selection algorithm being used.\n\nNew in version 1.6.\n\nAn enumeration type indicating how permissive data conversions should be. This\nis used by the iterator added in NumPy 1.6, and is intended to be used more\nbroadly in a future version.\n\nOnly allow identical types.\n\nAllow identical and casts involving byte swapping.\n\nOnly allow casts which will not cause values to be rounded, truncated, or\notherwise changed.\n\nAllow any safe casts, and casts between types of the same kind. For example,\nfloat64 -> float32 is permitted with this rule.\n\nAllow any cast, no matter what kind of data loss may occur.\n\n"}, {"name": "int PyArray_ObjectType()", "path": "reference/c-api/array#c.PyArray_ObjectType", "type": "Array API", "text": "\nThis function is superseded by `PyArray_MinScalarType` and/or\n`PyArray_ResultType`.\n\nThis function is useful for determining a common type that two or more arrays\ncan be converted to. It only works for non-flexible array types as no itemsize\ninformation is passed. The mintype argument represents the minimum type\nacceptable, and op represents the object that will be converted to an array.\nThe return value is the enumerated typenumber that represents the data-type\nthat op should have.\n\n"}, {"name": "int PyArray_OrderConverter()", "path": "reference/c-api/array#c.PyArray_OrderConverter", "type": "Array API", "text": "\nConvert the Python strings \u2018C\u2019, \u2018F\u2019, \u2018A\u2019, and \u2018K\u2019 into the `NPY_ORDER`\nenumeration `NPY_CORDER`, `NPY_FORTRANORDER`, `NPY_ANYORDER`, and\n`NPY_KEEPORDER`.\n\n"}, {"name": "int PyArray_OutputConverter()", "path": "reference/c-api/array#c.PyArray_OutputConverter", "type": "Array API", "text": "\nThis is a default converter for output arrays given to functions. If obj is\n`Py_None` or `NULL`, then *address will be `NULL` but the call will succeed.\nIf `PyArray_Check` ( obj) is TRUE then it is returned in *address without\nincrementing its reference count.\n\n"}, {"name": "int PyArray_Partition()", "path": "reference/c-api/array#c.PyArray_Partition", "type": "Array API", "text": "\nEquivalent to `ndarray.partition` (self, ktharray, axis, kind). Partitions the\narray so that the values of the element indexed by ktharray are in the\npositions they would be if the array is fully sorted and places all elements\nsmaller than the kth before and all elements equal or greater after the kth\nelement. The ordering of all elements within the partitions is undefined. If\nself->descr is a data-type with fields defined, then self->descr->names is\nused to determine the sort order. A comparison where the first field is equal\nwill use the second field and so on. To alter the sort order of a structured\narray, create a new data-type with a different order of names and construct a\nview of the array with that new data-type. Returns zero on success and -1 on\nfailure.\n\n"}, {"name": "int PyArray_RegisterCanCast()", "path": "reference/c-api/array#c.PyArray_RegisterCanCast", "type": "Array API", "text": "\nRegister the data-type number, totype, as castable from data-type object,\ndescr, of the given scalar kind. Use scalar = `NPY_NOSCALAR` to register that\nan array of data-type descr can be cast safely to a data-type whose\ntype_number is totype. The return value is 0 on success or -1 on failure.\n\n"}, {"name": "int PyArray_RegisterCastFunc()", "path": "reference/c-api/array#c.PyArray_RegisterCastFunc", "type": "Array API", "text": "\nRegister a low-level casting function, castfunc, to convert from the data-\ntype, descr, to the given data-type number, totype. Any old casting function\nis over-written. A `0` is returned on success or a `-1` on failure.\n\n"}, {"name": "int PyArray_RegisterDataType()", "path": "reference/c-api/array#c.PyArray_RegisterDataType", "type": "Array API", "text": "\nRegister a data-type as a new user-defined data type for arrays. The type must\nhave most of its entries filled in. This is not always checked and errors can\nproduce segfaults. In particular, the typeobj member of the `dtype` structure\nmust be filled with a Python type that has a fixed-size element-size that\ncorresponds to the elsize member of dtype. Also the `f` member must have the\nrequired functions: nonzero, copyswap, copyswapn, getitem, setitem, and cast\n(some of the cast functions may be `NULL` if no support is desired). To avoid\nconfusion, you should choose a unique character typecode but this is not\nenforced and not relied on internally.\n\nA user-defined type number is returned that uniquely identifies the type. A\npointer to the new structure can then be obtained from `PyArray_DescrFromType`\nusing the returned type number. A -1 is returned if an error occurs. If this\ndtype has already been registered (checked only by the address of the\npointer), then return the previously-assigned type-number.\n\n"}, {"name": "int PyArray_RemoveSmallest()", "path": "reference/c-api/array#c.PyArray_RemoveSmallest", "type": "Array API", "text": "\nThis function takes a multi-iterator object that has been previously\n\u201cbroadcasted,\u201d finds the dimension with the smallest \u201csum of strides\u201d in the\nbroadcasted result and adapts all the iterators so as not to iterate over that\ndimension (by effectively making them of length-1 in that dimension). The\ncorresponding dimension is returned unless mit ->nd is 0, then -1 is returned.\nThis function is useful for constructing ufunc-like routines that broadcast\ntheir inputs correctly and then call a strided 1-d version of the routine as\nthe inner-loop. This 1-d version is usually optimized for speed and for this\nreason the loop should be performed over the axis that won\u2019t require large\nstride jumps.\n\n"}, {"name": "int PyArray_ResolveWritebackIfCopy()", "path": "reference/c-api/array#c.PyArray_ResolveWritebackIfCopy", "type": "Array API", "text": "\nIf `obj.flags` has `NPY_ARRAY_WRITEBACKIFCOPY` or (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY`, this function clears the flags, `DECREF` s\n`obj->base` and makes it writeable, and sets `obj->base` to NULL. It then\ncopies `obj->data` to `obj->base->data`, and returns the error state of the\ncopy operation. This is the opposite of `PyArray_SetWritebackIfCopyBase`.\nUsually this is called once you are finished with `obj`, just before\n`Py_DECREF(obj)`. It may be called multiple times, or with `NULL` input. See\nalso `PyArray_DiscardWritebackIfCopy`.\n\nReturns 0 if nothing was done, -1 on error, and 1 if action was taken.\n\n"}, {"name": "int PyArray_SearchsideConverter()", "path": "reference/c-api/array#c.PyArray_SearchsideConverter", "type": "Array API", "text": "\nConvert Python strings into one of `NPY_SEARCHLEFT` (starts with \u2018l\u2019 or \u2018L\u2019),\nor `NPY_SEARCHRIGHT` (starts with \u2018r\u2019 or \u2018R\u2019).\n\n"}, {"name": "int PyArray_SetBaseObject()", "path": "reference/c-api/array#c.PyArray_SetBaseObject", "type": "Array API", "text": "\nNew in version 1.7.\n\nThis function steals a reference to `obj` and sets it as the base property of\n`arr`.\n\nIf you construct an array by passing in your own memory buffer as a parameter,\nyou need to set the array\u2019s `base` property to ensure the lifetime of the\nmemory buffer is appropriate.\n\nThe return value is 0 on success, -1 on failure.\n\nIf the object provided is an array, this function traverses the chain of\n`base` pointers so that each array points to the owner of the memory directly.\nOnce the base is set, it may not be changed to another value.\n\n"}, {"name": "int PyArray_SetField()", "path": "reference/c-api/array#c.PyArray_SetField", "type": "Array API", "text": "\nEquivalent to `ndarray.setfield` (self, val, dtype, offset ). Set the field\nstarting at offset in bytes and of the given dtype to val. The offset plus\ndtype ->elsize must be less than self ->descr->elsize or an error is raised.\nOtherwise, the val argument is converted to an array and copied into the field\npointed to. If necessary, the elements of val are repeated to fill the\ndestination array, But, the number of elements in the destination must be an\ninteger multiple of the number of elements in val.\n\n"}, {"name": "int PyArray_SETITEM()", "path": "reference/c-api/array#c.PyArray_SETITEM", "type": "Array API", "text": "\nConvert obj and place it in the ndarray, arr, at the place pointed to by\nitemptr. Return -1 if an error occurs or 0 on success.\n\n"}, {"name": "int PyArray_SetUpdateIfCopyBase()", "path": "reference/c-api/array#c.PyArray_SetUpdateIfCopyBase", "type": "Array API", "text": "\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Set the UPDATEIFCOPY flag and `arr->base` so that\nwhen `arr` is destructed, it will copy any changes back to `base`. DEPRECATED,\nuse `PyArray_SetWritebackIfCopyBase`.\n\nReturns 0 for success, -1 for failure.\n\n"}, {"name": "int PyArray_SetWritebackIfCopyBase()", "path": "reference/c-api/array#c.PyArray_SetWritebackIfCopyBase", "type": "Array API", "text": "\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Sets the `NPY_ARRAY_WRITEBACKIFCOPY` flag and\n`arr->base`, and set `base` to READONLY. Call `PyArray_ResolveWritebackIfCopy`\nbefore calling `Py_DECREF` in order copy any changes back to `base` and reset\nthe READONLY flag.\n\nReturns 0 for success, -1 for failure.\n\n"}, {"name": "int PyArray_SortkindConverter()", "path": "reference/c-api/array#c.PyArray_SortkindConverter", "type": "Array API", "text": "\nConvert Python strings into one of `NPY_QUICKSORT` (starts with \u2018q\u2019 or \u2018Q\u2019),\n`NPY_HEAPSORT` (starts with \u2018h\u2019 or \u2018H\u2019), `NPY_MERGESORT` (starts with \u2018m\u2019 or\n\u2018M\u2019) or `NPY_STABLESORT` (starts with \u2018t\u2019 or \u2018T\u2019). `NPY_MERGESORT` and\n`NPY_STABLESORT` are aliased to each other for backwards compatibility and may\nrefer to one of several stable sorting algorithms depending on the data type.\n\n"}, {"name": "int PyArray_TYPE()", "path": "reference/c-api/array#c.PyArray_TYPE", "type": "Array API", "text": "\nReturn the (builtin) typenumber for the elements of this array.\n\n"}, {"name": "int PyArray_TypeNumFromName()", "path": "reference/c-api/array#c.PyArray_TypeNumFromName", "type": "Array API", "text": "\nGiven a string return the type-number for the data-type with that string as\nthe type-object name. Returns `NPY_NOTYPE` without setting an error if no type\ncan be found. Only works for user-defined data-types.\n\n"}, {"name": "int PyArray_TypestrConvert()", "path": "reference/c-api/array#c.PyArray_TypestrConvert", "type": "Array API", "text": "\nConvert typestring characters (with itemsize) to basic enumerated data types.\nThe typestring character corresponding to signed and unsigned integers,\nfloating point numbers, and complex-floating point numbers are recognized and\nconverted. Other values of gentype are returned. This function can be used to\nconvert, for example, the string \u2018f4\u2019 to `NPY_FLOAT32`.\n\n"}, {"name": "int PyArray_ValidType()", "path": "reference/c-api/array#c.PyArray_ValidType", "type": "Array API", "text": "\nReturns `NPY_TRUE` if typenum represents a valid type-number (builtin or user-\ndefined or character code). Otherwise, this function returns `NPY_FALSE`.\n\n"}, {"name": "int PyArray_XDECREF()", "path": "reference/c-api/array#c.PyArray_XDECREF", "type": "Array API", "text": "\nUsed for an array, op, that contains any Python objects. It decrements the\nreference count of every object in the array according to the data-type of op.\nNormal return value is 0. A -1 is returned if an error occurs.\n\n"}, {"name": "int PyArrayIter_Check()", "path": "reference/c-api/array#c.PyArrayIter_Check", "type": "Array API", "text": "\nEvaluates true if op is an array iterator (or instance of a subclass of the\narray iterator type).\n\n"}, {"name": "int PyArrayNeighborhoodIter_Next()", "path": "reference/c-api/array#c.PyArrayNeighborhoodIter_Next", "type": "Array API", "text": "\nAfter this call, iter->dataptr points to the next point of the neighborhood.\nCalling this function after every point of the neighborhood has been visited\nis undefined.\n\n"}, {"name": "int PyArrayNeighborhoodIter_Reset()", "path": "reference/c-api/array#c.PyArrayNeighborhoodIter_Reset", "type": "Array API", "text": "\nReset the iterator position to the first point of the neighborhood. This\nshould be called whenever the iter argument given at\nPyArray_NeighborhoodIterObject is changed (see example)\n\n"}, {"name": "int PyDataType_FLAGCHK()", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.PyDataType_FLAGCHK", "type": "Python Types and C-Structures", "text": "\nReturn true if all the given flags are set for the data-type object.\n\n"}, {"name": "int PyDataType_HASFIELDS()", "path": "reference/c-api/array#c.PyDataType_HASFIELDS", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISBOOL()", "path": "reference/c-api/array#c.PyDataType_ISBOOL", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISCOMPLEX()", "path": "reference/c-api/array#c.PyDataType_ISCOMPLEX", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISEXTENDED()", "path": "reference/c-api/array#c.PyDataType_ISEXTENDED", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyDataType_ISFLEXIBLE", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISFLOAT()", "path": "reference/c-api/array#c.PyDataType_ISFLOAT", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISINTEGER()", "path": "reference/c-api/array#c.PyDataType_ISINTEGER", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISNUMBER()", "path": "reference/c-api/array#c.PyDataType_ISNUMBER", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISOBJECT()", "path": "reference/c-api/array#c.PyDataType_ISOBJECT", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISPYTHON()", "path": "reference/c-api/array#c.PyDataType_ISPYTHON", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISSIGNED()", "path": "reference/c-api/array#c.PyDataType_ISSIGNED", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISSTRING()", "path": "reference/c-api/array#c.PyDataType_ISSTRING", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISUNSIGNED()", "path": "reference/c-api/array#c.PyDataType_ISUNSIGNED", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISUNSIZED()", "path": "reference/c-api/array#c.PyDataType_ISUNSIZED", "type": "Array API", "text": "\nType has no size information attached, and can be resized. Should only be\ncalled on flexible dtypes. Types that are attached to an array will always be\nsized, hence the array form of this macro not existing.\n\nChanged in version 1.18.\n\nFor structured datatypes with no fields this function now returns False.\n\n"}, {"name": "int PyDataType_ISUSERDEF()", "path": "reference/c-api/array#c.PyDataType_ISUSERDEF", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_REFCHK()", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.PyDataType_REFCHK", "type": "Python Types and C-Structures", "text": "\nEquivalent to `PyDataType_FLAGCHK` (dtype, `NPY_ITEM_REFCOUNT`).\n\n"}, {"name": "int PyModule_AddIntConstant()", "path": "user/c-info.how-to-extend#c.PyModule_AddIntConstant", "type": "User Guide", "text": "\n\n"}, {"name": "int PyModule_AddObject()", "path": "user/c-info.how-to-extend", "type": "User Guide", "text": "\nWhile the ndarray object is designed to allow rapid computation in Python, it\nis also designed to be general-purpose and satisfy a wide- variety of\ncomputational needs. As a result, if absolute speed is essential, there is no\nreplacement for a well-crafted, compiled loop specific to your application and\nhardware. This is one of the reasons that numpy includes f2py so that an easy-\nto-use mechanisms for linking (simple) C/C++ and (arbitrary) Fortran code\ndirectly into Python are available. You are encouraged to use and improve this\nmechanism. The purpose of this section is not to document this tool but to\ndocument the more basic steps to writing an extension module that this tool\ndepends on.\n\nWhen an extension module is written, compiled, and installed to somewhere in\nthe Python path (sys.path), the code can then be imported into Python as if it\nwere a standard python file. It will contain objects and methods that have\nbeen defined and compiled in C code. The basic steps for doing this in Python\nare well-documented and you can find more information in the documentation for\nPython itself available online at www.python.org .\n\nIn addition to the Python C-API, there is a full and rich C-API for NumPy\nallowing sophisticated manipulations on a C-level. However, for most\napplications, only a few API calls will typically be used. For example, if you\nneed to just extract a pointer to memory along with some shape information to\npass to another calculation routine, then you will use very different calls\nthan if you are trying to create a new array-like type or add a new data type\nfor ndarrays. This chapter documents the API calls and macros that are most\ncommonly used.\n\nThere is exactly one function that must be defined in your C-code in order for\nPython to use it as an extension module. The function must be called\ninit{name} where {name} is the name of the module from Python. This function\nmust be declared so that it is visible to code outside of the routine. Besides\nadding the methods and constants you desire, this subroutine must also contain\ncalls like `import_array()` and/or `import_ufunc()` depending on which C-API\nis needed. Forgetting to place these commands will show itself as an ugly\nsegmentation fault (crash) as soon as any C-API subroutine is actually called.\nIt is actually possible to have multiple init{name} functions in a single file\nin which case multiple modules will be defined by that file. However, there\nare some tricks to get that to work correctly and it is not covered here.\n\nA minimal `init{name}` method looks like:\n\nThe mymethods must be an array (usually statically declared) of PyMethodDef\nstructures which contain method names, actual C-functions, a variable\nindicating whether the method uses keyword arguments or not, and docstrings.\nThese are explained in the next section. If you want to add constants to the\nmodule, then you store the returned value from Py_InitModule which is a module\nobject. The most general way to add items to the module is to get the module\ndictionary using PyModule_GetDict(module). With the module dictionary, you can\nadd whatever you like to the module manually. An easier way to add objects to\nthe module is to use one of three additional Python C-API calls that do not\nrequire a separate extraction of the module dictionary. These are documented\nin the Python documentation, but repeated here for convenience:\n\nAll three of these functions require the module object (the return value of\nPy_InitModule). The name is a string that labels the value in the module.\nDepending on which function is called, the value argument is either a general\nobject (`PyModule_AddObject` steals a reference to it), an integer constant,\nor a string constant.\n\nThe second argument passed in to the Py_InitModule function is a structure\nthat makes it easy to to define functions in the module. In the example given\nabove, the mymethods structure would have been defined earlier in the file\n(usually right before the init{name} subroutine) to:\n\nEach entry in the mymethods array is a `PyMethodDef` structure containing 1)\nthe Python name, 2) the C-function that implements the function, 3) flags\nindicating whether or not keywords are accepted for this function, and 4) The\ndocstring for the function. Any number of functions may be defined for a\nsingle module by adding more entries to this table. The last entry must be all\nNULL as shown to act as a sentinel. Python looks for this entry to know that\nall of the functions for the module have been defined.\n\nThe last thing that must be done to finish the extension module is to actually\nwrite the code that performs the desired functions. There are two kinds of\nfunctions: those that don\u2019t accept keyword arguments, and those that do.\n\nFunctions that don\u2019t accept keyword arguments should be written as:\n\nThe dummy argument is not used in this context and can be safely ignored. The\nargs argument contains all of the arguments passed in to the function as a\ntuple. You can do anything you want at this point, but usually the easiest way\nto manage the input arguments is to call `PyArg_ParseTuple` (args,\nformat_string, addresses_to_C_variables\u2026) or `PyArg_UnpackTuple` (tuple,\n\u201cname\u201d, min, max, \u2026). A good description of how to use the first function is\ncontained in the Python C-API reference manual under section 5.5 (Parsing\narguments and building values). You should pay particular attention to the\n\u201cO&\u201d format which uses converter functions to go between the Python object and\nthe C object. All of the other format functions can be (mostly) thought of as\nspecial cases of this general rule. There are several converter functions\ndefined in the NumPy C-API that may be of use. In particular, the\n`PyArray_DescrConverter` function is very useful to support arbitrary data-\ntype specification. This function transforms any valid data-type Python object\ninto a PyArray_Descr* object. Remember to pass in the address of the\nC-variables that should be filled in.\n\nThere are lots of examples of how to use `PyArg_ParseTuple` throughout the\nNumPy source code. The standard usage is like this:\n\nIt is important to keep in mind that you get a borrowed reference to the\nobject when using the \u201cO\u201d format string. However, the converter functions\nusually require some form of memory handling. In this example, if the\nconversion is successful, dtype will hold a new reference to a PyArray_Descr*\nobject, while input will hold a borrowed reference. Therefore, if this\nconversion were mixed with another conversion (say to an integer) and the\ndata-type conversion was successful but the integer conversion failed, then\nyou would need to release the reference count to the data-type object before\nreturning. A typical way to do this is to set dtype to `NULL` before calling\n`PyArg_ParseTuple` and then use `Py_XDECREF` on dtype before returning.\n\nAfter the input arguments are processed, the code that actually does the work\nis written (likely calling other functions as needed). The final step of the\nC-function is to return something. If an error is encountered then `NULL`\nshould be returned (making sure an error has actually been set). If nothing\nshould be returned then increment `Py_None` and return it. If a single object\nshould be returned then it is returned (ensuring that you own a reference to\nit first). If multiple objects should be returned then you need to return a\ntuple. The `Py_BuildValue` (format_string, c_variables\u2026) function makes it\neasy to build tuples of Python objects from C variables. Pay special attention\nto the difference between \u2018N\u2019 and \u2018O\u2019 in the format string or you can easily\ncreate memory leaks. The \u2018O\u2019 format string increments the reference count of\nthe PyObject* C-variable it corresponds to, while the \u2018N\u2019 format string steals\na reference to the corresponding PyObject* C-variable. You should use \u2018N\u2019 if\nyou have already created a reference for the object and just want to give that\nreference to the tuple. You should use \u2018O\u2019 if you only have a borrowed\nreference to an object and need to create one to provide for the tuple.\n\nThese functions are very similar to functions without keyword arguments. The\nonly difference is that the function signature is:\n\nThe kwds argument holds a Python dictionary whose keys are the names of the\nkeyword arguments and whose values are the corresponding keyword-argument\nvalues. This dictionary can be processed however you see fit. The easiest way\nto handle it, however, is to replace the `PyArg_ParseTuple` (args,\nformat_string, addresses\u2026) function with a call to\n`PyArg_ParseTupleAndKeywords` (args, kwds, format_string, char *kwlist[],\naddresses\u2026). The kwlist parameter to this function is a `NULL` -terminated\narray of strings providing the expected keyword arguments. There should be one\nstring for each entry in the format_string. Using this function will raise a\nTypeError if invalid keyword arguments are passed in.\n\nFor more help on this function please see section 1.8 (Keyword Parameters for\nExtension Functions) of the Extending and Embedding tutorial in the Python\ndocumentation.\n\nThe biggest difficulty when writing extension modules is reference counting.\nIt is an important reason for the popularity of f2py, weave, Cython, ctypes,\netc\u2026. If you mis-handle reference counts you can get problems from memory-\nleaks to segmentation faults. The only strategy I know of to handle reference\ncounts correctly is blood, sweat, and tears. First, you force it into your\nhead that every Python variable has a reference count. Then, you understand\nexactly what each function does to the reference count of your objects, so\nthat you can properly use DECREF and INCREF when you need them. Reference\ncounting can really test the amount of patience and diligence you have towards\nyour programming craft. Despite the grim depiction, most cases of reference\ncounting are quite straightforward with the most common difficulty being not\nusing DECREF on objects before exiting early from a routine due to some error.\nIn second place, is the common error of not owning the reference on an object\nthat is passed to a function or macro that is going to steal the reference (\ne.g. `PyTuple_SET_ITEM`, and most functions that take `PyArray_Descr`\nobjects).\n\nTypically you get a new reference to a variable when it is created or is the\nreturn value of some function (there are some prominent exceptions, however \u2014\nsuch as getting an item out of a tuple or a dictionary). When you own the\nreference, you are responsible to make sure that `Py_DECREF` (var) is called\nwhen the variable is no longer necessary (and no other function has \u201cstolen\u201d\nits reference). Also, if you are passing a Python object to a function that\nwill \u201csteal\u201d the reference, then you need to make sure you own it (or use\n`Py_INCREF` to get your own reference). You will also encounter the notion of\nborrowing a reference. A function that borrows a reference does not alter the\nreference count of the object and does not expect to \u201chold on \u201cto the\nreference. It\u2019s just going to use the object temporarily. When you use\n`PyArg_ParseTuple` or `PyArg_UnpackTuple` you receive a borrowed reference to\nthe objects in the tuple and should not alter their reference count inside\nyour function. With practice, you can learn to get reference counting right,\nbut it can be frustrating at first.\n\nOne common source of reference-count errors is the `Py_BuildValue` function.\nPay careful attention to the difference between the \u2018N\u2019 format character and\nthe \u2018O\u2019 format character. If you create a new object in your subroutine (such\nas an output array), and you are passing it back in a tuple of return values,\nthen you should most- likely use the \u2018N\u2019 format character in `Py_BuildValue`.\nThe \u2018O\u2019 character will increase the reference count by one. This will leave\nthe caller with two reference counts for a brand-new array. When the variable\nis deleted and the reference count decremented by one, there will still be\nthat extra reference count, and the array will never be deallocated. You will\nhave a reference-counting induced memory leak. Using the \u2018N\u2019 character will\navoid this situation as it will return to the caller an object (inside the\ntuple) with a single reference count.\n\nMost extension modules for NumPy will need to access the memory for an ndarray\nobject (or one of it\u2019s sub-classes). The easiest way to do this doesn\u2019t\nrequire you to know much about the internals of NumPy. The method is to\n\nEnsure you are dealing with a well-behaved array (aligned, in machine byte-\norder and single-segment) of the correct type and number of dimensions.\n\nEach of these sub-topics is covered in the following sub-sections.\n\nThe main routine for obtaining an array from any Python object that can be\nconverted to an array is `PyArray_FromAny`. This function is very flexible\nwith many input arguments. Several macros make it easier to use the basic\nfunction. `PyArray_FROM_OTF` is arguably the most useful of these macros for\nthe most common uses. It allows you to convert an arbitrary Python object to\nan array of a specific builtin data-type ( e.g. float), while specifying a\nparticular set of requirements ( e.g. contiguous, aligned, and writeable). The\nsyntax is\n\nReturn an ndarray from any Python object, obj, that can be converted to an\narray. The number of dimensions in the returned array is determined by the\nobject. The desired data-type of the returned array is provided in typenum\nwhich should be one of the enumerated types. The requirements for the returned\narray can be any combination of standard array flags. Each of these arguments\nis explained in more detail below. You receive a new reference to the array on\nsuccess. On failure, `NULL` is returned and an exception is set.\n\nThe object can be any Python object convertible to an ndarray. If the object\nis already (a subclass of) the ndarray that satisfies the requirements then a\nnew reference is returned. Otherwise, a new array is constructed. The contents\nof obj are copied to the new array unless the array interface is used so that\ndata does not have to be copied. Objects that can be converted to an array\ninclude: 1) any nested sequence object, 2) any object exposing the array\ninterface, 3) any object with an `__array__` method (which should return an\nndarray), and 4) any scalar object (becomes a zero-dimensional array). Sub-\nclasses of the ndarray that otherwise fit the requirements will be passed\nthrough. If you want to ensure a base-class ndarray, then use\n`NPY_ARRAY_ENSUREARRAY` in the requirements flag. A copy is made only if\nnecessary. If you want to guarantee a copy, then pass in\n`NPY_ARRAY_ENSURECOPY` to the requirements flag.\n\nOne of the enumerated types or `NPY_NOTYPE` if the data-type should be\ndetermined from the object itself. The C-based names can be used:\n\n`NPY_BOOL`, `NPY_BYTE`, `NPY_UBYTE`, `NPY_SHORT`, `NPY_USHORT`, `NPY_INT`,\n`NPY_UINT`, `NPY_LONG`, `NPY_ULONG`, `NPY_LONGLONG`, `NPY_ULONGLONG`,\n`NPY_DOUBLE`, `NPY_LONGDOUBLE`, `NPY_CFLOAT`, `NPY_CDOUBLE`,\n`NPY_CLONGDOUBLE`, `NPY_OBJECT`.\n\nAlternatively, the bit-width names can be used as supported on the platform.\nFor example:\n\n`NPY_INT8`, `NPY_INT16`, `NPY_INT32`, `NPY_INT64`, `NPY_UINT8`, `NPY_UINT16`,\n`NPY_UINT32`, `NPY_UINT64`, `NPY_FLOAT32`, `NPY_FLOAT64`, `NPY_COMPLEX64`,\n`NPY_COMPLEX128`.\n\nThe object will be converted to the desired type only if it can be done\nwithout losing precision. Otherwise `NULL` will be returned and an error\nraised. Use `NPY_ARRAY_FORCECAST` in the requirements flag to override this\nbehavior.\n\nThe memory model for an ndarray admits arbitrary strides in each dimension to\nadvance to the next element of the array. Often, however, you need to\ninterface with code that expects a C-contiguous or a Fortran-contiguous memory\nlayout. In addition, an ndarray can be misaligned (the address of an element\nis not at an integral multiple of the size of the element) which can cause\nyour program to crash (or at least work more slowly) if you try and\ndereference a pointer into the array data. Both of these problems can be\nsolved by converting the Python object into an array that is more \u201cwell-\nbehaved\u201d for your specific usage.\n\nThe requirements flag allows specification of what kind of array is\nacceptable. If the object passed in does not satisfy this requirements then a\ncopy is made so that the returned object will satisfy the requirements. these\nndarray can use a very generic pointer to memory. This flag allows\nspecification of the desired properties of the returned array object. All of\nthe flags are explained in the detailed API chapter. The flags most commonly\nneeded are `NPY_ARRAY_IN_ARRAY`, `NPY_OUT_ARRAY`, and `NPY_ARRAY_INOUT_ARRAY`:\n\nThis flag is useful for arrays that must be in C-contiguous order and aligned.\nThese kinds of arrays are usually input arrays for some algorithm.\n\nThis flag is useful to specify an array that is in C-contiguous order, is\naligned, and can be written to as well. Such an array is usually returned as\noutput (although normally such output arrays are created from scratch).\n\nThis flag is useful to specify an array that will be used for both input and\noutput. `PyArray_ResolveWritebackIfCopy` must be called before `Py_DECREF` at\nthe end of the interface routine to write back the temporary data into the\noriginal array passed in. Use of the `NPY_ARRAY_WRITEBACKIFCOPY` or\n`NPY_ARRAY_UPDATEIFCOPY` flags requires that the input object is already an\narray (because other objects cannot be automatically updated in this fashion).\nIf an error occurs use `PyArray_DiscardWritebackIfCopy` (obj) on an array with\nthese flags set. This will set the underlying base array writable without\ncausing the contents to be copied back into the original array.\n\nOther useful flags that can be OR\u2019d as additional requirements are:\n\nCast to the desired type, even if it can\u2019t be done without losing information.\n\nMake sure the resulting array is a copy of the original.\n\nMake sure the resulting object is an actual ndarray and not a sub- class.\n\nNote\n\nWhether or not an array is byte-swapped is determined by the data-type of the\narray. Native byte-order arrays are always requested by `PyArray_FROM_OTF` and\nso there is no need for a `NPY_ARRAY_NOTSWAPPED` flag in the requirements\nargument. There is also no way to get a byte-swapped array from this routine.\n\nQuite often, new arrays must be created from within extension-module code.\nPerhaps an output array is needed and you don\u2019t want the caller to have to\nsupply it. Perhaps only a temporary array is needed to hold an intermediate\ncalculation. Whatever the need there are simple ways to get an ndarray object\nof whatever data-type is needed. The most general function for doing this is\n`PyArray_NewFromDescr`. All array creation functions go through this heavily\nre-used code. Because of its flexibility, it can be somewhat confusing to use.\nAs a result, simpler forms exist that are easier to use. These forms are part\nof the `PyArray_SimpleNew` family of functions, which simplify the interface\nby providing default values for common use cases.\n\nIf obj is an ndarray (PyArrayObject*), then the data-area of the ndarray is\npointed to by the void* pointer `PyArray_DATA` (obj) or the char* pointer\n`PyArray_BYTES` (obj). Remember that (in general) this data-area may not be\naligned according to the data-type, it may represent byte-swapped data, and/or\nit may not be writeable. If the data area is aligned and in native byte-order,\nthen how to get at a specific element of the array is determined only by the\narray of npy_intp variables, `PyArray_STRIDES` (obj). In particular, this\nc-array of integers shows how many bytes must be added to the current element\npointer to get to the next element in each dimension. For arrays less than\n4-dimensions there are `PyArray_GETPTR{k}` (obj, \u2026) macros where {k} is the\ninteger 1, 2, 3, or 4 that make using the array strides easier. The arguments\n\u2026. represent {k} non- negative integer indices into the array. For example,\nsuppose `E` is a 3-dimensional ndarray. A (void*) pointer to the element\n`E[i,j,k]` is obtained as `PyArray_GETPTR3` (E, i, j, k).\n\nAs explained previously, C-style contiguous arrays and Fortran-style\ncontiguous arrays have particular striding patterns. Two array flags\n(`NPY_ARRAY_C_CONTIGUOUS` and `NPY_ARRAY_F_CONTIGUOUS`) indicate whether or\nnot the striding pattern of a particular array matches the C-style contiguous\nor Fortran-style contiguous or neither. Whether or not the striding pattern\nmatches a standard C or Fortran one can be tested Using\n`PyArray_IS_C_CONTIGUOUS` (obj) and `PyArray_ISFORTRAN` (obj) respectively.\nMost third-party libraries expect contiguous arrays. But, often it is not\ndifficult to support general-purpose striding. I encourage you to use the\nstriding information in your own code whenever possible, and reserve single-\nsegment requirements for wrapping third-party code. Using the striding\ninformation provided with the ndarray rather than requiring a contiguous\nstriding reduces copying that otherwise must be made.\n\nThe following example shows how you might write a wrapper that accepts two\ninput arguments (that will be converted to an array) and an output argument\n(that must be an array). The function returns None and updates the output\narray. Note the updated use of WRITEBACKIFCOPY semantics for NumPy v1.14 and\nabove\n\n"}, {"name": "int PyModule_AddStringConstant()", "path": "user/c-info.how-to-extend#c.PyModule_AddStringConstant", "type": "User Guide", "text": "\nAll three of these functions require the module object (the return value of\nPy_InitModule). The name is a string that labels the value in the module.\nDepending on which function is called, the value argument is either a general\nobject (`PyModule_AddObject` steals a reference to it), an integer constant,\nor a string constant.\n\n"}, {"name": "int PyTypeNum_ISBOOL()", "path": "reference/c-api/array#c.PyTypeNum_ISBOOL", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISCOMPLEX()", "path": "reference/c-api/array#c.PyTypeNum_ISCOMPLEX", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISEXTENDED()", "path": "reference/c-api/array#c.PyTypeNum_ISEXTENDED", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyTypeNum_ISFLEXIBLE", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISFLOAT()", "path": "reference/c-api/array#c.PyTypeNum_ISFLOAT", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISINTEGER()", "path": "reference/c-api/array#c.PyTypeNum_ISINTEGER", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISNUMBER()", "path": "reference/c-api/array#c.PyTypeNum_ISNUMBER", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISOBJECT()", "path": "reference/c-api/array#c.PyTypeNum_ISOBJECT", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISPYTHON()", "path": "reference/c-api/array#c.PyTypeNum_ISPYTHON", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISSIGNED()", "path": "reference/c-api/array#c.PyTypeNum_ISSIGNED", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISSTRING()", "path": "reference/c-api/array#c.PyTypeNum_ISSTRING", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISUSERDEF()", "path": "reference/c-api/array#c.PyTypeNum_ISUSERDEF", "type": "Array API", "text": "\n\n"}, {"name": "int PyUFunc_checkfperr()", "path": "reference/c-api/ufunc#c.PyUFunc_checkfperr", "type": "UFunc API", "text": "\nA simple interface to the IEEE error-flag checking support. The errmask\nargument is a mask of `UFUNC_MASK_{ERR}` bitmasks indicating which errors to\ncheck for (and how to check for them). The errobj must be a Python tuple with\ntwo elements: a string containing the name which will be used in any\ncommunication of error and either a callable Python object (call-back\nfunction) or `Py_None`. The callable object will only be used if\n`UFUNC_ERR_CALL` is set as the desired error checking method. This routine\nmanages the GIL and is safe to call even after releasing the GIL. If an error\nin the IEEE-compatible hardware is determined a -1 is returned, otherwise a 0\nis returned.\n\n"}, {"name": "int PyUFunc_RegisterLoopForDescr()", "path": "reference/c-api/ufunc#c.PyUFunc_RegisterLoopForDescr", "type": "UFunc API", "text": "\nThis function behaves like PyUFunc_RegisterLoopForType above, except that it\nallows the user to register a 1-d loop using PyArray_Descr objects instead of\ndtype type num values. This allows a 1-d loop to be registered for structured\narray data-dtypes and custom data-types instead of scalar data-types.\n\n"}, {"name": "int PyUFunc_RegisterLoopForType()", "path": "reference/c-api/ufunc#c.PyUFunc_RegisterLoopForType", "type": "UFunc API", "text": "\nThis function allows the user to register a 1-d loop with an already- created\nufunc to be used whenever the ufunc is called with any of its input arguments\nas the user-defined data-type. This is needed in order to make ufuncs work\nwith built-in data-types. The data-type must have been previously registered\nwith the numpy system. The loop is passed in as function. This loop can take\narbitrary data which should be passed in as data. The data-types the loop\nrequires are passed in as arg_types which must be a pointer to memory at least\nas large as ufunc->nargs.\n\n"}, {"name": "int PyUFunc_ReplaceLoopBySignature()", "path": "reference/c-api/ufunc#c.PyUFunc_ReplaceLoopBySignature", "type": "UFunc API", "text": "\nReplace a 1-d loop matching the given signature in the already-created ufunc\nwith the new 1-d loop newfunc. Return the old 1-d loop function in oldfunc.\nReturn 0 on success and -1 on failure. This function works only with built-in\ntypes (use `PyUFunc_RegisterLoopForType` for user-defined types). A signature\nis an array of data-type numbers indicating the inputs followed by the outputs\nassumed by the 1-d loop.\n\n"}, {"name": "int random_multivariate_hypergeometric_count()", "path": "reference/random/c-api#c.random_multivariate_hypergeometric_count", "type": "C API for random", "text": "\n\n"}, {"name": "int reserved1", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.reserved1", "type": "Python Types and C-Structures", "text": "\nUnused.\n\n"}, {"name": "int scanfunc()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.scanfunc", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that scans (scanf style) one element of the\ncorresponding type from the file descriptor `fd` into the array memory pointed\nto by `ip`. The array is assumed to be behaved. The last argument `arr` is the\narray to be scanned into. Returns number of receiving arguments successfully\nassigned (which may be zero in case a matching failure occurred before the\nfirst receiving argument was assigned), or EOF if input failure occurs before\nthe first receiving argument was assigned. This function should be called\nwithout holding the Python GIL, and has to grab it for error reporting.\n\n"}, {"name": "int setitem()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.setitem", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that sets the Python object item into the array, arr,\nat the position pointed to by data . This function deals with \u201cmisbehaved\u201d\narrays. If successful, a zero is returned, otherwise, a negative one is\nreturned (and a Python error set).\n\n"}, {"name": "int sort()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.sort", "type": "Python Types and C-Structures", "text": "\nAn array of function pointers to a particular sorting algorithms. A particular\nsorting algorithm is obtained using a key (so far `NPY_QUICKSORT`,\n`NPY_HEAPSORT`, and `NPY_MERGESORT` are defined). These sorts are done in-\nplace assuming contiguous and aligned data.\n\n"}, {"name": "Internal organization of NumPy arrays", "path": "dev/internals", "type": "Development", "text": "\nIt helps to understand a bit about how NumPy arrays are handled under the\ncovers to help understand NumPy better. This section will not go into great\ndetail. Those wishing to understand the full details are requested to refer to\nTravis Oliphant\u2019s book Guide to NumPy.\n\nNumPy arrays consist of two major components: the raw array data (from now on,\nreferred to as the data buffer), and the information about the raw array data.\nThe data buffer is typically what people think of as arrays in C or Fortran, a\ncontiguous (and fixed) block of memory containing fixed-sized data items.\nNumPy also contains a significant set of data that describes how to interpret\nthe data in the data buffer. This extra information contains (among other\nthings):\n\nThis arrangement allows for the very flexible use of arrays. One thing that it\nallows is simple changes to the metadata to change the interpretation of the\narray buffer. Changing the byteorder of the array is a simple change involving\nno rearrangement of the data. The shape of the array can be changed very\neasily without changing anything in the data buffer or any data copying at\nall.\n\nAmong other things that are made possible is one can create a new array\nmetadata object that uses the same data buffer to create a new view of that\ndata buffer that has a different interpretation of the buffer (e.g., different\nshape, offset, byte order, strides, etc) but shares the same data bytes. Many\noperations in NumPy do just this such as slicing. Other operations, such as\ntranspose, don\u2019t move data elements around in the array, but rather change the\ninformation about the shape and strides so that the indexing of the array\nchanges, but the data in the doesn\u2019t move.\n\nTypically these new versions of the array metadata but the same data buffer\nare new views into the data buffer. There is a different `ndarray` object, but\nit uses the same data buffer. This is why it is necessary to force copies\nthrough the use of the `copy` method if one really wants to make a new and\nindependent copy of the data buffer.\n\nNew views into arrays mean the object reference counts for the data buffer\nincrease. Simply doing away with the original array object will not remove the\ndata buffer if other views of it still exist.\n\nSee also\n\nIndexing on ndarrays\n\nWhat is the right way to index multi-dimensional arrays? Before you jump to\nconclusions about the one and true way to index multi-dimensional arrays, it\npays to understand why this is a confusing issue. This section will try to\nexplain in detail how NumPy indexing works and why we adopt the convention we\ndo for images, and when it may be appropriate to adopt other conventions.\n\nThe first thing to understand is that there are two conflicting conventions\nfor indexing 2-dimensional arrays. Matrix notation uses the first index to\nindicate which row is being selected and the second index to indicate which\ncolumn is selected. This is opposite the geometrically oriented-convention for\nimages where people generally think the first index represents x position\n(i.e., column) and the second represents y position (i.e., row). This alone is\nthe source of much confusion; matrix-oriented users and image-oriented users\nexpect two different things with regard to indexing.\n\nThe second issue to understand is how indices correspond to the order in which\nthe array is stored in memory. In Fortran, the first index is the most rapidly\nvarying index when moving through the elements of a two-dimensional array as\nit is stored in memory. If you adopt the matrix convention for indexing, then\nthis means the matrix is stored one column at a time (since the first index\nmoves to the next row as it changes). Thus Fortran is considered a Column-\nmajor language. C has just the opposite convention. In C, the last index\nchanges most rapidly as one moves through the array as stored in memory. Thus\nC is a Row-major language. The matrix is stored by rows. Note that in both\ncases it presumes that the matrix convention for indexing is being used, i.e.,\nfor both Fortran and C, the first index is the row. Note this convention\nimplies that the indexing convention is invariant and that the data order\nchanges to keep that so.\n\nBut that\u2019s not the only way to look at it. Suppose one has large two-\ndimensional arrays (images or matrices) stored in data files. Suppose the data\nare stored by rows rather than by columns. If we are to preserve our index\nconvention (whether matrix or image) that means that depending on the language\nwe use, we may be forced to reorder the data if it is read into memory to\npreserve our indexing convention. For example, if we read row-ordered data\ninto memory without reordering, it will match the matrix indexing convention\nfor C, but not for Fortran. Conversely, it will match the image indexing\nconvention for Fortran, but not for C. For C, if one is using data stored in\nrow order, and one wants to preserve the image index convention, the data must\nbe reordered when reading into memory.\n\nIn the end, what you do for Fortran or C depends on which is more important,\nnot reordering data or preserving the indexing convention. For large images,\nreordering data is potentially expensive, and often the indexing convention is\ninverted to avoid that.\n\nThe situation with NumPy makes this issue yet more complicated. The internal\nmachinery of NumPy arrays is flexible enough to accept any ordering of\nindices. One can simply reorder indices by manipulating the internal stride\ninformation for arrays without reordering the data at all. NumPy will know how\nto map the new index order to the data without moving the data.\n\nSo if this is true, why not choose the index order that matches what you most\nexpect? In particular, why not define row-ordered images to use the image\nconvention? (This is sometimes referred to as the Fortran convention vs the C\nconvention, thus the \u2018C\u2019 and \u2018FORTRAN\u2019 order options for array ordering in\nNumPy.) The drawback of doing this is potential performance penalties. It\u2019s\ncommon to access the data sequentially, either implicitly in array operations\nor explicitly by looping over rows of an image. When that is done, then the\ndata will be accessed in non-optimal order. As the first index is incremented,\nwhat is actually happening is that elements spaced far apart in memory are\nbeing sequentially accessed, with usually poor memory access speeds. For\nexample, for a two-dimensional image `im` defined so that `im[0, 10]`\nrepresents the value at `x = 0`, `y = 10`. To be consistent with usual Python\nbehavior then `im[0]` would represent a column at `x = 0`. Yet that data would\nbe spread over the whole array since the data are stored in row order. Despite\nthe flexibility of NumPy\u2019s indexing, it can\u2019t really paper over the fact basic\noperations are rendered inefficient because of data order or that getting\ncontiguous subarrays is still awkward (e.g., `im[:, 0]` for the first row, vs\n`im[0]`). Thus one can\u2019t use an idiom such as for row in `im`; for col in `im`\ndoes work, but doesn\u2019t yield contiguous column data.\n\nAs it turns out, NumPy is smart enough when dealing with ufuncs to determine\nwhich index is the most rapidly varying one in memory and uses that for the\ninnermost loop. Thus for ufuncs, there is no large intrinsic advantage to\neither approach in most cases. On the other hand, use of `ndarray.flat` with a\nFORTRAN ordered array will lead to non-optimal memory access as adjacent\nelements in the flattened array (iterator, actually) are not contiguous in\nmemory.\n\nIndeed, the fact is that Python indexing on lists and other sequences\nnaturally leads to an outside-to-inside ordering (the first index gets the\nlargest grouping, the next largest, and the last gets the smallest element).\nSince image data are normally stored in rows, this corresponds to the position\nwithin rows being the last item indexed.\n\nIf you do want to use Fortran ordering realize that there are two approaches\nto consider: 1) accept that the first index is just not the most rapidly\nchanging in memory and have all your I/O routines reorder your data when going\nfrom memory to disk or visa versa, or use NumPy\u2019s mechanism for mapping the\nfirst index to the most rapidly varying data. We recommend the former if\npossible. The disadvantage of the latter is that many of NumPy\u2019s functions\nwill yield arrays without Fortran ordering unless you are careful to use the\n`order` keyword. Doing this would be highly inconvenient.\n\nOtherwise, we recommend simply learning to reverse the usual order of indices\nwhen accessing elements of an array. Granted, it goes against the grain, but\nit is more in line with Python semantics and the natural order of the data.\n\n"}, {"name": "Is the intended behavior clear under all conditions? Some things to watch:", "path": "dev/reviewer_guidelines", "type": "Development", "text": "\nReviewing open pull requests (PRs) helps move the project forward. We\nencourage people outside the project to get involved as well; it\u2019s a great way\nto get familiar with the codebase.\n\nReviews can come from outside the NumPy team \u2013 we welcome contributions from\ndomain experts (for instance, `linalg` or `fft`) or maintainers of other\nprojects. You do not need to be a NumPy maintainer (a NumPy team member with\npermission to merge a PR) to review.\n\nIf we do not know you yet, consider introducing yourself in the mailing list\nor Slack before you start reviewing pull requests.\n\nWhen reviewing pull requests, please use workflow tracking features on GitHub\nas appropriate:\n\nIt may be helpful to have a copy of the pull request code checked out on your\nown machine so that you can play with it locally. You can use the GitHub CLI\nto do this by clicking the `Open with` button in the upper right-hand corner\nof the PR page.\n\nAssuming you have your development environment set up, you can now build the\ncode and test it.\n\nIt may be helpful to store some of these in GitHub\u2019s saved replies for\nreviewing:\n\n"}, {"name": "is_array()", "path": "reference/swig.interface-file", "type": "numpy.i: a SWIG Interface File for NumPy", "text": "\nThe Simple Wrapper and Interface Generator (or SWIG) is a powerful tool for\ngenerating wrapper code for interfacing to a wide variety of scripting\nlanguages. SWIG can parse header files, and using only the code prototypes,\ncreate an interface to the target language. But SWIG is not omnipotent. For\nexample, it cannot know from the prototype:\n\nwhat exactly `seq` is. Is it a single value to be altered in-place? Is it an\narray, and if so what is its length? Is it input-only? Output-only? Input-\noutput? SWIG cannot determine these details, and does not attempt to do so.\n\nIf we designed `rms`, we probably made it a routine that takes an input-only\narray of length `n` of `double` values called `seq` and returns the root mean\nsquare. The default behavior of SWIG, however, will be to create a wrapper\nfunction that compiles, but is nearly impossible to use from the scripting\nlanguage in the way the C routine was intended.\n\nFor Python, the preferred way of handling contiguous (or technically, strided)\nblocks of homogeneous data is with NumPy, which provides full object-oriented\naccess to multidimensial arrays of data. Therefore, the most logical Python\ninterface for the `rms` function would be (including doc string):\n\nwhere `seq` would be a NumPy array of `double` values, and its length `n`\nwould be extracted from `seq` internally before being passed to the C routine.\nEven better, since NumPy supports construction of arrays from arbitrary Python\nsequences, `seq` itself could be a nearly arbitrary sequence (so long as each\nelement can be converted to a `double`) and the wrapper code would internally\nconvert it to a NumPy array before extracting its data and length.\n\nSWIG allows these types of conversions to be defined via a mechanism called\ntypemaps. This document provides information on how to use `numpy.i`, a SWIG\ninterface file that defines a series of typemaps intended to make the type of\narray-related conversions described above relatively simple to implement. For\nexample, suppose that the `rms` function prototype defined above was in a\nheader file named `rms.h`. To obtain the Python interface discussed above,\nyour SWIG interface file would need the following:\n\nTypemaps are keyed off a list of one or more function arguments, either by\ntype or by type and name. We will refer to such lists as signatures. One of\nthe many typemaps defined by `numpy.i` is used above and has the signature\n`(double* IN_ARRAY1, int DIM1)`. The argument names are intended to suggest\nthat the `double*` argument is an input array of one dimension and that the\n`int` represents the size of that dimension. This is precisely the pattern in\nthe `rms` prototype.\n\nMost likely, no actual prototypes to be wrapped will have the argument names\n`IN_ARRAY1` and `DIM1`. We use the SWIG `%apply` directive to apply the\ntypemap for one-dimensional input arrays of type `double` to the actual\nprototype used by `rms`. Using `numpy.i` effectively, therefore, requires\nknowing what typemaps are available and what they do.\n\nA SWIG interface file that includes the SWIG directives given above will\nproduce wrapper code that looks something like:\n\nThe typemaps from `numpy.i` are responsible for the following lines of code:\n12\u201320, 25 and 30. Line 10 parses the input to the `rms` function. From the\nformat string `\"O:rms\"`, we can see that the argument list is expected to be a\nsingle Python object (specified by the `O` before the colon) and whose pointer\nis stored in `obj0`. A number of functions, supplied by `numpy.i`, are called\nto make and check the (possible) conversion from a generic Python object to a\nNumPy array. These functions are explained in the section Helper Functions,\nbut hopefully their names are self-explanatory. At line 12 we use `obj0` to\nconstruct a NumPy array. At line 17, we check the validity of the result: that\nit is non-null and that it has a single dimension of arbitrary length. Once\nthese states are verified, we extract the data buffer and length in lines 19\nand 20 so that we can call the underlying C function at line 22. Line 25\nperforms memory management for the case where we have created a new array that\nis no longer needed.\n\nThis code has a significant amount of error handling. Note the `SWIG_fail` is\na macro for `goto fail`, referring to the label at line 28. If the user\nprovides the wrong number of arguments, this will be caught at line 10. If\nconstruction of the NumPy array fails or produces an array with the wrong\nnumber of dimensions, these errors are caught at line 17. And finally, if an\nerror is detected, memory is still managed correctly at line 30.\n\nNote that if the C function signature was in a different order:\n\nthat SWIG would not match the typemap signature given above with the argument\nlist for `rms`. Fortunately, `numpy.i` has a set of typemaps with the data\npointer given last:\n\nThis simply has the effect of switching the definitions of `arg1` and `arg2`\nin lines 3 and 4 of the generated code above, and their assignments in lines\n19 and 20.\n\nThe `numpy.i` file is currently located in the `tools/swig` sub-directory\nunder the `numpy` installation directory. Typically, you will want to copy it\nto the directory where you are developing your wrappers.\n\nA simple module that only uses a single SWIG interface file should include the\nfollowing:\n\nWithin a compiled Python module, `import_array()` should only get called once.\nThis could be in a C/C++ file that you have written and is linked to the\nmodule. If this is the case, then none of your interface files should `#define\nSWIG_FILE_WITH_INIT` or call `import_array()`. Or, this initialization call\ncould be in a wrapper file generated by SWIG from an interface file that has\nthe `%init` block as above. If this is the case, and you have more than one\nSWIG interface file, then only one interface file should `#define\nSWIG_FILE_WITH_INIT` and call `import_array()`.\n\nThe typemap directives provided by `numpy.i` for arrays of different data\ntypes, say `double` and `int`, and dimensions of different types, say `int` or\n`long`, are identical to one another except for the C and NumPy type\nspecifications. The typemaps are therefore implemented (typically behind the\nscenes) via a macro:\n\nthat can be invoked for appropriate `(DATA_TYPE, DATA_TYPECODE, DIM_TYPE)`\ntriplets. For example:\n\nThe `numpy.i` interface file uses the `%numpy_typemaps` macro to implement\ntypemaps for the following C data types and `int` dimension types:\n\nIn the following descriptions, we reference a generic `DATA_TYPE`, which could\nbe any of the C data types listed above, and `DIM_TYPE` which should be one of\nthe many types of integers.\n\nThe typemap signatures are largely differentiated on the name given to the\nbuffer pointer. Names with `FARRAY` are for Fortran-ordered arrays, and names\nwith `ARRAY` are for C-ordered (or 1D arrays).\n\nInput arrays are defined as arrays of data that are passed into a routine but\nare not altered in-place or returned to the user. The Python input array is\ntherefore allowed to be almost any Python sequence (such as a list) that can\nbe converted to the requested type of array. The input array signatures are\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThe first signature listed, `( DATA_TYPE IN_ARRAY[ANY] )` is for one-\ndimensional arrays with hard-coded dimensions. Likewise, `( DATA_TYPE\nIN_ARRAY2[ANY][ANY] )` is for two-dimensional arrays with hard-coded\ndimensions, and similarly for three-dimensional.\n\nIn-place arrays are defined as arrays that are modified in-place. The input\nvalues may or may not be used, but the values at the time the function returns\nare significant. The provided Python argument must therefore be a NumPy array\nof the required type. The in-place signatures are\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThese typemaps now check to make sure that the `INPLACE_ARRAY` arguments use\nnative byte ordering. If not, an exception is raised.\n\nThere is also a \u201cflat\u201d in-place array for situations in which you would like\nto modify or process each element, regardless of the number of dimensions. One\nexample is a \u201cquantization\u201d function that quantizes each element of an array\nin-place, be it 1D, 2D or whatever. This form checks for continuity but allows\neither C or Fortran ordering.\n\nND:\n\nArgout arrays are arrays that appear in the input arguments in C, but are in\nfact output arrays. This pattern occurs often when there is more than one\noutput variable and the single return argument is therefore not sufficient. In\nPython, the conventional way to return multiple arguments is to pack them into\na sequence (tuple, list, etc.) and return the sequence. This is what the\nargout typemaps do. If a wrapped function that uses these argout typemaps has\nmore than one return argument, they are packed into a tuple or list, depending\non the version of Python. The Python user does not pass these arrays in, they\nsimply get returned. For the case where a dimension is specified, the python\nuser must provide that dimension as an argument. The argout signatures are\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThese are typically used in situations where in C/C++, you would allocate a(n)\narray(s) on the heap, and call the function to fill the array(s) values. In\nPython, the arrays are allocated for you and returned as new array objects.\n\nNote that we support `DATA_TYPE*` argout typemaps in 1D, but not 2D or 3D.\nThis is because of a quirk with the SWIG typemap syntax and cannot be avoided.\nNote that for these types of 1D typemaps, the Python function will take a\nsingle argument representing `DIM1`.\n\nArgoutview arrays are for when your C code provides you with a view of its\ninternal data and does not require any memory to be allocated by the user.\nThis can be dangerous. There is almost no way to guarantee that the internal\ndata from the C code will remain in existence for the entire lifetime of the\nNumPy array that encapsulates it. If the user destroys the object that\nprovides the view of the data before destroying the NumPy array, then using\nthat array may result in bad memory references or segmentation faults.\nNevertheless, there are situations, working with large data sets, where you\nsimply have no other choice.\n\nThe C code to be wrapped for argoutview arrays are characterized by pointers:\npointers to the dimensions and double pointers to the data, so that these\nvalues can be passed back to the user. The argoutview typemap signatures are\ntherefore\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nNote that arrays with hard-coded dimensions are not supported. These cannot\nfollow the double pointer signatures of these typemaps.\n\nA recent addition to `numpy.i` are typemaps that permit argout arrays with\nviews into memory that is managed. See the discussion here.\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThe `numpy.i` interface file does not support typemaps for output arrays, for\nseveral reasons. First, C/C++ return arguments are limited to a single value.\nThis prevents obtaining dimension information in a general way. Second, arrays\nwith hard-coded lengths are not permitted as return arguments. In other words:\n\nis not legal C/C++ syntax. Therefore, we cannot provide typemaps of the form:\n\nIf you run into a situation where a function or method is returning a pointer\nto an array, your best bet is to write your own version of the function to be\nwrapped, either with `%extend` for the case of class methods or `%ignore` and\n`%rename` for the case of functions.\n\nNote that C++ type `bool` is not supported in the list in the Available\nTypemaps section. NumPy bools are a single byte, while the C++ `bool` is four\nbytes (at least on my system). Therefore:\n\nwill result in typemaps that will produce code that reference improper data\nlengths. You can implement the following macro expansion:\n\nto fix the data length problem, and Input Arrays will work fine, but In-Place\nArrays might fail type-checking.\n\nTypemap conversions for complex floating-point types is also not supported\nautomatically. This is because Python and NumPy are written in C, which does\nnot have native complex types. Both Python and NumPy implement their own\n(essentially equivalent) `struct` definitions for complex variables:\n\nWe could have implemented:\n\nwhich would have provided automatic type conversions for arrays of type\n`Py_complex`, `npy_cfloat` and `npy_cdouble`. However, it seemed unlikely that\nthere would be any independent (non-Python, non-NumPy) application code that\npeople would be using SWIG to generate a Python interface to, that also used\nthese definitions for complex types. More likely, these application codes will\ndefine their own complex types, or in the case of C++, use `std::complex`.\nAssuming these data structures are compatible with Python and NumPy complex\ntypes, `%numpy_typemap` expansions as above (with the user\u2019s complex type\nsubstituted for the first argument) should work.\n\nSWIG has sophisticated type checking for numerical types. For example, if your\nC/C++ routine expects an integer as input, the code generated by SWIG will\ncheck for both Python integers and Python long integers, and raise an overflow\nerror if the provided Python integer is too big to cast down to a C integer.\nWith the introduction of NumPy scalar arrays into your Python code, you might\nconceivably extract an integer from a NumPy array and attempt to pass this to\na SWIG-wrapped C/C++ function that expects an `int`, but the SWIG type\nchecking will not recognize the NumPy array scalar as an integer. (Often, this\ndoes in fact work \u2013 it depends on whether NumPy recognizes the integer type\nyou are using as inheriting from the Python integer type on the platform you\nare using. Sometimes, this means that code that works on a 32-bit machine will\nfail on a 64-bit machine.)\n\nIf you get a Python error that looks like the following:\n\nand the argument you are passing is an integer extracted from a NumPy array,\nthen you have stumbled upon this problem. The solution is to modify the SWIG\ntype conversion system to accept NumPy array scalars in addition to the\nstandard integer types. Fortunately, this capability has been provided for\nyou. Simply copy the file:\n\nto the working build directory for you project, and this problem will be\nfixed. It is suggested that you do this anyway, as it only increases the\ncapabilities of your Python interface.\n\nThe SWIG type checking and conversion system is a complicated combination of C\nmacros, SWIG macros, SWIG typemaps and SWIG fragments. Fragments are a way to\nconditionally insert code into your wrapper file if it is needed, and not\ninsert it if not needed. If multiple typemaps require the same fragment, the\nfragment only gets inserted into your wrapper code once.\n\nThere is a fragment for converting a Python integer to a C `long`. There is a\ndifferent fragment that converts a Python integer to a C `int`, that calls the\nroutine defined in the `long` fragment. We can make the changes we want here\nby changing the definition for the `long` fragment. SWIG determines the active\ndefinition for a fragment using a \u201cfirst come, first served\u201d system. That is,\nwe need to define the fragment for `long` conversions prior to SWIG doing it\ninternally. SWIG allows us to do this by putting our fragment definitions in\nthe file `pyfragments.swg`. If we were to put the new fragment definitions in\n`numpy.i`, they would be ignored.\n\nThe `numpy.i` file contains several macros and routines that it uses\ninternally to build its typemaps. However, these functions may be useful\nelsewhere in your interface file. These macros and routines are implemented as\nfragments, which are described briefly in the previous section. If you try to\nuse one or more of the following macros or functions, but your compiler\ncomplains that it does not recognize the symbol, then you need to force these\nfragments to appear in your code using:\n\nin your SWIG interface file.\n\nEvaluates as true if `a` is non-`NULL` and can be cast to a `PyArrayObject*`.\n\nEvaluates to the integer data type code of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to the integer number of dimensions of `a`, assuming `a` can be cast\nto a `PyArrayObject*`.\n\nEvaluates to an array of type `npy_intp` and length `array_numdims(a)`, giving\nthe lengths of all of the dimensions of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to the `i`-th dimension size of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to an array of type `npy_intp` and length `array_numdims(a)`, giving\nthe stridess of all of the dimensions of `a`, assuming `a` can be cast to a\n`PyArrayObject*`. A stride is the distance in bytes between an element and its\nimmediate neighbor along the same axis.\n\nEvaluates to the `i`-th stride of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to a pointer of type `void*` that points to the data buffer of `a`,\nassuming `a` can be cast to a `PyArrayObject*`.\n\nReturns a borrowed reference to the dtype property (`PyArray_Descr*`) of `a`,\nassuming `a` can be cast to a `PyArrayObject*`.\n\nReturns an integer representing the flags of `a`, assuming `a` can be cast to\na `PyArrayObject*`.\n\nSets the flag represented by `f` of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates as true if `a` is a contiguous array. Equivalent to\n`(PyArray_ISCONTIGUOUS(a))`.\n\nEvaluates as true if the data buffer of `a` uses native byte order. Equivalent\nto `(PyArray_ISNOTSWAPPED(a))`.\n\nEvaluates as true if `a` is FORTRAN ordered.\n\npytype_string()\n\nReturn type: `const char*`\n\nArguments:\n\nReturn a string describing the type of `py_obj`.\n\ntypecode_string()\n\nReturn type: `const char*`\n\nArguments:\n\nReturn a string describing the type corresponding to the NumPy `typecode`.\n\ntype_match()\n\nReturn type: `int`\n\nArguments:\n\nMake sure that `actual_type` is compatible with `desired_type`. For example,\nthis allows character and byte types, or int and long types, to match. This is\nnow equivalent to `PyArray_EquivTypenums()`.\n\nobj_to_array_no_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nCast `input` to a `PyArrayObject*` if legal, and ensure that it is of type\n`typecode`. If `input` cannot be cast, or the `typecode` is wrong, set a\nPython error and return `NULL`.\n\nobj_to_array_allow_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nConvert `input` to a NumPy array with the given `typecode`. On success, return\na valid `PyArrayObject*` with the correct type. On failure, the Python error\nstring will be set and the routine returns `NULL`.\n\nmake_contiguous()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nCheck to see if `ary` is contiguous. If so, return the input pointer and flag\nit as not a new object. If it is not contiguous, create a new `PyArrayObject*`\nusing the original data, flag it as a new object and return the pointer.\n\nmake_fortran()\n\nReturn type: `PyArrayObject*`\n\nArguments\n\nCheck to see if `ary` is Fortran contiguous. If so, return the input pointer\nand flag it as not a new object. If it is not Fortran contiguous, create a new\n`PyArrayObject*` using the original data, flag it as a new object and return\nthe pointer.\n\nobj_to_array_contiguous_allow_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nConvert `input` to a contiguous `PyArrayObject*` of the specified type. If the\ninput object is not a contiguous `PyArrayObject*`, a new one will be created\nand the new object flag will be set.\n\nobj_to_array_fortran_allow_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nConvert `input` to a Fortran contiguous `PyArrayObject*` of the specified\ntype. If the input object is not a Fortran contiguous `PyArrayObject*`, a new\none will be created and the new object flag will be set.\n\nrequire_contiguous()\n\nReturn type: `int`\n\nArguments:\n\nTest whether `ary` is contiguous. If so, return 1. Otherwise, set a Python\nerror and return 0.\n\nrequire_native()\n\nReturn type: `int`\n\nArguments:\n\nRequire that `ary` is not byte-swapped. If the array is not byte-swapped,\nreturn 1. Otherwise, set a Python error and return 0.\n\nrequire_dimensions()\n\nReturn type: `int`\n\nArguments:\n\nRequire `ary` to have a specified number of dimensions. If the array has the\nspecified number of dimensions, return 1. Otherwise, set a Python error and\nreturn 0.\n\nrequire_dimensions_n()\n\nReturn type: `int`\n\nArguments:\n\nRequire `ary` to have one of a list of specified number of dimensions. If the\narray has one of the specified number of dimensions, return 1. Otherwise, set\nthe Python error string and return 0.\n\nrequire_size()\n\nReturn type: `int`\n\nArguments:\n\nRequire `ary` to have a specified shape. If the array has the specified shape,\nreturn 1. Otherwise, set the Python error string and return 0.\n\nrequire_fortran()\n\nReturn type: `int`\n\nArguments:\n\nRequire the given `PyArrayObject` to to be Fortran ordered. If the\n`PyArrayObject` is already Fortran ordered, do nothing. Else, set the Fortran\nordering flag and recompute the strides.\n\nThere are many C or C++ array/NumPy array situations not covered by a simple\n`%include \"numpy.i\"` and subsequent `%apply` directives.\n\nConsider a reasonable prototype for a dot product function:\n\nThe Python interface that we want is:\n\nThe problem here is that there is one dimension argument and two array\narguments, and our typemaps are set up for dimensions that apply to a single\narray (in fact, SWIG does not provide a mechanism for associating `len` with\n`vec2` that takes two Python input arguments). The recommended solution is the\nfollowing:\n\nIf the header file that contains the prototype for `double dot()` also\ncontains other prototypes that you want to wrap, so that you need to\n`%include` this header file, then you will also need a `%ignore dot;`\ndirective, placed after the `%rename` and before the `%include` directives.\nOr, if the function in question is a class method, you will want to use\n`%extend` rather than `%inline` in addition to `%ignore`.\n\nA note on error handling: Note that `my_dot` returns a `double` but that it\ncan also raise a Python error. The resulting wrapper function will return a\nPython float representation of 0.0 when the vector lengths do not match. Since\nthis is not `NULL`, the Python interpreter will not know to check for an\nerror. For this reason, we add the `%exception` directive above for `my_dot`\nto get the behavior we want (note that `$action` is a macro that gets expanded\nto a valid call to `my_dot`). In general, you will probably want to write a\nSWIG macro to perform this task.\n\nThere are other wrapping situations in which `numpy.i` may be helpful when you\nencounter them.\n\nIn some situations, it is possible that you could use the `%numpy_typemaps`\nmacro to implement typemaps for your own types. See the Other Common Types:\nbool or Other Common Types: complex sections for examples. Another situation\nis if your dimensions are of a type other than `int` (say `long` for example):\n\nWhen you use the `%apply` directive, as is usually necessary to use `numpy.i`,\nit will remain in effect until you tell SWIG that it shouldn\u2019t be. If the\narguments to the functions or methods that you are wrapping have common names,\nsuch as `length` or `vector`, these typemaps may get applied in situations you\ndo not expect or want. Therefore, it is always a good idea to add a `%clear`\ndirective after you are done with a specific typemap:\n\nIn general, you should target these typemap signatures specifically where you\nwant them, and then clear them after you are done.\n\nOut of the box, `numpy.i` provides typemaps that support conversion between\nNumPy arrays and C arrays:\n\nThat support 74 different argument signatures for each data type, including:\n\nThe `numpy.i` interface file also provides additional tools for wrapper\ndevelopers, including:\n\n"}, {"name": "Iterating Over Arrays", "path": "reference/arrays.nditer", "type": "Iterating Over Arrays", "text": "\nNote\n\nArrays support the iterator protocol and can be iterated over like Python\nlists. See the Indexing, Slicing and Iterating section in the Quickstart guide\nfor basic usage and examples. The remainder of this document presents the\n`nditer` object and covers more advanced usage.\n\nThe iterator object `nditer`, introduced in NumPy 1.6, provides many flexible\nways to visit all the elements of one or more arrays in a systematic fashion.\nThis page introduces some basic ways to use the object for computations on\narrays in Python, then concludes with how one can accelerate the inner loop in\nCython. Since the Python exposure of `nditer` is a relatively straightforward\nmapping of the C array iterator API, these ideas will also provide help\nworking with array iteration from C or C++.\n\nThe most basic task that can be done with the `nditer` is to visit every\nelement of an array. Each element is provided one by one using the standard\nPython iterator interface.\n\nAn important thing to be aware of for this iteration is that the order is\nchosen to match the memory layout of the array instead of using a standard C\nor Fortran ordering. This is done for access efficiency, reflecting the idea\nthat by default one simply wants to visit each element without concern for a\nparticular ordering. We can see this by iterating over the transpose of our\nprevious array, compared to taking a copy of that transpose in C order.\n\nThe elements of both `a` and `a.T` get traversed in the same order, namely the\norder they are stored in memory, whereas the elements of `a.T.copy(order=\u2019C\u2019)`\nget visited in a different order because they have been put into a different\nmemory layout.\n\nThere are times when it is important to visit the elements of an array in a\nspecific order, irrespective of the layout of the elements in memory. The\n`nditer` object provides an `order` parameter to control this aspect of\niteration. The default, having the behavior described above, is order=\u2019K\u2019 to\nkeep the existing order. This can be overridden with order=\u2019C\u2019 for C order and\norder=\u2019F\u2019 for Fortran order.\n\nBy default, the `nditer` treats the input operand as a read-only object. To be\nable to modify the array elements, you must specify either read-write or\nwrite-only mode using the `\u2018readwrite\u2019` or `\u2018writeonly\u2019` per-operand flags.\n\nThe nditer will then yield writeable buffer arrays which you may modify.\nHowever, because the nditer must copy this buffer data back to the original\narray once iteration is finished, you must signal when the iteration is ended,\nby one of two methods. You may either:\n\nThe nditer can no longer be iterated once either `close` is called or its\ncontext is exited.\n\nIf you are writing code that needs to support older versions of numpy, note\nthat prior to 1.15, `nditer` was not a context manager and did not have a\n`close` method. Instead it relied on the destructor to initiate the writeback\nof the buffer.\n\nIn all the examples so far, the elements of `a` are provided by the iterator\none at a time, because all the looping logic is internal to the iterator.\nWhile this is simple and convenient, it is not very efficient. A better\napproach is to move the one-dimensional innermost loop into your code,\nexternal to the iterator. This way, NumPy\u2019s vectorized operations can be used\non larger chunks of the elements being visited.\n\nThe `nditer` will try to provide chunks that are as large as possible to the\ninner loop. By forcing \u2018C\u2019 and \u2018F\u2019 order, we get different external loop\nsizes. This mode is enabled by specifying an iterator flag.\n\nObserve that with the default of keeping native memory order, the iterator is\nable to provide a single one-dimensional chunk, whereas when forcing Fortran\norder, it has to provide three chunks of two elements each.\n\nDuring iteration, you may want to use the index of the current element in a\ncomputation. For example, you may want to visit the elements of an array in\nmemory order, but use a C-order, Fortran-order, or multidimensional index to\nlook up values in a different array.\n\nThe index is tracked by the iterator object itself, and accessible through the\n`index` or `multi_index` properties, depending on what was requested. The\nexamples below show printouts demonstrating the progression of the index:\n\nTracking an index or multi-index is incompatible with using an external loop,\nbecause it requires a different index value per element. If you try to combine\nthese flags, the `nditer` object will raise an exception.\n\nTo make its properties more readily accessible during iteration, `nditer` has\nan alternative syntax for iterating, which works explicitly with the iterator\nobject itself. With this looping construct, the current value is accessible by\nindexing into the iterator. Other properties, such as tracked indices remain\nas before. The examples below produce identical results to the ones in the\nprevious section.\n\nWhen forcing an iteration order, we observed that the external loop option may\nprovide the elements in smaller chunks because the elements can\u2019t be visited\nin the appropriate order with a constant stride. When writing C code, this is\ngenerally fine, however in pure Python code this can cause a significant\nreduction in performance.\n\nBy enabling buffering mode, the chunks provided by the iterator to the inner\nloop can be made larger, significantly reducing the overhead of the Python\ninterpreter. In the example forcing Fortran iteration order, the inner loop\ngets to see all the elements in one go when buffering is enabled.\n\nThere are times when it is necessary to treat an array as a different data\ntype than it is stored as. For instance, one may want to do all computations\non 64-bit floats, even if the arrays being manipulated are 32-bit floats.\nExcept when writing low-level C code, it\u2019s generally better to let the\niterator handle the copying or buffering instead of casting the data type\nyourself in the inner loop.\n\nThere are two mechanisms which allow this to be done, temporary copies and\nbuffering mode. With temporary copies, a copy of the entire array is made with\nthe new data type, then iteration is done in the copy. Write access is\npermitted through a mode which updates the original array after all the\niteration is complete. The major drawback of temporary copies is that the\ntemporary copy may consume a large amount of memory, particularly if the\niteration data type has a larger itemsize than the original one.\n\nBuffering mode mitigates the memory usage issue and is more cache-friendly\nthan making temporary copies. Except for special cases, where the whole array\nis needed at once outside the iterator, buffering is recommended over\ntemporary copying. Within NumPy, buffering is used by the ufuncs and other\nfunctions to support flexible inputs with minimal memory overhead.\n\nIn our examples, we will treat the input array with a complex data type, so\nthat we can take square roots of negative numbers. Without enabling copies or\nbuffering mode, the iterator will raise an exception if the data type doesn\u2019t\nmatch precisely.\n\nIn copying mode, \u2018copy\u2019 is specified as a per-operand flag. This is done to\nprovide control in a per-operand fashion. Buffering mode is specified as an\niterator flag.\n\nThe iterator uses NumPy\u2019s casting rules to determine whether a specific\nconversion is permitted. By default, it enforces \u2018safe\u2019 casting. This means,\nfor example, that it will raise an exception if you try to treat a 64-bit\nfloat array as a 32-bit float array. In many cases, the rule \u2018same_kind\u2019 is\nthe most reasonable rule to use, since it will allow conversion from 64 to\n32-bit float, but not from float to int or from complex to float.\n\nOne thing to watch out for is conversions back to the original data type when\nusing a read-write or write-only operand. A common case is to implement the\ninner loop in terms of 64-bit floats, and use \u2018same_kind\u2019 casting to allow the\nother floating-point types to be processed as well. While in read-only mode,\nan integer array could be provided, read-write mode will raise an exception\nbecause conversion back to the array would violate the casting rule.\n\nNumPy has a set of rules for dealing with arrays that have differing shapes\nwhich are applied whenever functions take multiple operands which combine\nelement-wise. This is called broadcasting. The `nditer` object can apply these\nrules for you when you need to write such a function.\n\nAs an example, we print out the result of broadcasting a one and a two\ndimensional array together.\n\nWhen a broadcasting error occurs, the iterator raises an exception which\nincludes the input shapes to help diagnose the problem.\n\nA common case in NumPy functions is to have outputs allocated based on the\nbroadcasting of the input, and additionally have an optional parameter called\n\u2018out\u2019 where the result will be placed when it is provided. The `nditer` object\nprovides a convenient idiom that makes it very easy to support this mechanism.\n\nWe\u2019ll show how this works by creating a function `square` which squares its\ninput. Let\u2019s start with a minimal function definition excluding \u2018out\u2019\nparameter support.\n\nBy default, the `nditer` uses the flags \u2018allocate\u2019 and \u2018writeonly\u2019 for\noperands that are passed in as None. This means we were able to provide just\nthe two operands to the iterator, and it handled the rest.\n\nWhen adding the \u2018out\u2019 parameter, we have to explicitly provide those flags,\nbecause if someone passes in an array as \u2018out\u2019, the iterator will default to\n\u2018readonly\u2019, and our inner loop would fail. The reason \u2018readonly\u2019 is the\ndefault for input arrays is to prevent confusion about unintentionally\ntriggering a reduction operation. If the default were \u2018readwrite\u2019, any\nbroadcasting operation would also trigger a reduction, a topic which is\ncovered later in this document.\n\nWhile we\u2019re at it, let\u2019s also introduce the \u2018no_broadcast\u2019 flag, which will\nprevent the output from being broadcast. This is important, because we only\nwant one input value for each output. Aggregating more than one input value is\na reduction operation which requires special handling. It would already raise\nan error because reductions must be explicitly enabled in an iterator flag,\nbut the error message that results from disabling broadcasting is much more\nunderstandable for end-users. To see how to generalize the square function to\na reduction, look at the sum of squares function in the section about Cython.\n\nFor completeness, we\u2019ll also add the \u2018external_loop\u2019 and \u2018buffered\u2019 flags, as\nthese are what you will typically want for performance reasons.\n\nAny binary operation can be extended to an array operation in an outer product\nfashion like in `outer`, and the `nditer` object provides a way to accomplish\nthis by explicitly mapping the axes of the operands. It is also possible to do\nthis with `newaxis` indexing, but we will show you how to directly use the\nnditer `op_axes` parameter to accomplish this with no intermediate views.\n\nWe\u2019ll do a simple outer product, placing the dimensions of the first operand\nbefore the dimensions of the second operand. The `op_axes` parameter needs one\nlist of axes for each operand, and provides a mapping from the iterator\u2019s axes\nto the axes of the operand.\n\nSuppose the first operand is one dimensional and the second operand is two\ndimensional. The iterator will have three dimensions, so `op_axes` will have\ntwo 3-element lists. The first list picks out the one axis of the first\noperand, and is -1 for the rest of the iterator axes, with a final result of\n[0, -1, -1]. The second list picks out the two axes of the second operand, but\nshouldn\u2019t overlap with the axes picked out in the first operand. Its list is\n[-1, 0, 1]. The output operand maps onto the iterator axes in the standard\nmanner, so we can provide None instead of constructing another list.\n\nThe operation in the inner loop is a straightforward multiplication.\nEverything to do with the outer product is handled by the iterator setup.\n\nNote that once the iterator is closed we can not access `operands` and must\nuse a reference created inside the context manager.\n\nWhenever a writeable operand has fewer elements than the full iteration space,\nthat operand is undergoing a reduction. The `nditer` object requires that any\nreduction operand be flagged as read-write, and only allows reductions when\n\u2018reduce_ok\u2019 is provided as an iterator flag.\n\nFor a simple example, consider taking the sum of all elements in an array.\n\nThings are a little bit more tricky when combining reduction and allocated\noperands. Before iteration is started, any reduction operand must be\ninitialized to its starting values. Here\u2019s how we can do this, taking sums\nalong the last axis of `a`.\n\nTo do buffered reduction requires yet another adjustment during the setup.\nNormally the iterator construction involves copying the first buffer of data\nfrom the readable arrays into the buffer. Any reduction operand is readable,\nso it may be read into a buffer. Unfortunately, initialization of the operand\nafter this buffering operation is complete will not be reflected in the buffer\nthat the iteration starts with, and garbage results will be produced.\n\nThe iterator flag \u201cdelay_bufalloc\u201d is there to allow iterator-allocated\nreduction operands to exist together with buffering. When this flag is set,\nthe iterator will leave its buffers uninitialized until it receives a reset,\nafter which it will be ready for regular iteration. Here\u2019s how the previous\nexample looks if we also enable buffering.\n\nThose who want really good performance out of their low level operations\nshould strongly consider directly using the iteration API provided in C, but\nfor those who are not comfortable with C or C++, Cython is a good middle\nground with reasonable performance tradeoffs. For the `nditer` object, this\nmeans letting the iterator take care of broadcasting, dtype conversion, and\nbuffering, while giving the inner loop to Cython.\n\nFor our example, we\u2019ll create a sum of squares function. To start, let\u2019s\nimplement this function in straightforward Python. We want to support an\n\u2018axis\u2019 parameter similar to the numpy `sum` function, so we will need to\nconstruct a list for the `op_axes` parameter. Here\u2019s how this looks.\n\nTo Cython-ize this function, we replace the inner loop (y[\u2026] += x*x) with\nCython code that\u2019s specialized for the float64 dtype. With the \u2018external_loop\u2019\nflag enabled, the arrays provided to the inner loop will always be one-\ndimensional, so very little checking needs to be done.\n\nHere\u2019s the listing of sum_squares.pyx:\n\nOn this machine, building the .pyx file into a module looked like the\nfollowing, but you may have to find some Cython tutorials to tell you the\nspecifics for your system configuration.:\n\nRunning this from the Python interpreter produces the same answers as our\nnative Python/NumPy code did.\n\nDoing a little timing in IPython shows that the reduced overhead and memory\nallocation of the Cython inner loop is providing a very nice speedup over both\nthe straightforward Python code and an expression using NumPy\u2019s built-in sum\nfunction.:\n\n"}, {"name": "Laguerre Series (numpy.polynomial.laguerre)", "path": "reference/routines.polynomials.laguerre", "type": "Laguerre Series ( \n        \n         numpy.polynomial.laguerre\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Laguerre series, including a `Laguerre` class that encapsulates the usual\narithmetic operations. (General information on how this module represents and\nworks with such polynomials is in the docstring for its \u201cparent\u201d sub-package,\n`numpy.polynomial`).\n\n`Laguerre`(coef[, domain, window])\n\nA Laguerre series class.\n\n`lagdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagadd`(c1, c2)\n\nAdd one Laguerre series to another.\n\n`lagsub`(c1, c2)\n\nSubtract one Laguerre series from another.\n\n`lagmulx`(c)\n\nMultiply a Laguerre series by x.\n\n`lagmul`(c1, c2)\n\nMultiply one Laguerre series by another.\n\n`lagdiv`(c1, c2)\n\nDivide one Laguerre series by another.\n\n`lagpow`(c, pow[, maxpower])\n\nRaise a Laguerre series to a power.\n\n`lagval`(x, c[, tensor])\n\nEvaluate a Laguerre series at points x.\n\n`lagval2d`(x, y, c)\n\nEvaluate a 2-D Laguerre series at points (x, y).\n\n`lagval3d`(x, y, z, c)\n\nEvaluate a 3-D Laguerre series at points (x, y, z).\n\n`laggrid2d`(x, y, c)\n\nEvaluate a 2-D Laguerre series on the Cartesian product of x and y.\n\n`laggrid3d`(x, y, z, c)\n\nEvaluate a 3-D Laguerre series on the Cartesian product of x, y, and z.\n\n`lagder`(c[, m, scl, axis])\n\nDifferentiate a Laguerre series.\n\n`lagint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Laguerre series.\n\n`lagfromroots`(roots)\n\nGenerate a Laguerre series with given roots.\n\n`lagroots`(c)\n\nCompute the roots of a Laguerre series.\n\n`lagvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`lagvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`lagvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`laggauss`(deg)\n\nGauss-Laguerre quadrature.\n\n`lagweight`(x)\n\nWeight function of the Laguerre polynomials.\n\n`lagcompanion`(c)\n\nReturn the companion matrix of c.\n\n`lagfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Laguerre series to data.\n\n`lagtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`lagline`(off, scl)\n\nLaguerre series whose graph is a straight line.\n\n`lag2poly`(c)\n\nConvert a Laguerre series to a polynomial.\n\n`poly2lag`(pol)\n\nConvert a polynomial to a Laguerre series.\n\n`numpy.polynomial`\n\n"}, {"name": "Legendre Series (numpy.polynomial.legendre)", "path": "reference/routines.polynomials.legendre", "type": "Legendre Series ( \n        \n         numpy.polynomial.legendre\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Legendre series, including a `Legendre` class that encapsulates the usual\narithmetic operations. (General information on how this module represents and\nworks with such polynomials is in the docstring for its \u201cparent\u201d sub-package,\n`numpy.polynomial`).\n\n`Legendre`(coef[, domain, window])\n\nA Legendre series class.\n\n`legdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legadd`(c1, c2)\n\nAdd one Legendre series to another.\n\n`legsub`(c1, c2)\n\nSubtract one Legendre series from another.\n\n`legmulx`(c)\n\nMultiply a Legendre series by x.\n\n`legmul`(c1, c2)\n\nMultiply one Legendre series by another.\n\n`legdiv`(c1, c2)\n\nDivide one Legendre series by another.\n\n`legpow`(c, pow[, maxpower])\n\nRaise a Legendre series to a power.\n\n`legval`(x, c[, tensor])\n\nEvaluate a Legendre series at points x.\n\n`legval2d`(x, y, c)\n\nEvaluate a 2-D Legendre series at points (x, y).\n\n`legval3d`(x, y, z, c)\n\nEvaluate a 3-D Legendre series at points (x, y, z).\n\n`leggrid2d`(x, y, c)\n\nEvaluate a 2-D Legendre series on the Cartesian product of x and y.\n\n`leggrid3d`(x, y, z, c)\n\nEvaluate a 3-D Legendre series on the Cartesian product of x, y, and z.\n\n`legder`(c[, m, scl, axis])\n\nDifferentiate a Legendre series.\n\n`legint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Legendre series.\n\n`legfromroots`(roots)\n\nGenerate a Legendre series with given roots.\n\n`legroots`(c)\n\nCompute the roots of a Legendre series.\n\n`legvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`legvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`legvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`leggauss`(deg)\n\nGauss-Legendre quadrature.\n\n`legweight`(x)\n\nWeight function of the Legendre polynomials.\n\n`legcompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`legfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Legendre series to data.\n\n`legtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`legline`(off, scl)\n\nLegendre series whose graph is a straight line.\n\n`leg2poly`(c)\n\nConvert a Legendre series to a polynomial.\n\n`poly2leg`(pol)\n\nConvert a polynomial to a Legendre series.\n\nnumpy.polynomial\n\n"}, {"name": "lib.format.descr_to_dtype()", "path": "reference/generated/numpy.lib.format.descr_to_dtype", "type": "numpy.lib.format.descr_to_dtype", "text": "\nReturns a dtype based off the given description.\n\nThis is essentially the reverse of `dtype_to_descr()`. It will remove the\nvalueless padding fields created by, i.e. simple fields like dtype(\u2018float32\u2019),\nand then convert the description to its corresponding dtype.\n\nThe object retrieved by dtype.descr. Can be passed to `numpy.dtype()` in order\nto replicate the input dtype.\n\nThe dtype constructed by the description.\n\n"}, {"name": "lib.format.dtype_to_descr()", "path": "reference/generated/numpy.lib.format.dtype_to_descr", "type": "numpy.lib.format.dtype_to_descr", "text": "\nGet a serializable descriptor from the dtype.\n\nThe .descr attribute of a dtype object cannot be round-tripped through the\ndtype() constructor. Simple types, like dtype(\u2018float32\u2019), have a descr which\nlooks like a record array with one field with \u2018\u2019 as a name. The dtype()\nconstructor interprets this as a request to give a default name. Instead, we\nconstruct descriptor that can be passed to dtype().\n\nThe dtype of the array that will be written to disk.\n\nAn object that can be passed to `numpy.dtype()` in order to replicate the\ninput dtype.\n\n"}, {"name": "lib.format.header_data_from_array_1_0()", "path": "reference/generated/numpy.lib.format.header_data_from_array_1_0", "type": "numpy.lib.format.header_data_from_array_1_0", "text": "\nGet the dictionary of header metadata from a numpy.ndarray.\n\nThis has the appropriate entries for writing its string representation to the\nheader of the file.\n\n"}, {"name": "lib.format.magic()", "path": "reference/generated/numpy.lib.format.magic", "type": "numpy.lib.format.magic", "text": "\nReturn the magic string for the given file format version.\n\n"}, {"name": "lib.format.open_memmap()", "path": "reference/generated/numpy.lib.format.open_memmap", "type": "numpy.lib.format.open_memmap", "text": "\nOpen a .npy file as a memory-mapped array.\n\nThis may be used to read an existing file or create a new one.\n\nThe name of the file on disk. This may not be a file-like object.\n\nThe mode in which to open the file; the default is \u2018r+\u2019. In addition to the\nstandard file modes, \u2018c\u2019 is also accepted to mean \u201ccopy on write.\u201d See\n`memmap` for the available mode strings.\n\nThe data type of the array if we are creating a new file in \u201cwrite\u201d mode, if\nnot, `dtype` is ignored. The default value is None, which results in a data-\ntype of `float64`.\n\nThe shape of the array if we are creating a new file in \u201cwrite\u201d mode, in which\ncase this parameter is required. Otherwise, this parameter is ignored and is\nthus optional.\n\nWhether the array should be Fortran-contiguous (True) or C-contiguous (False,\nthe default) if we are creating a new file in \u201cwrite\u201d mode.\n\nIf the mode is a \u201cwrite\u201d mode, then this is the version of the file format\nused to create the file. None means use the oldest supported version that is\nable to store the data. Default: None\n\nThe memory-mapped array.\n\nIf the data or the mode is invalid.\n\nIf the file is not found or cannot be opened correctly.\n\nSee also\n\n"}, {"name": "lib.format.read_array()", "path": "reference/generated/numpy.lib.format.read_array", "type": "numpy.lib.format.read_array", "text": "\nRead an array from an NPY file.\n\nIf this is not a real file object, then this may take extra memory and time.\n\nWhether to allow writing pickled data. Default: False\n\nChanged in version 1.16.3: Made default False in response to CVE-2019-6446.\n\nAdditional keyword arguments to pass to pickle.load. These are only useful\nwhen loading object arrays saved on Python 2 when using Python 3.\n\nThe array from the data on disk.\n\nIf the data is invalid, or allow_pickle=False and the file contains an object\narray.\n\n"}, {"name": "lib.format.read_array_header_1_0()", "path": "reference/generated/numpy.lib.format.read_array_header_1_0", "type": "numpy.lib.format.read_array_header_1_0", "text": "\nRead an array header from a filelike object using the 1.0 file format version.\n\nThis will leave the file object located just after the header.\n\nA file object or something with a `read()` method like a file.\n\nThe shape of the array.\n\nThe array data will be written out directly if it is either C-contiguous or\nFortran-contiguous. Otherwise, it will be made contiguous before writing it\nout.\n\nThe dtype of the file\u2019s data.\n\nIf the data is invalid.\n\n"}, {"name": "lib.format.read_array_header_2_0()", "path": "reference/generated/numpy.lib.format.read_array_header_2_0", "type": "numpy.lib.format.read_array_header_2_0", "text": "\nRead an array header from a filelike object using the 2.0 file format version.\n\nThis will leave the file object located just after the header.\n\nNew in version 1.9.0.\n\nA file object or something with a `read()` method like a file.\n\nThe shape of the array.\n\nThe array data will be written out directly if it is either C-contiguous or\nFortran-contiguous. Otherwise, it will be made contiguous before writing it\nout.\n\nThe dtype of the file\u2019s data.\n\nIf the data is invalid.\n\n"}, {"name": "lib.format.read_magic()", "path": "reference/generated/numpy.lib.format.read_magic", "type": "numpy.lib.format.read_magic", "text": "\nRead the magic string to get the version of the file format.\n\n"}, {"name": "lib.format.write_array()", "path": "reference/generated/numpy.lib.format.write_array", "type": "numpy.lib.format.write_array", "text": "\nWrite an array to an NPY file, including a header.\n\nIf the array is neither C-contiguous nor Fortran-contiguous AND the file_like\nobject is not a real file object, this function will have to copy data in\nmemory.\n\nAn open, writable file object, or similar object with a `.write()` method.\n\nThe array to write to disk.\n\nThe version number of the format. None means use the oldest supported version\nthat is able to store the data. Default: None\n\nWhether to allow writing pickled data. Default: True\n\nAdditional keyword arguments to pass to pickle.dump, excluding \u2018protocol\u2019.\nThese are only useful when pickling objects in object arrays on Python 3 to\nPython 2 compatible format.\n\nIf the array cannot be persisted. This includes the case of allow_pickle=False\nand array being an object array.\n\nIf the array contains Python objects as part of its dtype, the process of\npickling them may raise various errors if the objects are not picklable.\n\n"}, {"name": "lib.format.write_array_header_1_0()", "path": "reference/generated/numpy.lib.format.write_array_header_1_0", "type": "numpy.lib.format.write_array_header_1_0", "text": "\nWrite the header for an array using the 1.0 format.\n\nThis has the appropriate entries for writing its string representation to the\nheader of the file.\n\n"}, {"name": "lib.format.write_array_header_2_0()", "path": "reference/generated/numpy.lib.format.write_array_header_2_0", "type": "numpy.lib.format.write_array_header_2_0", "text": "\nThe 2.0 format allows storing very large structured arrays.\n\nNew in version 1.9.0.\n\nThis has the appropriate entries for writing its string representation to the\nheader of the file.\n\n"}, {"name": "lib.scimath.arccos()", "path": "reference/generated/numpy.lib.scimath.arccos", "type": "numpy.lib.scimath.arccos", "text": "\nCompute the inverse cosine of x.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.arccos`)\nof the inverse cosine of `x`. For real `x` such that `abs(x) <= 1`, this is a\nreal number in the closed interval \\\\([0, \\pi]\\\\). Otherwise, the complex\nprinciple value is returned.\n\nThe value(s) whose arccos is (are) required.\n\nThe inverse cosine(s) of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array object is returned.\n\nSee also\n\nFor an arccos() that returns `NAN` when real `x` is not in the interval\n`[-1,1]`, use `numpy.arccos`.\n\n"}, {"name": "lib.scimath.arcsin()", "path": "reference/generated/numpy.lib.scimath.arcsin", "type": "numpy.lib.scimath.arcsin", "text": "\nCompute the inverse sine of x.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.arcsin`)\nof the inverse sine of `x`. For real `x` such that `abs(x) <= 1`, this is a\nreal number in the closed interval \\\\([-\\pi/2, \\pi/2]\\\\). Otherwise, the\ncomplex principle value is returned.\n\nThe value(s) whose arcsin is (are) required.\n\nThe inverse sine(s) of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array object is returned.\n\nSee also\n\nFor an arcsin() that returns `NAN` when real `x` is not in the interval\n`[-1,1]`, use `numpy.arcsin`.\n\n"}, {"name": "lib.scimath.arctanh()", "path": "reference/generated/numpy.lib.scimath.arctanh", "type": "numpy.lib.scimath.arctanh", "text": "\nCompute the inverse hyperbolic tangent of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.arctanh`)\nof `arctanh(x)`. For real `x` such that `abs(x) < 1`, this is a real number.\nIf `abs(x) > 1`, or if `x` is complex, the result is complex. Finally, `x = 1`\nreturns``inf`` and `x=-1` returns `-inf`.\n\nThe value(s) whose arctanh is (are) required.\n\nThe inverse hyperbolic tangent(s) of the `x` value(s). If `x` was a scalar so\nis `out`, otherwise an array is returned.\n\nSee also\n\nFor an arctanh() that returns `NAN` when real `x` is not in the interval\n`(-1,1)`, use `numpy.arctanh` (this latter, however, does return +/-inf for `x\n= +/-1`).\n\n"}, {"name": "lib.scimath.log()", "path": "reference/generated/numpy.lib.scimath.log", "type": "numpy.lib.scimath.log", "text": "\nCompute the natural logarithm of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.log`) of\n\\\\(log_e(x)\\\\). For real `x > 0`, this is a real number (`log(0)` returns\n`-inf` and `log(np.inf)` returns `inf`). Otherwise, the complex principle\nvalue is returned.\n\nThe value(s) whose log is (are) required.\n\nThe log of the `x` value(s). If `x` was a scalar, so is `out`, otherwise an\narray is returned.\n\nSee also\n\nFor a log() that returns `NAN` when real `x < 0`, use `numpy.log` (note,\nhowever, that otherwise `numpy.log` and this `log` are identical, i.e., both\nreturn `-inf` for `x = 0`, `inf` for `x = inf`, and, notably, the complex\nprinciple value if `x.imag != 0`).\n\nNegative arguments are handled \u201ccorrectly\u201d (recall that `exp(log(x)) == x`\ndoes not hold for real `x < 0`):\n\n"}, {"name": "lib.scimath.log10()", "path": "reference/generated/numpy.lib.scimath.log10", "type": "numpy.lib.scimath.log10", "text": "\nCompute the logarithm base 10 of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.log10`) of\n\\\\(log_{10}(x)\\\\). For real `x > 0`, this is a real number (`log10(0)` returns\n`-inf` and `log10(np.inf)` returns `inf`). Otherwise, the complex principle\nvalue is returned.\n\nThe value(s) whose log base 10 is (are) required.\n\nThe log base 10 of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array object is returned.\n\nSee also\n\nFor a log10() that returns `NAN` when real `x < 0`, use `numpy.log10` (note,\nhowever, that otherwise `numpy.log10` and this `log10` are identical, i.e.,\nboth return `-inf` for `x = 0`, `inf` for `x = inf`, and, notably, the complex\nprinciple value if `x.imag != 0`).\n\n(We set the printing precision so the example can be auto-tested)\n\n"}, {"name": "lib.scimath.log2()", "path": "reference/generated/numpy.lib.scimath.log2", "type": "numpy.lib.scimath.log2", "text": "\nCompute the logarithm base 2 of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.log2`) of\n\\\\(log_2(x)\\\\). For real `x > 0`, this is a real number (`log2(0)` returns\n`-inf` and `log2(np.inf)` returns `inf`). Otherwise, the complex principle\nvalue is returned.\n\nThe value(s) whose log base 2 is (are) required.\n\nThe log base 2 of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array is returned.\n\nSee also\n\nFor a log2() that returns `NAN` when real `x < 0`, use `numpy.log2` (note,\nhowever, that otherwise `numpy.log2` and this `log2` are identical, i.e., both\nreturn `-inf` for `x = 0`, `inf` for `x = inf`, and, notably, the complex\nprinciple value if `x.imag != 0`).\n\nWe set the printing precision so the example can be auto-tested:\n\n"}, {"name": "lib.scimath.logn()", "path": "reference/generated/numpy.lib.scimath.logn", "type": "numpy.lib.scimath.logn", "text": "\nTake log base n of x.\n\nIf `x` contains negative inputs, the answer is computed and returned in the\ncomplex domain.\n\nThe integer base(s) in which the log is taken.\n\nThe value(s) whose log base `n` is (are) required.\n\nThe log base `n` of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array is returned.\n\n"}, {"name": "lib.scimath.power()", "path": "reference/generated/numpy.lib.scimath.power", "type": "numpy.lib.scimath.power", "text": "\nReturn x to the power p, (x**p).\n\nIf `x` contains negative values, the output is converted to the complex\ndomain.\n\nThe input value(s).\n\nThe power(s) to which `x` is raised. If `x` contains multiple values, `p` has\nto either be a scalar, or contain the same number of values as `x`. In the\nlatter case, the result is `x[0]**p[0], x[1]**p[1], ...`.\n\nThe result of `x**p`. If `x` and `p` are scalars, so is `out`, otherwise an\narray is returned.\n\nSee also\n\n"}, {"name": "lib.scimath.sqrt()", "path": "reference/generated/numpy.lib.scimath.sqrt", "type": "numpy.lib.scimath.sqrt", "text": "\nCompute the square root of x.\n\nFor negative input elements, a complex value is returned (unlike `numpy.sqrt`\nwhich returns NaN).\n\nThe input value(s).\n\nThe square root of `x`. If `x` was a scalar, so is `out`, otherwise an array\nis returned.\n\nSee also\n\nFor real, non-negative inputs this works just like `numpy.sqrt`:\n\nBut it automatically handles negative inputs:\n\n"}, {"name": "lib.stride_tricks.as_strided()", "path": "reference/generated/numpy.lib.stride_tricks.as_strided", "type": "numpy.lib.stride_tricks.as_strided", "text": "\nCreate a view into the array with the given shape and strides.\n\nWarning\n\nThis function has to be used with extreme care, see notes.\n\nArray to create a new.\n\nThe shape of the new array. Defaults to `x.shape`.\n\nThe strides of the new array. Defaults to `x.strides`.\n\nNew in version 1.10.\n\nIf True, subclasses are preserved.\n\nNew in version 1.12.\n\nIf set to False, the returned array will always be readonly. Otherwise it will\nbe writable if the original array was. It is advisable to set this to False if\npossible (see Notes).\n\nSee also\n\nbroadcast an array to a given shape.\n\nreshape an array.\n\nuserfriendly and safe function for the creation of sliding window views.\n\n`as_strided` creates a view into the array given the exact strides and shape.\nThis means it manipulates the internal data structure of ndarray and, if done\nincorrectly, the array elements can point to invalid memory and can corrupt\nresults or crash your program. It is advisable to always use the original\n`x.strides` when calculating new strides to avoid reliance on a contiguous\nmemory layout.\n\nFurthermore, arrays created with this function often contain self overlapping\nmemory, so that two elements are identical. Vectorized write operations on\nsuch arrays will typically be unpredictable. They may even give different\nresults for small, large, or transposed arrays. Since writing to these arrays\nhas to be tested and done with great care, you may want to use\n`writeable=False` to avoid accidental write operations.\n\nFor these reasons it is advisable to avoid `as_strided` when possible.\n\n"}, {"name": "lib.stride_tricks.sliding_window_view()", "path": "reference/generated/numpy.lib.stride_tricks.sliding_window_view", "type": "numpy.lib.stride_tricks.sliding_window_view", "text": "\nCreate a sliding window view into the array with the given window shape.\n\nAlso known as rolling or moving window, the window slides across all\ndimensions of the array and extracts subsets of the array at all window\npositions.\n\nNew in version 1.20.0.\n\nArray to create the sliding window view from.\n\nSize of window over each axis that takes part in the sliding window. If `axis`\nis not present, must have same length as the number of input array dimensions.\nSingle integers `i` are treated as if they were the tuple `(i,)`.\n\nAxis or axes along which the sliding window is applied. By default, the\nsliding window is applied to all axes and `window_shape[i]` will refer to axis\n`i` of `x`. If `axis` is given as a `tuple of int`, `window_shape[i]` will\nrefer to the axis `axis[i]` of `x`. Single integers `i` are treated as if they\nwere the tuple `(i,)`.\n\nIf True, sub-classes will be passed-through, otherwise the returned array will\nbe forced to be a base-class array (default).\n\nWhen true, allow writing to the returned view. The default is false, as this\nshould be used with caution: the returned view contains the same memory\nlocation multiple times, so writing to one location will cause others to\nchange.\n\nSliding window view of the array. The sliding window dimensions are inserted\nat the end, and the original dimensions are trimmed as required by the size of\nthe sliding window. That is, `view.shape = x_shape_trimmed + window_shape`,\nwhere `x_shape_trimmed` is `x.shape` with every entry reduced by one less than\nthe corresponding window size.\n\nSee also\n\nA lower-level and less safe routine for creating arbitrary views from custom\nshape and strides.\n\nbroadcast an array to a given shape.\n\nFor many applications using a sliding window view can be convenient, but\npotentially very slow. Often specialized solutions exist, for example:\n\nAs a rough estimate, a sliding window approach with an input size of `N` and a\nwindow size of `W` will scale as `O(N*W)` where frequently a special algorithm\ncan achieve `O(N)`. That means that the sliding window variant for a window\nsize of 100 can be a 100 times slower than a more specialized version.\n\nNevertheless, for small window sizes, when no custom algorithm exists, or as a\nprototyping and developing tool, this function can be a good solution.\n\nThis also works in more dimensions, e.g.\n\nThe axis can be specified explicitly:\n\nThe same axis can be used several times. In that case, every use reduces the\ncorresponding original dimension:\n\nCombining with stepped slicing (`::step`), this can be used to take sliding\nviews which skip elements:\n\nor views which move by multiple elements\n\nA common application of `sliding_window_view` is the calculation of running\nstatistics. The simplest example is the moving average:\n\nNote that a sliding window approach is often not optimal (see Notes).\n\n"}, {"name": "linalg.cholesky()", "path": "reference/generated/numpy.linalg.cholesky", "type": "numpy.linalg.cholesky", "text": "\nCholesky decomposition.\n\nReturn the Cholesky decomposition, `L * L.H`, of the square matrix `a`, where\n`L` is lower-triangular and .H is the conjugate transpose operator (which is\nthe ordinary transpose if `a` is real-valued). `a` must be Hermitian\n(symmetric if real-valued) and positive-definite. No checking is performed to\nverify whether `a` is Hermitian or not. In addition, only the lower-triangular\nand diagonal elements of `a` are used. Only `L` is actually returned.\n\nHermitian (symmetric if all elements are real), positive-definite input\nmatrix.\n\nUpper or lower-triangular Cholesky factor of `a`. Returns a matrix object if\n`a` is a matrix object.\n\nIf the decomposition fails, for example, if `a` is not positive-definite.\n\nSee also\n\nSimilar function in SciPy.\n\nCholesky decompose a banded Hermitian positive-definite matrix.\n\nCholesky decomposition of a matrix, to use in `scipy.linalg.cho_solve`.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe Cholesky decomposition is often used as a fast way of solving\n\n(when `A` is both Hermitian/symmetric and positive-definite).\n\nFirst, we solve for \\\\(\\mathbf{y}\\\\) in\n\nand then for \\\\(\\mathbf{x}\\\\) in\n\n"}, {"name": "linalg.cond()", "path": "reference/generated/numpy.linalg.cond", "type": "numpy.linalg.cond", "text": "\nCompute the condition number of a matrix.\n\nThis function is capable of returning the condition number using one of seven\ndifferent norms, depending on the value of `p` (see Parameters below).\n\nThe matrix whose condition number is sought.\n\nOrder of the norm used in the condition number computation:\n\np\n\nnorm for matrices\n\nNone\n\n2-norm, computed directly using the `SVD`\n\n\u2018fro\u2019\n\nFrobenius norm\n\ninf\n\nmax(sum(abs(x), axis=1))\n\n-inf\nmin(sum(abs(x), axis=1))\n\n1\n\nmax(sum(abs(x), axis=0))\n\n-1\nmin(sum(abs(x), axis=0))\n\n2\n\n2-norm (largest sing. value)\n\n-2\nsmallest singular value\n\ninf means the `numpy.inf` object, and the Frobenius norm is the root-of-sum-\nof-squares norm.\n\nThe condition number of the matrix. May be infinite.\n\nSee also\n\nThe condition number of `x` is defined as the norm of `x` times the norm of\nthe inverse of `x` [1]; the norm can be the usual L2-norm (root-of-sum-of-\nsquares) or one of a number of other matrix norms.\n\nG. Strang, Linear Algebra and Its Applications, Orlando, FL, Academic Press,\nInc., 1980, pg. 285.\n\n"}, {"name": "linalg.det()", "path": "reference/generated/numpy.linalg.det", "type": "numpy.linalg.det", "text": "\nCompute the determinant of an array.\n\nInput array to compute determinants for.\n\nDeterminant of `a`.\n\nSee also\n\nAnother way to represent the determinant, more suitable for large matrices\nwhere underflow/overflow may occur.\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe determinant is computed via LU factorization using the LAPACK routine\n`z/dgetrf`.\n\nThe determinant of a 2-D array [[a, b], [c, d]] is ad - bc:\n\nComputing determinants for a stack of matrices:\n\n"}, {"name": "linalg.eig()", "path": "reference/generated/numpy.linalg.eig", "type": "numpy.linalg.eig", "text": "\nCompute the eigenvalues and right eigenvectors of a square array.\n\nMatrices for which the eigenvalues and right eigenvectors will be computed\n\nThe eigenvalues, each repeated according to its multiplicity. The eigenvalues\nare not necessarily ordered. The resulting array will be of complex type,\nunless the imaginary part is zero in which case it will be cast to a real\ntype. When `a` is real the resulting eigenvalues will be real (0 imaginary\npart) or occur in conjugate pairs\n\nThe normalized (unit \u201clength\u201d) eigenvectors, such that the column `v[:,i]` is\nthe eigenvector corresponding to the eigenvalue `w[i]`.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues of a non-symmetric array.\n\neigenvalues and eigenvectors of a real symmetric or complex Hermitian\n(conjugate symmetric) array.\n\neigenvalues of a real symmetric or complex Hermitian (conjugate symmetric)\narray.\n\nSimilar function in SciPy that also solves the generalized eigenvalue problem.\n\nBest choice for unitary and other non-Hermitian normal matrices.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThis is implemented using the `_geev` LAPACK routines which compute the\neigenvalues and eigenvectors of general square arrays.\n\nThe number `w` is an eigenvalue of `a` if there exists a vector `v` such that\n`a @ v = w * v`. Thus, the arrays `a`, `w`, and `v` satisfy the equations `a @\nv[:,i] = w[i] * v[:,i]` for \\\\(i \\in \\\\{0,...,M-1\\\\}\\\\).\n\nThe array `v` of eigenvectors may not be of maximum rank, that is, some of the\ncolumns may be linearly dependent, although round-off error may obscure that\nfact. If the eigenvalues are all different, then theoretically the\neigenvectors are linearly independent and `a` can be diagonalized by a\nsimilarity transformation using `v`, i.e, `inv(v) @ a @ v` is diagonal.\n\nFor non-Hermitian normal matrices the SciPy function `scipy.linalg.schur` is\npreferred because the matrix `v` is guaranteed to be unitary, which is not the\ncase when using `eig`. The Schur factorization produces an upper triangular\nmatrix rather than a diagonal matrix, but for normal matrices only the\ndiagonal of the upper triangular matrix is needed, the rest is roundoff error.\n\nFinally, it is emphasized that `v` consists of the right (as in right-hand\nside) eigenvectors of `a`. A vector `y` satisfying `y.T @ a = z * y.T` for\nsome number `z` is called a left eigenvector of `a`, and, in general, the left\nand right eigenvectors of a matrix are not necessarily the (perhaps conjugate)\ntransposes of each other.\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, Various pp.\n\n(Almost) trivial example with real e-values and e-vectors.\n\nReal matrix possessing complex e-values and e-vectors; note that the e-values\nare complex conjugates of each other.\n\nComplex-valued matrix with real e-values (but complex-valued e-vectors); note\nthat `a.conj().T == a`, i.e., `a` is Hermitian.\n\nBe careful about round-off error!\n\n"}, {"name": "linalg.eigh()", "path": "reference/generated/numpy.linalg.eigh", "type": "numpy.linalg.eigh", "text": "\nReturn the eigenvalues and eigenvectors of a complex Hermitian (conjugate\nsymmetric) or a real symmetric matrix.\n\nReturns two objects, a 1-D array containing the eigenvalues of `a`, and a 2-D\nsquare array or matrix (depending on the input type) of the corresponding\neigenvectors (in columns).\n\nHermitian or real symmetric matrices whose eigenvalues and eigenvectors are to\nbe computed.\n\nSpecifies whether the calculation is done with the lower triangular part of\n`a` (\u2018L\u2019, default) or the upper triangular part (\u2018U\u2019). Irrespective of this\nvalue only the real parts of the diagonal will be considered in the\ncomputation to preserve the notion of a Hermitian matrix. It therefore follows\nthat the imaginary part of the diagonal will always be treated as zero.\n\nThe eigenvalues in ascending order, each repeated according to its\nmultiplicity.\n\nThe column `v[:, i]` is the normalized eigenvector corresponding to the\neigenvalue `w[i]`. Will return a matrix object if `a` is a matrix object.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues of real symmetric or complex Hermitian (conjugate symmetric)\narrays.\n\neigenvalues and right eigenvectors for non-symmetric arrays.\n\neigenvalues of non-symmetric arrays.\n\nSimilar function in SciPy (but also solves the generalized eigenvalue\nproblem).\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe eigenvalues/eigenvectors are computed using LAPACK routines `_syevd`,\n`_heevd`.\n\nThe eigenvalues of real symmetric or complex Hermitian matrices are always\nreal. [1] The array `v` of (column) eigenvectors is unitary and `a`, `w`, and\n`v` satisfy the equations `dot(a, v[:, i]) = w[i] * v[:, i]`.\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, pg. 222.\n\n"}, {"name": "linalg.eigvals()", "path": "reference/generated/numpy.linalg.eigvals", "type": "numpy.linalg.eigvals", "text": "\nCompute the eigenvalues of a general matrix.\n\nMain difference between `eigvals` and `eig`: the eigenvectors aren\u2019t returned.\n\nA complex- or real-valued matrix whose eigenvalues will be computed.\n\nThe eigenvalues, each repeated according to its multiplicity. They are not\nnecessarily ordered, nor are they necessarily real for real matrices.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues and right eigenvectors of general arrays\n\neigenvalues of real symmetric or complex Hermitian (conjugate symmetric)\narrays.\n\neigenvalues and eigenvectors of real symmetric or complex Hermitian (conjugate\nsymmetric) arrays.\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThis is implemented using the `_geev` LAPACK routines which compute the\neigenvalues and eigenvectors of general square arrays.\n\nIllustration, using the fact that the eigenvalues of a diagonal matrix are its\ndiagonal elements, that multiplying a matrix on the left by an orthogonal\nmatrix, `Q`, and on the right by `Q.T` (the transpose of `Q`), preserves the\neigenvalues of the \u201cmiddle\u201d matrix. In other words, if `Q` is orthogonal, then\n`Q * A * Q.T` has the same eigenvalues as `A`:\n\nNow multiply a diagonal matrix by `Q` on one side and by `Q.T` on the other:\n\n"}, {"name": "linalg.eigvalsh()", "path": "reference/generated/numpy.linalg.eigvalsh", "type": "numpy.linalg.eigvalsh", "text": "\nCompute the eigenvalues of a complex Hermitian or real symmetric matrix.\n\nMain difference from eigh: the eigenvectors are not computed.\n\nA complex- or real-valued matrix whose eigenvalues are to be computed.\n\nSpecifies whether the calculation is done with the lower triangular part of\n`a` (\u2018L\u2019, default) or the upper triangular part (\u2018U\u2019). Irrespective of this\nvalue only the real parts of the diagonal will be considered in the\ncomputation to preserve the notion of a Hermitian matrix. It therefore follows\nthat the imaginary part of the diagonal will always be treated as zero.\n\nThe eigenvalues in ascending order, each repeated according to its\nmultiplicity.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues and eigenvectors of real symmetric or complex Hermitian (conjugate\nsymmetric) arrays.\n\neigenvalues of general real or complex arrays.\n\neigenvalues and right eigenvectors of general real or complex arrays.\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe eigenvalues are computed using LAPACK routines `_syevd`, `_heevd`.\n\n"}, {"name": "linalg.inv()", "path": "reference/generated/numpy.linalg.inv", "type": "numpy.linalg.inv", "text": "\nCompute the (multiplicative) inverse of a matrix.\n\nGiven a square matrix `a`, return the matrix `ainv` satisfying `dot(a, ainv) =\ndot(ainv, a) = eye(a.shape[0])`.\n\nMatrix to be inverted.\n\n(Multiplicative) inverse of the matrix `a`.\n\nIf `a` is not square or inversion fails.\n\nSee also\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nIf a is a matrix object, then the return value is a matrix as well:\n\nInverses of several matrices can be computed at once:\n\n"}, {"name": "linalg.LinAlgError", "path": "reference/generated/numpy.linalg.linalgerror", "type": "numpy.linalg.LinAlgError", "text": "\nGeneric Python-exception-derived object raised by linalg functions.\n\nGeneral purpose exception class, derived from Python\u2019s exception.Exception\nclass, programmatically raised in linalg functions when a Linear Algebra-\nrelated condition would prevent further correct execution of the function.\n\n"}, {"name": "linalg.lstsq()", "path": "reference/generated/numpy.linalg.lstsq", "type": "numpy.linalg.lstsq", "text": "\nReturn the least-squares solution to a linear matrix equation.\n\nComputes the vector `x` that approximately solves the equation `a @ x = b`.\nThe equation may be under-, well-, or over-determined (i.e., the number of\nlinearly independent rows of `a` can be less than, equal to, or greater than\nits number of linearly independent columns). If `a` is square and of full\nrank, then `x` (but for round-off error) is the \u201cexact\u201d solution of the\nequation. Else, `x` minimizes the Euclidean 2-norm \\\\(||b - ax||\\\\). If there\nare multiple minimizing solutions, the one with the smallest 2-norm\n\\\\(||x||\\\\) is returned.\n\n\u201cCoefficient\u201d matrix.\n\nOrdinate or \u201cdependent variable\u201d values. If `b` is two-dimensional, the least-\nsquares solution is calculated for each of the `K` columns of `b`.\n\nCut-off ratio for small singular values of `a`. For the purposes of rank\ndetermination, singular values are treated as zero if they are smaller than\n`rcond` times the largest singular value of `a`.\n\nChanged in version 1.14.0: If not set, a FutureWarning is given. The previous\ndefault of `-1` will use the machine precision as `rcond` parameter, the new\ndefault will use the machine precision times `max(M, N)`. To silence the\nwarning and use the new default, use `rcond=None`, to keep using the old\nbehavior, use `rcond=-1`.\n\nLeast-squares solution. If `b` is two-dimensional, the solutions are in the\n`K` columns of `x`.\n\nSums of squared residuals: Squared Euclidean 2-norm for each column in `b - a\n@ x`. If the rank of `a` is < N or M <= N, this is an empty array. If `b` is\n1-dimensional, this is a (1,) shape array. Otherwise the shape is (K,).\n\nRank of matrix `a`.\n\nSingular values of `a`.\n\nIf computation does not converge.\n\nSee also\n\nSimilar function in SciPy.\n\nIf `b` is a matrix, then all array results are returned as matrices.\n\nFit a line, `y = mx + c`, through some noisy data-points:\n\nBy examining the coefficients, we see that the line should have a gradient of\nroughly 1 and cut the y-axis at, more or less, -1.\n\nWe can rewrite the line equation as `y = Ap`, where `A = [[x 1]]` and `p =\n[[m], [c]]`. Now use `lstsq` to solve for `p`:\n\nPlot the data along with the fitted line:\n\n"}, {"name": "linalg.matrix_power()", "path": "reference/generated/numpy.linalg.matrix_power", "type": "numpy.linalg.matrix_power", "text": "\nRaise a square matrix to the (integer) power `n`.\n\nFor positive integers `n`, the power is computed by repeated matrix squarings\nand matrix multiplications. If `n == 0`, the identity matrix of the same shape\nas M is returned. If `n < 0`, the inverse is computed and then raised to the\n`abs(n)`.\n\nNote\n\nStacks of object matrices are not currently supported.\n\nMatrix to be \u201cpowered\u201d.\n\nThe exponent can be any integer or long integer, positive, negative, or zero.\n\nThe return value is the same shape and type as `M`; if the exponent is\npositive or zero then the type of the elements is the same as those of `M`. If\nthe exponent is negative the elements are floating-point.\n\nFor matrices that are not square or that (for negative powers) cannot be\ninverted numerically.\n\nSomewhat more sophisticated example\n\n"}, {"name": "linalg.matrix_rank()", "path": "reference/generated/numpy.linalg.matrix_rank", "type": "numpy.linalg.matrix_rank", "text": "\nReturn matrix rank of array using SVD method\n\nRank of the array is the number of singular values of the array that are\ngreater than `tol`.\n\nChanged in version 1.14: Can now operate on stacks of matrices\n\nInput vector or stack of matrices.\n\nThreshold below which SVD values are considered zero. If `tol` is None, and\n`S` is an array with singular values for `M`, and `eps` is the epsilon value\nfor datatype of `S`, then `tol` is set to `S.max() * max(M, N) * eps`.\n\nChanged in version 1.14: Broadcasted against the stack of matrices\n\nIf True, `A` is assumed to be Hermitian (symmetric if real-valued), enabling a\nmore efficient method for finding singular values. Defaults to False.\n\nNew in version 1.14.\n\nRank of A.\n\nThe default threshold to detect rank deficiency is a test on the magnitude of\nthe singular values of `A`. By default, we identify singular values less than\n`S.max() * max(M, N) * eps` as indicating rank deficiency (with the symbols\ndefined above). This is the algorithm MATLAB uses [1]. It also appears in\nNumerical recipes in the discussion of SVD solutions for linear least squares\n[2].\n\nThis default threshold is designed to detect rank deficiency accounting for\nthe numerical errors of the SVD computation. Imagine that there is a column in\n`A` that is an exact (in floating point) linear combination of other columns\nin `A`. Computing the SVD on `A` will not produce a singular value exactly\nequal to 0 in general: any difference of the smallest SVD value from 0 will be\ncaused by numerical imprecision in the calculation of the SVD. Our threshold\nfor small SVD values takes this numerical imprecision into account, and the\ndefault threshold will detect such numerical rank deficiency. The threshold\nmay declare a matrix `A` rank deficient even if the linear combination of some\ncolumns of `A` is not exactly equal to another column of `A` but only\nnumerically very close to another column of `A`.\n\nWe chose our default threshold because it is in wide use. Other thresholds are\npossible. For example, elsewhere in the 2007 edition of Numerical recipes\nthere is an alternative threshold of `S.max() * np.finfo(A.dtype).eps / 2. *\nnp.sqrt(m + n + 1.)`. The authors describe this threshold as being based on\n\u201cexpected roundoff error\u201d (p 71).\n\nThe thresholds above deal with floating point roundoff error in the\ncalculation of the SVD. However, you may have more information about the\nsources of error in `A` that would make you consider other tolerance values to\ndetect effective rank deficiency. The most useful measure of the tolerance\ndepends on the operations you intend to use on your matrix. For example, if\nyour data come from uncertain measurements with uncertainties greater than\nfloating point epsilon, choosing a tolerance near that uncertainty may be\npreferable. The tolerance may be absolute if the uncertainties are absolute\nrather than relative.\n\nMATLAB reference documentation, \u201cRank\u201d\nhttps://www.mathworks.com/help/techdoc/ref/rank.html\n\nW. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery, \u201cNumerical\nRecipes (3rd edition)\u201d, Cambridge University Press, 2007, page 795.\n\n"}, {"name": "linalg.multi_dot()", "path": "reference/generated/numpy.linalg.multi_dot", "type": "numpy.linalg.multi_dot", "text": "\nCompute the dot product of two or more arrays in a single function call, while\nautomatically selecting the fastest evaluation order.\n\n`multi_dot` chains `numpy.dot` and uses optimal parenthesization of the\nmatrices [1] [2]. Depending on the shapes of the matrices, this can speed up\nthe multiplication a lot.\n\nIf the first argument is 1-D it is treated as a row vector. If the last\nargument is 1-D it is treated as a column vector. The other arguments must be\n2-D.\n\nThink of `multi_dot` as:\n\nIf the first argument is 1-D it is treated as row vector. If the last argument\nis 1-D it is treated as column vector. The other arguments must be 2-D.\n\nOutput argument. This must have the exact kind that would be returned if it\nwas not used. In particular, it must have the right type, must be\nC-contiguous, and its dtype must be the dtype that would be returned for\n`dot(a, b)`. This is a performance feature. Therefore, if these conditions are\nnot met, an exception is raised, instead of attempting to be flexible.\n\nNew in version 1.19.0.\n\nReturns the dot product of the supplied arrays.\n\nSee also\n\ndot multiplication with two arguments.\n\nThe cost for a matrix multiplication can be calculated with the following\nfunction:\n\nAssume we have three matrices \\\\(A_{10x100}, B_{100x5}, C_{5x50}\\\\).\n\nThe costs for the two different parenthesizations are as follows:\n\nCormen, \u201cIntroduction to Algorithms\u201d, Chapter 15.2, p. 370-378\n\nhttps://en.wikipedia.org/wiki/Matrix_chain_multiplication\n\n`multi_dot` allows you to write:\n\ninstead of:\n\n"}, {"name": "linalg.norm()", "path": "reference/generated/numpy.linalg.norm", "type": "numpy.linalg.norm", "text": "\nMatrix or vector norm.\n\nThis function is able to return one of eight different matrix norms, or one of\nan infinite number of vector norms (described below), depending on the value\nof the `ord` parameter.\n\nInput array. If `axis` is None, `x` must be 1-D or 2-D, unless `ord` is None.\nIf both `axis` and `ord` are None, the 2-norm of `x.ravel` will be returned.\n\nOrder of the norm (see table under `Notes`). inf means numpy\u2019s `inf` object.\nThe default is None.\n\nIf `axis` is an integer, it specifies the axis of `x` along which to compute\nthe vector norms. If `axis` is a 2-tuple, it specifies the axes that hold 2-D\nmatrices, and the matrix norms of these matrices are computed. If `axis` is\nNone then either a vector norm (when `x` is 1-D) or a matrix norm (when `x` is\n2-D) is returned. The default is None.\n\nNew in version 1.8.0.\n\nIf this is set to True, the axes which are normed over are left in the result\nas dimensions with size one. With this option the result will broadcast\ncorrectly against the original `x`.\n\nNew in version 1.10.0.\n\nNorm of the matrix or vector(s).\n\nSee also\n\nSimilar function in SciPy.\n\nFor values of `ord < 1`, the result is, strictly speaking, not a mathematical\n\u2018norm\u2019, but it may still be useful for various numerical purposes.\n\nThe following norms can be calculated:\n\nord\n\nnorm for matrices\n\nnorm for vectors\n\nNone\n\nFrobenius norm\n\n2-norm\n\n\u2018fro\u2019\n\nFrobenius norm\n\n\u2013\n\n\u2018nuc\u2019\n\nnuclear norm\n\n\u2013\n\ninf\n\nmax(sum(abs(x), axis=1))\n\nmax(abs(x))\n\n-inf\nmin(sum(abs(x), axis=1))\n\nmin(abs(x))\n\n0\n\n\u2013\n\nsum(x != 0)\n\n1\n\nmax(sum(abs(x), axis=0))\n\nas below\n\n-1\nmin(sum(abs(x), axis=0))\n\nas below\n\n2\n\n2-norm (largest sing. value)\n\nas below\n\n-2\nsmallest singular value\n\nas below\n\nother\n\n\u2013\n\nsum(abs(x)**ord)**(1./ord)\n\nThe Frobenius norm is given by [1]:\n\n\\\\(||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}\\\\)\n\nThe nuclear norm is the sum of the singular values.\n\nBoth the Frobenius and nuclear norm orders are only defined for matrices and\nraise a ValueError when `x.ndim != 2`.\n\nG. H. Golub and C. F. Van Loan, Matrix Computations, Baltimore, MD, Johns\nHopkins University Press, 1985, pg. 15\n\nUsing the `axis` argument to compute vector norms:\n\nUsing the `axis` argument to compute matrix norms:\n\n"}, {"name": "linalg.pinv()", "path": "reference/generated/numpy.linalg.pinv", "type": "numpy.linalg.pinv", "text": "\nCompute the (Moore-Penrose) pseudo-inverse of a matrix.\n\nCalculate the generalized inverse of a matrix using its singular-value\ndecomposition (SVD) and including all large singular values.\n\nChanged in version 1.14: Can now operate on stacks of matrices\n\nMatrix or stack of matrices to be pseudo-inverted.\n\nCutoff for small singular values. Singular values less than or equal to `rcond\n* largest_singular_value` are set to zero. Broadcasts against the stack of\nmatrices.\n\nIf True, `a` is assumed to be Hermitian (symmetric if real-valued), enabling a\nmore efficient method for finding singular values. Defaults to False.\n\nNew in version 1.17.0.\n\nThe pseudo-inverse of `a`. If `a` is a `matrix` instance, then so is `B`.\n\nIf the SVD computation does not converge.\n\nSee also\n\nSimilar function in SciPy.\n\nSimilar function in SciPy (SVD-based).\n\nCompute the (Moore-Penrose) pseudo-inverse of a Hermitian matrix.\n\nThe pseudo-inverse of a matrix A, denoted \\\\(A^+\\\\), is defined as: \u201cthe\nmatrix that \u2018solves\u2019 [the least-squares problem] \\\\(Ax = b\\\\),\u201d i.e., if\n\\\\(\\bar{x}\\\\) is said solution, then \\\\(A^+\\\\) is that matrix such that\n\\\\(\\bar{x} = A^+b\\\\).\n\nIt can be shown that if \\\\(Q_1 \\Sigma Q_2^T = A\\\\) is the singular value\ndecomposition of A, then \\\\(A^+ = Q_2 \\Sigma^+ Q_1^T\\\\), where \\\\(Q_{1,2}\\\\)\nare orthogonal matrices, \\\\(\\Sigma\\\\) is a diagonal matrix consisting of A\u2019s\nso-called singular values, (followed, typically, by zeros), and then\n\\\\(\\Sigma^+\\\\) is simply the diagonal matrix consisting of the reciprocals of\nA\u2019s singular values (again, followed by zeros). [1]\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, pp. 139-142.\n\nThe following example checks that `a * a+ * a == a` and `a+ * a * a+ == a+`:\n\n"}, {"name": "linalg.qr()", "path": "reference/generated/numpy.linalg.qr", "type": "numpy.linalg.qr", "text": "\nCompute the qr factorization of a matrix.\n\nFactor the matrix `a` as qr, where `q` is orthonormal and `r` is upper-\ntriangular.\n\nAn array-like object with the dimensionality of at least 2.\n\nIf K = min(M, N), then\n\n(\u2026, M, K), (\u2026, K, N) (default)\n\nThe options \u2018reduced\u2019, \u2018complete, and \u2018raw\u2019 are new in numpy 1.8, see the\nnotes for more information. The default is \u2018reduced\u2019, and to maintain backward\ncompatibility with earlier versions of numpy both it and the old default\n\u2018full\u2019 can be omitted. Note that array h returned in \u2018raw\u2019 mode is transposed\nfor calling Fortran. The \u2018economic\u2019 mode is deprecated. The modes \u2018full\u2019 and\n\u2018economic\u2019 may be passed using only the first letter for backwards\ncompatibility, but all others must be spelled out. See the Notes for more\nexplanation.\n\nA matrix with orthonormal columns. When mode = \u2018complete\u2019 the result is an\northogonal/unitary matrix depending on whether or not a is real/complex. The\ndeterminant may be either +/- 1 in that case. In case the number of dimensions\nin the input array is greater than 2 then a stack of the matrices with above\nproperties is returned.\n\nThe upper-triangular matrix or a stack of upper-triangular matrices if the\nnumber of dimensions in the input array is greater than 2.\n\nThe array h contains the Householder reflectors that generate q along with r.\nThe tau array contains scaling factors for the reflectors. In the deprecated\n\u2018economic\u2019 mode only h is returned.\n\nIf factoring fails.\n\nSee also\n\nSimilar function in SciPy.\n\nCompute RQ decomposition of a matrix.\n\nThis is an interface to the LAPACK routines `dgeqrf`, `zgeqrf`, `dorgqr`, and\n`zungqr`.\n\nFor more information on the qr factorization, see for example:\nhttps://en.wikipedia.org/wiki/QR_factorization\n\nSubclasses of `ndarray` are preserved except for the \u2018raw\u2019 mode. So if `a` is\nof type `matrix`, all the return values will be matrices too.\n\nNew \u2018reduced\u2019, \u2018complete\u2019, and \u2018raw\u2019 options for mode were added in NumPy\n1.8.0 and the old option \u2018full\u2019 was made an alias of \u2018reduced\u2019. In addition\nthe options \u2018full\u2019 and \u2018economic\u2019 were deprecated. Because \u2018full\u2019 was the\nprevious default and \u2018reduced\u2019 is the new default, backward compatibility can\nbe maintained by letting `mode` default. The \u2018raw\u2019 option was added so that\nLAPACK routines that can multiply arrays by q using the Householder reflectors\ncan be used. Note that in this case the returned arrays are of type np.double\nor np.cdouble and the h array is transposed to be FORTRAN compatible. No\nroutines using the \u2018raw\u2019 return are currently exposed by numpy, but some are\navailable in lapack_lite and just await the necessary work.\n\nExample illustrating a common use of `qr`: solving of least squares problems\n\nWhat are the least-squares-best `m` and `y0` in `y = y0 + mx` for the\nfollowing data: {(0,1), (1,0), (1,2), (2,1)}. (Graph the points and you\u2019ll see\nthat it should be y0 = 0, m = 1.) The answer is provided by solving the over-\ndetermined matrix equation `Ax = b`, where:\n\nIf A = qr such that q is orthonormal (which is always possible via Gram-\nSchmidt), then `x = inv(r) * (q.T) * b`. (In numpy practice, however, we\nsimply use `lstsq`.)\n\n"}, {"name": "linalg.slogdet()", "path": "reference/generated/numpy.linalg.slogdet", "type": "numpy.linalg.slogdet", "text": "\nCompute the sign and (natural) logarithm of the determinant of an array.\n\nIf an array has a very small or very large determinant, then a call to `det`\nmay overflow or underflow. This routine is more robust against such issues,\nbecause it computes the logarithm of the determinant rather than the\ndeterminant itself.\n\nInput array, has to be a square 2-D array.\n\nA number representing the sign of the determinant. For a real matrix, this is\n1, 0, or -1. For a complex matrix, this is a complex number with absolute\nvalue 1 (i.e., it is on the unit circle), or else 0.\n\nThe natural log of the absolute value of the determinant.\n\nSee also\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nNew in version 1.6.0.\n\nThe determinant is computed via LU factorization using the LAPACK routine\n`z/dgetrf`.\n\nThe determinant of a 2-D array `[[a, b], [c, d]]` is `ad - bc`:\n\nComputing log-determinants for a stack of matrices:\n\nThis routine succeeds where ordinary `det` does not:\n\n"}, {"name": "linalg.solve()", "path": "reference/generated/numpy.linalg.solve", "type": "numpy.linalg.solve", "text": "\nSolve a linear matrix equation, or system of linear scalar equations.\n\nComputes the \u201cexact\u201d solution, `x`, of the well-determined, i.e., full rank,\nlinear matrix equation `ax = b`.\n\nCoefficient matrix.\n\nOrdinate or \u201cdependent variable\u201d values.\n\nSolution to the system a x = b. Returned shape is identical to `b`.\n\nIf `a` is singular or not square.\n\nSee also\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe solutions are computed using LAPACK routine `_gesv`.\n\n`a` must be square and of full-rank, i.e., all rows (or, equivalently,\ncolumns) must be linearly independent; if either is not true, use `lstsq` for\nthe least-squares best \u201csolution\u201d of the system/equation.\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, pg. 22.\n\nSolve the system of equations `x0 + 2 * x1 = 1` and `3 * x0 + 5 * x1 = 2`:\n\nCheck that the solution is correct:\n\n"}, {"name": "linalg.svd()", "path": "reference/generated/numpy.linalg.svd", "type": "numpy.linalg.svd", "text": "\nSingular Value Decomposition.\n\nWhen `a` is a 2D array, it is factorized as `u @ np.diag(s) @ vh = (u * s) @\nvh`, where `u` and `vh` are 2D unitary arrays and `s` is a 1D array of `a`\u2019s\nsingular values. When `a` is higher-dimensional, SVD is applied in stacked\nmode as explained below.\n\nA real or complex array with `a.ndim >= 2`.\n\nIf True (default), `u` and `vh` have the shapes `(..., M, M)` and `(..., N,\nN)`, respectively. Otherwise, the shapes are `(..., M, K)` and `(..., K, N)`,\nrespectively, where `K = min(M, N)`.\n\nWhether or not to compute `u` and `vh` in addition to `s`. True by default.\n\nIf True, `a` is assumed to be Hermitian (symmetric if real-valued), enabling a\nmore efficient method for finding singular values. Defaults to False.\n\nNew in version 1.17.0.\n\nUnitary array(s). The first `a.ndim - 2` dimensions have the same size as\nthose of the input `a`. The size of the last two dimensions depends on the\nvalue of `full_matrices`. Only returned when `compute_uv` is True.\n\nVector(s) with the singular values, within each vector sorted in descending\norder. The first `a.ndim - 2` dimensions have the same size as those of the\ninput `a`.\n\nUnitary array(s). The first `a.ndim - 2` dimensions have the same size as\nthose of the input `a`. The size of the last two dimensions depends on the\nvalue of `full_matrices`. Only returned when `compute_uv` is True.\n\nIf SVD computation does not converge.\n\nSee also\n\nSimilar function in SciPy.\n\nCompute singular values of a matrix.\n\nChanged in version 1.8.0: Broadcasting rules apply, see the `numpy.linalg`\ndocumentation for details.\n\nThe decomposition is performed using LAPACK routine `_gesdd`.\n\nSVD is usually described for the factorization of a 2D matrix \\\\(A\\\\). The\nhigher-dimensional case will be discussed below. In the 2D case, SVD is\nwritten as \\\\(A = U S V^H\\\\), where \\\\(A = a\\\\), \\\\(U= u\\\\), \\\\(S=\n\\mathtt{np.diag}(s)\\\\) and \\\\(V^H = vh\\\\). The 1D array `s` contains the\nsingular values of `a` and `u` and `vh` are unitary. The rows of `vh` are the\neigenvectors of \\\\(A^H A\\\\) and the columns of `u` are the eigenvectors of\n\\\\(A A^H\\\\). In both cases the corresponding (possibly non-zero) eigenvalues\nare given by `s**2`.\n\nIf `a` has more than two dimensions, then broadcasting rules apply, as\nexplained in Linear algebra on several matrices at once. This means that SVD\nis working in \u201cstacked\u201d mode: it iterates over all indices of the first\n`a.ndim - 2` dimensions and for each combination SVD is applied to the last\ntwo indices. The matrix `a` can be reconstructed from the decomposition with\neither `(u * s[..., None, :]) @ vh` or `u @ (s[..., None] * vh)`. (The `@`\noperator can be replaced by the function `np.matmul` for python versions below\n3.5.)\n\nIf `a` is a `matrix` object (as opposed to an `ndarray`), then so are all the\nreturn values.\n\nReconstruction based on full SVD, 2D case:\n\nReconstruction based on reduced SVD, 2D case:\n\nReconstruction based on full SVD, 4D case:\n\nReconstruction based on reduced SVD, 4D case:\n\n"}, {"name": "linalg.tensorinv()", "path": "reference/generated/numpy.linalg.tensorinv", "type": "numpy.linalg.tensorinv", "text": "\nCompute the \u2018inverse\u2019 of an N-dimensional array.\n\nThe result is an inverse for `a` relative to the tensordot operation\n`tensordot(a, b, ind)`, i. e., up to floating-point accuracy,\n`tensordot(tensorinv(a), a, ind)` is the \u201cidentity\u201d tensor for the tensordot\noperation.\n\nTensor to \u2018invert\u2019. Its shape must be \u2018square\u2019, i. e., `prod(a.shape[:ind]) ==\nprod(a.shape[ind:])`.\n\nNumber of first indices that are involved in the inverse sum. Must be a\npositive integer, default is 2.\n\n`a`\u2019s tensordot inverse, shape `a.shape[ind:] + a.shape[:ind]`.\n\nIf `a` is singular or not \u2018square\u2019 (in the above sense).\n\nSee also\n\n"}, {"name": "linalg.tensorsolve()", "path": "reference/generated/numpy.linalg.tensorsolve", "type": "numpy.linalg.tensorsolve", "text": "\nSolve the tensor equation `a x = b` for x.\n\nIt is assumed that all indices of `x` are summed over in the product, together\nwith the rightmost indices of `a`, as is done in, for example, `tensordot(a,\nx, axes=b.ndim)`.\n\nCoefficient tensor, of shape `b.shape + Q`. `Q`, a tuple, equals the shape of\nthat sub-tensor of `a` consisting of the appropriate number of its rightmost\nindices, and must be such that `prod(Q) == prod(b.shape)` (in which sense `a`\nis said to be \u2018square\u2019).\n\nRight-hand tensor, which can be of any shape.\n\nAxes in `a` to reorder to the right, before inversion. If None (default), no\nreordering is done.\n\nIf `a` is singular or not \u2018square\u2019 (in the above sense).\n\nSee also\n\n"}, {"name": "Linear algebra (numpy.linalg)", "path": "reference/routines.linalg", "type": "Linear algebra ( \n      \n       numpy.linalg\n      \n      )", "text": "\nThe NumPy linear algebra functions rely on BLAS and LAPACK to provide\nefficient low level implementations of standard linear algebra algorithms.\nThose libraries may be provided by NumPy itself using C versions of a subset\nof their reference implementations but, when possible, highly optimized\nlibraries that take advantage of specialized processor functionality are\npreferred. Examples of such libraries are OpenBLAS, MKL (TM), and ATLAS.\nBecause those libraries are multithreaded and processor dependent,\nenvironmental variables and external packages such as threadpoolctl may be\nneeded to control the number of threads or specify the processor architecture.\n\nThe SciPy library also contains a `linalg` submodule, and there is overlap in\nthe functionality provided by the SciPy and NumPy submodules. SciPy contains\nfunctions not found in `numpy.linalg`, such as functions related to LU\ndecomposition and the Schur decomposition, multiple ways of calculating the\npseudoinverse, and matrix transcendentals such as the matrix logarithm. Some\nfunctions that exist in both have augmented functionality in `scipy.linalg`.\nFor example, `scipy.linalg.eig` can take a second matrix argument for solving\ngeneralized eigenvalue problems. Some functions in NumPy, however, have more\nflexible broadcasting options. For example, `numpy.linalg.solve` can handle\n\u201cstacked\u201d arrays, while `scipy.linalg.solve` accepts only a single square\narray as its first argument.\n\nNote\n\nThe term matrix as it is used on this page indicates a 2d `numpy.array`\nobject, and not a `numpy.matrix` object. The latter is no longer recommended,\neven for linear algebra. See the matrix object documentation for more\ninformation.\n\nIntroduced in NumPy 1.10.0, the `@` operator is preferable to other methods\nwhen computing the matrix product between 2d arrays. The `numpy.matmul`\nfunction implements the `@` operator.\n\n`dot`(a, b[, out])\n\nDot product of two arrays.\n\n`linalg.multi_dot`(arrays, *[, out])\n\nCompute the dot product of two or more arrays in a single function call, while\nautomatically selecting the fastest evaluation order.\n\n`vdot`(a, b, /)\n\nReturn the dot product of two vectors.\n\n`inner`(a, b, /)\n\nInner product of two arrays.\n\n`outer`(a, b[, out])\n\nCompute the outer product of two vectors.\n\n`matmul`(x1, x2, /[, out, casting, order, ...])\n\nMatrix product of two arrays.\n\n`tensordot`(a, b[, axes])\n\nCompute tensor dot product along specified axes.\n\n`einsum`(subscripts, *operands[, out, dtype, ...])\n\nEvaluates the Einstein summation convention on the operands.\n\n`einsum_path`(subscripts, *operands[, optimize])\n\nEvaluates the lowest cost contraction order for an einsum expression by\nconsidering the creation of intermediate arrays.\n\n`linalg.matrix_power`(a, n)\n\nRaise a square matrix to the (integer) power `n`.\n\n`kron`(a, b)\n\nKronecker product of two arrays.\n\n`linalg.cholesky`(a)\n\nCholesky decomposition.\n\n`linalg.qr`(a[, mode])\n\nCompute the qr factorization of a matrix.\n\n`linalg.svd`(a[, full_matrices, compute_uv, ...])\n\nSingular Value Decomposition.\n\n`linalg.eig`(a)\n\nCompute the eigenvalues and right eigenvectors of a square array.\n\n`linalg.eigh`(a[, UPLO])\n\nReturn the eigenvalues and eigenvectors of a complex Hermitian (conjugate\nsymmetric) or a real symmetric matrix.\n\n`linalg.eigvals`(a)\n\nCompute the eigenvalues of a general matrix.\n\n`linalg.eigvalsh`(a[, UPLO])\n\nCompute the eigenvalues of a complex Hermitian or real symmetric matrix.\n\n`linalg.norm`(x[, ord, axis, keepdims])\n\nMatrix or vector norm.\n\n`linalg.cond`(x[, p])\n\nCompute the condition number of a matrix.\n\n`linalg.det`(a)\n\nCompute the determinant of an array.\n\n`linalg.matrix_rank`(A[, tol, hermitian])\n\nReturn matrix rank of array using SVD method\n\n`linalg.slogdet`(a)\n\nCompute the sign and (natural) logarithm of the determinant of an array.\n\n`trace`(a[, offset, axis1, axis2, dtype, out])\n\nReturn the sum along diagonals of the array.\n\n`linalg.solve`(a, b)\n\nSolve a linear matrix equation, or system of linear scalar equations.\n\n`linalg.tensorsolve`(a, b[, axes])\n\nSolve the tensor equation `a x = b` for x.\n\n`linalg.lstsq`(a, b[, rcond])\n\nReturn the least-squares solution to a linear matrix equation.\n\n`linalg.inv`(a)\n\nCompute the (multiplicative) inverse of a matrix.\n\n`linalg.pinv`(a[, rcond, hermitian])\n\nCompute the (Moore-Penrose) pseudo-inverse of a matrix.\n\n`linalg.tensorinv`(a[, ind])\n\nCompute the 'inverse' of an N-dimensional array.\n\n`linalg.LinAlgError`\n\nGeneric Python-exception-derived object raised by linalg functions.\n\nNew in version 1.8.0.\n\nSeveral of the linear algebra routines listed above are able to compute\nresults for several matrices at once, if they are stacked into the same array.\n\nThis is indicated in the documentation via input parameter specifications such\nas `a : (..., M, M) array_like`. This means that if for instance given an\ninput array `a.shape == (N, M, M)`, it is interpreted as a \u201cstack\u201d of N\nmatrices, each of size M-by-M. Similar specification applies to return values,\nfor instance the determinant has `det : (...)` and will in this case return an\narray of shape `det(a).shape == (N,)`. This generalizes to linear algebra\noperations on higher-dimensional arrays: the last 1 or 2 dimensions of a\nmultidimensional array are interpreted as vectors or matrices, as appropriate\nfor each operation.\n\n"}, {"name": "Logic functions", "path": "reference/routines.logic", "type": "Logic functions", "text": "\n`all`(a[, axis, out, keepdims, where])\n\nTest whether all array elements along a given axis evaluate to True.\n\n`any`(a[, axis, out, keepdims, where])\n\nTest whether any array element along a given axis evaluates to True.\n\n`isfinite`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for finiteness (not infinity and not Not a Number).\n\n`isinf`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for positive or negative infinity.\n\n`isnan`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for NaN and return result as a boolean array.\n\n`isnat`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for NaT (not a time) and return result as a boolean array.\n\n`isneginf`(x[, out])\n\nTest element-wise for negative infinity, return result as bool array.\n\n`isposinf`(x[, out])\n\nTest element-wise for positive infinity, return result as bool array.\n\n`iscomplex`(x)\n\nReturns a bool array, where True if input element is complex.\n\n`iscomplexobj`(x)\n\nCheck for a complex type or an array of complex numbers.\n\n`isfortran`(a)\n\nCheck if the array is Fortran contiguous but not C contiguous.\n\n`isreal`(x)\n\nReturns a bool array, where True if input element is real.\n\n`isrealobj`(x)\n\nReturn True if x is a not complex type or an array of complex numbers.\n\n`isscalar`(element)\n\nReturns True if the type of `element` is a scalar type.\n\n`logical_and`(x1, x2, /[, out, where, ...])\n\nCompute the truth value of x1 AND x2 element-wise.\n\n`logical_or`(x1, x2, /[, out, where, casting, ...])\n\nCompute the truth value of x1 OR x2 element-wise.\n\n`logical_not`(x, /[, out, where, casting, ...])\n\nCompute the truth value of NOT x element-wise.\n\n`logical_xor`(x1, x2, /[, out, where, ...])\n\nCompute the truth value of x1 XOR x2, element-wise.\n\n`allclose`(a, b[, rtol, atol, equal_nan])\n\nReturns True if two arrays are element-wise equal within a tolerance.\n\n`isclose`(a, b[, rtol, atol, equal_nan])\n\nReturns a boolean array where two arrays are element-wise equal within a\ntolerance.\n\n`array_equal`(a1, a2[, equal_nan])\n\nTrue if two arrays have the same shape and elements, False otherwise.\n\n`array_equiv`(a1, a2)\n\nReturns True if input arrays are shape consistent and all elements equal.\n\n`greater`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 > x2) element-wise.\n\n`greater_equal`(x1, x2, /[, out, where, ...])\n\nReturn the truth value of (x1 >= x2) element-wise.\n\n`less`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 < x2) element-wise.\n\n`less_equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 <= x2) element-wise.\n\n`equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn (x1 == x2) element-wise.\n\n`not_equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn (x1 != x2) element-wise.\n\n"}, {"name": "ma.all()", "path": "reference/generated/numpy.ma.all", "type": "numpy.ma.all", "text": "\nReturns True if all elements evaluate to True.\n\nThe output array is masked where all the values along the given axis are\nmasked: if the output would have been a scalar and that all the values are\nmasked, then the output is `masked`.\n\nRefer to `numpy.all` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.allclose()", "path": "reference/generated/numpy.ma.allclose", "type": "numpy.ma.allclose", "text": "\nReturns True if two arrays are element-wise equal within a tolerance.\n\nThis function is equivalent to `allclose` except that masked values are\ntreated as equal (default) or unequal, depending on the `masked_equal`\nargument.\n\nInput arrays to compare.\n\nWhether masked values in `a` and `b` are considered equal (True) or not\n(False). They are considered equal by default.\n\nRelative tolerance. The relative difference is equal to `rtol * b`. Default is\n1e-5.\n\nAbsolute tolerance. The absolute difference is equal to `atol`. Default is\n1e-8.\n\nReturns True if the two arrays are equal within the given tolerance, False\notherwise. If either array contains NaN, then False is returned.\n\nSee also\n\nthe non-masked `allclose`.\n\nIf the following equation is element-wise True, then `allclose` returns True:\n\nReturn True if all elements of `a` and `b` are equal subject to given\ntolerances.\n\nMasked values are not compared directly.\n\n"}, {"name": "ma.allequal()", "path": "reference/generated/numpy.ma.allequal", "type": "numpy.ma.allequal", "text": "\nReturn True if all entries of a and b are equal, using fill_value as a truth\nvalue where either or both are masked.\n\nInput arrays to compare.\n\nWhether masked values in a or b are considered equal (True) or not (False).\n\nReturns True if the two arrays are equal within the given tolerance, False\notherwise. If either array contains NaN, then False is returned.\n\nSee also\n\n"}, {"name": "ma.anom()", "path": "reference/generated/numpy.ma.anom", "type": "numpy.ma.anom", "text": "\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\nReturns an array of anomalies, with the same shape as the input and where the\narithmetic mean is computed along the given axis.\n\nAxis over which the anomalies are taken. The default is to use the mean of the\nflattened array as reference.\n\nthe default is float32; for arrays of float types it is the same as the array\ntype.\n\nSee also\n\nCompute the mean of the array.\n\n"}, {"name": "ma.anomalies()", "path": "reference/generated/numpy.ma.anomalies", "type": "numpy.ma.anomalies", "text": "\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\nReturns an array of anomalies, with the same shape as the input and where the\narithmetic mean is computed along the given axis.\n\nAxis over which the anomalies are taken. The default is to use the mean of the\nflattened array as reference.\n\nthe default is float32; for arrays of float types it is the same as the array\ntype.\n\nSee also\n\nCompute the mean of the array.\n\n"}, {"name": "ma.any()", "path": "reference/generated/numpy.ma.any", "type": "numpy.ma.any", "text": "\nReturns True if any of the elements of `a` evaluate to True.\n\nMasked values are considered as False during computation.\n\nRefer to `numpy.any` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.append()", "path": "reference/generated/numpy.ma.append", "type": "numpy.ma.append", "text": "\nAppend values to the end of an array.\n\nNew in version 1.9.0.\n\nValues are appended to a copy of this array.\n\nThese values are appended to a copy of `a`. It must be of the correct shape\n(the same shape as `a`, excluding `axis`). If `axis` is not specified, `b` can\nbe any shape and will be flattened before use.\n\nThe axis along which `v` are appended. If `axis` is not given, both `a` and\n`b` are flattened before use.\n\nA copy of `a` with `b` appended to `axis`. Note that `append` does not occur\nin-place: a new array is allocated and filled. If `axis` is None, the result\nis a flattened array.\n\nSee also\n\nEquivalent function in the top-level NumPy module.\n\n"}, {"name": "ma.apply_along_axis()", "path": "reference/generated/numpy.ma.apply_along_axis", "type": "numpy.ma.apply_along_axis", "text": "\nApply a function to 1-D slices along the given axis.\n\nExecute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays and\n`a` is a 1-D slice of `arr` along `axis`.\n\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of `ii`, `jj`, and `kk` to a tuple of indices:\n\nEquivalently, eliminating the inner loop, this can be expressed as:\n\nThis function should accept 1-D arrays. It is applied to 1-D slices of `arr`\nalong the specified axis.\n\nAxis along which `arr` is sliced.\n\nInput array.\n\nAdditional arguments to `func1d`.\n\nAdditional named arguments to `func1d`.\n\nNew in version 1.9.0.\n\nThe output array. The shape of `out` is identical to the shape of `arr`,\nexcept along the `axis` dimension. This axis is removed, and replaced with new\ndimensions equal to the shape of the return value of `func1d`. So if `func1d`\nreturns a scalar `out` will have one fewer dimensions than `arr`.\n\nSee also\n\nApply a function repeatedly over multiple axes.\n\nFor a function that returns a 1D array, the number of dimensions in `outarr`\nis the same as `arr`.\n\nFor a function that returns a higher dimensional array, those dimensions are\ninserted in place of the `axis` dimension.\n\n"}, {"name": "ma.apply_over_axes()", "path": "reference/generated/numpy.ma.apply_over_axes", "type": "numpy.ma.apply_over_axes", "text": "\nApply a function repeatedly over multiple axes.\n\n`func` is called as `res = func(a, axis)`, where `axis` is the first element\nof `axes`. The result `res` of the function call must have either the same\ndimensions as `a` or one less dimension. If `res` has one less dimension than\n`a`, a dimension is inserted before `axis`. The call to `func` is then\nrepeated for each axis in `axes`, with `res` as the first argument.\n\nThis function must take two arguments, `func(a, axis)`.\n\nInput array.\n\nAxes over which `func` is applied; the elements must be integers.\n\nThe output array. The number of dimensions is the same as `a`, but the shape\ncan be different. This depends on whether `func` changes the shape of its\noutput with respect to its input.\n\nSee also\n\nApply a function to 1-D slices of an array along the given axis.\n\nTuple axis arguments to ufuncs are equivalent:\n\n"}, {"name": "ma.arange()", "path": "reference/generated/numpy.ma.arange", "type": "numpy.ma.arange", "text": "\nReturn evenly spaced values within a given interval.\n\nValues are generated within the half-open interval `[start, stop)` (in other\nwords, the interval including `start` but excluding `stop`). For integer\narguments the function is equivalent to the Python built-in `range` function,\nbut returns an ndarray rather than a list.\n\nWhen using a non-integer step, such as 0.1, it is often better to use\n`numpy.linspace`. See the warnings section below for more information.\n\nStart of interval. The interval includes this value. The default start value\nis 0.\n\nEnd of interval. The interval does not include this value, except in some\ncases where `step` is not an integer and floating point round-off affects the\nlength of `out`.\n\nSpacing between values. For any output `out`, this is the distance between two\nadjacent values, `out[i+1] - out[i]`. The default step size is 1. If `step` is\nspecified as a position argument, `start` must also be given.\n\nThe type of the output array. If `dtype` is not given, infer the data type\nfrom the other input arguments.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of evenly spaced values.\n\nFor floating point arguments, the length of the result is `ceil((stop -\nstart)/step)`. Because of floating point overflow, this rule may result in the\nlast element of `out` being greater than `stop`.\n\nWarning\n\nThe length of the output might not be numerically stable.\n\nAnother stability issue is due to the internal implementation of\n`numpy.arange`. The actual step value used to populate the array is\n`dtype(start + step) - dtype(start)` and not `step`. Precision loss can occur\nhere, due to casting or due to using floating points when `start` is much\nlarger than `step`. This can lead to unexpected behaviour. For example:\n\nIn such cases, the use of `numpy.linspace` should be preferred.\n\nSee also\n\nEvenly spaced numbers with careful handling of endpoints.\n\nArrays of evenly spaced numbers in N-dimensions.\n\nGrid-shaped arrays of evenly spaced numbers in N-dimensions.\n\n"}, {"name": "ma.argmax()", "path": "reference/generated/numpy.ma.argmax", "type": "numpy.ma.argmax", "text": "\nReturns array of indices of the maximum values along the given axis. Masked\nvalues are treated as if they had the value fill_value.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nmaximum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\n"}, {"name": "ma.argmin()", "path": "reference/generated/numpy.ma.argmin", "type": "numpy.ma.argmin", "text": "\nReturn array of indices to the minimum values along the given axis.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nminimum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\nIf multi-dimension input, returns a new ndarray of indices to the minimum\nvalues along the given axis. Otherwise, returns a scalar of index to the\nminimum values along the given axis.\n\n"}, {"name": "ma.argsort()", "path": "reference/generated/numpy.ma.argsort", "type": "numpy.ma.argsort", "text": "\nReturn an ndarray of indices that sort the array along the specified axis.\nMasked values are filled beforehand to `fill_value`.\n\nAxis along which to sort. If None, the default, the flattened array is used.\n\nChanged in version 1.13.0: Previously, the default was documented to be -1,\nbut that was in error. At some future date, the default will change to -1, as\noriginally intended. Until then, the axis should be given explicitly when\n`arr.ndim > 1`, to avoid a FutureWarning.\n\nThe sorting algorithm used.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. Not all fields need be specified.\n\nWhether missing values (if any) should be treated as the largest values (True)\nor the smallest values (False) When the array contains unmasked values at the\nsame extremes of the datatype, the ordering of these values and the masked\nvalues is undefined.\n\nValue used internally for the masked values. If `fill_value` is not None, it\nsupersedes `endwith`.\n\nArray of indices that sort `a` along the specified axis. In other words,\n`a[index_array]` yields a sorted `a`.\n\nSee also\n\nDescribes sorting algorithms used.\n\nIndirect stable sort with multiple keys.\n\nInplace sort.\n\nSee `sort` for notes on the different sorting algorithms.\n\n"}, {"name": "ma.around", "path": "reference/generated/numpy.ma.around", "type": "numpy.ma.around", "text": "\nRound an array to the given number of decimals.\n\nSee also\n\nequivalent function; see for details.\n\n"}, {"name": "ma.array()", "path": "reference/generated/numpy.ma.array", "type": "numpy.ma.array", "text": "\nAn array class with possibly masked values.\n\nMasked values of True exclude the corresponding element from any computation.\n\nConstruction:\n\nInput data.\n\nMask. Must be convertible to an array of booleans with the same shape as\n`data`. True indicates a masked (i.e. invalid) data.\n\nData type of the output. If `dtype` is None, the type of the data argument\n(`data.dtype`) is used. If `dtype` is not None and different from\n`data.dtype`, a copy is performed.\n\nWhether to copy the input data (True), or to use a reference instead. Default\nis False.\n\nWhether to return a subclass of `MaskedArray` if possible (True) or a plain\n`MaskedArray`. Default is True.\n\nMinimum number of dimensions. Default is 0.\n\nValue used to fill in the masked values when necessary. If None, a default\nbased on the data-type is used.\n\nWhether to combine `mask` with the mask of the input data, if any (True), or\nto use only `mask` for the output (False). Default is True.\n\nWhether to use a hard mask or not. With a hard mask, masked values cannot be\nunmasked. Default is False.\n\nWhether to force compression of an empty mask. Default is True.\n\nSpecify the order of the array. If order is \u2018C\u2019, then the array will be in\nC-contiguous order (last-index varies the fastest). If order is \u2018F\u2019, then the\nreturned array will be in Fortran-contiguous order (first-index varies the\nfastest). If order is \u2018A\u2019 (default), then the returned array may be in any\norder (either C-, Fortran-contiguous, or even discontiguous), unless a copy is\nrequired, in which case it will be C-contiguous.\n\nThe `mask` can be initialized with an array of boolean values with the same\nshape as `data`.\n\nAlternatively, the `mask` can be initialized to homogeneous boolean array with\nthe same shape as `data` by passing in a scalar boolean value:\n\nNote\n\nThe recommended practice for initializing `mask` with a scalar boolean value\nis to use `True`/`False` rather than `np.True_`/`np.False_`. The reason is\n`nomask` is represented internally as `np.False_`.\n\n"}, {"name": "ma.asanyarray()", "path": "reference/generated/numpy.ma.asanyarray", "type": "numpy.ma.asanyarray", "text": "\nConvert the input to a masked array, conserving subclasses.\n\nIf `a` is a subclass of `MaskedArray`, its class is conserved. No copy is\nperformed if the input is already an `ndarray`.\n\nInput data, in any form that can be converted to an array.\n\nBy default, the data-type is inferred from the input data.\n\nWhether to use row-major (\u2018C\u2019) or column-major (\u2018FORTRAN\u2019) memory\nrepresentation. Default is \u2018C\u2019.\n\nMaskedArray interpretation of `a`.\n\nSee also\n\nSimilar to `asanyarray`, but does not conserve subclass.\n\n"}, {"name": "ma.asarray()", "path": "reference/generated/numpy.ma.asarray", "type": "numpy.ma.asarray", "text": "\nConvert the input to a masked array of the given data-type.\n\nNo copy is performed if the input is already an `ndarray`. If `a` is a\nsubclass of `MaskedArray`, a base class `MaskedArray` is returned.\n\nInput data, in any form that can be converted to a masked array. This includes\nlists, lists of tuples, tuples, tuples of tuples, tuples of lists, ndarrays\nand masked arrays.\n\nBy default, the data-type is inferred from the input data.\n\nWhether to use row-major (\u2018C\u2019) or column-major (\u2018FORTRAN\u2019) memory\nrepresentation. Default is \u2018C\u2019.\n\nMasked array interpretation of `a`.\n\nSee also\n\nSimilar to `asarray`, but conserves subclasses.\n\n"}, {"name": "ma.atleast_1d()", "path": "reference/generated/numpy.ma.atleast_1d", "type": "numpy.ma.atleast_1d", "text": "\nConvert inputs to arrays with at least one dimension.\n\nScalar inputs are converted to 1-dimensional arrays, whilst higher-dimensional\ninputs are preserved.\n\nOne or more input arrays.\n\nAn array, or list of arrays, each with `a.ndim >= 1`. Copies are made only if\nnecessary.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.atleast_2d()", "path": "reference/generated/numpy.ma.atleast_2d", "type": "numpy.ma.atleast_2d", "text": "\nView inputs as arrays with at least two dimensions.\n\nOne or more array-like sequences. Non-array inputs are converted to arrays.\nArrays that already have two or more dimensions are preserved.\n\nAn array, or list of arrays, each with `a.ndim >= 2`. Copies are avoided where\npossible, and views with two or more dimensions are returned.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.atleast_3d()", "path": "reference/generated/numpy.ma.atleast_3d", "type": "numpy.ma.atleast_3d", "text": "\nView inputs as arrays with at least three dimensions.\n\nOne or more array-like sequences. Non-array inputs are converted to arrays.\nArrays that already have three or more dimensions are preserved.\n\nAn array, or list of arrays, each with `a.ndim >= 3`. Copies are avoided where\npossible, and views with three or more dimensions are returned. For example, a\n1-D array of shape `(N,)` becomes a view of shape `(1, N, 1)`, and a 2-D array\nof shape `(M, N)` becomes a view of shape `(M, N, 1)`.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.average()", "path": "reference/generated/numpy.ma.average", "type": "numpy.ma.average", "text": "\nReturn the weighted average of array over the given axis.\n\nData to be averaged. Masked entries are not taken into account in the\ncomputation.\n\nAxis along which to average `a`. If None, averaging is done over the flattened\narray.\n\nThe importance that each element has in the computation of the average. The\nweights array can either be 1-D (in which case its length must be the size of\n`a` along the given axis) or of the same shape as `a`. If `weights=None`, then\nall data in `a` are assumed to have a weight equal to one. The 1-D calculation\nis:\n\nThe only constraint on `weights` is that `sum(weights)` must not be 0.\n\nFlag indicating whether a tuple `(result, sum of weights)` should be returned\nas output (True), or just the result (False). Default is False.\n\nThe average along the specified axis. When returned is `True`, return a tuple\nwith the average as the first element and the sum of the weights as the second\nelement. The return type is `np.float64` if `a` is of integer type and floats\nsmaller than `float64`, or the input data-type, otherwise. If returned,\n`sum_of_weights` is always `float64`.\n\n"}, {"name": "ma.choose()", "path": "reference/generated/numpy.ma.choose", "type": "numpy.ma.choose", "text": "\nUse an index array to construct a new array from a list of choices.\n\nGiven an array of integers and a list of n choice arrays, this method will\ncreate a new array that merges each of the choice arrays. Where a value in\n`index` is i, the new array will have the value that choices[i] contains in\nthe same place.\n\nThis array must contain integers in `[0, n-1]`, where n is the number of\nchoices.\n\nChoice arrays. The index array and all of the choices should be broadcastable\nto the same shape.\n\nIf provided, the result will be inserted into this array. It should be of the\nappropriate shape and `dtype`.\n\nSpecifies how out-of-bounds indices will behave.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.clip()", "path": "reference/generated/numpy.ma.clip", "type": "numpy.ma.clip", "text": "\nClip (limit) the values in an array.\n\nGiven an interval, values outside the interval are clipped to the interval\nedges. For example, if an interval of `[0, 1]` is specified, values smaller\nthan 0 become 0, and values larger than 1 become 1.\n\nEquivalent to but faster than `np.minimum(a_max, np.maximum(a, a_min))`.\n\nNo check is performed to ensure `a_min < a_max`.\n\nArray containing elements to clip.\n\nMinimum and maximum value. If `None`, clipping is not performed on the\ncorresponding edge. Only one of `a_min` and `a_max` may be `None`. Both are\nbroadcast against `a`.\n\nThe results will be placed in this array. It may be the input array for in-\nplace clipping. `out` must be of the right shape to hold the output. Its type\nis preserved.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nNew in version 1.17.0.\n\nAn array with the elements of `a`, but where values < `a_min` are replaced\nwith `a_min`, and those > `a_max` with `a_max`.\n\nSee also\n\nWhen `a_min` is greater than `a_max`, `clip` returns an array in which all\nvalues are equal to `a_max`, as shown in the second example.\n\n"}, {"name": "ma.clump_masked()", "path": "reference/generated/numpy.ma.clump_masked", "type": "numpy.ma.clump_masked", "text": "\nReturns a list of slices corresponding to the masked clumps of a 1-D array. (A\n\u201cclump\u201d is defined as a contiguous region of the array).\n\nA one-dimensional masked array.\n\nThe list of slices, one for each continuous region of masked elements in `a`.\n\nSee also\n\nNew in version 1.4.0.\n\n"}, {"name": "ma.clump_unmasked()", "path": "reference/generated/numpy.ma.clump_unmasked", "type": "numpy.ma.clump_unmasked", "text": "\nReturn list of slices corresponding to the unmasked clumps of a 1-D array. (A\n\u201cclump\u201d is defined as a contiguous region of the array).\n\nA one-dimensional masked array.\n\nThe list of slices, one for each continuous region of unmasked elements in\n`a`.\n\nSee also\n\nNew in version 1.4.0.\n\n"}, {"name": "ma.column_stack()", "path": "reference/generated/numpy.ma.column_stack", "type": "numpy.ma.column_stack", "text": "\nStack 1-D arrays as columns into a 2-D array.\n\nTake a sequence of 1-D arrays and stack them as columns to make a single 2-D\narray. 2-D arrays are stacked as-is, just like with `hstack`. 1-D arrays are\nturned into 2-D columns first.\n\nArrays to stack. All of them must have the same first dimension.\n\nThe array formed by stacking the given arrays.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.common_fill_value()", "path": "reference/generated/numpy.ma.common_fill_value", "type": "numpy.ma.common_fill_value", "text": "\nReturn the common filling value of two masked arrays, if any.\n\nIf `a.fill_value == b.fill_value`, return the fill value, otherwise return\nNone.\n\nThe masked arrays for which to compare fill values.\n\nThe common fill value, or None.\n\n"}, {"name": "ma.compress_cols()", "path": "reference/generated/numpy.ma.compress_cols", "type": "numpy.ma.compress_cols", "text": "\nSuppress whole columns of a 2-D array that contain masked values.\n\nThis is equivalent to `np.ma.compress_rowcols(a, 1)`, see `compress_rowcols`\nfor details.\n\nSee also\n\n"}, {"name": "ma.compress_rowcols()", "path": "reference/generated/numpy.ma.compress_rowcols", "type": "numpy.ma.compress_rowcols", "text": "\nSuppress the rows and/or columns of a 2-D array that contain masked values.\n\nThe suppression behavior is selected with the `axis` parameter.\n\nThe array to operate on. If not a MaskedArray instance (or if no array\nelements are masked), `x` is interpreted as a MaskedArray with `mask` set to\n`nomask`. Must be a 2D array.\n\nAxis along which to perform the operation. Default is None.\n\nThe compressed array.\n\n"}, {"name": "ma.compress_rows()", "path": "reference/generated/numpy.ma.compress_rows", "type": "numpy.ma.compress_rows", "text": "\nSuppress whole rows of a 2-D array that contain masked values.\n\nThis is equivalent to `np.ma.compress_rowcols(a, 0)`, see `compress_rowcols`\nfor details.\n\nSee also\n\n"}, {"name": "ma.compressed()", "path": "reference/generated/numpy.ma.compressed", "type": "numpy.ma.compressed", "text": "\nReturn all the non-masked data as a 1-D array.\n\nThis function is equivalent to calling the \u201ccompressed\u201d method of a\n`ma.MaskedArray`, see `ma.MaskedArray.compressed` for details.\n\nSee also\n\nEquivalent method.\n\n"}, {"name": "ma.concatenate()", "path": "reference/generated/numpy.ma.concatenate", "type": "numpy.ma.concatenate", "text": "\nConcatenate a sequence of arrays along the given axis.\n\nThe arrays must have the same shape, except in the dimension corresponding to\n`axis` (the first, by default).\n\nThe axis along which the arrays will be joined. Default is 0.\n\nThe concatenated array with any masked entries preserved.\n\nSee also\n\nEquivalent function in the top-level NumPy module.\n\n"}, {"name": "ma.conjugate()", "path": "reference/generated/numpy.ma.conjugate", "type": "numpy.ma.conjugate", "text": "\nReturn the complex conjugate, element-wise.\n\nThe complex conjugate of a complex number is obtained by changing the sign of\nits imaginary part.\n\nInput value.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe complex conjugate of `x`, with same dtype as `y`. This is a scalar if `x`\nis a scalar.\n\n`conj` is an alias for `conjugate`:\n\n"}, {"name": "ma.copy()", "path": "reference/generated/numpy.ma.copy", "type": "numpy.ma.copy", "text": "\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior numpy.copyto\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "ma.corrcoef()", "path": "reference/generated/numpy.ma.corrcoef", "type": "numpy.ma.corrcoef", "text": "\nReturn Pearson product-moment correlation coefficients.\n\nExcept for the handling of missing data this function does the same as\n`numpy.corrcoef`. For more details and examples, see `numpy.corrcoef`.\n\nA 1-D or 2-D array containing multiple variables and observations. Each row of\n`x` represents a variable, and each column a single observation of all those\nvariables. Also see `rowvar` below.\n\nAn additional set of variables and observations. `y` has the same shape as\n`x`.\n\nIf `rowvar` is True (default), then each row represents a variable, with\nobservations in the columns. Otherwise, the relationship is transposed: each\ncolumn represents a variable, while the rows contain observations.\n\nHas no effect, do not use.\n\nDeprecated since version 1.10.0.\n\nIf True, masked values are propagated pair-wise: if a value is masked in `x`,\nthe corresponding value is masked in `y`. If False, raises an exception.\nBecause `bias` is deprecated, this argument needs to be treated as keyword\nonly to avoid a warning.\n\nHas no effect, do not use.\n\nDeprecated since version 1.10.0.\n\nSee also\n\nEquivalent function in top-level NumPy module.\n\nEstimate the covariance matrix.\n\nThis function accepts but discards arguments `bias` and `ddof`. This is for\nbackwards compatibility with previous versions of this function. These\narguments had no effect on the return values of the function and can be safely\nignored in this and previous versions of numpy.\n\n"}, {"name": "ma.count()", "path": "reference/generated/numpy.ma.count", "type": "numpy.ma.count", "text": "\nCount the non-masked elements of the array along the given axis.\n\nAxis or axes along which the count is performed. The default, None, performs\nthe count over all the dimensions of the input array. `axis` may be negative,\nin which case it counts from the last to the first axis.\n\nNew in version 1.10.0.\n\nIf this is a tuple of ints, the count is performed on multiple axes, instead\nof a single axis or all the axes as before.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nAn array with the same shape as the input array, with the specified axis\nremoved. If the array is a 0-d array, or if `axis` is None, a scalar is\nreturned.\n\nSee also\n\nCount masked elements in array or along a given axis.\n\nWhen the `axis` keyword is specified an array of appropriate size is returned.\n\n"}, {"name": "ma.count_masked()", "path": "reference/generated/numpy.ma.count_masked", "type": "numpy.ma.count_masked", "text": "\nCount the number of masked elements along the given axis.\n\nAn array with (possibly) masked elements.\n\nAxis along which to count. If None (default), a flattened version of the array\nis used.\n\nThe total number of masked elements (axis=None) or the number of masked\nelements along each slice of the given axis.\n\nSee also\n\nCount non-masked elements.\n\nWhen the `axis` keyword is used an array is returned.\n\n"}, {"name": "ma.cov()", "path": "reference/generated/numpy.ma.cov", "type": "numpy.ma.cov", "text": "\nEstimate the covariance matrix.\n\nExcept for the handling of missing data this function does the same as\n`numpy.cov`. For more details and examples, see `numpy.cov`.\n\nBy default, masked values are recognized as such. If `x` and `y` have the same\nshape, a common mask is allocated: if `x[i,j]` is masked, then `y[i,j]` will\nalso be masked. Setting `allow_masked` to False will raise an exception if\nvalues are missing in either of the input arrays.\n\nA 1-D or 2-D array containing multiple variables and observations. Each row of\n`x` represents a variable, and each column a single observation of all those\nvariables. Also see `rowvar` below.\n\nAn additional set of variables and observations. `y` has the same shape as\n`x`.\n\nIf `rowvar` is True (default), then each row represents a variable, with\nobservations in the columns. Otherwise, the relationship is transposed: each\ncolumn represents a variable, while the rows contain observations.\n\nDefault normalization (False) is by `(N-1)`, where `N` is the number of\nobservations given (unbiased estimate). If `bias` is True, then normalization\nis by `N`. This keyword can be overridden by the keyword `ddof` in numpy\nversions >= 1.5.\n\nIf True, masked values are propagated pair-wise: if a value is masked in `x`,\nthe corresponding value is masked in `y`. If False, raises a `ValueError`\nexception when some values are missing.\n\nIf not `None` normalization is by `(N - ddof)`, where `N` is the number of\nobservations; this overrides the value implied by `bias`. The default value is\n`None`.\n\nNew in version 1.5.\n\nRaised if some values are missing and `allow_masked` is False.\n\nSee also\n\n"}, {"name": "ma.cumprod()", "path": "reference/generated/numpy.ma.cumprod", "type": "numpy.ma.cumprod", "text": "\nReturn the cumulative product of the array elements over the given axis.\n\nMasked values are set to 1 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumprod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid MaskedArray !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.cumsum()", "path": "reference/generated/numpy.ma.cumsum", "type": "numpy.ma.cumsum", "text": "\nReturn the cumulative sum of the array elements over the given axis.\n\nMasked values are set to 0 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumsum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid `ma.MaskedArray` !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.default_fill_value()", "path": "reference/generated/numpy.ma.default_fill_value", "type": "numpy.ma.default_fill_value", "text": "\nReturn the default fill value for the argument object.\n\nThe default filling value depends on the datatype of the input array or the\ntype of the input scalar:\n\ndatatype\n\ndefault\n\nbool\n\nTrue\n\nint\n\n999999\n\nfloat\n\n1.e20\n\ncomplex\n\n1.e20+0j\n\nobject\n\n\u2018?\u2019\n\nstring\n\n\u2018N/A\u2019\n\nFor structured types, a structured scalar is returned, with each field the\ndefault fill value for its type.\n\nFor subarray types, the fill value is an array of the same size containing the\ndefault scalar fill value.\n\nThe array data-type or scalar for which the default fill value is returned.\n\nThe default fill value.\n\n"}, {"name": "ma.diag()", "path": "reference/generated/numpy.ma.diag", "type": "numpy.ma.diag", "text": "\nExtract a diagonal or construct a diagonal array.\n\nThis function is the equivalent of `numpy.diag` that takes masked values into\naccount, see `numpy.diag` for details.\n\nSee also\n\nEquivalent function for ndarrays.\n\n"}, {"name": "ma.diff()", "path": "reference/generated/numpy.ma.diff", "type": "numpy.ma.diff", "text": "\nCalculate the n-th discrete difference along the given axis.\n\nThe first difference is given by `out[i] = a[i+1] - a[i]` along the given\naxis, higher differences are calculated by using `diff` recursively.\n\nInput array\n\nThe number of times values are differenced. If zero, the input is returned as-\nis.\n\nThe axis along which the difference is taken, default is the last axis.\n\nValues to prepend or append to `a` along axis prior to performing the\ndifference. Scalar values are expanded to arrays with length 1 in the\ndirection of axis and the shape of the input array in along all other axes.\nOtherwise the dimension and shape must match `a` except along axis.\n\nNew in version 1.16.0.\n\nThe n-th differences. The shape of the output is the same as `a` except along\n`axis` where the dimension is smaller by `n`. The type of the output is the\nsame as the type of the difference between any two elements of `a`. This is\nthe same as the type of `a` in most cases. A notable exception is\n`datetime64`, which results in a `timedelta64` output array.\n\nSee also\n\nType is preserved for boolean arrays, so the result will contain `False` when\nconsecutive elements are the same and `True` when they differ.\n\nFor unsigned integer arrays, the results will also be unsigned. This should\nnot be surprising, as the result is consistent with calculating the difference\ndirectly:\n\nIf this is not desirable, then the array should be cast to a larger integer\ntype first:\n\n"}, {"name": "ma.dot()", "path": "reference/generated/numpy.ma.dot", "type": "numpy.ma.dot", "text": "\nReturn the dot product of two arrays.\n\nThis function is the equivalent of `numpy.dot` that takes masked values into\naccount. Note that `strict` and `out` are in different position than in the\nmethod version. In order to maintain compatibility with the corresponding\nmethod, it is recommended that the optional arguments be treated as keyword\nonly. At some point that may be mandatory.\n\nNote\n\nWorks only with 2-D arrays at the moment.\n\nInputs arrays.\n\nWhether masked data are propagated (True) or set to 0 (False) for the\ncomputation. Default is False. Propagating the mask means that if a masked\nvalue appears in a row or column, the whole row or column is considered\nmasked.\n\nOutput argument. This must have the exact kind that would be returned if it\nwas not used. In particular, it must have the right type, must be\nC-contiguous, and its dtype must be the dtype that would be returned for\n`dot(a,b)`. This is a performance feature. Therefore, if these conditions are\nnot met, an exception is raised, instead of attempting to be flexible.\n\nNew in version 1.10.2.\n\nSee also\n\nEquivalent function for ndarrays.\n\n"}, {"name": "ma.dstack()", "path": "reference/generated/numpy.ma.dstack", "type": "numpy.ma.dstack", "text": "\nStack arrays in sequence depth wise (along third axis).\n\nThis is equivalent to concatenation along the third axis after 2-D arrays of\nshape `(M,N)` have been reshaped to `(M,N,1)` and 1-D arrays of shape `(N,)`\nhave been reshaped to `(1,N,1)`. Rebuilds arrays divided by `dsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the third axis. 1-D or 2-D\narrays must have the same shape.\n\nThe array formed by stacking the given arrays, will be at least 3-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence horizontally (column wise).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit array along third axis.\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.ediff1d()", "path": "reference/generated/numpy.ma.ediff1d", "type": "numpy.ma.ediff1d", "text": "\nCompute the differences between consecutive elements of an array.\n\nThis function is the equivalent of `numpy.ediff1d` that takes masked values\ninto account, see `numpy.ediff1d` for details.\n\nSee also\n\nEquivalent function for ndarrays.\n\n"}, {"name": "ma.empty()", "path": "reference/generated/numpy.ma.empty", "type": "numpy.ma.empty", "text": "\nReturn a new array of given shape and type, without initializing entries.\n\nShape of the empty array, e.g., `(2, 3)` or `2`.\n\nDesired output data-type for the array, e.g, `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of uninitialized (arbitrary) data of the given shape, dtype, and order.\nObject arrays will be initialized to None.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn a new array setting values to one.\n\nReturn a new array setting values to zero.\n\nReturn a new array of given shape filled with value.\n\n`empty`, unlike `zeros`, does not set the array values to zero, and may\ntherefore be marginally faster. On the other hand, it requires the user to\nmanually set all the values in the array, and should be used with caution.\n\n"}, {"name": "ma.empty_like()", "path": "reference/generated/numpy.ma.empty_like", "type": "numpy.ma.empty_like", "text": "\nReturn a new array with the same shape and type as a given array.\n\nThe shape and data-type of `prototype` define these same attributes of the\nreturned array.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `prototype` is Fortran contiguous, \u2018C\u2019 otherwise.\n\u2018K\u2019 means match the layout of `prototype` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of\n`prototype`, otherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of uninitialized (arbitrary) data with the same shape and type as\n`prototype`.\n\nSee also\n\nReturn an array of ones with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new uninitialized array.\n\nThis function does not initialize the returned array; to do that use\n`zeros_like` or `ones_like` instead. It may be marginally faster than the\nfunctions that do set the array values.\n\n"}, {"name": "ma.expand_dims()", "path": "reference/generated/numpy.ma.expand_dims", "type": "numpy.ma.expand_dims", "text": "\nExpand the shape of an array.\n\nInsert a new axis that will appear at the `axis` position in the expanded\narray shape.\n\nInput array.\n\nPosition in the expanded axes where the new axis (or axes) is placed.\n\nDeprecated since version 1.13.0: Passing an axis where `axis > a.ndim` will be\ntreated as `axis == a.ndim`, and passing `axis < -a.ndim - 1` will be treated\nas `axis == 0`. This behavior is deprecated.\n\nChanged in version 1.18.0: A tuple of axes is now supported. Out of range axes\nas described above are now forbidden and raise an `AxisError`.\n\nView of `a` with the number of dimensions increased.\n\nSee also\n\nThe inverse operation, removing singleton dimensions\n\nInsert, remove, and combine dimensions, and resize existing ones\n\nThe following is equivalent to `x[np.newaxis, :]` or `x[np.newaxis]`:\n\nThe following is equivalent to `x[:, np.newaxis]`:\n\n`axis` may also be a tuple:\n\nNote that some examples may use `None` instead of `np.newaxis`. These are the\nsame objects:\n\n"}, {"name": "ma.filled()", "path": "reference/generated/numpy.ma.filled", "type": "numpy.ma.filled", "text": "\nReturn input as an array with masked data replaced by a fill value.\n\nIf `a` is not a `MaskedArray`, `a` itself is returned. If `a` is a\n`MaskedArray` and `fill_value` is None, `fill_value` is set to `a.fill_value`.\n\nAn input object.\n\nCan be scalar or non-scalar. If non-scalar, the resulting filled array should\nbe broadcastable over input array. Default is None.\n\nThe filled array.\n\nSee also\n\n"}, {"name": "ma.fix_invalid()", "path": "reference/generated/numpy.ma.fix_invalid", "type": "numpy.ma.fix_invalid", "text": "\nReturn input with invalid data masked and replaced by a fill value.\n\nInvalid data means values of `nan`, `inf`, etc.\n\nInput array, a (subclass of) ndarray.\n\nMask. Must be convertible to an array of booleans with the same shape as\n`data`. True indicates a masked (i.e. invalid) data.\n\nWhether to use a copy of `a` (True) or to fix `a` in place (False). Default is\nTrue.\n\nValue used for fixing invalid data. Default is None, in which case the\n`a.fill_value` is used.\n\nThe input array with invalid entries fixed.\n\nA copy is performed by default.\n\n"}, {"name": "ma.flatnotmasked_contiguous()", "path": "reference/generated/numpy.ma.flatnotmasked_contiguous", "type": "numpy.ma.flatnotmasked_contiguous", "text": "\nFind contiguous unmasked data in a masked array along the given axis.\n\nThe input array.\n\nA sorted sequence of `slice` objects (start index, end index).\n\nChanged in version 1.15.0: Now returns an empty list instead of None for a\nfully masked array\n\nSee also\n\nOnly accepts 2-D arrays at most.\n\n"}, {"name": "ma.flatnotmasked_edges()", "path": "reference/generated/numpy.ma.flatnotmasked_edges", "type": "numpy.ma.flatnotmasked_edges", "text": "\nFind the indices of the first and last unmasked values.\n\nExpects a 1-D `MaskedArray`, returns None if all values are masked.\n\nInput 1-D `MaskedArray`\n\nThe indices of first and last non-masked value in the array. Returns None if\nall values are masked.\n\nSee also\n\nOnly accepts 1-D arrays.\n\n"}, {"name": "ma.frombuffer()", "path": "reference/generated/numpy.ma.frombuffer", "type": "numpy.ma.frombuffer", "text": "\nInterpret a buffer as a 1-dimensional array.\n\nAn object that exposes the buffer interface.\n\nData-type of the returned array; default: float.\n\nNumber of items to read. `-1` means all data in the buffer.\n\nStart reading the buffer from this offset (in bytes); default: 0.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nIf the buffer has data that is not in machine byte-order, this should be\nspecified as part of the data-type, e.g.:\n\nThe data of the resulting array will not be byteswapped, but will be\ninterpreted correctly.\n\n"}, {"name": "ma.fromfunction()", "path": "reference/generated/numpy.ma.fromfunction", "type": "numpy.ma.fromfunction", "text": "\nConstruct an array by executing a function over each coordinate.\n\nThe resulting array therefore has a value `fn(x, y, z)` at coordinate `(x, y,\nz)`.\n\nThe function is called with N parameters, where N is the rank of `shape`. Each\nparameter represents the coordinates of the array varying along a specific\naxis. For example, if `shape` were `(2, 2)`, then the parameters would be\n`array([[0, 0], [1, 1]])` and `array([[0, 1], [0, 1]])`\n\nShape of the output array, which also determines the shape of the coordinate\narrays passed to `function`.\n\nData-type of the coordinate arrays passed to `function`. By default, `dtype`\nis float.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nThe result of the call to `function` is passed back directly. Therefore the\nshape of `fromfunction` is completely determined by `function`. If `function`\nreturns a scalar value, the shape of `fromfunction` would not match the\n`shape` parameter.\n\nSee also\n\nKeywords other than `dtype` are passed to `function`.\n\n"}, {"name": "ma.getdata()", "path": "reference/generated/numpy.ma.getdata", "type": "numpy.ma.getdata", "text": "\nReturn the data of a masked array as an ndarray.\n\nReturn the data of `a` (if any) as an ndarray if `a` is a `MaskedArray`, else\nreturn `a` as a ndarray or subclass (depending on `subok`) if not.\n\nInput `MaskedArray`, alternatively a ndarray or a subclass thereof.\n\nWhether to force the output to be a `pure` ndarray (False) or to return a\nsubclass of ndarray if appropriate (True, default).\n\nSee also\n\nReturn the mask of a masked array, or nomask.\n\nReturn the mask of a masked array, or full array of False.\n\nEquivalently use the `MaskedArray` `data` attribute.\n\n"}, {"name": "ma.getmask()", "path": "reference/generated/numpy.ma.getmask", "type": "numpy.ma.getmask", "text": "\nReturn the mask of a masked array, or nomask.\n\nReturn the mask of `a` as an ndarray if `a` is a `MaskedArray` and the mask is\nnot `nomask`, else return `nomask`. To guarantee a full array of booleans of\nthe same shape as a, use `getmaskarray`.\n\nInput `MaskedArray` for which the mask is required.\n\nSee also\n\nReturn the data of a masked array as an ndarray.\n\nReturn the mask of a masked array, or full array of False.\n\nEquivalently use the `MaskedArray` `mask` attribute.\n\nResult when mask == `nomask`\n\n"}, {"name": "ma.getmaskarray()", "path": "reference/generated/numpy.ma.getmaskarray", "type": "numpy.ma.getmaskarray", "text": "\nReturn the mask of a masked array, or full boolean array of False.\n\nReturn the mask of `arr` as an ndarray if `arr` is a `MaskedArray` and the\nmask is not `nomask`, else return a full boolean array of False of the same\nshape as `arr`.\n\nInput `MaskedArray` for which the mask is required.\n\nSee also\n\nReturn the mask of a masked array, or nomask.\n\nReturn the data of a masked array as an ndarray.\n\nResult when mask == `nomask`\n\n"}, {"name": "ma.harden_mask()", "path": "reference/generated/numpy.ma.harden_mask", "type": "numpy.ma.harden_mask", "text": "\nForce the mask to hard.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `harden_mask` sets `hardmask` to `True`.\n\nSee also\n\n"}, {"name": "ma.hsplit()", "path": "reference/generated/numpy.ma.hsplit", "type": "numpy.ma.hsplit", "text": "\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\nPlease refer to the `split` documentation. `hsplit` is equivalent to `split`\nwith `axis=1`, the array is always split along the second axis regardless of\nthe array dimension.\n\nSee also\n\nSplit an array into multiple sub-arrays of equal size.\n\nThe function is applied to both the _data and the _mask, if any.\n\nWith a higher dimensional array the split is still along the second axis.\n\n"}, {"name": "ma.hstack()", "path": "reference/generated/numpy.ma.hstack", "type": "numpy.ma.hstack", "text": "\nStack arrays in sequence horizontally (column wise).\n\nThis is equivalent to concatenation along the second axis, except for 1-D\narrays where it concatenates along the first axis. Rebuilds arrays divided by\n`hsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the second axis, except 1-D\narrays which can be any length.\n\nThe array formed by stacking the given arrays.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.identity()", "path": "reference/generated/numpy.ma.identity", "type": "numpy.ma.identity", "text": "\nReturn the identity array.\n\nThe identity array is a square array with ones on the main diagonal.\n\nNumber of rows (and columns) in `n` x `n` output.\n\nData-type of the output. Defaults to `float`.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\n`n` x `n` array with its main diagonal set to one, and all other elements 0.\n\n"}, {"name": "ma.indices()", "path": "reference/generated/numpy.ma.indices", "type": "numpy.ma.indices", "text": "\nReturn an array representing the indices of a grid.\n\nCompute an array where the subarrays contain index values 0, 1, \u2026 varying only\nalong the corresponding axis.\n\nThe shape of the grid.\n\nData type of the result.\n\nReturn a sparse representation of the grid instead of a dense representation.\nDefault is False.\n\nNew in version 1.17.\n\nReturns one array of grid indices, `grid.shape = (len(dimensions),) +\ntuple(dimensions)`.\n\nReturns a tuple of arrays, with `grid[i].shape = (1, ..., 1, dimensions[i], 1,\n..., 1)` with dimensions[i] in the ith place\n\nSee also\n\nThe output shape in the dense case is obtained by prepending the number of\ndimensions in front of the tuple of dimensions, i.e. if `dimensions` is a\ntuple `(r0, ..., rN-1)` of length `N`, the output shape is `(N, r0, ...,\nrN-1)`.\n\nThe subarrays `grid[k]` contains the N-D array of indices along the `k-th`\naxis. Explicitly:\n\nThe indices can be used as an index into an array.\n\nNote that it would be more straightforward in the above example to extract the\nrequired elements directly with `x[:2, :3]`.\n\nIf sparse is set to true, the grid will be returned in a sparse\nrepresentation.\n\n"}, {"name": "ma.inner()", "path": "reference/generated/numpy.ma.inner", "type": "numpy.ma.inner", "text": "\nInner product of two arrays.\n\nOrdinary inner product of vectors for 1-D arrays (without complex\nconjugation), in higher dimensions a sum product over the last axes.\n\nIf `a` and `b` are nonscalar, their last dimensions must match.\n\nIf `a` and `b` are both scalars or both 1-D arrays then a scalar is returned;\notherwise an array is returned. `out.shape = (*a.shape[:-1], *b.shape[:-1])`\n\nIf both `a` and `b` are nonscalar and their last dimensions have different\nsizes.\n\nSee also\n\nSum products over arbitrary axes.\n\nGeneralised matrix product, using second last dimension of `b`.\n\nEinstein summation convention.\n\nMasked values are replaced by 0.\n\nFor vectors (1-D arrays) it computes the ordinary inner-product:\n\nMore generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`:\n\nor explicitly:\n\nIn addition `a` or `b` may be scalars, in which case:\n\nOrdinary inner product for vectors:\n\nSome multidimensional examples:\n\nAn example where `b` is a scalar:\n\n"}, {"name": "ma.innerproduct()", "path": "reference/generated/numpy.ma.innerproduct", "type": "numpy.ma.innerproduct", "text": "\nInner product of two arrays.\n\nOrdinary inner product of vectors for 1-D arrays (without complex\nconjugation), in higher dimensions a sum product over the last axes.\n\nIf `a` and `b` are nonscalar, their last dimensions must match.\n\nIf `a` and `b` are both scalars or both 1-D arrays then a scalar is returned;\notherwise an array is returned. `out.shape = (*a.shape[:-1], *b.shape[:-1])`\n\nIf both `a` and `b` are nonscalar and their last dimensions have different\nsizes.\n\nSee also\n\nSum products over arbitrary axes.\n\nGeneralised matrix product, using second last dimension of `b`.\n\nEinstein summation convention.\n\nMasked values are replaced by 0.\n\nFor vectors (1-D arrays) it computes the ordinary inner-product:\n\nMore generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`:\n\nor explicitly:\n\nIn addition `a` or `b` may be scalars, in which case:\n\nOrdinary inner product for vectors:\n\nSome multidimensional examples:\n\nAn example where `b` is a scalar:\n\n"}, {"name": "ma.is_mask()", "path": "reference/generated/numpy.ma.is_mask", "type": "numpy.ma.is_mask", "text": "\nReturn True if m is a valid, standard mask.\n\nThis function does not check the contents of the input, only that the type is\nMaskType. In particular, this function returns False if the mask has a\nflexible dtype.\n\nArray to test.\n\nTrue if `m.dtype.type` is MaskType, False otherwise.\n\nSee also\n\nTest whether input is an instance of MaskedArray.\n\nInput must be an ndarray (or have similar attributes) for it to be considered\na valid mask.\n\nArrays with complex dtypes don\u2019t return True.\n\n"}, {"name": "ma.is_masked()", "path": "reference/generated/numpy.ma.is_masked", "type": "numpy.ma.is_masked", "text": "\nDetermine whether input has masked values.\n\nAccepts any object as input, but always returns False unless the input is a\nMaskedArray containing masked values.\n\nArray to check for masked values.\n\nTrue if `x` is a MaskedArray with masked values, False otherwise.\n\nAlways returns False if `x` isn\u2019t a MaskedArray.\n\n"}, {"name": "ma.isarray()", "path": "reference/generated/numpy.ma.isarray", "type": "numpy.ma.isarray", "text": "\nTest whether input is an instance of MaskedArray.\n\nThis function returns True if `x` is an instance of MaskedArray and returns\nFalse otherwise. Any object is accepted as input.\n\nObject to test.\n\nTrue if `x` is a MaskedArray.\n\nSee also\n\nAlias to isMaskedArray.\n\nAlias to isMaskedArray.\n\n"}, {"name": "ma.isMA()", "path": "reference/generated/numpy.ma.isma", "type": "numpy.ma.isMA", "text": "\nTest whether input is an instance of MaskedArray.\n\nThis function returns True if `x` is an instance of MaskedArray and returns\nFalse otherwise. Any object is accepted as input.\n\nObject to test.\n\nTrue if `x` is a MaskedArray.\n\nSee also\n\nAlias to isMaskedArray.\n\nAlias to isMaskedArray.\n\n"}, {"name": "ma.isMaskedArray()", "path": "reference/generated/numpy.ma.ismaskedarray", "type": "numpy.ma.isMaskedArray", "text": "\nTest whether input is an instance of MaskedArray.\n\nThis function returns True if `x` is an instance of MaskedArray and returns\nFalse otherwise. Any object is accepted as input.\n\nObject to test.\n\nTrue if `x` is a MaskedArray.\n\nSee also\n\nAlias to isMaskedArray.\n\nAlias to isMaskedArray.\n\n"}, {"name": "ma.make_mask()", "path": "reference/generated/numpy.ma.make_mask", "type": "numpy.ma.make_mask", "text": "\nCreate a boolean mask from an array.\n\nReturn `m` as a boolean mask, creating a copy if necessary or requested. The\nfunction can accept any sequence that is convertible to integers, or `nomask`.\nDoes not require that contents must be 0s and 1s, values of 0 are interpreted\nas False, everything else as True.\n\nPotential mask.\n\nWhether to return a copy of `m` (True) or `m` itself (False).\n\nWhether to shrink `m` to `nomask` if all its values are False.\n\nData-type of the output mask. By default, the output mask has a dtype of\nMaskType (bool). If the dtype is flexible, each field has a boolean dtype.\nThis is ignored when `m` is `nomask`, in which case `nomask` is always\nreturned.\n\nA boolean mask derived from `m`.\n\nEffect of the `shrink` parameter.\n\nUsing a flexible `dtype`.\n\n"}, {"name": "ma.make_mask_descr()", "path": "reference/generated/numpy.ma.make_mask_descr", "type": "numpy.ma.make_mask_descr", "text": "\nConstruct a dtype description list from a given dtype.\n\nReturns a new dtype object, with the type of all fields in `ndtype` to a\nboolean type. Field names are not altered.\n\nThe dtype to convert.\n\nA dtype that looks like `ndtype`, the type of all fields is boolean.\n\n"}, {"name": "ma.make_mask_none()", "path": "reference/generated/numpy.ma.make_mask_none", "type": "numpy.ma.make_mask_none", "text": "\nReturn a boolean mask of the given shape, filled with False.\n\nThis function returns a boolean ndarray with all entries False, that can be\nused in common mask manipulations. If a complex dtype is specified, the type\nof each field is converted to a boolean type.\n\nA tuple indicating the shape of the mask.\n\nIf None, use a MaskType instance. Otherwise, use a new datatype with the same\nfields as `dtype`, converted to boolean types.\n\nAn ndarray of appropriate shape and dtype, filled with False.\n\nSee also\n\nCreate a boolean mask from an array.\n\nConstruct a dtype description list from a given dtype.\n\nDefining a more complex dtype.\n\n"}, {"name": "ma.mask_cols()", "path": "reference/generated/numpy.ma.mask_cols", "type": "numpy.ma.mask_cols", "text": "\nMask columns of a 2D array that contain masked values.\n\nThis function is a shortcut to `mask_rowcols` with `axis` equal to 1.\n\nSee also\n\nMask rows and/or columns of a 2D array.\n\nMask where a condition is met.\n\n"}, {"name": "ma.mask_or()", "path": "reference/generated/numpy.ma.mask_or", "type": "numpy.ma.mask_or", "text": "\nCombine two masks with the `logical_or` operator.\n\nThe result may be a view on `m1` or `m2` if the other is `nomask` (i.e.\nFalse).\n\nInput masks.\n\nIf copy is False and one of the inputs is `nomask`, return a view of the other\ninput mask. Defaults to False.\n\nWhether to shrink the output to `nomask` if all its values are False. Defaults\nto True.\n\nThe result masks values that are masked in either `m1` or `m2`.\n\nIf `m1` and `m2` have different flexible dtypes.\n\n"}, {"name": "ma.mask_rowcols()", "path": "reference/generated/numpy.ma.mask_rowcols", "type": "numpy.ma.mask_rowcols", "text": "\nMask rows and/or columns of a 2D array that contain masked values.\n\nMask whole rows and/or columns of a 2D array that contain masked values. The\nmasking behavior is selected using the `axis` parameter.\n\nThe array to mask. If not a MaskedArray instance (or if no array elements are\nmasked). The result is a MaskedArray with `mask` set to `nomask` (False). Must\nbe a 2D array.\n\nAxis along which to perform the operation. If None, applies to a flattened\nversion of the array.\n\nA modified version of the input array, masked depending on the value of the\n`axis` parameter.\n\nIf input array `a` is not 2D.\n\nSee also\n\nMask rows of a 2D array that contain masked values.\n\nMask cols of a 2D array that contain masked values.\n\nMask where a condition is met.\n\nThe input array\u2019s mask is modified by this function.\n\n"}, {"name": "ma.mask_rows()", "path": "reference/generated/numpy.ma.mask_rows", "type": "numpy.ma.mask_rows", "text": "\nMask rows of a 2D array that contain masked values.\n\nThis function is a shortcut to `mask_rowcols` with `axis` equal to 0.\n\nSee also\n\nMask rows and/or columns of a 2D array.\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_all()", "path": "reference/generated/numpy.ma.masked_all", "type": "numpy.ma.masked_all", "text": "\nEmpty masked array with all elements masked.\n\nReturn an empty masked array of the given shape and dtype, where all the data\nare masked.\n\nShape of the required MaskedArray.\n\nData type of the output.\n\nA masked array with all data masked.\n\nSee also\n\nEmpty masked array modelled on an existing array.\n\nThe `dtype` parameter defines the underlying data type.\n\n"}, {"name": "ma.masked_all_like()", "path": "reference/generated/numpy.ma.masked_all_like", "type": "numpy.ma.masked_all_like", "text": "\nEmpty masked array with the properties of an existing array.\n\nReturn an empty masked array of the same shape and dtype as the array `arr`,\nwhere all the data are masked.\n\nAn array describing the shape and dtype of the required MaskedArray.\n\nA masked array with all data masked.\n\nIf `arr` doesn\u2019t have a shape attribute (i.e. not an ndarray)\n\nSee also\n\nEmpty masked array with all elements masked.\n\nThe dtype of the masked array matches the dtype of `arr`.\n\n"}, {"name": "ma.masked_equal()", "path": "reference/generated/numpy.ma.masked_equal", "type": "numpy.ma.masked_equal", "text": "\nMask an array where equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x ==\nvalue). For floating point arrays, consider using `masked_values(x, value)`.\n\nSee also\n\nMask where a condition is met.\n\nMask using floating point equality.\n\n"}, {"name": "ma.masked_greater()", "path": "reference/generated/numpy.ma.masked_greater", "type": "numpy.ma.masked_greater", "text": "\nMask an array where greater than a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x > value).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_greater_equal()", "path": "reference/generated/numpy.ma.masked_greater_equal", "type": "numpy.ma.masked_greater_equal", "text": "\nMask an array where greater than or equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x >=\nvalue).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_inside()", "path": "reference/generated/numpy.ma.masked_inside", "type": "numpy.ma.masked_inside", "text": "\nMask an array inside a given interval.\n\nShortcut to `masked_where`, where `condition` is True for `x` inside the\ninterval [v1,v2] (v1 <= x <= v2). The boundaries `v1` and `v2` can be given in\neither order.\n\nSee also\n\nMask where a condition is met.\n\nThe array `x` is prefilled with its filling value.\n\nThe order of `v1` and `v2` doesn\u2019t matter.\n\n"}, {"name": "ma.masked_invalid()", "path": "reference/generated/numpy.ma.masked_invalid", "type": "numpy.ma.masked_invalid", "text": "\nMask an array where invalid values occur (NaNs or infs).\n\nThis function is a shortcut to `masked_where`, with `condition` =\n~(np.isfinite(a)). Any pre-existing mask is conserved. Only applies to arrays\nwith a dtype where NaNs or infs make sense (i.e. floating point types), but\naccepts any array_like object.\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_less()", "path": "reference/generated/numpy.ma.masked_less", "type": "numpy.ma.masked_less", "text": "\nMask an array where less than a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x < value).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_less_equal()", "path": "reference/generated/numpy.ma.masked_less_equal", "type": "numpy.ma.masked_less_equal", "text": "\nMask an array where less than or equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x <=\nvalue).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_not_equal()", "path": "reference/generated/numpy.ma.masked_not_equal", "type": "numpy.ma.masked_not_equal", "text": "\nMask an array where `not` equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x !=\nvalue).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_object()", "path": "reference/generated/numpy.ma.masked_object", "type": "numpy.ma.masked_object", "text": "\nMask the array `x` where the data are exactly equal to value.\n\nThis function is similar to `masked_values`, but only suitable for object\narrays: for floating point, use `masked_values` instead.\n\nArray to mask\n\nComparison value\n\nWhether to return a copy of `x`.\n\nWhether to collapse a mask full of False to nomask\n\nThe result of masking `x` where equal to `value`.\n\nSee also\n\nMask where a condition is met.\n\nMask where equal to a given value (integers).\n\nMask using floating point equality.\n\nNote that `mask` is set to `nomask` if possible.\n\n"}, {"name": "ma.masked_outside()", "path": "reference/generated/numpy.ma.masked_outside", "type": "numpy.ma.masked_outside", "text": "\nMask an array outside a given interval.\n\nShortcut to `masked_where`, where `condition` is True for `x` outside the\ninterval [v1,v2] (x < v1)|(x > v2). The boundaries `v1` and `v2` can be given\nin either order.\n\nSee also\n\nMask where a condition is met.\n\nThe array `x` is prefilled with its filling value.\n\nThe order of `v1` and `v2` doesn\u2019t matter.\n\n"}, {"name": "ma.masked_values()", "path": "reference/generated/numpy.ma.masked_values", "type": "numpy.ma.masked_values", "text": "\nMask using floating point equality.\n\nReturn a MaskedArray, masked where the data in array `x` are approximately\nequal to `value`, determined using `isclose`. The default tolerances for\n`masked_values` are the same as those for `isclose`.\n\nFor integer types, exact equality is used, in the same way as `masked_equal`.\n\nThe fill_value is set to `value` and the mask is set to `nomask` if possible.\n\nArray to mask.\n\nMasking value.\n\nTolerance parameters passed on to `isclose`\n\nWhether to return a copy of `x`.\n\nWhether to collapse a mask full of False to `nomask`.\n\nThe result of masking `x` where approximately equal to `value`.\n\nSee also\n\nMask where a condition is met.\n\nMask where equal to a given value (integers).\n\nNote that `mask` is set to `nomask` if possible.\n\nFor integers, the fill value will be different in general to the result of\n`masked_equal`.\n\n"}, {"name": "ma.masked_where()", "path": "reference/generated/numpy.ma.masked_where", "type": "numpy.ma.masked_where", "text": "\nMask an array where a condition is met.\n\nReturn `a` as an array masked where `condition` is True. Any masked values of\n`a` or `condition` are also masked in the output.\n\nMasking condition. When `condition` tests floating point values for equality,\nconsider using `masked_values` instead.\n\nArray to mask.\n\nIf True (default) make a copy of `a` in the result. If False modify `a` in\nplace and return a view.\n\nThe result of masking `a` where `condition` is True.\n\nSee also\n\nMask using floating point equality.\n\nMask where equal to a given value.\n\nMask where `not` equal to a given value.\n\nMask where less than or equal to a given value.\n\nMask where greater than or equal to a given value.\n\nMask where less than a given value.\n\nMask where greater than a given value.\n\nMask inside a given interval.\n\nMask outside a given interval.\n\nMask invalid values (NaNs or infs).\n\nMask array `b` conditional on `a`.\n\nEffect of the `copy` argument.\n\nWhen `condition` or `a` contain masked values.\n\n"}, {"name": "ma.MaskedArray.__abs__()", "path": "reference/generated/numpy.ma.maskedarray.__abs__", "type": "Masked arrays", "text": "\nmethod\n\n"}, {"name": "ma.MaskedArray.__add__()", "path": "reference/generated/numpy.ma.maskedarray.__add__", "type": "Masked arrays", "text": "\nmethod\n\nAdd self to other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__and__()", "path": "reference/generated/numpy.ma.maskedarray.__and__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self&value.\n\n"}, {"name": "ma.MaskedArray.__array__()", "path": "reference/generated/numpy.ma.maskedarray.__array__", "type": "Masked arrays", "text": "\nmethod\n\nReturns either a new reference to self if dtype is not given or a new array of\nprovided data type if dtype is different from the current dtype of the array.\n\n"}, {"name": "ma.MaskedArray.__array_priority__", "path": "reference/generated/numpy.ma.maskedarray.__array_priority__", "type": "Masked arrays", "text": "\nattribute\n\n"}, {"name": "ma.MaskedArray.__array_wrap__()", "path": "reference/generated/numpy.ma.maskedarray.__array_wrap__", "type": "Masked arrays", "text": "\nmethod\n\nSpecial hook for ufuncs.\n\nWraps the numpy array and sets the mask according to context.\n\n"}, {"name": "ma.MaskedArray.__bool__()", "path": "reference/generated/numpy.ma.maskedarray.__bool__", "type": "Masked arrays", "text": "\nmethod\n\nself != 0\n\n"}, {"name": "ma.MaskedArray.__contains__()", "path": "reference/generated/numpy.ma.maskedarray.__contains__", "type": "Masked arrays", "text": "\nmethod\n\nReturn key in self.\n\n"}, {"name": "ma.MaskedArray.__copy__()", "path": "reference/generated/numpy.ma.maskedarray.__copy__", "type": "Masked arrays", "text": "\nmethod\n\nUsed if `copy.copy` is called on an array. Returns a copy of the array.\n\nEquivalent to `a.copy(order='K')`.\n\n"}, {"name": "ma.MaskedArray.__deepcopy__()", "path": "reference/generated/numpy.ma.maskedarray.__deepcopy__", "type": "Masked arrays", "text": "\nmethod\n\nUsed if `copy.deepcopy` is called on an array.\n\n"}, {"name": "ma.MaskedArray.__delitem__()", "path": "reference/generated/numpy.ma.maskedarray.__delitem__", "type": "Masked arrays", "text": "\nmethod\n\nDelete self[key].\n\n"}, {"name": "ma.MaskedArray.__div__()", "path": "reference/generated/numpy.ma.maskedarray.__div__", "type": "Masked arrays", "text": "\nmethod\n\nDivide other into self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__divmod__()", "path": "reference/generated/numpy.ma.maskedarray.__divmod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn divmod(self, value).\n\n"}, {"name": "ma.MaskedArray.__eq__()", "path": "reference/generated/numpy.ma.maskedarray.__eq__", "type": "Masked arrays", "text": "\nmethod\n\nCheck whether other equals self elementwise.\n\nWhen either of the elements is masked, the result is masked as well, but the\nunderlying boolean data are still set, with self and other considered equal if\nboth are masked, and unequal otherwise.\n\nFor structured arrays, all fields are combined, with masked values ignored.\nThe result is masked if all fields were masked, with self and other considered\nequal only if both were fully masked.\n\n"}, {"name": "ma.MaskedArray.__float__()", "path": "reference/generated/numpy.ma.maskedarray.__float__", "type": "Masked arrays", "text": "\nmethod\n\nConvert to float.\n\n"}, {"name": "ma.MaskedArray.__floordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__floordiv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide other into self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__ge__()", "path": "reference/generated/numpy.ma.maskedarray.__ge__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>=value.\n\n"}, {"name": "ma.MaskedArray.__getitem__()", "path": "reference/generated/numpy.ma.maskedarray.__getitem__", "type": "Masked arrays", "text": "\nmethod\n\nx.__getitem__(y) <==> x[y]\n\nReturn the item described by i, as a masked array.\n\n"}, {"name": "ma.MaskedArray.__getstate__()", "path": "reference/generated/numpy.ma.maskedarray.__getstate__", "type": "Masked arrays", "text": "\nmethod\n\nReturn the internal state of the masked array, for pickling purposes.\n\n"}, {"name": "ma.MaskedArray.__gt__()", "path": "reference/generated/numpy.ma.maskedarray.__gt__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>value.\n\n"}, {"name": "ma.MaskedArray.__iadd__()", "path": "reference/generated/numpy.ma.maskedarray.__iadd__", "type": "Masked arrays", "text": "\nmethod\n\nAdd other to self in-place.\n\n"}, {"name": "ma.MaskedArray.__iand__()", "path": "reference/generated/numpy.ma.maskedarray.__iand__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self&=value.\n\n"}, {"name": "ma.MaskedArray.__idiv__()", "path": "reference/generated/numpy.ma.maskedarray.__idiv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__ifloordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__ifloordiv__", "type": "Masked arrays", "text": "\nmethod\n\nFloor divide self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__ilshift__()", "path": "reference/generated/numpy.ma.maskedarray.__ilshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<<=value.\n\n"}, {"name": "ma.MaskedArray.__imod__()", "path": "reference/generated/numpy.ma.maskedarray.__imod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self%=value.\n\n"}, {"name": "ma.MaskedArray.__imul__()", "path": "reference/generated/numpy.ma.maskedarray.__imul__", "type": "Masked arrays", "text": "\nmethod\n\nMultiply self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__int__()", "path": "reference/generated/numpy.ma.maskedarray.__int__", "type": "Masked arrays", "text": "\nmethod\n\nConvert to int.\n\n"}, {"name": "ma.MaskedArray.__ior__()", "path": "reference/generated/numpy.ma.maskedarray.__ior__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self|=value.\n\n"}, {"name": "ma.MaskedArray.__ipow__()", "path": "reference/generated/numpy.ma.maskedarray.__ipow__", "type": "Masked arrays", "text": "\nmethod\n\nRaise self to the power other, in place.\n\n"}, {"name": "ma.MaskedArray.__irshift__()", "path": "reference/generated/numpy.ma.maskedarray.__irshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>>=value.\n\n"}, {"name": "ma.MaskedArray.__isub__()", "path": "reference/generated/numpy.ma.maskedarray.__isub__", "type": "Masked arrays", "text": "\nmethod\n\nSubtract other from self in-place.\n\n"}, {"name": "ma.MaskedArray.__itruediv__()", "path": "reference/generated/numpy.ma.maskedarray.__itruediv__", "type": "Masked arrays", "text": "\nmethod\n\nTrue divide self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__ixor__()", "path": "reference/generated/numpy.ma.maskedarray.__ixor__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self^=value.\n\n"}, {"name": "ma.MaskedArray.__le__()", "path": "reference/generated/numpy.ma.maskedarray.__le__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<=value.\n\n"}, {"name": "ma.MaskedArray.__len__()", "path": "reference/generated/numpy.ma.maskedarray.__len__", "type": "Masked arrays", "text": "\nmethod\n\nReturn len(self).\n\n"}, {"name": "ma.MaskedArray.__lshift__()", "path": "reference/generated/numpy.ma.maskedarray.__lshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<<value.\n\n"}, {"name": "ma.MaskedArray.__lt__()", "path": "reference/generated/numpy.ma.maskedarray.__lt__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<value.\n\n"}, {"name": "ma.MaskedArray.__mod__()", "path": "reference/generated/numpy.ma.maskedarray.__mod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self%value.\n\n"}, {"name": "ma.MaskedArray.__mul__()", "path": "reference/generated/numpy.ma.maskedarray.__mul__", "type": "Masked arrays", "text": "\nmethod\n\nMultiply self by other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__ne__()", "path": "reference/generated/numpy.ma.maskedarray.__ne__", "type": "Masked arrays", "text": "\nmethod\n\nCheck whether other does not equal self elementwise.\n\nWhen either of the elements is masked, the result is masked as well, but the\nunderlying boolean data are still set, with self and other considered equal if\nboth are masked, and unequal otherwise.\n\nFor structured arrays, all fields are combined, with masked values ignored.\nThe result is masked if all fields were masked, with self and other considered\nequal only if both were fully masked.\n\n"}, {"name": "ma.MaskedArray.__or__()", "path": "reference/generated/numpy.ma.maskedarray.__or__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self|value.\n\n"}, {"name": "ma.MaskedArray.__pow__()", "path": "reference/generated/numpy.ma.maskedarray.__pow__", "type": "Masked arrays", "text": "\nmethod\n\nRaise self to the power other, masking the potential NaNs/Infs\n\n"}, {"name": "ma.MaskedArray.__radd__()", "path": "reference/generated/numpy.ma.maskedarray.__radd__", "type": "Masked arrays", "text": "\nmethod\n\nAdd other to self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rand__()", "path": "reference/generated/numpy.ma.maskedarray.__rand__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value&self.\n\n"}, {"name": "ma.MaskedArray.__rdivmod__()", "path": "reference/generated/numpy.ma.maskedarray.__rdivmod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn divmod(value, self).\n\n"}, {"name": "ma.MaskedArray.__reduce__()", "path": "reference/generated/numpy.ma.maskedarray.__reduce__", "type": "Masked arrays", "text": "\nmethod\n\nReturn a 3-tuple for pickling a MaskedArray.\n\n"}, {"name": "ma.MaskedArray.__repr__()", "path": "reference/generated/numpy.ma.maskedarray.__repr__", "type": "Masked arrays", "text": "\nmethod\n\nLiteral string representation.\n\n"}, {"name": "ma.MaskedArray.__rfloordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__rfloordiv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide self into other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rlshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rlshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value<<self.\n\n"}, {"name": "ma.MaskedArray.__rmod__()", "path": "reference/generated/numpy.ma.maskedarray.__rmod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value%self.\n\n"}, {"name": "ma.MaskedArray.__rmul__()", "path": "reference/generated/numpy.ma.maskedarray.__rmul__", "type": "Masked arrays", "text": "\nmethod\n\nMultiply other by self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__ror__()", "path": "reference/generated/numpy.ma.maskedarray.__ror__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value|self.\n\n"}, {"name": "ma.MaskedArray.__rpow__()", "path": "reference/generated/numpy.ma.maskedarray.__rpow__", "type": "Masked arrays", "text": "\nmethod\n\nRaise other to the power self, masking the potential NaNs/Infs\n\n"}, {"name": "ma.MaskedArray.__rrshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rrshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value>>self.\n\n"}, {"name": "ma.MaskedArray.__rshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>>value.\n\n"}, {"name": "ma.MaskedArray.__rsub__()", "path": "reference/generated/numpy.ma.maskedarray.__rsub__", "type": "Masked arrays", "text": "\nmethod\n\nSubtract self from other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rtruediv__()", "path": "reference/generated/numpy.ma.maskedarray.__rtruediv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide self into other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rxor__()", "path": "reference/generated/numpy.ma.maskedarray.__rxor__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value^self.\n\n"}, {"name": "ma.MaskedArray.__setitem__()", "path": "reference/generated/numpy.ma.maskedarray.__setitem__", "type": "Masked arrays", "text": "\nmethod\n\nx.__setitem__(i, y) <==> x[i]=y\n\nSet item described by index. If value is masked, masks those locations.\n\n"}, {"name": "ma.MaskedArray.__setmask__()", "path": "reference/generated/numpy.ma.maskedarray.__setmask__", "type": "Masked arrays", "text": "\nmethod\n\nSet the mask.\n\n"}, {"name": "ma.MaskedArray.__setstate__()", "path": "reference/generated/numpy.ma.maskedarray.__setstate__", "type": "Masked arrays", "text": "\nmethod\n\nRestore the internal state of the masked array, for pickling purposes. `state`\nis typically the output of the `__getstate__` output, and is a 5-tuple:\n\n"}, {"name": "ma.MaskedArray.__str__()", "path": "reference/generated/numpy.ma.maskedarray.__str__", "type": "Masked arrays", "text": "\nmethod\n\nReturn str(self).\n\n"}, {"name": "ma.MaskedArray.__sub__()", "path": "reference/generated/numpy.ma.maskedarray.__sub__", "type": "Masked arrays", "text": "\nmethod\n\nSubtract other from self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__truediv__()", "path": "reference/generated/numpy.ma.maskedarray.__truediv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide other into self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__xor__()", "path": "reference/generated/numpy.ma.maskedarray.__xor__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self^value.\n\n"}, {"name": "ma.MaskedArray.all()", "path": "reference/generated/numpy.ma.maskedarray.all", "type": "numpy.ma.MaskedArray.all", "text": "\nmethod\n\nReturns True if all elements evaluate to True.\n\nThe output array is masked where all the values along the given axis are\nmasked: if the output would have been a scalar and that all the values are\nmasked, then the output is `masked`.\n\nRefer to `numpy.all` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.anom()", "path": "reference/generated/numpy.ma.maskedarray.anom", "type": "numpy.ma.MaskedArray.anom", "text": "\nmethod\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\nReturns an array of anomalies, with the same shape as the input and where the\narithmetic mean is computed along the given axis.\n\nAxis over which the anomalies are taken. The default is to use the mean of the\nflattened array as reference.\n\nthe default is float32; for arrays of float types it is the same as the array\ntype.\n\nSee also\n\nCompute the mean of the array.\n\n"}, {"name": "ma.MaskedArray.any()", "path": "reference/generated/numpy.ma.maskedarray.any", "type": "numpy.ma.MaskedArray.any", "text": "\nmethod\n\nReturns True if any of the elements of `a` evaluate to True.\n\nMasked values are considered as False during computation.\n\nRefer to `numpy.any` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.argmax()", "path": "reference/generated/numpy.ma.maskedarray.argmax", "type": "numpy.ma.MaskedArray.argmax", "text": "\nmethod\n\nReturns array of indices of the maximum values along the given axis. Masked\nvalues are treated as if they had the value fill_value.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nmaximum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\n"}, {"name": "ma.MaskedArray.argmin()", "path": "reference/generated/numpy.ma.maskedarray.argmin", "type": "numpy.ma.MaskedArray.argmin", "text": "\nmethod\n\nReturn array of indices to the minimum values along the given axis.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nminimum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\nIf multi-dimension input, returns a new ndarray of indices to the minimum\nvalues along the given axis. Otherwise, returns a scalar of index to the\nminimum values along the given axis.\n\n"}, {"name": "ma.MaskedArray.argsort()", "path": "reference/generated/numpy.ma.maskedarray.argsort", "type": "numpy.ma.MaskedArray.argsort", "text": "\nmethod\n\nReturn an ndarray of indices that sort the array along the specified axis.\nMasked values are filled beforehand to `fill_value`.\n\nAxis along which to sort. If None, the default, the flattened array is used.\n\nChanged in version 1.13.0: Previously, the default was documented to be -1,\nbut that was in error. At some future date, the default will change to -1, as\noriginally intended. Until then, the axis should be given explicitly when\n`arr.ndim > 1`, to avoid a FutureWarning.\n\nThe sorting algorithm used.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. Not all fields need be specified.\n\nWhether missing values (if any) should be treated as the largest values (True)\nor the smallest values (False) When the array contains unmasked values at the\nsame extremes of the datatype, the ordering of these values and the masked\nvalues is undefined.\n\nValue used internally for the masked values. If `fill_value` is not None, it\nsupersedes `endwith`.\n\nArray of indices that sort `a` along the specified axis. In other words,\n`a[index_array]` yields a sorted `a`.\n\nSee also\n\nDescribes sorting algorithms used.\n\nIndirect stable sort with multiple keys.\n\nInplace sort.\n\nSee `sort` for notes on the different sorting algorithms.\n\n"}, {"name": "ma.MaskedArray.astype()", "path": "reference/generated/numpy.ma.maskedarray.astype", "type": "Masked arrays", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "ma.MaskedArray.base", "path": "reference/generated/numpy.ma.maskedarray.base", "type": "Masked arrays", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "ma.MaskedArray.byteswap()", "path": "reference/generated/numpy.ma.maskedarray.byteswap", "type": "Masked arrays", "text": "\nmethod\n\nSwap the bytes of the array elements\n\nToggle between low-endian and big-endian data representation by returning a\nbyteswapped array, optionally swapped in-place. Arrays of byte-strings are not\nswapped. The real and imaginary parts of a complex number are swapped\nindividually.\n\nIf `True`, swap bytes in-place, default is `False`.\n\nThe byteswapped array. If `inplace` is `True`, this is a view to self.\n\nArrays of byte-strings are not swapped\n\nbut different representation in memory\n\n"}, {"name": "ma.MaskedArray.choose()", "path": "reference/generated/numpy.ma.maskedarray.choose", "type": "Masked arrays", "text": "\nmethod\n\nUse an index array to construct a new array from a set of choices.\n\nRefer to `numpy.choose` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.clip()", "path": "reference/generated/numpy.ma.maskedarray.clip", "type": "numpy.ma.MaskedArray.clip", "text": "\nmethod\n\nReturn an array whose values are limited to `[min, max]`. One of max or min\nmust be given.\n\nRefer to `numpy.clip` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.compress()", "path": "reference/generated/numpy.ma.maskedarray.compress", "type": "Masked arrays", "text": "\nmethod\n\nReturn `a` where condition is `True`.\n\nIf condition is a `MaskedArray`, missing values are considered as `False`.\n\nBoolean 1-d array selecting which entries to return. If len(condition) is less\nthan the size of a along the axis, then output is truncated to length of\ncondition array.\n\nAxis along which the operation must be performed.\n\nAlternative output array in which to place the result. It must have the same\nshape as the expected output but the type will be cast if necessary.\n\nA `MaskedArray` object.\n\nPlease note the difference with `compressed` ! The output of `compress` has a\nmask, the output of `compressed` does not.\n\n"}, {"name": "ma.MaskedArray.compressed()", "path": "reference/generated/numpy.ma.maskedarray.compressed", "type": "numpy.ma.MaskedArray.compressed", "text": "\nmethod\n\nReturn all the non-masked data as a 1-D array.\n\nA new `ndarray` holding the non-masked data is returned.\n\nThe result is not a MaskedArray!\n\n"}, {"name": "ma.MaskedArray.conj()", "path": "reference/generated/numpy.ma.maskedarray.conj", "type": "Masked arrays", "text": "\nmethod\n\nComplex-conjugate all elements.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.conjugate()", "path": "reference/generated/numpy.ma.maskedarray.conjugate", "type": "Masked arrays", "text": "\nmethod\n\nReturn the complex conjugate, element-wise.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.copy()", "path": "reference/generated/numpy.ma.maskedarray.copy", "type": "numpy.ma.MaskedArray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "ma.MaskedArray.count()", "path": "reference/generated/numpy.ma.maskedarray.count", "type": "numpy.ma.MaskedArray.count", "text": "\nmethod\n\nCount the non-masked elements of the array along the given axis.\n\nAxis or axes along which the count is performed. The default, None, performs\nthe count over all the dimensions of the input array. `axis` may be negative,\nin which case it counts from the last to the first axis.\n\nNew in version 1.10.0.\n\nIf this is a tuple of ints, the count is performed on multiple axes, instead\nof a single axis or all the axes as before.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nAn array with the same shape as the input array, with the specified axis\nremoved. If the array is a 0-d array, or if `axis` is None, a scalar is\nreturned.\n\nSee also\n\nCount masked elements in array or along a given axis.\n\nWhen the `axis` keyword is specified an array of appropriate size is returned.\n\n"}, {"name": "ma.MaskedArray.ctypes", "path": "reference/generated/numpy.ma.maskedarray.ctypes", "type": "Masked arrays", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "ma.MaskedArray.cumprod()", "path": "reference/generated/numpy.ma.maskedarray.cumprod", "type": "numpy.ma.MaskedArray.cumprod", "text": "\nmethod\n\nReturn the cumulative product of the array elements over the given axis.\n\nMasked values are set to 1 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumprod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid MaskedArray !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.cumsum()", "path": "reference/generated/numpy.ma.maskedarray.cumsum", "type": "numpy.ma.MaskedArray.cumsum", "text": "\nmethod\n\nReturn the cumulative sum of the array elements over the given axis.\n\nMasked values are set to 0 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumsum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid `ma.MaskedArray` !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.diagonal()", "path": "reference/generated/numpy.ma.maskedarray.diagonal", "type": "Masked arrays", "text": "\nmethod\n\nReturn specified diagonals. In NumPy 1.9 the returned array is a read-only\nview instead of a copy as in previous NumPy versions. In a future version the\nread-only restriction will be removed.\n\nRefer to `numpy.diagonal` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.dump()", "path": "reference/generated/numpy.ma.maskedarray.dump", "type": "Masked arrays", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "ma.MaskedArray.dumps()", "path": "reference/generated/numpy.ma.maskedarray.dumps", "type": "Masked arrays", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "ma.MaskedArray.fill()", "path": "reference/generated/numpy.ma.maskedarray.fill", "type": "Masked arrays", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "ma.MaskedArray.filled()", "path": "reference/generated/numpy.ma.maskedarray.filled", "type": "numpy.ma.MaskedArray.filled", "text": "\nmethod\n\nReturn a copy of self, with masked values filled with a given value. However,\nif there are no masked values to fill, self will be returned instead as an\nndarray.\n\nThe value to use for invalid entries. Can be scalar or non-scalar. If non-\nscalar, the resulting ndarray must be broadcastable over input array. Default\nis None, in which case, the `fill_value` attribute of the array is used\ninstead.\n\nA copy of `self` with invalid entries replaced by fill_value (be it the\nfunction argument or the attribute of `self`), or `self` itself as an ndarray\nif there are no invalid entries to be replaced.\n\nThe result is not a MaskedArray!\n\nSubclassing is preserved. This means that if, e.g., the data part of the\nmasked array is a recarray, `filled` returns a recarray:\n\n"}, {"name": "ma.MaskedArray.flags", "path": "reference/generated/numpy.ma.maskedarray.flags", "type": "Masked arrays", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "ma.MaskedArray.flatten()", "path": "reference/generated/numpy.ma.maskedarray.flatten", "type": "numpy.ma.MaskedArray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "ma.MaskedArray.get_fill_value()", "path": "reference/generated/numpy.ma.maskedarray.get_fill_value", "type": "numpy.ma.MaskedArray.get_fill_value", "text": "\nmethod\n\nThe filling value of the masked array is a scalar. When setting, None will set\nto a default based on the data type.\n\nReset to default:\n\n"}, {"name": "ma.MaskedArray.harden_mask()", "path": "reference/generated/numpy.ma.maskedarray.harden_mask", "type": "numpy.ma.MaskedArray.harden_mask", "text": "\nmethod\n\nForce the mask to hard.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `harden_mask` sets `hardmask` to `True`.\n\nSee also\n\n"}, {"name": "ma.MaskedArray.ids()", "path": "reference/generated/numpy.ma.maskedarray.ids", "type": "Masked arrays", "text": "\nmethod\n\nReturn the addresses of the data and mask areas.\n\nIf the array has no mask, the address of `nomask` is returned. This address is\ntypically not close to the data in memory:\n\n"}, {"name": "ma.MaskedArray.iscontiguous()", "path": "reference/generated/numpy.ma.maskedarray.iscontiguous", "type": "Masked arrays", "text": "\nmethod\n\nReturn a boolean indicating whether the data is contiguous.\n\n`iscontiguous` returns one of the flags of the masked array:\n\n"}, {"name": "ma.MaskedArray.item()", "path": "reference/generated/numpy.ma.maskedarray.item", "type": "Masked arrays", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "ma.MaskedArray.itemsize", "path": "reference/generated/numpy.ma.maskedarray.itemsize", "type": "Masked arrays", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "ma.MaskedArray.max()", "path": "reference/generated/numpy.ma.maskedarray.max", "type": "numpy.ma.MaskedArray.max", "text": "\nmethod\n\nReturn the maximum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\nmaximum_fill_value().\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the maximum filling value for a given datatype.\n\n"}, {"name": "ma.MaskedArray.mean()", "path": "reference/generated/numpy.ma.maskedarray.mean", "type": "numpy.ma.MaskedArray.mean", "text": "\nmethod\n\nReturns the average of the array elements along given axis.\n\nMasked entries are ignored, and result elements which are not finite will be\nmasked.\n\nRefer to `numpy.mean` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\nWeighted average.\n\n"}, {"name": "ma.MaskedArray.min()", "path": "reference/generated/numpy.ma.maskedarray.min", "type": "numpy.ma.MaskedArray.min", "text": "\nmethod\n\nReturn the minimum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\n`minimum_fill_value`.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the minimum filling value for a given datatype.\n\n"}, {"name": "ma.MaskedArray.nbytes", "path": "reference/generated/numpy.ma.maskedarray.nbytes", "type": "Masked arrays", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "ma.MaskedArray.ndim", "path": "reference/generated/numpy.ma.maskedarray.ndim", "type": "Masked arrays", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "ma.MaskedArray.nonzero()", "path": "reference/generated/numpy.ma.maskedarray.nonzero", "type": "numpy.ma.MaskedArray.nonzero", "text": "\nmethod\n\nReturn the indices of unmasked elements that are not zero.\n\nReturns a tuple of arrays, one for each dimension, containing the indices of\nthe non-zero elements in that dimension. The corresponding non-zero values can\nbe obtained with:\n\nTo group the indices by element, rather than dimension, use instead:\n\nThe result of this is always a 2d array, with a row for each non-zero element.\n\nIndices of elements that are non-zero.\n\nSee also\n\nFunction operating on ndarrays.\n\nReturn indices that are non-zero in the flattened version of the input array.\n\nEquivalent ndarray method.\n\nCounts the number of non-zero elements in the input array.\n\nMasked elements are ignored.\n\nIndices can also be grouped by element.\n\nA common use for `nonzero` is to find the indices of an array, where a\ncondition is True. Given an array `a`, the condition `a` > 3 is a boolean\narray and since False is interpreted as 0, ma.nonzero(a > 3) yields the\nindices of the `a` where the condition is true.\n\nThe `nonzero` method of the condition array can also be called.\n\n"}, {"name": "ma.MaskedArray.prod()", "path": "reference/generated/numpy.ma.maskedarray.prod", "type": "numpy.ma.MaskedArray.prod", "text": "\nmethod\n\nReturn the product of the array elements over the given axis.\n\nMasked elements are set to 1 internally for computation.\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.product()", "path": "reference/generated/numpy.ma.maskedarray.product", "type": "Masked arrays", "text": "\nmethod\n\nReturn the product of the array elements over the given axis.\n\nMasked elements are set to 1 internally for computation.\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.ptp()", "path": "reference/generated/numpy.ma.maskedarray.ptp", "type": "numpy.ma.MaskedArray.ptp", "text": "\nmethod\n\nReturn (maximum - minimum) along the given dimension (i.e. peak-to-peak\nvalue).\n\nWarning\n\n`ptp` preserves the data type of the array. This means the return value for an\ninput of signed integers with n bits (e.g. `np.int8`, `np.int16`, etc) is also\na signed integer with n bits. In that case, peak-to-peak values greater than\n`2**(n-1)-1` will be returned as negative values. An example with a work-\naround is shown below.\n\nAxis along which to find the peaks. If None (default) the flattened array is\nused.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary.\n\nValue used to fill in the masked values.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nA new array holding the result, unless `out` was specified, in which case a\nreference to `out` is returned.\n\nThis example shows that a negative value can be returned when the input is an\narray of signed integers.\n\nA work-around is to use the `view()` method to view the result as unsigned\nintegers with the same bit width:\n\n"}, {"name": "ma.MaskedArray.put()", "path": "reference/generated/numpy.ma.maskedarray.put", "type": "Masked arrays", "text": "\nmethod\n\nSet storage-indexed locations to corresponding values.\n\nSets self._data.flat[n] = values[n] for each n in indices. If `values` is\nshorter than `indices` then it will repeat. If `values` has some masked\nvalues, the initial mask is updated in consequence, else the corresponding\nvalues are unmasked.\n\nTarget indices, interpreted as integers.\n\nValues to place in self._data copy at target indices.\n\nSpecifies how out-of-bounds indices will behave. \u2018raise\u2019 : raise an error.\n\u2018wrap\u2019 : wrap around. \u2018clip\u2019 : clip to the range.\n\n`values` can be a scalar or length 1 array.\n\n"}, {"name": "ma.MaskedArray.ravel()", "path": "reference/generated/numpy.ma.maskedarray.ravel", "type": "numpy.ma.MaskedArray.ravel", "text": "\nmethod\n\nReturns a 1D version of self, as a view.\n\nThe elements of `a` are read using this index order. \u2018C\u2019 means to index the\nelements in C-like order, with the last axis index changing fastest, back to\nthe first axis index changing slowest. \u2018F\u2019 means to index the elements in\nFortran-like index order, with the first index changing fastest, and the last\nindex changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of\nthe memory layout of the underlying array, and only refer to the order of axis\nindexing. \u2018A\u2019 means to read the elements in Fortran-like index order if `m` is\nFortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the\nelements in the order they occur in memory, except for reversing the data when\nstrides are negative. By default, \u2018C\u2019 index order is used.\n\nOutput view is of shape `(self.size,)` (or `(np.ma.product(self.shape),)`).\n\n"}, {"name": "ma.MaskedArray.repeat()", "path": "reference/generated/numpy.ma.maskedarray.repeat", "type": "Masked arrays", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.reshape()", "path": "reference/generated/numpy.ma.maskedarray.reshape", "type": "numpy.ma.MaskedArray.reshape", "text": "\nmethod\n\nGive a new shape to the array without changing its data.\n\nReturns a masked array containing the same data, but with a new shape. The\nresult is a view on the original array; if this is not possible, a ValueError\nis raised.\n\nThe new shape should be compatible with the original shape. If an integer is\nsupplied, then the result will be a 1-D array of that length.\n\nDetermines whether the array data should be viewed as in C (row-major) or\nFORTRAN (column-major) order.\n\nA new view on the array.\n\nSee also\n\nEquivalent function in the masked array module.\n\nEquivalent method on ndarray object.\n\nEquivalent function in the NumPy module.\n\nThe reshaping operation cannot guarantee that a copy will not be made, to\nmodify the shape in place, use `a.shape = s`\n\n"}, {"name": "ma.MaskedArray.resize()", "path": "reference/generated/numpy.ma.maskedarray.resize", "type": "numpy.ma.MaskedArray.resize", "text": "\nmethod\n\nWarning\n\nThis method does nothing, except raise a ValueError exception. A masked array\ndoes not own its data and therefore cannot safely be resized in place. Use the\n`numpy.ma.resize` function instead.\n\nThis method is difficult to implement safely and may be deprecated in future\nreleases of NumPy.\n\n"}, {"name": "ma.MaskedArray.round()", "path": "reference/generated/numpy.ma.maskedarray.round", "type": "numpy.ma.MaskedArray.round", "text": "\nmethod\n\nReturn each element rounded to the given number of decimals.\n\nRefer to `numpy.around` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.searchsorted()", "path": "reference/generated/numpy.ma.maskedarray.searchsorted", "type": "Masked arrays", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.set_fill_value()", "path": "reference/generated/numpy.ma.maskedarray.set_fill_value", "type": "numpy.ma.MaskedArray.set_fill_value", "text": "\nmethod\n\n"}, {"name": "ma.MaskedArray.shrink_mask()", "path": "reference/generated/numpy.ma.maskedarray.shrink_mask", "type": "numpy.ma.MaskedArray.shrink_mask", "text": "\nmethod\n\nReduce a mask to nomask when possible.\n\n"}, {"name": "ma.MaskedArray.size", "path": "reference/generated/numpy.ma.maskedarray.size", "type": "Masked arrays", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "ma.MaskedArray.soften_mask()", "path": "reference/generated/numpy.ma.maskedarray.soften_mask", "type": "numpy.ma.MaskedArray.soften_mask", "text": "\nmethod\n\nForce the mask to soft.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `soften_mask` sets `hardmask` to `False`.\n\nSee also\n\n"}, {"name": "ma.MaskedArray.sort()", "path": "reference/generated/numpy.ma.maskedarray.sort", "type": "numpy.ma.MaskedArray.sort", "text": "\nmethod\n\nSort the array, in-place\n\nArray to be sorted.\n\nAxis along which to sort. If None, the array is flattened before sorting. The\ndefault is -1, which sorts along the last axis.\n\nThe sorting algorithm used.\n\nWhen `a` is a structured array, this argument specifies which fields to\ncompare first, second, and so on. This list does not need to include all of\nthe fields.\n\nWhether missing values (if any) should be treated as the largest values (True)\nor the smallest values (False) When the array contains unmasked values sorting\nat the same extremes of the datatype, the ordering of these values and the\nmasked values is undefined.\n\nValue used internally for the masked values. If `fill_value` is not None, it\nsupersedes `endwith`.\n\nArray of the same type and shape as `a`.\n\nSee also\n\nMethod to sort an array in-place.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in a sorted array.\n\nSee `sort` for notes on the different sorting algorithms.\n\n"}, {"name": "ma.MaskedArray.squeeze()", "path": "reference/generated/numpy.ma.maskedarray.squeeze", "type": "numpy.ma.MaskedArray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.std()", "path": "reference/generated/numpy.ma.maskedarray.std", "type": "numpy.ma.MaskedArray.std", "text": "\nmethod\n\nReturns the standard deviation of the array elements along given axis.\n\nMasked entries are ignored.\n\nRefer to `numpy.std` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\n"}, {"name": "ma.MaskedArray.strides", "path": "reference/generated/numpy.ma.maskedarray.strides", "type": "Masked arrays", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "ma.MaskedArray.sum()", "path": "reference/generated/numpy.ma.maskedarray.sum", "type": "numpy.ma.MaskedArray.sum", "text": "\nmethod\n\nReturn the sum of the array elements over the given axis.\n\nMasked elements are set to 0 internally.\n\nRefer to `numpy.sum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.swapaxes()", "path": "reference/generated/numpy.ma.maskedarray.swapaxes", "type": "numpy.ma.MaskedArray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.take()", "path": "reference/generated/numpy.ma.maskedarray.take", "type": "Masked arrays", "text": "\nmethod\n\n"}, {"name": "ma.MaskedArray.tobytes()", "path": "reference/generated/numpy.ma.maskedarray.tobytes", "type": "numpy.ma.MaskedArray.tobytes", "text": "\nmethod\n\nReturn the array data as a string containing the raw bytes in the array.\n\nThe array is filled with a fill value before the string conversion.\n\nNew in version 1.9.0.\n\nValue used to fill in the masked values. Default is None, in which case\n`MaskedArray.fill_value` is used.\n\nOrder of the data item in the copy. Default is \u2018C\u2019.\n\nSee also\n\nAs for `ndarray.tobytes`, information about the shape, dtype, etc., but also\nabout `fill_value`, will be lost.\n\n"}, {"name": "ma.MaskedArray.tofile()", "path": "reference/generated/numpy.ma.maskedarray.tofile", "type": "numpy.ma.MaskedArray.tofile", "text": "\nmethod\n\nSave a masked array to a file in binary format.\n\nWarning\n\nThis function is not implemented yet.\n\nWhen `tofile` is called.\n\n"}, {"name": "ma.MaskedArray.toflex()", "path": "reference/generated/numpy.ma.maskedarray.toflex", "type": "Masked arrays", "text": "\nmethod\n\nTransforms a masked array into a flexible-type array.\n\nThe flexible type array that is returned will have two fields:\n\nA new flexible-type `ndarray` with two fields: the first element containing a\nvalue, the second element containing the corresponding mask boolean. The\nreturned record shape matches self.shape.\n\nA side-effect of transforming a masked array into a flexible `ndarray` is that\nmeta information (`fill_value`, \u2026) will be lost.\n\n"}, {"name": "ma.MaskedArray.tolist()", "path": "reference/generated/numpy.ma.maskedarray.tolist", "type": "numpy.ma.MaskedArray.tolist", "text": "\nmethod\n\nReturn the data portion of the masked array as a hierarchical Python list.\n\nData items are converted to the nearest compatible Python type. Masked values\nare converted to `fill_value`. If `fill_value` is None, the corresponding\nentries in the output list will be `None`.\n\nThe value to use for invalid entries. Default is None.\n\nThe Python list representation of the masked array.\n\n"}, {"name": "ma.MaskedArray.torecords()", "path": "reference/generated/numpy.ma.maskedarray.torecords", "type": "numpy.ma.MaskedArray.torecords", "text": "\nmethod\n\nTransforms a masked array into a flexible-type array.\n\nThe flexible type array that is returned will have two fields:\n\nA new flexible-type `ndarray` with two fields: the first element containing a\nvalue, the second element containing the corresponding mask boolean. The\nreturned record shape matches self.shape.\n\nA side-effect of transforming a masked array into a flexible `ndarray` is that\nmeta information (`fill_value`, \u2026) will be lost.\n\n"}, {"name": "ma.MaskedArray.tostring()", "path": "reference/generated/numpy.ma.maskedarray.tostring", "type": "Masked arrays", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "ma.MaskedArray.trace()", "path": "reference/generated/numpy.ma.maskedarray.trace", "type": "numpy.ma.MaskedArray.trace", "text": "\nmethod\n\nReturn the sum along diagonals of the array.\n\nRefer to `numpy.trace` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.transpose()", "path": "reference/generated/numpy.ma.maskedarray.transpose", "type": "numpy.ma.MaskedArray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "ma.MaskedArray.unshare_mask()", "path": "reference/generated/numpy.ma.maskedarray.unshare_mask", "type": "numpy.ma.MaskedArray.unshare_mask", "text": "\nmethod\n\nCopy the mask and set the sharedmask flag to False.\n\nWhether the mask is shared between masked arrays can be seen from the\n`sharedmask` property. `unshare_mask` ensures the mask is not shared. A copy\nof the mask is only made if it was shared.\n\nSee also\n\n"}, {"name": "ma.MaskedArray.var()", "path": "reference/generated/numpy.ma.maskedarray.var", "type": "numpy.ma.MaskedArray.var", "text": "\nmethod\n\nCompute the variance along the specified axis.\n\nReturns the variance of the array elements, a measure of the spread of a\ndistribution. The variance is computed for the flattened array by default,\notherwise over the specified axis.\n\nArray containing numbers whose variance is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the variance is computed. The default is to compute\nthe variance of the flattened array.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a variance is performed over multiple axes,\ninstead of a single axis or all the axes as before.\n\nType to use in computing the variance. For arrays of integer type the default\nis `float64`; for arrays of float types it is the same as the array type.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output, but the type is cast if necessary.\n\n\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is `N - ddof`,\nwhere `N` represents the number of elements. By default `ddof` is zero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `var` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in the variance. See `reduce` for details.\n\nNew in version 1.20.0.\n\nIf `out=None`, returns a new array containing the variance; otherwise, a\nreference to the output array is returned.\n\nSee also\n\nThe variance is the average of the squared deviations from the mean, i.e.,\n`var = mean(x)`, where `x = abs(a - a.mean())**2`.\n\nThe mean is typically calculated as `x.sum() / N`, where `N = len(x)`. If,\nhowever, `ddof` is specified, the divisor `N - ddof` is used instead. In\nstandard statistical practice, `ddof=1` provides an unbiased estimator of the\nvariance of a hypothetical infinite population. `ddof=0` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\n\nNote that for complex numbers, the absolute value is taken before squaring, so\nthat the result is always real and nonnegative.\n\nFor floating-point input, the variance is computed using the same precision\nthe input has. Depending on the input data, this can cause the results to be\ninaccurate, especially for `float32` (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\nIn single precision, var() can be inaccurate:\n\nComputing the variance in float64 is more accurate:\n\nSpecifying a where argument:\n\n"}, {"name": "ma.MaskedArray.view()", "path": "reference/generated/numpy.ma.maskedarray.view", "type": "Masked arrays", "text": "\nmethod\n\nReturn a view of the MaskedArray data.\n\nData-type descriptor of the returned view, e.g., float32 or int16. The\ndefault, None, results in the view having the same data-type as `a`. As with\n`ndarray.view`, dtype can also be specified as an ndarray sub-class, which\nthen specifies the type of the returned object (this is equivalent to setting\nthe `type` parameter).\n\nType of the returned view, either ndarray or a subclass. The default None\nresults in type preservation.\n\nThe value to use for invalid entries (None by default). If None, then this\nargument is inferred from the passed `dtype`, or in its absence the original\narray, as discussed in the notes below.\n\nSee also\n\nEquivalent method on ndarray object.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nIf `fill_value` is not specified, but `dtype` is specified (and is not an\nndarray sub-class), the `fill_value` of the MaskedArray will be reset. If\nneither `fill_value` nor `dtype` are specified (or if `dtype` is an ndarray\nsub-class), then the fill value is preserved. Finally, if `fill_value` is\nspecified, but `dtype` is not, the fill value is set to the specified value.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\n"}, {"name": "ma.max()", "path": "reference/generated/numpy.ma.max", "type": "numpy.ma.max", "text": "\nReturn the maximum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\nmaximum_fill_value().\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the maximum filling value for a given datatype.\n\n"}, {"name": "ma.maximum_fill_value()", "path": "reference/generated/numpy.ma.maximum_fill_value", "type": "numpy.ma.maximum_fill_value", "text": "\nReturn the minimum value that can be represented by the dtype of an object.\n\nThis function is useful for calculating a fill value suitable for taking the\nmaximum of an array with a given dtype.\n\nAn object that can be queried for it\u2019s numeric type.\n\nThe minimum representable value.\n\nIf `obj` isn\u2019t a suitable numeric type.\n\nSee also\n\nThe inverse function.\n\nSet the filling value of a masked array.\n\nReturn current fill value.\n\nAn array of numeric data can also be passed.\n\n"}, {"name": "ma.mean()", "path": "reference/generated/numpy.ma.mean", "type": "numpy.ma.mean", "text": "\nReturns the average of the array elements along given axis.\n\nMasked entries are ignored, and result elements which are not finite will be\nmasked.\n\nRefer to `numpy.mean` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\nWeighted average.\n\n"}, {"name": "ma.median()", "path": "reference/generated/numpy.ma.median", "type": "numpy.ma.median", "text": "\nCompute the median along the specified axis.\n\nReturns the median of the array elements.\n\nInput array or object that can be converted to an array.\n\nAxis along which the medians are computed. The default (None) is to compute\nthe median along a flattened version of the array.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary.\n\nIf True, then allow use of memory of input array (a) for calculations. The\ninput array will be modified by the call to median. This will save memory when\nyou do not need to preserve the contents of the input array. Treat the input\nas undefined, but it will probably be fully or partially sorted. Default is\nFalse. Note that, if `overwrite_input` is True, and the input is not already\nan `ndarray`, an error will be raised.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nNew in version 1.10.0.\n\nA new array holding the result is returned unless out is specified, in which\ncase a reference to out is returned. Return data-type is `float64` for\nintegers and floats smaller than `float64`, or the input data-type, otherwise.\n\nSee also\n\nGiven a vector `V` with `N` non masked values, the median of `V` is the middle\nvalue of a sorted copy of `V` (`Vs`) - i.e. `Vs[(N-1)/2]`, when `N` is odd, or\n`{Vs[N/2 - 1] + Vs[N/2]}/2` when `N` is even.\n\n"}, {"name": "ma.min()", "path": "reference/generated/numpy.ma.min", "type": "numpy.ma.min", "text": "\nReturn the minimum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\n`minimum_fill_value`.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the minimum filling value for a given datatype.\n\n"}, {"name": "ma.minimum_fill_value()", "path": "reference/generated/numpy.ma.minimum_fill_value", "type": "numpy.ma.minimum_fill_value", "text": "\nReturn the maximum value that can be represented by the dtype of an object.\n\nThis function is useful for calculating a fill value suitable for taking the\nminimum of an array with a given dtype.\n\nAn object that can be queried for it\u2019s numeric type.\n\nThe maximum representable value.\n\nIf `obj` isn\u2019t a suitable numeric type.\n\nSee also\n\nThe inverse function.\n\nSet the filling value of a masked array.\n\nReturn current fill value.\n\nAn array of numeric data can also be passed.\n\n"}, {"name": "ma.mr_", "path": "reference/generated/numpy.ma.mr_", "type": "numpy.ma.mr_", "text": "\nTranslate slice objects to concatenation along the first axis.\n\nThis is the masked array version of `lib.index_tricks.RClass`.\n\nSee also\n\n"}, {"name": "ma.nonzero()", "path": "reference/generated/numpy.ma.nonzero", "type": "numpy.ma.nonzero", "text": "\nReturn the indices of unmasked elements that are not zero.\n\nReturns a tuple of arrays, one for each dimension, containing the indices of\nthe non-zero elements in that dimension. The corresponding non-zero values can\nbe obtained with:\n\nTo group the indices by element, rather than dimension, use instead:\n\nThe result of this is always a 2d array, with a row for each non-zero element.\n\nIndices of elements that are non-zero.\n\nSee also\n\nFunction operating on ndarrays.\n\nReturn indices that are non-zero in the flattened version of the input array.\n\nEquivalent ndarray method.\n\nCounts the number of non-zero elements in the input array.\n\nMasked elements are ignored.\n\nIndices can also be grouped by element.\n\nA common use for `nonzero` is to find the indices of an array, where a\ncondition is True. Given an array `a`, the condition `a` > 3 is a boolean\narray and since False is interpreted as 0, ma.nonzero(a > 3) yields the\nindices of the `a` where the condition is true.\n\nThe `nonzero` method of the condition array can also be called.\n\n"}, {"name": "ma.notmasked_contiguous()", "path": "reference/generated/numpy.ma.notmasked_contiguous", "type": "numpy.ma.notmasked_contiguous", "text": "\nFind contiguous unmasked data in a masked array along the given axis.\n\nThe input array.\n\nAxis along which to perform the operation. If None (default), applies to a\nflattened version of the array, and this is the same as\n`flatnotmasked_contiguous`.\n\nA list of slices (start and end indexes) of unmasked indexes in the array.\n\nIf the input is 2d and axis is specified, the result is a list of lists.\n\nSee also\n\nOnly accepts 2-D arrays at most.\n\n"}, {"name": "ma.notmasked_edges()", "path": "reference/generated/numpy.ma.notmasked_edges", "type": "numpy.ma.notmasked_edges", "text": "\nFind the indices of the first and last unmasked values along an axis.\n\nIf all values are masked, return None. Otherwise, return a list of two tuples,\ncorresponding to the indices of the first and last unmasked values\nrespectively.\n\nThe input array.\n\nAxis along which to perform the operation. If None (default), applies to a\nflattened version of the array.\n\nAn array of start and end indexes if there are any masked data in the array.\nIf there are no masked data in the array, `edges` is a list of the first and\nlast index.\n\nSee also\n\n"}, {"name": "ma.ones()", "path": "reference/generated/numpy.ma.ones", "type": "numpy.ma.ones", "text": "\nReturn a new array of given shape and type, filled with ones.\n\nShape of the new array, e.g., `(2, 3)` or `2`.\n\nThe desired data-type for the array, e.g., `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of ones with the given shape, dtype, and order.\n\nSee also\n\nReturn an array of ones with shape and type of input.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to zero.\n\nReturn a new array of given shape filled with value.\n\n"}, {"name": "ma.ones_like()", "path": "reference/generated/numpy.ma.ones_like", "type": "numpy.ma.ones_like", "text": "\nReturn an array of ones with the same shape and type as a given array.\n\nThe shape and data-type of `a` define these same attributes of the returned\narray.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means\nmatch the layout of `a` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of `a`,\notherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of ones with the same shape and type as `a`.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new array setting values to one.\n\n"}, {"name": "ma.outer()", "path": "reference/generated/numpy.ma.outer", "type": "numpy.ma.outer", "text": "\nCompute the outer product of two vectors.\n\nGiven two vectors, `a = [a0, a1, ..., aM]` and `b = [b0, b1, ..., bN]`, the\nouter product [1] is:\n\nFirst input vector. Input is flattened if not already 1-dimensional.\n\nSecond input vector. Input is flattened if not already 1-dimensional.\n\nA location where the result is stored\n\nNew in version 1.9.0.\n\n`out[i, j] = a[i] * b[j]`\n\nSee also\n\n`einsum('i,j->ij', a.ravel(), b.ravel())` is the equivalent.\n\nA generalization to dimensions other than 1D and other operations.\n`np.multiply.outer(a.ravel(), b.ravel())` is the equivalent.\n\n`np.tensordot(a.ravel(), b.ravel(), axes=((), ()))` is the equivalent.\n\nMasked values are replaced by 0.\n\n: G. H. Golub and C. F. Van Loan, Matrix Computations, 3rd ed., Baltimore, MD,\nJohns Hopkins University Press, 1996, pg. 8.\n\nMake a (very coarse) grid for computing a Mandelbrot set:\n\nAn example using a \u201cvector\u201d of letters:\n\n"}, {"name": "ma.outerproduct()", "path": "reference/generated/numpy.ma.outerproduct", "type": "numpy.ma.outerproduct", "text": "\nCompute the outer product of two vectors.\n\nGiven two vectors, `a = [a0, a1, ..., aM]` and `b = [b0, b1, ..., bN]`, the\nouter product [1] is:\n\nFirst input vector. Input is flattened if not already 1-dimensional.\n\nSecond input vector. Input is flattened if not already 1-dimensional.\n\nA location where the result is stored\n\nNew in version 1.9.0.\n\n`out[i, j] = a[i] * b[j]`\n\nSee also\n\n`einsum('i,j->ij', a.ravel(), b.ravel())` is the equivalent.\n\nA generalization to dimensions other than 1D and other operations.\n`np.multiply.outer(a.ravel(), b.ravel())` is the equivalent.\n\n`np.tensordot(a.ravel(), b.ravel(), axes=((), ()))` is the equivalent.\n\nMasked values are replaced by 0.\n\n: G. H. Golub and C. F. Van Loan, Matrix Computations, 3rd ed., Baltimore, MD,\nJohns Hopkins University Press, 1996, pg. 8.\n\nMake a (very coarse) grid for computing a Mandelbrot set:\n\nAn example using a \u201cvector\u201d of letters:\n\n"}, {"name": "ma.polyfit()", "path": "reference/generated/numpy.ma.polyfit", "type": "numpy.ma.polyfit", "text": "\nLeast squares polynomial fit.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nFit a polynomial `p(x) = p[0] * x**deg + ... + p[deg]` of degree `deg` to\npoints `(x, y)`. Returns a vector of coefficients `p` that minimises the\nsquared error in the order `deg`, `deg-1`, \u2026 `0`.\n\nThe `Polynomial.fit` class method is recommended for new code as it is more\nstable numerically. See the documentation of the method for more information.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree of the fitting polynomial\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nIf given and not `False`, return not just the estimate but also its covariance\nmatrix. By default, the covariance are scaled by chi2/dof, where dof = M -\n(deg + 1), i.e., the weights are presumed to be unreliable except in a\nrelative sense and everything is scaled such that the reduced chi2 is unity.\nThis scaling is omitted if `cov='unscaled'`, as is relevant for the case that\nthe weights are w = 1/sigma, with sigma known to be a reliable estimate of the\nuncertainty.\n\nPolynomial coefficients, highest power first. If `y` was 2-D, the coefficients\nfor `k`-th data set are in `p[:,k]`.\n\nThese values are only returned if `full == True`\n\ncoefficient matrix\n\ncoefficient matrix\n\nFor more details, see `numpy.linalg.lstsq`.\n\nPresent only if `full == False` and `cov == True`. The covariance matrix of\nthe polynomial coefficient estimates. The diagonal of this matrix are the\nvariance estimates for each coefficient. If y is a 2-D array, then the\ncovariance matrix for the `k`-th data set are in `V[:,:,k]`\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full == False`.\n\nThe warnings can be turned off by\n\nSee also\n\nCompute polynomial values.\n\nComputes a least-squares fit.\n\nComputes spline fits.\n\nAny masked values in x is propagated in y, and vice-versa.\n\nThe solution minimizes the squared error\n\nin the equations:\n\nThe coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n\n`polyfit` issues a `RankWarning` when the least-squares fit is badly\nconditioned. This implies that the best fit is not well-defined due to\nnumerical error. The results may be improved by lowering the polynomial degree\nor by replacing `x` by `x` \\- `x`.mean(). The `rcond` parameter can also be\nset to a value smaller than its default, but the resulting fit may be\nspurious: including contributions from the small singular values can add\nnumerical noise to the result.\n\nNote that fitting polynomial coefficients is inherently badly conditioned when\nthe degree of the polynomial is large or the interval of sample points is\nbadly centered. The quality of the fit should always be checked in these\ncases. When polynomial fits are not satisfactory, splines may be a good\nalternative.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\nWikipedia, \u201cPolynomial interpolation\u201d,\nhttps://en.wikipedia.org/wiki/Polynomial_interpolation\n\nIt is convenient to use `poly1d` objects for dealing with polynomials:\n\nHigh-order polynomials may oscillate wildly:\n\nIllustration:\n\n"}, {"name": "ma.power()", "path": "reference/generated/numpy.ma.power", "type": "numpy.ma.power", "text": "\nReturns element-wise base array raised to power from second array.\n\nThis is the masked array version of `numpy.power`. For details see\n`numpy.power`.\n\nSee also\n\nThe out argument to `numpy.power` is not supported, `third` has to be None.\n\n"}, {"name": "ma.prod()", "path": "reference/generated/numpy.ma.prod", "type": "numpy.ma.prod", "text": "\nReturn the product of the array elements over the given axis.\n\nMasked elements are set to 1 internally for computation.\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.ptp()", "path": "reference/generated/numpy.ma.ptp", "type": "numpy.ma.ptp", "text": "\nReturn (maximum - minimum) along the given dimension (i.e. peak-to-peak\nvalue).\n\nWarning\n\n`ptp` preserves the data type of the array. This means the return value for an\ninput of signed integers with n bits (e.g. `np.int8`, `np.int16`, etc) is also\na signed integer with n bits. In that case, peak-to-peak values greater than\n`2**(n-1)-1` will be returned as negative values. An example with a work-\naround is shown below.\n\nAxis along which to find the peaks. If None (default) the flattened array is\nused.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary.\n\nValue used to fill in the masked values.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nA new array holding the result, unless `out` was specified, in which case a\nreference to `out` is returned.\n\nThis example shows that a negative value can be returned when the input is an\narray of signed integers.\n\nA work-around is to use the `view()` method to view the result as unsigned\nintegers with the same bit width:\n\n"}, {"name": "ma.ravel()", "path": "reference/generated/numpy.ma.ravel", "type": "numpy.ma.ravel", "text": "\nReturns a 1D version of self, as a view.\n\nThe elements of `a` are read using this index order. \u2018C\u2019 means to index the\nelements in C-like order, with the last axis index changing fastest, back to\nthe first axis index changing slowest. \u2018F\u2019 means to index the elements in\nFortran-like index order, with the first index changing fastest, and the last\nindex changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of\nthe memory layout of the underlying array, and only refer to the order of axis\nindexing. \u2018A\u2019 means to read the elements in Fortran-like index order if `m` is\nFortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the\nelements in the order they occur in memory, except for reversing the data when\nstrides are negative. By default, \u2018C\u2019 index order is used.\n\nOutput view is of shape `(self.size,)` (or `(np.ma.product(self.shape),)`).\n\n"}, {"name": "ma.reshape()", "path": "reference/generated/numpy.ma.reshape", "type": "numpy.ma.reshape", "text": "\nReturns an array containing the same data with a new shape.\n\nRefer to `MaskedArray.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.resize()", "path": "reference/generated/numpy.ma.resize", "type": "numpy.ma.resize", "text": "\nReturn a new masked array with the specified size and shape.\n\nThis is the masked equivalent of the `numpy.resize` function. The new array is\nfilled with repeated copies of `x` (in the order that the data are stored in\nmemory). If `x` is masked, the new array will be masked, and the new mask will\nbe a repetition of the old one.\n\nSee also\n\nEquivalent function in the top level NumPy module.\n\nA MaskedArray is always returned, regardless of the input type.\n\n"}, {"name": "ma.round()", "path": "reference/generated/numpy.ma.round", "type": "numpy.ma.round", "text": "\nReturn a copy of a, rounded to \u2018decimals\u2019 places.\n\nWhen \u2018decimals\u2019 is negative, it specifies the number of positions to the left\nof the decimal point. The real and imaginary parts of complex numbers are\nrounded separately. Nothing is done if the array is not of float type and\n\u2018decimals\u2019 is greater than or equal to 0.\n\nNumber of decimals to round to. May be negative.\n\nExisting array to use for output. If not given, returns a default copy of a.\n\nIf out is given and does not have a mask attribute, the mask of a is lost!\n\n"}, {"name": "ma.row_stack()", "path": "reference/generated/numpy.ma.row_stack", "type": "numpy.ma.row_stack", "text": "\nStack arrays in sequence vertically (row wise).\n\nThis is equivalent to concatenation along the first axis after 1-D arrays of\nshape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the first axis. 1-D arrays\nmust have the same length.\n\nThe array formed by stacking the given arrays, will be at least 2-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.set_fill_value()", "path": "reference/generated/numpy.ma.set_fill_value", "type": "numpy.ma.set_fill_value", "text": "\nSet the filling value of a, if a is a masked array.\n\nThis function changes the fill value of the masked array `a` in place. If `a`\nis not a masked array, the function returns silently, without doing anything.\n\nInput array.\n\nFilling value. A consistency test is performed to make sure the value is\ncompatible with the dtype of `a`.\n\nNothing returned by this function.\n\nSee also\n\nReturn the default fill value for a dtype.\n\nReturn current fill value.\n\nEquivalent method.\n\nNothing happens if `a` is not a masked array.\n\n"}, {"name": "ma.shape()", "path": "reference/generated/numpy.ma.shape", "type": "numpy.ma.shape", "text": "\nReturn the shape of an array.\n\nInput array.\n\nThe elements of the shape tuple give the lengths of the corresponding array\ndimensions.\n\nSee also\n\nEquivalent array method.\n\n"}, {"name": "ma.size()", "path": "reference/generated/numpy.ma.size", "type": "numpy.ma.size", "text": "\nReturn the number of elements along a given axis.\n\nInput data.\n\nAxis along which the elements are counted. By default, give the total number\nof elements.\n\nNumber of elements along the specified axis.\n\nSee also\n\ndimensions of array\n\ndimensions of array\n\nnumber of elements in array\n\n"}, {"name": "ma.soften_mask()", "path": "reference/generated/numpy.ma.soften_mask", "type": "numpy.ma.soften_mask", "text": "\nForce the mask to soft.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `soften_mask` sets `hardmask` to `False`.\n\nSee also\n\n"}, {"name": "ma.sort()", "path": "reference/generated/numpy.ma.sort", "type": "numpy.ma.sort", "text": "\nReturn a sorted copy of the masked array.\n\nEquivalent to creating a copy of the array and applying the MaskedArray\n`sort()` method.\n\nRefer to `MaskedArray.sort` for the full documentation\n\nSee also\n\nequivalent method\n\n"}, {"name": "ma.squeeze()", "path": "reference/generated/numpy.ma.squeeze", "type": "numpy.ma.squeeze", "text": "\nRemove axes of length one from `a`.\n\nInput data.\n\nNew in version 1.7.0.\n\nSelects a subset of the entries of length one in the shape. If an axis is\nselected with shape entry greater than one, an error is raised.\n\nThe input array, but with all or a subset of the dimensions of length 1\nremoved. This is always `a` itself or a view into `a`. Note that if all axes\nare squeezed, the result is a 0d array and not a scalar.\n\nIf `axis` is not None, and an axis being squeezed is not of length 1\n\nSee also\n\nThe inverse operation, adding entries of length one\n\nInsert, remove, and combine dimensions, and resize existing ones\n\n"}, {"name": "ma.stack()", "path": "reference/generated/numpy.ma.stack", "type": "numpy.ma.stack", "text": "\nJoin a sequence of arrays along a new axis.\n\nThe `axis` parameter specifies the index of the new axis in the dimensions of\nthe result. For example, if `axis=0` it will be the first dimension and if\n`axis=-1` it will be the last dimension.\n\nNew in version 1.10.0.\n\nEach array must have the same shape.\n\nThe axis in the result array along which the input arrays are stacked.\n\nIf provided, the destination to place the result. The shape must be correct,\nmatching that of what stack would have returned if no out argument were\nspecified.\n\nThe stacked array has one more dimension than the input arrays.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nSplit array into a list of multiple sub-arrays of equal size.\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.std()", "path": "reference/generated/numpy.ma.std", "type": "numpy.ma.std", "text": "\nReturns the standard deviation of the array elements along given axis.\n\nMasked entries are ignored.\n\nRefer to `numpy.std` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\n"}, {"name": "ma.sum()", "path": "reference/generated/numpy.ma.sum", "type": "numpy.ma.sum", "text": "\nReturn the sum of the array elements over the given axis.\n\nMasked elements are set to 0 internally.\n\nRefer to `numpy.sum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.swapaxes()", "path": "reference/generated/numpy.ma.swapaxes", "type": "numpy.ma.swapaxes", "text": "\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.trace()", "path": "reference/generated/numpy.ma.trace", "type": "numpy.ma.trace", "text": "\nReturn the sum along diagonals of the array.\n\nRefer to `numpy.trace` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.transpose()", "path": "reference/generated/numpy.ma.transpose", "type": "numpy.ma.transpose", "text": "\nPermute the dimensions of an array.\n\nThis function is exactly equivalent to `numpy.transpose`.\n\nSee also\n\nEquivalent function in top-level NumPy module.\n\n"}, {"name": "ma.vander()", "path": "reference/generated/numpy.ma.vander", "type": "numpy.ma.vander", "text": "\nGenerate a Vandermonde matrix.\n\nThe columns of the output matrix are powers of the input vector. The order of\nthe powers is determined by the `increasing` boolean argument. Specifically,\nwhen `increasing` is False, the `i`-th output column is the input vector\nraised element-wise to the power of `N - i - 1`. Such a matrix with a\ngeometric progression in each row is named for Alexandre- Theophile\nVandermonde.\n\n1-D input array.\n\nNumber of columns in the output. If `N` is not specified, a square array is\nreturned (`N = len(x)`).\n\nOrder of the powers of the columns. If True, the powers increase from left to\nright, if False (the default) they are reversed.\n\nNew in version 1.9.0.\n\nVandermonde matrix. If `increasing` is False, the first column is `x^(N-1)`,\nthe second `x^(N-2)` and so forth. If `increasing` is True, the columns are\n`x^0, x^1, ..., x^(N-1)`.\n\nSee also\n\nMasked values in the input array result in rows of zeros.\n\nThe determinant of a square Vandermonde matrix is the product of the\ndifferences between the values of the input vector:\n\n"}, {"name": "ma.var()", "path": "reference/generated/numpy.ma.var", "type": "numpy.ma.var", "text": "\nCompute the variance along the specified axis.\n\nReturns the variance of the array elements, a measure of the spread of a\ndistribution. The variance is computed for the flattened array by default,\notherwise over the specified axis.\n\nArray containing numbers whose variance is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the variance is computed. The default is to compute\nthe variance of the flattened array.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a variance is performed over multiple axes,\ninstead of a single axis or all the axes as before.\n\nType to use in computing the variance. For arrays of integer type the default\nis `float64`; for arrays of float types it is the same as the array type.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output, but the type is cast if necessary.\n\n\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is `N - ddof`,\nwhere `N` represents the number of elements. By default `ddof` is zero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `var` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in the variance. See `reduce` for details.\n\nNew in version 1.20.0.\n\nIf `out=None`, returns a new array containing the variance; otherwise, a\nreference to the output array is returned.\n\nSee also\n\nThe variance is the average of the squared deviations from the mean, i.e.,\n`var = mean(x)`, where `x = abs(a - a.mean())**2`.\n\nThe mean is typically calculated as `x.sum() / N`, where `N = len(x)`. If,\nhowever, `ddof` is specified, the divisor `N - ddof` is used instead. In\nstandard statistical practice, `ddof=1` provides an unbiased estimator of the\nvariance of a hypothetical infinite population. `ddof=0` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\n\nNote that for complex numbers, the absolute value is taken before squaring, so\nthat the result is always real and nonnegative.\n\nFor floating-point input, the variance is computed using the same precision\nthe input has. Depending on the input data, this can cause the results to be\ninaccurate, especially for `float32` (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\nIn single precision, var() can be inaccurate:\n\nComputing the variance in float64 is more accurate:\n\nSpecifying a where argument:\n\n"}, {"name": "ma.vstack()", "path": "reference/generated/numpy.ma.vstack", "type": "numpy.ma.vstack", "text": "\nStack arrays in sequence vertically (row wise).\n\nThis is equivalent to concatenation along the first axis after 1-D arrays of\nshape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the first axis. 1-D arrays\nmust have the same length.\n\nThe array formed by stacking the given arrays, will be at least 2-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.where()", "path": "reference/generated/numpy.ma.where", "type": "numpy.ma.where", "text": "\nReturn a masked array with elements from `x` or `y`, depending on condition.\n\nNote\n\nWhen only `condition` is provided, this function is identical to `nonzero`.\nThe rest of this documentation covers only the case where all three arguments\nare provided.\n\nWhere True, yield `x`, otherwise yield `y`.\n\nValues from which to choose. `x`, `y` and `condition` need to be broadcastable\nto some shape.\n\nAn masked array with `masked` elements where the condition is masked, elements\nfrom `x` where `condition` is True, and elements from `y` elsewhere.\n\nSee also\n\nEquivalent function in the top-level NumPy module.\n\nThe function that is called when x and y are omitted\n\n"}, {"name": "ma.zeros()", "path": "reference/generated/numpy.ma.zeros", "type": "numpy.ma.zeros", "text": "\nReturn a new array of given shape and type, filled with zeros.\n\nShape of the new array, e.g., `(2, 3)` or `2`.\n\nThe desired data-type for the array, e.g., `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of zeros with the given shape, dtype, and order.\n\nSee also\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to one.\n\nReturn a new array of given shape filled with value.\n\n"}, {"name": "ma.zeros_like()", "path": "reference/generated/numpy.ma.zeros_like", "type": "numpy.ma.zeros_like", "text": "\nReturn an array of zeros with the same shape and type as a given array.\n\nThe shape and data-type of `a` define these same attributes of the returned\narray.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means\nmatch the layout of `a` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of `a`,\notherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of zeros with the same shape and type as `a`.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of ones with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new array setting values to zero.\n\n"}, {"name": "make_config_py()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.make_config_py", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nGenerate package __config__.py file containing system_info information used\nduring building the package.\n\nThis file is installed to the package installation directory.\n\n"}, {"name": "make_svn_version_py()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.make_svn_version_py", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAppends a data function to the data_files list that will generate\n__svn_version__.py file to the current package directory.\n\nGenerate package __svn_version__.py file from SVN revision number, it will be\nremoved after python exits but will be available when sdist, etc commands are\nexecuted.\n\nIf __svn_version__.py existed before, nothing is done.\n\nThis is intended for working with source directories that are in an SVN\nrepository.\n\n"}, {"name": "Masked array operations", "path": "reference/routines.ma", "type": "Masked array operations", "text": "\n`ma.MaskType`\n\nalias of `numpy.bool_`\n\n`ma.masked_array`\n\nalias of `numpy.ma.core.MaskedArray`\n\n`ma.array`(data[, dtype, copy, order, mask, ...])\n\nAn array class with possibly masked values.\n\n`ma.copy`(self, *args, **params) a.copy(order=)\n\nReturn a copy of the array.\n\n`ma.frombuffer`(buffer[, dtype, count, ...])\n\nInterpret a buffer as a 1-dimensional array.\n\n`ma.fromfunction`(function, shape, **dtype)\n\nConstruct an array by executing a function over each coordinate.\n\n`ma.MaskedArray.copy`([order])\n\nReturn a copy of the array.\n\n`ma.empty`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, without initializing entries.\n\n`ma.empty_like`(prototype[, dtype, order, ...])\n\nReturn a new array with the same shape and type as a given array.\n\n`ma.masked_all`(shape[, dtype])\n\nEmpty masked array with all elements masked.\n\n`ma.masked_all_like`(arr)\n\nEmpty masked array with the properties of an existing array.\n\n`ma.ones`(shape[, dtype, order])\n\nReturn a new array of given shape and type, filled with ones.\n\n`ma.ones_like`(*args, **kwargs)\n\nReturn an array of ones with the same shape and type as a given array.\n\n`ma.zeros`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with zeros.\n\n`ma.zeros_like`(*args, **kwargs)\n\nReturn an array of zeros with the same shape and type as a given array.\n\n`ma.all`(self[, axis, out, keepdims])\n\nReturns True if all elements evaluate to True.\n\n`ma.any`(self[, axis, out, keepdims])\n\nReturns True if any of the elements of `a` evaluate to True.\n\n`ma.count`(self[, axis, keepdims])\n\nCount the non-masked elements of the array along the given axis.\n\n`ma.count_masked`(arr[, axis])\n\nCount the number of masked elements along the given axis.\n\n`ma.getmask`(a)\n\nReturn the mask of a masked array, or nomask.\n\n`ma.getmaskarray`(arr)\n\nReturn the mask of a masked array, or full boolean array of False.\n\n`ma.getdata`(a[, subok])\n\nReturn the data of a masked array as an ndarray.\n\n`ma.nonzero`(self)\n\nReturn the indices of unmasked elements that are not zero.\n\n`ma.shape`(obj)\n\nReturn the shape of an array.\n\n`ma.size`(obj[, axis])\n\nReturn the number of elements along a given axis.\n\n`ma.is_masked`(x)\n\nDetermine whether input has masked values.\n\n`ma.is_mask`(m)\n\nReturn True if m is a valid, standard mask.\n\n`ma.isMaskedArray`(x)\n\nTest whether input is an instance of MaskedArray.\n\n`ma.isMA`(x)\n\nTest whether input is an instance of MaskedArray.\n\n`ma.isarray`(x)\n\nTest whether input is an instance of MaskedArray.\n\n`ma.MaskedArray.all`([axis, out, keepdims])\n\nReturns True if all elements evaluate to True.\n\n`ma.MaskedArray.any`([axis, out, keepdims])\n\nReturns True if any of the elements of `a` evaluate to True.\n\n`ma.MaskedArray.count`([axis, keepdims])\n\nCount the non-masked elements of the array along the given axis.\n\n`ma.MaskedArray.nonzero`()\n\nReturn the indices of unmasked elements that are not zero.\n\n`ma.shape`(obj)\n\nReturn the shape of an array.\n\n`ma.size`(obj[, axis])\n\nReturn the number of elements along a given axis.\n\n`ma.MaskedArray.data`\n\nReturns the underlying data, as a view of the masked array.\n\n`ma.MaskedArray.mask`\n\nCurrent mask.\n\n`ma.MaskedArray.recordmask`\n\nGet or set the mask of the array if it has no named fields.\n\n`ma.ravel`(self[, order])\n\nReturns a 1D version of self, as a view.\n\n`ma.reshape`(a, new_shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`ma.resize`(x, new_shape)\n\nReturn a new masked array with the specified size and shape.\n\n`ma.MaskedArray.flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`ma.MaskedArray.ravel`([order])\n\nReturns a 1D version of self, as a view.\n\n`ma.MaskedArray.reshape`(*s, **kwargs)\n\nGive a new shape to the array without changing its data.\n\n`ma.MaskedArray.resize`(newshape[, refcheck, ...])\n\n`ma.swapaxes`(self, *args, ...)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`ma.transpose`(a[, axes])\n\nPermute the dimensions of an array.\n\n`ma.MaskedArray.swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`ma.MaskedArray.transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`ma.atleast_1d`(*args, **kwargs)\n\nConvert inputs to arrays with at least one dimension.\n\n`ma.atleast_2d`(*args, **kwargs)\n\nView inputs as arrays with at least two dimensions.\n\n`ma.atleast_3d`(*args, **kwargs)\n\nView inputs as arrays with at least three dimensions.\n\n`ma.expand_dims`(a, axis)\n\nExpand the shape of an array.\n\n`ma.squeeze`(*args, **kwargs)\n\nRemove axes of length one from `a`.\n\n`ma.MaskedArray.squeeze`([axis])\n\nRemove axes of length one from `a`.\n\n`ma.stack`(*args, **kwargs)\n\nJoin a sequence of arrays along a new axis.\n\n`ma.column_stack`(*args, **kwargs)\n\nStack 1-D arrays as columns into a 2-D array.\n\n`ma.concatenate`(arrays[, axis])\n\nConcatenate a sequence of arrays along the given axis.\n\n`ma.dstack`(*args, **kwargs)\n\nStack arrays in sequence depth wise (along third axis).\n\n`ma.hstack`(*args, **kwargs)\n\nStack arrays in sequence horizontally (column wise).\n\n`ma.hsplit`(*args, **kwargs)\n\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\n`ma.mr_`\n\nTranslate slice objects to concatenation along the first axis.\n\n`ma.row_stack`(*args, **kwargs)\n\nStack arrays in sequence vertically (row wise).\n\n`ma.vstack`(*args, **kwargs)\n\nStack arrays in sequence vertically (row wise).\n\n`ma.concatenate`(arrays[, axis])\n\nConcatenate a sequence of arrays along the given axis.\n\n`ma.stack`(*args, **kwargs)\n\nJoin a sequence of arrays along a new axis.\n\n`ma.vstack`(*args, **kwargs)\n\nStack arrays in sequence vertically (row wise).\n\n`ma.hstack`(*args, **kwargs)\n\nStack arrays in sequence horizontally (column wise).\n\n`ma.dstack`(*args, **kwargs)\n\nStack arrays in sequence depth wise (along third axis).\n\n`ma.column_stack`(*args, **kwargs)\n\nStack 1-D arrays as columns into a 2-D array.\n\n`ma.append`(a, b[, axis])\n\nAppend values to the end of an array.\n\n`ma.make_mask`(m[, copy, shrink, dtype])\n\nCreate a boolean mask from an array.\n\n`ma.make_mask_none`(newshape[, dtype])\n\nReturn a boolean mask of the given shape, filled with False.\n\n`ma.mask_or`(m1, m2[, copy, shrink])\n\nCombine two masks with the `logical_or` operator.\n\n`ma.make_mask_descr`(ndtype)\n\nConstruct a dtype description list from a given dtype.\n\n`ma.getmask`(a)\n\nReturn the mask of a masked array, or nomask.\n\n`ma.getmaskarray`(arr)\n\nReturn the mask of a masked array, or full boolean array of False.\n\n`ma.masked_array.mask`\n\nCurrent mask.\n\n`ma.flatnotmasked_contiguous`(a)\n\nFind contiguous unmasked data in a masked array along the given axis.\n\n`ma.flatnotmasked_edges`(a)\n\nFind the indices of the first and last unmasked values.\n\n`ma.notmasked_contiguous`(a[, axis])\n\nFind contiguous unmasked data in a masked array along the given axis.\n\n`ma.notmasked_edges`(a[, axis])\n\nFind the indices of the first and last unmasked values along an axis.\n\n`ma.clump_masked`(a)\n\nReturns a list of slices corresponding to the masked clumps of a 1-D array.\n\n`ma.clump_unmasked`(a)\n\nReturn list of slices corresponding to the unmasked clumps of a 1-D array.\n\n`ma.mask_cols`(a[, axis])\n\nMask columns of a 2D array that contain masked values.\n\n`ma.mask_or`(m1, m2[, copy, shrink])\n\nCombine two masks with the `logical_or` operator.\n\n`ma.mask_rowcols`(a[, axis])\n\nMask rows and/or columns of a 2D array that contain masked values.\n\n`ma.mask_rows`(a[, axis])\n\nMask rows of a 2D array that contain masked values.\n\n`ma.harden_mask`(self)\n\nForce the mask to hard.\n\n`ma.soften_mask`(self)\n\nForce the mask to soft.\n\n`ma.MaskedArray.harden_mask`()\n\nForce the mask to hard.\n\n`ma.MaskedArray.soften_mask`()\n\nForce the mask to soft.\n\n`ma.MaskedArray.shrink_mask`()\n\nReduce a mask to nomask when possible.\n\n`ma.MaskedArray.unshare_mask`()\n\nCopy the mask and set the sharedmask flag to False.\n\n`ma.asarray`(a[, dtype, order])\n\nConvert the input to a masked array of the given data-type.\n\n`ma.asanyarray`(a[, dtype])\n\nConvert the input to a masked array, conserving subclasses.\n\n`ma.fix_invalid`(a[, mask, copy, fill_value])\n\nReturn input with invalid data masked and replaced by a fill value.\n\n`ma.masked_equal`(x, value[, copy])\n\nMask an array where equal to a given value.\n\n`ma.masked_greater`(x, value[, copy])\n\nMask an array where greater than a given value.\n\n`ma.masked_greater_equal`(x, value[, copy])\n\nMask an array where greater than or equal to a given value.\n\n`ma.masked_inside`(x, v1, v2[, copy])\n\nMask an array inside a given interval.\n\n`ma.masked_invalid`(a[, copy])\n\nMask an array where invalid values occur (NaNs or infs).\n\n`ma.masked_less`(x, value[, copy])\n\nMask an array where less than a given value.\n\n`ma.masked_less_equal`(x, value[, copy])\n\nMask an array where less than or equal to a given value.\n\n`ma.masked_not_equal`(x, value[, copy])\n\nMask an array where `not` equal to a given value.\n\n`ma.masked_object`(x, value[, copy, shrink])\n\nMask the array `x` where the data are exactly equal to value.\n\n`ma.masked_outside`(x, v1, v2[, copy])\n\nMask an array outside a given interval.\n\n`ma.masked_values`(x, value[, rtol, atol, ...])\n\nMask using floating point equality.\n\n`ma.masked_where`(condition, a[, copy])\n\nMask an array where a condition is met.\n\n`ma.compress_cols`(a)\n\nSuppress whole columns of a 2-D array that contain masked values.\n\n`ma.compress_rowcols`(x[, axis])\n\nSuppress the rows and/or columns of a 2-D array that contain masked values.\n\n`ma.compress_rows`(a)\n\nSuppress whole rows of a 2-D array that contain masked values.\n\n`ma.compressed`(x)\n\nReturn all the non-masked data as a 1-D array.\n\n`ma.filled`(a[, fill_value])\n\nReturn input as an array with masked data replaced by a fill value.\n\n`ma.MaskedArray.compressed`()\n\nReturn all the non-masked data as a 1-D array.\n\n`ma.MaskedArray.filled`([fill_value])\n\nReturn a copy of self, with masked values filled with a given value.\n\n`ma.MaskedArray.tofile`(fid[, sep, format])\n\nSave a masked array to a file in binary format.\n\n`ma.MaskedArray.tolist`([fill_value])\n\nReturn the data portion of the masked array as a hierarchical Python list.\n\n`ma.MaskedArray.torecords`()\n\nTransforms a masked array into a flexible-type array.\n\n`ma.MaskedArray.tobytes`([fill_value, order])\n\nReturn the array data as a string containing the raw bytes in the array.\n\n`ma.common_fill_value`(a, b)\n\nReturn the common filling value of two masked arrays, if any.\n\n`ma.default_fill_value`(obj)\n\nReturn the default fill value for the argument object.\n\n`ma.maximum_fill_value`(obj)\n\nReturn the minimum value that can be represented by the dtype of an object.\n\n`ma.minimum_fill_value`(obj)\n\nReturn the maximum value that can be represented by the dtype of an object.\n\n`ma.set_fill_value`(a, fill_value)\n\nSet the filling value of a, if a is a masked array.\n\n`ma.MaskedArray.get_fill_value`()\n\nThe filling value of the masked array is a scalar.\n\n`ma.MaskedArray.set_fill_value`([value])\n\n`ma.MaskedArray.fill_value`\n\nThe filling value of the masked array is a scalar.\n\n`ma.anom`(self[, axis, dtype])\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\n`ma.anomalies`(self[, axis, dtype])\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\n`ma.average`(a[, axis, weights, returned])\n\nReturn the weighted average of array over the given axis.\n\n`ma.conjugate`(x, /[, out, where, casting, ...])\n\nReturn the complex conjugate, element-wise.\n\n`ma.corrcoef`(x[, y, rowvar, bias, ...])\n\nReturn Pearson product-moment correlation coefficients.\n\n`ma.cov`(x[, y, rowvar, bias, allow_masked, ddof])\n\nEstimate the covariance matrix.\n\n`ma.cumsum`(self[, axis, dtype, out])\n\nReturn the cumulative sum of the array elements over the given axis.\n\n`ma.cumprod`(self[, axis, dtype, out])\n\nReturn the cumulative product of the array elements over the given axis.\n\n`ma.mean`(self[, axis, dtype, out, keepdims])\n\nReturns the average of the array elements along given axis.\n\n`ma.median`(a[, axis, out, overwrite_input, ...])\n\nCompute the median along the specified axis.\n\n`ma.power`(a, b[, third])\n\nReturns element-wise base array raised to power from second array.\n\n`ma.prod`(self[, axis, dtype, out, keepdims])\n\nReturn the product of the array elements over the given axis.\n\n`ma.std`(self[, axis, dtype, out, ddof, keepdims])\n\nReturns the standard deviation of the array elements along given axis.\n\n`ma.sum`(self[, axis, dtype, out, keepdims])\n\nReturn the sum of the array elements over the given axis.\n\n`ma.var`(self[, axis, dtype, out, ddof, keepdims])\n\nCompute the variance along the specified axis.\n\n`ma.MaskedArray.anom`([axis, dtype])\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\n`ma.MaskedArray.cumprod`([axis, dtype, out])\n\nReturn the cumulative product of the array elements over the given axis.\n\n`ma.MaskedArray.cumsum`([axis, dtype, out])\n\nReturn the cumulative sum of the array elements over the given axis.\n\n`ma.MaskedArray.mean`([axis, dtype, out, keepdims])\n\nReturns the average of the array elements along given axis.\n\n`ma.MaskedArray.prod`([axis, dtype, out, keepdims])\n\nReturn the product of the array elements over the given axis.\n\n`ma.MaskedArray.std`([axis, dtype, out, ddof, ...])\n\nReturns the standard deviation of the array elements along given axis.\n\n`ma.MaskedArray.sum`([axis, dtype, out, keepdims])\n\nReturn the sum of the array elements over the given axis.\n\n`ma.MaskedArray.var`([axis, dtype, out, ddof, ...])\n\nCompute the variance along the specified axis.\n\n`ma.argmax`(self[, axis, fill_value, out])\n\nReturns array of indices of the maximum values along the given axis.\n\n`ma.argmin`(self[, axis, fill_value, out])\n\nReturn array of indices to the minimum values along the given axis.\n\n`ma.max`(obj[, axis, out, fill_value, keepdims])\n\nReturn the maximum along a given axis.\n\n`ma.min`(obj[, axis, out, fill_value, keepdims])\n\nReturn the minimum along a given axis.\n\n`ma.ptp`(obj[, axis, out, fill_value, keepdims])\n\nReturn (maximum - minimum) along the given dimension (i.e.\n\n`ma.diff`(*args, **kwargs)\n\nCalculate the n-th discrete difference along the given axis.\n\n`ma.MaskedArray.argmax`([axis, fill_value, ...])\n\nReturns array of indices of the maximum values along the given axis.\n\n`ma.MaskedArray.argmin`([axis, fill_value, ...])\n\nReturn array of indices to the minimum values along the given axis.\n\n`ma.MaskedArray.max`([axis, out, fill_value, ...])\n\nReturn the maximum along a given axis.\n\n`ma.MaskedArray.min`([axis, out, fill_value, ...])\n\nReturn the minimum along a given axis.\n\n`ma.MaskedArray.ptp`([axis, out, fill_value, ...])\n\nReturn (maximum - minimum) along the given dimension (i.e.\n\n`ma.argsort`(a[, axis, kind, order, endwith, ...])\n\nReturn an ndarray of indices that sort the array along the specified axis.\n\n`ma.sort`(a[, axis, kind, order, endwith, ...])\n\nReturn a sorted copy of the masked array.\n\n`ma.MaskedArray.argsort`([axis, kind, order, ...])\n\nReturn an ndarray of indices that sort the array along the specified axis.\n\n`ma.MaskedArray.sort`([axis, kind, order, ...])\n\nSort the array, in-place\n\n`ma.diag`(v[, k])\n\nExtract a diagonal or construct a diagonal array.\n\n`ma.dot`(a, b[, strict, out])\n\nReturn the dot product of two arrays.\n\n`ma.identity`(n[, dtype])\n\nReturn the identity array.\n\n`ma.inner`(a, b, /)\n\nInner product of two arrays.\n\n`ma.innerproduct`(a, b, /)\n\nInner product of two arrays.\n\n`ma.outer`(a, b)\n\nCompute the outer product of two vectors.\n\n`ma.outerproduct`(a, b)\n\nCompute the outer product of two vectors.\n\n`ma.trace`(self[, offset, axis1, axis2, ...])\n\nReturn the sum along diagonals of the array.\n\n`ma.transpose`(a[, axes])\n\nPermute the dimensions of an array.\n\n`ma.MaskedArray.trace`([offset, axis1, axis2, ...])\n\nReturn the sum along diagonals of the array.\n\n`ma.MaskedArray.transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`ma.vander`(x[, n])\n\nGenerate a Vandermonde matrix.\n\n`ma.polyfit`(x, y, deg[, rcond, full, w, cov])\n\nLeast squares polynomial fit.\n\n`ma.around`\n\nRound an array to the given number of decimals.\n\n`ma.clip`(*args, **kwargs)\n\nClip (limit) the values in an array.\n\n`ma.round`(a[, decimals, out])\n\nReturn a copy of a, rounded to 'decimals' places.\n\n`ma.MaskedArray.clip`([min, max, out])\n\nReturn an array whose values are limited to `[min, max]`.\n\n`ma.MaskedArray.round`([decimals, out])\n\nReturn each element rounded to the given number of decimals.\n\n`ma.allequal`(a, b[, fill_value])\n\nReturn True if all entries of a and b are equal, using fill_value as a truth\nvalue where either or both are masked.\n\n`ma.allclose`(a, b[, masked_equal, rtol, atol])\n\nReturns True if two arrays are element-wise equal within a tolerance.\n\n`ma.apply_along_axis`(func1d, axis, arr, ...)\n\nApply a function to 1-D slices along the given axis.\n\n`ma.apply_over_axes`(func, a, axes)\n\nApply a function repeatedly over multiple axes.\n\n`ma.arange`([start,] stop[, step,][, dtype, like])\n\nReturn evenly spaced values within a given interval.\n\n`ma.choose`(indices, choices[, out, mode])\n\nUse an index array to construct a new array from a list of choices.\n\n`ma.ediff1d`(arr[, to_end, to_begin])\n\nCompute the differences between consecutive elements of an array.\n\n`ma.indices`(dimensions[, dtype, sparse])\n\nReturn an array representing the indices of a grid.\n\n`ma.where`(condition[, x, y])\n\nReturn a masked array with elements from `x` or `y`, depending on condition.\n\n"}, {"name": "Masked arrays", "path": "reference/maskedarray", "type": "Masked arrays", "text": "\nMasked arrays are arrays that may have missing or invalid entries. The\n`numpy.ma` module provides a nearly work-alike replacement for numpy that\nsupports data arrays with masks.\n\n"}, {"name": "MaskedArray.baseclass", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.baseclass", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.fill_value", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.fill_value", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.hardmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.hardmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.mask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.mask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.recordmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.recordmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.sharedmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.sharedmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "Mathematical functions", "path": "reference/routines.math", "type": "Mathematical functions", "text": "\n`sin`(x, /[, out, where, casting, order, ...])\n\nTrigonometric sine, element-wise.\n\n`cos`(x, /[, out, where, casting, order, ...])\n\nCosine element-wise.\n\n`tan`(x, /[, out, where, casting, order, ...])\n\nCompute tangent element-wise.\n\n`arcsin`(x, /[, out, where, casting, order, ...])\n\nInverse sine, element-wise.\n\n`arccos`(x, /[, out, where, casting, order, ...])\n\nTrigonometric inverse cosine, element-wise.\n\n`arctan`(x, /[, out, where, casting, order, ...])\n\nTrigonometric inverse tangent, element-wise.\n\n`hypot`(x1, x2, /[, out, where, casting, ...])\n\nGiven the \"legs\" of a right triangle, return its hypotenuse.\n\n`arctan2`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise arc tangent of `x1/x2` choosing the quadrant correctly.\n\n`degrees`(x, /[, out, where, casting, order, ...])\n\nConvert angles from radians to degrees.\n\n`radians`(x, /[, out, where, casting, order, ...])\n\nConvert angles from degrees to radians.\n\n`unwrap`(p[, discont, axis, period])\n\nUnwrap by taking the complement of large deltas with respect to the period.\n\n`deg2rad`(x, /[, out, where, casting, order, ...])\n\nConvert angles from degrees to radians.\n\n`rad2deg`(x, /[, out, where, casting, order, ...])\n\nConvert angles from radians to degrees.\n\n`sinh`(x, /[, out, where, casting, order, ...])\n\nHyperbolic sine, element-wise.\n\n`cosh`(x, /[, out, where, casting, order, ...])\n\nHyperbolic cosine, element-wise.\n\n`tanh`(x, /[, out, where, casting, order, ...])\n\nCompute hyperbolic tangent element-wise.\n\n`arcsinh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic sine element-wise.\n\n`arccosh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic cosine, element-wise.\n\n`arctanh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic tangent element-wise.\n\n`around`(a[, decimals, out])\n\nEvenly round to the given number of decimals.\n\n`round_`(a[, decimals, out])\n\nRound an array to the given number of decimals.\n\n`rint`(x, /[, out, where, casting, order, ...])\n\nRound elements of the array to the nearest integer.\n\n`fix`(x[, out])\n\nRound to nearest integer towards zero.\n\n`floor`(x, /[, out, where, casting, order, ...])\n\nReturn the floor of the input, element-wise.\n\n`ceil`(x, /[, out, where, casting, order, ...])\n\nReturn the ceiling of the input, element-wise.\n\n`trunc`(x, /[, out, where, casting, order, ...])\n\nReturn the truncated value of the input, element-wise.\n\n`prod`(a[, axis, dtype, out, keepdims, ...])\n\nReturn the product of array elements over a given axis.\n\n`sum`(a[, axis, dtype, out, keepdims, ...])\n\nSum of array elements over a given axis.\n\n`nanprod`(a[, axis, dtype, out, keepdims, ...])\n\nReturn the product of array elements over a given axis treating Not a Numbers\n(NaNs) as ones.\n\n`nansum`(a[, axis, dtype, out, keepdims, ...])\n\nReturn the sum of array elements over a given axis treating Not a Numbers\n(NaNs) as zero.\n\n`cumprod`(a[, axis, dtype, out])\n\nReturn the cumulative product of elements along a given axis.\n\n`cumsum`(a[, axis, dtype, out])\n\nReturn the cumulative sum of the elements along a given axis.\n\n`nancumprod`(a[, axis, dtype, out])\n\nReturn the cumulative product of array elements over a given axis treating Not\na Numbers (NaNs) as one.\n\n`nancumsum`(a[, axis, dtype, out])\n\nReturn the cumulative sum of array elements over a given axis treating Not a\nNumbers (NaNs) as zero.\n\n`diff`(a[, n, axis, prepend, append])\n\nCalculate the n-th discrete difference along the given axis.\n\n`ediff1d`(ary[, to_end, to_begin])\n\nThe differences between consecutive elements of an array.\n\n`gradient`(f, *varargs[, axis, edge_order])\n\nReturn the gradient of an N-dimensional array.\n\n`cross`(a, b[, axisa, axisb, axisc, axis])\n\nReturn the cross product of two (arrays of) vectors.\n\n`trapz`(y[, x, dx, axis])\n\nIntegrate along the given axis using the composite trapezoidal rule.\n\n`exp`(x, /[, out, where, casting, order, ...])\n\nCalculate the exponential of all elements in the input array.\n\n`expm1`(x, /[, out, where, casting, order, ...])\n\nCalculate `exp(x) - 1` for all elements in the array.\n\n`exp2`(x, /[, out, where, casting, order, ...])\n\nCalculate `2**p` for all `p` in the input array.\n\n`log`(x, /[, out, where, casting, order, ...])\n\nNatural logarithm, element-wise.\n\n`log10`(x, /[, out, where, casting, order, ...])\n\nReturn the base 10 logarithm of the input array, element-wise.\n\n`log2`(x, /[, out, where, casting, order, ...])\n\nBase-2 logarithm of `x`.\n\n`log1p`(x, /[, out, where, casting, order, ...])\n\nReturn the natural logarithm of one plus the input array, element-wise.\n\n`logaddexp`(x1, x2, /[, out, where, casting, ...])\n\nLogarithm of the sum of exponentiations of the inputs.\n\n`logaddexp2`(x1, x2, /[, out, where, casting, ...])\n\nLogarithm of the sum of exponentiations of the inputs in base-2.\n\n`i0`(x)\n\nModified Bessel function of the first kind, order 0.\n\n`sinc`(x)\n\nReturn the normalized sinc function.\n\n`signbit`(x, /[, out, where, casting, order, ...])\n\nReturns element-wise True where signbit is set (less than zero).\n\n`copysign`(x1, x2, /[, out, where, casting, ...])\n\nChange the sign of x1 to that of x2, element-wise.\n\n`frexp`(x[, out1, out2], / [[, out, where, ...])\n\nDecompose the elements of x into mantissa and twos exponent.\n\n`ldexp`(x1, x2, /[, out, where, casting, ...])\n\nReturns x1 * 2**x2, element-wise.\n\n`nextafter`(x1, x2, /[, out, where, casting, ...])\n\nReturn the next floating-point value after x1 towards x2, element-wise.\n\n`spacing`(x, /[, out, where, casting, order, ...])\n\nReturn the distance between x and the nearest adjacent number.\n\n`lcm`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the lowest common multiple of `|x1|` and `|x2|`\n\n`gcd`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the greatest common divisor of `|x1|` and `|x2|`\n\n`add`(x1, x2, /[, out, where, casting, order, ...])\n\nAdd arguments element-wise.\n\n`reciprocal`(x, /[, out, where, casting, ...])\n\nReturn the reciprocal of the argument, element-wise.\n\n`positive`(x, /[, out, where, casting, order, ...])\n\nNumerical positive, element-wise.\n\n`negative`(x, /[, out, where, casting, order, ...])\n\nNumerical negative, element-wise.\n\n`multiply`(x1, x2, /[, out, where, casting, ...])\n\nMultiply arguments element-wise.\n\n`divide`(x1, x2, /[, out, where, casting, ...])\n\nReturns a true division of the inputs, element-wise.\n\n`power`(x1, x2, /[, out, where, casting, ...])\n\nFirst array elements raised to powers from second array, element-wise.\n\n`subtract`(x1, x2, /[, out, where, casting, ...])\n\nSubtract arguments, element-wise.\n\n`true_divide`(x1, x2, /[, out, where, ...])\n\nReturns a true division of the inputs, element-wise.\n\n`floor_divide`(x1, x2, /[, out, where, ...])\n\nReturn the largest integer smaller or equal to the division of the inputs.\n\n`float_power`(x1, x2, /[, out, where, ...])\n\nFirst array elements raised to powers from second array, element-wise.\n\n`fmod`(x1, x2, /[, out, where, casting, ...])\n\nReturns the element-wise remainder of division.\n\n`mod`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the element-wise remainder of division.\n\n`modf`(x[, out1, out2], / [[, out, where, ...])\n\nReturn the fractional and integral parts of an array, element-wise.\n\n`remainder`(x1, x2, /[, out, where, casting, ...])\n\nReturns the element-wise remainder of division.\n\n`divmod`(x1, x2[, out1, out2], / [[, out, ...])\n\nReturn element-wise quotient and remainder simultaneously.\n\n`angle`(z[, deg])\n\nReturn the angle of the complex argument.\n\n`real`(val)\n\nReturn the real part of the complex argument.\n\n`imag`(val)\n\nReturn the imaginary part of the complex argument.\n\n`conj`(x, /[, out, where, casting, order, ...])\n\nReturn the complex conjugate, element-wise.\n\n`conjugate`(x, /[, out, where, casting, ...])\n\nReturn the complex conjugate, element-wise.\n\n`maximum`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise maximum of array elements.\n\n`fmax`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise maximum of array elements.\n\n`amax`(a[, axis, out, keepdims, initial, where])\n\nReturn the maximum of an array or maximum along an axis.\n\n`nanmax`(a[, axis, out, keepdims, initial, where])\n\nReturn the maximum of an array or maximum along an axis, ignoring any NaNs.\n\n`minimum`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise minimum of array elements.\n\n`fmin`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise minimum of array elements.\n\n`amin`(a[, axis, out, keepdims, initial, where])\n\nReturn the minimum of an array or minimum along an axis.\n\n`nanmin`(a[, axis, out, keepdims, initial, where])\n\nReturn minimum of an array or minimum along an axis, ignoring any NaNs.\n\n`convolve`(a, v[, mode])\n\nReturns the discrete, linear convolution of two one-dimensional sequences.\n\n`clip`(a, a_min, a_max[, out])\n\nClip (limit) the values in an array.\n\n`sqrt`(x, /[, out, where, casting, order, ...])\n\nReturn the non-negative square-root of an array, element-wise.\n\n`cbrt`(x, /[, out, where, casting, order, ...])\n\nReturn the cube-root of an array, element-wise.\n\n`square`